<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CONNA: Addressing Name Disambiguation on 2 the Fly 3</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
							<email>bochen@ruc.edu</email>
							<idno type="ORCID">0000-0002-9629-5493</idno>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<email>zhang-jing@ruc.edu</email>
							<idno type="ORCID">0000-0003-2019-225X</idno>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn.</email>
							<idno type="ORCID">0000-0003-3487-4593</idno>
						</author>
						<author>
							<persName><forename type="first">Lingfan</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhaoyu</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shu</forename><surname>Zhao</surname></persName>
							<email>zhaoshuzs@ahu.edu.cn</email>
							<idno type="ORCID">0000-0001-7647-3603</idno>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
							<email>licuiping@ruc.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">the Information School</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<postCode>100872</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Tsinghua National Laboratory for Information Science and Technology (TNList)</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Anhui University</orgName>
								<address>
									<postCode>230039</postCode>
									<settlement>Hefei</settlement>
									<region>Anhui</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CONNA: Addressing Name Disambiguation on 2 the Fly 3</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TKDE.2020.3021256</idno>
					<note type="submission">received 18 Sept. 2019; revised 3 Aug. 2020; accepted 29 Aug. 2020.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Name disambiguation is a key and also a very tough problem in many online systems such as social search and academic 6 search. Despite considerable research, a critical issue that has not been systematically studied is disambiguation on the fly -to 7 complete the disambiguation in the real-time. This is very challenging, as the disambiguation algorithm must be accurate, efficient, and 8 error tolerance. In this paper, we propose a novel framework -CONNA -to train a matching component and a decision component 9 jointly via reinforcement learning. The matching component is responsible for finding the top matched candidate for the given paper, 10 and the decision component is responsible for deciding on assigning the top matched person or creating a new person. The two 11 components are intertwined and can be bootstrapped via jointly training. Empirically, we evaluate CONNA on two name disambiguation 12 datasets. Experimental results show that the proposed framework can achieve a 1.21-19.84 percent improvement on F1-score using 13 joint training of the matching and the decision components. The proposed CONNA has been successfully deployed on AMiner -a 14 large online academic search system. 15 Index Terms-Name disambiguation, joint model, multi-field multi-instance Ç 16 1 INTRODUCTION 17 N AME disambiguation, aiming at disambiguating who is 18 who, is one of the fundamental problems of the online 19 academic network platforms such as Google Scholar, Micro-20 soft Academic and AMiner. The problem has been exten-21 sively studied for decades [9], [13], [21], [35], [40], [42], <ref type="bibr" target="#b57">[47]</ref> 22 and most of the works focus on how to group the papers 23 belonging to same persons together into a cluster from 24 scratch. However, online academic systems have already 25 maintained a huge number of person profiles, which are 26 made by the "from scratch" algorithms or human beings. 27 Out of the consideration of the computation and time cost 28 of the real systems, it is not practical to re-compute the clus-29 ters from scratch for the new arriving papers every day. We 30 need a more effective way to deal with the problem of name 31 disambiguation on the fly. 32 This paper takes AMiner as the basis to explain how we 33 deal with the name ambiguity problem when continuously 34 updating persons' profiles. AMiner is a free online academic 35 search and mining system [37], which has already extracted 133,204,120 researchers' profiles from the Web [36] and integrated with 263,781,570 papers from heterogeneous publication databases [47]. Currently, the newly arrived papers of AMiner are more than 500,000 per month. How to correctly assign these papers to the right persons in the system on the fly is a critical problem for many upper applications such as expert finding, academic evaluation, reviewer recommendation and so on. Existing methods on addressing the similar problem of anonymous author identification [2], [46], [50] are possible solutions to continuously disambiguating papers on the fly.</p><p>However, they merely target at finding the top matched person from all the candidates, but fail to deal with the situation when no right person exists, which is common in real academic systems. For example, the papers published by new researchers should not be assigned to any persons, as their profiles have not been established by the system. Thus, to assign a paper on the fly, we need to pay attention to not only find the top matched candidate, but also identify whether to assign the top matched candidate or create a new person. In other words, we consider the absence of the right person from the candidates to be a distinct candidate, the so-called NIL candidate. Fig. <ref type="figure">1</ref> illustrates the problem to be solved in the paper, where given a paper with an author to be disambiguated, the returned right person can be a real person or a non-existing candidate denoted as NIL. Actually, in AMiner, in addition to the "on-the-fly" assignment, we also perform a "from scratch" algorithm to cluster "NIL" papers into new profiles, and run an offline "checking" algorithm to correct errors from historical profiles periodically. In general, AMiner performs a multi-strategy combining "from scratch", "on-the-fly" and "checking" together to solve the complex continuous name disambiguation problem. In this paper, we only introduce the principle of "on-</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>70 the-fly" strategy under the assumption that the previously 71 built profiles are correct, where the errors of the profiles are 72 left to the "checking" strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>73</head><p>To tackle the problem, we first investigate how to find the 74 top matched candidate for a given target paper. Straightfor-75 wardly, we can use the traditional feature-engineering 76 methods to estimate the matching probability between each 77 candidate and the target paper, and then return the top 78 matched candidate. However, these methods are devoted to 79 exactly matching the tokens between a paper and a person, 80 which is too rigid and cannot handle the cases with similar 81 semantics but different tokens. The widely used representa-82 tion-based models <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b56">[46]</ref> can capture the soft/semantic 83 matches through learning low-dimensional dense embed-84 dings, but they may contrarily hurt the performance of exact 85 matching due to the highly compressed embeddings. For 86 example in Fig. <ref type="figure" target="#fig_2">1</ref>, if only depending on the semantics of 87 learned embeddings, we can infer that both of the candi-88 dates are interested in social network mining. However, it is 89 apparent that the exact matches of the coauthor names or 90 words, e.g., "Jie Tang", "Juanzi Li", "social", "network" 91 between the target paper and the right person are more 92 than those of the wrong person. Thus, a challenge is posed: 93 how to capture both the exact matches and the soft matches in a 94 principled way? Simultaneously, the effects of different fields 95 are different. For example, the two matched coauthors in 96 the right person make it significantly more confident than 97 the wrong person with only one matched coauthor, com-98 pared with the matches in other fields. Besides, each person 99 publishes multiple papers, which also take different effects.  <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr" target="#b34">[32]</ref> or if the top matched person is predicted as NIL by an additional classifier <ref type="bibr" target="#b27">[27]</ref>. Essentially, the first process of finding the top matched candidate tries to keep the relative distances between the right and the wrong persons of each target paper, and the later process of assigning the top matched candidate or not devotes to optimize the absolute positions among top matched candidates of all target papers. Intuitively, the two processes can influence each other, and the errors of each process can be corrected by their interactions. However, none of the existing NIL solutions are aware of this and it is not clear how to correct the errors by the interactions between the two processes. Experimental results on two large name disambiguation datasets show that CONNA compares favorably decision accuracy (+1.21%-19.84% in terms of F1) and matching accuracy (+ 3.80%-49.90% in terms of HR@1) against the baselines methods. CONNA is deployed on AMiner to assign papers on the fly now. All codes and data used in the paper are publicly available. <ref type="foot" target="#foot_0">1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM FORMULATION</head><p>We introduce the definitions and the problem in this section.</p><p>Definition 1 Paper. We denote a paper as p associated with multiple fields of attributes, i.e., p ¼ fA 1 ; . . . ; A F g, where A f 2 p represents the fth attribute such as authors' names and affiliations, title, keywords, venue and so on.</p><p>Definition 2 Target paper-author pair. Given a paper p with one of its authors denoted by a, we define a target paperauthor pair as hp; ai, where p is the target paper and a is the target author to be disambiguated. We abbreviate a target paperauthor pair as a target pair henceforth.  there are still 14.59 percent target pairs having small same-coauthor ratios. The coauthor-related features will hardly take effect when dealing with the target pairs with small same-coauthor ratios. For these target pairs, it is also not easy to leverage other features except the coauthor features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Same-coauthor ratio</head><formula xml:id="formula_0">¼ max c2C S c À second c2C S c max c2C S c À min c2C S c ;<label>(1</label></formula><p>To verify the above hypothesis, we estimate the probability of matching each candidate person to the target pair by GBDT based on several features such as the literal similarities between the title, venue, or the affiliations of the target pair and those of a candidate person besides the coauthorrelated features, then evaluate whether the top matched candidate is the right person or not and show the evaluated metric, top 1 Hit Ratio (i.e., HR@1 on the right Y -axis) for different ranges of the same-coauthor ratio in Fig. <ref type="figure">2</ref>. Clearly, we can see that the performance of GBDT decreases dramatically with the decrease of the same-coauthor ratio. The evaluated HR@1 is 66.71 percent when the same-coauthor ratio is within (0, 0.1), but is 96.40 percent within (0.9,1.0).</p><p>The results indicate that when the coauthors of the target pair and the right person are not similar, it is also difficult for feature-engineering methods to capture the similarities of other attributes. Thus, a more promising way to match each candidate with the target pair is required.</p><p>In addition to find the top matched candidate, we also need to consider the situation when no right person exists, which is usually ignored by existing author identification tasks <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b56">[46]</ref>. Suppose an academic system establishes a profile for a researcher only if she/he has published at least one paper, a lot of papers written by the new researchers who publish papers for the first time, cannot be assigned to any existing person in the system. Thus, the right person should be either a real person or a non-existing person. In summary, the problem is defined as: </p><p>to assign a target paper-author pair to its right person.</p><p>In our problem, a is usually used to select candidate persons and p is used to extract features to match the candidates. To simplify the problem, we assume the historical papers assigned to the candidates are correct. However, historical errors cannot be avoided. Thus, we design an independent model to check and correct the historical assignments repeatedly. The study is left in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CONNA</head><p>In this section, we first give an overview of the end-to-end framework and then introduce the matching component which is to match the most possible candidate to the target pair and the decision component which is to decide whether to assign the top matched candidate to the target pair or not respectively. Finally, we introduce how to self-correct the errors of the two components by jointly fine-tuning them through reinforcement learning.</p><p>Fig. <ref type="figure">2</ref>. Distribution of the same-coauthor ratio and the corresponding matching performance. Yellow bar: Distribution of the same-coauthor ratio of the target pairs. Lines: HR@1 performances of different methods.</p><p>2. The names are treated as strings to be compared with each other. Some metrics such as Jaccards Coefficient <ref type="bibr" target="#b31">[30]</ref> and cosine similarity <ref type="bibr" target="#b31">[30]</ref> can easily capture the exact matches. However, they suffer from the sparsity of the token-based representations. For example, the similarity is zero if two representations do not contain any same tokens, even if they are semantically similar. On the other hand, recently, some representationbased models <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b14">[14]</ref> can successfully capture the soft/ semantic similarities, as they embed the high-dimensional sparse features into low-dimensional dense representations.</p><p>Through training on the labeled data, the model can reduce the distance between the semantically similar inputs in the lowdimensional space. However, these models may suffer from the problem of semantic drift. For example, two token-based representations with many overlapped tokens may become dissimilar after being embedded by the model, as the global representation may dilute the effect of the exact same tokens by other different tokens. In summary, the above two types of methods are good at either exact matching or soft matching. To capture both the exact and soft matches, we adopt the interaction-based models <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b52">[43]</ref> widely used in information retrieval. The interaction-based models first build a similarity matrix between each candidate person and the target pair and then apply an aggregation function to extract features from the matrix. These models avoid learning the global representations, thus can reduce the issue of semantic drift.</p><p>Similarity Matrix. We represent the matches between each candidate and the target pair as a similarity matrix S, with each element S ij standing for the basic interaction, i.e., the cosine similarity S ij ¼ p i Ác j jjp i jjÁjjc i jj between p i and c j , where p i represents the embedding of the ith token in the target pair hp; ai and c j represents the embedding of the jth token in the candidate person c, which can be pre-trained by Word2-Vec <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b23">[23]</ref> or BERT <ref type="bibr" target="#b6">[6]</ref>.</p><p>Aggregation Function. For sentence matching, CNN <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b25">[25]</ref> and RNN <ref type="bibr" target="#b45">[39]</ref> are widely used as aggregation functions to extract matching patterns from the similarity matrix.</p><p>However, different from sentence matching, title, keywords, venue and affiliation are all short text. We need to pay more attention to the occurrence of the exact same or semantically </p><formula xml:id="formula_2">X N i¼1 log KðS i Þ;<label>(3)</label></formula><formula xml:id="formula_3">KðS i Þ ¼ fK 1 ðS i Þ; . . . ; K K ðS i Þg;<label>(4)</label></formula><formula xml:id="formula_4">K k ðS i Þ ¼ X M j¼1 exp À ðS ij À m k Þ 2 2s 2 k " # :<label>(5)</label></formula><p>The kernel with m ¼ 1 and s ! 0 only considers the exact matches between tokens, and others, e.g., with m ¼ 0:5, counts the number of tokens in the candidate person whose similarities to a queried token in the target paper are close to 0.5. Thus, the kernel aggregation not only emphasizes the effect of exact matching but also captures the soft matches.   <ref type="table" target="#tab_0">1</ref>.</p><formula xml:id="formula_5">a f ¼ expðwfðA p f ; A c f Þ þ bÞ P f expðwfðA p f ; A c f Þ þ bÞ ; fðhp; ai; cÞ ¼ X f a f fðA p f ; A c f Þ;<label>(6</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>435</head><p>Loss Function. We use the triplet loss function to optimize 436 the matching component. Similar ideas has been also used 437 in <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b56">[46]</ref>, <ref type="bibr" target="#b57">[47]</ref>. Let D r be a set of triplets with each triplet 438 denoted as ðhp; ai; c þ ; c À Þ, where c þ is the right person of the target pair hp; ai and c À is a wrong person sampled from the 440 candidates, the triplet loss function LðQÞ is defined as   </p><formula xml:id="formula_6">LðQÞ¼ X ðhp;ai;c þ ;c À Þ2D r L Q ðhp; ai; c þ ; c À Þ ¼ X ðhp;ai;c þ ;c À Þ2D r</formula><p>where D is the ranked training data, p Q ðhp; ai; ĈÞ is the probability of generating the ranking list Ĉ of the target pair hp; ai by the matching component, and Rðy; ŷÞ is the reward function defined as follows:</p><formula xml:id="formula_8">Rðy; ŷÞ ¼ 1 ŷ ¼ y; 0 otherwise. (<label>10</label></formula><formula xml:id="formula_9">)</formula><p>where ŷ is the predicted label for the top-ranked candidate ĉ of Ĉ and y is the ground truth label. The defined reward function encourages the matching component to float the right person at the top and push the wrong person away from the top. The policy gradient algorithm <ref type="bibr" target="#b37">[34]</ref> is adopted to optimize the expected reward in Eq. ( <ref type="formula" target="#formula_7">9</ref>), whose gradient is calculated as</p><formula xml:id="formula_10">r Q JðQÞ ¼ X ðhp;ai; ĈÞ2 D Rðy; ŷÞrp Q ðhp; ai; ĈÞ; ' X ðhp;ai;ĉ;c À Þ2D r Rðy; ŷÞrL Q ðhp; ai; ĉ; c À Þ:<label>(11)</label></formula><p>Since the probability of a ranking list Ĉ is not easy to be estimated, we transform Ĉ into a set of triplets, with each triplet including the target pair hp; ai, the top ranked candidate ĉ 2 Ĉ and a negative candidate c À 2 Ĉ. Then the loss of a triplet in Eq. ( <ref type="formula">7</ref>) is calculated and the losses of all the triplets are summed up to approximately measure the ranking performance of Ĉ. Thus, the gradient rp Q ðhp; ai; ĈÞ is approximated by rLðhp; ai; ĉ; c À Þ of all the triplets in Ĉ.</p><p>Then the parameters Q of the matching component can be updated by the gradient. After the matching component is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Datasets</head><p>We evaluate CONNA on two name disambiguation datasets: in some well-known academic websites such as Scopus <ref type="bibr" target="#b29">[28]</ref> CiteSeerX <ref type="bibr" target="#b54">[45]</ref>, Web of Science <ref type="bibr" target="#b0">[1]</ref> and PubMed <ref type="bibr" target="#b43">[38]</ref>, or annotate a much smaller datasets by human beings, such as 8,453 <ref type="bibr" target="#b9">[9]</ref>, 6,921 <ref type="bibr" target="#b15">[15]</ref>, 7,528 <ref type="bibr" target="#b38">[35]</ref> and 2,946 annotated persons <ref type="bibr" target="#b24">[24]</ref>.</p><p>Compared to the most popular KDD Cup 2013 challenge dataset, the OAG-WhoIsWho is also superior to it both in quantity (608,363 versus 424,384 in terms of the number of papers) and quality (fully human-labeled versus partially human-labeled).</p><p>We annotate the dataset as follows. From the AMiner system, we choose 642 highly ambiguous names, create the relevant names by the candidate generation strategy in Section 3.1 and select all the authors for each name, collect all the papers assigned for each author and extract title, authors, organizations, keywords and abstract for each paper. We also collect all the unassigned papers for each name from AMiner. Since the assigned papers may be wrongly assigned and the papers are not fully assigned, additional efforts are needed to clean and reassign the papers. First, we clean the dataset by removing the wrongly assigned papers or splitting the papers of an author into different clusters. Second, we annotate the unassigned papers or merge the papers of two authors. We aim to clean the dataset as much as possible but increase the highly reliable assignments. According to the purpose, we only hire one annotator to perform the cleaning step, but hire three annotators to perform the assignment step respectively and then obtain the final results by majority voting their annotations.</p><p>Besides, an annotation tool is developed to recommend highly reliable removing, splitting, assigning or merging operations to the annotators to simplify the human annotation process. <ref type="foot" target="#foot_3">4</ref>KDD Cup <ref type="bibr" target="#b30">[29]</ref>. Is the dataset used in the KDD Cup 2013 challenge 1 to address name disambiguation problem. We collect the training data containing 3,739 authors and 123,447 papers, as only the training labels are published.</p><p>We only use title, organizations, keywords and abstract as features, but ignore coauthor names. As shown in Fig. <ref type="figure" target="#fig_16">7a</ref>, the distribution of same-coauthor ratio is extremely skewed.</p><p>According to Eq. ( <ref type="formula" target="#formula_0">1</ref>), same-coauthor ratio equalling 1 means the second similar candidate and the least similar candidate have the same number of same-coauthors with the target pair. In another word, the most similar candidate is significantly different from all the other candidates when only considering the coauthor name features. Thus, 98 percent target pairs holding 1.0 same-coauthor ratio means only using the coauthor names can correctly assign 98 percent target pairs. In fact, when considering the coauthor name feature, any baselines including our model can easily achieve approximate 99 percent HR@1. Thus, for increasing the difficulty, we ignore coauthor names on this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Comparison Methods</head><p>Matching Component. To evaluate the matching performance, we compare feature engineering-based GBDT and three embedding-based models:   </p><formula xml:id="formula_11">Q ! Q þ mr Q JðQÞ,</formula><p>where m is the learning rate;  </p><formula xml:id="formula_12">tp ¼ jfc Ã ¼ c þ and ĉ ¼ c þ and ŷ ¼ 1gj; fn ¼ jfc Ã ¼ c þ and ŷ ¼ 0gj; tn ¼ jfc Ã ¼ NIL and ŷ ¼ 0gj; fp ¼ jfc Ã ¼ NIL and ŷ ¼ 1g[ fc Ã ¼ c þ and ĉ 6 ¼ c þ and ŷ ¼ 1gj; (<label>12</label></formula><formula xml:id="formula_13">)</formula><p>where tp is the number of the positive samples, with the right persons ranked at the first (i.e., ĉ ¼ c þ ) and also predicted as the right persons (i.e., ŷ ¼ 1). On the contrary, fn counts the positive samples with ŷ ¼ 0. Notation tn denotes the number of negative samples with the first ranked persons predicted as the wrong persons (i.e., ŷ ¼ 0), while fp counts the negative samples with ŷ ¼ 1 and also counts the positive samples with the wrong persons ranked at the first (i.e., ĉ 6 ¼ c þ ) but still predicted as the right persons (i.e., ŷ ¼ 1). Since we aim at assigning the target pair to an existing right person and also assigning it to NIL if there is no right person, we calculate precision and recall for both the</p><formula xml:id="formula_14">cases with c Ã ¼ c þ and c Ã ¼ NIL TABLE 2 Features Extracted for GBDT Model No.</formula><p>Feature description</p><formula xml:id="formula_15">1</formula><p>The number of the papers of c 2</p><p>The number of the coauthors of a in p 3</p><p>The number of the coauthors of c 4</p><p>The number of the same coauthors between a and c 5</p><p>Ratio of the same coauthors between a and c in p's coauthor names 6</p><p>Ratio of the same coauthors between a and c in c's coauthor names 7</p><p>Frequency of a's affiliation in c's affiliations 8</p><p>Ratio of a's affiliation in c's affiliations 9</p><p>Cosine similarity between a's affiliation and c's affiliations 10</p><p>Jaccards similarity between a's affiliation and c's affiliations </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Implementation Details</head><p>We divide the attributes of a paper into two fields: coauthor names and other attributes including title, abstract, organizations and keywords, as coauthor names have no literal or semantic overlaps with other attributes. We pre-train an embedding for each author name and each word. Specifically, we use Word2Vec to train an embedding for an author name in the context of all the coauthors' names in a paper, and train an embedding for a word in the context of all the other occurred words in title, keywords, venue and affiliation. We set the dimension of the embedding as 100. To enable matrix operation, for each paper or candidate person, we restrict the maximal number of author names to 100, the maximal number of words to 500, and the maximal number of papers published by each person to 100.</p><p>The hyper-parameters of the RBF kernel functions are set the same as <ref type="bibr" target="#b52">[43]</ref>. We use 11 RBF kernels, with the hyper-parameters m = f1; 0:9; 0:7; 0:5; 0:3; 0:1; À0:1; À0:3; À0:5; À0:7; À0:9g and s = f10 À3 ; 0:1; 0:1; 0:1; 0:1; 0:1; 0:1; 0:1; 0:1; 0:1; 0:1g.</p><p>Function g in Eq. ( <ref type="formula">7</ref>) is instantiated as a 3-layer MLP followed by a ReLU function which transforms a similarity embedding fðhp; ai; cÞ into a 1-dimensional score. Function h in Eq. ( <ref type="formula">8</ref>) is also a 3-layer MLP which transforms a fðhp; ai; cÞ into 2-dimensional classification probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Matching Performance</head><p>Overall Matching Performance.Table <ref type="table" target="#tab_4">3</ref>  However, it is difficult to directly compare the embeddings of a long text (i.e, all the papers of a candidate person) and a short text (i.e., a target paper).</p><p>In the name disambiguation problem, the exact matches between tokens especially the matches between coauthor names are more important than the soft matches, thus although GBDT only captures the exact matches, it performs better than the representation-based models.  ing the assignment performance, for each target pair, if its same-coauthor ratio is larger than 0.9, we directly apply GBDT to perform paper assignment, otherwise we apply CONNA to complete the task.</p><p>In addition, the online candidate selection is a little different from the offline name variant strategy explained in Section 3.1. To improve the recall of the online predicting as much as possible, we adopt ElasticSearch 5 to perform fuzzy search for similar candidates with each target author.</p><p>Compared with this online fuzzy strategy, the offline candidate selection is more strict, as for annotating high-quality name disambiguation dataset, the simple name variant strategy can already produce enough challenging candidates. However, the fuzzy strategy may result in too many noisy candidates, which increase annotation efforts.</p><p>We develop a demo of disambiguation on the fly in AMiner, 6 and show two screenshots of the demo in Fig. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>This paper is related to the problems of name disambiguation from scratch, author identification and entity linking.</p><p>Name Disambiguation From Scratch. Much effort has been made to disambiguate names from scratch defined as: given a set of papers written by the authors with similar name, it targets at partitioning all the papers into several disjoint  engineering methods <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b38">[35]</ref>, <ref type="bibr" target="#b47">[40]</ref>, <ref type="bibr" target="#b51">[42]</ref> or embedding 1013 models <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b49">[41]</ref>, <ref type="bibr" target="#b54">[45]</ref>, <ref type="bibr" target="#b57">[47]</ref> and then adopt a clustering 1014 algorithm such as hierarchical agglomerative clustering <ref type="bibr" target="#b2">[3]</ref>,</p><p>1015 <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b49">[41]</ref>, <ref type="bibr" target="#b54">[45]</ref>, <ref type="bibr" target="#b57">[47]</ref>, K-means <ref type="bibr" target="#b47">[40]</ref>, <ref type="bibr" target="#b61">[49]</ref>, DBSCAN <ref type="bibr" target="#b13">[13]</ref> or 1016 semi-supervised clustering <ref type="bibr" target="#b21">[21]</ref> to partition these papers.</p><p>1017</p><p>Embedding models further include graph auto-encoder <ref type="bibr" target="#b57">[47]</ref>, 1018 heterogeneous GCN <ref type="bibr" target="#b26">[26]</ref> and adversarial representation 1019 learning <ref type="bibr" target="#b49">[41]</ref>. Continuous name disambiguation is formal-1020 ized differently from the above problem, thus it can not be 1021 solved by the above methods.</p><p>1022</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>100</head><label></label><figDesc>For example in Fig. 1, in the papers of the right person, the 101 effect of the second similar paper may be diluted by the first 102 irrelevant one if combining all papers. Thus, an effective way 103 to distinguish the effects of different fields of the attributes and dif-104 ferent instances of the published papers is worth studying. 105 After obtaining the top matched candidate, we need to 106 decide whether to assign the top matched candidate or NIL 107 candidate to the target paper. The NIL problem is widely 108 studied in entity linking, a similar problem that aims at link-109 ing the mentions extracted from the unstructured text to the 110 right entities in a knowledge graph. We can adopt the simi-111 lar idea to assign the NIL candidate to a target paper if the 112 score of the top matched person is smaller than a NIL 113 threshold</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>To this end, in AMiner, we propose a joint model CONNA that consists of a matching component and a decision component to solve CONtinuous Name Ambiguity, i.e., name disambiguation on the fly, where "on the fly" emphasizes the solved problem in the paper is different from name disambiguation "from scratch". In the model, the matching component adopts an interaction-based deep learning model plus a kernel pooling strategy to capture both the exact and soft matches between a target paper and a candidate person and also a multi-field multi-instance strategy to distinguish the effects of different attributes and different instances of papers. The decision component is trained on the similarity embeddings learned by the matching component, to further decide whether a top matched person is the right person or not. In addition, the errors of the proposed model can be self-corrected through jointly fine-tune the two components by reinforcement learning. To summarize, the main contributions include: We propose CONNA consisting of a multi-field multi-instance interaction-based matching component and a decision component to address the problem of continuous name disambiguation. With jointly fine-tuning of the two components by reinforcement learning, the errors of the two components can be self-corrected.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Disambiguation on the fly. Given a target paper with target author as "Yang Yang", we aim at searching for the right person of "Yang Yang" from the candidates, where the right person can be a real person or a non-existing candidate denoted as NIL.</figDesc><graphic url="image-1.png" coords="2,26.93,45.52,249.60,137.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>is the number of the same coauthors of a in p with 193 the candidate c. Same-coauthor ratio reflects the gap 194 between the most similar candidate and the second similar 195 candidate. The denominator is to normalize the gap calcu-196 lated for different candidate lists into the same scale. It will 197 be easier to distinguish the right person from the other can-198 didates when the same-coauthor ratio is larger. 199 Then we plot the distribution of the same-coauthor ratio 200 for all the target pairs in Fig. 2, where X-axis indicates the 201 same-coauthor ratio of a target pair, and Y -axis on the left 202 denotes the proportion of the target pairs with a certain same-203 coauthor ratio. From the figure, we can see that although 204 62.72 percent target pairs have large same-coauthor ratios, 205</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Problem 1</head><label>1</label><figDesc>Disambiguation on the fly. Given a training set D ¼ fðhp; ai; CÞg, for each target paper-author pair hp; ai and the corresponding candidate persons C, the right person c Ã can be either a real person in C denoted by c þ or a non-existing person denoted by NIL, and other persons except c Ã in C are the wrong persons denoted by fc À g. The target is to learn a predictive function F : fðhp; ai; CÞg ! fc Ã g;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1</head><label></label><figDesc>indicates ĉ is the right person and ŷ ¼ 0 indicates ĉ is the 291 wrong person. We construct the training data D c for the 292 decision component by extracting ðhp; ai; c þ Þ as the positive 293 instance (i.e., y ¼ 1) and ðhp; ai; ĉÀ Þ as the negative instance 294 (i.e., y ¼ 0) from each sample ðhp; ai; ĈÞ, where ĉÀ indicates 295 the top matched wrong person in C. Finally, we fine-tune 296 the matching component based on the feedback (i.e., error 297 cases) of the decision component, and then fine-tune the 298 decision component based on the updated output of the 299 matching component. Essentially, the matching component 300 tries to keep the relative distances between the right and the 301 wrong persons of each target pair, and the decision compo-302 nent devotes to optimize the absolute positions between the 303 top matched persons of all the target pairs found by the 304 matching component. 305 During the online predicting process, to disambiguate a 306 target pair hp; ai, the matching component first finds out the 307 top matched candidate person ĉ, then based on the similar-308 ity features fðhp; ai; ĉÞ output by the matching component, the decision component will predict the label ŷ for ĉ and finally assign the person c Ã to hp; ai, where c Ã ¼ ĉ if ŷ ¼ 1 and c Ã ¼ NIL otherwise.3.2 Matching Basic Profile Model (BP). Let's imagine how humans assign a paper to a person. The humans usually browse all the papers published by the person to understand her/his affiliation, overall research interest, and frequently collaborated authors, then comparing them with those of the paper. In other words, humans directly compare the person's profile with the target pair, which can guide us to build our model. Thus, we name the model as the basic profile model. Specifically, we merge all the attributes of a paper and divide them into a set of tokens to represent the paper, and then merge the tokens of all the papers of a person into a unified set of tokens to represent the person's profile. Based on the tokenbased representations of the target paper and the person, we can estimate the similarity between them. Note a complete author name or a word in titles, keywords, venues and affiliations is viewed as a token.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The whole framework of training and predicting.</figDesc><graphic url="image-3.png" coords="4,36.00,45.53,231.48,142.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 illustrates the model. Multi-Field Profile Model (MFP). The basic profile model does not distinguish different fields of attributes but groups them together. However, it is not necessary to compare different attributes, such as comparing authors with venues. Moreover, it takes more effect to compare coauthor names than other attributes. So we build a basic profile model on each field of the attributes respectively, i.e., different attributes are not allowed to be compared, then aggregate the similarity embeddings together by the corresponding attention coefficients estimated by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>) where fðA p f ; A c f Þ denotes the similarity embedding between A p f and A c f with A p f being the fth field of p and A c f being that of the candidate person c. Notations w and b denote the parameters. The model is named as multi-field profile model and is shown in Fig. 5. 410 Multi-Field Multi-Instance Model (MFMI). A person usually 411 publishes multiple papers. Some persons even publish papers 412 of multiple topics on multiple fields of venues and collaborate 413 with multiple communities of persons. In this scenario, a target 414 paper can be only similar to a small part of a person's diverse 415 profile, but is totally irrelevant to other parts of the profile. 416 However, the multi-field profile model may dilute the similar-417 ity with this small part when summing the similarities with all 418 the tokens in a person's profile together by Eq. (5). To reduce 419 the impact from the irrelevant papers, we build a multi-field 420 model between the target pair and each published paper of the 421 candidate person, and then aggregate the resultant similarity 422 embeddings of all the published papers by their correspond-423 ing attention coefficients, which are estimated the same as 424 Eq. (6). The model is named as the multi-field multi-instance 425 model and is shown in Fig. 6. 426 The Combination Model (CONNA r ). Essentially, the multi-427 field profile model captures the global similarities between 428 the target pair and a person's profile, while the multi-field 429 multi-instance model considers the local similarities 430 between the target pair and each of the papers published by 431 a person. Both of them can be explained intuitively, thus we 432 can combine their output similarity embeddings together as 433 the final feature embedding. We summarize different com-434 ponent variants in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>maxf0; gðfðhp; ai; c À ÞÞ À gðfðhp; ai; c þ ÞÞ þ mÞg; (7) 442 442</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 4 .Fig. 6 .</head><label>46</label><figDesc>Fig. 4. The basic profile model. Fig. 5. The multi-field profile model.</figDesc><graphic url="image-5.png" coords="5,304.33,45.52,221.01,118.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>443where g is defined to be a non-linear function to transform 444 the similarity embedding f into a one-dimension matching 445 score that can be compared between the positive pair 446 ðhp; ai; c þ Þ and the negative pair ðhp; ai; c À Þ. Notation Q indi-447 cates the parameter of the matching component and m &gt; 0 448 is a margin enforcing a distance between positive pairs and 449 negative pairs. We optimize the triplet loss instead of 450 directly optimizing the cross-entropy loss between the out-451 put matching score and the true label, as we aim at finding 452 the top matched candidate from all the candidates for each 453 target pair, thus the objective should be keeping a relative 454 order within the candidate persons of each target pair 455 instead of keeping a global order among all the ðp; cÞ pairs. 456 The triplet loss is more direct and close to our objective than 457 the cross-entropy loss. 458 3.3 Decision 459 The decision component is built upon the output of the 460 matching component to identify the right person, who can be 461 either the top matched real person or NIL. The candidate per-462 sons C of each sample ðhp; ai; CÞ 2 D are ranked into Ĉ based 463 on the matching probabilities estimated by the matching 464 component. Note for the samples with c Ã ¼ c þ , the real right 465 person c þ may be ranked the first or not. Then the decision 466 component is trained to predict the first ranked person ĉ 2 Ĉ 467 to be a right person (i.e., ŷ ¼ 1) or a wrong person (i.e., 468 ŷ ¼ 0). To achieve the goal, we construct the training data D c 469 from the ranked dataset D ¼ fðhp; ai; ĈÞg. Specifically, from 470 each sample ðhp; ai; ĈÞ, we extract ðhp; ai; c þ Þ as the positive 471 instance (i.e., y ¼ 1) and extract ðhp; ai; ĉÀ Þ as the negative 472 instance (i.e., y ¼ 0), where ĉÀ indicates the first ranked 473 wrong person in C. In another words, the positive instances 474 are only extracted from the samples with c Ã ¼ c þ , while the 475 negative instances are extracted from both the samples with 476 c Ã ¼ c þ and the samples with c Ã ¼ NIL. For an instance 477 ðhp; ai; cÞ, we use the similarity embedding fðhp; ai; cÞ output 478 by the matching component as its feature. Thus, D c ¼ 479 fðfðhp; ai; c þ Þ; y ¼ 1Þg [ fðfðhp; ai; ĉÀ Þ; y ¼ 0Þg. Then we 480 train a multi-layer perceptron hðFÞ hðFÞ : ffðhp; ai; cÞg ! fyg; the label of the instance ðhp; ai; cÞ, whose value 484 equals 1 if ðhp; ai; cÞ is a positive instance and 0 otherwise. 485 3.4 Reinforcement Self-Correction 486 We finally fine-tune the two components by jointly training 487 them to correct their errors by themselves. The matching 488 component can be viewed as the generator to generate the 489 ranking list. Without the decision component, the triplet loss 490 in Eq. (7) is used to measure whether the ranking list is good 491 or not. However, as the final objective is to determine whether the top ranked candidate is the right person or not, the triplet loss is not enough to verify the effect. Fortunately, we can use the prediction result of the top ranked candidate by the decision component as the delayed feedback to the ranking results of the matching component. Specifically, we can punish the ranking list with the wrongly predicted top candidate and reward the ranking list with the correctly predicted top candidate. Then based on the reward we update the matching component, expecting the ranking lists generated by the matching component to the decision component are more accurate. Followed by the motivation, we propose fine-tuning the two components via reinforcement learning. Specifically, the objective is to maximize the expected reward of the ranking lists generated by the matching component JðQÞ ¼ X ðhp;ai; ĈÞÞ2 D p Q ðhp; ai; ĈÞRðy; ŷÞ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>tuned, the decision component is also updated based on the updated similarity embeddings output by the matching component. Algorithm 1 illustrates the joint training process, where we first pre-train the matching component and the decision component, and then jointly fine-tune the two components together.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>601GBDT.</head><label></label><figDesc>Is a widely used model to solve KDD Cup 2013 602 challenge-1<ref type="bibr" target="#b7">[7]</ref>,<ref type="bibr" target="#b19">[19]</ref>,<ref type="bibr" target="#b60">[48]</ref>. We train a GBDT model to esti-603 mate a matching probability between each candidate and 604 the target pair. The extracted features for GBDT are 605 shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>613 1 : 2 : 3 : 4 : 5 : 6 : repeat 619 7 : 8 :</head><label>12345678</label><figDesc>Build D r ¼ fðhp; ai; c þ ; c À Þg from D; 614 Pre-train Q of the matching component on D r ; 615 Rank D by the matching component to generate D; 616 Build D c ¼ fðfðhp; ai; cÞ; yÞg from D; 617 Pre-train F of the decision component on D c ; 618 for ðhp; ai; ĈÞ 2 D do 620 Predict ŷ for ĉ by the decision component;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>624 12 :HetNetE [ 2 ]</head><label>122</label><figDesc>Re-rank D to generate D by the matching component; 625 13: Re-generate D c from D; 626 14: Update F of the decision component on D c ; 627 15: until Convergence 628 Camel [46]. Is a representation-based model. Given a trip-629 let ðhp; ai; c þ ; c À Þ, it first represents hp; ai by p's title, and rep-630 resents c þ and c À by their identities. Then it calculates the 631 matching scores for both ðhp; ai; c þ Þ and ðhp; ai; c À Þ, . Is similar as Camel except that hp; ai is repre-635 sented by all its attributes. 636 GML [47]. Is a representation-based model to identify 637 whether two papers are written by the same person through 638 optimizing a triplet loss. The model accepts the pre-trained 639 embeddings of all the tokens in a paper as input and output 640 an embedding for the paper. We represent a person by aver-641 aging all his/her papers' embeddings. 642 Decision Component. To evaluate the performance of the 643 decision component, we compare two strategies: 644 Threshold [8]. Picks the top matched person whose score 645 is lower than a threshold as NIL, where the threshold is 646 determined as the value when the best accuracy is obtained 647 on a validation set. We use the same matching model as our 648 proposed method to obtain the top matched persons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. (a) Distribution of the same-coauthor ratio on KDD Cup dataset; (b) The effects of different attributes.</figDesc><graphic url="image-7.png" coords="7,306.94,45.52,215.64,87.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>shows the matching performance of the proposed model, the model variants and the comparison methods on the two datasets OAG-WhoIsWho and KDD Cup. In terms of HR@1, the proposed CONNA+Fine-tune achieves 3.80 to 49.90 percent improvement over all the baseline methods.Camel, HetNetE and GML are all representation-based deep learning models, which can capture the soft/semantic matches, but they will dilute the effect of the exact matches of tokens due to the global representations of the papers and persons. Among the three models, HetNetE uses all the attributes of a paper rather than the single title to represent a paper, which achieves better performance than Camel. Camel and HetNetE represent the candidate persons only based on their identities. Thus they suffer from the sparsity issue, i.e, the embeddings of the persons cannot be trained accurately if they publish few papers. GML avoids the sparsity issue through representing persons by their published papers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>11. In the demo, users are allowed to search a paper by its title, then select the expected paper and click one author name to see the disambiguation results of the paper with the current name. Under the selected paper, we present the most matched candidates by the trained matching component in CONNA on the left, and show the decision result of the assigned person by the trained decision component in CONNA on the right. Fig. 11a shows a case with c Ã ¼ c þ .We can see that our model can correctly match "Jing Zhang" from Renmin University for the author "Jing Zhang" in the paper "StructInf: Mining Structural Influence from Social Streams" at the top and then decide the top matched one as the final assigned person. Fig.11bshows a case with c Ã ¼ NIL. Since "Bo Chen" of the paper "MEgo2Vec: EmbeddingMatched Ego Networks for User Alignment Across SocialNetworks" is a postgraduate student whose profile has not been established by AMiner, none of the existing "Bo Chen" should be assigned to the paper. Our model correctly assigns NIL to this case. Besides, since errors are still inevitable, we allow the users to provide feedback to our decision results. Specifically, users are allowed to directly "submit" the result if they agree with it, otherwise, they can choose another right person from the top matched persons. The feedback can be simply regarded as new training instances to update the decision performance at each step of the joint training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Convergence analysis.</figDesc><graphic url="image-10.png" coords="11,44.96,45.52,213.60,87.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-11.png" coords="12,28.74,45.52,246.00,420.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 Matching</head><label>1</label><figDesc>Component Variants of CONNA</figDesc><table><row><cell>Component variants</cell><cell>Key idea</cell></row><row><cell>Basic Profile (BP)</cell><cell>The basic interaction-based model</cell></row><row><cell>Multi-field Profile (MFP)</cell><cell>Build BP for each field</cell></row><row><cell>Multi-field Multi-instance (MFMI) CONNA r</cell><cell>Build MFP for each instance Combine MFP and MFMI</cell></row></table><note>OAG-WhoIsWho 3 : Is the largest human-annotated name disambiguation dataset so far, which is consist of 608,363 papers belonging to 57,138 persons of 642 common names. Existing work either leverage the disambiguating results by algorithms</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>As the model can directly predict a</figDesc><table><row><cell>606</cell></row></table><note>609 Algorithm 1. Reinforcement Joint Training 610 Input: A training set D ¼ fðhp; ai; CÞg. 611 Output: A matching component and a decision component 612 parametrized by Q and F respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 3</head><label>3</label><figDesc>Performance of the Matching Results (%)</figDesc><table><row><cell>Model</cell><cell cols="3">OAG-WhoIsWho</cell><cell></cell><cell>KDD Cup</cell><cell></cell></row><row><cell></cell><cell cols="5">HR@1 HR@3 MRR HR@1 HR@3</cell><cell>MRR</cell></row><row><cell>Camel</cell><cell>41.20</cell><cell>62.00</cell><cell>55.00</cell><cell>44.62</cell><cell>67.19</cell><cell>59.44</cell></row><row><cell>HetNetE</cell><cell>46.00</cell><cell>67.00</cell><cell>60.24</cell><cell>51.06</cell><cell>77.44</cell><cell>66.41</cell></row><row><cell>GML</cell><cell>70.87</cell><cell>94.53</cell><cell>82.59</cell><cell>72.13</cell><cell>95.34</cell><cell>82.90</cell></row><row><cell>GBDT</cell><cell>87.30</cell><cell>98.10</cell><cell>92.71</cell><cell>84.18</cell><cell>92.09</cell><cell>89.59</cell></row><row><cell>CONNA r (BP) CONNA r (MFP) CONNA r (MFMI)</cell><cell>86.20 88.00 89.45</cell><cell>96.40 98.75 98.40</cell><cell>92.20 93.25 93.82</cell><cell>91.12 -91.45</cell><cell>95.72 -95.80</cell><cell>93.73 -94.03</cell></row><row><cell>CONNA</cell><cell>90.45</cell><cell>98.30</cell><cell>94.46</cell><cell>92.10</cell><cell>96.35</cell><cell>94.66</cell></row><row><cell>CONNA+Fine-tune</cell><cell>91.10</cell><cell>98.45</cell><cell>94.86</cell><cell>92.60</cell><cell>96.71</cell><cell>94.95</cell></row></table><note>of each target paper, the relative order is not directly opti-914 mized, leading to a lot of mistakes in the final results. 915 Threshold can be viewed as a global optimization model, 916 but merely uses a heuristic threshold to distinguish differ-925 Compared with CONNA, the performance of CONNA 926 +Fine-tune is further improved, as some of the wrongly-pre-927 dicted instances are gradually represented better to gener-928 ate accurate similarity embeddings by the iteratively 929 refined matching component, which will finally increase the 930 number of rightly predicted instances. The result demon-931 strates that the errors of the decision component can be 932 reduced through jointly fine-tuning of the two components.933Convergence Analysis. We plot the train/test loss of the 953 than GBDT on both the ranking and the decision performance, 954 from Fig.2, we can see for about 62.17 percent easy samples, 955 i.e., the target pairs with the same-coauthor ratio larger than 956 0.9, the ranking performance of GBDT is comparable to 957 CONNA, where the ranking performance directly determines 958 the final decision performance of the top-1 candidates. Thus, 959 to improve the online assignment efficiency meanwhile keep-960</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 5 Average</head><label>5</label><figDesc>Time Cost(ms) of Assigning Each Target Pair</figDesc><table><row><cell>Model</cell><cell>Feature Preparing</cell><cell>Matching</cell><cell>Decision</cell></row><row><cell>GBDT</cell><cell>183.34</cell><cell>-</cell><cell>3.61</cell></row><row><cell>CONNA</cell><cell>260.45</cell><cell>76.12</cell><cell>6.34</cell></row></table><note>5. https://www.elastic.co 6. http://na-demo.aminer.cn/ 1010 clusters, with each of them corresponds to a real person. 1011 Existing work first represent papers by traditional feature 1012</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">. https://github.com/BoChen-Daniel/TKDE-2019-CONNA</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1">IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">. https://www.aminer.cn/whoiswho</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">. https://www.aminer.cn/annotation</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4">CHEN ET AL.: CONNA: ADDRESSING NAME DISAMBIGUATION ON THE FLY</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the National Key R&amp;D Program of China (No.2018YFB1004401) and NSFC (No.61532021, 61772537, 61772536, 61702522).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Especially when the same-coauthor ratio is less than 0.1, the performance gap between CONNA and GBDT is significantly more than 16 percent. The result indicates that CONNA is more suitable to tackle the hard cases, i.e. the cases that are hardly predicted by similar coauthors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Decision Performance</head><p>Table <ref type="table">4</ref> shows the final decision performance of the proposed model and the comparison methods. Comparing with other methods, in terms of F1, the proposed joint model CONNA+Fine-tune achieves 1.69-19.84 percent improvement on the samples with c Ã ¼ c þ and 1.21-14.03 percent improvement on the samples with c Ã ¼ NIL. We evaluate the results on both of the samples as we aim at not only assigning the target papers to the right persons if they exist, but also assigning them to NIL if the right persons do not exist. The problem in this paper is not merely a matching or a classification decision problem, but can be solved by first matching each candidate to the target paper p and then deciding whether the top matched person is right or not. Thus, we need to not only keep the relevant order within each candidate list, but also globally distinguish all the positive pairs from all the negative pairs. GBDT and CrossEntropy only aim to optimize the global positions of all the ðhp; ai; cÞ pairs, but ignore the relative order within each candidate list. Although the globally predicted probabilities can be used to compare the candidates   an author identification challenge to solve the similar problem. However, the situation that no right person exists was not considered and all the participations devoted to featureengineering methods <ref type="bibr" target="#b7">[7]</ref>, <ref type="bibr" target="#b60">[48]</ref>.</p><p>Entity Linking. Entity linking aims at linking the mentions extracted from the unstructured text to the right entities in a knowledge graph <ref type="bibr" target="#b32">[31]</ref>. Feature-based <ref type="bibr" target="#b17">[17]</ref> or neural models such as skip-gram <ref type="bibr" target="#b53">[44]</ref>, autoencoder <ref type="bibr" target="#b11">[11]</ref>, CNN <ref type="bibr" target="#b36">[33]</ref>,</p><p>LSTM <ref type="bibr" target="#b16">[16]</ref> are proposed to calculate the similarity between the context of a mention and a candidate entity. The NIL problem is widely studied in entity linking. The main solutions usually include the NIL threshold methods <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr" target="#b34">[32]</ref> predicting the mention as unlinkable if the score of the top ranked entity is smaller than a NIL threshold, the classification methods <ref type="bibr" target="#b22">[22]</ref>, <ref type="bibr" target="#b27">[27]</ref> which predict the unlinkable mentions by a binary classifier, and the unified models incorporating unlinkable mention prediction process into entity matching process <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b10">[10]</ref>. Different from above, we jointly train the NIL decision model and the candidate matching model to boost both of their performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>This paper presents the first attempt to formalize and solve the problem of name disambiguation on the fly by considering different cases of assignments, in particular when a paper cannot be assigned to any existing persons in the system. We propose a novel joint model that consists of a match-  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The impact of name-matching and blocking on author disambiguation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Backes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th ACM Int</title>
				<meeting>27th ACM Int</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="803" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Task-guided and path-augmented heterogeneous network embedding for author identification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th ACM Int. Conf. Web Search Data Mining</title>
				<meeting>10th ACM Int. Conf. Web Search Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="295" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards robust unsupervised personal name disambiguation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint Conf. Empir. Methods Natural Lang</title>
				<meeting>Joint Conf. Empir. Methods Natural Lang</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for mention-ranking coreference models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empir. Methods Natural Lang</title>
				<meeting>Conf. Empir. Methods Natural Lang</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2256" to="2262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for soft-matching N-grams in Ad-hoc search</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th ACM Int. Conf. Web Search Data Mining</title>
				<meeting>11th ACM Int. Conf. Web Search Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="126" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m">A demo of disambiguation on the fly in AMiner</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pretraining of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. North Amer</title>
				<meeting>Conf. North Amer</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">KDD cup 2013-author-paper identification challenge: Second place team</title>
		<author>
			<persName><forename type="first">D</forename><surname>Efimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Solecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD Cup Workshop</title>
				<meeting>KDD Cup Workshop<address><addrLine>Art</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Linking entities to a knowledge base with query expansion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gottipati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empir. Methods Natural Lang. Process</title>
				<meeting>Conf. Empir. Methods Natural Lang. ess</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="804" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Two supervised learning approaches for name disambiguation in author citations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM/IEEE-CS Joint Conf. Digit. Libraries</title>
				<meeting>4th ACM/IEEE-CS Joint Conf. Digit. Libraries</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="296" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A generative entity-mention model for linking entities with knowledge base</title>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 49th Annu. Meeting Assoc</title>
				<meeting>49th Annu. Meeting Assoc</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="945" to="954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning entity representation for entity disambiguation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 51st Annu. Meeting Assoc</title>
				<meeting>51st Annu. Meeting Assoc</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="30" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th Int. Conf. Neural Inf</title>
				<meeting>27th Int. Conf. Neural Inf</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient name disambiguation for large-scale databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ertekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Princ. Data Mining Knowl</title>
				<meeting>Eur. Conf. Princ. Data Mining Knowl</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="536" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd ACM Int. Conf. Inf. Knowl. Manage</title>
				<meeting>22nd ACM Int. Conf. Inf. Knowl. Manage</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Construction of a large-scale test set for author disambiguation</title>
		<author>
			<persName><forename type="first">I.-S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-J</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="452" to="465" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">End-to-end neural entity linking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O.-E</forename><surname>Ganea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Conf. Comput. Natural Lang</title>
				<meeting>22nd Conf. Comput. Natural Lang</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="519" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">LCC approaches to knowledge base population at TAC 2010</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Monahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nezda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Text Anal. Conf</title>
				<meeting>Text Anal. Conf</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scaling Word2Vec on big corpus</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Drozd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matsuoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="175" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Feature engineering and tree modeling for author-paper identification challenge</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD Cup Workshop</title>
				<meeting>KDD Cup Workshop<address><addrLine>Art</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What&apos;s in a name?: An unsupervised approach to link users across communities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-I</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Hon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th ACM Int. Conf. Web Search Data Mining</title>
				<meeting>6th ACM Int. Conf. Web Search Data Mining</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="495" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ethnicity sensitive author disambiguation using semi-supervised learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Louppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Al-Natsheh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suszhanik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Maguire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Knowl. Eng. Semantic Web</title>
				<meeting>Int. Conf. Knowl. Eng. Semantic Web</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="272" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">HLTCOE efforts in entity linking at TAC KBP 2010</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Text Anal. Conf</title>
				<meeting>Text Anal. Conf</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Representations</title>
				<meeting>Int. Conf. Learn. Representations</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data sets for author name disambiguation: An empirical analysis and a new resource</title>
		<author>
			<persName><forename type="first">M.-C</forename><surname>M€ Uller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Reitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1467" to="1500" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Text matching as image recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th AAAI Conf</title>
				<meeting>13th AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2793" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised author disambiguation using heterogeneous graph convolutional network embedding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Big Data</title>
				<meeting>IEEE Int. Conf. Big Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="910" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Local and global algorithms for disambiguation to Wikipedia</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 49th</title>
				<meeting>49th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Annu. Meeting Assoc. Comput. Linguistics: Hum. Lang. Technol</title>
		<imprint>
			<biblScope unit="page" from="1375" to="1384" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Seed+ expand&apos;: A general methodology for detecting publication oeuvres of individual researchers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Reijnhoudt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Costas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Noyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Scharnhorst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1403" to="1417" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The Microsoft academic search dataset and KDD cup 2013</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD Cup Workshop</title>
				<meeting>KDD Cup Workshop</meeting>
		<imprint>
			<date type="published" when="1167">2013. 1167</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Introduction to Modern Information 1168 Retrieval</title>
		<author>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>McGraw-Hill</publisher>
			<biblScope unit="page">1169</biblScope>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Entity linking with a knowledge 1170 base: Issues, techniques, and solutions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data</title>
		<imprint>
			<date type="published" when="1171">1171</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><surname>Eng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1172">Feb. 2015. 1172</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="443" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Linking named entities 1173 in tweets with knowledge base via user interest modeling</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">1174</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m">Proc. 19th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
				<meeting>19th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="1176">1175 2013. 1176</date>
			<biblScope unit="page" from="68" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Modeling 1177 mention, context and entity with neural networks for entity dis-1178 ambiguation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Int. Joint Conf</title>
				<meeting>24th Int. Joint Conf</meeting>
		<imprint>
			<date type="published" when="1180">2015. 1180</date>
			<biblScope unit="page" from="1333" to="1339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with func-1182 tion approximation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Neural Inf</title>
				<meeting>Int. Conf. Neural Inf</meeting>
		<imprint>
			<date type="published" when="1181">1181. 1183 2000. 1184</date>
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A unified probabilis-1185 tic framework for name disambiguation in digital library</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno>IEEE 1186</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="1187">Jun. 2012. 1187</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A combination approach 1188 to web user profiling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1190</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">ArnetMiner: 1191 Extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th 1192</title>
				<meeting>14th 1192</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
		<imprint>
			<biblScope unit="page" from="990" to="998" />
			<date type="published" when="1193">2008. 1193</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Author name disambiguation 1194 in MEDLINE</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Torvik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Smalheiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1195</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Art</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">1196</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Match-SRNN: 1197 Modeling the recursive matching structure with spatial RNN</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">1198</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int. Joint Conf</title>
				<meeting>25th Int. Joint Conf</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">1199</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A constraint-based topic 1200 modeling approach for name disambiguation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Comput. Sci</title>
		<imprint>
			<biblScope unit="page">1201</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">China</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">1202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Author name disambiguation on heterogeneous 1203 information network with adversarial representation learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">1204</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
				<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="1205">2020. 1205</date>
			<biblScope unit="page" from="238" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">ADANA: Active name 1206 disambiguation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 11th Int. Conf. Data Mining</title>
				<meeting>IEEE 11th Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="1208">2011. 1208</date>
			<biblScope unit="page" from="1207" to="1794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">End-to-end neu-1209 ral ad-hoc ranking with kernel pooling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 40th Int. ACM 1210 SIGIR Conf. Res. Develop. Inf</title>
				<meeting>40th Int. ACM 1210 SIGIR Conf. Res. Develop. Inf</meeting>
		<imprint>
			<date type="published" when="1211">2017. 1211</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Joint learning 1212 of the embedding of words and entities for named entity dis-1213 ambiguation</title>
		<author>
			<persName><forename type="first">I</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shindo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takefuji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th SIGNLL Conf. Comput. Natural Lang</title>
				<meeting>20th SIGNLL Conf. Comput. Natural Lang</meeting>
		<imprint>
			<biblScope unit="page">1214</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Name disambiguation in anony-1216 mized graphs using network embedding</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. 1217</title>
				<meeting>ACM Int. Conf. 1217</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName><surname>Inf</surname></persName>
		</author>
		<author>
			<persName><surname>Knowl</surname></persName>
		</author>
		<author>
			<persName><surname>Manage</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1218">2017. 1218</date>
			<biblScope unit="page" from="1239" to="1248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Camel: 1219 Content-aware and meta-path augmented metric learning for author 1220 identification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. World Wide Web Conf</title>
				<meeting>World Wide Web Conf</meeting>
		<imprint>
			<date type="published" when="1221">2018. 1221</date>
			<biblScope unit="page" from="709" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">1222</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">AMiner: Clustering, maintenance, and human in the loop</title>
		<imprint>
			<biblScope unit="page">1223</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m">Proc. 24th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
				<meeting>24th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="1225">1224 2018. 1225</date>
			<biblScope unit="page" from="1002" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The scorecard solution to the author-paper identifica-1226 tion challenge</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD Cup Workshop</title>
				<meeting>KDD Cup Workshop<address><addrLine>Art</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">1227</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Toward a K-means clustering approach to adaptive 1228 random testing for object-oriented software</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. China Inform</title>
		<imprint>
			<biblScope unit="page">1229</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName><surname>Sci</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page">1230</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Uncertainty-optimized deep learning model for 1231 small-scale person re-identification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. China Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1233</biblScope>
			<date type="published" when="1232">1232. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m">Bo Chen is currently working toward the post</title>
				<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
