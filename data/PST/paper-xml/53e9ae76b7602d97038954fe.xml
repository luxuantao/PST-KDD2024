<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A taxonomy and an empirical analysis of multiple objective ant colony optimization algorithms for the bi-criteria TSP q</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-06-05">5 June 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">C</forename><surname>Garcı ´a-Martı ´nez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Artificial Intelligence</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<postCode>18071</postCode>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">O</forename><surname>Cordo ´n</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Artificial Intelligence</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<postCode>18071</postCode>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
							<email>herrera@decsai.ugr.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Artificial Intelligence</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<postCode>18071</postCode>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A taxonomy and an empirical analysis of multiple objective ant colony optimization algorithms for the bi-criteria TSP q</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-06-05">5 June 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">17A0E56F21AD81C2D9CFCDB61416AFD3</idno>
					<idno type="DOI">10.1016/j.ejor.2006.03.041</idno>
					<note type="submission">Received 30 August 2004; accepted 6 March 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Traveling salesman</term>
					<term>Ant colony optimization</term>
					<term>Multiple objective optimization</term>
					<term>Multiple objective evolutionary algorithms</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The difficulty to solve multiple objective combinatorial optimization problems with traditional techniques has urged researchers to look for alternative, better performing approaches for them. Recently, several algorithms have been proposed which are based on the ant colony optimization metaheuristic. In this contribution, the existing algorithms of this kind are reviewed and a proposal of a taxonomy for them is presented. In addition, an empirical analysis is developed by analyzing their performance on several instances of the bi-criteria traveling salesman problem in comparison with two wellknown multi-objective genetic algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-criteria optimization problems are characterized by the fact that several objectives have to be simultaneously optimized, thus making especially difficult the problem solving <ref type="bibr" target="#b5">[6]</ref>. The use of metaheuristics for these problems has been subject to a growing interest in the last decade. The existence of many multi-objective problems in the real world, their intrinsic complexity and the advantages of metaheuristic procedures to deal with them has strongly developed this research area in the last few years <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>Ant colony optimization (ACO) is a metaheuristic inspired by the shortest path searching behavior of various ant species. Since the initial work of Dorigo, Maniezzo, and Colorni on the first ACO algorithm, the ant system <ref type="bibr" target="#b19">[20]</ref>, several researchers have developed different ACO algorithms that performed properly when solving combinatorial problems such as the traveling salesman problem, the quadratic assignment problem, the sequential ordering problem, production scheduling, timetabling, project scheduling, vehicle routing, telecommunication routing, investment planning, staff scheduling, among others <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>Recently, some researchers have designed ACO algorithms to deal with multi-objective problems (MOACO algorithms) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b45">46]</ref>. The most of them are specific proposals to solve a concrete multi-criteria problem such as scheduling, vehicle routing, or portfolio selection, among others.</p><p>The aim of the current contribution is to review and classify the existing MOACO algorithms by proposing a taxonomy for them and developing a systematic experimental study comparing them when tackling a concrete benchmark problem, the multi-objective traveling salesman problem (MOTSP). An empirical study based on this taxonomy will allow us to analyze whether the fact of belonging to a specific MOACO family involves a good or bad performance or, instead, the characteristics of the specific MOACO algorithm itself determine the quality of the Pareto fronts generated.</p><p>To do our study, six instances of the bi-criteria TSP are chosen and all the former MOACO algorithms are applied to solve them. Besides, two well-established multi-objective genetic algorithms (MOGAs) are considered as baselines to check the global performance of MOACO approaches, NSGA-II <ref type="bibr" target="#b14">[15]</ref> and SPEA2 <ref type="bibr" target="#b47">[48]</ref>. A detailed study is then developed to analyze the performance of each algorithm by considering several classical multiobjective quality metrics.</p><p>This paper is structured as follows. In Section 2, some preliminaries about ACO and multi-objective optimization are reviewed. In Section 3, the existing MOACO algorithms are introduced, reporting their key characteristics. In Section 4, a taxonomy for them is presented. The requirements of the experimentation (adaptation of the algorithms considered to the bi-objective TSP, MOTSP instances used, metrics of performance considered and parameter settings) are commented on in Section 5. The experimental results of the MOACO algorithms and MOGAs considered are analyzed in Section 6. In Section 7, some concluding remarks and proposals for future works are shown. Finally, the paper is complemented with an introduction to evolutionary multi-objective optimization in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Ant colony optimization</head><p>Ants are social insects that live in colonies and that, thanks to their collaborative interaction, are capable of showing complex behaviors and to perform difficult tasks from an ant's local perspective. A very interesting aspect of the behavior of several ant species is their ability to find shortest paths between the ants' nest and the food sources. This fact is specially noticeable having in mind that, in many ant species, ants are almost blind, which avoids the exploitation of visual clues.</p><p>While walking between their nest and food sources, some ant species deposit a chemical called pheromone (an odorous substance). If no pheromone trails are available, ants move essentially at random, but in the presence of pheromone they have a tendency to follow the trail. In practice, choices between different paths occur when several paths intersect. Then, ants choose the path to follow by a probabilistic decision biased by the amount of pheromone: the stronger the pheromone trail, the higher its desirability. Because ants in turn deposit pheromone on the path they are following, this behavior results in a self-reinforcing process leading to the formation of paths marked by high pheromone concentration. This behavior also allows ants to identify shortest paths between their nest and the food source. <ref type="foot" target="#foot_0">1</ref>The latter procedure is complemented in the natural environment by the fact that pheromone evaporates after some time. This way, less promising paths progressively loose pheromone because of being visited by less and less ants.</p><p>ACO algorithms take inspiration from the behavior of real ant colonies to solve combinatorial optimization problems. They are based on a colony of artificial ants, that is, simple computational agents that work cooperatively and communicate through artificial pheromone trails <ref type="bibr" target="#b21">[22]</ref>.</p><p>ACO algorithms are essentially construction algorithms: in each algorithm iteration, every ant constructs a solution to the problem by traveling on a construction graph. Each edge of the graph, representing the possible steps the ant can make, has associated two kinds of information that guide the ant movement:</p><p>• Heuristic information, which measures the heuristic preference of moving from node i to node j, i.e., of traveling the edge a ij . It is denoted by g ij .</p><p>This information is not modified by the ants during the algorithm run. • (Artificial) pheromone trail information, which measures the ''learned desirability'' of the movement and mimics the real pheromone that natural ants deposit. This information is modified during the algorithm run depending on the solutions found by the ants. It is denoted by s ij .</p><p>Several ACO algorithms have been proposed which are included within the ACO metaheuristic <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21]</ref>, such as the Ant System <ref type="bibr" target="#b19">[20]</ref>, the ant colony system <ref type="bibr" target="#b18">[19]</ref>, the Max-Min ant system <ref type="bibr" target="#b44">[45]</ref>, the rank-based ant system <ref type="bibr" target="#b3">[4]</ref>, and the best-worst ant system <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. The two former algorithms are briefly reviewed as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Ant system</head><p>Ant system (AS) <ref type="bibr" target="#b19">[20]</ref>, developed by Dorigo, Maniezzo and Colorni in 1991, was the first ACO algorithm. AS is characterized by the fact that the pheromone update is triggered once all ants have completed their solutions and it is done as follows. First, all pheromone trails are reduced by a constant factor, implementing in this way the pheromone evaporation. Second, every ant of the colony deposits an amount of pheromone in its path which is a function of the quality of its solution. Initially, AS did not use any centralized daemon actions (actions not performed by the ants but by an external agent, which have not got any natural counterpart, but are just additional procedures to improve the metaheuristic performance), but it is very straightforward to, for example, add a local search procedure to refine the solutions generated by the ants.</p><p>Solutions in AS are constructed as follows. At each construction step, an ant h in AS chooses to go to a next node with a probability that is computed as</p><formula xml:id="formula_0">p h ij ¼ ½sij a Á½g ij b P u2N h i</formula><p>½siu a Á½g iu b ; if j 2 N h ðiÞ; 0; otherwise;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">&lt; :</head><p>where N h ðiÞ is the feasible neighborhood of ant h when located at node i, and a; b 2 R are two parameters that weight the relative importance of the pheromone trail and the heuristic information. Each ant h stores the sequence it has followed so far and this memory L h is exploited to determine N h ðiÞ in each construction step. As said, the pheromone deposit is made once all ants have finished to construct their solutions. First, the pheromone trail associated to every edge is evaporated by reducing all pheromones by a constant factor:</p><formula xml:id="formula_1">s ij ð1 À qÞ Á s ij ;</formula><p>where q 2 (0, 1] is the evaporation rate. Next, each ant retraces the path it has followed (stored in its local memory L h ) and deposits an amount of pheromone Ds h ij on each traversed connection (on-line a posteriori update or global update):</p><formula xml:id="formula_2">s ij s ij þ Ds h ij ; 8a ij 2 S h ;</formula><p>where Ds h ij ¼ f ðCðS h ÞÞ, i.e., the amount of pheromone released is function of the quality C(S h ) of the solution S h of ant h. In the TSP, f(x) is usually equal to x À1 .</p><p>Before concluding this section, it is important to notice that the creators of AS also proposed a typically better performing, extended version of this algorithm called elitist AS <ref type="bibr" target="#b19">[20]</ref>. In elitist AS, once the ants have released pheromone on the connections associated to their generated solutions, the daemon performs an additional pheromone deposit on the edges belonging to the best solution found until that moment in the search process (this solution is called global-best solution in the following). The amount of pheromone deposited, which depends on the quality of that global best solution, is weighted by the number of elitist ants considered, e, as follows:</p><formula xml:id="formula_3">s ij s ij þ e Á f ðCðS global-best ÞÞ; 8a ij 2 S global-best :</formula><p>2.1.2. Ant colony system Ant colony system (ACS) <ref type="bibr" target="#b18">[19]</ref> is one of the first successors of AS. It introduces three major modifications into AS:</p><p>1. ACS uses a different transition rule, which is called pseudo-random proportional rule: Let h be an ant located at a node i, q 0 2 [0, 1] be a parameter, and q a random value in [0, 1]. The next node j to be visited is randomly chosen according to the following probability distribution:</p><p>• If q 6 q 0 : • else (q &gt; q 0 ):</p><formula xml:id="formula_4">p h ij ¼ 1; if j ¼ arg max</formula><formula xml:id="formula_5">p h ij ¼ ½sij a Á½g ij b P u2N h i ½siu a Á½g iu b ; if j 2 N h ðiÞ;</formula><p>0; otherwise:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">&lt; :</head><p>As can be seen, the rule has a double aim: when q 6 q 0 , it exploits the available knowledge, choosing the best option with respect to the heuristic information and the pheromone trail. However, if q &gt; q 0 , it applies a controlled exploration, as done in AS. In summary, the rule establishes a trade-off between the exploration of new connections and the exploitation of the information available at that moment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Only the daemon (and not the individual ants)</head><p>triggers the global pheromone update, i.e., an offline pheromone trail update is done. To do so, ACS only considers a single ant, the one who generated the global best solution, S global-best .</p><p>The pheromone update is done by first evaporating the pheromone trails on all the connections used by the global-best ant (it is important to notice that in ACS, pheromone evaporation is only applied to the connections of the solution that is also used to deposit pheromone (see p. 77 in <ref type="bibr" target="#b21">[22]</ref>)) as follows:</p><formula xml:id="formula_6">s ij ð1 À qÞ Á s ij ; 8a ij 2 S global-best :</formula><p>Next, the daemon deposits pheromone by the rule:</p><formula xml:id="formula_7">s ij s ij þ q Á f ðCðS global-best ÞÞ; 8a ij 2 S global-best :</formula><p>Additionally, the daemon can apply a local search algorithm to improve the ants' solutions before updating the pheromone trails. 3. Ants apply an online step-by-step pheromone trail update (local update) that encourages the generation of different solutions to those yet found. Each time an ant travels an edge a ij , it applies the rule:</p><formula xml:id="formula_8">s ij ð1 À uÞ Á s ij þ u Á s 0 ;</formula><p>where u 2 (0, 1] is a second pheromone decay parameter. As can be seen, the online step-by-step update rule includes both, pheromone evaporation and deposit. Because the amount of pheromone deposited is very small (in fact, s 0 is the initial pheromone trail value which is chosen in such a way that, in practice, it corresponds to a lower pheromone trail limit. That is by the choice of the ACS pheromone update rules, no pheromone trail value can fall below s 0 ), the application of this rule makes the pheromone trail on the connections traversed by an ant decrease. 2  Hence, this results in an additional exploration technique of ACS by making the connections traversed by an ant less attractive to the following ants and helps to avoid that every ant follows the same path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Multi-objective optimization</head><p>Multi-criteria optimization problems are characterized by the fact that several objectives have to be simultaneously optimized. Hence, there is not usually a single best solution solving the problem, i.e., being better than the remainder with respect to every objective, as in single-objective optimization. Instead, in a typical multi-objective optimization problem, there is a set of solutions that are superior to the remainder when all the objectives are considered, the Pareto set. These solutions are known as non-dominated solutions <ref type="bibr" target="#b5">[6]</ref>, while the remainder are known as dominated solutions. Since none of the Pareto set solutions is absolutely better than the other non-dominated solutions, all of them are equally acceptable as regards the satisfaction of all the objectives. This way, the formal definition of the dominance concept is as follows. Let us consider a multi-objective minimization problem with n parameters (decision variables) and K objectives: Min f ðxÞ ¼ ðf 1 ðxÞ; f 2 ðxÞ; . . . ; f K ðxÞÞ; with</p><formula xml:id="formula_9">x ¼ ðx 1 ; x 2 ; . . . ; x n Þ 2 X : A decision vector a 2 X dominates another b 2 X (a 1 b) if,</formula><p>and only if 8i 2 1; 2; . . . ; Kjf i ðaÞ 6 f i ðbÞ 9j 2 1; 2; . . . ; Kjf j ðaÞ &lt; f j ðbÞ:</p><p>2 ACS is actually based on Ant-Q, an earlier algorithm proposed by Gambardella and Dorigo <ref type="bibr" target="#b23">[24]</ref>. The only difference between ACS and Ant-Q is in the definition of the term s 0 in the online step-by-step update rule, which in Ant-Q is the discounted evaluation of the next state, set to c Á max j2NhðiÞ fs ij g. However, experimental results suggested that ACS results in the same level of performance and, because of its greater simplicity, it was preferred.</p><p>Any vector that is not dominated by any other is said to be Pareto-optimal or non-dominated.</p><p>As said, a common difficulty with multi-objective optimization is the appearance of an objective conflict <ref type="bibr" target="#b30">[31]</ref>, i.e., none of the feasible solutions allows simultaneous optimal solutions for all objectives. Mathematically, the best way of acting is to keep with those solutions with the least objective conflict. These solutions can be viewed as points in the search space that are optimally placed from the individual optimum of each objective. However, such solutions may not satisfy a decision-maker because he may want a solution that satisfies some associated priorities of the objectives. To find such points, all classical methods scalarize the objective vector reducing it to a scalar optimization problem. Actually, in this case a compromise solution is found subjected to specified constraints.</p><p>Four are the most commonly classical methods to solve the multi-optimality <ref type="bibr" target="#b6">[7]</ref>: objective weighting, distance functions, Min-Max formulation and Lexicographic approach. All of them are based on reducing the multi-objective optimization problem to a single objective one: In the former one, the multiple objective functions are combined into one overall objective function, as follows:</p><formula xml:id="formula_10">F ¼ X K i¼1 w i Á f i ðxÞ; X K i¼1 w i ¼ 1; 0 6 w i 6 1:</formula><p>In distance functions, the single-objective F function to be optimized is calculated using a demand-level vector, f , which has to be specified by a decisionmaker:</p><formula xml:id="formula_11">F ¼ X K i¼1 jf i ðxÞ À f i j r " # 1=r ; 1 6 r &lt; 1:</formula><p>Min-Max formulation attempts to minimize the relative deviations of the single-objective functions from the corresponding individual optimum. Hence, it tries to minimize: f ðxÞ ¼ max½Z i ðxÞ; i ¼ 1; 2; . . . ; K where Z i (x) is calculated for a non-negative target optimal value f i &gt; 0:</p><formula xml:id="formula_12">Z i ðxÞ ¼ ðf i À f i Þ= f i :</formula><p>The last method, Lexicographic approach <ref type="bibr" target="#b6">[7]</ref>, is based on an order of importance of the objectives. Then, it attempts to optimize the ith objective keeping the best found solution for the (i À 1)th objective.</p><p>All the classical techniques used to solve multiobjective problem have serious drawbacks <ref type="bibr" target="#b6">[7]</ref>, that are reviewed as follows:</p><p>• Since objectives are combined to form a single objective function, a single Pareto-optimal solution can be simultaneously obtained. In realworld problems, the decision-maker often requires different alternatives for the decision making, but these techniques can not offer them. • Even if different weights are adopted during a single run in order to obtain several solutions, the algorithm will not be able to generate concave portions of the Pareto front <ref type="bibr" target="#b11">[12]</ref>. • Furthermore, before forming the single objective from the objectives set, the decision-maker must usually have a thorough knowledge of the priority of each objective, which is a difficult problem in itself. • If some objectives are noisy or have a discontinuous variable space, these methods may not appropriately work. • If the objective functions are not deterministic, the definition of a weight vector or a demand level may become even more difficult. • They have much sensitivity and dependency toward weights or demand levels.</p><p>In order to solve these problems, some advanced multi-objective optimization techniques have been proposed in the last few years. They are mainly based on well-established metaheuristics such as simulated annealing, evolutionary algorithms, and ACO algorithms, as seen in this paper <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Multiple objective ant colony optimization algorithms</head><p>In this section, the different existing proposals for MOACO algorithms are reviewed by reporting their main characteristics, as well as the original problem they were designed to tackle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Multiple objective Ant-Q algorithm</head><p>Multiple objective Ant-Q algorithm (MOAQ) is a MOACO algorithm that was proposed by Mariano and Morales in <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> to be applied to the design of water distribution irrigation networks. It was based on a distributed reinforcement learning algorithm called Ant-Q <ref type="bibr" target="#b23">[24]</ref>, a variant of the classical ACS <ref type="bibr" target="#b18">[19]</ref> (see Section 2.1.2). In Ant-Q, several autonomous agents learn an optimal policy p : S ! A, that outputs an appropriate action a 2 A, given the current state s 2 S, where A is the set of all possible actions in a state and S is the set of states. The available information to the agent is the sequence of immediate rewards r(s i , a i ) for all the possible actions and states i = 0,1,2,. . ., Q(s, a), and a domain dependent heuristic value indicating how good is to select a particular action (a) being in the actual state (s), HE(s, a). Each agent uses the following transition rule to select the action a according to the actual state s:</p><formula xml:id="formula_13">a ¼ arg max a2A</formula><p>ðHE a ðs; aÞ Á Q b ðs; aÞÞ; if q &gt; q 0 ; P ; otherwise;</p><p>( where a and b are parameters that weight the relative importance of pheromone trail and heuristic information, q is a random value in [0, 1], and q 0 (0 6 q 0 6 1) is calculated in every iteration as follows:</p><formula xml:id="formula_14">q 0 ¼ ðq 0 Á kÞ=q max ;</formula><p>where q max 2 [0, 1], and P is a random action selected according to the following probability distribution:</p><p>pðaÞ ¼ HE a ðs; aÞ Á Q b ðs; aÞ P b2A HE a ðs; bÞ Á Q b ðs; bÞ with s being the current state.</p><p>The basic idea behind MOAQ is to perform an optimization algorithm with a family of agents (ants) for each objective. Each family k tries to optimize an objective considering the solutions found for the other objectives and its corresponding function HE k . This way, all the agents from the different families act in the same environment proposing actions and expecting a reward value r which depends on how their actions helped to find tradeoff solutions between the rest of the agents. The delayed reinforcement is computed as follows:</p><p>Qðs; aÞ ¼ ð1 À qÞ Á Qðs; aÞ þ q Á ½rðs; aÞ þ c Á Qðs 0 ; a 0 Þ; where q is the learning step, s 0 and a 0 are the state and action in the next algorithm step, and c is a discount factor. On the other hand, when a solution found is not feasible, the algorithm applies a punishment to its components on the Q values.</p><p>Finally, MOAQ presents a distinguishing characteristic. While the jth ant from the ith family (i &gt; 1) is constructing its solution, it takes into account the solution found by the jth ant of family i À 1. Hence, the objectives are processed in a certain order of importance similarly to the lexicographic ordering. This issue is related to the problem to which the algorithm was applied, the design of water distribution irrigation networks. In this problem some objectives needed to be determined before optimizing others. So, it needed to be tackled in a specific order. At first sight, this could seem that the algorithm would return only a single solution, which is the best for the first objective, and try to optimize the remainder. However, MOAQ keeps an external set of non-dominated solutions that is returned when the run finishes. The authors explain this characteristic in <ref type="bibr" target="#b37">[38]</ref> by indicating that the algorithm tries to find a set of compromise solutions for all the objectives involved according to an order of importance, which, in some cases, can be arbitrary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Ant algorithm for bi-criterion optimization problems</head><p>In <ref type="bibr" target="#b31">[32]</ref>, Iredi et al. introduced some general techniques in order to solve multi or bi-criteria problems by ACO algorithms. They tested these techniques on a bi-criteria vehicle routing problem. In this section, we describe one of the algorithms proposed in <ref type="bibr" target="#b31">[32]</ref>, which will be called BicriterionAnt. It uses a pheromone trail matrix for every objective, e.g., when there are two objectives, there will be two pheromone matrices, s and s 0 .</p><p>In every generation, each of the m ants in the colony generates a solution to the problem. During its construction trip, the ant selects the next node j to be visited by means of the following probability distribution:</p><formula xml:id="formula_15">pðjÞ ¼ s ka ij Ás 0 ð1ÀkÞa ij Ág kb ij Ág 0 ð1ÀkÞb ij P u2X s ka iu Ás 0 ð1ÀkÞa iu Ág kb iu Ág 0 ð1ÀkÞb iu ; if j 2 X; 0; otherwise; 8 &lt; :</formula><p>where a and b are the usual weighting parameters, g ij and g 0 ij are the heuristic values associated to edge a ij according to the first and the second objective, respectively, X is the current feasible neighborhood of the ant, and k is computed for each ant h, h 2 {1, . . ., m}, in order to force the ants to search in different regions of the Pareto front, as follows:</p><formula xml:id="formula_16">k h ¼ ðh À 1Þ=ðm À 1Þ:</formula><p>Once all the ants have generated their solutions, the pheromone trails are evaporated by applying the usual rule on every edge a ij :</p><formula xml:id="formula_17">s ij ¼ ð1 À qÞ Á s ij</formula><p>with q 2 [0, 1] being the pheromone evaporation rate.</p><p>Then, every ant that generated a solution in the non-dominated front at the current iteration is allowed to update both pheromone matrices, s and s 0 , by laying down an amount equal to 1/l, with l being the number of ants currently updating the pheromone trails. The non-dominated solutions generated along the algorithm run are kept in an external set, as it happened in MOAQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Multi-colony for bi-criterion optimization problems</head><p>In the same contribution <ref type="bibr" target="#b31">[32]</ref>, Iredi et al. proposed another MOACO algorithm. It was designed from BicriterionAnt (see Section 3.2) with a distinguishing remark: it takes as an user parameter the number of colonies N C , which is independent from the number of objectives. Then, each colony has a pheromone trail matrix associated for every objective, e.g., if there are two objectives to be optimized, then there will be two pheromone trail matrices in every colony.</p><p>In order to update the pheromone matrices, the authors consider two different methods:</p><p>• Method 1-Update by origin: an ant only updates the pheromone trail matrices in its own colony. The algorithm using method 1 will be called UnsortBicriterion. • Method 2-Update by region: the sequence of solutions along the non-dominated front is split into N C parts of equal size. Ants that have found solutions in the ith part update the pheromone trails in colony i</p><formula xml:id="formula_18">, i 2 [1, N C ].</formula><p>The aim is to explicitly guide the ant colonies to search in different regions of the Pareto front, each of them in one region. The algorithm using method 2 is called BicriterionMC.</p><p>Finally, another difference is the way to compute the value of the transition parameter k for ant h. The authors describe three different rules and propose to use the third of them which gives better results. This rule overlaps the k-interval of colony i in a 50% with the k-interval of colony i À 1 and colony i + 1. Formally, colony i has ants with k-values in [(i À 1)/(N C + 1), (i + 1)/(N C + 1)].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Pareto ant colony optimization</head><p>Pareto ant colony optimization (P-ACO), proposed by Doerner et al. in <ref type="bibr" target="#b16">[17]</ref>, was originally applied to solve the multi-objective portfolio selection problem. It considers the classical ACS as the underlying ACO algorithm but the global pheromone update is performed by using two different ants, the best and the second-best solutions generated in the current iteration for each objective k. In P-ACO, several pheromone matrices s k are considered, one for each objective k. At every algorithm iteration, each ant computes a set of weights p = (p 1 , . . ., p k ), and uses it to combine the pheromone trail and heuristic information. When an ant has to select the next node to be visited, it uses the ACS transition rule considering the k pheromone matrices:</p><formula xml:id="formula_19">j ¼ arg max j2X P K k¼1 p k Á s k ij ! a Á g b ij ; if q 6 q 0 ; î; otherwise; 8 &gt; &lt; &gt; :</formula><p>where K is the number of objectives, g ij is an aggregated value of attractiveness of edge a ij used as heuristic information, and î is a node selected according to the probability distribution given by</p><formula xml:id="formula_20">pðjÞ ¼ P K k¼1 p k Ás k ij Â Ã a Ág b ij P u2X P K k¼1 p k Ás k iu Â Ã a Ág b iu ; if j 2 X; 0; otherwise: 8 &gt; &lt; &gt; :</formula><p>Every time an ant travels an edge a ij , it performs the local pheromone update in each pheromone trail matrix, i.e., for each objective k, as follows:</p><formula xml:id="formula_21">s k ij ¼ ð1 À qÞ Á s k ij þ q Á s</formula><p>0 with q being the pheromone evaporation rate, and s 0 being the initial pheromone value.</p><p>The global pheromone trail information is updated once each ant of the population has constructed its solution. The rule applied for each objective k is as follows:</p><formula xml:id="formula_22">s k ij ¼ ð1 À qÞ Á s k ij þ q Á Ds k ij ;</formula><p>where Ds k ij has the following values in the tackled problem:</p><formula xml:id="formula_23">Ds k ij ¼</formula><p>15 if edge a ij 2 best and second-best solutions; 10 if edge a ij 2 best solution; 5 if edge a ij 2 second-best solution; 0 otherwise:</p><formula xml:id="formula_24">8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; :</formula><p>Along the process, the non-dominated solutions found are stored in an external set, as in the previous MOACO algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Multiple ant colony system for vehicle routing problem with time windows</head><p>As its name suggests, the multiple ant colony system for vehicle routing problem with time windows (MACS-VRPTW) algorithm introduced by Gambardella et al. in <ref type="bibr" target="#b24">[25]</ref> was thought to solve this specific kind of vehicle routing problems. As P-ACO, it also starts from the classical ACS.</p><p>MACS-VRPTW is based on setting up a preference to minimize one objective (the number of tours) over the other (the travel time). This solution is defined as the first of a lexicographic order on the values of the objectives. It defines two different colonies, ACS-VEI and ACS-TIME, whose activities are coordinated by the global MACS-VRPTW algorithm in order that both objectives are simultaneously optimized. The former colony tries to diminish the number of vehicles used while the latter optimizes the feasible solutions obtained by the former. Each one uses an independent pheromone trail matrix for its specific objective, and they collaborate by sharing the best solution found by their cooperative action. The global algorithm kills and runs again the two colonies each time a new best solution containing less vehicles than the previous one is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Multiple ant colony system</head><p>Multiple ant colony system (MACS) <ref type="bibr" target="#b0">[1]</ref> was proposed as a variation of the MACS-VRPTW algorithm reviewed in the previous section. So, it is also based on ACS but, contrary to its predecessor, MACS uses a single pheromone matrix, s, and several heuristic information functions, g k , initially two, g 0 and g 1 . In this way, an ant moves from node i to node j by applying the following rule:</p><formula xml:id="formula_25">j ¼ arg max j2X ðs ij Á ½g 0 ij kb Á ½g 1 ij ð1ÀkÞb Þ; if q 6 q 0 ; î; otherwise; 8 &lt; :</formula><p>where b weights the relative importance of the objectives with respect to the pheromone trail, k is computed for each ant h as k = h/m, with m being the number of ants, and î is a node selected according to the following probability distribution:</p><formula xml:id="formula_26">pðjÞ ¼ sijÁ½g 0 ij kb Á½g 1 ij ð1ÀkÞb P u2X s iu Á½g 0 iu kb Á½g 1 iu ð1ÀkÞb ; if j 2 X; 0;</formula><p>otherwise:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">&lt; :</head><p>Every time an ant crosses the edge a ij , it performs the local pheromone update as follows:</p><formula xml:id="formula_27">s ij ¼ ð1 À qÞ Á s ij þ q Á s 0 :</formula><p>Initially, s 0 is calculated from a set of heuristic solutions by taking their average costs in each of the two objective functions, f 0 and f 1 , and applying the following expression:</p><formula xml:id="formula_28">s 0 ¼ 1=ð f 0 Á f 1 Þ:</formula><p>However, the value of s 0 is not fixed during the algorithm run, as usual in ACS, but it undergoes adaptation. Every time an ant h builds a complete solution, it is compared to the Pareto set P generated till now to check if the former is a non-dominated solution. At the end of each iteration, s 0 0 is calculated by applying the previous equation with the average values of each objective function taken from the solutions currently included in the Pareto set.</p><p>Then, if s 0 0 &gt; s 0 , the current initial pheromone value, the pheromone trails are reinitialized to the new value s 0 s 0 0 . Otherwise, the global update is performed with each solution S of the current Pareto optimal set P by applying the following rule on its composing edges a ij :</p><formula xml:id="formula_29">s ij ¼ ð1 À qÞ Á s ij þ q=ðf 0 ðSÞ Á f 1 ðSÞÞ:</formula><p>Recently, Pinto et al. have slightly modified MACS in order to solve a multi-objective multi-cast routing problem <ref type="bibr" target="#b40">[41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Multi-objective network ACO</head><p>Multi-objective network ACO (MONACO) is quite different to the remaining algorithms reviewed in this section as it was designed to be applied to a dynamic problem, the optimization of the message traffic in a network <ref type="bibr" target="#b4">[5]</ref>. Hence, the policy of the network changes according to the algorithm's steps, and it does not wait till the algorithm ends up. In the following, we present an adaptation of the original algorithm, developed by ourselves, to use MON-ACO in static problems. It requires several modifications such as the fact that the ants have to wait till the cycle ends before updating the pheromone trails.</p><p>The original algorithm takes the classical AS <ref type="bibr" target="#b19">[20]</ref> as a base but uses several pheromone trail matrices, s k . Each ant, which is defined as a message, uses the multi-pheromone trail and a single heuristic information to choose the next node to visit, according to the following probability distribution:</p><formula xml:id="formula_30">pðjÞ ¼ g b ij Á Q K k¼1 ðs k ij Þ a k P u2X g b iu Á Q K k¼1 ðs k iu Þ a k ; if j 2 X; 0; otherwise:<label>8 &lt;</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>:</head><p>In this equation, g ij is the heuristic information for edge a ij , both b and the different a k 's weight the importance of each pheromone matrix value and the heuristic information, K is the number of objective functions, and X is the feasible neighborhood of the ant at this step. After each cycle, the pheromone trails associated to every edge visited by at least one ant in the current iteration are evaporated in the usual way:</p><formula xml:id="formula_31">s k ij ¼ ð1 À q k Þ Á s k ij</formula><p>with q k being the pheromone evaporation rate for objective k (notice that a different evaporation rate is considered for each pheromone trail matrix). Then, the pheromone trails of these edges are updated. Every ant h lays down the following amount of pheromone in each edge a ij used by each ant and for every objective k:</p><formula xml:id="formula_32">Ds k ij ¼ Q=f k ðS h Þ;</formula><p>where Q is a constant related to the amount of pheromone laid by the ants, f k is the objective function k, and S h is the solution built by the ant. As said, the aim of the original algorithm is not to find a good set of non-dominated solutions but to make the network work efficiently. To apply it to static optimization problems, we have to store the non-dominated solutions generated in each run in an external set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.">COMPETants</head><p>Initially, Doerner et al. introduced COMPE-Tants to deal with bi-objective transportation problems <ref type="bibr" target="#b15">[16]</ref>. The algorithm, based on the rank-based AS <ref type="bibr" target="#b3">[4]</ref>, used two ant colonies, each with its own pheromone trail matrix, s 0 and s 1 , and its heuristic information, g 0 and g 1 . An interesting point is that the number of ants in each population is not fixed but undergoes adaptation. When every ant has built its solution, the colony which has constructed better solutions gets more ants for the next iteration. The ants walk through the edges using the following probability distribution to select the next node to be visited (notice that it is an adaptation of the AS transition rule to the case of multiple heuristic and pheromone trail values):</p><formula xml:id="formula_33">pðjÞ ¼ s k a ij Ág k b ij P u2X s k a iu Ág k b iu ; if j 2 X;</formula><p>0; otherwise:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">&lt; :</head><p>Each ant uses the s and g values of its colony k. Besides, some ants in every population, called spies, use another rule combining the information of both pheromone trails:</p><formula xml:id="formula_34">pðjÞ ¼ ½0:5Ásijþ0:5Ás 0 ij a Ág k b ij P u2X ½0:5Ásiuþ0:5Ás 0 iu a Ág k b iu ; if j 2 X;</formula><p>0; otherwise:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">&lt; :</head><p>In this new rule, s is the ant's pheromone trail and s 0 the pheromone trail of the other colony. g k is the ant's heuristic information.</p><p>When every ant has built its solution, the pheromone trails of each edge a ij are evaporated:</p><formula xml:id="formula_35">s k ij ¼ ð1 À qÞ Á s k ij :</formula><p>Then, the C best ants of each population deposit pheromone on the edges visited using its own pheromone trail matrix and the following rule:</p><formula xml:id="formula_36">Ds k ij ¼ 1 À ðk À 1Þ=C;</formula><p>where k is the position of the ant in the sorted list of the C best ants.</p><p>Before the end of the cycle, every ant is assigned to the first colony with the following probability:</p><formula xml:id="formula_37">f 1 =ð f 0 þ f 1 Þ</formula><p>with f 1 being the average of the costs of the solutions in the second colony (that associated to the second objective function), and f 0 being the average of the costs of the first colony (that corresponding to the first objective function). The remaining ants will be assigned to the second colony.</p><p>Finally, the number of spies in both colonies is randomly calculated with the following probability:</p><formula xml:id="formula_38">f ðbestÞ=ð4 Á f 0 ðbest 0 Þ þ f ðbestÞÞ;</formula><p>where f is the objective function associated to the current colony, f 0 is the objective function associated to the other colony, best is the best ant of the current colony according to f and best 0 is the best ant of the other according to f 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9.">Multiple objective ant colony optimization metaheuristic</head><p>In <ref type="bibr" target="#b27">[28]</ref>, Gravel et al. proposed a multi-objective ACO algorithm for a real-world scheduling problem related to the aluminum production industry, that was called Multiple Objective ACO metaheuristic (MOACOM) by its creators. MOACOM is based on an AS algorithm that deals with the multiple objectives in a lexicographic order, a priori established by the decision maker. At the end of a cycle, only the first solution according to the lexicographic order considered is taken into account. For this reason, the aim of MOACOM is not to find a good non-dominated solution set. Hence, the algorithm deals with a single heuristic information and pheromone trail matrices. The authors provide several rules to construct the heuristic matrix g, where each value is the result of the aggregation of information associated to every objective.</p><p>Considering the latter two matrices, the AS transition rule is applied to build the ants solutions. At the end of a cycle, the pheromone trail intensity is updated based on the evaluation of the primary objective in isolation. Every ant h lays down the following amount of pheromone on the edges used:</p><formula xml:id="formula_39">Ds ij ¼ Q=f 0 ðS h Þ;</formula><p>where f 0 is the primary objective function, S h is the solution found by the ant, and Q is a constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.10.">Ant colony optimization approach to multiple objectives</head><p>As the previous algorithm, the ACO approach to multiple objectives (ACOAMO), proposed in <ref type="bibr" target="#b38">[39]</ref> to solve a multi-objective JIT sequencing problem, is based on dealing with a single best solution and not with a set of non-dominated ones in each iteration. This solution is the first of a lexicographic order defined on the objectives. ACOAMO splits the solutions in components and randomly distributes these components over the search space. The heuristic information is the inverse of the distances between the components, and the ants are guided by the following probability distribution:</p><formula xml:id="formula_40">pðjÞ ¼ sijÁg ij P u2X siuÁg iu ; if j 2 X; 0; otherwise (</formula><p>with s being the pheromone trail matrix, g referring to the heuristic information, and X being the current feasible neighborhood of the ant.</p><p>When an ant goes through the edge a ij , it applies the ACS local update rule:</p><formula xml:id="formula_41">s ij ¼ ð1 À qÞ Á s ij þ q Á s 0 :</formula><p>Finally, every ant that completes a solution computes its cost as the Euclidean sum of the distances of every edge crossed, C. If this value is lesser than the smallest value of C found so far, then the global update is performed to every edge in this solution according to the following expression:</p><formula xml:id="formula_42">s ij ¼ ð1 À qÞ Á s ij þ q Á C À1 : 3.11. SACO</formula><p>SACO is a very specific MOACO algorithm proposed in <ref type="bibr" target="#b45">[46]</ref> by T'kindt et al. for 2-machine bi-criteria flowshop scheduling problems. Its name comes from the fact that it puts into effect a search methodology mimicking that applied by simulated annealing (developing a stronger diversification at the beginning of the trek, and a stronger intensification at later stages). Again, it is based on only dealing with a single best solution, that having the best cost for one of the objectives, and not with a set of non-dominated solutions. At every cycle, each ant builds a feasible solution using the pheromone trail information, which can be used in two different ways: (a) intensification mode, where the ant chooses the most suitable job according to the highest value of s ij , and (b) diversification mode, where the ant chooses the next node by a random-proportional rule. The probability of selecting the intensification mode is regulated by p 0 , a parameter computed at every iteration it as follows:</p><formula xml:id="formula_43">p 0 ¼ logðitÞ= logðN Þ</formula><p>with N being the total number of iterations.</p><p>At the end of the cycle, the evaporation is performed on every edge and the best solution is kept and used to update the pheromone trails of the edges composing it</p><formula xml:id="formula_44">s ij ¼ s ij þ 1=f 0 ðSÞ</formula><p>with S being the best solution found and f 0 being one of the objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.12.">Multiple objective ant colony optimization approach to assembly line balancing problems</head><p>The MOACO approach to assembly line balancing problem (MOACO-ALBP), proposed in <ref type="bibr" target="#b2">[3]</ref> to solve Assembly Line Balancing Problems, is based on dealing with a single best solution and not with a set of non-dominated ones in each iteration. This solution is the first of a lexicographic order defined on the objectives.</p><p>MOACO-ALBP performs like an AS with a pheromone matrix and a heuristic one. The pheromone matrix is updated according to a function of all the objective criterions. The used formulas are specific to the Assembly Line Balancing Problem. In addition, it keeps the best obtained solution across the iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.13.">Multi-criteria population-based ACO</head><p>In <ref type="bibr" target="#b29">[30]</ref>, Guntsch and Middendorf proposed an adaptation of the Population-based ACO (PACO) <ref type="bibr" target="#b28">[29]</ref> for multiple objective optimization (MO-PACO). PACO differs from the standard ACO heuristic in that it employs a population P = {p 1 , . . . , p k } of k good solutions, from which the pheromone information s ij is derived as follows: Each element of the pheromone matrix has an initial value s init . Whenever a solution enters the population P, a positive update is performed by adding a pheromone amount D. In addition, if a solution is removed from the population, its influence is explicitly removed from the pheromone matrix by performing a negative update, i.e., using ÀD. As a result, the pheromone matrix is perfectly defined by the members in the population P:</p><formula xml:id="formula_45">s ij ¼ s init þ D Á jfp 2 P jði; jÞ 2 pgj:</formula><p>Notice that, since the construction of the solutions depends, among others, on the current distribution of individuals in P, PACO seems similar to the Estimation of Distribution Algorithms, where new solutions depends only on the distribution of the individual of the current population.</p><p>MO-PACO is the multiple objective version of PACO. It uses an external population, with the non-dominated solutions it finds (Q), which the individuals of P are chosen from. Every m solutions, MO-PACO creates a new P with a randomly chosen individual and the (k À 1) nearest ones to it. Then, MO-PACO calculates several pheromone matrix, one for each optimization criterion, which, together with a heuristic matrix for each optimization criterion, are used for the transition rule. Every new solution is tested against the individuals in Q in order to keep Q updated with the non-dominated solutions found so far.</p><p>In addition, MO-PACO uses an average-rankweight method that modifies the probability distribution used in the transition rule, which assigns a higher importance to one of the optimizing criterions according to the quality of the solutions in P, regard to those in Q, with respect to this criterion (see <ref type="bibr" target="#b29">[30]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A proposal of a taxonomy for the different MOACO algorithms</head><p>MOACO algorithms can be classified according to different criteria. One of them could be whether the algorithm returns a set of non-dominated solutions, i.e., if it looks for a set of Pareto solutions during its run, or it just gives a single solution as output. According to this, MOAQ, BicriterionAnt, UnsortBicriterion, BicriterionMC, P-ACO, MACS, our adaptation of MONACO, COMPETants and MO-PACO belong to the former group, that could be called Pareto-based MOACO algorithms, while the remainder (MACS-VRPTW, MOACOM, ACOAMO, SACO, and MOACO-ALBP) compose the second.</p><p>Another, more interesting criterion could be the fact whether the algorithms are based on the operation of only one or several ant colonies. However, we should notice that this criterion is problematic because there are different ways in which several ant colonies can be used, such as the use of several pheromone trails, several heuristic functions or, even, several independent processes as done in MACS-VRPTW.</p><p>We have decided to classify the algorithms according to two different criteria when the ant has to choose the next node to be visited:</p><p>• The use of only one or several pheromone trails.</p><p>• The use of only one or several heuristic functions.</p><p>In this way, we get the taxonomy shown in Table <ref type="table" target="#tab_0">1</ref>: SACO has not been considered for the previous classification as it does not use any heuristic information at all. As seen in Section 3.11, in SACO, the ants are only guided by the pheromone trails.</p><p>An empirical study based on this taxonomy will allow us to analyze which family can generate better Pareto fronts. This way, it would be for example possible to check if the use of more than a single pheromone trail matrix, which gives a higher diversification capability to the algorithm, is more important in order to obtain a better performance than other factors such as either the use of several or only one heuristic matrix, or the specific operation mode of each MOACO algorithm.</p><p>This way, we would be able to corroborate previous results as regards this issue such as those obtained in <ref type="bibr" target="#b31">[32]</ref> by Iredi et al. They concluded that the performance of the BicriterionMC algorithm when using a pheromone trail matrix for each objective is better than when using a single pheromone trail matrix for all of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">On the experimental study</head><p>To perform the experimental comparison, we will only consider those MOACO algorithms introduced in Section 3 whose aim is to obtain a set of nondominated solutions for the problem being solved (Pareto-based MOACO algorithms). We have not considered the MO-PACO algorithm due to it does not follows the classical ACO heuristic, which does not consider any population of solutions. This way, eight algorithms will be used: MOAQ, Bicriterio-nAnt, UnsortBicriterion, BicriterionMC, P-ACO, MACS, our adaptation of MONACO, and COMPETants.</p><p>The reason why the remainder are not implemented and tested in the developed study is because they are so specific to be applied to the problem tackled, the bi-objective TSP, as they are usually based on a lexicographical order, thus requiring to specify an order of importance between the two problem objectives (which is not the case). Although MOAQ also needed an order of importance, the authors remarked that it could be arbitrary, and thus this aspect is not taken into account and the algorithm is considered in our experimental setup.</p><p>On the other hand, we should notice that two of the most known, Pareto-based second generation MOGAs, NSGA-II (see Appendix A.1) and SPEA2 (see Appendix A.2) (which represent the state-ofthe-art in multi-objective evolutionary optimization, see <ref type="bibr" target="#b6">[7]</ref>), will be run on the same problem instances and their results used as baselines for the MOACO algorithms performance. Hence, ten different algorithms will be run on the six bi-criteria TSP instances selected.</p><p>It is important to indicate that, in order to make fair comparisons, every algorithm will store the non-dominated solutions found along its run in an external unbounded archive (there is no limit for the number of non-dominated solutions collected). However, this archive will not be used by the algorithms in order to modify their behavior. For instance, the number of ants in MOACOs or the size of P 0 in SPEA2 (see Appendix A.2) is constant through the run.</p><p>In addition, as seen in Section 3, the eight MOACO algorithms implemented are characterized by tackling very diverse applications. Hence, several changes have to be done in order to adapt them to solve the multi-objective TSP. Leaving apart the fact that all of them have to manage the same problem representation, the usual permutation, the different changes performed are reported in the following sections.</p><p>Finally, it is interesting to notice that no local optimizer has been added to the studied MOACO algorithms in the current contribution. The reason is that this study aims at comparing the tradeoff between diversification and intensification offered by the original algorithms themselves, i.e., by the good combination of the selection and replacement mechanism and crossover and mutation operators, characteristics of MOGAs, and the good management of problem specific and learned information, characteristic of MOACO algorithms. Of course, local search is usually considered in the latter kind of algorithms in order to optimize the quality of the final results in the TSP, but this causes a completely different behavior where it would be difficult to determine the real influence of the original algorithm search process with respect to the one of the local optimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Adaptation of MOACOs to multi-objective TSP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">MOAQ for the multi-objective TSP</head><p>In our MOAQ-TSP, the Q values corresponding to the system rewards (see Section 3.1) will be implemented as a matrix. The set of appropriate actions a 2 A will be the set of possible nodes to be visited in the current step of the ant's way, and S, the set of states, will be the set of nodes of the graph.</p><p>There will be as many colonies as the number of objectives (graphs). Ants belonging to different colonies will use different heuristic functions HE k . However, every ant will use the same pheromone matrix s, initialized using the values of its corresponding reward function Q. The value of HE k for edge a ij will be</p><formula xml:id="formula_46">HE k ði; jÞ ¼ 1=d k ij with d k</formula><p>ij being the cost associated to the edge a ij according to the kth graph.</p><p>The reward given to the Q values of the edge a ij will be rði; jÞ ¼ X</p><formula xml:id="formula_47">s2NDPI K P K k¼1 f k<label>ðSÞ</label></formula><formula xml:id="formula_48">;</formula><p>where K is the number of objectives, NDPI is the set of non-dominated solutions found in the current iteration, and f k (S) is the cost of solution S according to the kth objective function.</p><p>The punishment applied to components of unfeasible solutions will not be considered as every permutation is a feasible solution in the multiobjective TSP. Finally, the jth ant of family i will build a solution trying to optimize the cost according to the ith objective function without using the solution of the jth ant of family i À 1, due to the fact that the objectives can be optimized without taking account any specific ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">BicriterionAnt for the multi-objective TSP</head><p>BicriterionAnt uses two pheromone matrices, s and s 0 . Every ant in the non-dominated front of the current generation updates both matrices and the amount deposited is 1/l, with l being the number of ants allowed to perform the update. In the bi-criteria TSP, s ij and s 0 ij are, respectively, the pheromone trail on edge a ij on each matrix, and if we use the previous rule to update both pheromone matrices, both of them will have the same values. Due to this, we have changed the pheromone update rule. The amount deposited on s by the ant h will be the inverse of the cost of its solution according to the first objective function, f 1 (S h ), and the amount on s 0 will be the inverse of the cost according to the second objective function, f 2 (S h ). Usually, the cost associated to the first graph will be different to the cost associated to the second, so the amount of pheromone on edge a ij will be probably different in s and in s 0</p><formula xml:id="formula_49">s ij ¼ s ij þ 1=f 1 ðS h Þ; s 0 ij ¼ s 0 ij þ 1=f 2 ðS h Þ:<label>ð1Þ</label></formula><p>5.1.3. BicriterionMC for the multi-objective TSP We will use ten colonies in BicriterionMC-MOTSP with two pheromone matrices in every colony, as Iredi et al. did in <ref type="bibr" target="#b31">[32]</ref> for a problem with two criteria. Besides, the pheromone trail update rule considered will be that shown in Eq. ( <ref type="formula" target="#formula_49">1</ref>) in the previous section. When updating the first matrix s, the algorithm will apply the left-hand expression. On the other hand, the right-hand expression will be used when updating the second matrix s 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4.">P-ACO for the multi-objective TSP</head><p>In P-ACO, g ij is an aggregated value of the attractiveness of edge a ij which depends on the specific problem instance. For P-ACO-MOTSP, g ij will be the inverse of the average of the costs of the edges for every graph</p><formula xml:id="formula_50">g ij ¼ K P K k¼1 d k ij<label>ð2Þ</label></formula><p>with d k ij being the cost of edge a ij according to the kth graph and K being the number of graphs.</p><p>P-ACO uses a specific rule to update the pheromone trail values. In the multi-objective TSP, we have considered that the ant which is updating a pheromone trail matrix, lays down an amount equal to the inverse of the cost of its solution according to the graph associated to the matrix </p><formula xml:id="formula_51">Ds k ij ¼ 1=f k ðbestÞ þ 1=f k ; if</formula><formula xml:id="formula_52">8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; :</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.5.">MONACO for the multi-objective TSP</head><p>The only specification to the previously updated algorithm shown in Section 3.7 is that g ij will be computed as in P-ACO-MOTSP, using Eq. (2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">TSP instances</head><p>The TSP is a very common combinatorial optimization problem that can be described as: given a finite number of ''cities'' along with the cost of traveling between each pair of them, find the cheapest way of visiting all the cities once and returning to the starting point.</p><p>More formally, it can be represented by a complete weighted graph, G = (N, A), with N being the set of cities and A the set of edges fully connecting the nodes N. Each edge is assigned a value d ij , which is the length of edge a ij 2 A. The TSP is the problem of finding a minimal length Hamiltonian circuit of the graph, where a Hamiltonian circuit is a closed tour visiting exactly once each of the n = jNj cities of G.</p><p>In the K-objective TSP, K different cost factors are defined between each pair of towns. In practical applications, the cost factors may for example correspond to cost, length, travel time or tourist attractiveness. We could say that an instance of the K-objective TSP has several graphs associated, each of them having a different cost d k ij for the same edge a ij . In our case, the K-objective symmetric TSP instances considered have been obtained from Jaszkiewicz's web page: http://www-idss.cs.put. poznan.pl/~jaszkiewicz/, where several instances usually tackled in evolutionary multiobjective optimization are collected. Each of these instances was constructed from K = 2 different single objective TSP instances having the same number of towns. The interested reader can refer to <ref type="bibr" target="#b33">[34]</ref> for more information on them. In this study, we will use six bi-criteria TSP instances: Kroab50, Krocd50, Kroab100, Kroad100, Krobc100, and Krocd100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Metrics of performance considered</head><p>In this contribution, we are interested on the two kind of metrics shown in Appendix A.3:</p><p>• those which measure the quality of a non-dominated solution set returned by an algorithm and, • those which compare the performance of two different multi-objective algorithms <ref type="bibr" target="#b46">[47]</ref>.</p><p>As regards the former group, we should notice that the Pareto-optimal sets X and Y , needed to compute the values of metrics M 1 and M Ã 1 , are not known, so we will construct a pseudo-optimal Pareto front combining all the solutions found by all the algorithms and removing the dominated ones in order to use the M Ã 1 metric in our study. On the other hand, we will use the M Ã 2 and M Ã 3 metrics, with r = 10,000 and 20,000, depending on the size of the problem, 50 or 100, respectively (these values are close to the 10% of the Euclidean distance between the two outer solutions in the Pareto fronts obtained).</p><p>Besides, the C metric will be taken as the metric of the second group.</p><p>In addition, we will compare the number of iterations and evaluations needed by each algorithm to generate its Pareto front.</p><p>We should remark that, as the main goal of this work was to study the performance of the MOACO algorithms to generate proper Pareto fronts for the bi-criteria TSP, we have not considered the comparison of the solutions in the genotypic space. To do so, a metric for the decision space would be needed. This could be an interesting extension for future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Parameter settings</head><p>Each of the considered multi-objective algorithms (both MOACO and MOGAs) has been run ten times for each of the six bi-criteria TSP instances. The generic parameter values considered are so usual when applying MOACO algorithms and MOGAs to the TSP problem (see Table <ref type="table" target="#tab_2">2</ref>). The values of the specific parameters, such as k in MOAQ or the number of ants for the Bic-riterionMC algorithm, have been obtained from the papers where the algorithms using them were defined.</p><p>To choose the initial pheromone trail value s 0 , we have considered the method used by each algorithm to update the pheromone trails. Most of them add an amount of pheromone equal to the inverse of the cost of the selected solutions, or the sum of them. Thus, the initial pheromone trail will be computed with the following rule:</p><formula xml:id="formula_53">s 0 ¼ K P K k¼1 f i ðG i Þ ;</formula><p>where G i is a solution for the ith graph given by a greedy algorithm, K is the number of graphs/objectives in the current problem, and f i (G i ) is the cost of the solution G i according to the ith graph. However, two MOACO algorithms use a special rule in order to update the pheromone trails. Thus, they will consider a different value for s 0 : s 0 will be 0.1 for COMPETants, as Doerner et al. did in <ref type="bibr" target="#b15">[16]</ref>, and MACS will apply the following rule to compute it:</p><formula xml:id="formula_54">s 0 ¼ 1 Q K i¼1 P K j¼1 f j ðGiÞ K !</formula><p>as mentioned in Section 3.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results and analysis</head><p>This section is devoted to report and analyze the different results obtained in the experimentation developed. In order to develop this analysis, we will consider the following aspects:</p><p>• The number of iterations and evaluations performed by the algorithms. These results will allow us to identify which algorithms are faster and which are slower. • The graphical representation of the Pareto sets returned. These graphics will help us to understand the values for the following metrics. • Values for the M Ã 1 metric. They will evaluate the distance between the Pareto sets returned and the pseudo-optimal Pareto front.</p><p>• Values for the M Ã 2 metric. M Ã 2 values will evaluate the distribution of the solutions in the Pareto sets returned.</p><p>• Values for the M Ã 3 metric. M Ã 3 values will evaluate the extent of the Pareto sets obtained.</p><p>• Values for the C metric. C values will compare the algorithms between them by calculating the dominance degree of their respective Pareto sets. • Global analysis. Finally, we will draw some conclusions according to the previous results.</p><p>All the experimental data will be reported in the form of box-plots, where the minimum and maximum values are the lowest and highest lines, the upper and lower ends of the box are the upper and lower quartiles and a thick line within the box shows the median.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Analysis of the results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1.">Statistics of the runs</head><p>Figs. <ref type="figure" target="#fig_1">1</ref> and<ref type="figure">2</ref> show the statistics of the runs considered for each algorithm in each of the six bi-criteria TSP instances. The former two graphics are associated to the two small instances, Kroab50  and Krocd50, while the latter two correspond to the four large instances, Kroab100, Kroad100, Krobc100 and Krocd100. We have used the following abbreviations:</p><p>• MONAC for MONACO,</p><p>• BIANT for BicriterionAnt,</p><p>• BIMC for BicriterionMC,</p><p>• UNBI for UnsortBicriterion, and • C-ants for COMPETants.</p><p>In view of these graphics, we can see that both MOGAs, NSGA-II and SPEA2, can usually perform much more iterations and evaluations than the MOACO algorithms considered in the same fixed run time. Hence, this shows how MOACO algorithms are somehow slower than MOGAs in the current problem. We can also notice that Bic-riterionMC and UnsortBicriterion perform less iterations whereas MACS is the algorithm which performs less evaluations than any other. The former is due to the fact that BicriterionMC and UnsortBicriterion used 100 ants while the other MOACO algorithms only handled 20 ants.</p><p>On the other hand, COMPETants, MOAQ and P-ACO are the quickest of the MOACO algorithms implemented, since they perform more evaluations and iterations than the remainder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2.">Visual analysis of the Pareto fronts generated</head><p>In order to graphically represent the different algorithms performance, we will proceed in the same way that Zitzler et al. did in <ref type="bibr" target="#b46">[47]</ref>. All the Pareto sets generated by each algorithm in the 10 runs performed will be fused into a single Pareto front by removing the dominated solutions from the joined set.</p><p>Let us call P j i the non-dominated solution set returned by algorithm i in the jth run, P i the union of the solution sets returned by the ten runs of algorithm i (P 1 i [ P 2 i [ Á Á Á [ P 10 i ), and finally P i the set of all non-dominated solutions in P i . We use the legend in Fig. <ref type="figure">3</ref>. The graphics in Figs. <ref type="figure">4</ref> and<ref type="figure">5</ref>, show these sets P i for the Kroab50 and Krocd50 instances, respectively. In the same way, Figs. <ref type="figure">6</ref><ref type="figure">7</ref><ref type="figure">8</ref><ref type="figure">9</ref>relate to the sets P i when the algorithms are applied to Kroab100, Kroad100, Krobc100 and Krocd100 instances. These graphics offers a visual information, not measurable but sometimes more useful than numeric valuations.</p><p>Looking at Figs. <ref type="figure">4</ref><ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref><ref type="figure">8</ref><ref type="figure">9</ref>, we can draw some conclusions, which must be later trusted in view of the performance metrics values:  comparison with most of those returned by MOACO algorithms. These sets can only dominate some solutions returned by COMPETants and MOAQ when applied to the two small instances of size 50.</p><p>• COMPETants and MOAQ algorithms offer good solutions which optimize one of the two objectives. However, they are not able to cover the middle of the Pareto front in a proper way, i.e., to generate good quality solutions which establish a compromise between the different objectives. In fact, COMPETants is only able to generate solutions in the central part of the Pareto front in the two smaller problem instances considered. In the remaining four, the Pareto fronts generated converged to the two extents. This could be due to the fact that in both algorithms, the ants of a colony only consider the heuristic information associated to their own colony, and not the remainder. • P-ACO, MONACO and BicriterionMC algorithms return very good solutions in the central part of the Pareto front but they are not able to generate any solution at all in the extents of the Pareto front. On the one hand, P-ACO and MONACO only use a single heuristic matrix, which is built by using the average of the cost of the edges for every graph. In addition, they both weight the learned information in a way that gives some automatic bias towards compromise solutions. On the other hand, Bic-riterionMC uses the Update by region method. It makes that the extreme colonies do not receive pheromone, and thus they loss it by evaporation. Finally, the ant belonging to the extreme colonies construct somehow random circuits (every s ij and s 0 ij are similar and close to zero), which is not sufficient in order to obtain new non-dominated solutions. In other words, it seems to loss diversity in its pheromone trails.</p><p>• Finally, BicriterionAnt and, specially, UnsortBicriterion and MACS achieve a good distribution over the Pareto front. Their solutions are sometimes dominated by those returned by P-ACO, MONACO, BicriterionMC, but only in the central part of the Pareto front.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3.">Analysis of the M Ã 1 metric</head><p>The graphics in Figs. <ref type="figure" target="#fig_1">10</ref><ref type="figure" target="#fig_1">11</ref><ref type="figure" target="#fig_1">12</ref>show the values of the M Ã 1 metric obtained by each algorithm in each of the six bi-criteria TSP instances. We can see that P-ACO, MONACO, BicriterionAnt, Bic-riterionMC, Unsortbicriterion and MACS algorithms are those which get the lowest values on the two instances with 50 nodes (they produce non-dominated solution sets very close to the pseudo-optimal Pareto front), whereas MOAQ, COMPETants, SPEA2, and NSGA-II obtain Pareto sets far away from the pseudo-optimal one. On the other hand, the M Ã 1 values of the MOACO algorithms for the instances with 100 nodes behave in a similar way to the previous case. The algorithms that get the lowest values are P-ACO, MONACO, BicriterionMC, UnsortBicriterion and MACS. Both MOGAs obtain poor (high) values. This confirms what we said as regards P-ACO, MONACO, and BicriterionMC obtain high quality solutions. In addition, now we can say that the solutions obtained by BicriterionAnt, UnsortBicriterion, and MACS are also good, although they were dominated in the central region of the Pareto front. and BicriterionMC only obtain solutions in the central part. In addition, the values obtained by the MOGAs, NSGA-II and SPEA2, are low, specially in the instances with 100 nodes. They are only a little bit higher than those obtained by MONACO, P-ACO and BicriterionMC.</p><p>6.1.5. Analysis of the M Ã 3 metric Figs. <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> show the values of the M Ã 3 metric obtained by each algorithm in each of the six bi-criteria TSP instances. In view of these figures, the algorithms which get the higher values are COMPE-Tants, MOAQ, MACS and UnsortBicriterion. On the opposite, P-ACO and MONACO achieve very low measures in the current problem. We should remark how, when analyzing Figs. <ref type="figure">4</ref><ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref><ref type="figure">8</ref><ref type="figure">9</ref>, we recognized that non-dominated solution sets returned by P-ACO and MONACO were located in a small region of the objective space, whereas the Pareto fronts returned by COMPETants, MOAQ and MACS were properly spread off.</p><p>Finally, it is interesting to remark the special behavior of BicriterionMC. Notice that it obtains relatively higher M Ã 3 values in the Krocd50, Kroab100 and Kroad100 instances than P-ACO and MONACO, what indicates that, in these instances and in some runs, BicriterionMC returned some non-dominated solutions far away from the central part of the Pareto front. They may not be present in Figs. <ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>because they could be dominated by other solution from other run. However, one of them can be identified in Fig. <ref type="figure">5</ref> near the point (54,000, 24,000) (highlighted with a circle).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.6.">Analysis of the C metric</head><p>The graphics in Fig. <ref type="figure" target="#fig_1">19</ref> are box-plots based on the C metric. Each rectangle contains six box-plots representing the distribution of the C values for a certain ordered pair of algorithms. From left to right, the leftmost box-plot refers to Kroab50, the second relates to Krocd50, the third to Krobc100, the fourth to Kroad100, the fifth to Kroab100   for instance, the top right box, which represents the fraction of solutions of NSGA-II covered by the non-dominated sets produced by the P-ACO algorithm.</p><p>At the end of the analysis, we can draw the following conclusions: . Between them, P-ACO seems to perform better than the two others. • However, it is easier to identify the algorithms which usually return Pareto sets of bad quality for the problem, when they are compared to those returned by the remaining algorithms considered. This is the case of SPEA2, NSGA-II, COMPETants, and MOAQ. Their Pareto fronts do not usually dominate those generated by the other algorithms while they are normally welldominated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Global analysis</head><p>This section is devoted to draw some general conclusions summarizing all the analysis developed. The conclusions obtained are shown as follows.</p><p>The MOACO algorithms considered are a good choice to solve the bi-objective TSP, performing better than the MOGAs implemented. Notice that, although NSGA-II is one of the state-of-the-art MOGAs for continuous optimization, it does not seem to be well-suited to the TSP since tours can not be well-represented for the application of crossover.</p><p>Besides, it is interesting to notice that the results obtained are robust with respect to the six instances considered, regardless the instance itself and its particular composition. This way, the MOACO algorithms get similar statistic values in the Pareto fronts derived regardless the concrete instance.</p><p>Finally, it is difficult to relate the performance of the MOACO algorithms, when tackling the TSP, according to the taxonomy introduced in Section 4. For example, MOAQ, based on a single pheromone trail matrix and two heuristic matrices, and COMPETants, based on the use of two pheromone trail and heuristic matrices, perform in the same way generating Pareto fronts of good quality in the extremes but badly cover the central parts.</p><p>Opposite to what can be thought, the Pareto fronts generated by MOAQ dominate those got from COMPETants, although the former considers a single pheromone trail matrix and the latter two of them.</p><p>On the other hand, MACS and BicriterionAnt, which showed very good behavior, also belong to the two latter, different families (a single pheromone matrix and two heuristic matrices and two of both matrices, respectively). Again, the Pareto fronts of the former, which only considers a single pheromone matrix, outperforms those of the latter as regards the three metrics considered.</p><p>Nevertheless, we may say that the use of only one heuristic matrix, which could be obtained by averaging the different objectives when tackling the TSP, makes the MOACO algorithm obtain very good compromise solutions and forget the extreme regions of the Pareto front. This is the case of P-ACO and MONACO. This way, it seems that the operation mode of the MOACO algorithm itself is more important for performance purposes than the number of pheromone trail matrices considered by it in the problem instances tackled.</p><p>However, there is a huge diversity in the behavior of the different MOACO algorithms analyzed. As seen in the Pareto fronts graphical representations collected in Section 6.1.2, and later corroborated as regards the M Ã 1 , M Ã 2 and M Ã 3 metric values in Sections 6.1.3-6.1.5, we can find three different behaviors:</p><p>• Algorithms obtaining well-spread Pareto fronts in the objective space extents but with a very bad covering of the central part of the Pareto fronts, like MOAQ and COMPETants. This is clearly checked by the high values of both algorithms in metric M Ã 3 together with their low values in metric M Ã 2 , which show a good extent of the Pareto front obtained but a bad distribution of the non-dominated solutions. These two algorithms share the interesting property that most or all their ants only use one of the two heuristic matrices.</p><p>• Algorithms like P-ACO, MONACO and Bic-riterionMC with the opposite behavior, i.e., generating very good solutions in the central part of the Pareto front by obtaining fronts with a very low extent (with the corresponding lowest values in the M Ã 1 , M Ã 2 and M Ã 3 metrics). The two former algorithms only use one heuristic matrix which is built from the average of the two objectives, whereas BicriterionMC seems to loss diversity in its pheromone trail matrices and, finally, • algorithms with a good generation of the nondominated solution sets, with a proper tradeoff between the central and extreme parts of the Pareto surface. This is the case of MACS, UnsortBicriterion and BicriterionAnt, as can be seen in view of their very low values in M Ã 1 metric (showing high quality in their solutions), highest values in metric M Ã 2 (showing the best distribution of solutions in the front) and their good values in the M Ã 3 one (showing a large extent covered). Between these three algorithms, we can consider that MACS and UnsortBicriterion outperform BicriterionAnt as they obtain better values in M Ã 2 , M Ã 3 and C metrics than the latter. However, we can not easily state which algorithm is the best between MACS and UnsortBicriterion, because they both return very good and similar values for every metric of performance. In addition, with regard to the C metric, it does not seem that the solutions of one algorithm clearly dominate the ones of the other, as slight differences are only observed favouring each of them in different instances. This way, the algorithms of the latter group seem to be the best choice for the current problem with the only drawback that P-ACO, MONACO and BicriterionMC generate better solutions than them in the central parts of the Pareto fronts (see Fig. <ref type="figure" target="#fig_6">20</ref>). When comparing the latter group algorithms with those generating well-spread Pareto fronts such as MOAQ and COMPETants, it can be seen how this is clearly due the fact that the latter algorithms do not converge to the pseudo-optimal Pareto front. An example of this behavior is shown in Fig. <ref type="figure" target="#fig_7">21</ref>.</p><p>The only case we found where the algorithms of a family behaves in the same way is that of P-ACO and MONACO, characterized by two pheromone matrices and a single heuristic matrix. Both algorithms achieve a good convergence to the central parts of the Pareto fronts, avoiding the generation of solutions in the extents of the front. However, the existence of just two MOACO algorithms within the family could be not enough to consider this as a generic behavior. On the other hand, it could be argued that MOAQ and MACS, both belonging to the single pheromone-several heuristic matrices family, show a similar behavior as regards the values obtained in metric M Ã 3 , where the two MOACO algorithms always present high values. However, these high values actually correspond to different kinds of Pareto fronts as, in view of the figures shown in Section 6.1.2, while MOAQ generates good non-dominated solution sets in the extremes of the Pareto fronts, but does not cover their central parts, MACS obtains a well-distributed set all over the fronts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Concluding remarks and future works</head><p>In the current contribution, we have classified the existing Pareto-based MOACO algorithms into a taxonomy and developed an experimental study comparing their performance when applied to several classical instances of the bi-criteria TSP. From the results obtained, we have drawn the conclusion that the MOACO algorithms considered are more competitive in the current problem than two of the state-of-the-art MOGAs, SPEA2 and NSGA-II. Besides, we have drawn the conclusion that belonging to a specific family is not enough to achieve good performance but the operation mode of the ACO algorithm itself is more determinant for the quality of the Pareto fronts generated.</p><p>Several ideas for future developments arise from this study: (i) to analyze the influence of adding local search optimizers to the MOACO algorithms, as usually done in ACO to solve the TSP, and to compare the performance of the resulting techniques against that of memetic algorithms such as Jaszkiewicz's MOGLS <ref type="bibr" target="#b33">[34]</ref>, as some authors have recently started to do for the Quadratic Assignment Problem (where the use of local optimizers is mandatory to achieve good performance when using ACO algorithms) in works such as <ref type="bibr" target="#b35">[36]</ref>; and (ii) to study the performance of MOACO algorithms in other complex multi-objective combinatorial optimization problems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Evolutionary multi-objective optimization</head><p>Evolutionary computation uses computational models of evolutionary processes as key elements in the design and implementation of computerbased problem solving systems. There is a variety of evolutionary computational models that have been proposed and studied which are referred as evolutionary algorithms (EAs) <ref type="bibr" target="#b1">[2]</ref>. Concretely, four well-defined EAs have served as the basis for much of the activity in the field: genetic algorithms (GAs) <ref type="bibr" target="#b39">[40]</ref>, evolution strategies <ref type="bibr" target="#b42">[43]</ref>, genetic programming (GP) <ref type="bibr" target="#b34">[35]</ref> and evolutionary programming <ref type="bibr" target="#b22">[23]</ref>.</p><p>An EA maintains a population of trial solutions, imposes random changes to these solutions, and incorporates selection to determine which ones are going to be maintained in future generations and which will be removed from the pool of trials. But there are also important differences between them. Focusing on the kind of EA considered on this paper, GAs emphasize models of genetic operators as observed in nature, such as crossover (recombination) and mutation, and apply these to abstracted chromosomes with different representation schemes according to the problem being solved.</p><p>EAs are very appropriate to solve multi-objective problems as, thanks to the use of a population of solutions, EAs can search many Pareto-optimal solutions in the same run. Generally, multi-objective EAs (MOEAS) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref> only differ from the rest of EAs in the fitness function and/or in the selection mechanism.</p><p>The evolutionary approaches in multi-objective optimization can be classified in three groups: plain aggregating approaches, population-based non-Pareto approaches and Pareto-based approaches <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>The first group constitutes the extension of classical methods to EAs. The objectives are artificially combined, or aggregated, into a scalar function according to some understanding of the problem, and then the EA is applied in the usual way. Optimizing a combination of the objectives has the advantage of producing a single compromise solution but some of the problems found in the classical multi-objective approaches (see Section 2.2) remain: (i) it can be difficult to define the combination weights in order to obtain acceptable solutions, and (ii) if the optimal solution generated can not be finally accepted, new runs of the EA may be required until a suitable solution is found.</p><p>Population-based non-Pareto approaches allow us to exploit the special characteristics of EAs. A nondominated individual set is obtained instead of only one solution. In order to do so, the selection mechanism is changed. Generally, the best individuals according to each of the objectives are selected, and then these partial results are combined to obtain the new population. An example of a multi-objective GA of this group is vector evaluated genetic algorithm (VEGA) <ref type="bibr" target="#b41">[42]</ref>.</p><p>Finally, Pareto-based approaches seem to be the most active research area on multi-objective EAs nowadays. In fact, algorithms included within this family are divided in two different groups: first and second generation <ref type="bibr" target="#b6">[7]</ref>. They all attempt to promote the generation of multiple non-dominated solutions, as the former group, but directly making use of the Pareto-optimality definition (see Section 2.2).</p><p>This way, to calculate the probability of reproduction of each individual in this approach, the solutions are compared by means of the dominance relation. Different equivalence groups are defined depending on the dominance of their constituent individuals among the remainder and those individuals belonging to the ''good'' classes (those groups including individuals dominating a large number of the remainder) are assigned a higher selection probability than those in the ''bad'' classes.</p><p>The difference between the first and the second generation Pareto-based approaches arise on the use of elitism. Algorithms included within the first generation group <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref>, such as Niched Pareto Genetic Algorithm (NPGA), Non-dominated Sorting Genetic Algorithm (NSGA) and Multiple-Objective Genetic Algorithm (MOGA), do not present this characteristic. On the other hand, second generation Pareto-based multi-objective EAs are based on the consideration of an auxiliary population where the non-dominated solutions generated among the different generations are stored. Examples of the latter family are Strength Pareto EA (SPEA) and SPEA2 <ref type="bibr" target="#b47">[48]</ref> and NSGA-II <ref type="bibr" target="#b14">[15]</ref>, among others. As can be seen, several of the latter algorithms are elitist versions of the corresponding first generation ones.</p><p>Finally, it is important to notice that, although the Pareto-based ranking correctly assigns all nondominated individuals the same fitness, it does not guarantee that the Pareto set is uniformly sampled. When multiple equivalent optima exist, finite populations tend to converge to only one of them, due to stochastic errors in the selection process. This phenomenon is known as genetic drift <ref type="bibr" target="#b13">[14]</ref>. Since preservation of diversity is crucial in the field of multiobjective optimization, several multi-objective EAs have incorporated the niche and species concepts <ref type="bibr" target="#b26">[27]</ref> for the purpose of favoring such behavior.</p><p>The next two subsections are devoted to introduce the two second generation Pareto-based MOGAs considered in this contribution as baselines for the MOACO algorithms implemented, NSGA-II and SPEA2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Non-dominated sorting genetic Algorithm II</head><p>The so-called non-dominated sorting genetic Algorithm II (NSGA-II) was designed by Deb et al. in <ref type="bibr" target="#b14">[15]</ref> to alleviate three difficulties of MOEAs which use non-dominated sorting and sharing: (i) O(K AE N 3 ) computational complexity (where K is the number of objectives and N is the population size); (ii) nonelitist approach; and (iii) the need of specifying a sharing parameter.</p><p>NSGA-II uses two key concepts, ranking and crowding-distance. In order to define the former, NSGA-II classifies every chromosome in the P in several fronts. The first front is composed of the non-dominated solutions. Chromosomes belonging to the second front are solutions which are only dominated by at least one solution in the first front. Those belonging to the third front are solutions only dominated by solutions in the first front and at least one of the second, and so on. Finally, the ranking of the chromosome p, p rank , is the index of the front which the chromosome p belongs to.</p><p>On the other hand, the crowding-distance is a value which estimates the density for every chromosome in the population P. It is the average side length of the cuboid showed in Fig. <ref type="figure" target="#fig_8">22</ref>. The crowding-distance of the chromosome p will be called p distance .</p><p>According to the crowding-distance, NSGA-II defines the Crowded-Comparison Operator, 0 n . Given two chromosomes p and q, p 0 n q if p rank &lt; q rank or p rank = q rank and p distance &gt; q distance .</p><p>Finally, the main loop of the algorithm is as follows. Initially, a random population P 0 is created. The population is sorted based on the non-dominance criterion. Each solution is assigned a fitness equal to its non-dominance level, p rank . Thus, minimization of fitness is assumed. At first, the usual binary tournament selection, recombination, and mutation operators are used to create an offspring population Q 0 of size N, the number of chromosomes in P 0 . Since elitism is introduced by comparing the current population with the best non-dominated solutions previously found, the procedure is different after the initial generation.</p><p>Then, at every iteration, a combined population R t = P t [ Q t is formed. The population R t is of size 2 AE N. Then, R t is classified in fronts according to dominance. Since all previous and current population members are included in R t , elitism is ensured. Now, if the size of the first front in the combined population is smaller than N, NSGA-II chooses all the members from that front for the new population. The remaining population members are chosen from subsequent non-dominated fronts in the order of their ranking. Thus, solutions from the second front are chosen next, followed by solutions from the third front, and so on. This procedure is continued until no more sets can be accommodated. Let us say that the ith front is the last non-dominated set beyond which no other set can be accommodated. To choose exactly N population members, we sort the solutions of the ith front using the crowdedcomparison, 0 n , operator in descending order and choose the best solutions needed to fill all the new population slots. The NSGA-II procedure is also graphically illustrated in Fig. <ref type="figure" target="#fig_9">23</ref>. The new population P t+1 of size N is now used for selection, crossover, and mutation to create a new population Q t+1 of size N. Notice that we use a binary tournament selection operator but the selection criterion is now based on the crowded-comparison operator, 0 n . Since this operator requires both the rank and crowded distance of each solution in the population, we calculate these quantities while forming the new population, as shown in Fig. <ref type="figure" target="#fig_9">23</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Strength Pareto EA2</head><p>Strength Pareto EA2 (SPEA2), proposed by Zitzler et al. in <ref type="bibr" target="#b47">[48]</ref>, was developed as an improvement of SPEA <ref type="bibr" target="#b48">[49]</ref>. In contrast to its predecessor, SPEA2 incorporates a fine-grained fitness assignment strategy, a density estimation technique, and an enhanced archive truncation method.</p><p>This algorithm uses two separate populations of chromosomes, P with N chromosomes as the current population, and P 0 which will contain the N 0 best chromosomes found so far.</p><p>At every iteration, the algorithm copies all the non-dominated individuals in P t and P 0 t to P 0 tþ1 . If the size of P 0 tþ1 exceeds N 0 then it reduces P 0 tþ1 by means of the truncation operator; otherwise if the size of P 0 tþ1 is less than N 0 then it fills P 0 tþ1 with dominated individuals in P t and P 0 t . Then, it performs a binary tournament selection with replacement on P 0 tþ1 in order to fill a mating pool. Finally, the algorithm applies the recombination and mutation operators to the mating pool and set P t+1 to the resulting population.</p><p>In order to assign a fitness value to every chromosome p of populations P and P 0 , the algorithm uses the following rule: fitnessðpÞ ¼ RðpÞ þ DðpÞ:</p><p>In this equation, R(p) is the raw fitness of chromosome p, and D(p) its density. The raw fitness, R, is calculated as follows:</p><formula xml:id="formula_55">RðpÞ ¼ X i1p</formula><p>SðiÞ; SðiÞ ¼ jj; j 2 P [ P 0 ^i 1 jj;</p><p>where i 1 j indicates that solution i dominates solution j. S(i) is called the strength of solution i.</p><p>At the other hand, D(p) is computed using an adaptation of Silverman's kth nearest neighbor method <ref type="bibr" target="#b43">[44]</ref>. The algorithm calculates D(p) as follows:</p><p>DðpÞ ¼ 1=ðr k p þ 2Þ; where r k p is the distance between the chromosome p and its kth nearest neighbor. Usually k is equal to ffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi N þ N 0 p . When the size of P 0 tþ1 is lesser than N 0 , the algorithm fills this external population with the best solutions in (P t [ P 0 t ) À P 0 tþ1 , according to their fitness values. Otherwise, if the size of P 0 tþ1 is greater than N 0 , the algorithm iteratively removes individuals from P 0 tþ1 until jP 0 tþ1 j = N 0 . Here, at each iteration, the algorithm removes the individual i, with i 6 d j for all j 2 P 0 tþ1 where i6 d j () 8k; 0 &lt; k &lt; jP 0 tþ1 j : r k i ¼ r k j _ 9k; 0 &lt; k &lt; jP 0 tþ1 j : ½ð8l; 0 &lt; l &lt; k : r l i ¼ r l j Þ ^rk i &lt; r k j with r k i denoting the distance of i to its kth nearest neighbor in P 0 tþ1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Metrics of performance</head><p>Experimentally comparing different optimization techniques always involves the notion of performance. In the case of multi-objective optimization, </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Number of iterations (left) and evaluations (right) performed by the algorithms in the Kroab50 and Krocd50 runs (logarithmic scale).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .Fig. 3 .Fig. 4 .Fig. 5 .Fig. 6 .Fig. 7 .Fig. 8 .Fig. 9 .</head><label>23456789</label><figDesc>Fig. 2. Number of iterations (left) and evaluations (right) performed by the algorithms in the Kroab100, Kroad100, Krobc100 and Krocd100 runs (logarithmic scale).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 10 Fig. 11 .Fig. 12 .Fig. 13</head><label>10111213</label><figDesc>Fig. 10. M Ã 1 values for the algorithms in the instance Kroab50 and Krocd50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 14 .Fig. 15 .</head><label>1415</label><figDesc>Fig. 14. M Ã 2 values for the algorithms in the instance Kroab100 and Kroad100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 18 .Fig. 19 .</head><label>1819</label><figDesc>Fig. 18. M Ã3 values for the algorithms in the instance Krobc100 and Krocd100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. Central parts of Pareto fronts of P-ACO, MONACO, BicriterionMC, MACS and UnsortBicriterion in the Krobc100 (left) and Krocd100 (right) instances. The line which joins the overall non-dominated solutions represents the pseudo-optimal Pareto front.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 21 .</head><label>21</label><figDesc>Fig. 21. Pareto fronts of MACS, UnsortBicriterion, MOAQ, and COMPETants in the Kroad100 instance. The line which joins the overall non-dominated solutions represents the pseudo-optimal Pareto front.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 22 .</head><label>22</label><figDesc>Fig. 22. Crowding-distance calculation. Points marked in filled circles are solutions of the same non-dominated front. Figure taken from [15].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. NSGA-II procedure. Figure taken from [15].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">A taxonomy for MOACO algorithms</cell><cell></cell></row><row><cell></cell><cell>A single heuristic</cell><cell>Several heuristic</cell></row><row><cell></cell><cell>matrix</cell><cell>matrices</cell></row><row><cell>A single pheromone</cell><cell>MOACOM</cell><cell>MOAQ</cell></row><row><cell>trail matrix</cell><cell></cell><cell></cell></row><row><cell></cell><cell>MOACO-ALBP</cell><cell></cell></row><row><cell></cell><cell>ACOAMO</cell><cell>MACS</cell></row><row><cell></cell><cell></cell><cell>BicriterionAnt</cell></row><row><cell>Several pheromone</cell><cell>P-ACO</cell><cell>UnsortBicriterion</cell></row><row><cell>trail matrices</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>BicriterionMC</cell></row><row><cell></cell><cell>MONACO</cell><cell>COMPETants</cell></row><row><cell></cell><cell></cell><cell>MACS-VRPTW</cell></row><row><cell></cell><cell></cell><cell>MO-PACO</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>edge a ij 2 best;</figDesc><table><row><cell>ðsecond-bestÞ</cell><cell>and second-best solutions;</cell></row><row><cell>1=f k ðbestÞ;</cell><cell>if edge a ij 2 best solution;</cell></row><row><cell cols="2">1=f k ðsecond-bestÞ; if edge</cell></row><row><cell></cell><cell>a ij 2 second-best solution;</cell></row><row><cell>0;</cell><cell>otherwise:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>Parameter values considered</cell><cell></cell></row><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Number of runs for</cell><cell>10</cell></row><row><cell>each algorithm</cell><cell></cell></row><row><cell>Maximum run time</cell><cell>300 seconds (50 nodes instances)</cell></row><row><cell></cell><cell>900 seconds (100 nodes instances)</cell></row><row><cell>Number of ants</cell><cell>20 (100 for BicriterionMC</cell></row><row><cell></cell><cell>and UnsortBicriterion)</cell></row><row><cell>a</cell><cell>1</cell></row><row><cell>b</cell><cell>2</cell></row><row><cell>q</cell><cell>0.2</cell></row><row><cell>q 0</cell><cell>0.98 (0.99 for MOAQ)</cell></row><row><cell>c (MOAQ)</cell><cell>0.4</cell></row><row><cell>k (MOAQ)</cell><cell>0.9</cell></row><row><cell>N C (BicriterionMC and</cell><cell>10</cell></row><row><cell>UnsortBicriterion)</cell><cell></cell></row><row><cell>MOGA population size</cell><cell>100 (NSGA-II)</cell></row><row><cell></cell><cell>80 plus 20 in the elite</cell></row><row><cell></cell><cell>population (SPEA2)</cell></row><row><cell>Crossover probability</cell><cell>0.8</cell></row><row><cell>Mutation probability</cell><cell>0.1</cell></row><row><cell>Computer specifications</cell><cell>Intel Celeron TM 1200 MHz</cell></row><row><cell></cell><cell>with 256 MB RAM</cell></row><row><cell>Operating system</cell><cell>Linux Red Hat 9.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>). Consider,</figDesc><table><row><cell>20000 40000 60000 80000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>20000 40000 60000 80000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>P-ACO</cell><cell>MONAC</cell><cell>BIANT</cell><cell>BIMC</cell><cell>UNBI</cell><cell>MOAQ</cell><cell>MACS</cell><cell>C-ants</cell><cell>SPEA2</cell><cell>NSGA-II</cell><cell>P-ACO</cell><cell>MONAC</cell><cell>BIANT</cell><cell>BIMC</cell><cell>UNBI</cell><cell>MOAQ</cell><cell>MACS</cell><cell>C-ants</cell><cell>SPEA2</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="12">Fig. 16. M Ã 3 values for the algorithms in the instance Kroab50 and Krocd50.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>50000 100000 200000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50000 100000 150000 200000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>P-ACO</cell><cell>MONAC</cell><cell>BIANT</cell><cell>BIMC</cell><cell>UNBI</cell><cell>MOAQ</cell><cell>MACS</cell><cell>C-ants</cell><cell>SPEA2</cell><cell>NSGA-II</cell><cell>P-ACO</cell><cell>MONAC</cell><cell>BIANT</cell><cell>BIMC</cell><cell>UNBI</cell><cell>MOAQ</cell><cell>MACS</cell><cell>C-ants</cell><cell>SPEA2</cell><cell>NSGA-II</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="13">Fig. 17. M Ã 3 values for the algorithms in the instance Kroab100 and Kroad100.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>50000 100000 150000 200000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50000 100000 150000 200000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>P-ACO</cell><cell>MONAC</cell><cell>BIANT</cell><cell>BIMC</cell><cell>UNBI</cell><cell>MOAQ</cell><cell>MACS</cell><cell>C-ants</cell><cell>SPEA2</cell><cell>NSGA-II</cell><cell>P-ACO</cell><cell>MONAC</cell><cell>BIANT</cell><cell>BIMC</cell><cell>UNBI</cell><cell>MOAQ</cell><cell>MACS</cell><cell>C-ants</cell><cell>SPEA2</cell><cell>NSGA-II</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Note that ants only communicate indirectly, through modifications of the physical environment they perceive. This form of communication is called artificial stigmergy in<ref type="bibr" target="#b17">[18]</ref>. C. Garcı ´a-Martı ´nez et al. / European Journal of Operational Research 180 (2007) 116-148</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>C. Garcı ´a-Martı ´nez et al. / European Journal of Operational Research 180 (2007) 116-148</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>C. Garcı ´a-Martı ´nez et al. / European Journal of Operational Research 180 (2007) 116-148</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>q This work was partially supported by the Spanish Ministerio de Ciencia y Tecnologı ´a under project TIC2003-00877 (including FEDER fundings), under Network HEUR TIC2002-10866-E, and under a scholarship from the Education and Universities Spanish Government Secretariat given to the author C. Garcı ´a-Martı ´nez.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>the definition of quality is substantially more complex than for single-objective optimization problems, because the optimization goal itself consists of multiple objectives <ref type="bibr" target="#b6">[7]</ref>:</p><p>• The distance of the resulting non-dominated set to the real Pareto-optimal front should be minimized. • A good (in most cases uniform) distribution of the solutions found is desirable. The assessment of this criterion might be based on a certain distance metric. • The extent of the obtained non-dominated front should be maximized, i.e., for each objective, a wide range of values should be covered by the non-dominated solutions.</p><p>Several individual metrics aiming at measuring the achievement of the previous goals by the Pareto set derived from a specific multi-objective algorithm have been proposed in the literature <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b46">47]</ref>. Some of them, proposed by Zitzler et al. in <ref type="bibr" target="#b46">[47]</ref>, are reviewed as follows:</p><p>Given a set of pairwise non-dominated decision vectors X 0 X, a neighborhood parameter r &gt; 0 (to be chosen appropriately), and a distance metric kAEk:</p><p>1. Function M 1 gives the average distance to the Pareto-optimal set X X :</p><p>2. Function M 2 takes the distribution in combination with the number of non-dominated solutions found into account:</p><p>3. Function M 3 considers the extent of the front described by X 0 :</p><p>Analogously, Zitzler et al. define three metrics M Ã 1 , M Ã 2 and M Ã 3 on the objective space. Let Y 0 ; Y Y be the sets of objective vectors that correspond to X 0 and X , respectively, and r * &gt; 0 and kAEk * as before:</p><p>While M 1 and M Ã 1 are intuitive, M 2 and M 3 (respectively, M Ã 2 and M Ã 3 ) need further explanation. The distribution metrics give a value within the interval [0, jX 0 j] ([0, jY 0 j]). The higher the value of the metric, the better the distribution for an appropriate neighborhood parameter (e.g., M Ã 2 ðY 0 Þ ¼ jY 0 j means that, for each objective vector, there is no other objective vector within a r * -distance to it). Functions M 3 and M Ã 3 use the maximum extent in each dimension to estimate the range to which the front spreads out. In the case of two objectives, this equals the distance of the two outer solutions.</p><p>The previous metrics allows us to determine the absolute, individual quality of a Pareto front. On the other hand, other metrics whose aim is to compare the performance of two different multi-objective algorithms by comparing the Pareto sets generated by each of them, have also been introduced in the literature. One of the most used among these metrics was that proposed by Zitzler et al. in <ref type="bibr" target="#b46">[47]</ref>, which compares a pair of non-dominated sets by computing the fraction of each set that is covered by the other: CðX 0 ; X 00 Þ ¼ jfa 00 2 X 00 ; 9a 0 2 X 0 : a 0 1 a 00 gj=jX 00 j;</p><p>where a 0 1 a 00 indicates that the solution a 0 dominates the solution a 00 .</p><p>Hence, the value C(X 0 , X 00 ) = 1 means that all the solutions in X 00 are dominated by or equal to solutions in X 0 . The opposite, C(X 0 , X 00 ) = 0, represents the situation where none of the solutions in X 00 are covered by the set X 0 . Note that both C(X 0 , X 00 ) and C(X 00 , X 0 ) have to be considered, since C(X 0 , X 00 ) is not necessarily equal to 1 À C(X 00 , X 0 ).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A multiobjective ant colony system for vehicle routing problem with time windows</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bara ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schaerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Twenty first IASTED International Conference on Applied Informatics, Insbruck, Austria</title>
		<meeting>Twenty first IASTED International Conference on Applied Informatics, Insbruck, Austria</meeting>
		<imprint>
			<date type="published" when="2003">February 10-13, 2003</date>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Ba</surname></persName>
		</author>
		<title level="m">Evolutionary Algorithms in Theory and Practice</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A multiple objective ant colony optimization approach to assembly line balancing problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baykasoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dereli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">35th International Conference on Computers and Industrial Engineering (CIE35)</title>
		<meeting><address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="263" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new rank-based version of the ant system: A computational study</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bullnheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kotsis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Central European Journal for Operations Research and Economics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="38" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MONACO-multi-objective network optimisation based on an ACO</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jesu ´s</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ma ´rquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. X Encuentros de Geometrı ´a Computacional</title>
		<meeting>X Encuentros de Geometrı ´a Computacional<address><addrLine>Seville, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">June 16-17, 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multiobjective Decision Making Theory and Methodology</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chankong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Haimes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>North-Holland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Evolutionary Algorithms for Solving Multi-objective Problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new ACO model integrating evolutionary computation concepts: The best-worst ant system</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cordo ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ferna ´ndez De Viana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ANTS2000-From Ant Colonies to Artificial Ants</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</editor>
		<meeting>of ANTS2000-From Ant Colonies to Artificial Ants<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-09">September, 2000</date>
			<biblScope unit="page" from="22" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ferna ´ndez de Viana, F. Herrera, Analysis of the best-worst ant system and its variants on the TSP</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cordo ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathware and Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="177" to="192" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysis of the best-worst ant system and its variants on the QAP</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cordo ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ferna ´ndez De Viana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ant Algorithms, Proc. of ANTS2002</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Di</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Caro</surname></persName>
		</editor>
		<editor>
			<persName><surname>Sampels</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2463</biblScope>
			<biblScope unit="page" from="228" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A review on the ant colony optimization metaheuristic: Basis, models and new trends</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cordo ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathware and Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="141" to="175" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A closer look at drawbacks of minimizing weighted sums of objectives for Pareto set generation in multicriteria optimization problems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dennis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Optimization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="63" to="69" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Multi-objective Optimization Using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An investigation of niche and species formation in genetic function optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third International Conference on Genetic Algorithms (ICGA&apos;89)</title>
		<meeting>Third International Conference on Genetic Algorithms (ICGA&apos;89)<address><addrLine>Hillsdale, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="42" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Are COMPETants more competent for problem solving?-The case of full truckload transportation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Doerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Hartl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teimann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Central European Journal of Operations Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="141" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pareto ant colony optimization: A metaheuristic approach to multiobjective portfolio selection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Doerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Gutjahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Hartl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strauss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="79" to="99" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The ant colony optimization metaheuristic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Di</forename><surname>Caro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Ideas in Optimization</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</editor>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="11" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ant colony system: A cooperative learning approach to the travelling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="66" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The ant system: Optimization by a colony of cooperating agents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics-Part B</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The ant colony optimization metaheuristic: Algorithms, applications, and advances</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Kochenberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Ant Colony Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">System Identification Trough Simulated Evolution, A Machine Learning Approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Ginn Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ant-Q: A reinforcement learning approach to the traveling salesman problem</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Twelfth International Conference on Machine Learning (ML-95)</title>
		<meeting>Twelfth International Conference on Machine Learning (ML-95)<address><addrLine>Tahoe City, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="252" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">MACS-VRPTW: A multiple ant colony system for vehicle routing problems with time windows</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Taillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Agazzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Ideas in Optimization</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</editor>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="73" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<author>
			<persName><forename type="first">X</forename><surname>Gandibleux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sevaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>So ¨rensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Metaheuristics for Mutiobjective Optimisation</title>
		<title level="s">Lecture Notes in Economics and Mathematical Systems</title>
		<editor>
			<persName><forename type="first">V</forename></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">535</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Genetic algorithms with sharing for multimodal function optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Second International Conference on Genetic Algorithms (ICGA&apos;87)</title>
		<meeting>Second International Conference on Genetic Algorithms (ICGA&apos;87)<address><addrLine>Hillsdale, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Scheduling continuous casting of aluminium using a multiple objective ant colony optimization metaheuristic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gravel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gagne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="218" to="229" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A population based approach for ACO, applications of evolutionary computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guntsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EvoWorkshops2002: EvoCOP, EvoIASP, EvoSTim, 2279</title>
		<meeting>of EvoWorkshops2002: EvoCOP, EvoIASP, EvoSTim, 2279<address><addrLine>Kinsale, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Solving multi-objective permutation problems with population based ACO</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guntsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Evolutionary Multi-Criteria Optimization (EMO&apos;03)</title>
		<meeting>Evolutionary Multi-Criteria Optimization (EMO&apos;03)<address><addrLine>Faro, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="464" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multicriteria optimization for highly accurate systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multicriteria Optimization in Engineering and Sciences</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Stadler</surname></persName>
		</editor>
		<imprint>
			<publisher>Plenum Press</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="309" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bi-criterion optimization with multi colony ant algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iredi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. First International Conference on Evolutionary Multi-criterion Optimization (EMO&apos;01)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>First International Conference on Evolutionary Multi-criterion Optimization (EMO&apos;01)</meeting>
		<imprint>
			<date type="published" when="1993">1993. 2001</date>
			<biblScope unit="page" from="359" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Multiple Objective Metaheuristic Algorithms for Combinatorial Optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaszkiewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Poznan University of Technology</publisher>
			<biblScope unit="volume">360</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Habilitation thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Genetic local search for multi-objective combinatorial optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaszkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="71" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Genetic Programming: On the Programming of Computers by Means of Natural Selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On the design of ACO for the biobjective quadratic assignment problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lo ´pez-Iba ´n ˜ez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paquete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fourth International Workshop on Ant Colony Optimization (ANTS 2004)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Birattari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Blum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Gambardella</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Montada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</editor>
		<meeting>of the Fourth International Workshop on Ant Colony Optimization (ANTS 2004)</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3172</biblScope>
			<biblScope unit="page" from="214" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A multiple objective Ant-Q algorithm for the design of water distribution irrigation networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Mariano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Morales</surname></persName>
		</author>
		<idno>HC-9904</idno>
	</analytic>
	<monogr>
		<title level="j">Instituto Mexicano de Tecnologı ´a del Agua</title>
		<imprint>
			<date type="published" when="1999-06">June, 1999</date>
			<pubPlace>Mexico</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">MOAQ: An Ant-Q algorithm for multiple objective optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Mariano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Morales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Genetic and Evolutionary Computing Conference (GECCO 99)</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Daida</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Garzon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Hnavar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Jakiela</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</editor>
		<meeting>of the Genetic and Evolutionary Computing Conference (GECCO 99)<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-07">July 1999</date>
			<biblScope unit="page" from="894" to="901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An ant colony optimization approach to addressing a JIT sequencing problem with multiple objectives</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Mcmullen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in Engineering</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="309" to="317" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Genetic Algorithms + Data Structures = Evolution Programs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Solving multiobjective multicast problem with a new ant colony optimization approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bara ´n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second IFIP/ACM Latin American Networking Conference (LANC&apos;05)</title>
		<imprint>
			<publisher>Cali Colombia</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multiple objective optimization with vector evaluated genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms and Their Applications: Proc. of the 1st Int. Conf. on Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Evolution and Optimum SeekingSixth-Generation Computer Technology Series</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Schwefel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>John Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Density Estimation for Statistics and Data Analysis</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Silverman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">MAX-MIN ant system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="889" to="914" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Lau ¨gt, An ant colony optimization algorithm to solve a 2-machine bicriteria flowshop scheduling problem</title>
		<author>
			<persName><forename type="first">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Monmarche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tercinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="250" to="257" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Comparison of multiobjective evolutionary algorithms: Empirical results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="195" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Evolutionary Methods for Design, Optimization and Control with Applications to Industrial Problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<editor>K. Giannakoglou et al.</editor>
		<imprint>
			<date type="published" when="2001-09">2001. September 2001</date>
			<biblScope unit="page" from="12" to="21" />
			<pubPlace>Athens, Greece</pubPlace>
		</imprint>
	</monogr>
	<note>SPEA2: Improving the strength Pareto evolutionary algorithm</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithms: A comparative case study and the strength Pareto approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
