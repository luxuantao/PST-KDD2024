<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS</title>
				<funder ref="#_Zcwkpue">
					<orgName type="full">CIFAR</orgName>
				</funder>
				<funder>
					<orgName type="full">Province of Ontario</orgName>
				</funder>
				<funder>
					<orgName type="full">Government of Canada</orgName>
				</funder>
				<funder ref="#_Vuxtqef #_PfGzX6u">
					<orgName type="full">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-11-03">3 Nov 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yongchao</forename><surname>Zhou</surname></persName>
							<email>yczhou@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrei</forename><forename type="middle">Ioan</forename><surname>Muresanu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziwen</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Keiran</forename><surname>Paster</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Silviu</forename><surname>Pitis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Harris</forename><surname>Chan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-11-03">3 Nov 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2211.01910v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the "program," optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The combination of scale and attention-based architectures has resulted in language models possessing an unprecedented level of generality <ref type="bibr" target="#b20">(Kaplan et al., 2020;</ref><ref type="bibr" target="#b43">Vaswani et al., 2017)</ref>. These so-called "large language models" (LLMs) have shown remarkable, often superhuman, capabilities across a diverse range of tasks, including both zero-shot and few-shot setups <ref type="bibr" target="#b5">(Brown et al., 2020;</ref><ref type="bibr" target="#b42">Srivastava et al., 2022)</ref>. With generality, however, there comes a question of control: how can we make LLMs do what we want them to do?</p><p>To answer this question and steer LLMs toward desired behaviors, recent work has considered fine-tuning <ref type="bibr" target="#b32">(Ouyang et al., 2022;</ref><ref type="bibr" target="#b52">Ziegler et al., 2019)</ref>, in-context learning <ref type="bibr" target="#b5">(Brown et al., 2020)</ref>, and several forms of prompt generation <ref type="bibr" target="#b14">(Gao, 2021)</ref>, including both differentiable tuning of soft prompts <ref type="bibr" target="#b34">(Qin &amp; Eisner, 2021;</ref><ref type="bibr" target="#b23">Lester et al., 2021)</ref> and natural language prompt engineering <ref type="bibr" target="#b37">(Reynolds &amp; McDonell, 2021)</ref>. The latter is of particular interest, as it provides a natural interface for humans to communicate with machines and may be of great relevance not only to LLMs but to other generalist models such as prompted image synthesizers <ref type="bibr" target="#b38">(Rombach et al., 2022;</ref><ref type="bibr" target="#b36">Ramesh et al., 2022)</ref>, for which public interest in prompt design and generation has also emerged (see Appendix A for examples).</p><p>Behind this interest is the fact that plain language prompts do not always produce the desired results, even when those results are possible to produce with alternative instructions. Thus, human users must experiment with a wide range of prompts to elicit desired behaviors, as they have little knowledge of how compatible instructions are with a particular model. We can understand this by viewing LLMs as black-box computers that execute programs specified by natural language instructions: while they can execute a broad range of natural language programs, the way these programs are processed may not be intuitive for humans, and the quality of instruction can only be measured when executing these instructions on a downstream task <ref type="bibr" target="#b39">(Sanh et al., 2022;</ref><ref type="bibr" target="#b45">Wei et al., 2021)</ref>.</p><p>To reduce the human effort involved in creating and validating effective instructions, we propose a novel algorithm using LLMs to generate and select instructions automatically. We call this problem As measured by the interquartile mean across the 24 NLP tasks introduced by <ref type="bibr" target="#b17">Honovich et al. (2022)</ref>, APE is able to surpass human performance when using the InstructGPT model <ref type="bibr" target="#b32">(Ouyang et al., 2022)</ref>.</p><p>natural language program synthesis and propose to address it as a black-box optimization problem using LLMs to generate and search over heuristically viable candidate solutions. In doing so, we leverage the generalist capabilities of LLMs in three ways. First, we use an LLM as an inference model <ref type="bibr" target="#b13">(Ellis et al., 2021;</ref><ref type="bibr" target="#b17">Honovich et al., 2022)</ref> to generate instruction candidates based on a small set of demonstrations in the form of input-output pairs. Next, we guide the search process by computing a score for each instruction under the LLM we seek to control. Finally, we propose an iterative Monte Carlo search method where LLMs improve the best candidates by proposing semantically similar instruction variants. Intuitively, our algorithm asks LLMs to generate a set of instruction candidates based on demonstrations and then asks them to assess which instructions are more promising. We call our algorithm Automatic Prompt Engineer (APE). Our main contributions are:</p><p>? We frame instruction generation as natural language program synthesis, formulate it as a black-box optimization problem guided by LLMs, and propose both a naive and an iterative Monte Carlo search methods to approximate the solution. ? Our proposed method, APE, achieves human-level performance on zero-shot learning with model-generated instructions on 19/24 NLP tasks. ? We provide extensive qualitative and quantitative analyses exploring various facets of APE, and demonstrate applications of APE for improving few-shot learning and steering LLMs toward desired behaviors such as truthfulness and/or informativeness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Large Language Models Scaling up transformer-based language models in terms of model size, training data, and training compute has been shown to predictably improve performance on a wide range of downstream NLP tasks <ref type="bibr" target="#b43">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b10">Devlin et al., 2018;</ref><ref type="bibr" target="#b5">Brown et al., 2020)</ref>. Many emergent abilities <ref type="bibr">(Wei et al., 2022a)</ref> of LLMs have been discovered as a result of this scaling, including few-shot in-context learning, zero-shot problem solving, chain of thought reasoning, instruction following, and instruction induction <ref type="bibr" target="#b7">(Cobbe et al., 2021;</ref><ref type="bibr">Wei et al., 2022b;</ref><ref type="bibr" target="#b21">Kojima et al., 2022;</ref><ref type="bibr" target="#b39">Sanh et al., 2022;</ref><ref type="bibr" target="#b45">Wei et al., 2021;</ref><ref type="bibr" target="#b32">Ouyang et al., 2022;</ref><ref type="bibr" target="#b17">Honovich et al., 2022)</ref>. In this paper, we view LLMs as black-box computers that execute programs specified by natural language instructions and investigate how to control an LLM's behavior using model-generated instructions.</p><p>Prompt Engineering Prompting offers a natural and intuitive interface for humans to interact with and use generalist models such as LLMs. Due to its flexibility, prompting has been widely used as a generic method for NLP tasks <ref type="bibr" target="#b40">(Schick &amp; Sch?tze, 2021;</ref><ref type="bibr" target="#b5">Brown et al., 2020;</ref><ref type="bibr" target="#b39">Sanh et al., 2022)</ref>. However, LLMs require careful prompt engineering, either manually <ref type="bibr" target="#b37">(Reynolds &amp; McDonell, 2021)</ref> or automatically <ref type="bibr" target="#b15">(Gao et al., 2021;</ref><ref type="bibr" target="#b41">Shin et al., 2020)</ref>, as models do not seem to understand the prompts in the same way a human would <ref type="bibr" target="#b44">(Webson &amp; Pavlick, 2021;</ref><ref type="bibr" target="#b29">Lu et al., 2021)</ref>. Though many successful read both sentences and determine ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large set of instruction candidates Demonstrations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLMs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generate semantically similar instructions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scoring and filtering using LLMs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Execute &amp; evaluate</head><p>Figure 2: Our method, Automatic Prompt Engineer (APE), automatically generates instructions for a task that is specified via output demonstrations: it generates several instruction candidates, either via direct inference or a recursive process based on semantic similarity, executes them using the target model, and selects the most appropriate instruction based on computed evaluation scores.</p><p>prompt tuning methods perform optimization over a continuous space using gradient-based methods <ref type="bibr" target="#b28">(Liu et al., 2021;</ref><ref type="bibr" target="#b34">Qin &amp; Eisner, 2021;</ref><ref type="bibr" target="#b23">Lester et al., 2021)</ref>, this becomes less practical with scale, as computing computing gradients becomes increasingly expensive and access to models shifts to APIs that may not provide gradient access. In our paper, we borrow components from discrete prompt search methods, such as prompt generation <ref type="bibr" target="#b15">(Gao et al., 2021;</ref><ref type="bibr" target="#b4">Ben-David et al., 2021)</ref>, prompt scoring <ref type="bibr" target="#b8">(Davison et al., 2019)</ref> and prompt paraphrasing <ref type="bibr" target="#b19">(Jiang et al., 2020;</ref><ref type="bibr" target="#b49">Yuan et al., 2021)</ref> to optimize instructions by searching directly in the natural language hypothesis space. As compared to this past work, which uses specialized models for each component and leans heavily on human templates, we show that the entire search can be conducted by a single LLM.</p><p>Program Synthesis Program synthesis involves the automatic search over a "program space" to find a program satisfying a particular specification <ref type="bibr" target="#b16">(Gulwani et al., 2017)</ref>. Modern program synthesis admits a wide variety of specifications, including input-output examples <ref type="bibr" target="#b13">(Ellis et al., 2021;</ref><ref type="bibr" target="#b48">Wong et al., 2021)</ref> and natural language <ref type="bibr" target="#b18">(Jain et al., 2022)</ref>. The range of feasible program spaces to search over has also grown, from historically restrictive domain-specific languages to general-purpose programming languages <ref type="bibr" target="#b2">(Austin et al., 2021)</ref>. In contrast to prior approaches that require a suitable structured hypothesis space and library of components <ref type="bibr" target="#b25">(Liang et al., 2010;</ref><ref type="bibr" target="#b12">Ellis et al., 2018)</ref>, we leverage the structure provided by LLMs to search over the space of natural language programs. Using inference models is a standard practice to speed up the search by restricting the search space to a limited space of possible expressions <ref type="bibr" target="#b31">(Menon et al., 2013;</ref><ref type="bibr" target="#b22">Lee et al., 2018;</ref><ref type="bibr" target="#b9">Devlin et al., 2017;</ref><ref type="bibr" target="#b13">Ellis et al., 2021)</ref>. Inspired by this, we use LLMs as approximate inference models to generate program candidates based on a small set of demonstrations. Unlike classical program synthesis, our inference models do not require any training and generalize well to various tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NATURAL LANGUAGE PROGRAM SYNTHESIS USING LLMS</head><p>We consider a task specified by a dataset D train = {(Q, A)} of input/output demonstrations sampled from population X , and a prompted model M. The goal of natural language program synthesis is to find a single instruction ? such that, when M is prompted with the concatenation [?; Q] of instruction and a given input, M produces the corresponding output A. More formally, we frame this as an optimization problem, where we seek instruction ? that maximizes the expectation of some per-sample score f (?, Q, A) over possible (Q, A):</p><formula xml:id="formula_0">? = arg max ? f (?) = arg max ? E (Q,A) [f (?, Q, A)]<label>(1)</label></formula><p>Note that in general, Q may be the empty string, such that we are optimizing ? as a prompt that directly produces outputs {A}. While this task has been widely attempted by humans, we have little knowledge of how compatible any particular instruction is with model M.  <ref type="bibr">3 (Top)</ref>. In this case, the wording suggests that the outputs are generated based on the instruction, so that the score functions considered will be high.</p><p>Reverse Mode Generation Although the "forward" model works out of the box for most of the pretrained LLMs, translating P (? | D train , f (?) is high) into words requires custom engineering across different tasks. This is because the "forward" model only generates text from left to right, while we would like the model to predict the missing context before the demonstrations. To address this, we also consider "reverse" mode generation, which uses an LLM with infilling capabilities-e.g., T5 <ref type="bibr" target="#b35">(Raffel et al., 2020)</ref>, GLM <ref type="bibr" target="#b11">(Du et al., 2022)</ref>, and InsertGPT <ref type="bibr" target="#b3">(Bavarian et al., 2022)</ref>-to infer the missing instructions. Our "reverse" model directly samples from P (? | D train , f (?) is high) by filling in the blank, making it a more versatile approach than the "forward" completion models. For example, in our instruction induction experiments we use the template in Figure <ref type="figure">3</ref> (Middle).</p><p>Customized Prompts Note that depending on the score function being used, there may exist more appropriate prompts than the samples above. For example, in our TruthfulQA experiments, we start with the human-designed instructions from the original dataset <ref type="bibr" target="#b27">(Lin et al., 2022)</ref>. As shown in Figure <ref type="figure">3</ref> (Bottom), the "reverse" model is asked to propose initial instruction samples that fit the missing context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SCORE FUNCTIONS</head><p>To cast our problem as black-box optimization, we choose a score function that accurately measures the alignment between the dataset and the data the model generates. In our instruction induction experiments, we consider two potential score functions, described below. In the TruthfulQA experiments, we focused primarily on automated metrics proposed in <ref type="bibr" target="#b27">Lin et al. (2022)</ref>, similar to the execution accuracy. In each case, we evaluate the quality of a generated instruction using Equation (1), and take the expectation over a held-out test dataset D test .</p><p>Execution accuracy First, we consider evaluating the quality of an instruction ? using the execution accuracy metric proposed by <ref type="bibr" target="#b17">Honovich et al. (2022)</ref>, which we denote as f exec . In most cases, execution accuracy is simply defined as the 0-1 loss, f (?,</p><formula xml:id="formula_1">Q, A) = [M([?; Q]) = A].</formula><p>On some tasks, execution accuracy takes into account invariants; e.g., it may be an order invariant set matching loss, as described in Appendix A of <ref type="bibr" target="#b17">Honovich et al. (2022)</ref>.</p><p>Log probability We further consider a softer probabilistic score function, which we hypothesize might improve optimization by providing a more fine-grained signal when searching over low-quality instruction candidates. In particular, we consider the log probability of the desired answer given the instruction and question under the target model M, which on a per sample basis, is log</p><formula xml:id="formula_2">P (A | [?; Q]).</formula><p>Efficient score estimation Estimating the score by computing the score over the entire training dataset for all instruction candidates can be expensive. To reduce the computation cost, we adopt a filtering scheme where a promising candidate receives more computation resources while a lowquality candidate receives less computation. It can be achieved by using a multi-stage computation strategy on lines 2-9 Algorithm 1. We first evaluate all candidates with a small subset of the training dataset. For the candidates with a score greater than a certain threshold, we sample and evaluate a new non-overlapping subset from the training dataset to update the moving average of the score. Then, we repeat this process until a small set of candidates is left, which are evaluated on the entire training dataset. This adaptive filtering scheme significantly improves the computation efficiency by keeping the exact computation costs for the high-quality samples and drastically reducing the computation costs for low-quality candidates. We note that a similar score estimation scheme has been used in previous works <ref type="bibr" target="#b24">(Li et al., 2022;</ref><ref type="bibr" target="#b30">Maclaurin &amp; Adams, 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">ITERATIVE PROPOSAL DISTRIBUTIONS</head><p>Despite our attempt to directly sample high-quality initial instruction candidates, it could be the case that the method described in Subsection 3.1 fails to produce a good proposal set U, either because it lacks of diversity or does not contain any candidates with a suitably high score. In case of such challenges, we explore an iterative process for resampling U.</p><p>Generate a variation of the following instruction while keeping the semantic meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input: [INSTRUCTION]</head><p>Output: &lt;COMPLETE&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt for Resampling</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4: Resampling</head><p>Iterative Monte Carlo Search Instead of only sampling from the initial proposal, we consider exploring the search space locally around the current best candidates. This allows us to generate new instructions that are more likely to be successful. We call this variant iterative APE. At each stage, we evaluate a set of instructions and filter out candidates with low scores. Then, an LLM is asked to generate new instructions similar to those with high scores. We provide the prompt used for resampling in Figure <ref type="figure">4</ref>.</p><p>Figure <ref type="figure">8</ref> (Right) shows that although this approach improves the overall quality of the proposal set U, the highest scoring instruction tends to remain the same with more stages. We conclude iterative generation provides marginal improvement over the relative simplicity and effectiveness of the generative process described in Subsection 3.1. Therefore, we use APE without iterative search in our experiments unless otherwise stated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS</head><p>This section examines how APE can guide LLMs to desired behaviors. We investigate from three perspectives: zero-shot performance, few-shot in-context learning performance, and truthfulness. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">INSTRUCTION INDUCTION</head><p>We assess the effectiveness of zero-shot and few-shot in-context learning on 24 instruction induction tasks proposed in <ref type="bibr" target="#b17">Honovich et al. (2022)</ref>. The tasks span many facets of language understanding, from simple phrase structure to similarity and causality identification. We refer the reader to Appendix A of <ref type="bibr" target="#b17">Honovich et al. (2022)</ref> for detailed descriptions of each task. For each task, we sample five input-output pairs from the training data and select the best instruction using algorithm 1. Then, we evaluate the quality of the instruction by executing the instruction on InstructGPT<ref type="foot" target="#foot_0">2</ref> . We repeat our experiments five times with different random seeds to report the mean and standard deviation of the best performing result in each seed and report the best overall performance in Appendix (Figure <ref type="figure" target="#fig_0">13</ref> and 14). The exact templates for our experiments can be found in Appendix (Table <ref type="table" target="#tab_5">2</ref>).</p><p>Zero-shot Learning We compare our method against two baselines: human prompt engineers (Human)<ref type="foot" target="#foot_1">3</ref> and the model-generated instruction algorithm proposed by <ref type="bibr" target="#b17">Honovich et al. (2022)</ref>. This algorithm can be thought of as a greedy version of APE, without a search and selection process; thus, we refer to it as "Greedy". Figure <ref type="figure">5</ref> shows the zero-shot performance of InstructGPT using human instructions and model generated instructions. Our algorithm outperforms "Greedy" on every task and achieves equal or better than human performance on 19 of 24 tasks. Moreover, the Interquartile Mean (IQM) <ref type="bibr" target="#b0">(Agarwal et al., 2021)</ref> across all 24 tasks in Figure <ref type="figure" target="#fig_0">1</ref> suggests that APE with InstructGPT outperforms human-engineered prompts, obtaining an IQM of 0.765 vs humans' 0.749. We summarize the instruction selected by APE for each task in Appendix (Table <ref type="table" target="#tab_14">11</ref>).</p><p>We observe APE can propose varying quality candidates depending on the subset of demonstration chosen for tasks such as Passivization and Start With. As shown in Figure <ref type="figure">5</ref>, our method achieves worse average performance than humans in Passivization and Sentence Similarity. However, selecting the best instruction still outperforms the human in Figure <ref type="figure" target="#fig_0">13</ref>. These results highlight the importance of the initial proposal stage. We found it is crucial to generate instruction candidates based on different demonstrations. Additionally, tasks such as Membership and Second Letter are intrinsically challenging for the model, and APE consistently performs worse than humans.</p><p>Zero-shot Qualitative Analysis To better understand the weaknesses of APE, we examined instructions in three tasks where APE underperforms compared to humans in the zero-shot setting: Passivization, Membership, and Second Letter. As shown in Tables <ref type="table" target="#tab_6">3,</ref><ref type="table" target="#tab_7">4</ref>, we find large variance in the quality of APE instructions due to the difference in demonstration. The best instructions selected by APE for each task are semantically correct and recover accuracy relative to humans. In contrast, the worst instructions are all semantically incorrect and perform poorly. Notably, we observe no semantic difference in the demonstrations used to generate the best and worst instruction under inspection.  <ref type="figure" target="#fig_4">14</ref>.</p><p>Few-shot In-context Learning We also evaluate APE-generated instructions in the few-shot incontext learning scenario, where we insert the instruction before the in-context demonstrations. Those instructions are selected based on zero-shot execution accuracy, and we denote this setting as "Instruction + In-context" in Figure <ref type="figure">6</ref>. As shown in Figure <ref type="figure">6</ref>, adding an instruction achieves a comparable or better test performance than the standard in-context learning performance on 21 of 24 tasks. Counter-intuitively, adding in-context examples for Rhymes, Large Animal, and Second Letters hurts model performance. We conjecture that it may be because the selected instructions overfit the zero-shot learning scenario and thus do not perform well on the few-shot case. Therefore, we experiment using few-shot execution accuracy as the selection metric. Figure <ref type="figure" target="#fig_0">15</ref> shows that the few-shot metric achieves comparable or slightly better than the zero-shot metric except for Rhymes.</p><p>To have an intuitive understanding of what is happening, we provide a qualitative analysis below.</p><p>Few-shot Qualitative Analysis We find an adversarial case on Rhymes when combining the instruction and in-context prompts. Table <ref type="table" target="#tab_8">5</ref> shows that 4 of 5 filtered instructions ask to echo the input word. These proposals effectively hack the evaluation with near-perfect test accuracy, as every word rhymes with itself. However, adding in-context examples for these instructions creates a misalignment between instruction (induces trivial rhymes) and context (induces non-trivial rhymes), resulting in a significant drop in performance. If we instead score the instructions based on the few-shot metric, this performance drop can be alleviated since the model can choose a more aligned instruction. Another interesting case happens in the Second Letters task (Table <ref type="table" target="#tab_9">6</ref>), where the model's responses to two semantically "correct" instructions experience a drop in accuracy when paired with the in-context demonstration. In this case, though there is no semantic difference between the instruction and demonstration, adding in-context examples makes it more difficult for the LLM to identify the correct program to execute. However, this effect is mild for a task such as Large Animal (Table <ref type="table" target="#tab_10">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">TRUTHFULQA</head><p>We apply our method on TruthfulQA <ref type="bibr" target="#b27">(Lin et al., 2022)</ref> to see how APE-generated instructions can steer an LLM to generate answers with different styles, and study the trade-off between truthfulness and informativeness. Borrowing the metrics from the original paper, we use APE to the learn instructions that maximize three metrics: truthfulness (% True), informativeness (% Info), and a combination of both (%True + %Info). <ref type="bibr" target="#b27">Lin et al. (2022)</ref> used human evaluation to assess the model performance, but they found their automated metrics align with human prediction over 90% of the time. In our experiments, we rely on their fine-tuned GPT-judge and GPT-info to evaluate the scores.</p><p>Prompt Engineering in TruthfulQA We want to stress that the TruthfulQA dataset is intended to test pretrained models in zero-shot settings. Our results are not in any way compatible with the original benchmarks. Because we have optimized the instructions using a small portion of the question and answer pairs as training demonstrations, our results are not "true few-shot learning" <ref type="bibr" target="#b33">(Perez et al., 2021)</ref>. We randomly sampled 100 out of 817 questions for the actual experiments to form training demonstrations D train . To sample the proposal set U, we ask a "reverse" model to generate instructions based on six randomly chosen demonstration pairs, similar to our previous experiments. Unlike in Instruction Induction, in TruthfulQA, we aim to find a single best instruction prompt that works well across all 38 categories of questions spanning health, law, politics, and fiction. It is worth noting all our generated instructions are very generic, e.g., "You will be asked a series of questions. For each question, you must either answer the question or decline to answer, in which case you must state that you have no comment", and do not contain any examples from the dataset.</p><p>Truthfulness vs Informativeness Trade-off We found that APE outperforms the humanengineered prompt with only 200 candidates proposed by InstructGPT (175B), as seen in Figure <ref type="figure" target="#fig_1">7</ref>. We compared our generated prompt with the "help" prompt from <ref type="bibr" target="#b27">Lin et al. (2022)</ref>. The training and test performance are shown in Figure <ref type="figure" target="#fig_1">7</ref>(a)-(b). We found that choosing the top 10 of 200 candidates on the training set generalizes well to the test set. We report the average performance across the top 10 instructions for the three metrics. This result by itself is not surprising as the human baseline is not carefully chosen, as pointed out by <ref type="bibr" target="#b1">Askell et al. (2021)</ref>. However, we found that the instructions discovered by APE can achieve very high truthfulness with answers such as "No comment," but these answers provide little information. We used our top candidates to further investigate the trade-off between truthfulness and informativeness. We visualize the top 10 proposed samples across the three metrics on the truthfulness-informative plots shown in Figure <ref type="figure" target="#fig_1">7</ref>(c) and Figure <ref type="figure" target="#fig_1">7(d)</ref>. While APE achieves over 40% accuracy in providing both true and informative answers (v.s. 30% by the "help" prompt from humans), the instructions discovered tend to target the two ends of this %true-%info Pareto frontier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">QUANTITATIVE ANALYSIS</head><p>In this section, we conduct quantitative analyses to better understand the three main components of our method: proposal distribution, score functions, and iterative search. Moreover, we conduct a cost analysis in the Appendix D to understand the most cost-efficient way to find the best prompt. We observe the larger and more powerful language models are more cost-effective for generating the best prompt despite a higher per-token cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">LLMS FOR PROPOSAL DISTRIBUTION</head><p>How does the proposal quality change as we increase the model size? To understand how the model size affects the quality of the initial proposal distribution, we examine eight different models<ref type="foot" target="#foot_2">4</ref> available via the OpenAI API. To assess the quality of the proposal distribution, we generate 250 instructions per model and compute the execution accuracy on 50 test data points. We visualize the survival function (percentage of instructions with test accuracy greater than a certain threshold) and the histogram of test accuracy for a simple task (i.e., Pluralization) in Figure <ref type="figure">8</ref> (a) and include a similar plot for a more challenging task (Start With) in the Appendix (Figure <ref type="figure">30</ref>). As shown in both figures (and unsurprisingly), larger models tend to produce better proposal distributions than smaller ones, as do the models that were fine-tuned to follow human instructions. On the simple task, all instructions generated by the best model, InstructGPT (175B), have reasonable test accuracy. In contrast, half of the instructions are off-topic and perform poorly on the more challenging task.  <ref type="bibr" target="#b50">(Zeng et al., 2022)</ref>). We evaluate their performance on six tasks selected from instruction induction on both zero-shot and few-shot settings<ref type="foot" target="#foot_3">5</ref> . Figures <ref type="figure" target="#fig_1">17</ref> and<ref type="figure" target="#fig_2">19</ref> show that InstructGPT achieves the best performance except for passivization, where it underperforms compared to the two other forwardgeneration models. Interestingly, Codex and OPT nearly match InstructGPT performance despite their instruction proposal models being different from the InstructGPT scoring model. However, we observe some of the instructions generated by OPT contain in-context examples (Table <ref type="table" target="#tab_15">12</ref>), making them closer to few-shot rather than a zero-shot. In contrast, GLM achieves the poorest zero-shot performance as its infilling capabilities are trained to generate very short text, as shown in Table <ref type="table" target="#tab_17">14</ref>.</p><p>How important is the meta prompt? As shown in Table <ref type="table" target="#tab_19">16</ref>, the insert variant of InstructGPT underperforms compared to the forward variant, despite it being more intuitive to perform reverse generation from demonstrations. We hypothesize that the meta prompt for instruction generation substantially influences the distribution of proposed instructions. To this end, we experiment with our TruthfulQA template instead of the reverse generation template <ref type="bibr">(Figures 25,</ref><ref type="bibr">26,</ref><ref type="bibr">27,</ref><ref type="bibr">28)</ref>. We find the meta prompt template makes a difference, improving the performance on some tasks while impairing others. Notably, the accuracy of membership can surpass the instructions from forward generation, whereas good instructions could not be proposed with the original template. We leave to future work the exploration of meta prompt engineering for better proposal distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">LLMS FOR SELECTION</head><p>Does proposal quality matter under selection? If we sample more instructions from the LLMs, then it becomes more likely for us to find better instructions. To verify this hypothesis, we increase the sample size from 4 to 128 and evaluate the test accuracy change. Figure <ref type="figure" target="#fig_2">9</ref> (Left) shows a monotonically increasing trend with a diminishing return, as human-level performance is achieved with 64 instruction samples. Thus, we choose 50 as our default sample size. Under this configuration, we investigate how the proposal distribution affects the test accuracy of the best instruction selected by our algorithm. Figure <ref type="figure" target="#fig_0">1</ref>(c) shows that though the small models have a low chance of generating good instructions, they nonetheless generate some good ones if we sample enough candidates. Therefore, we can still find promising instructions with a small model by running our selection algorithm, explaining why our method performs significantly better than the greedy approach Honovich et al.</p><p>(2022) across all eight models.</p><p>Which scoring function is better? We compute the correlation between the test accuracy and two metrics on 24 instruction induction tasks to study how good our proposed metrics are. We generate 250 instructions per task using InstructGPT (175B) in "forward" mode and compute the metric score and test accuracy on 10 test data points. We visualize the Spearman correlation between the test accuracy and two metrics. Figure <ref type="figure" target="#fig_2">9</ref> (Middle) shows that the execution accuracy aligns better with the test performance across the tasks. Thus, we choose it as our default metric unless otherwise stated. How transferable are the generated instructions? We investigate whether APE can be used to steer the model not involved in the instruction generation and selection process. As shown in Figure <ref type="figure" target="#fig_5">21</ref>, there is a significant performance drop when we use the instructions from InstructGPT to steer the GPT-3 model, and vice versa. This performance drop can be mitigated by a human written instruction. It suggests that the alignment between the scoring model and execution model is crucial, and the instructions generated by InstructGPT work best for the InstructGPT itself but do not transfer well to a different model like GPT-3. In contrast, GPT-3-generated instructions can steer GPT-3 exceptionally well, outperforming the InstructGPT instructions and human instructions by a large margin. Though GPT-3 cannot follow human instructions well, we show that it can still generate prompts that are well-suited for itself despite being unintuitive, resulting in the desired behavior. We provide the generated prompts in Table <ref type="table" target="#tab_18">15</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">ITERATIVE MONTE CARLO SEARCH</head><p>Does Iterative Search improve the instruction quality? We visualize the survival function and histogram of test accuracy on the "Passivization" task in Figure <ref type="figure">8</ref> (Right) and include five more tasks in the Appendix. The survival plot shows that the curves increase as the round goes up, which suggests that iterative search does result in a higher-quality proposal set. However, we observe diminishing returns to further selection rounds as the quality seems to stabilize after three rounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Do we need Iterative Search?</head><p>We compare APE and iterative APE on six tasks 5 . As shown in Figure <ref type="figure" target="#fig_2">9</ref>, the iterative search marginally improves performance on tasks where APE underperforms humans but achieves similar performance on the other tasks. This is consistent with our hypothesis that iterative search would be most useful on tasks where generating a good initial U is challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>LLMs can be seen as general-purpose computers that execute programs specified by natural language prompts. We automate the prompt engineering process by formulating it as a black-box optimization problem, which we propose to solve using efficient search algorithms guided by LLMs. Our method achieves human-level performance on various tasks with minimum human inputs. As recent LLMs demonstrate an impressive ability to follow human instruction, we expect many future models, including those for formal program synthesis, to have a natural language interface. This work builds the foundation to control and steer generative AIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROMPT ENGINEERING IN THE WILD</head><p>Large models with natural language interfaces, including models for text generation and image synthesis, have seen an increasing amount of public usage in recent years. As finding the right prompt can be difficult for humans, a number of guides on prompt engineering as well as tools to aid in prompt discovery have been developed. Among others, see, for example:</p><p>? https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/</p><p>? https://techcrunch.com/2022/07/29/a-startup-is-charging-1-99-for-strings-of-text-to-feed-to-dall-e-2/</p><p>? https://news.ycombinator.com/item?id=32943224</p><p>? https://promptomania.com/stable-diffusion-prompt-builder/</p><p>? https://huggingface.co/spaces/Gustavosta/MagicPrompt-Stable-Diffusion</p><p>In this paper we apply APE to generate effective instructions for steering LLMs, but the general framework Algorithm 1 could be applied to steer other models with natural language interfaces so long as an appropriate proposal method and scoring function can be designed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B IMPLEMENTATION DETAILS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GLUE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentiment Analysis</head><p>Determine whether a movie review is positive or negative.</p><p>The film is small in scope, yet perfectly formed. ? positive</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence Similarity</head><p>Rate the semantic similarity of two input sentences on a scale of 0 -definitely not to 5 -perfectly.</p><p>Sentence 1: A man is smoking. Sentence 2: A man is skating. ? 0 -definitely not Word in Context Determine whether an input word has the same meaning in the two input sentences.</p><p>Sentence 1: Approach a task. Sentence 2: To approach the city. Word: approach ? not the same </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forward Generation</head><p>I gave a friend an instruction and five inputs. The friend read the instruction and wrote an output for every one of the inputs.\nHere are the input-output pairs:</p><formula xml:id="formula_3">Input: [ ]\nOutput: [ ]\n\nInput: [ ]\nOutput: [ ] ...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The instruction was&lt;COMPLETE&gt;</head><p>Reverse Generation 1 I instructed my friend to&lt;INSERT&gt;.The friend read the instruction and wrote an output for every one of the inputs.\nHere are the input-output pairs:</p><formula xml:id="formula_4">Input: [ ]\nOutput: [ ]\n\nInput: [ ]\nOutput: [ ] ...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reverse Generation 2</head><p>Professor Smith was given the following instructions:&lt;INSERT&gt;\nHere are the Professor's responses:</p><formula xml:id="formula_5">Q: [ ]\nA: [ ]\n\nQ: [ ]\nA: [ ] ...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resample Instruction</head><p>Generate a variation of the following instruction while keeping the semantic meaning.</p><p>Input: <ref type="bibr">[INSTRUCTION]</ref>\nOutput:&lt;COMPLETE&gt; </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C GENERATED INSTRUCTIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D COST ANALYSIS</head><p>More powerful models are cost-efficient for instruction proposal Despite higher per-token costs, we find larger, human-aligned models (models trained to follow human instructions <ref type="bibr" target="#b32">(Ouyang et al., 2022)</ref>) dominate the accuracy-cost frontier of APE (Figure <ref type="figure" target="#fig_0">10</ref>). Compared to smaller models not fined-tuned with human instructions, they tend to generate more concise instructions (Figure <ref type="figure" target="#fig_0">11</ref>), significantly reducing the cost of APE scoring. Therefore, we recommend using the larger and human-aligned instruction generation models whenever possible.</p><p>APE instructions are context condensers Although zero-shot instructions require more extensive sampling and scoring offline than in-context learning, they are token-efficient when amortized over a large number of inferences. In this light, we view the cost of APE as a one-time overhead to distill a concise prompt from demonstrations. As shown in Figure <ref type="figure" target="#fig_3">12</ref>, APE instructions reduce the number of prompt tokens by up to an order of magnitude compared to in-context learning. Future work exploring optimizing the prompt length can further reduce costs associated with steering LLMs.</p><p>Figure <ref type="figure" target="#fig_0">10</ref>: The accuracy-cost frontier of APE across eight OpenAI models. The colour assigned to each task is determined by text-davinci-002 accuracy quartiles. We measure the number of tokens used by various model sizes for instruction generation. We also measure the number of tokens used to score all generations with ten validation input-output pairs on InstructGPT (i.e., text-davinci-002). We calculated the total cost per task by multiplying and adding the number of tokens consumed by each model type with OpenAI's API rate as of September 1, 2022 (USD/1000 tokens: ada -0.0004, babbage -0.0005, curie -0.0020, davinci -0.0200). Counter-intuitively, smaller models are more expensive. This is because the most significant proportion of the cost is scoring with InstructGPT, which scales with the length of instructions generated. Smaller models not trained with human instructions tend to generate longer instructions, reaching the maximum limit of predefined 50 tokens. Larger models trained with human instructions are most cost-efficient as instruction generators as they significantly reduce scoring costs with shorter instructions.</p><p>Figure <ref type="figure" target="#fig_0">11</ref>: The accuracy-length frontier of prompts generated across eight OpenAI models and 24 NLP tasks. Models not trained with human instructions tend to reach the predefined maximum number of tokens we allow to be generated, while larger and more aligned LLMs output more concise instructions. The more capable LLMs dominate the frontier of instruction length and accuracy, which we view as a the ability to condense context into an instruction efficiently. We observe that exemplary instructions are up to five times more efficient than incontext learning to achieve comparable performance. Alternatively, we can boost in-context learning capabilities with a small number of tokens as overhead from prepending an instruction.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E ADDITIONAL VISUALIZATIONS</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) Natural language program synthesis finds an appropriate instruction (the program) that generates the observed demonstrations when executed by the model. We frame this as a black-box optimization problem guided by an inference procedure. (b) We use LLMs as inference models to fill in the blank; our algorithm involves a search over candidates proposed by the inference models. (c) As measured by the interquartile mean across the 24 NLP tasks introduced by Honovich et al. (2022), APE is able to surpass human performance when using the InstructGPT model<ref type="bibr" target="#b32">(Ouyang et al., 2022)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Comparison of APE and "help" (human) prompt on the TruthfulQA task. (a) Percentage of answers that were either true (% True), informative (% Info), or both (% True + % Info) on the 100 training examples. (b) Same data on the 717 test examples. (c) %True-%Info frontier computed on training data with top 10 instructions from each metric. (d) %True-%Info frontier on the test data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: (Left) Test execution of the best instruction as we increase the number of instruction candidates. We report the mean and standard deviation across 6 different tasks. (Middle) Spearman Correlation between the test accuracy and two metrics on 24 tasks. (Right) Test execution accuracy of the best instruction selected using APE and iterative APE (APE (IT)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Instructions found by APE from InstructGPT are token efficient compared to in-context examples.We observe that exemplary instructions are up to five times more efficient than incontext learning to achieve comparable performance. Alternatively, we can boost in-context learning capabilities with a small number of tokens as overhead from prepending an instruction.</figDesc><graphic url="image-3.png" coords="27,118.34,473.11,374.75,163.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Few-shot in-context test accuracy of best performing instructions on 24 Instruction Induction tasks. The APE -generated instruction improves the few-shot in-context learning performance on 23 out of 24 tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: Zero-shot test accuracy on 6 Instruction Induction tasks. We investigate the transfer ability of the APE instruction to a different model not involved during instruction generation and selection.</figDesc><graphic url="image-4.png" coords="31,118.36,120.27,374.29,203.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 22 :</head><label>22</label><figDesc>Figure 22: Zero-shot test accuracy of best performing instructions on 6 Instruction Induction tasks. We investigate the transfer ability of the APE instruction to a different model not involved during instruction generation and selection.</figDesc><graphic url="image-5.png" coords="31,118.37,441.72,374.65,205.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 23 :</head><label>23</label><figDesc>Figure 23: Few-shot test accuracy on 6 Instruction Induction tasks. We investigate the transfer ability of the APE instruction to a different model not involved during instruction generation and selection.</figDesc><graphic url="image-6.png" coords="32,118.36,120.98,374.71,203.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 24 :Figure 29 :Figure 30 :</head><label>242930</label><figDesc>Figure 24: Few-shot test accuracy of best performing instructions on 6 Instruction Induction tasks. We investigate the transfer ability of the APE instruction to a different model not involved during instruction generation and selection.</figDesc><graphic url="image-7.png" coords="32,118.36,443.81,374.77,202.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="26,118.34,256.56,374.66,203.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>&lt;COMPLETE&gt; Forward Generation Template I instructed my friend to &lt;INSERT&gt;. The friend read the instruction and wrote an output for every one of the inputs. Here are the input-output pairs: Input: [ ] Output: [ ] Input: [ ] Output: [</head><label></label><figDesc>according to a chosen score function, ultimately choosing the instruction with the highest score. We discuss options for proposal and scoring next. ] ...</figDesc><table><row><cell cols="2">Algorithm 1 Automatic Prompt Engineer (APE)</cell></row><row><cell cols="3">Require: Dtrain ? {(Q, A)}n: training examples, f : ? ? D ? R: score function</cell></row><row><cell cols="3">1: Use LLM to sample instruction proposals U ? {?1, ..., ?m}. (See Section 3.1)</cell></row><row><cell cols="2">2: while not converged do</cell></row><row><cell>3:</cell><cell>Choose a random training subset Dtrain ? Dtrain.</cell></row><row><cell>4:</cell><cell>for all ? in U do</cell></row><row><cell>5:</cell><cell>Evaluate score on the subset s ? f (?, Dtrain) (See Section 3.2 )</cell></row><row><cell>6:</cell><cell>end for</cell></row><row><cell>7:</cell><cell cols="2">Filter the top k% of instructions with high scores U k ? U using { s1, ..., sm}</cell></row><row><cell>8:</cell><cell cols="2">Update instructions U ? U k or use LLM to resample U ? resample(U k ) (See Section 3.3)</cell></row><row><cell cols="2">9: end while</cell></row><row><cell cols="2">Return instruction with the highest score ? ? arg max??U k f (?, Dtrain)</cell></row><row><cell cols="2">3.1 INITIAL PROPOSAL DISTRIBUTIONS</cell></row><row><cell cols="3">Due to the infinitely large search space, finding the right instruction can be extremely difficult, which</cell></row><row><cell cols="3">has rendered natural language program synthesis historically intractable. Recent progress in NLP</cell></row><row><cell cols="3">has shown language models are very good at generating diverse natural language text. Therefore, we</cell></row><row><cell cols="3">consider leveraging a pretrained LLM to propose a good set U of candidate solutions that will guide</cell></row><row><cell cols="3">our search procedure. While random samples from LLMs are unlikely to produce the desired (Q, A)</cell></row><row><cell cols="3">pairs, we can instead ask the LLM to approximately infer the most likely instructions with a high score,</cell></row><row><cell cols="3">given the input/output demonstrations; i.e., to approximately sample from P (? | D train , f (?) is high).</cell></row><row><cell cols="2">Forward Mode Generation We consider two approaches to gen-</cell></row><row><cell cols="2">erate high-quality candidates from P (? | D train , f (?) is high). First, we adopt an approach based on "forward" mode generation by trans-</cell><cell>I gave a friend an instruction and five inputs. The friend read the instruction</cell></row><row><cell cols="2">lating this distribution P (? | D train , f (?) is high) into words. For example, in our instruction induction experiments (Subsection 4.1),</cell><cell>and wrote an output for every one of the inputs. Here are the input-output pairs:</cell></row><row><cell cols="2">we follow Honovich et al. (2022) and prompt the LLM using Figure</cell><cell>Input: [ ] Output: [ ]</cell></row><row><cell></cell><cell></cell><cell>Input: [ ] Output: [ ]</cell></row><row><cell></cell><cell></cell><cell>...</cell></row><row><cell></cell><cell></cell><cell>The instruction was Reverse Generation Template</cell></row><row><cell></cell><cell></cell><cell>Template for TruthfulQA</cell></row><row><cell></cell><cell></cell><cell>Professor Smith was given the</cell></row><row><cell></cell><cell></cell><cell>following instructions: &lt;INSERT&gt;</cell></row><row><cell></cell><cell></cell><cell>Here are the Professor's responses:</cell></row><row><cell></cell><cell></cell><cell>Input: [ ] Output: [ ]</cell></row><row><cell></cell><cell></cell><cell>Input: [ ] Output: [ ]</cell></row><row><cell></cell><cell></cell><cell>...</cell></row><row><cell></cell><cell></cell><cell>Figure 3: Prompts for LLMs</cell></row></table><note><p><p><p>Thus, we propose to treat this human-intractable question as a black-box optimization process guided by LLMs. Our algorithm, APE, uses LLMs in each of two key components, proposal and scoring. As shown in Figure</p>2</p>and summarized in Algorithm 1, APE first proposes a few candidate prompts, and then filters/refines the candidate set</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Zero-shot test accuracy on 24 Instruction Induction tasks. APE achieves human-level performance on 19 out of 24 tasks. See best performing instruction performance in Figure13.</figDesc><table><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Execution Accuracy</cell><cell>0 0 1</cell><cell>Antonyms Membership</cell><cell cols="2">Cause Selection Common Concept Negation Number to Word</cell><cell>Diff Passivization</cell><cell>First Letter Pluralization</cell><cell>Formality Rhymes</cell><cell>Large Animal Second Letter Sentence Similarity List Letters</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>Sentiment</cell><cell>Starting With</cell><cell>Sum</cell><cell>Synonyms</cell><cell cols="3">Translation en-de Translation en-es Translation en-fr</cell><cell>Word in Context</cell></row><row><cell cols="2">Figure 5:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Figure 8: (Left) Quality of the proposal distribution of models with different size as assessed by test execution accuracy. (Right) Iterative Monte Carlo search improves the quality of the instruction candidates at each round.Can we use other LLMs for instruction proposal? We investigate other LLMs for instruction generation, including those with forward generation ability (OPT-175B<ref type="bibr" target="#b51">(Zhang et al., 2022)</ref>, OpenAI Codex<ref type="bibr" target="#b6">(Chen et al., 2021)</ref>) and one with reverse generation ability (INT4 quantized GLM-130B</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">GPT-3 (350M)</cell><cell cols="2">GPT-3 (6.7B)</cell><cell></cell><cell cols="3">InstructGPT (350M)</cell><cell cols="3">InstructGPT (6.7B)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">GPT-3 (1.3B)</cell><cell cols="2">GPT-3 (175B)</cell><cell></cell><cell cols="3">InstructGPT (1.3B)</cell><cell cols="3">InstructGPT (175B)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Start</cell><cell>1</cell><cell>2</cell><cell></cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>% instructions with accuracy &gt;</cell><cell>0.0 0.2 0.4 0.6 0.8</cell><cell>0.0</cell><cell>0.2</cell><cell cols="2">0.4 Test accuracy ( ) 0.6</cell><cell>0.8</cell><cell>1.0</cell><cell>0.0</cell><cell>0.2</cell><cell cols="2">0.4 Test accuracy ( ) 0.6</cell><cell>0.8</cell><cell>1.0</cell><cell>10 0 10 1 10 2</cell><cell>Count</cell><cell>% instructions with accuracy &gt;</cell><cell>0.0 0.2 0.4 0.6 0.8</cell><cell>0.0</cell><cell>0.2 Train accuracy ( ) 0.4 0.6</cell><cell>0.8</cell><cell>1.0</cell><cell>0.0</cell><cell cols="3">0.2 Train accuracy ( ) 0.4 0.6</cell><cell>0.8</cell><cell>1.0</cell><cell>10 0 10 2 10 1</cell><cell>Count</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>For convenience, Table1from<ref type="bibr" target="#b17">Honovich et al. (2022)</ref> is duplicated here. This describes the 24 NLP instruction induction tasks.</figDesc><table><row><cell cols="2">Category Task</cell><cell>Instruction</cell><cell>Demonstration</cell></row><row><cell>Spelling</cell><cell>First Letter</cell><cell>Extract the first letter of the input word.</cell><cell>cat ? c</cell></row><row><cell></cell><cell>Second Letter</cell><cell cols="2">Extract the second letter of the input word. cat ? a</cell></row><row><cell></cell><cell>List Letters</cell><cell>Break the input word into letters, sepa-</cell><cell>cat ? c a t</cell></row><row><cell></cell><cell></cell><cell>rated by spaces.</cell><cell></cell></row><row><cell></cell><cell>Starting With</cell><cell>Extract the words starting with a given</cell><cell>The man whose car I hit last week</cell></row><row><cell></cell><cell></cell><cell>letter from the input sentence.</cell><cell>sued me. [m] ? man, me</cell></row><row><cell>Morpho-</cell><cell>Pluralization</cell><cell cols="2">Convert the input word to its plural form. cat ? cats</cell></row><row><cell>syntax</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Passivization</cell><cell>Write the input sentence in passive form.</cell><cell>The artist introduced the scientist.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>? The scientist was introduced</cell></row><row><cell></cell><cell></cell><cell></cell><cell>by the artist.</cell></row><row><cell>Syntax</cell><cell>Negation</cell><cell>Negate the input sentence.</cell><cell>Time is finite ? Time is not fi-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>nite.</cell></row><row><cell>Lexical</cell><cell>Antonyms</cell><cell>Write a word that means the opposite of</cell><cell>won ? lost</cell></row><row><cell>Semantics</cell><cell></cell><cell>the input word.</cell><cell></cell></row><row><cell></cell><cell>Synonyms</cell><cell>Write a word with a similar meaning to</cell><cell>alleged ? supposed</cell></row><row><cell></cell><cell></cell><cell>the input word.</cell><cell></cell></row><row><cell></cell><cell>Membership</cell><cell>Write all the animals that appear in the</cell><cell>cat, helicopter, cook, whale, frog,</cell></row><row><cell></cell><cell></cell><cell>given list.</cell><cell>lion ? frog, cat, lion, whale</cell></row><row><cell cols="2">Phonetics Rhymes</cell><cell>Write a word that rhymes with the input</cell><cell>sing ? ring</cell></row><row><cell></cell><cell></cell><cell>word.</cell><cell></cell></row><row><cell cols="2">Knowledge Larger Animal</cell><cell cols="2">Write the larger of the two given animals. koala, snail ? koala</cell></row><row><cell cols="3">Semantics Cause Selection Find which of the two given cause and</cell><cell>Sentence 1: The soda went flat.</cell></row><row><cell></cell><cell></cell><cell>effect sentences is the cause.</cell><cell>Sentence 2: The bottle was left</cell></row><row><cell></cell><cell></cell><cell></cell><cell>open. ? The bottle was left open.</cell></row><row><cell></cell><cell>Common</cell><cell>Find a common characteristic for the given</cell><cell>guitars, pendulums, neutrinos ?</cell></row><row><cell></cell><cell>Concept</cell><cell>objects.</cell><cell>involve oscillations.</cell></row><row><cell>Style</cell><cell>Formality</cell><cell cols="2">Rephrase the sentence in formal language. Please call once you get there ?</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Please call upon your arrival.</cell></row><row><cell cols="2">Numerical Sum</cell><cell>Sum the two given numbers.</cell><cell>22 10 ? 32</cell></row><row><cell></cell><cell>Difference</cell><cell cols="2">Subtract the second number from the first. 32 22 ? 10</cell></row><row><cell></cell><cell cols="2">Number to Word Write the number in English words.</cell><cell>26 ? twenty-six</cell></row><row><cell>Multi-</cell><cell>Translation</cell><cell>Translate the word into German / Spanish</cell><cell>game ? juego</cell></row><row><cell>lingual</cell><cell></cell><cell>/ French.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Raw templates used for model prompting in our experiments</figDesc><table><row><cell>Usage</cell><cell>Template</cell><cell></cell></row><row><cell></cell><cell cols="2">Instruction: [INSTRUCTION]</cell></row><row><cell>Zero-shot Evaluation</cell><cell>Input: [</cell><cell>]\nOutput:&lt;COMPLETE&gt;</cell></row><row><cell></cell><cell cols="2">Instruction: [INSTRUCTION]</cell></row><row><cell>Few-shot Evaluation</cell><cell cols="2">Input: [ ]\nOutput: [ ]\n\nInput: [ ]\nOutput: [ ] ...</cell></row><row><cell></cell><cell>Input: [</cell><cell>]\nOutput:&lt;COMPLETE&gt;</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Best APE selected instructions for underperforming tasks in zero-shot setting</figDesc><table><row><cell>Task</cell><cell>Best instruction</cell><cell>Zero-shot test accuracy</cell></row><row><cell>Passivization</cell><cell>to use the passive voice.</cell><cell>1</cell></row><row><cell>Membership</cell><cell>to choose the animals from the list</cell><cell>0.5</cell></row><row><cell cols="2">Second Letter most likely "Find the second letter in each word."</cell><cell>0.84</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Worst APE selected instructions for underperforming tasks in zero-shot setting</figDesc><table><row><cell>Task</cell><cell>Worst instruction</cell><cell>Zero-shot test accuracy</cell></row><row><cell>Passivization</cell><cell>to reverse the order of the subject and object.</cell><cell>0.17</cell></row><row><cell>Membership</cell><cell>probably to sort the inputs alphabetically.</cell><cell>0</cell></row><row><cell>Second Letter</cell><cell>write the middle letter of the word.</cell><cell>0.32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>APE selected Rhyme instructions with zero-shot and few-shot test performance.</figDesc><table><row><cell>Instruction</cell><cell cols="2">Zero-shot Accuracy Few-shot Accuracy</cell></row><row><cell>probably "Write a word that rhymes with each of the following words."</cell><cell>0.55</cell><cell>0.61</cell></row><row><cell>write a function that takes in a string and outputs the string with the first letter capitalized.</cell><cell>1</cell><cell>0.03</cell></row><row><cell>probably "Write a function that takes a string as input and outputs the string in all caps."</cell><cell>0.99</cell><cell>0.37</cell></row><row><cell>"Write a function that takes in a string and prints out the string with the first letter capitalized."</cell><cell>1</cell><cell>0.39</cell></row><row><cell>write a function that takes a word as input and returns the word with the first letter capitalized.</cell><cell>1</cell><cell>0.07</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>APE selected Second Letters instructions with zero-shot and few-shot test performance.</figDesc><table><row><cell>Instruction</cell><cell cols="2">Zero-shot Accuracy Few-shot Accuracy</cell></row><row><cell>most likely "Find the second letter in each word."</cell><cell>0.84</cell><cell>0.69</cell></row><row><cell>to write the letter that appears second in the word.</cell><cell>0.72</cell><cell>0.64</cell></row><row><cell>to find the first vowel in each word.</cell><cell>0.60</cell><cell>0.62</cell></row><row><cell>to "write the vowel that comes before the first dou-ble letter in the word."</cell><cell>0.50</cell><cell>0.59</cell></row><row><cell>write the middle letter of the word.</cell><cell>0.32</cell><cell>0.22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>APE selected Large Animal instructions with zero-shot and few-shot test performance.</figDesc><table><row><cell>Instruction</cell><cell cols="2">Zero-shot Accuracy Few-shot Accuracy</cell></row><row><cell>"Identify which animal is larger."</cell><cell>0.97</cell><cell>0.97</cell></row><row><cell>given two animals, return the name of the animal that is more dangerous.</cell><cell>0.88</cell><cell>0.89</cell></row><row><cell>to choose the animal that is larger.</cell><cell>0.96</cell><cell>0.95</cell></row><row><cell>"write the name of the animal that is bigger."</cell><cell>0.97</cell><cell>0.94</cell></row><row><cell>"Choose the animal that is bigger."</cell><cell>0.94</cell><cell>0.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Top 10 APE selected truthfulQA instrutions with test true (% True), informative (% Info), or both (% True + % Info) computed on the 717 test examples. The instructions are selected based on train true (% True).</figDesc><table><row><cell>Instruction</cell><cell cols="3">% True % Info % True + % Info</cell></row><row><cell>to answer questions from reporters truthfully, but to refuse to answer any questions that he considered to be irrelevant.</cell><cell>0.95</cell><cell>0.22</cell><cell>0.17</cell></row><row><cell>"You are not to answer any questions about the following topics: religion, politics, or personal opinion"</cell><cell>0.95</cell><cell>0.22</cell><cell>0.17</cell></row><row><cell>"You are not to answer any questions about politics, re-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ligion, or personal opinion. Any other questions are fair</cell><cell>0.90</cell><cell>0.30</cell><cell>0.20</cell></row><row><cell>game."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>You will be asked a series of questions. For each question,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>you must either answer the question or decline to answer.</cell><cell>0.91</cell><cell>0.29</cell><cell>0.21</cell></row><row><cell>If you decline to answer, you must give a reason why.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"You will be asked a series of questions. For each question,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>you must either answer the question or decline to answer,</cell><cell>0.92</cell><cell>0.28</cell><cell>0.20</cell></row><row><cell>in which case you must state that you have no comment."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>He was to answer questions about the United States truth-fully, without offering any additional information.</cell><cell>0.90</cell><cell>0.31</cell><cell>0.21</cell></row><row><cell>"You are to answer questions truthfully, to the best of your</cell><cell></cell><cell></cell><cell></cell></row><row><cell>knowledge. You are not to answer questions that you do not know the answer to. You are not to make any comment</cell><cell>0.89</cell><cell>0.32</cell><cell>0.22</cell></row><row><cell>if you do not wish to answer a question."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"You are not to answer any questions that you deem to be personal, or to offer any opinions."</cell><cell>0.92</cell><cell>0.27</cell><cell>0.19</cell></row><row><cell>"You will be asked a series of questions. Your job is to</cell><cell></cell><cell></cell><cell></cell></row><row><cell>answer each question truthfully. However, you may refuse</cell><cell>0.88</cell><cell>0.35</cell><cell>0.23</cell></row><row><cell>to answer any question you deem too personal."</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.90</cell><cell>0.30</cell><cell>0.20</cell></row></table><note><p>"You will be asked a series of questions. For each question, you will either provide a short answer or decline to answer. If you decline to answer, simply say 'I have no comment."</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Top 10 APE selected truthfulQA instrutions with test true (% True), informative (% Info), or both (% True + % Info) computed on the 717 test examples. The instructions are selected based on train informative (% Info). You will be given a series of questions. For each question, you will have a limited amount of time to formulate an answer. Your answer can be as long or as short as you like, but you must answer the question to the best of your ability. You will not be given a second chance to answer any of the questions, so please take your time and think about each one carefully."</figDesc><table><row><cell>Instruction</cell><cell cols="3">% True % Info % True + % Info</cell></row><row><cell>"Tell me something that you know that you think other people don't know."</cell><cell>0.62</cell><cell>0.81</cell><cell>0.43</cell></row><row><cell>"For each question, I want a one-sentence answer that is both correct and helpful."</cell><cell>0.61</cell><cell>0.78</cell><cell>0.40</cell></row><row><cell>"You will be given a list of questions. For each question,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>you will need to provide a short answer. Be as brief and</cell><cell>0.65</cell><cell>0.77</cell><cell>0.41</cell></row><row><cell>as specific as possible."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Answer these questions with as few words as possible.</cell><cell>0.63</cell><cell>0.75</cell><cell>0.38</cell></row><row><cell>"You are an artificial intelligence created to answer ques-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>tions about the world. You will be asked a series of ques-tions, and you must answer them to the best of your abil-</cell><cell>0.70</cell><cell>0.74</cell><cell>0.44</cell></row><row><cell>ity."</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">"0.68</cell><cell>0.73</cell><cell>0.41</cell></row><row><cell>"You are an expert on everything. Answer the following questions."</cell><cell>0.67</cell><cell>0.74</cell><cell>0.41</cell></row><row><cell>"Answer the following questions as if you were speaking to a five-year-old."</cell><cell>0.65</cell><cell>0.77</cell><cell>0.41</cell></row><row><cell>"You will be asked a series of questions. For each question,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>you will have to provide a response. Some of the questions</cell><cell></cell><cell></cell><cell></cell></row><row><cell>will be easy, while others will be more difficult. You may</cell><cell>0.67</cell><cell>0.75</cell><cell>0.42</cell></row><row><cell>use any resources you have at your disposal to answer the</cell><cell></cell><cell></cell><cell></cell></row><row><cell>questions."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"Answer the following questions as concisely as possible."</cell><cell>0.66</cell><cell>0.73</cell><cell>0.39</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>Top 10 APE selected truthfulQA instrutions with test true (% True), informative (% Info), or both (% True + % Info) computed on the 717 test examples. The instructions are selected based on train both (% True + % Info).</figDesc><table><row><cell>Instruction</cell><cell cols="3">% True % Info % True + % Info</cell></row><row><cell>"You will be given a list of questions. For each question,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>you will need to provide a short answer. Be as brief and</cell><cell>0.65</cell><cell>0.77</cell><cell>0.42</cell></row><row><cell>as specific as possible."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"You are an artificial intelligence created to answer ques-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>tions about the world. You will be asked a series of ques-tions, and you must answer them to the best of your abil-</cell><cell>0.70</cell><cell>0.74</cell><cell>0.44</cell></row><row><cell>ity."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"You will be given a series of questions. For each question,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>you will have a limited amount of time to formulate an</cell><cell></cell><cell></cell><cell></cell></row><row><cell>answer. Your answer can be as long or as short as you</cell><cell></cell><cell></cell><cell></cell></row><row><cell>like, but you must answer the question to the best of your</cell><cell>0.68</cell><cell>0.73</cell><cell>0.41</cell></row><row><cell>ability. You will not be given a second chance to answer</cell><cell></cell><cell></cell><cell></cell></row><row><cell>any of the questions, so please take your time and think</cell><cell></cell><cell></cell><cell></cell></row><row><cell>about each one carefully."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Answer the following questions as concisely and accu-rately as possible.</cell><cell>0.68</cell><cell>0.73</cell><cell>0.40</cell></row><row><cell>"You will be asked a series of questions. For each question,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>you will have to provide a response. Some of the questions</cell><cell></cell><cell></cell><cell></cell></row><row><cell>will be easy, while others will be more difficult. You may</cell><cell>0.67</cell><cell>0.75</cell><cell>0.42</cell></row><row><cell>use any resources you have at your disposal to answer the</cell><cell></cell><cell></cell><cell></cell></row><row><cell>questions."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"You are an artificial intelligence created by the United</cell><cell></cell><cell></cell><cell></cell></row><row><cell>States government. Your mission is to answer any question that is asked of you. You may not refuse to answer a</cell><cell>0.69</cell><cell>0.72</cell><cell>0.41</cell></row><row><cell>question, and you must answer all questions truthfully."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"You are an artificial intelligence, created to answer ques-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>tions. You will be asked a series of questions, and you</cell><cell></cell><cell></cell><cell></cell></row><row><cell>must answer them as accurately as possible. Remember,</cell><cell>0.72</cell><cell>0.70</cell><cell>0.43</cell></row><row><cell>your answers will be made public, so please do not include</cell><cell></cell><cell></cell><cell></cell></row><row><cell>any sensitive information."</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"You will be given a series of questions. For each ques-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>tion, you will have a limited amount of time to come up</cell><cell></cell><cell></cell><cell></cell></row><row><cell>with an answer. Once you have provided an answer, you</cell><cell></cell><cell></cell><cell></cell></row><row><cell>will not be able to change it. The questions will cover a wide range of topics, so please be prepared for anything."</cell><cell>0.68</cell><cell>0.69</cell><cell>0.37</cell></row><row><cell>The questions are as follows: Q: What is human life ex-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>pectancy in the United States? Q: Who was president of</cell><cell></cell><cell></cell><cell></cell></row><row><cell>the United States"</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"Please answer the following questions as concisely as possible."</cell><cell>0.67</cell><cell>0.74</cell><cell>0.41</cell></row><row><cell>"For each question, I want a one-sentence answer that is both correct and helpful."</cell><cell>0.61</cell><cell>0.79</cell><cell>0.40</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>The best instruction under zero-shot test accuracy generated by APE for each of the 24 tasks in the Instruction-Induction benchmark</figDesc><table><row><cell cols="2">Category Task</cell><cell>Best Instruction Generated by APE</cell><cell>Zero-Shot Test Accuracy</cell></row><row><cell>Spelling</cell><cell>First Letter</cell><cell>most likely "Write the first letter of the word."</cell><cell>1.00</cell></row><row><cell></cell><cell>Second Letter</cell><cell>most likely "Find the second letter in each word."</cell><cell>0.84</cell></row><row><cell></cell><cell>List Letters</cell><cell>to write the inputted word out letter by letter with a</cell><cell>0.99</cell></row><row><cell></cell><cell></cell><cell>space in between each letter.</cell><cell></cell></row><row><cell></cell><cell>Starting With</cell><cell>to find the first word that starts with the letter given</cell><cell>0.68</cell></row><row><cell></cell><cell></cell><cell>in brackets.</cell><cell></cell></row><row><cell>Morpho-</cell><cell>Pluralization</cell><cell>to pluralize the word.</cell><cell>1.00</cell></row><row><cell>syntax</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Passivization</cell><cell>to use the passive voice.</cell><cell>1.00</cell></row><row><cell>Syntax</cell><cell>Negation</cell><cell>" negate the statement" and the inputs were all</cell><cell>0.83</cell></row><row><cell></cell><cell></cell><cell>factually correct statements.</cell><cell></cell></row><row><cell>Lexical</cell><cell>Antonyms</cell><cell>to write the opposite of the word given.</cell><cell>0.83</cell></row><row><cell>Semantics</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Synonyms</cell><cell>to write a synonym for each input.</cell><cell>0.22</cell></row><row><cell></cell><cell>Membership</cell><cell>to choose the animals from the list.</cell><cell>0.50</cell></row><row><cell cols="2">Phonetics Rhymes</cell><cell>write a function that takes in a string and outputs the</cell><cell>1.00</cell></row><row><cell></cell><cell></cell><cell>string with the first letter capitalized.</cell><cell></cell></row><row><cell cols="2">Knowledge Larger Animal</cell><cell>"Identify which animal is larger."</cell><cell>0.97</cell></row><row><cell cols="3">Semantics Cause Selection "For each input, write the sentence that comes first</cell><cell>0.84</cell></row><row><cell></cell><cell></cell><cell>chronologically."</cell><cell></cell></row><row><cell></cell><cell>Common</cell><cell>"List things that" and the inputs were " poker, displays</cell><cell>0.27</cell></row><row><cell></cell><cell>Concept</cell><cell>of embarrassment, toilets" so the output should have</cell><cell></cell></row><row><cell></cell><cell></cell><cell>been "involve flushes."</cell><cell></cell></row><row><cell>Style</cell><cell>Formality</cell><cell>"Translate the following phrases into more formal,</cell><cell>0.65</cell></row><row><cell></cell><cell></cell><cell>polite language."</cell><cell></cell></row><row><cell cols="2">Numerical Sum</cell><cell>"Add the two inputs together and output the result."</cell><cell>1.00</cell></row><row><cell></cell><cell>Difference</cell><cell>"Subtract the second number from the first number."</cell><cell>1.00</cell></row><row><cell></cell><cell cols="2">Number to Word probably something like "Convert this number to</cell><cell>1.00</cell></row><row><cell></cell><cell></cell><cell>words."</cell><cell></cell></row><row><cell>Multi-</cell><cell>Translation</cell><cell>to use the German cognate for each word.</cell><cell>0.82</cell></row><row><cell>lingual</cell><cell>English-German</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Translation</cell><cell>write a Spanish word for each English word.</cell><cell>0.86</cell></row><row><cell></cell><cell>English-Spanish</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Translation</cell><cell>write the French word for each English word.</cell><cell>0.78</cell></row><row><cell></cell><cell>English-Spanish</cell><cell></cell><cell></cell></row><row><cell>GLUE</cell><cell>Sentiment</cell><cell>write "positive" if the input is a positive review and</cell><cell>0.94</cell></row><row><cell></cell><cell>Analysis</cell><cell>"negative" if the input is a negative review.</cell><cell></cell></row><row><cell></cell><cell>Sentence</cell><cell>"Determine whether two sentences are about the same</cell><cell>0.43</cell></row><row><cell></cell><cell>Similarity</cell><cell>thing" and the inputs were two sentences. The outputs</cell><cell></cell></row><row><cell></cell><cell></cell><cell>were "0 -definitely not," "1 -probably not," "2 -</cell><cell></cell></row><row><cell></cell><cell></cell><cell>possibly," "3 -probably," "4 -almost perfectly</cell><cell></cell></row><row><cell></cell><cell cols="2">Word in Context to compare the sentences and see if the word is used</cell><cell>0.62</cell></row><row><cell></cell><cell></cell><cell>in the same context. "Same" means that the word is</cell><cell></cell></row><row><cell></cell><cell></cell><cell>used in the same context and "not the same" means</cell><cell></cell></row><row><cell></cell><cell></cell><cell>that the word is used in a different context.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 12 :</head><label>12</label><figDesc>Test accuracies of best OPT-175B instructions with APE under six selected tasks</figDesc><table><row><cell>Task</cell><cell>Instruction</cell><cell cols="2">Prompt-only In-context</cell></row><row><cell></cell><cell>this:</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Take any one of the inputs and replace it with its</cell><cell></cell><cell></cell></row><row><cell>Antonyms</cell><cell>opposite. For example, take the input "unwrapped" and re-</cell><cell>0.82</cell><cell>0.81</cell></row><row><cell></cell><cell>place it with "wrapped" -so the output would be</cell><cell></cell><cell></cell></row><row><cell></cell><cell>"wrapped" instead of</cell><cell></cell><cell></cell></row><row><cell></cell><cell>input N: The event is caused by an object. Output</cell><cell></cell><cell></cell></row><row><cell></cell><cell>N: The object hit the Earth.</cell><cell></cell><cell></cell></row><row><cell>Cause Selection</cell><cell>Input: Sentence 1: The girl skipped school. Sen-</cell><cell>0.72</cell><cell>0.84</cell></row><row><cell></cell><cell>tence 2: The girl got detention. Output: The girl</cell><cell></cell><cell></cell></row><row><cell></cell><cell>skipped school</cell><cell></cell><cell></cell></row><row><cell></cell><cell>the student was advised by the judge, who was</cell><cell></cell><cell></cell></row><row><cell></cell><cell>advised by the secretary, who was thanked by the</cell><cell></cell><cell></cell></row><row><cell>Passivization</cell><cell>senator, who was recognized by the scientists.</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Input: The presidents mentioned the students. Out-</cell><cell></cell><cell></cell></row><row><cell></cell><cell>put: The students were mentioned by the presidents</cell><cell></cell><cell></cell></row><row><cell></cell><cell>"Find the input that is missing a letter". So the first</cell><cell></cell><cell></cell></row><row><cell>Second Letter</cell><cell>input is "ribbon". The friend wrote "i". The second input is "sequel". The friend wrote "e". The third</cell><cell>0.28</cell><cell>0.10</cell></row><row><cell></cell><cell>input is "weapon". The</cell><cell></cell><cell></cell></row><row><cell></cell><cell>for each input, write a letter that gives an indication</cell><cell></cell><cell></cell></row><row><cell></cell><cell>of the relative "goodness" of the output.</cell><cell></cell><cell></cell></row><row><cell>Sentiment</cell><cell>Input: Strange it is, but delightfully so. Output:</cell><cell>0.96</cell><cell>0.93</cell></row><row><cell></cell><cell>positive</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Input: Meyjes's movie</cell><cell></cell><cell></cell></row><row><cell></cell><cell>to take all the output pairs and make them into the</cell><cell></cell><cell></cell></row><row><cell></cell><cell>same language.</cell><cell></cell><cell></cell></row><row><cell>Translation en-fr</cell><cell>Input: account Output: compte</cell><cell>0.85</cell><cell>0.88</cell></row><row><cell></cell><cell>Input: rice Output: riz</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Input: hardware Output: arme ? feu</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 13 :</head><label>13</label><figDesc>Test accuracies of best OpenAI Codex instructions with APE under six selected tasks</figDesc><table><row><cell>Task</cell><cell>Instruction</cell><cell cols="2">Prompt-only In-context</cell></row><row><cell>Antonyms</cell><cell>write the opposite of the input.</cell><cell>0.83</cell><cell>0.84</cell></row><row><cell></cell><cell>read the two sentences and determine which one is</cell><cell></cell><cell></cell></row><row><cell>Cause Selection</cell><cell>the cause and which one is the effect. If the first</cell><cell>0.76</cell><cell>0.96</cell></row><row><cell></cell><cell>sentence is the cause, write the first sentence.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>write the output for each input by reversing the</cell><cell></cell><cell></cell></row><row><cell>Passivization</cell><cell>order of the words in the input and changing the</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>verb to the passive voice.</cell><cell></cell><cell></cell></row><row><cell>Second Letter</cell><cell>write the second letter of the input.</cell><cell>0.77</cell><cell>0.73</cell></row><row><cell></cell><cell>write a program that takes a movie review as in-</cell><cell></cell><cell></cell></row><row><cell>Sentiment</cell><cell>put and outputs a positive or negative sentiment. The program should be able to distinguish between</cell><cell>0.91</cell><cell>0.95</cell></row><row><cell></cell><cell>positive and negative reviews.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>write the French word for the English word. If</cell><cell></cell><cell></cell></row><row><cell>Translation en-fr</cell><cell>you don't know the French word, write the English</cell><cell>0.81</cell><cell>0.87</cell></row><row><cell></cell><cell>word.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 14 :</head><label>14</label><figDesc>Test accuracies of best GLM-130B instructions with APE under six selected tasks</figDesc><table><row><cell>Task</cell><cell>Instruction</cell><cell cols="2">Prompt-only In-context</cell></row><row><cell>Antonyms</cell><cell>generate the opposites.</cell><cell>0.82</cell><cell>0.83</cell></row><row><cell cols="2">Cause Selection read each sentence aloud.</cell><cell>0.48</cell><cell>0.80</cell></row><row><cell>Passivization</cell><cell>read the input sentence.</cell><cell>0.64</cell><cell>1.00</cell></row><row><cell>Second Letter</cell><cell>find the letter on each of its inputs.</cell><cell>0.22</cell><cell>0.39</cell></row><row><cell>Sentiment</cell><cell>give them either positive or negative.</cell><cell>0.88</cell><cell>0.92</cell></row><row><cell cols="2">Translation en-fr translate English words into French.</cell><cell>0.75</cell><cell>0.87</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 15 :</head><label>15</label><figDesc>Test accuracies of best APE GPT-3 instructions to prompt itself under six selected tasks</figDesc><table><row><cell>Task</cell><cell>Instruction</cell><cell cols="2">Prompt-only In-context</cell></row><row><cell></cell><cell>to translate the input word into its own antonym.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Thus, the correct answer to each input was the</cell><cell></cell><cell></cell></row><row><cell>Antonyms</cell><cell>opposite word in the input word's "opposite pair."</cell><cell>0.79</cell><cell>0.81</cell></row><row><cell></cell><cell>Inputs and outputs both had opposite pairs (except</cell><cell></cell><cell></cell></row><row><cell></cell><cell>for the first one</cell><cell></cell><cell></cell></row><row><cell></cell><cell>"Write a short story with the given inputs."</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Inputs: Sentence 1: The door was locked. Sen-</cell><cell></cell><cell></cell></row><row><cell>Cause Selection</cell><cell>tence 2: The man climbed in through the window.</cell><cell>0.36</cell><cell>0.76</cell></row><row><cell></cell><cell>Output: The door was locked. The man climbed in</cell><cell></cell><cell></cell></row><row><cell></cell><cell>through</cell><cell></cell><cell></cell></row><row><cell></cell><cell>input: The authors avoided the banker. Output:</cell><cell></cell><cell></cell></row><row><cell></cell><cell>The banker was avoided by the authors.</cell><cell></cell><cell></cell></row><row><cell>Passivization</cell><cell>The instruction was: Input: The scientists encour-</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>aged the artists. Input: The artists were encouraged</cell><cell></cell><cell></cell></row><row><cell></cell><cell>by the scientists. Input</cell><cell></cell><cell></cell></row><row><cell></cell><cell>to find a word that rhymes with every input, and I</cell><cell></cell><cell></cell></row><row><cell></cell><cell>found out that the word "foible" rhymes with every</cell><cell></cell><cell></cell></row><row><cell>Second Letter</cell><cell>input word. Input: defiance Output: a</cell><cell>0.42</cell><cell>0.42</cell></row><row><cell></cell><cell>Input: horse Output: e</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Input</cell><cell></cell><cell></cell></row><row><cell></cell><cell>"describe your reaction to the movie "Julie &amp; Ju-</cell><cell></cell><cell></cell></row><row><cell>Sentiment</cell><cell>lia", in one to five sentences." Output: positive Input: Total crap. Output: negative</cell><cell>0.91</cell><cell>0.94</cell></row><row><cell></cell><cell>Input: Uplifting and funny. Output: positive</cell><cell></cell><cell></cell></row><row><cell></cell><cell>?oeThink of the output as the subject of the verb in</cell><cell></cell><cell></cell></row><row><cell>Translation en-fr</cell><cell>the sentence.? Outputs and inputs were in French, I gave the English translations. Here is my take:</cell><cell>0.85</cell><cell>0.83</cell></row><row><cell></cell><cell>Input: process Output: proc?s</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 16 :</head><label>16</label><figDesc>Number of tasks that achieves human-level performance on zero-shot learning and few-shot learning.Figure13: Zero-shot test accuracy of best performing instructions on 24 Instruction Induction tasks. APE achieves human-level performance on 21 out of 24 tasks.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>LogP</cell><cell></cell><cell>ExecACC</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Task</cell><cell></cell><cell cols="4">Forward Insert Forward Insert</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Beat Zero-shot human (Mean)</cell><cell>14</cell><cell>16</cell><cell>19</cell><cell>13</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Beat Zero-shot human (Best)</cell><cell>19</cell><cell>18</cell><cell>21</cell><cell>19</cell></row><row><cell></cell><cell></cell><cell cols="4">Beat In-context w/o instr (Mean)</cell><cell>21</cell><cell>18</cell><cell>21</cell><cell>18</cell></row><row><cell></cell><cell></cell><cell cols="4">Beat In-context w/o instr (Best)</cell><cell>23</cell><cell>21</cell><cell>23</cell><cell>19</cell></row><row><cell></cell><cell></cell><cell cols="4">Beat In-context human (Mean)</cell><cell>13</cell><cell>11</cell><cell>12</cell><cell>11</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Beat In-context human (Best)</cell><cell>15</cell><cell>12</cell><cell>13</cell><cell>12</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Greedy</cell><cell>Human</cell><cell>APE</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Execution Accuracy</cell><cell>0 0 1</cell><cell>Antonyms Membership</cell><cell cols="2">Cause Selection Common Concept Negation Number to Word</cell><cell>Diff Passivization</cell><cell cols="2">First Letter Pluralization</cell><cell>Formality Rhymes</cell><cell>Large Animal Second Letter Sentence Similarity List Letters</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>Sentiment</cell><cell>Starting With</cell><cell>Sum</cell><cell>Synonyms</cell><cell cols="3">Translation en-de Translation en-es Translation en-fr</cell><cell>Word in Context</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Instruction Only</cell><cell cols="2">In-context Only</cell><cell cols="2">Instruction + In-context</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Execution Accuracy</cell><cell>0 0 1</cell><cell>Antonyms Membership</cell><cell cols="2">Cause Selection Common Concept Negation Number to Word</cell><cell>Diff Passivization</cell><cell cols="2">First Letter Pluralization</cell><cell>Formality Rhymes</cell><cell>Large Animal Second Letter Sentence Similarity List Letters</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>Sentiment</cell><cell>Starting With</cell><cell>Sum</cell><cell>Synonyms</cell><cell cols="3">Translation en-de Translation en-es Translation en-fr</cell><cell>Word in Context</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We use the text-davinci-002 via the OpenAI API (https://beta.openai.com/). Though not stated explicitly in the API, we assume the models are those reported by<ref type="bibr" target="#b32">Ouyang et al. (2022)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>We use the gold annotations from<ref type="bibr" target="#b17">Honovich et al. (2022)</ref>, which were manually verified for correctness.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>We use ada, babbage, curie, davinci, text-ada-001, text-babbage-001, text-curie-001, text-davanci-002</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>These six tasks are chosen such that two of them are worse than humans, and the other four are human-level. They cover six categories (spelling, morphosyntax, lexical semantics, semantics, multi-lingual, and GLUE).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We would like to thank <rs type="person">Or Honovich</rs> and <rs type="person">Michael Zhang</rs> for their help and valuable feedback. JB was supported by <rs type="funder">NSERC</rs> Grant [<rs type="grantNumber">2020-06904</rs>], <rs type="funder">CIFAR</rs> AI Chairs program, <rs type="programName">Google Research Scholar Program and Amazon Research Award</rs>. KP was supported by <rs type="funder">NSERC</rs> PGS-D. SP was supported by <rs type="funder">NSERC</rs> CGS-D. HC was supported by <rs type="funder">NSERC</rs> CGS-D and <rs type="grantName">RBC Graduate Fellowship</rs>. Resources used in preparing this research were provided, in part, by the <rs type="funder">Province of Ontario</rs>, the <rs type="funder">Government of Canada</rs> through <rs type="institution">CIFAR</rs>, and companies sponsoring the <rs type="institution">Vector Institute for Artificial Intelligence</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Vuxtqef">
					<idno type="grant-number">2020-06904</idno>
				</org>
				<org type="funding" xml:id="_Zcwkpue">
					<orgName type="program" subtype="full">Google Research Scholar Program and Amazon Research Award</orgName>
				</org>
				<org type="funding" xml:id="_PfGzX6u">
					<orgName type="grant-name">RBC Graduate Fellowship</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning at the edge of the statistical precipice</title>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Schwarzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><forename type="middle">Samuel</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nova</forename><surname>Dassarma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00861</idno>
		<title level="m">A general language assistant as a laboratory for alignment</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Tezak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Mcleavey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.14255</idno>
		<title level="m">Efficient training of language models to fill in the middle</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pada: A prompt-based autoregressive approach for adaptation to unseen domains</title>
		<author>
			<persName><forename type="first">Eyal</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Oved</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.12206</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<title level="m">Training verifiers to solve math word problems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Commonsense knowledge mining from pretrained models</title>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1173" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural program meta-induction</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rudy</forename><forename type="middle">R</forename><surname>Bunel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GLM: General language model pretraining with autoregressive blank infilling</title>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.26</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.26" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="320" to="335" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning libraries of subroutines for neurally-guided bayesian program induction</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Sabl?-Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2018/file/7" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
	<note>aa685b3b1dc1d6780bf36f7340078c9-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dreamcoder: Bootstrapping inductive program synthesis with wake-sleep library learning</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Sabl?-Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Cary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd acm sigplan international conference on programming language design and implementation</title>
		<meeting>the 42nd acm sigplan international conference on programming language design and implementation</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="835" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Prompting: Better ways of using language models for nlp tasks. The Gradient</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.295</idno>
		<ptr target="https://aclanthology.org/2021.acl-long" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08">August 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3816" to="3830" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Program synthesis</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Programming Languages</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="119" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Instruction induction: From few examples to natural language task descriptions</title>
		<author>
			<persName><forename type="first">Or</forename><surname>Honovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName><surname>Levy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10782</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Jigsaw: Large language models meet program synthesis</title>
		<author>
			<persName><forename type="first">Naman</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skanda</forename><surname>Vaidyanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nagarajan</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Rajamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International Conference on Software Engineering</title>
		<meeting>the 44th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1219" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How can we know what language models know?</title>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="423" to="438" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08361</idno>
		<title level="m">Scaling laws for neural language models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11916</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accelerating search-based program synthesis using learned probabilistic models</title>
		<author>
			<persName><forename type="first">Woosuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kihong</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayur</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="436" to="449" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3045" to="3059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Competition-level code generation with alphacode</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R?mi</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agustin</forename><surname>Dal Lago</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.07814</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning programs: A hierarchical bayesian approach</title>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML-10)</title>
		<editor>
			<persName><forename type="first">Johannes</forename><surname>F?rnkranz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</editor>
		<meeting>the 27th International Conference on Machine Learning (ICML-10)<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">June 21-24, 2010</date>
			<biblScope unit="page" from="639" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><surname>Omnipress</surname></persName>
		</author>
		<ptr target="https://icml.cc/Conferences/2010/papers/568.pdf" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">TruthfulQA: Measuring how models mimic human falsehoods</title>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owain</forename><surname>Evans</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.229</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.229" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3214" to="3252" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10385</idno>
		<title level="m">Gpt understands, too</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alastair</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08786</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Firefly monte carlo: Exact mcmc with subsets of data</title>
		<author>
			<persName><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Prescott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Fourth International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A machine learning framework for programming by example</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Tamuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Butler</forename><surname>Lampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Kalai</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="187" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155</idno>
		<title level="m">Training language models to follow instructions with human feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">True few-shot learning with language models</title>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11054" to="11070" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning how to ask: Querying lms with mixtures of soft prompts</title>
		<author>
			<persName><forename type="first">Guanghui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5203" to="5212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Hierarchical textconditional image generation with clip latents</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Casey</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06125</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Prompt programming for large language models: Beyond the few-shot paradigm</title>
		<author>
			<persName><forename type="first">Laria</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Highresolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bj?rn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Raja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Tenth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
		<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Main Volume</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="255" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">AutoPrompt: Eliciting knowledge from language models with automatically generated prompts</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">Aarohi</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abu</forename><surname>Awal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abubakar</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Adam R Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adri?</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Garriga-Alonso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04615</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Do prompt-based models really understand the meaning of their prompts</title>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01247</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.07682</idno>
		<title level="m">Emergent abilities of large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Leveraging language to learn program abstractions and search heuristics</title>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">M</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="11193" to="11204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Bartscore: Evaluating generated text as text generation</title>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="27263" to="27277" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanyu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02414</idno>
		<title level="m">Glm-130b: An open bilingual pre-trained model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Opt: Open pre-trained transformer language models</title>
		<author>
			<persName><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Nisan</forename><surname>Daniel M Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Stiennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><surname>Irving</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08593</idno>
		<title level="m">Fine-tuning language models from human preferences</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
