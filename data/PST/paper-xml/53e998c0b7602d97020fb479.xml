<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A fuzzy extension of the silhouette width criterion for cluster analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-08-14">14 August 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
							<email>ricardo.campello@pesquisador.cnpq.br</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidade Católica de Santos -UniSantos</orgName>
								<address>
									<addrLine>Rua Dr. Carvalho de Mendonça, 144, Vila Mathias</addrLine>
									<postCode>11070-906</postCode>
									<settlement>Santos</settlement>
									<region>SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidade Católica de Santos -UniSantos</orgName>
								<address>
									<addrLine>Rua Dr. Carvalho de Mendonça, 144, Vila Mathias</addrLine>
									<postCode>11070-906</postCode>
									<settlement>Santos</settlement>
									<region>SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A fuzzy extension of the silhouette width criterion for cluster analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-08-14">14 August 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">8096CA3E8C1CCBB73FDD5EE00F51E894</idno>
					<idno type="DOI">10.1016/j.fss.2006.07.006</idno>
					<note type="submission">Received 4 October 2005; received in revised form 4 March 2006; accepted 15 July 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fuzzy clustering</term>
					<term>Silhouette criteria</term>
					<term>Validity measures</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The present paper proposes a new cluster validity measure as an additional criterion to help the decision making process in fuzzy cluster analysis. This measure, named Fuzzy Silhouette, is a generalization to the fuzzy case of the Average Silhouette Width Criterion, originally conceived to assess crisp (non-fuzzy) data partitions. The Fuzzy Silhouette is more appealing than its crisp counterpart in the context of fuzzy cluster analysis since it makes explicit use of the fuzzy partition matrix provided by the clustering algorithm. In addition, it has been designed to improve performance of the original silhouette criterion in detecting regions with higher data density when the data set involves overlapping clusters. The performance of the Fuzzy Silhouette is evaluated and compared to that of five well-known cluster validity measures. Six data sets are used to illustrate different scenarios in which the proposed Fuzzy Silhouette performs similar to or better than these other criteria, thus becoming eligible to join a pool of measures to be used all together in fuzzy cluster analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Clustering is a task in which the goal is to determine a finite set of categories to describe a data set according to similarities among its objects <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b13">14]</ref>. Clustering techniques can be broadly divided into three main types <ref type="bibr" target="#b26">[27]</ref>: overlapping (so-called non-exclusive), partitional, and hierarchical. The last two are related to each other in that a hierarchical clustering is a nested sequence of partitional clusterings, each of which represents a partition of the data set into a different number of mutually disjoint subsets. A partition of a data set X = {x 1 , . . . , x N }, where x j ∈ n (j = 1, . . . , N), is a collection S = {S 1 , . . . , S c } of c non-overlapping data subsets S i (clusters) such that</p><formula xml:id="formula_0">S 1 ∪ S 2 ∪ • • • ∪ S c = X, S i =</formula><p>and S i ∩ S l = for i = l.</p><p>In practice, however, most data sets comprise ill-delineated subsets that cannot be adequately split this way. For instance, there are situations in which the structure present in the data is characterized by categories that overlap with each other to some degree. In these cases, the use of clustering algorithms that are capable of dealing with such overlapping data clusters is recommended. Fuzzy clustering techniques can naturally cope with this sort of problem since they aim to find fuzzy clusters to which all the data objects belong to some degree <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b22">23]</ref>. The use of fuzzy clustering algorithms has been one of the most successful approaches to data-driven design of fuzzy and neuro-fuzzy systems, namely, models, predictors, controllers, and classifiers <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b0">1]</ref>. In all these potential applications, a key issue concerns determining the best number of clusters to adequately represent the system under interest. However, fuzzy clustering algorithms usually require that the number of clusters be previously defined by the user <ref type="bibr" target="#b22">[23]</ref>. This is quite restrictive in practice since the number of clusters in a data set is generally unknown, especially in real-world data involving overlapping clusters and many attributes. In order to get around this limitation, algorithmic schemes to determine the best number of fuzzy clusters in an automated manner have been developed, such as compatible cluster merging <ref type="bibr" target="#b16">[17]</ref>, progressive clustering <ref type="bibr" target="#b9">[10]</ref>, hierarchical methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11]</ref>, and evolutionary approaches <ref type="bibr" target="#b23">[24]</ref>. A widely known and simple scheme consists of executing the fuzzy clustering algorithm several times for different numbers of clusters and then selecting the particular number of clusters that provides the best result according to a specific criterion <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23]</ref>. Hence, in this scheme-as well as in any other aimed at finding the best data clustering among a set of possible choices-it is indispensable to devise means to evaluate the quality of every solution provided by the algorithm. In other words, the discovery of the best clustering solution among a set of candidates requires efficient criteria to quantitatively measure the quality of the solutions <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Several criteria for fuzzy clustering assessment have been proposed (e.g. see <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">21]</ref> and references therein). Among the most widespread are the Fuzzy Hypervolume and Average Partition Density <ref type="bibr" target="#b18">[19]</ref>, the Xie-Beni index <ref type="bibr" target="#b37">[38]</ref>, the Average Within-Cluster Distance <ref type="bibr" target="#b30">[31]</ref>, and the Average Silhouette Width Criterion <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b13">14]</ref>. These and other cluster validity measures available from the literature have particular features that make each of them capable of outperforming the others in specific classes (or instances) of problems. <ref type="foot" target="#foot_0">1</ref> For this reason, designers are advised to rely on a set of such measures in order to make a decision, rather than on just one <ref type="bibr" target="#b6">[7]</ref>.</p><p>The present paper proposes a new cluster validity measure as an additional criterion to help the decision making process in fuzzy cluster analysis. This measure, named Fuzzy Silhouette, is a generalization-to the fuzzy case-of the Average Silhouette Width Criterion cited above. For the sake of brevity, the Average Silhouette Width Criterion will be, from now on, referred to as Crisp Silhouette. Although the Crisp Silhouette was originally conceived to assess non-fuzzy data partitions, it has also shown to be useful in evaluating fuzzy partitions <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b23">24]</ref>. The Fuzzy Silhouette proposed here comprises the Crisp Silhouette as a particular case. From the theoretical point of view, the Fuzzy Silhouette is much more appealing than its Crisp counterpart in the context of fuzzy cluster analysis since it makes explicit use of the fuzzy partition matrix provided by the clustering algorithm. From a practical perspective, it has been designed to improve Crisp Silhouette's performance in detecting regions with higher data density when the data set involves overlapping clusters.</p><p>A reduced version of the present work was published in <ref type="bibr" target="#b8">[9]</ref>. In this preliminary version, the Fuzzy Silhouette was introduced and compared to four cluster validity measures, namely, Fuzzy Hypervolume, Average Partition Density, Average Within-Cluster Distance, and Crisp Silhouette, in a set of four different scenarios involving different data sets clustered (partitioned) by the classic Fuzzy c-Means algorithm <ref type="bibr" target="#b4">[5]</ref>. The present paper extends this previous work by providing a more insightful discussion on the proposed Fuzzy Silhouette and its differences or similarities with other criteria from the literature. The set of experiments has also been enhanced by including two additional data sets, one additional fuzzy clustering algorithm <ref type="bibr" target="#b19">[20]</ref> for test purposes, and the comparison results regarding an additional validity criterion (Xie-Beni) as well.</p><p>The remainder of this paper is organized as follows. Section 2 reviews the well-known fuzzy cluster validity measures mentioned above as well as the Fuzzy c-Means and Gustafson-Kessel (GK) algorithms, which will be adopted here as test algorithms. Next, in Section 3, the Fuzzy Silhouette is proposed as a new validity measure that comprises the conventional Crisp Silhouette as a particular case. The performances of all these measures are evaluated and compared in Section 4 using five synthetic data sets and one real-world data set. These data sets were selected to illustrate different scenarios in which the proposed Fuzzy Silhouette performs similar to or better than other criteria, thus becoming eligible to join a pool of measures to be used all together in fuzzy cluster analysis. Finally, the conclusions are addressed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background on Fuzzy clustering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Review of the fuzzy c-means algorithm</head><p>Fuzzy c-Means (FCM) is an iterative algorithmic procedure shown to be able to find local solutions to the following optimization problem <ref type="bibr" target="#b4">[5]</ref>:</p><formula xml:id="formula_1">min ij ,v i J = N j =1 c i=1 m ij x j -v i 2 A s.t. 0 ij 1, c i=1 ij = 1 ∀j ∈ {1, 2, . . . , N}, 0 &lt; N j =1 ij &lt; N ∀i ∈ {1, 2, . . . , c},<label>(1)</label></formula><p>where x j ∈ n (j = 1, . . . , N) are the data objects to be clustered into c clusters, v i ∈ n (i = 1, . . . , c) are the cluster prototypes, ij stands for the membership of the jth data object to the ith fuzzy cluster,<ref type="foot" target="#foot_1">2</ref> m ∈]1, ∞[ is a weighting parameter, and • A denotes an inner-product norm (e.g. Euclidean distance). The iterative algorithm is summarized below:</p><p>(1) Select initial cluster prototypes v 1 , v 2 , . . . , v c .</p><p>(2) Compute the distances between objects and prototypes:</p><formula xml:id="formula_2">x j -v i 2 A = (x j -v i ) T A(x j -v i ), (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where A is an n × n matrix that induces a particular norm (e.g. identity matrix for Euclidean distance). (3) Compute the partition matrix elements:</p><formula xml:id="formula_4">ij = c l=1 x j -v i A x j -v l A 2/(m-1) -1 .</formula><p>(3) (4) Compute the cluster prototypes:</p><formula xml:id="formula_5">v i = N j =1 m ij x j N j =1 m ij . (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>(5) Stop if convergence is attained or the number of iterations exceeds a given limit. Otherwise, go back to step 2.</p><p>Remark 1. Eq. (3) requires that x jv i A &gt; 0 for all j ∈ {1, . . . , N} and i ∈ {1, . . . , c}. For every j, if x jv i A = 0 for i ∈ I ⊆ {1, . . . , c}, then define ij in such a way that: (a) ij = 0 for i ∈ Ī ; and (b) i∈I ij = 1.</p><p>Remark 2. An effective stopping criterion for the algorithm is that the maximum absolute difference between elements of the partition matrix in two consecutive iterations be lower than a given positive threshold . A usual setting-adopted in this paper-is = 10 -3 <ref type="bibr" target="#b0">[1]</ref>.</p><p>Remark 3. The weighting parameter m, so-called fuzzifier, controls the fuzziness of the solution. As m approaches 1 from above the partition matrix tends to be crisp ( ij = 0 or 1). On the other hand, the larger the value of m, the fuzzier the resulting partition. Usually, m = 2 is chosen <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b22">23]</ref>. This value will be used in all the experiments presented in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Review of the GK algorithm</head><p>The use of a fixed inner-product norm in the FCM algorithm, i.e. a prearranged matrix A in Eq. ( <ref type="formula" target="#formula_2">2</ref>), induces fuzzy clusters of a particular shape. For instance, hyperspherical clusters are induced when the Euclidean norm is adopted. Gustafson and Kessel <ref type="bibr" target="#b19">[20]</ref> proposed the use of an adaptive distance measure that makes the algorithm able to find fuzzy clusters with different shapes depending on the spatial distribution of the data. More specifically, the algorithm is able to find hyperellipsoidal (possibly hyperspherical) fuzzy clusters with different spatial orientations.</p><p>The GK algorithm follows the same steps as the FCM algorithm, except that the distances between data objects and cluster prototypes in Eq. ( <ref type="formula" target="#formula_2">2</ref>) are computed as a function of independent adaptive matrices A i (i = 1, . . . , c). Assuming that the clusters have roughly similar volumes, these matrices are given by</p><formula xml:id="formula_7">A i = n det( i ) -1 i , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where i is related to the covariance of the ith cluster as</p><formula xml:id="formula_9">i = N j =1 m ij (x j -v i )(x j -v i ) T N j =1 m ij . (<label>6</label></formula><formula xml:id="formula_10">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Review of cluster validity measures 2.3.1. Fuzzy hypervolume and average partition density</head><p>Inspired by the principle that "good" clusters are not very fuzzy, even though the environment is fuzzy, Gath and Geva <ref type="bibr" target="#b18">[19]</ref> proposed validity measures based on criteria for hypervolume and density of fuzzy clusters. More specifically, the Fuzzy Hypervolume (FHV) is given by</p><formula xml:id="formula_11">FHV = c i=1 [det(F i )] 1/2 , (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>where F i is the fuzzy covariance matrix of the ith fuzzy cluster, defined as follows:</p><formula xml:id="formula_13">F i = N j =1 h(i|x j )(x j -v i )(x j -v i ) T N j =1 h(i|x j ) . (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>Under the perspective of a maximum likelihood estimation, h(i|x j ) is the (posterior) probability of selecting the ith cluster given the jth object x j . When the most usual value for the fuzzifier is chosen, i.e. m = 2, this probability approaches the membership of the jth object to the ith cluster <ref type="bibr" target="#b18">[19]</ref>. Accordingly, the fuzzy covariance matrix in (8) can be rewritten as</p><formula xml:id="formula_15">F i = N j =1 ij (x j -v i )(x j -v i ) T N j =1 ij . (<label>9</label></formula><formula xml:id="formula_16">)</formula><p>Since the eigenvalues of F i are directly related to the variances of the ith fuzzy cluster, the determinant in <ref type="bibr" target="#b6">(7)</ref>, given by the product of all the eigenvalues of F i , provides a measure of the n-dimensional dispersion (hypervolume) of the cluster. Hence, good fuzzy partitions-composed of compact fuzzy clusters-are distinguished by small values of FHV in <ref type="bibr" target="#b6">(7)</ref>. The Average Partition Density (APD), in its turn, is defined as</p><formula xml:id="formula_17">[19] APD = 1 c c i=1 R i [det(F i )] 1/2 , (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>where R i is the "sum of central members", i.e.</p><formula xml:id="formula_19">R i = j ij , ∀j such that (x j -v i ) T F -1 i (x j -v i ) &lt; 1,<label>(11)</label></formula><p>which is the sum of the membership values (w.r.t. cluster i) of those data objects within a hypresphere-or hyperellipsoid in the more general case of hyperellipsoidal fuzzy clustering algorithms-whose radii are the standard deviations of the cluster features. Since compact fuzzy clusters provide small values of [det(F i )] 1/2 and large values of R i in <ref type="bibr" target="#b9">(10)</ref>, it is straightforward to conclude that good fuzzy partitions are distinguished by large values of APD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Average within-cluster distance</head><p>Another well-known fuzzy cluster validity measure is the Average Within-Cluster Distance (AWCD), given by [31]</p><formula xml:id="formula_20">AWCD = 1 c c i=1 N j =1 m ij x j -v i 2 A N j =1 m ij , (<label>12</label></formula><formula xml:id="formula_21">)</formula><p>where • A and m refer to the same norm and weighting coefficient used in the fuzzy clustering algorithm, respectively. This measure is the mean value of the within-cluster distances computed over all clusters. The within-cluster distance of a specific cluster, in turn, is given by a weighted average of the distances between all the data objects and the prototype of the cluster, with each distance weighted by the membership value of the corresponding object to that cluster. As the AWCD monotonically decreases with the number of clusters-at least ideally, i.e. when the global optimal solution according to the objective function J in ( <ref type="formula" target="#formula_1">1</ref>) is considered-a "knee" in the curve of AWCD as a function of c indicates a good fuzzy partition <ref type="bibr" target="#b0">[1]</ref> (details are provided further in Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">Xie-Beni index</head><p>The Xie-Beni (XB) index is a popular fuzzy cluster validity measure defined as <ref type="bibr" target="#b37">[38]</ref> </p><formula xml:id="formula_22">XB = c i=1 N j =1 m ij x j -v i 2 A N min p =q { v p -v q 2 } , (<label>13</label></formula><formula xml:id="formula_23">)</formula><p>where • A and m refer to the same norm and weighting coefficient used in the fuzzy clustering algorithm, respectively. This criterion is closely related to AWCD in <ref type="bibr" target="#b11">(12)</ref>. Indeed, the numerator of ( <ref type="formula" target="#formula_22">13</ref>) is the total within-cluster distance, which is equivalent to the objective function J of FCM and GK algorithms. The ratio J /N is called the compactness of the fuzzy partition. The smaller this ratio, the more compact a partition with a fixed number of clusters (despite the number of data objects in a given data set). The minimum squared distance between prototypes in the denominator of ( <ref type="formula" target="#formula_22">13</ref>) is called separation. The greater this distance, the more separate a data partition with a fixed number of clusters.</p><p>Then, for a fixed number of clusters, the smaller XB, the better the partition. Actually, this proposition tends to hold even as a function of the number of clusters, since both the compactness ratio and the separation term tend to monotonically decrease with c, thus nearly canceling each other's dependency on this quantity. Although Xie and Beni claim that XB is independent of the algorithm used to obtain the fuzzy partition to be assessed <ref type="bibr" target="#b37">[38]</ref>, not much is said about how to compute this criterion in a scenario different from that based on the use of FCM, particularly in what concerns the norm that should be used for computing the separation term in each specific case. This point will be of particular relevance in the example of Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4.">Crisp silhouette</head><p>The last cluster validity measure to be considered for comparison purposes is the Average Silhouette Width Criterion <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b13">14]</ref>-or Crisp Silhouette, as stated previously in the introduction. In order to define this criterion, consider a data object j ∈ {1, 2, . . . , N} belonging to cluster p ∈ {1, . . . , c}. In the context of crisp partitions produced by a prototypebased clustering algorithm (e.g. Hard c-Means <ref type="bibr" target="#b6">[7]</ref>), for example, this means that object j is closer to the prototype of cluster p than to any other prototype. In the more general context of fuzzy partitions, on the other hand, this means that the membership of the jth object to the pth fuzzy cluster, pj , is higher than the membership of this object to any other fuzzy cluster, i.e. pj &gt; qj for every q ∈ {1, . . . , c}, q = p.</p><p>Let the average distance 3 of object j to all other objects belonging to cluster p be denoted by a pj . Also, let the average distance of this object to all objects belonging to another cluster q, q = p, be called d qj . Finally, let b pj be the minimum d qj computed over q = 1, . . . , c, q = p, which represents the dissimilarity of object j to its closest 3 Based on the same norm adopted in the fuzzy clustering algorithm. neighboring cluster. Then, the silhouette of object j is defined as</p><formula xml:id="formula_24">s j = b pj -a pj max{a pj , b pj } , (<label>14</label></formula><formula xml:id="formula_25">)</formula><p>where the denominator is used just as a normalization term. Clearly, the higher s j , the better the assignment of object j to cluster p. In case p is a singleton, i.e. if it is constituted uniquely by object j, then the silhouette of this object is defined as s j = 0 <ref type="bibr" target="#b27">[28]</ref>. This prevents the Crisp Silhouette (CS), defined as the average of s j over j = 1, 2, . . . , N, i.e.</p><formula xml:id="formula_26">CS = 1 N N j =1 s j , (<label>15</label></formula><formula xml:id="formula_27">)</formula><p>to find the trivial solution c = N , with each object of the data set forming a cluster on its own. This way, the best partition is achieved when CS in ( <ref type="formula" target="#formula_26">15</ref>) is maximized, which implies minimizing the intra-cluster distance (a pj ) while maximizing the inter-cluster distance (b pj ). Conceptually, several other criteria are based on the same idea (e.g. the Fukuyama-Sugeno index <ref type="bibr" target="#b17">[18]</ref>), including XB in <ref type="bibr" target="#b12">(13)</ref>. A comprehensive study involving two of them, namely, the Davies-Bouldin and Dunn's indexes, is presented in <ref type="bibr" target="#b6">[7]</ref>. Another one, called Compose Within and Between Scattering, is proposed and compared to indexes from the literature in <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 4.</head><p>A problem with the CS measure is that it depends on the highly intensive computation of all distances among all data objects. In order to get around this problem, Hruschka et al. <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b24">25]</ref> proposed to replace the terms a pj and b pj in Eq. ( <ref type="formula" target="#formula_24">14</ref>) with simplified versions of them based on the distances among the objects and the prototypes of the corresponding clusters. This modification has shown not to degrade accuracy while being able to significantly reduce the computational burden from O(N 2 ) to O(N ). Moreover, it does not change the dependency of CS on average distances (in this case represented by the prototypes), which is a desirable property concerning robustness to noise in the data <ref type="bibr" target="#b6">[7]</ref>. For these reasons, the prototype-based version of CS described above is adopted in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Fuzzy silhouette</head><p>Both the original and prototype-based versions of the Crisp Silhouette discussed in Section 2.3.4 do not make explicit use of the fuzzy partition matrix in their calculations. In those cases, the fuzzy partition matrix P = [ ij ] c×N is used only to impose on the data set a crisp partition P = [˜ ij ] c×N to which the CS measure can be applied. Specifically, P is such that ˜ ij = 1 if i = arg max l { lj } and ˜ ij = 0 otherwise. Consequently, CS may not be able to discriminate between overlapped data clusters-even if these clusters have their own (distinct) regions with higher data densitiessince it neglects information contained in the fuzzy partition matrix P on degrees to which clusters overlap one another. This information can be used to reveal those regions with high data densities by stressing importance of data objects concentrated in the vicinity of the cluster prototypes while reducing importance of objects lying in overlapping areas. To do so, a generalized silhouette criterion, named Fuzzy Silhouette (FS), is defined as follows:</p><formula xml:id="formula_28">FS = N j =1 ( pj -qj ) s j N j =1 ( pj -qj ) , (<label>16</label></formula><formula xml:id="formula_29">)</formula><p>where s j is the silhouette of object j according to Eq. ( <ref type="formula" target="#formula_24">14</ref>), pj and qj are the first and second largest elements of the jth column of the fuzzy partition matrix, respectively, and 0 is a weighting coefficient (to be explained further). There is an important aspect regarding Eq. ( <ref type="formula" target="#formula_28">16</ref>) that deserves particular attention. It differs from <ref type="bibr" target="#b14">(15)</ref> for being a weighted average (instead of an arithmetic mean) of the individual silhouettes given by <ref type="bibr" target="#b13">(14)</ref>. The weight of each term is determined by the difference between the membership degrees of the corresponding object to its first and second best matching fuzzy clusters, respectively. This way, an object in the near vicinity of a cluster prototype is given more importance than another object located in an overlapping area (where the membership degrees of the objects to two or more fuzzy clusters are similar).</p><p>A question that may arise is why not define the fuzzy silhouette just as (1/N ) N j =1 ( pjqj ) , since a good fuzzy partition would be expected to be such that each data object has a high membership degree to a specific fuzzy cluster and low membership degrees to the others. The problem is that this requirement may easily be met by a fuzzy clustering algorithm even when the number of fuzzy clusters, c, is not in conformity with the spatial distribution of the data. For instance, when the number of fuzzy clusters is unsuitably small, the algorithm may assign a given data object a high membership degree even if this object is not close to the corresponding cluster prototype. This problem takes place mainly because, unlike FS in ( <ref type="formula" target="#formula_28">16</ref>), the criterion just described relies solely on the fuzzy partition matrix, lacking a direct connection to geometrical information contained in the data themselves and in the cluster prototypes as well. This is the main criticism against other well-known validity criteria based uniquely upon the fuzzy partition matrix <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref>, such as the Partition Coefficient <ref type="bibr" target="#b2">[3]</ref>, the Partition Entropy <ref type="bibr" target="#b3">[4]</ref>, and the Proportion Exponent <ref type="bibr" target="#b36">[37]</ref>.</p><p>Remark 5. Some algorithms and methods for determining the number of clusters in data require validity measures for the individual clusters rather than for the whole data partition <ref type="bibr" target="#b9">[10]</ref>. For instance, the Crisp Silhouette of a given cluster i can easily be computed by taking into account in Eq. ( <ref type="formula" target="#formula_26">15</ref>) only those objects belonging to the ith cluster. The same idea can be straightforwardly extended to computing the Fuzzy Silhouette of an individual fuzzy cluster. Specifically, the Fuzzy Silhouette of the ith fuzzy cluster can be computed by taking into account in <ref type="bibr" target="#b15">(16)</ref> only those objects that belong the most to that cluster. This way, the property of CS being a particular case of FS is also retained in the context of individual clusters. Remark 6. Besides those benefits from extending CS to FS discussed above in this section, there are also some structural advantages in FS over those measures presented in Section 2.3. First, unlike AWCD, FS seeks a maximum instead of a "knee" in a graph. Recognizing a "knee" in a graph is a process that could hardly be automated. Moreover, this task may sometimes be impossible to be accomplished, even by humans (refer to Section 4.2 for an example). One may experience similar problems with XB, since it tends to decrease monotonically with large values of c <ref type="bibr" target="#b37">[38]</ref>. <ref type="foot" target="#foot_2">4</ref> With respect to FHV and APD, it follows that these measures are much more computationally intensive than FS. The reason is the need for computing the determinant and inverse of the fuzzy covariance matrices, which are both O(n 3 ) <ref type="bibr" target="#b12">[13]</ref>. This represents a serious drawback in data sets involving a large number n of attributes, which is generally the case, for instance, in bioinformatics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 7.</head><p>Exponent is an optional user-defined parameter (unit by default). The effect of varying this parameter on the weighting terms in Eq. ( <ref type="formula" target="#formula_28">16</ref>) is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. As Fig. <ref type="figure" target="#fig_0">1</ref> shows, the harder the partition matrix, the smaller the impact of changes in . Clearly, when approaches zero from above, the FS measure in ( <ref type="formula" target="#formula_28">16</ref>) approaches the CS measure in (15). In the limit, CS is obtained as a particular case of FS by setting = 0. Conversely, increasing moves FS away from CS by diminishing the relative importance of data objects in overlapping areas. Accordingly, increasing tends to stress the effect of revealing smaller regions with higher data densities (subclusters), if they exist. Such an effect can be particularly useful, for instance, when dealing with data sets contaminated by noise. Bearing this in mind, exponent can be seen as an additional tool for exploratory data analysis, as is the case with fuzzifier exponent (m) of the FCM and GK algorithms. From another perspective, the Fuzzy Silhouette with exponent can be seen as a family of parameterized cluster validity measures, rather than a single measure with a coefficient that must be adjusted to a specific problem in hand. The default value = 1 is used in all the examples of Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Examples</head><p>Six illustrative examples are presented in this section. The first five examples concern synthetic data sets with bidimensional objects. The 2D data sets are considered so that visual inspection can be more easily adopted as an absolute referential criterion for determining the natural clusters in the data. Indeed, as noticed by Hardy <ref type="bibr" target="#b21">[22]</ref>, it is easier to evaluate the performances and properties of procedures on data that can be represented graphically and directly assessed by eye. The last example concerns a real-world data set, the well-known IRIS data <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b5">6]</ref>. Although IRIS is 4D, its spatial distribution was extensively investigated and is widely known.</p><p>As mentioned in Section 1, different methods for finding the number of fuzzy clusters in data based upon cluster validity measures are available in the literature. Provided that the present paper focuses particularly on the validity measures rather than on the methods themselves, a very simple method based on multiple runs of a fuzzy clustering algorithm over a range of values for the number of clusters is adopted here for the sake of simplicity <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>In the first four examples, the FCM algorithm (with Euclidean distance) is used to produce fuzzy partitions of the data to be assessed by the validity measures discussed in Sections 2.3 and 3. The fifth example is intended to show the performance of these measures in evaluating fuzzy partitions derived from a different clustering approach, namely, the GK algorithm. In the last example (IRIS data), the validity measures are applied to partitions derived from both FCM and GK algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Example 1</head><p>The well-known Ruspini data set <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b27">28]</ref> is considered as a first example. This data set is composed of 75 bidimensional objects (shown in Fig. <ref type="figure">2</ref>) and has been widely used as a benchmark for clustering algorithms.</p><p>The FCM algorithm (Section 2.1) was sequentially applied to this data set with the number of clusters ranging from 2 to 7. For each c = 2, . . . , 7, FCM was run 10 times starting from random initializations of the prototypes. The best values obtained for the cluster validity measures (Sections 2.3 and 3) were stored. The results are shown in Fig. <ref type="figure" target="#fig_2">3</ref>. In this figure, maximum peaks are evident for FS, CS, and APD when c = 4. Similarly, clear minima and a distinguishable "knee" are also verified for c = 4 in FHV, XB, and AWCD, respectively. In summary, all these measures point out that the optimal number of clusters is 4. This is in accordance with common sense evaluation of the data by visual inspection, even though 5 clusters are also acceptable in this case <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Example 2</head><p>In this example, a data set composed of 900 objects containing 9 overlapping clusters with 100 objects each is considered <ref type="bibr" target="#b23">[24]</ref>. The data clusters were randomly generated using bi-dimensional Gaussian distributions with standard deviations equal to 0.5, as shown in Fig. <ref type="figure">4</ref>.</p><p>The same procedure described in example 1 for multiple (random restart) executions of the FCM algorithm is also adopted here, except that the number of clusters now ranges from 2 to 12. The results are displayed in Fig. <ref type="figure" target="#fig_4">5</ref>, which shows that neither AWCD nor FHV was able to detect 9 clusters in the data set. This figure also shows that APD is not conclusive, since there is only a local maximum at c = 9. Rigorously, the optimal number of clusters according to both APD and FHV is 2. The silhouettes (both CS and FS), on the other hand, indicate clearly that the optimal number of  clusters is 9. By taking the minimum at c = 9 for XB as a criterion to decide this tie, a voting scheme becomes capable of making the right decision. This is a sample of a possible scenario where the use of several different measures is advantageous over the use of a single one.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Example 3</head><p>In this example, a data set composed of 225 objects containing 9 clusters with 25 objects each is considered. Like in the previous example, the data clusters were randomly generated using 2D Gaussian distributions (standard deviations equal to 0.15), as shown in Fig. <ref type="figure">6</ref>. The results of the random restart sequential execution of the FCM algorithm are displayed in Fig. <ref type="figure" target="#fig_6">7</ref>. In summary, this figure shows that all six measures reflect the (misleading) spatial distribution of the data, with 9 small clusters disposed in such a way that they form 3 bigger clusters. In this case, only APD and the proposed FS were able to detect those 9 regions with higher data densities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Example 4</head><p>In this example, a data set composed of 350 objects containing 3 unbalanced clusters is considered. The data clusters were randomly generated using 2D Gaussian distributions with standard deviations equal to 3 (200 objects), 2 (100 objects), and 1 (50 objects), as shown in Fig. <ref type="figure">8</ref>. The results of the random restart executions of the FCM algorithm are displayed in Fig. <ref type="figure" target="#fig_8">9</ref>. Note that XB and CS were the only ones to fail in detecting the intrinsic distribution of the data, mainly due to the high degree to which two of the clusters overlap each other. Fig. <ref type="figure" target="#fig_0">10</ref> shows why the FS measure proposed outperforms CS and succeeds in detecting 3 clusters in this example. Basically, when the fuzzy clustering algorithm is run with 3 prototypes, the objects close to each prototype (dark gray dots) are given more importance than those objects located in the overlapping area between clusters (light gray dots), thus revealing those higher density regions in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Example 5</head><p>This example is inspired by the work in <ref type="bibr" target="#b30">[31]</ref>, where the GK fuzzy clustering algorithm (Section 2.2) was applied to character recognition problems. The data set shown in Fig. <ref type="figure" target="#fig_0">11</ref> is considered. This data set consists of 3 ellipsoidal clusters that altogether resemble the letter "A", each of which is composed of 100 objects. These clusters were randomly generated using 2D Gaussian distributions with different standard deviations along the horizontal and vertical axes, namely, (0.5, 0.02) for the first two clusters and (1, 0.01) for the third one. In addition, the first two clusters were rotated by 45 • and -45 • degrees with respect to the vertical axis.</p><p>In this example, the GK algorithm was sequentially applied to the data set in Fig. <ref type="figure" target="#fig_0">11</ref> with the number of clusters ranging from 2 to 6. For the sake of illustration, Fig. <ref type="figure" target="#fig_0">12</ref> displays a typical scenario after running GK with 3 prototypes, i.e. the right number of clusters. This figure redraws the data set in three different linear gray-scales, each of which is  proportional to the membership of the data objects to a specific cluster. It is clear from Fig. <ref type="figure" target="#fig_0">12</ref> that the fuzzy clusters derived by the GK algorithm are a faithful representation of the original clusters contained in the data set.</p><p>For each c = 2, . . . , 6, GK was run 10 times starting from random initializations of the prototypes. The best values obtained for the cluster validity measures are shown in Fig. <ref type="figure" target="#fig_11">13</ref>. This figure shows that all the criteria were able to detect  the right number of clusters, which confirms that they are not necessarily hooked on a specific fuzzy clustering algorithm. This includes the proposed Fuzzy Silhouette. In the case of the Xie-Beni index, however, it is worth remarking that the successful result shown in Fig. <ref type="figure" target="#fig_11">13</ref> was derived by computing the separation term in (13) using the Euclidean distance, which is different from the adaptive distance of the GK algorithm used to compute the compactness term of the index.</p><p>Results not reported here show that if the adaptive distance was also used to compute the separation term in (13), XB would not succeed in discovering 3 clusters in the data. As previously mentioned in Section 2.3.3, not much is said in <ref type="bibr" target="#b37">[38]</ref> about the norm that should be used for computing the separation term when evaluating partitions derived from algorithms other than FCM. Indeed, as highlighted in <ref type="bibr">[12, p. 495</ref>], although the Xie-Beni functional may in principle be generalized for clusters of different geometrical shapes, defining a minimum distance between prototypes becomes a problem in such a case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Example 6</head><p>The IRIS data set <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b5">6]</ref> is one of the most popular real-world benchmark problems used to evaluate performance of machine-learning techniques. This data set contains 150 4D objects, each of which describes a sample of flower belonging to one of three different classes of irises: setosa, versicolor, and virginica. Each class is composed of 50 samples. It is well known that one of the classes (setosa) is linearly separable from the others, while the other two   are overlapping. Actually, classes versicolor and virginica are often considered to form a single cluster, due to their overlapping degree and the statistical distribution of their objects. Hence, although there are 3 classes in the IRIS data set, a number of 2 or 3 clusters is acceptable <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>In this example, both the FCM and GK algorithms were sequentially applied to the data set. The results of the random restart executions of these algorithms are displayed in Figs. <ref type="figure" target="#fig_12">14</ref> and<ref type="figure" target="#fig_13">15</ref>. It can be seen from these figures that most of the criteria (including FS) found the expected number of clusters (i.e. 2 or 3). As expected, when 2 clusters are found, the partitions essentially assign class setosa to one cluster and a union of classes versicolor and virginica to another cluster.</p><p>The results concerned with AWCD and APD deserve particular attention. In what concerns AWCD, the present example has exposed another serious flaw of this index: it can never suggest 2 as the right number of clusters, by lack of a reference with respect to c = 1. So, one has no choice other than focusing on 3 or more clusters when using this index. Bearing this in mind, it could be considered that AWCD found 3 clusters for the Iris data set, even though it is somewhat undecided for FCM partitions (see Fig. <ref type="figure" target="#fig_12">14</ref>). With respect to APD, it follows from Fig. <ref type="figure" target="#fig_13">15</ref> that this index found 6 clusters when assessing GK partitions. Some care must be taken here, since it is the first time in all the examples that an index suggests a number of clusters greater than the expected one. In principle, it could be possible that APD had found a good partition with 2 or 3 main clusters plus 3 or 4 peripheral clusters with just a few objects or even singletons. Actually, however, APD found a partition in which classes versicolor and virginica were roughly subdivided into 5 clusters. This kind of error is not as serious as finding too few clusters (thereby losing important information on the structure present in the data) <ref type="bibr" target="#b31">[32]</ref>, but it is still an error that should be avoided. A voting scheme involving the six available indexes would undoubtedly avoid such an error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>A new cluster validity measure has been presented as an additional criterion to help the decision making process in fuzzy cluster analysis. This measure, named Fuzzy Silhouette, is a generalization to the fuzzy case of the Average Silhouette Width Criterion, originally conceived to assess crisp data partitions. The Fuzzy Silhouette has been designed to improve the performance of its crisp counterpart in detecting regions with higher data densities when the data set involves overlapping clusters, besides being more appealing in the context of fuzzy cluster analysis. Moreover, this measure is much less computationally intensive than the well-known Fuzzy Hypervolume and Average Partition Density criteria, especially when the data set involves many attributes. Finally, unlike the popularAverage Within-Cluster Distance measure and the Xie-Beni index, for example, the Fuzzy Silhouette is straightforwardly (and unrestrictedly) applicable as an objective function for global optimization methods-such as evolutionary algorithms <ref type="bibr" target="#b14">[15]</ref>-designed for automatically finding the right number of clusters in a data set.</p><p>The performance of the Fuzzy Silhouette was evaluated and compared to that of the other cluster validity measures mentioned above. The results show that the Fuzzy Silhouette was able to perform similar to or better than these criteria in a set of different scenarios involving different data sets and fuzzy clustering algorithms. However, these results should not be understood as a claim that they can be generalized to any other data set or validity criterion not explicitly (or implicitly) considered in this paper, particularly because, as said by Pal and Bezdek <ref type="bibr" target="#b32">[33]</ref>, "no matter how good your index is, there is a data set out there waiting to trick it (and you)". Indeed, like those other criteria used in the experiments for comparison purposes, the underlying rationale of the Fuzzy Silhouette clearly favors clusters of volumetric nature, and any extension of these ideas to clusters of a different nature would require further investigations. So, in summary, the results presented in this work basically suggest that the proposed Fuzzy Silhouette is eligible to join a pool of nice existing measures to be used all together in fuzzy cluster analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Effect of exponent on the weighting terms of FS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 Fig. 2 .</head><label>22</label><figDesc>Fig. 2. Ruspini data (example 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Cluster validity measures for example 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 Fig. 4 .</head><label>24</label><figDesc>Fig. 4. Data set composed of 900 objects containing 9 overlapping clusters with bi-dimensional Gaussian distributions (example 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Cluster validity measures for example 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 Fig. 6 .</head><label>26</label><figDesc>Fig. 6. Data set composed of 225 objects containing 9 small clusters forming 3 bigger clusters (example 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Cluster validity measures for example 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 Fig. 8 .</head><label>28</label><figDesc>Fig. 8. Data set composed of 350 objects containing 3 unbalanced clusters with 2D Gaussian distributions (example 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Cluster validity measures for example 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>2 Fig. 10 .</head><label>210</label><figDesc>Fig. 10. Data set of example 4 drawn in a linear gray-scale proportional to the weight of each object in the FS measure, i.e. ( pjqj ) in Eq. (16): typical scenario after running FCM with 3 prototypes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>2 Fig. 11 . 2 Fig. 12 .</head><label>211212</label><figDesc>Fig. 11. Data set containing 3 ellipsoidal clusters composed of 100 objects each (example 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Cluster validity measures for example 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Cluster validity measures for example 6 (FCM algorithm).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Cluster validity measures for example 6 (GK algorithm).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Indeed, the concept of cluster itself is quite subjective.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>ij is an element of the partition matrix P ∈ c×N .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>In<ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref>, the authors showed that the term "large" in this context may refer to values much lower than Xie and Beni conjectured it would.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors acknowledge CNPq and Fapesp for their financial support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Babuška</surname></persName>
		</author>
		<title level="m">Fuzzy Modeling for Control</title>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A clustering performance measure based on fuzzy set decomposition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Backer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="75" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cluster validity with fuzzy sets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cybernet</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mathematical models for systemics and taxonomy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Internat. Conf. on Numerical Taxonomy</title>
		<meeting>8th Internat. Conf. on Numerical Taxonomy<address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<title level="m">Pattern Recognition with Fuzzy Objective Function Algorithm</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Plenum Press</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Will the real Iris data please stand up?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnapuram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="368" to="369" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Some new indexes of cluster validity</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems Man Cybernet. B</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="301" to="315" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised fuzzy classification method based on a fuzzy proximity graph and on a graduated hierarchy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Billaudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Devillez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Villermain</surname></persName>
		</author>
		<author>
			<persName><surname>Lecolier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th IEEE Internat. Conf. on Fuzzy Systems, Seoul, Korea</title>
		<meeting>8th IEEE Internat. Conf. on Fuzzy Systems, Seoul, Korea</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1054" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fuzzy silhouette: an alternative cluster validity measure</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th IFSA World Congr</title>
		<meeting>11th IFSA World Congr<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="603" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust clustering methods: a unified view</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Davé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnapuram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="270" to="293" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A fuzzy hybrid hierarchical clustering method with a new criterion able to find the optimal partition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Devillez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Billaudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Villermain</surname></persName>
		</author>
		<author>
			<persName><surname>Lecolier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="323" to="338" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Fuzzy Sets and their Application to Clustering and Training</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dumitrescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lazzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Numerical Algorithms with C</title>
		<author>
			<persName><forename type="first">G</forename><surname>Engeln-Müllges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Uhlig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Landau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leese</surname></persName>
		</author>
		<title level="m">Cluster Analysis</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<publisher>Arnold</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>fourth ed.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Genetic Algorithms and Grouping Problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Falkenauer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The use of multiple measurements in taxonomic problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Eugenics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="188" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A robust algorithm for automatic extraction of an unknown number of clusters from noisy data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Frigui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnapuram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Lett</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1223" to="1232" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A new method of choosing the number of clusters for the fuzzy c-means method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fukuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugeno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Fuzzy Systems Symp. 1989</title>
		<meeting>5th Fuzzy Systems Symp. 1989</meeting>
		<imprint>
			<biblScope unit="page" from="247" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised optimal fuzzy clustering</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Geva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="773" to="781" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fuzzy clustering with a fuzzy covariance matrix</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Kessel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. on Decision and Control</title>
		<meeting><address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="761" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On clustering validation techniques</title>
		<author>
			<persName><forename type="first">M</forename><surname>Halkidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Batistakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vazirgiannis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Inform. Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="107" to="145" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the number of clusters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Statist. Data Anal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="83" to="96" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Höppner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Klawonn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Runkler</surname></persName>
		</author>
		<title level="m">Fuzzy Cluster Analysis: Methods for Classification, Data Analysis and Image Recognition</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Evolutionary search for optimal Fuzzy C-Means clustering</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>De Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th IEEE Internat. Conf. on Fuzzy Systems</title>
		<meeting>13th IEEE Internat. Conf. on Fuzzy Systems<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="685" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evolving clusters in gene-expression data</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>De Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="1898" to="1927" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms for clustering gene-expression data</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>De Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Internat. Conf. on Data Mining</title>
		<meeting>IEEE Internat. Conf. on Data Mining<address><addrLine>Brighton, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="403" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Algorithms for Clustering Data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Dubes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rousseeuw</surname></persName>
		</author>
		<title level="m">Finding Groups in Data</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Fuzzy Engineering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kosko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On finding the number of clusters</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kothari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pitts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="405" to="416" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fitting an unknown number of lines and planes to image data through compatible cluster merging</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnapuram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Freg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="385" to="400" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An examination of procedures for determining the number of clusters in a data set</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Milligan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="179" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On cluster validity for the fuzzy c-means model</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="379" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Correction to &quot;on cluster validity for the fuzzy c-means model</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="152" to="153" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A new cluster validity index for the fuzzy c-mean</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Rezaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P F</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H C</forename><surname>Reiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Lett</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="237" to="246" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Numerical methods for fuzzy clustering</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Ruspini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="319" to="350" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cluster validity for fuzzy clustering algorithms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Windham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="177" to="185" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A validity measure for fuzzy clustering</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Beni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="841" to="847" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
