<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparing Program Phase Detection Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ashutosh</forename><forename type="middle">S</forename><surname>Dhodapkar</surname></persName>
							<email>dhodapka@ece.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Wisconsin -Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Wisconsin -Madison</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Comparing Program Phase Detection Techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detecting program phase changes accurately is an important aspect of dynamically adaptable systems. Three dynamic program phase detection techniques are compared -using instruction working sets, basic block vectors (BBV), and conditional branch counts. Because program phases are difficult to define, we compare the techniques using a variety of metrics.</p><p>BBV techniques perform better than the other techniques providing higher sensitivity and more stable phases. However, the instruction working set technique yields 30% longer phases than the BBV method, although there is less stability within phases. On average, the methods agree on phase changes 85% of the time. Of the 15% of time they disagree, the BBV method is more efficient at detecting performance changes. The conditional branch counter technique provides good sensitivity, but is less effective at detecting major phase changes. Nevertheless, the branch counter technique correlates 83% of the time with the BBV based technique. As an auxiliary result, we show that techniques based on procedure granularities do not perform as well as those based on instruction or basic block granularities. This is mainly due to their inability to detect changes within procedures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>General-purpose microprocessor design has traditionally focused on optimizing microarchitectural parameters (e.g. issue window size, cache sizes, etc.) at design time. The goal is to provide good performance on average, over a wide variety of workloads. This can, however, lead to sub-optimal performance and power dissipation for certain programs or specific execution phases of a program.</p><p>With the ever-increasing need for performance and growing importance of power efficiency, architects have proposed multi-configuration hardware that dynamically adapts to changing program requirements in order to achieve better power/performance characteristics <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b11">[12]</ref>. Similarly, on the software side, dynamic code optimization <ref type="bibr" target="#b12">[13]</ref> <ref type="bibr" target="#b13">[14]</ref> is gaining importance with the wide spread acceptance of run-time environments such as Java [15] and .NET <ref type="bibr">[16]</ref>.</p><p>In the presence of dynamically configurable hardware and software, the ability to initiate reconfiguration at the right time is essential. Because programs go through phases of execution wherein their performance is relatively stable <ref type="bibr" target="#b14">[17]</ref> <ref type="bibr" target="#b15">[18]</ref>, phase boundaries are a natural choice for performing reconfiguration (or at least determining if reconfiguration will be beneficial). Detecting phase changes accurately is thus an important aspect of dynamically adaptable systems. Furthermore, in systems where overheads associated with reconfiguration decisions are significant, program phase identification may enable reuse of configuration information for recurring phases, thereby improving performance <ref type="bibr" target="#b10">[11]</ref>[12] <ref type="bibr" target="#b16">[19]</ref>.</p><p>There have been several proposals to implicitly <ref type="bibr" target="#b12">[13]</ref> or explicitly detect program phase changes <ref type="bibr" target="#b1">[2]</ref>[10] <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b11">[12]</ref> [19] <ref type="bibr" target="#b17">[20]</ref> <ref type="bibr" target="#b18">[21]</ref>. Recently, several researchers have proposed hardware techniques aimed specifically at detecting phase changes, identifying phases and predicting phases <ref type="bibr" target="#b1">[2]</ref>[10] <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b11">[12]</ref> <ref type="bibr" target="#b16">[19]</ref>. In this work, we focus on three of these proposed schemes -the first based on working set signatures <ref type="bibr" target="#b9">[10]</ref> <ref type="bibr" target="#b10">[11]</ref>, the second based on basic block vectors <ref type="bibr" target="#b16">[19]</ref>, and the third based on a conditional branch counter <ref type="bibr" target="#b1">[2]</ref>. Because phases are not well-defined, a significant aspect of the paper is the definition of appropriate metrics for comparing these techniques.</p><p>The next section presents an overview of previously proposed techniques for detecting program phase changes. Section 3 discusses some of the issues related to the definition of program phases. It also describes various metrics used for comparing the different program phase change detection techniques (called phase detection techniques henceforth). Section 4 presents a comparison of the techniques with unbounded hardware resources. Section 5 compares practical hardware implementations based on working set signatures and accumulator tables. Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>Balasubramonian et al. <ref type="bibr" target="#b1">[2]</ref> use a conditional branch counter to detect program phase changes. The counter keeps track of the number of dynamic conditional branches executed over a fixed execution interval (measured in terms of the dynamic instruction count). Phase changes are detected when the difference in branch counts of consecutive intervals exceeds a threshold. Their scheme does not use a fixed threshold. Rather, the detection algorithm dynamically varies the threshold throughout the execution of the program.</p><p>In previous work <ref type="bibr" target="#b10">[11]</ref>, we defined a program phase to be the instruction working set of the program i.e. the set of instructions touched in a fixed interval of time. Program phase changes are detected by comparing consecutive instruction working sets using a similarity metric called the relative working set distance. Because complete working sets can be too large to efficiently represent and compare in hardware, we propose the use of lossy-compressed representations of working sets called working set signatures <ref type="bibr">[10[11]</ref>. Signatures are compared using a metric called the relative signature distance. Phase changes are detected when the relative signature distance between consecutive intervals exceeds a preset (fixed) threshold. We show that signatures as small as 32 bytes in size can be used to resolve program phases in most benchmarks studied.</p><p>Sherwood et al. <ref type="bibr">[19][20][21]</ref> propose the use of basic block vectors (BBVs) to detect program phase changes. BBVs keep track of execution frequencies of basic blocks touched in a particular execution interval. Phase changes are detected when the Manhattan distance between consecutive BBVs exceeds a preset threshold. Because entire BBVs cannot be stored in hardware, BBVs are approximated by hashing into an accumulator table containing a few large counters <ref type="bibr" target="#b16">[19]</ref>. Their results indicate that as few as 32 24-bit counters are sufficient to represent BBVs.</p><p>Huang et al. <ref type="bibr" target="#b11">[12]</ref> use subroutines to identify program phases. They propose the use of a hardware based call stack to identify program subroutines. The call stack tracks time spent in each subroutine, taking into consideration nesting of subroutines. If the time spent in a subroutine is greater than a preset threshold, it is identified as a major phase. The call stack used in their evaluation is 32 entries deep and each entry is 9 bytes wide.</p><p>HP Dynamo <ref type="bibr" target="#b12">[13]</ref>, a run-time dynamic optimization system, detects phase changes in order to flush stale translations from the cache. Dynamo stores optimized traces of the program, called fragments, in a fragment cache. In steady state most of the instructions are fetched from this fragment cache. A sharp increase in fragment formation rate indicates a phase change and is used to trigger flushing of stale fragments from the cache, making room for new ones. Unlike the previous schemes, Dynamo detects phase changes by observing an implementation dependent system characteristic. In general, such schemes can not be easily applied to configurable systems where the system characteristic being observed is a function of the configuration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Comparison Metrics</head><p>The existence of program phases has intuitive appeal -but in practice phases are not easily determined, or even easily defined. Program phase behavior is a result of control passing through procedures and nested loop structures Consequently, program phases have a fractal-like self-similar behavior i.e. high-level (long duration) phases are composed of several lower-level (shorter duration) phases, and in the limit each instruction is a separate phase. In essence, there are no absolute phases and phase behavior can only be observed with respect to a certain granularity. Hind et al. arrive at a similar conclusion based on formal analysis of phases and the phase detection problem <ref type="bibr" target="#b19">[22]</ref>. Hence, phase detection methods do not literally detect phase changes; rather, they detect changes in program behavior that are assumed to result from phase changes. Nevertheless, we use the term "phase detection techniques" when describing them.</p><p>Phase detection techniques typically divide program execution into fixed-length sampling intervals (measured in terms of dynamic instructions executed). Programrelated information is collected over the sampling interval and compared with similar information collected over the previous interval. If the two differ by more than a difference threshold (∆ th ), a phase change (or transition) is indicated. In general, the type of program information collected is implementation independent, i.e. it is a function of the dynamic instruction stream, not of performance.</p><p>A sequence of two or more intervals containing no indicated phase changes is defined as a stable region. A maximal length stable region is defined to be a stable phase. Sequences of one or more intervals that do not belong to stable phases are called unstable regions. In other words, all the individual intervals belonging to an unstable region are separated by phase changes.</p><p>Comparison of phase detection techniques is complicated because, as stated above, there are no absolute phases, and thus there is no golden standard that techniques can be compared against. Consequently, we compare phase detection techniques using a variety of metrics that have some practical appeal. Because the goal of this work is to compare hardware based phase detection techniques, we use metrics that are mostly relevant to dynamic optimization and tuning algorithms for adapting multiconfiguration hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Sensitivity and False Positives</head><p>Program phase detection techniques have been used in power/performance optimization algorithms <ref type="bibr" target="#b1">[2]</ref>[10] <ref type="bibr" target="#b10">[11]</ref> [12] <ref type="bibr" target="#b16">[19]</ref> and to reduce simulation time of benchmarks by identifying sections of code whose performance is representative of the entire benchmark <ref type="bibr" target="#b17">[20]</ref> <ref type="bibr" target="#b18">[21]</ref>. Thus, one of the desirable properties in a phase detection mechanism is the ability to detect a phase change that results in a significant performance change.</p><p>We quantify this property with a metric called sensitivity <ref type="bibr" target="#b20">[23]</ref>. Sensitivity is defined as the fraction of intervals with significant performance changes (with respect to the preceding interval), which were also indicated to be phase changes by the phase detection mechanism. It should be noted that "significant performance change" is a relative term. In this work, a performance change of 2% is considered significant unless stated otherwise. Consider an example program execution, which consists of 1000 intervals, of which 100 intervals show a significant performance change with respect to the preceding interval. If the phase detection mechanism indicates a phase change in 75 of these 100 intervals, the sensitivity is 75%. If it indicates a change for all 100 intervals, then the sensitivity is 100%. Note that if a phase change were to be indicated for each of the 1000 intervals, the sensitivity would still be 100% because all the significant performance changes were in fact detected.</p><p>The instance just given indicates that we must also consider the flip side to sensitivity: the fraction of false positives <ref type="bibr" target="#b20">[23]</ref>. The fraction of false positives is the fraction of intervals where the performance shows no significant change but the phase detection technique indicates a phase change. Continuing with the previous example -of the 900 intervals where no significant performance change occurs, if the phase detection scheme indicates a change in 90 intervals, then the fraction of false positives is 10%. In the extreme case where all intervals are indicated as phase changes, there are 100% false positives.</p><p>High sensitivity is desirable in tuning algorithms because it exposes more tuning opportunities leading to better power/performance characteristics. On the other hand, a large fraction of false positives can cause unnecessary reconfigurations which can lead to significant performance loss and increase in power. Thus, a good phase detection technique should have high sensitivity and a small fraction of false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Stability and Average Phase Length</head><p>Attempting to tune and reconfigure in unstable regions can lead to unpredictable, non-optimal results. Consequently, algorithms such as the ones proposed in <ref type="bibr" target="#b9">[10]</ref> <ref type="bibr" target="#b10">[11]</ref> do not perform tuning while in unstable regions. Tuning algorithms can thus benefit if a large part of program execution is spent in stable phases. We quantify this with a metric called stability, which is defined as the fraction of intervals that belong to stable phases.</p><p>Most tuning algorithms use trial-and-error mechanisms to arrive at the optimal configuration. That is, they simply try a series of different configurations and determine the best one. These algorithms require several intervals at the beginning of a stable phase to complete the tuning process (the algorithm presented in <ref type="bibr" target="#b11">[12]</ref> is an exception). If phases are short (i.e. small number of intervals), tuning never completes. Also, short phases make it difficult to amortize reconfiguration overheads associated with the tuning process. Thus, the average phase length is an important metric -defined as the number of intervals that are part of stable phases, divided by the total number of stable phases.</p><p>It should be noted that two programs with the same stability can have different average phase lengths. For example, if a program runs for 1000 intervals divided into two length 500 stable phases, the stability is 100% and the average phase length is 500 intervals. However, if the phase changes at the end of every other interval, the stability is still 100% but the average phase length is two. These metrics should therefore be used in conjunction with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Performance Variance</head><p>Because most tuning algorithms are based on the assumption that performance is uniform within a phase, the performance variance within a phase can be used as a metric. A good phase detection method should be able to resolve phases with a relatively small variance in performance, compared to the variance across the whole program. A small variance is an indicator that the phase detection mechanism is detecting phase boundaries correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Correlation</head><p>Correlation between phase detection techniques can be useful for comparing their relative ability to detect phase changes. We define correlation between two phase detection techniques as the fraction of intervals for which they agree on the presence or absence of a phase change. If the techniques are highly correlated, then the technique with the simplest implementation is preferable. In the absence of high correlation, the choice of techniques must be based on one or more of the metrics defined above and other advantages associated with the technique and where it is being applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Performance with Unbounded Resources</head><p>Before comparing hardware based phase detection techniques, we evaluate their limits by comparing techniques based on unbounded working sets, BBVs, and conditional branch counters. In addition to instruction working set based techniques <ref type="bibr" target="#b9">[10]</ref>[11], we evaluate branch and procedure working set based techniques.</p><p>We equalize the granularity of these techniques by choosing a common sampling interval of 10 million instructions. In the course of this research, we tried other sampling intervals, and did not find any qualitative difference in our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Basic Definitions</head><p>The instruction working set is defined as the set of instructions touched over the sampling interval. Similarly, branch/procedure working sets are defined as the set of branches/procedures touched over the sampling interval. In previous work <ref type="bibr" target="#b9">[10]</ref>[11], we defined a similarity metric called the relative working set distance, to compare working sets. The relative working set distance between intervals i and i-1 is defined as</p><formula xml:id="formula_0">1 - i 1 - i i 1 - i i 1 , W W W W W W U I U − = ∆ − i i</formula><p>where W i and W i-1 are working sets collected over intervals i and i-1. The Norm of the set is the number of elements in the set i.e. the cardinality of the set. Since the relative working set distance is a normalized metric, the maximum possible working set difference is 100%.</p><p>Sherwood et al. <ref type="bibr" target="#b17">[20]</ref> define a BBV to be a set of counters, each of which counts the number of times a static basic block is entered in a given execution interval. In later work <ref type="bibr" target="#b16">[19]</ref>, they approximate the BBV with an array of counters, where each counter tracks the number of instructions executed by a basic block in a given execution interval. In this study, we use the latter definition for a BBV as it relates more closely to the hardware implementation. The BBV difference between intervals i and i-1 is given by the Manhattan distance</p><formula xml:id="formula_1">∑ ∞ = − − − = ∆ 0 , 1 , 1 , j j i j i i i count count</formula><p>where each distinct value of j represents a unique basic block.</p><p>Phase changes are defined with respect to a difference threshold (∆ th ) i.e. a phase change is indicated when ∆ i,i-1 &gt; ∆ th . In order to compare the techniques, we normalize the BBV and branch count differences to 100%. This is done by dividing the differences by the maximum possible difference, which is 2N for BBVs and N for branch counts, where N is the number of instructions in the sampling interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison</head><p>We evaluate phase detection techniques, using a modified version of sim-outorder, an out-of-order simulator provided as part of the SimpleScalar toolset <ref type="bibr" target="#b21">[24]</ref>. The microarchitecture parameters used for performance measurements are shown in Table <ref type="table" target="#tab_0">1</ref>. The results presented are averaged over all SPEC 2000 benchmarks <ref type="bibr" target="#b22">[25]</ref> with the exception of sixtrack and facerec. The latter two could not be run due to shortcomings of the simulation environment. Reference inputs have been used for each benchmark and due to time and resource constraints, each benchmark was run to completion or 15 billion instructions. As mentioned before, a sampling interval of 10 million instructions was used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Sensitivity and False Positives</head><p>Sensitivity and false positives are typically at odds with each other and are a strong function of the difference threshold. We use Receiver Operating Characteristic (ROC) analysis to arrive at difference thresholds for comparing the different techniques. ROC analysis is a widely used technique for analyzing medical tests, which have similar sensitivity and false positive tradeoffs <ref type="bibr" target="#b23">[26]</ref>. The ROC curve is a plot of the sensitivity versus false positives for various difference thresholds. In general, the best technique is the one which achieves maximum sensitivity for a given number of false positives.</p><p>Fig. <ref type="figure" target="#fig_1">1</ref> shows ROC curves for the different phase detection techniques. These curves are based on the assumption that a significant CPI (cycles per instruction) change is one of more than 2%, i.e. the sensitivity is computed as the fraction of intervals where a CPI change of more than 2% is indicated as a phase change. False positives are computed as the fraction of intervals where the CPI changes by less than 2%, but a phase change is indicated.</p><p>Both sensitivity and false positives increase with decreasing difference thresholds because as the threshold is reduced, even minor fluctuations in CPI are noticed. In order to compare the different techniques, we choose difference thresholds corresponding to the knees of the curves. The reasoning is that beyond the knee, a small increase in sensitivity comes at the expense of a large number of false positives. Moreover, we also try to equal-ize the false positives to make clear comparisons among methods. We arrive at difference thresholds of 4% for the BBV, instruction, and branch working set techniques; 2% for the procedure working set technique and 0.08% for the conditional branch counter based technique. This choice of thresholds leads to about 30% false positives for each technique.</p><p>It is evident that BBVs perform the best -with a sensitivity of 82%, followed by conditional branch counter (74%) and working set techniques (70%). The working set techniques do not perform well because they do not keep track of instruction (or branch/procedure) execution frequencies. Consequently, the maximum sensitivity achievable (∆th = 0) by the instruction working set technique is limited to 81%.</p><p>Amongst the working set methods, the procedure based method shows slightly lower sensitivity than the other two. This is expected because it fails to detect phase changes within procedures. Results show that the procedure based working set method achieves a maximum sensitivity of only 68% compared to 81% achieved by the instruction working set method. This is a fundamental problem with procedure based phase detection methods.</p><p>Redefining a "significant CPI change" leads to qualitatively similar results for BBV and working set based techniques. Fig. <ref type="figure" target="#fig_0">2</ref> shows ROC curves assuming that a CPI change of 10% (rather than 2%) is significant. The curves are similar to those in Fig. <ref type="figure" target="#fig_1">1</ref> except that each technique achieves higher sensitivity for a given number of false positives and the difference in sensitivity between the BBV and working set methods decreases. This is to be expected because a 10% change in CPI is more easily detected compared to a 2% change. A more interesting result is that in this case the working set based techniques work better than the conditional branch counter based technique, if the fraction of false positives is limited to less than 40%. This means that the working set based techniques are more efficient at detecting major phase changes, a result in agreement with our previous results <ref type="bibr" target="#b10">[11]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Stability and Average Phase Length</head><p>Fig. <ref type="figure" target="#fig_2">3</ref> shows, for BBV and working set methods, how stability and average phase length vary with respect to the difference threshold. Fig. <ref type="figure" target="#fig_3">4</ref> shows the same for the conditional branch counter method. Clearly, the stability of each method increases with the difference threshold because fewer changes are detected due to reduced sensitivity (see Fig. <ref type="figure" target="#fig_1">1</ref>). For the difference thresholds chosen for comparison in the previous section (circled in the figure) the working set based methods achieve slightly greater stability (64%) compared to the BBV (62%) and conditional branch counter (63%) based schemes.</p><p>The average phase length roughly increases with the difference threshold because small perturbations in program behavior are not indicated as phase changes. For the chosen difference thresholds, instruction and branch working set techniques lead to 30% longer phases on average compared to BBVs and 38% longer phases on average compared to the conditional branch counter technique. Given that the stability shown by each of these techniques is similar, using BBVs or branch counts leads to a larger number of shorter phases. This may not be desirable for tuning algorithms with large performance overheads associated with reconfiguration.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Performance Variance</head><p>Although large average phase lengths are desirable, the performance stability within a phase is also important. Fig. <ref type="figure" target="#fig_4">5</ref> shows the percent coefficient of variance (standard deviation/average) in CPI within stable phases, averaged over all benchmarks. The difference thresholds used were the ones arrived at in Sec. 4.2.1. Each of the techniques achieved less than 2% variance in CPI within stable phases as compared to a 116% CPI variance across all intervals (i.e. including unstable regions). Interestingly, the conditional branch counter technique performs the worst with a CPI variance of 1.6%, although its sensitivity is higher than any of the working set techniques. This means that the technique detects more relatively small phase changes and misses some of the larger phase changes compared to the working set techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Correlation</head><p>Because BBVs perform better than the other techniques on most metrics, we compute correlation between the BBV technique and each of the other techniques. The difference thresholds used were the ones arrived at in Sec. 4.2.1. The instruction and branch working set schemes show 85% correlation, while the procedure working set and conditional branch counter based schemes show 80% and 83% correlation respectively. Since each of the techniques agrees with the BBV technique more than 80% of the time, an important question is -do they agree on most of the major phase changes? To answer this question, we compare the BBV and instruction working set techniques in more detail (Fig. <ref type="figure" target="#fig_5">6</ref>). The first set of four bars in Fig. <ref type="figure" target="#fig_5">6</ref> show respectively, the percent of time the two techniques agree on the presence or absence of a phase change (agree), the percent of time they disagree (disagree), the percent of time the BBV technique indicates a change but the instruction working set technique does not (bbv_change_only) and the percent of time the instruction working set technique indicatess a change but the BBV technique does not (wset_change _only). The next four sets of bars show the average rela-tive change in performance metrics (CPI; data and L2 cache miss rates; branch misprediction rate) for each of these four events (agree, disagree, bbv_change_only, west_change_only). We do not include instruction cache miss rates because being close to zero they cause very large relative changes that cannot be well represented on this graph. Note that for the performance metrics, the agree case consists only of events where both techniques indicate a phase change, i.e. it does not contain cases where both agree that there is no phase change.</p><p>As seen from the figure, the BBV and the instruction working set technique agree about 85% of the time. Of the 15% of the time they disagree, they are split roughly equally. Focusing on the first two bars in each set of performance metrics, it is evident that the relative performance change seen when both the methods agree on a change is much higher than the relative change seen when they disagree. This means that most of the major phase changes are detected by both methods.</p><p>In cases where the two techniques disagree, the relative change in performance seen when only the BBV indicates a phase change (third bar in each set) is higher than the relative change seen when only the working set method indicates a change (fourth bar in each set). This means that the BBV based technique is better at detecting changes in performance. This is expected because the BBV inherently contains much more information compared to the instruction working set. However, it should be noted that this happens less than 9% of the time on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Hardware Implementations</head><p>The previous section compared the performance of BBV, working set and conditional branch count techniques using unbounded hardware resources. In practice, BBVs and working sets are too large to be efficiently stored and compared in hardware. In previous work <ref type="bibr" target="#b9">[10]</ref> <ref type="bibr" target="#b10">[11]</ref>, we proposed a hardware structure called the working set signature, which is a compact representation of the working set. Similarly, Sherwood et al. <ref type="bibr" target="#b16">[19]</ref> proposed an array of accumulators (counters) called the accumulator table to represent BBVs. In this section, we compare the performance of these hardware implementations. The hardware implementation for a conditional branch counter is equivalent to its unbounded implementation for the interval sizes studied, and thus is not discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Hardware Structures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Working Set Signature</head><p>A working set signature is a lossy-compressed representation of the complete working set <ref type="bibr" target="#b9">[10]</ref> <ref type="bibr" target="#b10">[11]</ref>. The signature is formed by sampling the working set i.e. program ) and hashing the samples into an n-bit vector using a random hash function (Fig. <ref type="figure" target="#fig_7">7</ref>). The signature is reset at the beginning of each interval to remove stale working set information.</p><p>Phase changes are detected by comparing consecutive signatures using the relative signature distance defined as</p><formula xml:id="formula_2">∆ = 2 1 2 1 S S S S + ⊕ , i.e.</formula><p>(ones count of exclusive OR of signatures)/(ones count of inclusive OR of signatures). If the relative signature distance is greater than a preset threshold, a phase change is indicated. We propose the use of virtual machine software to compute the relative signature distance <ref type="bibr">[10][11]</ref>. However, it can also be done in hardware. The signature fill-factor depends on the signature size as well as the working set size. Large working sets can saturate small working set signatures. In order to reduce the pressure on instruction working set signatures, the PCs are shifted by a few bits thereby reducing the number of unique elements that are hashed. In this work, we shift PCs by five bits, which is equivalent to sampling blocks of eight instructions. Shifting may not be necessary for branch and procedure working set signatures because only 20 -25% of committed instructions are branches and a mere 1 -2% are procedure entry points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Accumulator Table</head><p>The accumulator table (Fig. <ref type="figure">8</ref>) is an array of counters indexed by hashing branch PCs. Whenever a branch PC is encountered, the corresponding counter is incremented by the number of instructions committed since the last branch. The accumulator table collects samples over a fixed interval of instructions and is reset at the beginning of each interval.</p><p>To prevent overflow, each accumulator is made large enough to be able to count up to the number of instructions in the interval. For example, if the interval is 10 million instructions, then each accumulator is 24-bits wide. Phase changes are detected by comparing consecutive arrays using a Manhattan distance metric (see Sec. 4.1). If the distance is greater than a preset threshold, a phase change is indicated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 8. Accumulator table update mechanism.</head><p>Branch PC is hashed into the table and the corresponding counter is incremented with the number of instructions committed since the last branch. Hash function used is pseudo-random.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Design Space</head><p>In this work, we study three different sizes for each of the hardware based phase detection techniques. The sizes for instruction/branch signatures (4096, 1024, 512 bits) and accumulator tables (1024, 128, 32 entries) are similar to those used in previous work <ref type="bibr" target="#b9">[10]</ref>[11] <ref type="bibr" target="#b16">[19]</ref>. Procedure signature sizes were chosen to be 1024, 256 and 64 bits because procedure working sets are much smaller compared to corresponding instruction/branch working sets. These hardware techniques, along with the unbounded cases considered in the previous section, span a wide design space as shown in Fig. <ref type="figure" target="#fig_8">9</ref>. Each technique can be categorized in terms of the number of counters and the number of bits in each counter. The unbounded BBV  Adder # instructions 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># counters # bits in counter</head><formula xml:id="formula_3">0 1 1 0 0 0 1 0 0 0 H Shifted PC Signature 0 1 1 0 0 0 1 0 0 0 H Shifted PC 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 H Shifted PC</formula><p>Signature contains maximum information with unbounded counters each with an unbounded number of bits, the accumulator tables have a small number of unbounded counters and finally the conditional branch counter based scheme has one unbounded counter, although it counts only conditional branches. The working set based techniques form a similar spectrum albeit with a larger number of single-bit counters. It should be noted that accumulator table counters have a bounded number of bits, but they are considered unbounded because they are large enough to prevent overflows for a given sampling interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparison</head><p>Fig. <ref type="figure" target="#fig_10">10</ref> shows the correlation of each of the hardware based techniques with the corresponding unbounded case i.e. instruction working set signatures are compared to complete instruction working sets, accumulator tables to BBVs, etc. The difference threshold used is 4% for the instruction and branch working set signatures, 2% for the procedure working set signature and 4% for the accumulator table. (see Sec. 4.2.1.)</p><p>It is evident that the hardware schemes are highly correlated with their corresponding unbounded schemes. As the number of bits/entries is reduced, the correlations drop off mainly due to increased aliasing. However, the smallest size hardware structure still correlates more than 90% of the time (in each case) with the unbounded scheme. It is worth comparing the accumulator table with an equivalent instruction working set signature. We consider the smallest accumulator table i.e. 32 entries, since it shows reasonably high correlation with BBVs. To prevent overflow for a sampling interval of 10 million instructions, each of the accumulators should be at least 24-bits wide. This translates to a total of 32*24 = 768 bits. This is comparable in area to a 1024-bit signature taking into account the extra sense amplifiers and fast adder(s) required by the accumulator table. Correlation between the 32-entry accumulator table and 1024-bit instruction working set signature showed results similar to those given in Fig. <ref type="figure" target="#fig_5">6</ref> and thus are not repeated. The two hardware techniques correlate 87% of the time and the change in performance metrics when the techniques agree is much higher than the change when they disagree. This means that both techniques agree on major phase changes. This is not surprising given the fact that both these techniques are highly correlated to their unbounded cases and a similar observation was made there.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1.">Conditional Branch Counter</head><p>Sherwood et al. <ref type="bibr" target="#b16">[19]</ref> evaluated the performance of accumulator tables by using a metric called the visible phase difference. The visible phase difference is the ratio of the phase difference (Manhattan distance) observed using the accumulator table, to the phase difference observed using unbounded BBVs. The visible phase difference of the unbounded BBV is 100%.</p><p>The accumulator table size for their algorithms was chosen to be 32 entries, because the visible phase difference achieved by using 32 entries is 72%. However, this is not necessarily a good metric to use because phase changes are detected based on a difference threshold and as long as the phase difference is above threshold, it does not matter what the visible phase difference is. As an example, if the difference threshold is 10% and the unbounded BBV shows a phase difference of 90%, it does not matter if the phase difference achieved by the accumulator table is 80% or 25% because a phase change is detected in both cases. This explains why the 32-counter method agrees with the unbounded BBV 93% of the time even when results from <ref type="bibr" target="#b16">[19]</ref> show that it achieves a visible phase difference of only 70%.</p><p>This means that perhaps an even smaller number of counters can provide reasonable phase detection ability. In fact, the conditional branch counter <ref type="bibr" target="#b1">[2]</ref>, which is an extreme example with a single counter, works quite well correlating 83% of the time with the unbounded BBV scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Other Considerations</head><p>Because the hardware schemes discussed in the previous section correlate (agree) most of the time, the decision to use a particular technique may be based on other considerations such as hardware complexity and additional attributes that may be useful for tuning algorithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1.">Hardware Complexity</head><p>The hardware used in the conditional branch counter scheme is clearly the simplest and warrants no further discussion. The working set signature requires a 1-bit wide RAM array with one read/write port. The instruction sampling hardware samples each instruction (at most 4 in a 4-wide superscalar) and hashes it to get the signature bit to be set. One possible optimization is to sample only one instruction every two to four cycles. We have seen that this periodic sampling technique works reasonably well because the signature only tracks the number of static instructions touched and not the number of times they were touched. This can simplify the hardware significantly and make it amenable to a slow-transistor implementation, thereby saving power.</p><p>The accumulator table uses a 24-bit wide RAM array, with one read and one write port. Separate read and write ports may be needed for throughput reasons. The sampling hardware is more complex than that used in the working set signatures as it has to analyze the retire stream to detect positions of branches and increment counters appropriately. Moreover, since the Manhattan distance is based on instruction counts, dropping samples may not advisable, thus making fast hardware essential. Additionally, the accumulator table also requires a fast 24-bit adder to update the accumulators.</p><p>is clear that the accumulator table is more complex and less power efficient compared with the signature method. However, it should also be noted that neither of these schemes would form an appreciable fraction of hardware in a modern microprocessor, and thus their small contribution to power dissipation/ complexity may not be a concern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2.">Recurring Phase Identification</head><p>The ability to identify recurring phases is a desirable attribute in phase detection techniques. This property can be used in tuning algorithms to reuse previously found optimal configurations for recurring phases <ref type="bibr" target="#b9">[10]</ref>[11] <ref type="bibr">[12] [19]</ref>. This eliminates a significant fraction of reconfigurations, leading to performance improvements. In our previous work <ref type="bibr" target="#b10">[11]</ref>, we show that phase-identification based algorithms can reduce reconfigurations by as much 92% over a subset of SPEC 2000 integer benchmarks.</p><p>Working set signatures and BBVs have been shown to identify recurring program phases <ref type="bibr">[10][11][19]</ref>. Whether conditional branch counters can be used to identify recurring phases remains to be shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3.">Estimating Working Set Size</head><p>Working set signatures have an added advantage that they can be used to estimate the working set size directly <ref type="bibr" target="#b10">[11]</ref>. The working set size k can be estimated from the fill factor f (number of ones) of the signature using the relation</p><formula xml:id="formula_4">k = ) 1 1 log( ) 1 log( n f − −</formula><p>, where, n is the signature size. In cases where performance of a unit is directly related to the working set size (e.g. instruction and data caches) signatures can be used to determine the optimal configuration without going through a tuning process. This has been shown to reduce the number of reconfigurations by 74% in a particular instruction cache tuning algorithm <ref type="bibr" target="#b10">[11]</ref>.</p><p>However, it should be noted that to make use of this property, the signature should capture the same working set that the unit performance is dependent on. For example, instruction working set signatures can be used to configure instruction caches but not data caches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>The BBV based technique provides better sensitivity and lower performance variation in phases compared to the other techniques. The instruction and branch working set techniques have similar performance on each of the metrics described. These techniques are less sensitive than the BBV technique mainly because working sets contain less information compared to BBVs. However, the instruction working set technique provides slightly higher stability and achieves 30% longer phases on average compared to the BBV technique. This can benefit trial and error based tuning algorithms. On average, the BBV and instruction working set schemes agree on phase changes 85% of the time. Of the 15% time they disagree, the BBV is more efficient at detecting important performance changes. As an auxiliary result, we show that procedure working set based techniques do not perform quite as well as the other working set based methods. This is mainly due to their inability to detect phase changes within procedures.</p><p>One of the surprising results of this study is that a simple conditional branch counter scheme performs quite well and agrees with the unbounded BBV scheme 83% of the time. However, it does lead to shorter average phase lengths and higher performance variance within phases compared with the BBV and working set schemes. This indicates that the branch counter based technique fails to detect some of the major phase changes.</p><p>Finally, we find that the hardware schemes i.e. working set signatures and the accumulator table approximate their corresponding unbounded cases (working sets and BBV) very closely, correlating more than 90% of the time even for the smallest structures considered. Also, equivalent sized instruction working set signatures and accumulator tables agree on phase changes 87% of the time.</p><p>Given the high correlation between these techniques, the choice of technique may be guided by other considerations. While the conditional branch counter is the simplest to implement, signatures and accumulator tables can be used to identify recurring phases -leading to more efficient tuning algorithms. Signatures also provide the added advantage that they can be used to estimate certain working set sizes and immediately configure the corresponding microarchitectural units such as caches.</p><p>Finally, in this work, we dealt with a very large design space composed of several variables including sampling intervals, difference thresholds, and hardware sizes. Admittedly, the results therefore represent a very small slice of the design space. On the other hand, in the process of conducting this research we did simulate a large number of variations and found the results to be qualitatively similar to those reported here.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. ROC curves for the various phase detection techniques are shown. CPI changes of more than 10% are considered significant. (See Fig. 1 caption for more details)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. ROC curves for the various phase detection techniques are shown. CPI changes of more than 2% are considered significant. Difference thresholds (∆ ∆ ∆ ∆ th ) increase from right to left. IWSET, BWSET and PWSET represent instruction, branch and procedure working set techniques respectively. BR_CNT represents the conditional branch counter technique. The figure on the right shows a magnified view of the shaded part of the left figure. The circled points are chosen for comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Variation of stability and average phase length with respect to the difference threshold. The phase length is shown in terms of number of intervals. The circled points correspond to the difference thresholds used for comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Stability (primary axis) and average phase length (secondary axis) with respect to difference threshold, for the conditional branch counter technique. The circled points correspond to difference thresholds used for comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Average CPI variance within stable phases. Difference thresholds used were 4% for BBV, instruction and branch working sets, 2% for procedure working set, and 0.08% for the conditional branch counter technique.Using BBVs leads to least performance variance (0.65%) within phases. Instruction and branch working set techniques achieve just less than 1% variance. Using procedure working sets leads to 1.4% variance which</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. A comparison of BBV and instruction working set schemes. The first set of four bars (correlation) shows the fraction of time that the two techniques agree, disagree, only BBV detects a change and only working set detects a change. The remaining four sets show the relative change in CPI; data and L2 cache miss rates and branch misprediction rates for each of the four types of events described above.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>) over a fixed interval of instructions (e.g. 10 million</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Working set signature mechanism. PCs, shifted by a few bits, are hashed into the signature bit vector and the corresponding entries are set. The hash function used is pseudo-random.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. The position of each of the techniques in the design space is shown. The X-axis represents the number of counters used to capture information. The Y-axis shows the number of bits used in each counter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. The correlation of each hardware scheme with the corresponding unbounded scheme is shown. The figure shows correlations for three different sizes of instruction and branch working set signatures (4096, 1024, 512), procedure working set signatures (1024, 256, 64) and accumulator tables (1024, 128, 32).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Microarchitecture Parameters</head><label>1</label><figDesc></figDesc><table><row><cell>Processor</cell><cell>4-wide fetch/decode/issue/commit; 64-entry RUU, 32-</cell></row><row><cell>core</cell><cell>entry LSQ; 4 integer ALUs, 1 integer multiplier; 4 FP</cell></row><row><cell></cell><cell>ALUs, 1 FP multiplier;</cell></row><row><cell>Branch Prediction</cell><cell>4K entry gshare, 10-bit global history; 2K entry, 2-way BTB; 32 entry RAS</cell></row><row><cell>Memory subsystem</cell><cell>I and D-cache: 32KB, 2-way, 64 byte line, latency 1 cycle; unified L2-cache: 512KB 4-way, 128 byte line, latency 6 cycles; memory: width 16-byte, latency 100</cell></row><row><cell></cell><cell>cycles</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Hardware vs Unbounded Correlations 0 20 40 60 80 100 insn sign branch sign proc sign acc table Correlation (%) large medium small</head><label></label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgements</head><p>This work is being supported by an NSF grant CCR-0311361, SRC grant 2000-HJ-782, Intel and IBM.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dynamic IPC/clock rate optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25 th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 25 th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-06">Jun. 1998</date>
			<biblScope unit="page" from="282" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Memory hierarchy reconfiguration for energy and performance in general purpose architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dwarkadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 33 rd Annual Intl. Sym. on Microarchitecture</title>
				<meeting>of the 33 rd Annual Intl. Sym. on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2000-12">Dec. 2000</date>
			<biblScope unit="page" from="245" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An integrated circuit/architecture approach to reducing leakage in deep submicron high-performance Icaches</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Vijaykumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 7 th Intl. Sym. on High Performance Computer Architecture</title>
				<meeting>of the 7 th Intl. Sym. on High Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-01">Jan. 2001</date>
			<biblScope unit="page" from="147" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reconfigurable caches and their application to media processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27 th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 27 th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2000-06">Jun. 2000</date>
			<biblScope unit="page" from="214" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dynamic historylength fitting: a third level of adaptivity for branch prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanjeevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25 th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 25 th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-06">Jun. 1998</date>
			<biblScope unit="page" from="155" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Energy-effective issue logic</title>
		<author>
			<persName><forename type="first">D</forename><surname>Folegnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 28 th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 28 th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-06">Jun. 2001</date>
			<biblScope unit="page" from="230" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Energy efficient co-adaptive instruction fetch and issue</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Karkhanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 30th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 30th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">Jun. 2003</date>
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Power and energy reduction via pipeline balancing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 28th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 28th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-07">Jul. 2001</date>
			<biblScope unit="page" from="218" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A framework for dynamic energy efficiency and temperature management</title>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 33rd Annual Intl. Sym. on Microarchitecture</title>
				<meeting>of the 33rd Annual Intl. Sym. on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2000-12">Dec. 2000</date>
			<biblScope unit="page" from="202" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamic microarchitecture adaptation via co-designed virtual machines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Dhodapkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Solid State Circuits Conference, Digest of Technical Papers</title>
				<imprint>
			<date type="published" when="2002-02">2002. Feb. 2002</date>
			<biblScope unit="page" from="198" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Managing multiconfiguration hardware via dynamic working set analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Dhodapkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 29 th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 29 th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Positional adaptation of processors: application to energy reduction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Renau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 30 th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 30 th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">Jun. 2003</date>
			<biblScope unit="page" from="157" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamo: A transparent dynamic optimization system</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duesterwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Banerjia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation</title>
				<meeting>of the Conf. on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive Optimization in the Jalapeno JVM</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Object-Oriented Programming Systems, Languages, and Applications</title>
				<meeting>of the ACM Conference on Object-Oriented Programming Systems, Languages, and Applications</meeting>
		<imprint>
			<date type="published" when="2000-10">Oct. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Time varying behavior of programs</title>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<idno>UCSD- CS99-630</idno>
		<imprint>
			<date type="published" when="1999-08">Aug. 1999</date>
		</imprint>
	</monogr>
	<note type="report_type">UC San Diego Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">SPEC CPU2000 memory footprint</title>
		<author>
			<persName><forename type="first">J</forename><surname>Henning</surname></persName>
		</author>
		<ptr target="http://www.spec.org/cpu2000/analysis/memory" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Phase tracking and prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 30 th Annual Intl. Sym. on Computer Architecture</title>
				<meeting>of the 30 th Annual Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">Jun. 2003</date>
			<biblScope unit="page" from="336" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Basic block distribution analysis to find periodic behavior and simulation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Intl. Conf. on Parallel Architectures and Compilation Techniques</title>
				<meeting>of the Intl. Conf. on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2001-09">Sep. 2001</date>
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 10 th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>of 10 th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2002-10">Oct. 2002</date>
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Phase shift detection: a problem classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Sweeney</surname></persName>
		</author>
		<idno>RC-22887</idno>
		<imprint>
			<date type="published" when="2003-08">Aug. 2003</date>
		</imprint>
	</monogr>
	<note type="report_type">IBM Research Report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Confidence estimation for speculation control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pleszkun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25 th Intl. Sym. on Computer Architecture</title>
				<meeting>of the 25 th Intl. Sym. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-07">July 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The SimpleScalar tool set version 2.0</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
		<idno>#1342</idno>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison Computer Sciences Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SPEC CPU2000: Measuring CPU performance in the new millennium</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2000-07">Jul. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The statistical evaluation of medical tests for classification and prediction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Pepe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
