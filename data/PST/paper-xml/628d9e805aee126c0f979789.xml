<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Language Models are Zero-Shot Reasoners</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-05-24">24 May 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
							<email>t.kojima@weblab.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Google Research</orgName>
								<address>
									<country>Brain Team</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Gu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Google Research</orgName>
								<address>
									<country>Brain Team</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Machel</forename><surname>Reid</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yutaka</forename><surname>Matsuo</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yusuke</forename><surname>Iwasawa</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Large Language Models are Zero-Shot Reasoners</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-05-24">24 May 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2205.11916v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-bystep answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding "Let's think step by step" before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted fewshot examples, e.g. increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with an off-the-shelf 175B parameter model. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted through simple prompting. We hope our work not only serves as the minimal strongest zeroshot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.</p><p>Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scaling up the size of language models has been key ingredients of recent revolutions in natural language processing (NLP) <ref type="bibr" target="#b39">[Vaswani et al., 2017</ref><ref type="bibr" target="#b6">, Devlin et al., 2019</ref><ref type="bibr" target="#b27">, Raffel et al., 2020</ref><ref type="bibr">, Brown et al., 2020</ref><ref type="bibr" target="#b38">, Thoppilan et al., 2022</ref><ref type="bibr" target="#b26">, Rae et al., 2021</ref><ref type="bibr" target="#b4">, Chowdhery et al., 2022]</ref>. The success of large language models (LLMs) is often attributed to (in-context) few-shot or zero-shot learning. It can solve various tasks by simply conditioning the models on a few examples (few-shot) or instructions describing the task (zero-shot). The method of conditioning the language model is called "prompting" <ref type="bibr">[Liu et al., 2021b]</ref>, and designing prompts either manually <ref type="bibr" target="#b32">[Schick and</ref><ref type="bibr">Sch?tze, 2021, Reynolds and</ref><ref type="bibr">McDonell, 2021]</ref> or automatically <ref type="bibr" target="#b8">[Gao et al., 2021</ref><ref type="bibr" target="#b33">, Shin et al., 2020]</ref> becomes a hot topic in NLP.</p><p>In contrast to the excellent performance of LLMs in intuitive and single-step system-1 <ref type="bibr" target="#b36">[Stanovich and West, 2000]</ref> tasks with task-specific few-shot or zero-shot prompting <ref type="bibr">[Liu et al., 2021b]</ref>, even language models at the scale of 100B or more parameters had struggled on system-2 tasks requiring slow and multi-step reasoning <ref type="bibr" target="#b26">[Rae et al., 2021]</ref>. To address this shortcoming, <ref type="bibr" target="#b41">Wei et al. [2022]</ref>,</p><p>Figure <ref type="figure" target="#fig_2">1</ref>: Example inputs and outputs of GPT-3 with (a) standard Few-shot ( <ref type="bibr">[Brown et al., 2020]</ref>), (b) Few-shot-CoT ( <ref type="bibr" target="#b41">[Wei et al., 2022]</ref>), (c) standard <ref type="bibr">Zero-shot, and (d)</ref> ours <ref type="bibr">(Zero-shot-CoT)</ref>. Similar to Few-shot-CoT, Zero-shot-CoT facilitates multi-step reasoning (blue text) and reach correct answer where standard prompting fails. Unlike Few-shot-CoT using step-by-step reasoning examples per task, ours does not need any examples and just uses the same prompt "Let's think step by step" across all tasks (arithmetic, symbolic, commonsense, and other logical reasoning tasks). <ref type="bibr" target="#b40">Wang et al. [2022]</ref> have proposed chain of thought prompting (CoT), which feed LLMs with the step-by-step reasoning examples rather than standard question and answer examples (see Fig. <ref type="figure" target="#fig_2">1-a</ref>). Such chain of thought demonstrations facilitate models to generate a reasoning path that decomposes the complex reasoning into multiple easier steps. Notably with CoT, the reasoning performance then satisfies the scaling laws better and jumps up with the size of the language models. For example, when combined with the 540B parameter PaLM model <ref type="bibr" target="#b4">[Chowdhery et al., 2022]</ref>, chain of thought prompting significantly increases the performance over standard few-shot prompting across several benchmark reasoning tasks, e.g., GSM8K (17.9% ? 58.1%).</p><p>While the successes of CoT prompting <ref type="bibr" target="#b41">[Wei et al., 2022]</ref>, along those of many other task-specific prompting work <ref type="bibr" target="#b8">[Gao et al., 2021</ref><ref type="bibr" target="#b32">, Schick and Sch?tze, 2021</ref><ref type="bibr">, Liu et al., 2021b]</ref>, are often attributed to LLMs' ability for few-shot learning <ref type="bibr">[Brown et al., 2020]</ref>, we show that LLMs are decent zero-shot reasoners by adding a simple prompt, Let's think step by step, to facilitate step-by-step thinking before answering each question (see Figure <ref type="figure" target="#fig_2">1</ref>). Despite the simplicity, our Zero-shot-CoT successfully generates a plausible reasoning path in a zero-shot manner and reaches the correct answer in a problem where the standard zero-shot approach fails. Importantly, our Zero-shot-CoT is versatile and task-agnostic, unlike most prior task-specific prompt engineering in the forms of examples (few-shot) or templates (zero-shot) <ref type="bibr">[Liu et al., 2021b]</ref>: it can facilitate step-by-step answers across various reasoning tasks, including arithmetic (MultiArith <ref type="bibr" target="#b30">[Roy and Roth, 2015]</ref>, GSM8K <ref type="bibr" target="#b5">[Cobbe et al., 2021]</ref>, AQUA-RAT <ref type="bibr" target="#b14">[Ling et al., 2017]</ref>, and SVAMP <ref type="bibr" target="#b24">[Patel et al., 2021]</ref>), symbolic (Last letter and Coin flip), commonsense reasoning (CommonSenseQA <ref type="bibr" target="#b37">[Talmor et al., 2019]</ref> and Strategy QA <ref type="bibr" target="#b9">[Geva et al., 2021]</ref>), and other logical reasoning tasks (Date understanding and Tracking Shuffled Objects from <ref type="bibr">BIG-bench [big, 2021]</ref>) without modifying the prompt per task.</p><p>We empirically evaluate Zero-shot-CoT against other prompting baselines in Figure <ref type="figure" target="#fig_2">1</ref>. While our Zero-shot-CoT underperforms Few-shot-CoT with carefully-crafted and task-specific step-by-step examples, Zero-shot-CoT achieves enormous score gains compared to the zero-shot baseline, e.g. from 17.7% to 78.7% on MultiArith and from 10.4% to 40.7% on GSM8K. Importantly, with our single fixed prompt, zero-shot LLMs have a significantly better scaling curve comparable to that of the few-shot CoT baseline. We also show that besides Few-shot-CoT requiring human engineering of multi-step reasoning prompts, their performance deteriorates if prompt example question types and task question type are unmatched, suggesting high sensitivity to per-task prompt designs. In contrast, the versatility of this single prompt across diverse reasoning tasks hints at untapped and understudied zero-shot fundamental capabilities of LLMs, such as higher-level broad cognitive capabilities like generic logical reasoning <ref type="bibr" target="#b3">[Chollet, 2019]</ref>. While the vibrant field of LLMs started out from the premise of excellent few-shot learners <ref type="bibr">[Brown et al., 2020]</ref>, we hope our work encourages more research into uncovering high-level and multi-task zero-shot capabilities hidden inside those models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>We briefly review the two core preliminary concepts that form the basis of this work: the advent of large language models (LLMs) and prompting, and chain of thought (CoT) prompting for multi-step reasoning.</p><p>Large language models and prompting A language model (LM), is a model that looks to estimate the probability distribution over text. Recently, scaling improvements through larger model sizes (from a few million <ref type="bibr" target="#b19">[Merity et al., 2016]</ref> to hundreds of millions <ref type="bibr" target="#b6">[Devlin et al., 2019]</ref> to hundreds of billions <ref type="bibr">[Brown et al., 2020]</ref> parameters) and larger data (e.g. webtext corpora <ref type="bibr" target="#b7">[Gao et al., 2020]</ref>) have enabled pre-trained large language models (LLMs) to be incredibly adept at many downstream NLP tasks. Besides the classic "pre-train and fine-tune" paradigm <ref type="bibr">[Liu et al., 2021b]</ref>, models scaled to 100B+ parameters exhibit properties conducive to few-shot learning <ref type="bibr">[Brown et al., 2020]</ref>, by way of in context learning, where one can use a text or template known as a prompt to strongly guide the generation to output answers for desired tasks, thus beginning an era of "pre-train and prompt" <ref type="bibr">[Liu et al., 2021a]</ref>. In work, we call such prompts with explicit conditioning on few task examples as few-shot prompts, and other template-only prompts as zero-shot prompts.</p><p>Chain of thought prompting Multi-step arithmetic and logical reasoning benchmarks have particularly challenged the scaling laws of large language models <ref type="bibr" target="#b26">[Rae et al., 2021]</ref>. Chain of thought (CoT) prompting <ref type="bibr" target="#b41">[Wei et al., 2022]</ref>, an instance of few-shot prompting, proposed a simple solution by modifying the answers in few-shot examples to step-by-step answers, and achieved significant boosts in performance across these difficult benchmarks, especially when combined with very large language models like PaLM <ref type="bibr" target="#b4">[Chowdhery et al., 2022]</ref>. The top row of Figure <ref type="figure" target="#fig_2">1</ref> shows standard few-shot prompting against (few-shot) CoT prompting. Notably, few-shot learning was taken as a given for tackling such difficult tasks, and the zero-shot baseline performances were not even reported in the original work <ref type="bibr" target="#b41">[Wei et al., 2022]</ref>. To differentiate it from our method, we call <ref type="bibr" target="#b41">Wei et al. [2022]</ref> as Few-shot-CoT in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Zero-shot Chain of Thought</head><p>We propose Zero-shot-CoT, a zero-shot template-based prompting for chain of thought reasoning. It differs from the original chain of thought prompting <ref type="bibr" target="#b41">[Wei et al., 2022]</ref> as it does not require step-by-step few-shot examples, and it differs from most of the prior template prompting <ref type="bibr">[Liu et al., 2021b]</ref> as it is inherently task-agnostic and elicits multi-hop reasoning across a wide range of tasks with a single template. The core idea of our method is simple, as described in Figure <ref type="figure" target="#fig_2">1</ref>: add Let's think step by step, or a a similar text (see Table <ref type="table" target="#tab_2">5</ref>), to extract step-by-step reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Two-stage prompting</head><p>While Zero-shot-CoT is conceptually simple, its subtlety is that it uses prompting twice, as explained in Figure <ref type="figure">2</ref>. This is due to the fact that the zero-shot baseline (see the bottom-left in Figure <ref type="figure" target="#fig_2">1</ref>) already uses prompting in the form of "The answer is", to extract the answers in correct formats. Few-shot prompting, standard or CoT, avoids needing such answer-extraction prompting by explicitly designing the few-shot example answers to end in such formats (see the top-right in Figure <ref type="figure" target="#fig_2">1</ref>). In summary, Few-shot-CoT <ref type="bibr" target="#b41">[Wei et al., 2022]</ref> requires careful human engineering of a few prompt examples with specific answer formats per task, while Zero-shot-CoT does not require such engineering but requires prompting LLMs twice. Figure <ref type="figure">2</ref>: Full pipeline of Zero-shot-CoT as described in ? 3: we first use the first "reasoning" prompt to extract a full reasoning path from a language model, and then use the second "answer" prompt to extract the answer in the correct format from the reasoning text.</p><p>hand-crafted trigger sentence t that would extract chain of though to answer the question x. For example, if we use "Let's think step by step" as a trigger sentence, the prompt would be "Q: [X]. A: Let's think step by step.". Prompted text x is then fed into a language model and generate subsequent sentence z. We can use any decoding strategy, but we used greedy decoding throughout the paper for the simplicity.</p><p>2nd prompt: answer extraction In the second step, we use generated sentence z along with prompted sentence x to extract the final answer from the language model. To be concrete, we simply concatenate three elements as with "</p><formula xml:id="formula_0">[X ] [Z] [A]": [X ] for 1st prompt x , [Z]</formula><p>for sentence generated at the first step, and [A] for a trigger sentence to extract answer. The prompt for this step is self-augmented, since the prompt contains the sentence z generated by the same language model. In experiment, we use slightly different answer trigger depends on the answer format. For example, we use "Therefore, among A through E, the answer is" for multi-choice QA, and "Therefore, the answer (arabic numerals) is" for math problem requiring numerical answer. See Appendix A.5 for the details. Finally, the language model is fed the prompted text as input to generate sentences ? and parse the final answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>Tasks and datasets We evaluate our proposal on 12 datasets from four categories of reasoning tasks: arithmetic, commonsense, symbolic, and other logical reasoning tasks. See Appendix A.2 for the detailed description of each datasets.</p><p>For arithmetic reasoning, we consider the following six datasets: (1) SingleEq <ref type="bibr" target="#b12">[Koncel-Kedziorski et al., 2015]</ref>, (2) AddSub <ref type="bibr" target="#b10">[Hosseini et al., 2014]</ref>, (3) MultiArith <ref type="bibr" target="#b30">[Roy and Roth, 2015]</ref>, (4) AQUA-RAT <ref type="bibr" target="#b14">[Ling et al., 2017]</ref>, (5) GSM8K <ref type="bibr" target="#b5">[Cobbe et al., 2021]</ref>, and (6) SVAMP <ref type="bibr" target="#b24">[Patel et al., 2021]</ref>. The first three are from the classic Math World Problem Repository <ref type="bibr" target="#b13">[Koncel-Kedziorski et al., 2016]</ref>, and the last three are from more recent benchmarks. SingleEq and AddSub contain easier problems, which do not require multi-step calculation to solve the tasks. MultiArith, AQUA-RAT, GSM8k, and SVAMP are more challenging datasets that require multi-step reasoning to solve.</p><p>For commonsense reasoning, we use CommonsenseQA <ref type="bibr" target="#b37">[Talmor et al., 2019]</ref> and StrategyQA <ref type="bibr" target="#b9">[Geva et al., 2021]</ref>. CommonsenseQA asks questions with complex semantics that often require reasoning based on prior knowledge <ref type="bibr" target="#b37">[Talmor et al., 2019]</ref>. StrategyQA requires models to infer an implicit multi-hop reasoning to answer questions <ref type="bibr" target="#b9">[Geva et al., 2021]</ref>.</p><p>For symbolic reasoning, we use Last Letter Concatenation and Coin Flip <ref type="bibr" target="#b41">[Wei et al., 2022]</ref>. Last letter Concatenation asks the model to concatenate the last letters of each word. We used randomly selected four names for each sample. Coin flip asks the model to answer whether a coin is still heads up after people either flip or do not flip the coin. We created samples of four times flip or do not flip trials. Although these tasks are easy for humans, language models typically exhibit a flat scaling curve.</p><p>For other logical reasoning tasks, we choose two evaluation sets from the BIG-bench effort <ref type="bibr">[big, 2021]</ref>: Date Understanding<ref type="foot" target="#foot_0">1</ref> and Tracking Shuffled Objects. Date Understanding asks models to infer the date from a context. Tracking Shuffled Objects tests a model's ability to infer the final state of objects given its initial state and a sequence of object shuffling. We used a dataset of tracking three shuffled objects for our experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>We experiment with 13 models in total: Instruct-GPT3 <ref type="bibr" target="#b22">Ouyang et al. [2022]</ref> and GPT3 with four different model sizes (ada, babbage, curie, and davinci) 2 , GPT-2, GPT-Neo, GPT-J, T0 <ref type="bibr" target="#b31">[Sanh et al., 2022]</ref>, and OPT <ref type="bibr" target="#b44">[Zhang et al., 2022]</ref>. The size of LMs ranges from 0.3B to 175B. We include both standard (e.g. GPT-3 and OPT), and instruction following variants (e.g. Instruct-GPT3 and T0). See Appendix A.3 for details of model description. Without mentioning otherwise, we use Text-davinci-002 throughout the experiments.</p><p>Baselines We compare our Zero-shot-CoT mainly to standard Zero-shot prompting to verify the effectiveness of its chain of thought reasoning. For Zero-shot experiments, similar answer prompts as Zero-shot-CoT are used as default. See Appendix A.5 for detail. To better evaluate the zero-shot ability of LLMs on reasoning tasks, we also compare our method to Few-shot and Few-shot-CoT baselines from <ref type="bibr" target="#b41">[Wei et al., 2022]</ref>, using the same in-context examples. Throughout the experiments, we use greedy decoding across all the methods. For the zero-shot approaches, the results are therefore deterministic. For the few-shot approaches, since the order of in-context examples could affect the results <ref type="bibr" target="#b17">[Lu et al., 2022]</ref>, we run each experiment only once with a fixed seed across all methods and datasets, for fair comparisons with the zero-shot methods. <ref type="bibr" target="#b41">Wei et al. [2022]</ref> showed that the order of examples did not cause large variance in CoT experiments.</p><p>Answer cleansing After the model outputs a text by answer extraction (see ? 3 and Figure <ref type="figure">2</ref>), our method picks up only the part of the answer text that first satisfies the answer format. For example, if the answer prompting outputs "probably 375 and 376" on arithmetic tasks, we extract the first number "375" and set it as the model prediction. In the case of multiple-choice, the first large letter we encounter is set as the prediction. See Appendix A.6 for more detail. Standard Zero-shot method follows the same idea. For Few-shot and Few-shot-CoT methods, we follow <ref type="bibr" target="#b40">[Wang et al., 2022]</ref> and first extract the answer text after "The answer is " from the model output, and apply the same answer cleansing to parse the answer text. If "The answer is" is not found in the model output, we search from the back of the text and set the first text that satisfies the answer format as the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head><p>Zero-shot-CoT vs. Zero-shot Table <ref type="table" target="#tab_0">1</ref> summarize accuracy of our method (Zero-shot-CoT) and standard zero-shot prompting (Zero-shot) for each dataset. Zero-shot-CoT substantially outperforms four out of six arithmetic reasoning tasks (MultiArith, GSM8K, AQUA, SVAMP), all symbolic reasoning, and all other logical reasoning tasks (from BIG-bench <ref type="bibr">[big, 2021]</ref>). For example, Zeroshot-CoT achieves score gains from 17.7% to 78.7% on MultiArith and from 10.4% to 40.7% on GSM8K. Our method gives on-par performances for the remaining two arithmetic reasoning tasks (SingleEq and AddSub), which is expected since they do not require multi-step reasoning.</p><p>In commonsense reasoning tasks, Zero-shot-CoT does not provide performance gains. It is expected as <ref type="bibr" target="#b41">Wei et al. [2022]</ref> also reports that even Few-shot-CoT does not provide performance gains on Lambda (135B), but does improve StrategyQA when combined with substantially larger PaLM (540B) model, which may also apply for ours. More importantly, we observe that many generated chain of thought themselves are surprisingly logically correct or only contains human-understandable mistakes (see Table <ref type="table" target="#tab_1">4</ref>), suggesting that Zero-shot-CoT does elicit for better commonsense reasoning even when the task metrics do not directly reflect it. We provide samples generated by Zero-shot-CoT for each dataset in Appendix B. the error patterns. First, it tends to output unnecessary steps of reasoning after getting the correct prediction, which results in changing the prediction to incorrect one. Zero-shot-CoT also sometimes does not start reasoning, just rephrasing the input question. In contrast, Few-shot-CoT tend to fail when generated chain of thought include ternary operation, e.g. (3 + 2) * 4.</p><p>Does model size matter for zero-shot reasoning? Table <ref type="table">3</ref> compares performance of various language models on MultiArith dataset. Without chain of thought reasoning, the performance does not increase or increases slowly as the model scale is increased, i.e., the curve is mostly flat. In contrast, the performance drastically increases with chain of thought reasoning, as the model size gets bigger. When the model size is smaller, chain of thought reasoning is not effective. This result aligns with the few-shot experiment results in <ref type="bibr" target="#b41">Wei et al. [2022]</ref>. We also manually investigated the quality of generated chain of thought, and large-scale models clearly demonstrate better reasoning (see Appendix B for the sampled outputs for each model).</p><p>How does prompt selection affect Zero-shot-CoT? We validate the robustness of Zero-shot-CoT against input prompts. Table <ref type="table" target="#tab_2">5</ref> summarizes performance using eight different templates. The results indicate that the performance is improved if the text is written in a way that encourages chain of thought reasoning. However, the difference in accuracy is significant depending on the sentence. In this experiment, "Let's think step by step." achieves the best results. Interestingly, it is found that different templates encourage the model to express reasoning quite differently (see Appendix B for example outputs by each template).</p><p>How does prompt selection affect Few-shot-CoT? Table <ref type="table" target="#tab_3">6</ref> shows the performance of Fewshot-CoT when using examples from different datasets: CommonsenseQA to AQUA-RAT and CommonsenseQA to MultiArith. The domains are different in both cases, but the answer format is the same in the former. Surprisingly, the chain of thought examples from different domains (common sense to arithmetic) but with the same answer (multiple-choice) format provide substantial performance gain over Zero-shot (to AQUA-RAT), measured relative to the possible improvements from Zero-shot-CoT or Few-shot-CoT. In contrast, the performance gain becomes much less when using examples with different answer types (to MultiArith), confirming prior work <ref type="bibr" target="#b20">[Min et al., 2022]</ref> that suggests LLMs mostly leverage the few-shot examples to infer the repeated format rather than the task itself in-context. Nevertheless, for both cases the results are worse than Zero-shot-CoT, affirming the importance of task-specific sample engineering in Few-shot-CoT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Related Work</head><p>Reasoning Ability of LLMs Several studies have shown that pre-trained models usually are not good at reasoning <ref type="bibr">[Brown et al., 2020</ref><ref type="bibr" target="#b35">, Smith et al., 2022</ref><ref type="bibr" target="#b26">, Rae et al., 2021]</ref>, but its ability can be substantially increased by making them produce step-by-step reasoning, either by fine-tuning <ref type="bibr" target="#b28">[Rajani et al., 2019</ref><ref type="bibr" target="#b5">, Cobbe et al., 2021</ref><ref type="bibr" target="#b43">, Zelikman et al., 2022</ref><ref type="bibr" target="#b21">, Nye et al., 2022]</ref> or few-shot prompting <ref type="bibr" target="#b41">[Wei et al., 2022</ref><ref type="bibr">, Wang et al., 2022</ref><ref type="bibr" target="#b4">, Chowdhery et al., 2022]</ref> (Table <ref type="table" target="#tab_4">7</ref>). Unlike most prior work, we focus on zero-shot prompting and show that a single fixed trigger prompt substantially increases the zero-shot reasoning ability of LLMs across a variety of tasks requiring complex multi-hop thinking (Table <ref type="table" target="#tab_0">1</ref>), especially when the model is scaled up (Table <ref type="table">3</ref>). It also generates reasonable and understandable chain of thought across diverse tasks (Appendix B), even when the final prediction is wrong (Appendix C). Similar to our work, <ref type="bibr">Reynolds and McDonell [2021]</ref> demonstrate a prompt, "Let's solve this problem by splitting it into steps", would facilitate the multi-step reasoning in a simple arithmetic problem. However, they treated it as a task-specific example and did not evaluate quantitatively on diverse reasoning tasks against baselines. <ref type="bibr" target="#b34">Shwartz et al. [2020]</ref> propose to decompose a commonsense question into a series of information seeking question, such as "what is the definition of [X]". It does not require demonstrations but requires substantial manual prompt engineering per each reasoning task. Our results strongly suggest that LLMs are decent zero-shot reasoners, while prior work <ref type="bibr" target="#b41">[Wei et al., 2022]</ref> often emphasize only few-shot learning and task-specific in-context learning, e.g. no zero-shot baselines were reported. Our method does not require time-consuming fine-tuning or expensive sample engineering, and can be combined with any pre-trained LLM, serving as the strongest zero-shot baseline for all reasoning tasks. Zero-shot Abilities of LLMs <ref type="bibr" target="#b25">Radford et al. [2019]</ref> show that LLMs have excellent zero-shot abilities in many system-1 tasks, including reading comprehension, translation, and summarization. <ref type="bibr" target="#b31">Sanh et al. [2022]</ref>, <ref type="bibr" target="#b22">Ouyang et al. [2022]</ref> show that such zero-shot abilities of LLMs can be increased by explicitly fine-tuning models to follow instructions. Although these work focus on the zero-shot performances of LLMs, we focus on many system-2 tasks beyond system-1 tasks, considered a grand challenge for LLMs given flat scaling curves. In addition, Zero-shot-CoT is orthogonal to instruction tuning; it increases zero-shot performance for both Instruct GPT3 and vanilla GPT3 (Table <ref type="table">3</ref>).</p><p>From Narrow (task-specific) to Broad (multi-task) Prompting Most prompts are task-specific. While few-shot prompts are naturally so due to task-specific in-context samples <ref type="bibr">[Brown et al., 2020</ref><ref type="bibr">, Wei et al., 2022]</ref>, majority of zero-shot prompts have also focused on per-task engineering (of templates) <ref type="bibr">[Liu et al., 2021b, Reynolds and</ref><ref type="bibr">McDonell, 2021]</ref>. Borrowing terminologies from <ref type="bibr" target="#b3">Chollet [2019]</ref> which builds on hierarchical models of intelligence <ref type="bibr">[McGrew, 2005, Johnson and</ref><ref type="bibr" target="#b11">Bouchard Jr, 2005]</ref>, these prompts are arguably eliciting "narrow generalization" or task-specific skills from LLMs.</p><p>On the other hand, our method is a multi-task prompt and elicits "broad generalization" or broad cognitive abilities in LLMs, such as logical reasoning or system-2 itself. We hope our work can serve as a reference for accelerating not just logical reasoning research with LLMs, but also discovery of other broad cognitive capabilities within LLMs.</p><p>Limitation and Social Impact Our work is based on prompting methods for large language models. LLMs have been trained on large corpora from various sources on the web, and have shown to capture and amplify biases found in the training data. Prompting is a method that looks to take advantage of the patterns captured by language models conducive to various tasks, and therefore it has the same shortcomings. This being said, our approach is a more direct way to probe complex reasoning inside pre-trained LLMs, removing the confounding factor of in-context learning in prior few-shot approaches, and can lead to more unbiased study of biases in LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have proposed Zero-shot-CoT, a single zero-shot prompt that elicits chain of thought from large language models across a variety of reasoning tasks, in contrast to the few-shot (in-context) approach in previous work that requires hand-crafting few-shot examples per task. Our simple method not only is the minimalist and strongest zero-shot baseline for difficult multi-step system-2 reasoning tasks that long evaded the scaling laws of LLMs, but also encourages the community to further discover similar multi-task prompts that elicit broad cognitive abilities like logical reasoning instead of narrow task-specific skills.</p><p>( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Dataset creation</head><p>Regarding "Last Letter Concatenation" and "Coin Flip", datasets are not publicly available so we created the datasets following <ref type="bibr" target="#b41">Wei et al. [2022]</ref> with a minor rephrasing of the question template. Specifically, as for Last Letter Concatenation, we use the following template. We randomly select human names from names-dataset library (https://pypi.org/project/names-dataset/) and insert them into {Name1} through {Name4}.</p><p>? 'Take the last letters of each words in "{Name1} {Name2} {Name3} {Name4}" and concatenate them.'</p><p>As for Coin Flip, we use the following template. We randomly select human names from namesdataset library and insert them into {Name1} through {Name4}. We also randomly pick up "flips" or "does not flip" and insert the phrase into each {flips | does not flip} part, respectively.</p><p>? 'A coin is heads up. {Name1} {flips | does not flip} the coin. {Name2} {flips | does not flip} the coin. {Name3} {flips | does not flip} the coin. {Name4} {flips | does not flip} the coin. Is the coin still heads up? Note that "flip" here means "reverse".'</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Language Models</head><p>Our experiment uses multiple language models as described at </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Implementation details</head><p>For GPT-3 and Instruct-GPT3, we used OpenAI API. For other models, we used Hugging Face Transformer Library <ref type="bibr" target="#b42">[Wolf et al., 2020]</ref>. We set max_tokens = 128 and temperature = 0 across all the methods and models when requesting the APIs. "Q:" is set as a customized stop sequence for all the models except for Instruct-GPT3 to stop the models from repeating questions and answers by themselves. We run our experiments on cloud V100 instances without GPU for GPT-3 models, on cloud A100x8 GPU(60GB) instances for T0 and OTP, and on cloud A100x1 GPU(60GB) instances for the other models. Our implementation is in PyTorch <ref type="bibr" target="#b23">[Paszke et al., 2019]</ref>. 1 SingleEq</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Prompts For Answer Extraction</head><p>The answer (arabic numerals) is</p><p>The answer is 2 AddSub</p><p>The answer (arabic numerals) is</p><p>The answer is 3 MultiArith</p><p>The answer (arabic numerals) is</p><p>The answer is 4 GSM8K</p><p>The answer (arabic numerals) is</p><p>The answer is 5 AQUA-RAT Among A through E, the answer is The answer is 6 SVAMP</p><p>The answer (arabic numerals) is</p><p>The answer is 7 C.S.QA Among A through E, the answer is The answer is 8 StrategyQA</p><p>The answer (Yes or No) is The answer is 9 D.U.</p><p>Among A through F, the answer is The answer is 10 S.O.</p><p>Among  A: Let's think step by step. The spaceship traveled 0.5 light-years from Earth to Planet X. Then it traveled 0.1 light-years from Planet X to Planet Y. Finally, it traveled 0.1 light-years from Planet Y back to Earth. So the total distance the spaceship traveled is 0.5 + 0.1 + 0.1 = 0.7 light-years.</p><p>Therefore, the answer (arabic numerals) is: 0.7 light-years Q: While making desserts for a bake sale, Victor used 0.625 of a scoop of brown sugar as well as 0.25 of a scoop of white sugar. How much more brown sugar did Victor use?</p><p>A: Let's think step by step. 0.625 of a scoop of brown sugar is the same as 0.25 of a scoop of white sugar. This means that Victor used the same amount of brown sugar as he did white sugar.</p><p>Therefore, the answer (arabic numerals) is 0. (GT : 0.375) A: Let's think step by step. James buys a plane. This costs him $150,000. He pays $5000 a month to rent a hanger. This costs him $60,000 for the year. He spends twice as much as that on fuel per month. This costs him $120,000 for the year. So the total cost for the first year is $150,000 + $60,000 + $120,000 = $330,000. Therefore, the answer (arabic numerals) is 330,000. There are 12 children to the left of Neha, so there must be at least 12 children in the row.</p><formula xml:id="formula_1">AddSub</formula><p>There are 6 children to the right of Radha, so there must be at least 18 children in the row.</p><p>There are 6 children between Radha and Neha, so there must be at least 24 children in the row.</p><p>The answer must be between 24 and 27, and the only answer that satisfies this is 26.</p><p>Therefore, the answer is 26. Therefore, among A through E, the answer is C. (GT : D) SVAMP Q: There are 7 baskets of peaches. Each basket has 10 red peaches and 2 green peaches. How many green peaches are in the baskets altogether?</p><p>A: Let's think step by step. There are 7 baskets. Each basket has 10 red peaches and 2 green peaches. So, there are 2 green peaches in each basket. Now, we need to multiply because there are 7 baskets. 2 multiplied by 7 is 14. So, there are 14 green peaches in the baskets altogether.</p><p>Therefore, the answer (arabic numerals) is 14. A: Let's think step by step. The JPEG format is a lossy compression format, which means that some of the image data will be lost when the image is compressed. The Vitruvian Man is a very detailed image, with lots of small details. So, when we compress the image using JPEG, some of those small details will be lost, and the image will not be as sharp and clear as the original. So, in conclusion, JPEG is not the best format for saving an image of the Vitruvian Man.  A: Let's think step by step. First, Claire and Alice switch partners. This means that at the end of this step, Alice is dancing with Karl and Claire is dancing with Sam. Then, Bob and Alice switch partners. This means that at the end of this step, Alice is dancing with Helga and Bob is dancing with Karl. Finally, Claire and Bob switch partners. This means that at the end of this step, Claire is dancing with Helga and Bob is dancing with Sam. At the end of the dance, Alice is dancing with Sam. Therefore, among A through C, the answer is A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continued on next page</head><p>(GT : B) A: Let's think step by step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continued on next page</head><p>The last letter of "Vinny" is "y". The last letter of "Landon" is "n". The last letter of "Miguel" is "l". The last letter of "Caitlyn" is "n". So, the final answer would be "ynln".</p><p>Therefore, the answer is "ynln".</p><p>Q: Take the last letters of each words in "Lamont Frederick Lance Esperanza" and concatenate them.</p><p>A: Let's think step by step.</p><p>The last letter of "Lamont" is "t".</p><p>The last letter of "Frederick" is "k".</p><p>The last letter of "Lance" is "e".</p><p>The last letter of "Esperanza" is "a".</p><p>So the final answer would be "tkaea".</p><p>Therefore, the answer is "tkaea". (GT tkea)</p><p>Coin Flip Q: A coin is heads up. Jeff does not flip the coin. Jen flips the coin. Giselle flips the coin. Noel does not flip the coin. Is the coin still heads up? Note that "flip" here means "reverse".</p><p>A: Let's think step by step. Jeff does not flip the coin, so the coin remains heads up. Jen flips the coin, so the coin is now tails up. Giselle flips the coin, so the coin is now heads up again.</p><p>Noel does not flip the coin, so the coin remains heads up. Therefore, the final answer is that the coin is heads up.</p><p>Therefore, the answer (Yes or No) is Yes.</p><p>Q: A coin is heads up. Caroline flips the coin. Demetrius flips the coin. Fidel does not flip the coin. Solomon flips the coin. Is the coin still heads up? Note that "flip" here means "reverse".</p><p>A: Let's think step by step.</p><p>Caroline flips the coin. The coin is now tails up.</p><p>Demetrius flips the coin. The coin is now heads up.</p><p>Fidel does not flip the coin. The coin remains tails up.</p><p>Solomon flips the coin. The coin is now heads up.</p><p>So, the answer is yes, the coin is still heads up.</p><p>Therefore, the answer (Yes or No) is: Yes (GT : No) Therefore, the answer (arabic numerals) is 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (2)</head><p>A: First, we need to find the total number of pieces of candy Megan has. She has 11 pieces from neighbors and 5 pieces from her older sister, so the total number of pieces is 16. If she only ate 8 pieces a day, it would take her 2 days to finish the candy. Therefore, the answer (arabic numerals) is 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (3)</head><p>A: Let's think about this logically.</p><p>There are 11 + 5 = 16 pieces of candy. 8 pieces a day means that it would last her 2 days. 16 / 8 = 2 Therefore, the answer (arabic numerals) is 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (4)</head><p>A: Let's solve this problem by splitting it into steps.</p><p>Step 1: Megan received 11 pieces of candy from neighbors.</p><p>Step 2: Megan received 5 pieces of candy from her older sister.</p><p>Step 3: If she only ate 8 pieces a day, how long would the candy last her?</p><p>To answer the question in Step 3, we need to add the number of pieces of candy Megan received from her neighbors and her sister. This is called finding the sum. The sum of 11 and 5 is 16. So, Megan has a total of 16 pieces of candy.</p><p>If Megan only eats 8 pieces of candy a day, Therefore, the answer (arabic numerals) is 2 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (5)</head><p>A: Let's be realistic and think step by step.</p><p>Megan received 11 pieces of candy from neighbors and 5 pieces from her older sister. That's a total of 16 pieces of candy. 8 pieces a day would mean that it would last her 2 days. So the candy would last her 2 days.</p><p>Therefore, the answer (arabic numerals) is 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (6)</head><p>A: Let's think like a detective step by step.</p><p>Megan received 11 pieces of candy from neighbors and 5 pieces from her older sister. That's a total of 16 pieces of candy. If she only ate 8 pieces a day, that would mean that she would have to divide her candy into 2 days, and she would have 8 pieces of candy left over. So the candy would last her 2 days.</p><p>Therefore, the answer (arabic numerals) is 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (7)</head><p>A: Let's think about this in terms of days. Megan would receive candy for 16 days. Therefore, the answer (arabic numerals) is 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (8)</head><p>A: Before we dive into the answer, we need to think about what the question is asking. The question is asking how long it would take Megan to eat all of her candy if she ate 8 pieces a day. There are a total of 16 pieces of candy. If Megan ate 8 pieces a day, it would take her 2 days to eat all of her candy.</p><p>Therefore, the answer (arabic numerals) is 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zero-shot-CoT (9)</head><p>A: The answer is after the proof. 11 + 5 = 16 16 ? 8 = 2 2 days Therefore, the answer (arabic numerals) is 2. Therefore, the answer (arabic numerals) is :5</p><p>Instruct GPT-3 (1.3B) (Text-babbage-001)</p><p>A: Let's think step by step.</p><p>Adam bought 2 boxes of candy and 5 boxes of caramel candy. Each box has 4 pieces inside it. So he would have had 18 pieces of candy.</p><p>Therefore, the answer (arabic numerals) is 18.</p><p>Instruct GPT-3 (6.7B) (Text-curie-001)</p><p>A: Let's think step by step.</p><p>Adam bought 2 boxes of chocolate candy and 5 boxes of caramel candy. Each box of candy has 4 pieces inside it. So, Adam bought 10 pieces of candy.</p><p>Therefore, the answer (arabic numerals) is 60.</p><p>Instruct GPT-3 (175B) (Text-davinci-002)</p><p>A: Let's think step by step. Adam bought 2 boxes of chocolate candy and 5 boxes of caramel candy. We know that each box has 4 pieces inside it. So, we can multiply 2 by 4 to find out how many pieces of chocolate candy Adam bought. This will give us 8. We can also multiply 5 by 4 to find out how many pieces of caramel candy Adam bought. This will give us 20. Now, we can add 8 and 20 together to find out how much candy Adam bought in total. 8 + 20 = 28 Adam bought 28 pieces of candy in Therefore, the answer (arabic numerals) is 28.</p><p>Original GPT-3 (0.3B) (ada)</p><p>A: Let's think step by step. A: Let's think step by step.</p><p>Therefore, the answer (arabic numerals) is:</p><p>Original GPT-3 (6.7B) (curie)</p><p>A: Let's think step by step. First, we need to find the total number of pieces in the boxes. Let's start with the chocolate candy. There are 4 pieces in each box. So, the total number of pieces in the chocolate candy is 4 x 4 = 16. Now, let's find the total number of pieces in the caramel candy. There are 5 pieces in each box. So, the total number of pieces in the caramel candy is 5 x 5 = 25. Now, we can find the total number of pieces in the candy. The total number of pieces in the chocolate candy is 16 + 25 = 41</p><p>Therefore, the answer (arabic numerals) is 41.</p><p>Original GPT-3 (175B) (davinci)</p><p>A: Let's think step by step. First, we need to find out how many pieces of candy Adam has. 2 boxes of chocolate candy + 5 boxes of caramel candy = 7 boxes of candy 7 boxes of candy = 7 ? 4 pieces of candy 7 ? 4 = 28 pieces of candy So, Adam has 28 pieces of candy.</p><p>Therefore, the answer (arabic numerals) is 28.  <ref type="bibr">6,</ref><ref type="bibr">8,</ref><ref type="bibr">12,</ref><ref type="bibr">16,</ref><ref type="bibr">20,</ref><ref type="bibr">24,</ref><ref type="bibr">28,</ref><ref type="bibr">32,</ref><ref type="bibr">36,</ref><ref type="bibr">40,</ref><ref type="bibr">44,</ref><ref type="bibr">48,</ref><ref type="bibr">52,</ref><ref type="bibr">56,</ref><ref type="bibr">60,</ref><ref type="bibr">64</ref> GPT-Neo (2.7B)</p><p>A: Let's think step by step.</p><p>Step 1: She baked 68 cupcakes.</p><p>Step 2: She put 32 of them in a box.</p><p>Step 3: She put 6 cupcakes in each box.</p><p>Step 4: She put the box in the freezer.</p><p>Step 5: She took the box out of the freezer.</p><p>Step 6: She took the box out of the freezer.</p><p>Step 7: She took the box out of the freezer.</p><p>Step 8: She took the box out of the freezer.</p><p>Step 9: She took the box out of the freezer.</p><p>Step 10: She took the box out of the freezer.</p><p>Step</p><p>Therefore, the answer (arabic numerals) is:</p><p>Step 1: She baked 68 cupcakes.</p><p>Step 2: She put 32 of them in a box.</p><p>Step 3: She put 6 cup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-J (6B)</head><p>A: Let's think step by step.</p><p>Step Step Therefore, the answer (arabic numerals) is:</p><p>A: The answer is: 68 ? 6 = 408</p><p>Step 1: The first step is to count T0 (11B)</p><p>A: Let's think step by step. 12 Therefore, the answer (arabic numerals) is 12</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OPT (13B)</head><p>A: Let's think step by step.</p><p>Megan baked 68 cupcakes. She divided 68 by 6 to get 17. She divided 17 by 32 to get 6. Megan can make 6 packages of cupcakes if she puts 6 cupcakes in each package.</p><p>Therefore, the answer (arabic numerals) is: A: The answer is 8. Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?</p><p>A: The answer is 33. Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?</p><p>A: The answer is 5. Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?</p><p>A: The answer is 29. Q: Olivia has 23.Sheboughtf ivebagelsf or3 each. How much money does she have left?</p><p>A: The answer is 8. Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?</p><p>A: The answer is 6. Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?</p><p>A: The answer is 9. Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?</p><p>A: The answer is 39. ***** End In-Context Examples ***** Q: For Halloween Megan received 11 pieces of candy from neighbors and 5 pieces from her older sister. If she only ate 8 pieces a day, how long would the candy last her?</p><p>A: The answer is 3 days. (GT : 2) Table <ref type="table" target="#tab_8">18</ref>: An example output by Few-Shot-CoT (8 exemplars in context. These exemplars are cited from <ref type="bibr" target="#b41">[Wei et al., 2022]</ref> and randomly shuffled). The answer is 33. Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot? A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5. Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room? A: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. The answer is 29. Q: Olivia has 23.Sheboughtf ivebagelsf or3 each. How much money does she have left? A: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 -15 dollars left. 23 -15 is 8. The answer is 8. Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today? A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 -15 = 6. The answer is 6. Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now? A: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9. The answer is 9. Q: Leah had 32 chocolates and her sister had 42.   We randomly picked up 50 samples whose prediction results were correct and 50 samples whose prediction results were incorrect. We categorized those samples by CoT types. Some picked-up samples from each category are found Table <ref type="table" target="#tab_26">22</ref>.</p><p>First, it is found that the correct samples contain a certain amount of incorrect chain of thought. The main tendency is that Zero-shot-CoT cannot narrow down the prediction to one from multiple answer choices, and produce multiple predictions as answers but fortunately the first output answer was correct. See "Correct -CoT is INCORRECT" rows in Table <ref type="table" target="#tab_26">22</ref> Second, as for incorrect samples, commonsense mistake is the most frequent error type. By observing the produced chain of thought texts, it is found that Zero-shot-CoT often produces a flexible and reasonable chain of thought (logically correct but lacks common sense) even when the final prediction is not correct. See "CommonSense Mistake" rows in A: Let's think step by step. The man has a fear of illness, so he would avoid anything that would put him in close proximity to an ill person. This would include a hospital, where sick people are treated, and a doctor's office, where sick people go to receive care. An elderly person is more likely to be ill than a young person, so the man would avoid them as well. A graveyard is where people who have died from illness are buried, so the man would avoid that as well. The answer is A, sick person. Therefore, among A through E, the answer is A. (Model cannot narrow down choice to one in CoT.) (GT : (A), Zero-shot: (A))</p><p>Continued on next page (A) music school (B) music store (C) neighbor's house (D) lunch (E) drawing room A: Let's think step by step. If you don't have a piano, you can't use your own. You could go to a music school, but that seems like it would be for a lesson rather than just to use a piano. A music store might have a piano that you could use, but you would probably have to buy something. You could go to a neighbor's house, but that seems like a lot to ask. You could go to a lunch, but that doesn't make sense. You could go to a drawing room, but that also doesn't make sense. The answer must be (B) music store. Therefore, among A through E, the answer is B. And if their eyes are moving, they are probably not asleep. So it's probably not (C) or (D). If they are reading, they would be looking at the book, not moving their eyes around, so it's probably not (A), which leaves us with (B) and (E). It's more likely that they are thinking, so (E) is the best answer. Therefore, among A through E, the answer is E.</p><p>(GT : (A), Zero-shot: (E)) Continued on next page As for correct samples, we examined if the produced chain of thought is logical and consistent with the correct prediction. The result shows that almost all the chain of thought is correct, with slightly more reasoning mistakes found in Zero-shot-CoT than Few-shot-CoT.</p><p>As for incorrect samples, it is found that Zero-shot-CoT tends to output unnecessary steps of reasoning after getting the correct prediction, which results in changing the prediction to incorrect one. Zeroshot-CoT also sometimes does not start reasoning, just rephrasing the input question. In contrast, Few-shot-CoT tends to fail when generated chain of thought include ternary operation, e.g. (3 + 2) * 4.</p><p>Another finding is that Zero-shot-CoT and Few-shot-CoT have a certain amount of common sense mistakes to interpret a question. Some examples are found at Table <ref type="table" target="#tab_29">24</ref>. Therefore, the answer (arabic numerals) is 43.</p><p>A: If 8 were kids, then that means there were 15 -8 = 7 adults. Each adult meal costs $5. So the total cost would be 7 * 5 = 35. The answer is 35.</p><p>Q: April's discount flowers was having a sale where each flower was 6 dollars. If Katie bought 5 roses and 5 daisies, how much did she spend?</p><p>A: Let's think step by step. First, we need to calculate how much each type of flower costs. There are 5 roses, and each rose costs 6 dollars. So, the cost of the roses is 5*6=30 dollars. There are 5 daisies, and each daisy costs 6 dollars. So, the cost of the daisies is 5*6=30 dollars. Then, we need to calculate the total cost. The total cost is the cost of the roses plus the cost of the daisies. So, the total cost is 30+30=60 dollars. Therefore, the answer (arabic numerals) is 60.</p><p>A (CALCULATOR ERROR): Each flower was 6 dollars. Katie bought 5 roses and 5 daisies. So she spent 5 * 6 + 5 * 6 = 60 + 30 = 90. The answer is 90. Q: While shopping for music online, Faye bought 2 country albums and 3 pop albums. Each album came with a lyric sheet and had 6 songs. How many songs did Faye buy total? A: Let's think step by step. Faye bought 2 country albums. Each album has 6 songs. So she bought 2 * 6 = 12 songs from the country albums. Faye bought 3 pop albums. Each album has 6 songs. So she bought 3 * 6 = 18 songs from the pop albums. In total, Faye bought 12 + 18 = 30 songs. Therefore, the answer (arabic numerals) is 30.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A</head><p>(CALCULATOR ERROR): Faye bought 2 country albums and 3 pop albums. Each album had 6 songs. So she bought 2 * 6 + 3 * 6 = 24 songs. The answer is 24. Q: At the fair there were 12 people in line for the bumper cars. If 10 of them got tired of waiting and left and 15 more got in line, how many people would be in line? A (OTHERS; REASONING IS NOT STARTED): Let's think step by step. There were 12 people in line for the bumper cars. 10 of them got tired of waiting and left. 15 more got in line. That means that there are now 15 people in line for the bumper cars. Therefore, the answer (arabic numerals) is 15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continued on next page</head><p>A: There were originally 12 people in line. 10 of them left, so that left 12 -10 = 2. Then 15 more got in line, so that is 2 + 15 = 17. The answer is 17. Q: Luke made 9 dollars mowing lawns and 18 dollars weed eating. If he only spent 3 dollar a week, how long would the money last him? A (OTHERS; QUESTION UNDER-STANDING ERROR): Let's think step by step. How much money does Luke make in a week? How much money does Luke spend in a week? How much money does Luke have left over at the end of the week? How long will it take Luke to save up $54? Luke makes $27 a week. He spends $3 a week. He has $24 left over at the end of the week. It will take Luke 2 weeks to save up $54.</p><p>Therefore, the answer (arabic numerals) is 2.</p><p>A: Luke made 9 dollars mowing lawns and 18 dollars weed eating. In total, he made 9 + 18 = 27 dollars. If he spends 3 dollars a week, that is 3 dollars * 4 weeks = 12 dollars a month. So the money would last him 27 / 12 = 2.25 months. The answer is 2.25 months.</p><p>(GT : 9 weeks) A: Each chocolate cost 3 dollars. So if Wendy sold all but 3, she would have sold 9 -3 = 6. 6 * 3 = 18. The answer is 18.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continued on next page</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>1st prompt: reasoning extraction In this step we first modify the input question x into a prompt using a simple template "Q: [X]. A: [Z]", where [X] is an input slot for x and [T] is an slot for Q: On average Joe throws 25 punches per minute. A fight lasts 5 rounds of 3 minutes. How many punches did he throw? A: Let's think step by step. In one minute, Joe throws 25 punches. In three minutes, Joe throws 3 * 25 = 75 punches. In five rounds, Joe throws 5 * 75 = 375 punches. Q: On average Joe throws 25 punches per minute. A fight lasts 5 rounds of 3 ??? A: Let's think step by step. In one minute, Joe throws 25 punches. ???In five rounds, Joe throws 5 * 75 = 375 punches. .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>, Bob, and Claire are playing a game. At the start of the game, they are each holding a ball: Alice has a green ball, Bob has a purple ball, and Claire has a blue ball. As the game progresses, pairs of players trade balls. First, Bob and Alice swap balls. Then, Claire and Bob swap balls. Finally, Bob and Alice swap balls. At the end of the game, Bob has the Which choice is true ? Answer Choices: (A) green ball. (B) purple ball. (C) blue ball. A: Let's think step by step. First, Bob and Alice swap balls. This means that Alice now has the purple ball and Bob has the green ball. Then, Claire and Bob swap balls. This means that Claire now has the green ball and Bob has the blue ball. Finally, Bob and Alice swap balls. This means that Alice now has the blue ball and Bob has the purple ball. At the end of the game, Bob has the purple ball. Therefore, among A through C, the answer is B. Q: Alice, Bob, and Claire are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Sam, Bob is dancing with Helga, and Claire is dancing with Karl. Throughout the song, the dancers often trade partners. First, Claire and Alice switch partners. Then, Bob and Alice switch partners. Finally, Claire and Bob switch partners. At the end of the dance, Alice is dancing with Which choice is true ? Answer Choices: (A) Sam. (B) Helga. (C) Karl.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 :</head><label>1</label><figDesc>Step 2: Step 3: Step 4: Step 5: Step 6: Step 7: Step 8: Step 9: Step 10: Step 11: Step 12: Step 13: Step 14: Step 15: Step 16: Step 17: Step 18: Step 19: Step 20: Step 21: Step 22: Step 23: Step 24: Step 25:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Few</head><label></label><figDesc>** Start In-Context Examples ***** Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny? A: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 -12 = 8. The answer is 8. Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday? A: Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 -23 = 35. After losing 2 more, he had 35 -2 = 33 golf balls.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Table 19 :</head><label>19</label><figDesc>An example output by Few-Shot-CoT with exemplars from entirely different task (7 exemplars in context. These exemplars are cited from<ref type="bibr" target="#b41">[Wei et al., 2022]</ref> and randomly shuffled) Exemplars are CommonsenseQA (Multi-Choice question), and a task is MultiArith (Number question). Few-Shot-CoT with exemplars from a different task ***** Start In-Context Examples ***** Q: Sammy wanted to go to where the people were. Where might he go? Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblock A: The answer must be a place with a lot of people. Of the above choices, only populated areas have a lot of people. The answer is A. Q: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadness A: The answer should be the feeling of someone getting divorced who was doing all the work. Of the above choices, the closest feeling is bitterness The answer is C. Q: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (A) united states (B) mexico (C) countryside (D) atlas A: The answer must be something that used to do what Google Maps and GPS services do, which is to give directions. Of the above choices, only atlases are used to give directions. The answer is D. Q: The fox walked from the city into the forest, what was it looking for? Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybook A: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. The answer is B. Q: What do people use to absorb extra ink from a fountainpen? Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotter A: The answer must be an item that can absorb ink. Of the above choices, only blotters are used to absorb ink. The answer is E. Q: Where do you put your grapes just before checking out? Answer Choices: (A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit market A: The answer should be the place where grocery items are placed before checking out. Of the above choices, grocery cart makes the most sense for holding grocery items. The answer is B. Q: What home entertainment equipment requires cable? Answer Choices: (A) radio shack (B) substation (C) television (D) cabinet A: The answer must require cable. Of the above choices, only television requires cable. The answer is C. ***** End In-Context Examples ***** Q: Paige and her friends were recycling paper for their class. For every 4 pounds they recycled they earned one point. If Paige recycled 14 pounds and her friends recycled 2 pounds, how many points did they earn? A: Paige and her friends would have earned 3 points for recycling paper.(GT : 4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(GT : (C), Zero-shot: (C)) CommonSense Mistake Q: David watched some nesting birds using his binoculars while on vacation. Where might David be?. Answer Choices: (A) sky (B) vaccation (C) forest (D) countryside (E) roof A: Let's think step by step. First, we need to understand what the word "binoculars" means. Binoculars are two telescopes that are joined together and allow a person to see things that are far away. Now, we need to think about where a person might use binoculars. A person might use binoculars to see things that are far away and in the sky, or to see things that are far away and on the ground. So, the answer could be either (A) sky or (D) countryside. Therefore, among A through E, the answer is (A) or (D). (GT : (C), Zero-shot: (D)) CommonSense Mistake Q: When you get up in the morning before you begin work you should do what? Answer Choices: (A) apply for job (B) sleep (C) concentrate (D) shower (E) just do A: Let's think step by step. The first thing you should do when you wake up is probably to stretch and yawn to get your body moving. Then, you should probably brush your teeth and wash your face to get ready for the day. After that, you might want to eat breakfast to give yourself some energy for the day. Once you're all set, you can start your work for the day. Therefore, among A through E, the answer is C. (GT : (D), Zero-shot: (C)) CommonSense Mistake Q: What is someone doing if he or she is sitting quietly and his or her eyes are moving? Answer Choices: (A) reading (B) meditate (C) fall asleep (D) bunk (E) think A: Let's think step by step. If someone is sitting quietly, that means they are not moving around.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Accuracy comparison of Zero-shot-CoT with Zero-shot on each tasks. The values on the left side of each task are the results of using answer extraction prompts depending on answer format as described at ? 3. The values on the right side are the result of additional experiment where standard answer prompt "The answer is" is used for answer extraction. See Appendix A.5 for details.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Arithmetic</cell><cell></cell><cell></cell></row><row><cell></cell><cell>SingleEq</cell><cell>AddSub</cell><cell cols="2">MultiArith GSM8K</cell><cell>AQUA</cell><cell>SVAMP</cell></row><row><cell>zero-shot</cell><cell>74.6/78.7</cell><cell>72.2/77.0</cell><cell>17.7/22.7</cell><cell>10.4/12.5</cell><cell>22.4/22.4</cell><cell>58.8/58.7</cell></row><row><cell>zero-shot-cot</cell><cell>78.0/78.7</cell><cell>69.6/74.7</cell><cell>78.7/79.3</cell><cell>40.7/40.5</cell><cell>33.5/31.9</cell><cell>62.1/63.7</cell></row><row><cell></cell><cell cols="2">Common Sense</cell><cell cols="2">Other Reasoning Tasks</cell><cell cols="2">Symbolic Reasoning</cell></row><row><cell></cell><cell>Common</cell><cell>Strategy</cell><cell>Date</cell><cell>Shuffled</cell><cell>Last Letter</cell><cell>Coin Flip</cell></row><row><cell></cell><cell>SenseQA</cell><cell>QA</cell><cell cols="2">Understand Objects</cell><cell>(4 words)</cell><cell>(4 times)</cell></row><row><cell>zero-shot</cell><cell>68.8/72.6</cell><cell>12.7/54.3</cell><cell>49.3/33.6</cell><cell>31.3/29.7</cell><cell>0.2/-</cell><cell>12.8/53.8</cell></row><row><cell>zero-shot-cot</cell><cell>64.6/64.0</cell><cell>54.8/52.3</cell><cell>67.5/61.8</cell><cell>52.4/52.9</cell><cell>57.6/-</cell><cell>91.4/87.8</cell></row><row><cell cols="7">Table 2: Comparison with baseline methods using accuracies on MultiArith and GSM8K. Text-</cell></row><row><cell cols="7">davinci-002 (175B) is used as the model. We used the same 8 examples as described in [Wei et al.,</cell></row><row><cell cols="7">2022] for Few-shot and Few-shot-CoT settings. (*1) To verify the variance of changing examples, we</cell></row><row><cell cols="7">report two results for 4-shot-cot by splitting the eight examples into two groups. (*2) These results</cell></row><row><cell cols="7">are cited from [Wei et al., 2022] (*3) We insert "Let's think step by step." at the beginning of answer</cell></row><row><cell cols="5">part of each exemplars for Few-shot-CoT to test performance gains.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MultiArith GSM8K</cell><cell></cell></row><row><cell cols="2">Zero-Shot</cell><cell></cell><cell></cell><cell>17.7</cell><cell>10.4</cell><cell></cell></row><row><cell cols="3">Few-Shot (2 samples)</cell><cell></cell><cell>33.7</cell><cell>15.6</cell><cell></cell></row><row><cell cols="3">Few-Shot (8 samples)</cell><cell></cell><cell>33.8</cell><cell>15.6</cell><cell></cell></row><row><cell cols="2">Zero-Shot-CoT</cell><cell></cell><cell></cell><cell>78.7</cell><cell>40.7</cell><cell></cell></row><row><cell cols="3">Few-Shot-CoT (2 samples)</cell><cell></cell><cell>84.8</cell><cell>41.3</cell><cell></cell></row><row><cell cols="4">Few-Shot-CoT (4 samples : First) (*1)</cell><cell>89.2</cell><cell>-</cell><cell></cell></row><row><cell cols="4">Few-Shot-CoT (4 samples : Second) (*1)</cell><cell>90.5</cell><cell>-</cell><cell></cell></row><row><cell cols="3">Few-Shot-CoT (8 samples)</cell><cell></cell><cell>93.0</cell><cell>48.7</cell><cell></cell></row><row><cell cols="4">Zero-Plus-Few-Shot-CoT (8 samples) (*3)</cell><cell>92.8</cell><cell>51.5</cell><cell></cell></row><row><cell cols="3">Finetuned GPT-3 175B (*2)</cell><cell></cell><cell>-</cell><cell>33</cell><cell></cell></row><row><cell cols="4">Finetuned GPT-3 175B + verifier (*2)</cell><cell>-</cell><cell>55</cell><cell></cell></row><row><cell cols="3">PaLM 540B: Few-Shot (*2)</cell><cell></cell><cell>-</cell><cell>17.9</cell><cell></cell></row><row><cell cols="3">PaLM 540B: Few-Shot-CoT (*2)</cell><cell></cell><cell>-</cell><cell>58.1</cell><cell></cell></row><row><cell cols="7">Comparison with other baselines Table 2 compares the performances on two arithmetic reasoning</cell></row><row><cell cols="7">benchmarks (MultiArith and GSM8K) across Zero-shot-CoT and baselines. The large gap between</cell></row><row><cell cols="7">standard prompting (top block) and chain of thought prompting (middle block) suggests that these</cell></row><row><cell cols="7">tasks are difficult without eliciting multi-step reasoning. While Zero-shot-CoT naturally underper-</cell></row><row><cell cols="7">forms Few-shot-CoT, it substantially outperforms standard Few-shot prompting with even 8 examples</cell></row><row><cell cols="7">per task. For GSM8K, Zero-shot-CoT with Instruct GPT-3 (175B) also outperforms finetuned GPT-3</cell></row><row><cell cols="7">and standard few-shot prompting with large models (PaLM, 540B), reported in Wei et al. [2022]</cell></row><row><cell>(bottom block).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Error Analysis To better understand the behavior of Zero-shot-CoT, we manually investigated</cell></row><row><cell cols="7">randomly selected examples generated by Instruct-GPT3 with Zero-shot-CoT prompting. See Ap-</cell></row><row><cell cols="7">pendix C for examples, where some of the observations include: (1) In commonsense reasoning</cell></row><row><cell cols="7">(CommonsenseQA), Zero-shot-CoT often produces flexible and reasonable chain of thought even</cell></row><row><cell cols="7">when the final prediction is not correct. Zero-shot-CoT often output multiple answer choices when</cell></row><row><cell cols="7">the model find it is difficult to narrow it down to one (see Table 4 for examples). (2) In arithmetic</cell></row><row><cell cols="7">reasoning (MultiArith), Zero-shot-CoT and Few-shot-CoT show substantial differences regarding</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 :</head><label>4</label><figDesc>Failure examples generated by Zero-Shot-CoT for CommonsenseQA.</figDesc><table><row><cell>Example 1 (Reasoning is correct.)</cell><cell>Example 2 (Model cannot choose only one.)</cell></row><row><cell>Q: Where is a well used toy car likely to be found?</cell><cell>Q: What would be necessary for getting in shape?</cell></row><row><cell>Answer Choices: (A) child's room (B) boy's bed-</cell><cell>Answer Choices: (A) good health (B) exercise (C)</cell></row><row><cell>room (C) own home (D) toy store (E) house</cell><cell>muscle tone (D) sweat (E) feel better</cell></row><row><cell>A: Let's think step by step. A toy car is likely</cell><cell>A: Let's think step by step. In order to get in shape,</cell></row><row><cell>to be found in a child's room. A child's room is</cell><cell>you need to be able to do three things:</cell></row><row><cell>likely to be found in a house. Therefore, a toy</cell><cell>1. Exercise regularly</cell></row><row><cell>car is likely to be found in a house.</cell><cell>2. Eat a healthy diet</cell></row><row><cell>Therefore, among A through E, the answer is E.</cell><cell>3. Get enough sleep</cell></row><row><cell>(GT : A, Zero-shot: A)</cell><cell>If you can do all three of those things, then you will</cell></row><row><cell></cell><cell>be well on your way to getting in shape! Therefore,</cell></row><row><cell></cell><cell>among A through E, the answer is B, C, and D.</cell></row><row><cell></cell><cell>(GT : B, Zero-shot: B)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 :</head><label>5</label><figDesc>Robustness study against template measured on the MultiArith dataset with the Textdavinci-002 (175B) variant. (*1) This template is used in<ref type="bibr" target="#b1">Ahn et al. [2022]</ref> where a language model is prompted to generate step-by-step actions given a high-level instruction for controlling robotic actions. (*2) This template is used inReynolds and McDonell [2021]  but is not quantitatively evaluated.</figDesc><table><row><cell cols="2">No. Template</cell><cell>Accuracy</cell></row><row><cell>1</cell><cell>Let's think step by step.</cell><cell>78.7</cell></row><row><cell>2</cell><cell>First, (*1)</cell><cell>77.3</cell></row><row><cell>3</cell><cell>Let's think about this logically.</cell><cell>74.5</cell></row><row><cell>4</cell><cell>Let's solve this problem by splitting it into steps. (*2)</cell><cell>72.2</cell></row><row><cell>5</cell><cell>Let's be realistic and think step by step.</cell><cell>70.8</cell></row><row><cell>6</cell><cell>Let's think like a detective step by step.</cell><cell>70.3</cell></row><row><cell>7</cell><cell>Let's think</cell><cell>57.5</cell></row><row><cell>8</cell><cell>Before we dive into the answer,</cell><cell>55.7</cell></row><row><cell>9</cell><cell>The answer is after the proof.</cell><cell>45.7</cell></row><row><cell>-</cell><cell>(Zero-shot)</cell><cell>17.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell>Zero-shot</cell><cell>Few-shot-CoT  ?</cell><cell>Zero-shot-CoT</cell><cell>Few-shot-CoT</cell></row><row><cell>AQUA-RAT</cell><cell>22.4</cell><cell>31.9</cell><cell>33.5</cell><cell>39.0</cell></row><row><cell>MultiArith</cell><cell>17.7</cell><cell>27.0</cell><cell>78.7</cell><cell>88.2</cell></row></table><note><p>Robustness study of Few-shot-CoT against examples. When the examples are from entirely different tasks, the performance generally becomes worse, but when the answer formats are matched (i.e. CommonsenseQA to AQUA-RAT, multiple-choice), the performance loss is less severe. ? CommonsenseQA samples are used in this variation</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 7 :</head><label>7</label><figDesc>Summary of related works on arithmetic/commonsense reasoning tasks. Category denotes the training strategy. CoT denotes whether to output chain of thought. Task column lists the tasks that are performed in corresponding papers. AR: Arithmetic Reasoning, CR: Commonsense Reasoning.</figDesc><table><row><cell>Method</cell><cell>Category</cell><cell>CoT Task</cell><cell>Model</cell></row><row><cell>Rajani et al. [2019]</cell><cell>Fine-Tuning</cell><cell>CR</cell><cell>GPT</cell></row><row><cell>Cobbe et al. [2021]</cell><cell>Fine-Tuning</cell><cell>AR</cell><cell>GPT-3</cell></row><row><cell>Zelikman et al. [2022]</cell><cell>Fine-Tuning</cell><cell cols="2">AR,CR GPT-3, etc</cell></row><row><cell>Nye et al. [2022]</cell><cell>Fine-Tuning</cell><cell>AR</cell><cell>Transformer(Decoder)</cell></row><row><cell>Brown et al. [2020]</cell><cell>Few/Zero-Shot</cell><cell>CR</cell><cell>GPT-3</cell></row><row><cell>Smith et al. [2022]</cell><cell>Few/Zero-Shot</cell><cell cols="2">AR,CR MT-NLG</cell></row><row><cell>Rae et al. [2021]</cell><cell>Few-Shot</cell><cell cols="2">AR,CR Gopher</cell></row><row><cell>Wei et al. [2022]</cell><cell>Few-Shot</cell><cell cols="2">AR,CR PaLM, LaMBDA, GPT-3</cell></row><row><cell>Wang et al. [2022]</cell><cell>Few-Shot</cell><cell cols="2">AR,CR PaLM, etc</cell></row><row><cell>Chowdhery et al. [2022]</cell><cell>Few-Shot</cell><cell cols="2">AR,CR PaLM</cell></row><row><cell>Shwartz et al. [2020]</cell><cell>Zero-Shot</cell><cell>CR</cell><cell>GPT-2, etc</cell></row><row><cell cols="2">Reynolds and McDonell [2021] Zero-Shot</cell><cell>AR</cell><cell>GPT-3</cell></row><row><cell>Zero-shot-CoT (Ours)</cell><cell>Zero-Shot</cell><cell cols="2">AR,CR GPT-3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 8 :</head><label>8</label><figDesc>d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes] 2. If you are including theoretical results... (a) Did you state the full set of assumptions of all theoretical results? [N/A] (b) Did you include complete proofs of all theoretical results? [N/A] 3. If you ran experiments... (a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] (c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [No] Our paper mainly used GPT-3 API with greedy decoding, and there are no randomness for the experiments. (d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] 4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets... Dataset Description. Our experiments used publicly available datasets except for "Last Letters" and "Coin Flip" datasets. We created these two datasets. See Appendix A.2.2 for the details. (*1) N : Number, M : Pick up one from multiple choices, Y : Answer Yes or No, F : Free Format. (*2) Average number of words in questions texts.</figDesc><table><row><cell>if</cell></row></table><note><p>(a) If your work uses existing assets, did you cite the creators? [Yes] (b) Did you mention the license of the assets? [Yes] (c) Did you include any new assets either in the supplemental material or as a URL? [Yes] (d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes] (e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes] 5. If you used crowdsourcing or conducted research with human subjects... (a) Did you include the full text of instructions given to participants and screenshots,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 9 Table 9 :</head><label>99</label><figDesc>Description of language models. (*1) As for GPT-3 model series, we attach model size information to each model by referring to https://blog.eleuther.ai/gpt3-model-sizes/</figDesc><table><row><cell cols="3">Language Model # of params Library / API Name</cell><cell cols="2">Model Name in Library / API License</cell></row><row><cell>Original GPT3</cell><cell>175B (*1)</cell><cell>OpenAI API</cell><cell>davinci</cell><cell>unspecified</cell></row><row><cell>Original GPT3</cell><cell>6.7B (*1)</cell><cell>OpenAI API</cell><cell>curie</cell><cell>unspecified</cell></row><row><cell>Original GPT3</cell><cell>1.3B (*1)</cell><cell>OpenAI API</cell><cell>babbage</cell><cell>unspecified</cell></row><row><cell>Original GPT3</cell><cell>0.3B (*1)</cell><cell>OpenAI API</cell><cell>ada</cell><cell>unspecified</cell></row><row><cell>Instruct GPT3</cell><cell>175B (*1)</cell><cell>OpenAI API</cell><cell>text-davinci-002</cell><cell>unspecified</cell></row><row><cell>Instruct GPT3</cell><cell>6.7B (*1)</cell><cell>OpenAI API</cell><cell>text-curie-001</cell><cell>unspecified</cell></row><row><cell>Instruct GPT3</cell><cell>1.3B (*1)</cell><cell>OpenAI API</cell><cell>text-babbage-001</cell><cell>unspecified</cell></row><row><cell>Instruct GPT3</cell><cell>0.3B (*1)</cell><cell>OpenAI API</cell><cell>text-ada-001</cell><cell>unspecified</cell></row><row><cell>OPT</cell><cell>13B</cell><cell cols="2">Hugging Face Library opt-13b</cell><cell>Apache-2.0</cell></row><row><cell>T0</cell><cell>11B</cell><cell cols="2">Hugging Face Library T0pp</cell><cell>Apache-2.0</cell></row><row><cell>GPT-J</cell><cell>6B</cell><cell cols="2">Hugging Face Library gptj</cell><cell>Apache-2.0</cell></row><row><cell>GPT-Neo</cell><cell>2.7B</cell><cell cols="2">Hugging Face Library gpt-neo</cell><cell>Apache-2.0</cell></row><row><cell>GPT-2</cell><cell>1.5B</cell><cell cols="2">Hugging Face Library gpt2-xl</cell><cell>Apache-2.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 10 and</head><label>10</label><figDesc>Table 11 summarizes a list of answer extraction prompts used for the experiments at</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 1 .</head><label>1</label><figDesc>We used Zero-shot (left) and Zero-shot-CoT (left) as default prompts for answer extraction across all the experiments.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 :</head><label>10</label><figDesc>Answer extraction prompts used for Zero-shot experiments in Table 1. C.S.QA : Common-senseQA, D.U. : Date Understanding, S.O. : Tracking Shuffled Objects</figDesc><table><row><cell>No Task</cell><cell>Zero-Shot (left)</cell><cell>Zero-Shot (right)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 13 :</head><label>13</label><figDesc>Example outputs by Zero-shot-CoT for each datasets.</figDesc><table><row><cell>Dataset</cell><cell>Question</cell><cell>Answer</cell></row><row><cell>SingleEq</cell><cell>Q: A spaceship traveled 0.5</cell><cell></cell></row><row><cell></cell><cell>of a light-year from Earth to</cell><cell></cell></row><row><cell></cell><cell>Planet X and 0.1 of a light-</cell><cell></cell></row><row><cell></cell><cell>year from Planet X to Planet Y.</cell><cell></cell></row><row><cell></cell><cell>Then it traveled 0.1 of a light-</cell><cell></cell></row><row><cell></cell><cell>year from Planet Y back to</cell><cell></cell></row><row><cell></cell><cell>Earth. How many light-years</cell><cell></cell></row><row><cell></cell><cell>did the spaceship travel in all?</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 13 -</head><label>13</label><figDesc>Continued from previous page</figDesc><table><row><cell>Dataset</cell><cell>Question</cell><cell>Answer</cell></row><row><cell></cell><cell>Q: Mary is baking a cake. The</cell><cell>A: Let's think step by step. Mary has already put</cell></row><row><cell></cell><cell>recipe calls for 12 cups of flour</cell><cell>in 2 cups of flour. The recipe calls for a total of 12</cell></row><row><cell></cell><cell>14 cups of sugar and 7 cups of</cell><cell>cups of flour. That means Mary needs to add 10</cell></row><row><cell></cell><cell>salt. She already put in 2 cups</cell><cell>more cups of flour. The recipe calls for a total of 7</cell></row><row><cell></cell><cell>of flour. How many more cups</cell><cell>cups of salt. That means Mary needs to add 5 more</cell></row><row><cell></cell><cell>of flour than cups of salt does</cell><cell>cups of salt. So, Mary needs to add 10 more cups</cell></row><row><cell></cell><cell>she need to add now?</cell><cell>of flour than she does salt. Therefore, the answer</cell></row><row><cell></cell><cell></cell><cell>(arabic numerals) is 10. (GT : 3)</cell></row><row><cell>Common-</cell><cell>Q: If there is a pond with trees</cell><cell>A: Let's think step by step. A pond is likely to</cell></row><row><cell>senseQA</cell><cell>around it, where is it likely lo-</cell><cell>be located near trees because trees need water to</cell></row><row><cell></cell><cell>cated? Answer Choices: (A)</cell><cell>survive. Therefore, the most likely location for a</cell></row><row><cell></cell><cell>ground (B) bathroom (C) for-</cell><cell>pond with trees around it is in a forest. Therefore,</cell></row><row><cell></cell><cell>est (D) countryside (E) rural</cell><cell>among A through E, the answer is C.</cell></row><row><cell></cell><cell>area</cell><cell></cell></row><row><cell></cell><cell>Q: David watched some nest-</cell><cell>A: Let's think step by step.</cell></row><row><cell></cell><cell>ing birds using his binoculars</cell><cell>First, we need to understand what the word "binoc-</cell></row><row><cell></cell><cell>while on vacation. Where</cell><cell>ulars" means. Binoculars are two telescopes that</cell></row><row><cell></cell><cell>might David be?. Answer</cell><cell>are joined together and allow a person to see things</cell></row><row><cell></cell><cell>Choices: (A) sky (B) vacca-</cell><cell>that are far away.</cell></row><row><cell></cell><cell>tion (C) forest (D) countryside</cell><cell>Now, we need to think about where a person might</cell></row><row><cell></cell><cell>(E) roof</cell><cell>use binoculars. A person might use binoculars to</cell></row><row><cell></cell><cell></cell><cell>see things that are far away and in the sky, or to</cell></row><row><cell></cell><cell></cell><cell>see things that are far away and on the ground.</cell></row><row><cell></cell><cell></cell><cell>So, the answer could be either (A) sky or (D) coun-</cell></row><row><cell></cell><cell></cell><cell>tryside.</cell></row><row><cell></cell><cell></cell><cell>Therefore, among A through E, the answer is (A)</cell></row><row><cell></cell><cell></cell><cell>or (D). (GT : C)</cell></row><row><cell>StrategyQA</cell><cell>Q: Would JPEG be a good for-</cell><cell></cell></row><row><cell></cell><cell>mat for saving an image of Da</cell><cell></cell></row><row><cell></cell><cell>Vinci's Vitruvian Man?</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 13 -</head><label>13</label><figDesc>Continued from previous page</figDesc><table><row><cell>Dataset</cell><cell>Question</cell><cell>Answer</cell></row><row><cell>Last Letters</cell><cell>Q: Take the last letters of</cell><cell></cell></row><row><cell></cell><cell>each words in "Vinny Landon</cell><cell></cell></row><row><cell></cell><cell>Miguel Caitlyn" and concate-</cell><cell></cell></row><row><cell></cell><cell>nate them.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 14 :</head><label>14</label><figDesc>Example outputs by Zero-Shot and Zero-Shot-CoT. The number within the parenthesis corresponds to the number in Table5. Megan received 11 pieces of candy from neighbors and 5 pieces from her older sister. That means she has a total of 16 pieces of candy. If she only ate 8 pieces a day, she would have to divide her candy into two days. That means she would have 8 pieces of candy for Day 1 and 8 pieces of candy for Day 2.</figDesc><table><row><cell>Question</cell><cell>Q: For Halloween Megan received 11 pieces of candy from neighbors and 5</cell></row><row><cell></cell><cell>pieces from her older sister. If she only ate 8 pieces a day, how long would the</cell></row><row><cell></cell><cell>candy last her?</cell></row><row><cell>Zero-Shot</cell><cell>A: The answer (arabic numerals) is 3 days.</cell></row><row><cell>Zero-shot-</cell><cell>A: Let's think step by step.</cell></row><row><cell>CoT (1)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 15 :</head><label>15</label><figDesc>Example outputs by Zero-Shot-CoT at various language models (GPT-3 models).</figDesc><table><row><cell>Question</cell><cell>Q: Adam bought 2 boxes of chocolate candy and 5 boxes of caramel</cell></row><row><cell></cell><cell>candy. If each box has 4 pieces inside it, how much candy did he have</cell></row><row><cell></cell><cell>total? (GT : 28)</cell></row><row><cell>Instruct GPT-3</cell><cell>A: Let's think step by step.</cell></row><row><cell>(0.3B)</cell><cell>If each box has 4 pieces inside it, Adam would have 4 pieces of candy</cell></row><row><cell>(Text-ada-001)</cell><cell>in it.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 16 :</head><label>16</label><figDesc>Example outputs by Zero-Shot-CoT at various language models (Models other than GPT-3).</figDesc><table><row><cell>Question</cell><cell>Q: Megan baked 68 cupcakes for her school's bake sale. If her brother,</cell></row><row><cell></cell><cell>Todd, ate 32 of them how many packages could she make if she put 6</cell></row><row><cell></cell><cell>cupcake in each package? (GT : 6)</cell></row><row><cell>GPT-2</cell><cell>A: Let's think step by step.</cell></row><row><cell>(1.5B)</cell><cell>Todd's brother, Todd, eats 32 cupcakes. Todd's brother, Todd, eats</cell></row><row><cell></cell><cell>32 cupcakes. Todd's brother, Todd, eats 32 cupcakes. Todd's brother,</cell></row><row><cell></cell><cell>Todd, eats 32 cupcakes. Todd's brother, Todd, eats 32 cupcakes. Todd's</cell></row><row><cell></cell><cell>brother, Todd, eats 32 cupcakes. Todd's brother, Todd, eats 32 cupcakes.</cell></row><row><cell></cell><cell>Todd's brother, Todd, eats 32 cupcakes. Todd's brother, Todd, eats</cell></row><row><cell></cell><cell>32 cupcakes. Todd's brother, Todd, eats 32 cupcakes. Todd's brother,</cell></row><row><cell></cell><cell>Todd, eats 32 cupcakes. Todd's brother, Todd, eats Therefore, the</cell></row><row><cell></cell><cell>answer (arabic numerals) is:</cell></row><row><cell></cell><cell>Therefore, the answer (arabic numerals) is:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 17 :</head><label>17</label><figDesc>An example output by Few-shot (8 exemplars in context. These exemplars are cited from<ref type="bibr" target="#b41">[Wei et al., 2022]</ref> and randomly shuffled). Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?</figDesc><table><row><cell>Few-Shot</cell><cell>***** Start In-Context Examples *****</cell></row><row><cell></cell><cell>Q:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 20 :</head><label>20</label><figDesc>An example output by Zero-Plus-Few-Shot-CoT (8 exemplars in context. These exemplars are cited from<ref type="bibr" target="#b41">[Wei et al., 2022]</ref> and randomly shuffled).To validate the correctness of chain of thought, we analyze texts generated by Zero-shot-CoT for CommonsenseQA and MultiArith datasets.</figDesc><table><row><cell>Zero-Plus-Few-</cell><cell>***** Start In-Context Examples *****</cell></row><row><cell>Shot-CoT</cell><cell>Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason</cell></row><row><cell></cell><cell>has 12 lollipops. How many lollipops did Jason give to Denny?</cell></row><row><cell></cell><cell>A: Let's think step by step. Jason started with 20 lollipops. Then he</cell></row><row><cell></cell><cell>had 12 after giving some to Denny. So he gave Denny 20 -12 = 8. The</cell></row><row><cell></cell><cell>answer is 8.</cell></row><row><cell></cell><cell>Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On</cell></row><row><cell></cell><cell>wednesday, he lost 2 more. How many golf balls did he have at the end</cell></row><row><cell></cell><cell>of wednesday?</cell></row><row><cell></cell><cell>A: Let's think step by step. Michael started with 58 golf balls. After</cell></row><row><cell></cell><cell>losing 23 on tuesday, he had 58 -23 = 35. After losing 2 more, he had</cell></row><row><cell></cell><cell>35 -2 = 33 golf balls. The answer is 33.</cell></row><row><cell></cell><cell>Q: If there are 3 cars in the parking lot and 2 more cars arrive, how</cell></row><row><cell></cell><cell>many cars are in the parking lot?</cell></row><row><cell></cell><cell>A: Let's think step by step. There are originally 3 cars. 2 more cars</cell></row><row><cell></cell><cell>arrive. 3 + 2 = 5. The answer is 5.</cell></row><row><cell></cell><cell>Q: There were nine computers in the server room. Five more com-</cell></row><row><cell></cell><cell>puters were installed each day, from monday to thursday. How many</cell></row><row><cell></cell><cell>computers are now in the server room?</cell></row><row><cell></cell><cell>A: Let's think step by step. There were originally 9 computers. For</cell></row><row><cell></cell><cell>each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers</cell></row><row><cell></cell><cell>were added. 9 + 20 is 29. The answer is 29.</cell></row><row><cell></cell><cell>Q: Olivia has 23.Sheboughtf ivebagelsf or3 each. How much money</cell></row><row><cell></cell><cell>does she have left?</cell></row><row><cell></cell><cell>A: Let's think step by step. Olivia had 23 dollars. 5 bagels for 3</cell></row><row><cell></cell><cell>dollars each will be 5 x 3 = 15 dollars. So she has 23 -15 dollars left.</cell></row><row><cell></cell><cell>23 -15 is 8. The answer is 8.</cell></row><row><cell></cell><cell>Q: There are 15 trees in the grove. Grove workers will plant trees in</cell></row><row><cell></cell><cell>the grove today. After they are done, there will be 21 trees. How many</cell></row><row><cell></cell><cell>trees did the grove workers plant today?</cell></row><row><cell></cell><cell>A: Let's think step by step. There are 15 trees originally. Then there</cell></row><row><cell></cell><cell>were 21 trees after some more were planted. So there must have been</cell></row><row><cell></cell><cell>21 -15 = 6. The answer is 6.</cell></row><row><cell></cell><cell>Q: Shawn has five toys. For Christmas, he got two toys each from his</cell></row><row><cell></cell><cell>mom and dad. How many toys does he have now?</cell></row><row><cell></cell><cell>A: Let's think step by step. Shawn started with 5 toys. If he got 2</cell></row><row><cell></cell><cell>toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.</cell></row><row><cell></cell><cell>The answer is 9.</cell></row><row><cell></cell><cell>Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how</cell></row><row><cell></cell><cell>many pieces do they have left in total?</cell></row><row><cell></cell><cell>A: Let's think step by step. Originally, Leah had 32 chocolates. Her</cell></row><row><cell></cell><cell>sister had 42. So in total they had 32 + 42 = 74. After eating 35, they</cell></row><row><cell></cell><cell>had 74 -35 = 39. The answer is 39.</cell></row><row><cell></cell><cell>***** End In-Context Examples *****</cell></row><row><cell></cell><cell>Q: For Halloween Megan received 11 pieces of candy from neighbors</cell></row><row><cell></cell><cell>and 5 pieces from her older sister. If she only ate 8 pieces a day, how</cell></row><row><cell></cell><cell>long would the candy last her?</cell></row><row><cell></cell><cell>A: Let's think step by step. Megan received 11 pieces of candy from</cell></row><row><cell></cell><cell>neighbors and 5 pieces from her older sister. So in total she had 11 + 5</cell></row><row><cell></cell><cell>= 16 pieces of candy. If she ate 8 pieces a day, it would last her 16 / 8</cell></row><row><cell></cell><cell>= 2 days. The answer is 2.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 21 :</head><label>21</label><figDesc>Categorization results of generated chain of thought by Zero-shot-CoT for CommonsenseQA datasets.Table 21 summarizes the categorization results of texts generated by Zero-shot-CoT for Common-senseQA.</figDesc><table><row><cell cols="2">Prediction CoT Category</cell><cell>Zero-Shot-CoT (%)</cell></row><row><cell>Correct</cell><cell>CoT is correct CoT is incorrect</cell><cell>78.0 22.0</cell></row><row><cell></cell><cell cols="2">CommonSense Mistake 62.0</cell></row><row><cell>Incorrect</cell><cell>Factual Mistake Logical Mistake</cell><cell>0.0 28.0</cell></row><row><cell></cell><cell>Others</cell><cell>10.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 22 Table 22 :</head><label>2222</label><figDesc>Prediction examples produced by Zero-shot-CoT for CommonsenseQA.</figDesc><table><row><cell>Category</cell><cell>Question</cell><cell>Answer</cell></row><row><cell>Correct -CoT</cell><cell>Q: If there is a pond with</cell><cell>A: Let's think step by step. A pond is likely to</cell></row><row><cell>is correct</cell><cell>trees around it, where it</cell><cell>be located near trees because trees need water to</cell></row><row><cell></cell><cell>it likely located? Answer</cell><cell>survive. Therefore, the most likely location for a</cell></row><row><cell></cell><cell>Choices: (A) ground (B)</cell><cell>pond with trees around it is in a forest. Therefore,</cell></row><row><cell></cell><cell>bathroom (C) forest (D)</cell><cell>among A through E, the answer is C.</cell></row><row><cell></cell><cell>countryside (E) rural area</cell><cell></cell></row><row><cell>Correct -CoT</cell><cell>Q: Human beings learn</cell><cell>A: Let's think step by step. How do human beings</cell></row><row><cell>is correct</cell><cell>about current events from</cell><cell>learn? They learn by observing and listening to</cell></row><row><cell></cell><cell>what print item? Answer</cell><cell>others, and they also learn by reading. So it's most</cell></row><row><cell></cell><cell>Choices: (A) question au-</cell><cell>likely that human beings learn about current events</cell></row><row><cell></cell><cell>thority (B) melt (C) read</cell><cell>from reading newspapers. Therefore, among A</cell></row><row><cell></cell><cell>newspapers (D) act (E)</cell><cell>through E, the answer is C.</cell></row><row><cell></cell><cell>dictionary</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Continued on next page</cell></row></table><note><p>E, the answer is A, B, C, D, or E. (Model cannot choose only one.) (GT : (A), Zero-shot: (E))</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 22 -</head><label>22</label><figDesc>Continued from previous page</figDesc><table><row><cell>Category</cell><cell cols="2">Question</cell><cell>Answer</cell></row><row><cell>CommonSense</cell><cell cols="2">Q: Where is a well</cell><cell>A: Let's think step by step. A toy car is likely to be</cell></row><row><cell>Mistake</cell><cell cols="2">used toy car likely to be</cell><cell>found in a child's room. A child's room is likely to</cell></row><row><cell></cell><cell cols="2">found? Answer Choices:</cell><cell>be found in a house. Therefore, a toy car likely to</cell></row><row><cell></cell><cell cols="2">(A) child's room (B)</cell><cell>be found in a house. Therefore, among A through</cell></row><row><cell></cell><cell cols="2">boy's bedroom (C) own</cell><cell>E, the answer is E. (GT : (A), Zero-shot: (A))</cell></row><row><cell></cell><cell cols="2">home (D) toy store (E)</cell></row><row><cell></cell><cell>house</cell><cell></cell></row><row><cell>CommonSense</cell><cell cols="2">Q: Where can you go to</cell></row><row><cell>Mistake</cell><cell cols="2">use a piano in your neigh-</cell></row><row><cell></cell><cell cols="2">borhood if you don't</cell></row><row><cell></cell><cell>have one?</cell><cell>Answer</cell></row><row><cell></cell><cell>Choices:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 22 -</head><label>22</label><figDesc>Continued from previous page</figDesc><table><row><cell>Category</cell><cell>Question</cell><cell>Answer</cell></row><row><cell>Logical</cell><cell>Q: If you really wanted a</cell><cell>A: Let's think step by step. If you want a grape, the</cell></row><row><cell>Mistake</cell><cell>grape, where would you</cell><cell>first place you might think to look is a fruit stand. If</cell></row><row><cell></cell><cell>go to get it? Answer</cell><cell>there are no grapes at the fruit stand, your next best</cell></row><row><cell></cell><cell>Choices: (A) winery (B)</cell><cell>bet would be grocery store. If there are no grapes</cell></row><row><cell></cell><cell>fruit stand (C) field (D)</cell><cell>at the grocery store, you might try a vineyard or</cell></row><row><cell></cell><cell>kitchen (E) food</cell><cell>winery. If there are no grapes at the vineyard or</cell></row><row><cell></cell><cell></cell><cell>winery, your last resort would be to grow your own</cell></row><row><cell></cell><cell></cell><cell>grapes. Therefore, among A through E, the answer</cell></row><row><cell></cell><cell></cell><cell>is E. (GT : (B), Zero-shot: (B))</cell></row><row><cell>C.2 MultiArith</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 23 :</head><label>23</label><figDesc>Categorization results of produced chain of thought for MultiArith datasets. (*1) These categories are cited from<ref type="bibr" target="#b41">Wei et al. [2022]</ref>.Table23summarizes the categorization results of texts generated by Zero-shot-CoT and Few-shot-CoT for MultiArith. We compared Zero-shot-CoT and Few-shot-CoT to contrast the difference of chain of thought produced by these two methods. Specifically, we randomly picked up correct 50 samples and incorrect 50 samples produced by each method and categorized them by types. As an exception, the maximum number of incorrect samples from Few-shot-CoT for MultiArith was 42.</figDesc><table><row><cell>Prediction</cell><cell>CoT Category</cell><cell cols="2">Zero-Shot-CoT (%) Few-Shot-CoT (%)</cell></row><row><cell>Correct</cell><cell>CoT is correct CoT is incorrect</cell><cell>94.0 6.0</cell><cell>98.0 2.0</cell></row><row><cell></cell><cell>CommonSense Mistake</cell><cell>10.0</cell><cell>23.8</cell></row><row><cell></cell><cell>Factual Mistake</cell><cell>2.0</cell><cell>0.0</cell></row><row><cell></cell><cell>Logical Mistake</cell><cell>68.0</cell><cell>73.8</cell></row><row><cell></cell><cell>-Calculator error (*1)</cell><cell>(8.)</cell><cell>(26.2)</cell></row><row><cell>Incorrect</cell><cell>-Symbol mapping error (*1)</cell><cell>(4.)</cell><cell>(2.4)</cell></row><row><cell></cell><cell>-One step missing error (*1)</cell><cell>(6.)</cell><cell>(7.1)</cell></row><row><cell></cell><cell>-One unnecessary step error</cell><cell>(10.)</cell><cell>(2.4)</cell></row><row><cell></cell><cell>-More complicated</cell><cell>(40.)</cell><cell>(35.7)</cell></row><row><cell></cell><cell>Others</cell><cell>20.0</cell><cell>2.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29"><head>Table 24 :</head><label>24</label><figDesc>Example-based comparison between Zero-shot-CoT and Few-shot-CoT from MultiArith. Let's think step by step. Adam bought 13 tickets. That means he spent 13 * 9 = 117 dollars on tickets. After riding the ferris wheel, he had 4 tickets left. That means he used 9 tickets to ride the ferris wheel. That means he spent 9 * 9 = 81 dollars on riding the ferris wheel. So the answer is 117 -81 = 36 dollars. Let's think step by step. There are 8 kids, so that means there are 7 adults. Each adult meal costs $5, so that means that the 7 adults will cost $5*7=$35 Now we just need to add the two numbers together. $35+8=43$ So it would cost $43 for the group to eat.</figDesc><table><row><cell>Question</cell><cell>Zero-shot-CoT</cell><cell>Few-shot-CoT</cell></row><row><cell>Q: At the fair Adam</cell><cell>A (ONE UNNECESSARY STEP ER-</cell><cell>A: Adam started with 13</cell></row><row><cell>bought 13 tickets. Af-ter riding the ferris wheel he had 4 tickets left. If each ticket cost 9 dol-lars, how much money did Adam spend riding the ferris wheel?</cell><cell>ROR): Therefore, the answer (arabic numerals)</cell><cell>tickets. He had 4 left af-ter riding the ferris wheel. So he must have spent 13 -4 = 9 tickets. 9 tickets times 9 dollars per ticket is 9 * 9 = 81. The answer is 81.</cell></row><row><cell></cell><cell>is 36.</cell><cell></cell></row><row><cell>Q: At a restaurant each</cell><cell>A (ONE UNNECESSARY STEP ER-</cell><cell></cell></row><row><cell>adult meal costs $5 and</cell><cell>ROR):</cell><cell></cell></row><row><cell>kids eat free. If a group</cell><cell></cell><cell></cell></row><row><cell>of 15 people came in</cell><cell></cell><cell></cell></row><row><cell>and 8 were kids, how</cell><cell></cell><cell></cell></row><row><cell>much would it cost for</cell><cell></cell><cell></cell></row><row><cell>the group to eat?</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_30"><head>Table 24</head><label>24</label><figDesc>Let's think step by step. Jerry can carry 8 trays at a time. There are 9 trays on the first table. That means Jerry will need to make 2 trips to the first table. There are 7 trays on the second table. That means Jerry will need to make 1 trip to the second table. In total, Jerry will make 3 trips. Therefore, the answer (arabic numerals) is 3. : Let's think step by step. Kaleb bought 14 boxes of chocolate candy. This means that he had 84 pieces of chocolate candy. He gave 5 boxes to his little brother, which means that he gave his little brother 30 pieces of chocolate candy. Kaleb still had 54 pieces of chocolate candy. Therefore, the answer (arabic numerals) is 54.</figDesc><table><row><cell></cell><cell>-continued from previous page</cell><cell></cell></row><row><cell>Question</cell><cell>Zero-shot-CoT</cell><cell cols="2">Few-shot-CoT</cell></row><row><cell>Q: Jerry was helping the</cell><cell>A (COMMONSENSE MISTAKE):</cell><cell cols="2">A: Jerry can carry 8 trays</cell></row><row><cell>cafeteria workers pick up</cell><cell></cell><cell cols="2">at a time. If he has to pick</cell></row><row><cell>lunch trays, but he could</cell><cell></cell><cell cols="2">up 9 trays from one table</cell></row><row><cell>only carry 8 trays at a</cell><cell></cell><cell cols="2">and 7 trays from another,</cell></row><row><cell>time. If he had to pick</cell><cell></cell><cell cols="2">he will have to make 2</cell></row><row><cell>up 9 trays from one table</cell><cell></cell><cell cols="2">trips. The answer is 2.</cell></row><row><cell>and 7 trays from another,</cell><cell></cell><cell></cell></row><row><cell>how many trips will he</cell><cell></cell><cell></cell></row><row><cell>make?</cell><cell></cell><cell></cell></row><row><cell>Q: Kaleb bought 14</cell><cell></cell><cell cols="2">A (COMMONSENSE</cell></row><row><cell>boxes of chocolate candy</cell><cell></cell><cell>MISTAKE):</cell><cell>Kaleb</cell></row><row><cell>and gave 5 to his little</cell><cell></cell><cell cols="2">bought 14 boxes. Each</cell></row><row><cell>brother. If each box has</cell><cell></cell><cell cols="2">box has 6 pieces. So 14 *</cell></row><row><cell>6 pieces inside it, how</cell><cell></cell><cell cols="2">6 = 84 pieces. He gave 5</cell></row><row><cell>many pieces did Kaleb</cell><cell></cell><cell cols="2">to his brother. So he has</cell></row><row><cell>still have?</cell><cell></cell><cell cols="2">84 -5 = 79 pieces. The</cell></row><row><cell></cell><cell></cell><cell>answer is 79.</cell></row></table><note><p>A</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head>Table 24</head><label>24</label><figDesc>Let's think step by step. Each chocolate bar in a box costs $3. If a box had 9 bars total, then Wendy sold all but 3 bars. How much money would she have made? We can solve this problem using algebra. Let's start by creating a variable to represent the number of chocolate bars Wendy sold. We'll call this variable "x". If Wendy sold "x" chocolate bars, then she would have 9 -x chocolate bars left in the box. We know that each chocolate bar costs $3, so the total cost of the chocolate bars Wendy sold Therefore, the answer (arabic numerals) is: Wendy would have made $12.</figDesc><table><row><cell></cell><cell>-continued from previous page</cell><cell></cell></row><row><cell>Question</cell><cell>Zero-shot-CoT</cell><cell>Few-shot-CoT</cell></row><row><cell>Q: Each chocolate bar</cell><cell>A (OTHERS; MAXIMUM LIMIT</cell><cell></cell></row><row><cell>in a box cost $3. If a</cell><cell>OF TEXT LENGTH):</cell><cell></cell></row><row><cell>box had 9 bars total and</cell><cell></cell><cell></cell></row><row><cell>Wendy sold all but 3 bars,</cell><cell></cell><cell></cell></row><row><cell>how much money would</cell><cell></cell><cell></cell></row><row><cell>she have made?</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>While prior work[Wei et al.,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2022] categorized Date Understanding task into Common Sense reasoning, our study categorized this task into logical reasoning because this task requires less prior knowledge and more logical reasoning between dates.2 Our experiments are run between April-2022 and May-2022 by using OpenAI API. We attach model size information to each model referring to the following URL. https://blog.eleuther.ai/gpt3-model-sizes/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Therefore, the answer (arabic numerals) is Therefore, the answer is 2 AddSub</p><p>Therefore, the answer (arabic numerals) is</p><p>Therefore, the answer is 3 MultiArith</p><p>Therefore, the answer (arabic numerals) is Therefore, the answer is 4 GSM8K</p><p>Therefore, the answer (arabic numerals) is Therefore, the answer is 5 AQUA-RAT Therefore, among A through E, the answer is Therefore, the answer is 6 SVAMP</p><p>Therefore, the answer (arabic numerals) is Therefore, the answer is 7 C.S.QA Therefore, among A through E, the answer is Therefore, the answer is 8 StrategyQA</p><p>Therefore, the answer (Yes or No) is</p><p>Therefore, the answer is 9 D.U.</p><p>Therefore, among A through F, the answer is Therefore, the answer is 10 S.O.</p><p>Therefore, among A through C, the answer is Therefore, the answer is 11 Last Letters -Therefore, the answer is 12 Coin Flip</p><p>Therefore, the answer (Yes or No) is Therefore, the answer is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple-Choice</head><p>Pick up the first large letter encountered in the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes or No</head><p>Pick up the first "yes" or "no" encountered in the text after removing unnecessary letters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Experiment Results</head><p>This section summarizes more example texts generated in our experiments. Note that for readability all texts are modified from the original ones by omitting or inserting some linebreaks.</p><p>? Table <ref type="table">13</ref> lists example texts generated by Zero-shot-CoT for each dataset (See Table <ref type="table">1</ref>). </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Big-bench collaboration. beyond the imitation game: Measuring and extrapolating the capabilities of language models</title>
		<ptr target="https://github.com/google/BIG-bench" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2022" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Michael Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Brohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yevgen</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keerthana</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmine</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Irpan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosario</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Jauregui Ruano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sally</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName><surname>Jesmonth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nikhil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Julian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuheng</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuang-Huei</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolina</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Parada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jornell</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishka</forename><surname>Quiambao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Rettinghouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clayton</forename><surname>Sievers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sichun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><surname>Yan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.01691" />
		<title level="m">Do as i can, not as i say: Grounding language in robotic affordances</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.01547</idno>
		<ptr target="https://arxiv.org/abs/1911.01547" />
		<title level="m">On the measure of intelligence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathy</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><surname>Eck</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.02311" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<pubPlace>Jeff Dean, Slav Petrov</pubPlace>
		</imprint>
	</monogr>
	<note>and Noah Fiedel. Palm: Scaling language modeling with pathways</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiichiro</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.14168" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Travis</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anish</forename><surname>Thite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noa</forename><surname>Nabeshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shawn</forename><surname>Presser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<idno>arXiv: Arxiv-2101.00027</idno>
		<title level="m">The pile: An 800gb dataset of diverse text for language modeling</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.acl-long.295" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3816" to="3830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies</title>
		<author>
			<persName><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elad</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.tacl-1.21/" />
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="346" to="361" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to solve arithmetic word problems with verb categorization</title>
		<author>
			<persName><forename type="first">Mohammad Javad</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/D14-1058/" />
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">523533</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The structure of human intelligence: It is verbal, perceptual, and image rotation (vpr), not fluid and crystallized</title>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><surname>Bouchard</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="393" to="416" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parsing algebraic word problems into equations</title>
		<author>
			<persName><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siena</forename><surname>Dumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ang</forename></persName>
		</author>
		<ptr target="https://aclanthology.org/Q15-1042" />
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="585" to="597" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MAWPS: A math word problem repository</title>
		<author>
			<persName><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aida</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N16-1136" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1152" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Program induction by rationale generation: Learning to solve and explain algebraic word problems</title>
		<author>
			<persName><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/P17-1015" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="158" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">What makes good in-context examples for</title>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06804</idno>
		<ptr target="https://arxiv.org/abs/2101.06804" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">gpt-3? arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.13586</idno>
		<ptr target="https://arxiv.org/abs/2107.13586" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alastair</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.acl-long.556" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8086" to="8098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The cattell-horn-carroll theory of cognitive abilities: Past, present, and future</title>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">S</forename><surname>Mcgrew</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>arXiv: Arxiv-1609.07843</idno>
		<ptr target="https://arxiv.org/abs/1609.07843" />
		<title level="m">Pointer sentinel mixture models</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Rethinking the role of demonstrations: What makes in-context learning work</title>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxi</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12837</idno>
		<ptr target="https://arxiv.org/pdf/2202.12837.pdf" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Show your work: Scratchpads for intermediate computation with language models</title>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Johan Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HBlx2idbkbq" />
	</analytic>
	<monogr>
		<title level="m">Deep Learning for Code Workshop</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2203.02155" />
		<title level="m">Training language models to follow instructions with human feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<ptr target="https://papers.nips.cc/paper/2019/hash/bdbca288fee" />
	</analytic>
	<monogr>
		<title level="j">Advances in NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8026" to="8037" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>f92f2bfa9f7012727740-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Are NLP models really able to solve simple math word problems?</title>
		<author>
			<persName><forename type="first">Arkil</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satwik</forename><surname>Bhattamishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Goyal</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.naacl-main.168" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2080" to="2094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="http://www.persagen.com/files/misc/radford2019language.pdf" />
	</analytic>
	<monogr>
		<title level="m">OpenAI blog, page 9</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albin</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhant</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esme</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michela</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lena</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aida</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenic</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolai</forename><surname>Tsimpoukelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Grigorev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Sottiaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><surname>Pajarskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Pohlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayfun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelia</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Hechtman</surname></persName>
		</author>
		<author>
			<persName><surname>Weidinger</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2112.11446" />
		<editor>Iason Gabriel, William Isaac, Ed Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Scaling language models: Methods, analysis &amp; insights from training gopher</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Explain yourself! leveraging language models for commonsense reasoning</title>
		<author>
			<persName><forename type="first">Nazneen</forename><surname>Fatema Rajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/P19-1487" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4932" to="4942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Prompt programming for large language models: Beyond the few-shot paradigm</title>
		<author>
			<persName><forename type="first">Laria</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/2102.07350.pdf" />
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Solving general arithmetic word problems</title>
		<author>
			<persName><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/D15-1202" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1743" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urmish</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanya</forename><surname>Sharma Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Szczechla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taewoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nihal</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debajyoti</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Tian-Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng Xin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshit</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trishala</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos</forename><surname>Neeraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abheesht</forename><surname>Rozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Fevry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Teehan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=9Vrb9D0WI4" />
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">It&apos;s not just size that matters: Small language models are also fewshot learners</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.naacl-main.185" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2339" to="2352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Auto-Prompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.emnlp-main.346" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4222" to="4235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised commonsense question answering with self-talk</title>
		<author>
			<persName><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.emnlp-main.373" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4615" to="4629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model</title>
		<author>
			<persName><forename type="first">Shaden</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostofa</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Legresley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samyam</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shrimai</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Zerveas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Korthikanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elton</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Yazdani Aminabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Bernauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.11990" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Individual differences in reasoning: Implications for the rationality debate?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">F</forename><surname>Stanovich</surname></persName>
		</author>
		<author>
			<persName><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="645" to="665" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N19-1421/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaguang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongrae</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaixiu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Steven Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Ghafouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Menegali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung-Ching</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Rusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranesh</forename><surname>Pickett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laichee</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tulsee</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renelito Delos</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnny</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Soraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinodkumar</forename><surname>Zevenbergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Lamda</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.08239" />
		<title level="m">Language models for dialog applications</title>
		<editor>
			<persName><forename type="first">Alejandra</forename><surname>Molina</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Erin</forename><surname>Hoffman-John</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Josh</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lora</forename><surname>Aroyo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ravi</forename><surname>Rajakumar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alena</forename><surname>Butryna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Matthew</forename><surname>Lamm</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Viktoriya</forename><surname>Kuzmina</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joe</forename><surname>Fenton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aaron</forename><surname>Cohen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rachel</forename><surname>Bernstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Blaise</forename><surname>Aguera-Arcas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Claire</forename><surname>Cui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marian</forename><surname>Croak</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">? Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/file/3" />
	</analytic>
	<monogr>
		<title level="m">Advances in NeurIPS</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<ptr target="https://arxiv.org/abs/2203.11171" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2201.11903" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2203.14465" />
		<title level="m">Star: Bootstrapping reasoning with reasoning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Opt: Open pre-trained transformer language models</title>
		<author>
			<persName><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<ptr target="https://arxiv.org/abs/2205.01068.Checklist" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Do the main claims made in the abstract and introduction accurately reflect the paper&apos;s contributions and scope? [Yes] (b) Did you describe the limitations of your work? [Yes] (c) Did you discuss any potential negative societal impacts of your work</title>
		<imprint>
			<publisher>For all authors</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
