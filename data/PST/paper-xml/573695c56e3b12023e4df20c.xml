<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">*Highlights (for review)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-04-09">April 9, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">John</forename><surname>Arevalo</surname></persName>
							<email>jearevaloo@unal.edu.co</email>
							<affiliation key="aff0">
								<orgName type="department">Systems and Computer Engineering Department</orgName>
								<orgName type="laboratory">Machine learning, perception and discovery Lab</orgName>
								<orgName type="institution">Universidad Nacional de Colombia</orgName>
								<address>
									<addrLine>Cra 30 No 45 03-Ciudad Universitaria</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Engineering -Building</orgName>
								<address>
									<addrLine>453 Office 114</addrLine>
									<settlement>Bogotá</settlement>
									<region>DC</region>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Angel</forename><surname>Cruz-Roa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Systems and Computer Engineering Department</orgName>
								<orgName type="laboratory">Machine learning, perception and discovery Lab</orgName>
								<orgName type="institution">Universidad Nacional de Colombia</orgName>
								<address>
									<addrLine>Cra 30 No 45 03-Ciudad Universitaria</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Engineering -Building</orgName>
								<address>
									<addrLine>453 Office 114</addrLine>
									<settlement>Bogotá</settlement>
									<region>DC</region>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Viviana</forename><surname>Arias</surname></persName>
							<email>vlariasp@unal.edu.co</email>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Pathology Department</orgName>
								<orgName type="department" key="dep2">Faculty of Medicine</orgName>
								<orgName type="institution">Universidad Nacional de Colombia</orgName>
								<address>
									<addrLine>Cra 30 No 45 03-Ciudad Universitaria</addrLine>
									<settlement>Bogotá</settlement>
									<region>DC</region>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eduardo</forename><surname>Romero</surname></persName>
							<email>edromero@unal.edu.co</email>
							<affiliation key="aff3">
								<orgName type="department">Faculty of Medicine</orgName>
								<orgName type="laboratory">Computer Imaging &amp; Medical Applications Laboratory</orgName>
								<orgName type="institution">Universidad Nacional de Colombia</orgName>
								<address>
									<addrLine>Cra 30 No 45 03-Ciudad Universitaria</addrLine>
									<settlement>Bogotá</settlement>
									<region>DC</region>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabio</forename><forename type="middle">A</forename><surname>González</surname></persName>
							<email>fagonzalezo@unal.edu.co</email>
							<affiliation key="aff0">
								<orgName type="department">Systems and Computer Engineering Department</orgName>
								<orgName type="laboratory">Machine learning, perception and discovery Lab</orgName>
								<orgName type="institution">Universidad Nacional de Colombia</orgName>
								<address>
									<addrLine>Cra 30 No 45 03-Ciudad Universitaria</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Engineering -Building</orgName>
								<address>
									<addrLine>453 Office 114</addrLine>
									<settlement>Bogotá</settlement>
									<region>DC</region>
									<country key="CO">Colombia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">*Highlights (for review)</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-04-09">April 9, 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">3DFDB4546E1C97AE522448E914BBD09A</idno>
					<idno type="DOI">10.1016/j.artmed.2015.04.004</idno>
					<note type="submission">Preprint submitted to Elsevier</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>digital pathology</term>
					<term>representation learning</term>
					<term>unsupervised feature learning</term>
					<term>basal cell carcinoma</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Highlights</head><p> A framework for basal cell carcinoma detection based on unsupervised feature learning.</p><p> Experimental results show an improvement when compared to state-of-the-art methods.</p><p> The framework integrates a digital staining method which improves interpretability.</p><p> Digital staining highlights regions in the image which the model relates to cancer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A c c e p t e d M a n u s c r i p t</head><p>An unsupervised feature learning framework for basal cell carcinoma image analysis</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Digital pathology refers to the set of computational methods and technologies that support the different pathology workflow stages, including digital slide acquisition, computer aided diagnosis, prognosis and theragnosis <ref type="bibr" target="#b0">[1]</ref>. The importance and popularity of digital pathology have rapidly grown during the last years thanks of the emergence of fast, cost-effective whole slide image acquisition systems. An important component of digital pathology is automatic image analysis, which is fundamental for tasks such as automatic tumor detection and grading <ref type="bibr" target="#b1">[2]</ref>. Automatic image analysis encompasses different kinds of computer vision and pattern recognition problems associated with the detection, segmentation and classification of biological structures (pathological and non-pathological).</p><p>A c c e p t e d M a n u s c r i p t</p><p>The success of any histopathology image analysis method depends on how well it captures morphological and architectural characteristics from nuclei, cells, glands, organs and tissues. In turn this depends on how well the method characterizes the visual content of the histopathology image. This characterization is accomplished by a feature extraction process which typically uses canonical (e.g. wavelet transforms) or hand-engineered features (e.g. SIFT). Different visual features have been proposed and extensively evaluated in different histopathology image analysis problems: 1) object level features to characterize biological structures, e.g. size and shape, radiometric and densitometric, texture, chromatin-specific; 2) spatially related features to represent the architectural arrangement of cells or other structures, usually derived from graph-based representations and descriptors, e.g. Voronoi tessellation, Delaunay triangulation, minimum spanning graph, connected graph, relative neighbor graph and others <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>; 3) multi-scale feature extraction algorithms, e.g. multi-resolution, pyramid and hierarchical representation of images among others <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. Mostly, feature choice is handmade and based on the particularities of the problem at hand. However, recent investigations in computer vision suggests that strategies which learn the image representation directly, and automatically, from image collections may produce better representations resulting in better performance of automatic analysis algorithms <ref type="bibr" target="#b3">[4]</ref>. This approach, known as unsupervised feature learning (UFL), has been applied to different computer vision and pattern recognition problems with great success <ref type="bibr" target="#b4">[5]</ref>.</p><p>This paper explores the application of UFL strategies to the representation and automatic analysis of histopathology images. In particular, the paper presents a framework for basal cell carcinoma (BCC) image analysis which is able to learn an appropriate representation from a representative set of images for automatic carcinoma detection. The experimental evaluation shows that a strategy to endow the classification method with a visual interpretation layer, which exploits both the hierarchical representation of the model, to highlight those regions of the image that contribute to a higher degree to the model prediction, and the topographic organization of the learned representation, to identify visual patterns associated with tumor and nontumor images; and a systematic evaluation of different UFL strategies on BCC histopathology images, which shows that, in this particular problem, learned features outperform state-of-the-art canonical representations.</p><p>The rest of the paper is organized as follows: section 2 makes a review of the relevant literature, Section 3 describes the unified unsupervised learning framework for BCC histopathology image representation and analysis; Section 4 presents the results of experimental evaluation for BCC detection. Finally, conclusions are presented in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Nowadays, the explosion of big data in pathology research is bringing many opportunities and challenges that have given birth to a novel research area known as digital pathology <ref type="bibr" target="#b0">[1]</ref>. This is possible thanks to the massification of histology slide scanners as part of the pathology routine, the increase on the A c c e p t e d M a n u s c r i p t number of publicly available histology and histopathology image databases, and the development of virtual slide navigation systems <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Digital or computational pathology is a new emerging area that investigates a complete probabilistic treatment of scientific and clinical workflows in general pathology, i.e. it combines experimental design, statistical pattern recognition and survival analysis within a unified framework to answer scientific and clinical questions in pathology <ref type="bibr" target="#b7">[8]</ref>. This area is faced with big challenges such as automatic diagnosis and objective quantification of disease's indicators for personalized diagnosis <ref type="bibr" target="#b0">[1]</ref>. Typically, tumor detection and grading are the main goals in pathology digital slide analysis <ref type="bibr" target="#b1">[2]</ref>. The main goal of tumor detection is to differentiate between healthy and tumor tissues to support diagnosis.</p><p>The goal of grading is to quantify architectural and morphological signatures within tumor to classify the grade of aggressiveness, which is very important to determine the appropriate treatment for each patient. These two problems are mainly addressed combining two different, but complementary strategies:</p><p>1) hand-crafted features to capture chromatin, morphological and architectural characteristics from nuclei, glands and tissues, and 2) machine learning methods to induce models that use the visual features for detection, segmentation, and classification of biological structures or types of cancer.</p><p>There is an extensive literature in automatic histopathology image analysis. forme from the TCGA<ref type="foot" target="#foot_0">1</ref> database. They learned the feature representation in an unsupervised way using a reconstruction independent subspace analysis network <ref type="bibr" target="#b28">[29]</ref>. Cruz-Roa et al. <ref type="bibr" target="#b29">[30]</ref> proposed a CNN-based framework for invasive ductal carcinoma tumor region detection in whole-slide breast cancer images improving the performance in comparison with a set of hand-crafted features used in computer vision and histopathology image analysis. Recently, CNN models had been also applied to the challenging task of automatic mitosis detection in breast cancer histopathology images <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>. In <ref type="bibr" target="#b30">[31]</ref> the authors propose combining a set of hand-crafted features with a CNN. Whereas, authors in <ref type="bibr" target="#b31">[32]</ref> proposed a more sophisticated and large, GPU optimized, CNN architecture trained over a huge amount of training data, around 1 million samples for training. These two strategies got the fourth and first place respectively in the mitosis detection challenge in ICPR'2012 <ref type="bibr" target="#b34">[35]</ref>. However, the ICPR'2012 winner <ref type="bibr" target="#b31">[32]</ref> used an A c c e p t e d M a n u s c r i p t implementation that is not easy to apply in the clinical practice due to the high computing time required for training and prediction and the special requirements of GPU hardware. Recently, Wang et al. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref> proposed an approach which combines hand-crafted features with a CNN using a cascade of classifiers to predict mitosis presence. This approach obtained better results than other hand-crafted features and CNN combination methods <ref type="bibr" target="#b30">[31]</ref>.</p><p>Most of the above previous works in histopathology image analysis are focused on supervised feature learning techniques such as CNN models. These kind of methods are addressed to solve supervised tasks, such as nuclei segmentation or tissue classification, where the learned representation depends on a particular supervised task. Nevertheless, it is possible to look for an appropriate image representation regardless of a particular high-level task. This representation must capture visual patterns which are the building blocks of the visual content. This unsupervised approach has an additional advantage, it does not depend on labeled samples and prior knowledge provided by experts.</p><p>In many cases this labeled data is not available, particularly in a biomedical domain due to limitations in time or cost. UFL methods have shown successful and promising results to automatically learn the appropriate image representation from raw data <ref type="bibr" target="#b22">[23]</ref>. In addition, since 2006 a breakthrough in feature learning was initiated by Geoff Hinton <ref type="bibr" target="#b3">[4]</ref> proposing novel methods to learn a hierarchy of features one level at a time in a unsupervised way. This allows a faster training of deep architecture models (networks with multiple layers) for representation learning. However, UFL have not been sufficiently explored for histopathology image analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Basal cell carcinoma</head><p>BCC is the most common skin disease <ref type="bibr" target="#b35">[36]</ref> and its incidence is growing worldwide <ref type="bibr" target="#b36">[37]</ref>.  interest in BCC images, allowing to concentrate any processing effort on specific image areas. Díaz and Romero <ref type="bibr" target="#b46">[46]</ref> proposed a microstructural tissue analysis method in BCC images, which combines a stain correction strategy and an automatic method to identify morphological and architectural features in square image regions based on latent semantic analysis and support vector machines.</p><p>A preliminary work by Cruz-Roa et al. <ref type="bibr" target="#b47">[47]</ref> explored sparse autoencoders (SAE)</p><p>to do UFL combined with a softmax classifier for BCC detection. An adaptation, including a topographic approach, was proposed in <ref type="bibr" target="#b48">[48]</ref>. The present work extends the work in <ref type="bibr" target="#b48">[48]</ref> and <ref type="bibr" target="#b47">[47]</ref> in several ways: different UFL strategies along with different network architectures are evaluated, a novel hybrid image representation strategy, combining learned features with a BOF is proposed, and a new visualization strategy to improve the model interpretability is introduced.   There are different approaches to perform UFL. Among the most popular ones, is auto-encoding UFL, which attempts to find a function (the autoencoder) able to reconstruct its input. In this context, feature detectors, f j , may be seen as encoding functions with a corresponding decoding function g, which tries to recover the original input images from the features:</p><formula xml:id="formula_0">r Θ (I) = g(f (I)) ≈ I,<label>(1)</label></formula><p>where g : R n → R d is the decoding function, r Θ : R d → R d is the reconstruction function, and Θ is a set of parameters which determine the functions g and f . This approach may be seen as a 2-layer neural network which looks for an output as similar as possible to the input, i.e. minimizing the reconstruction error.</p><p>It should be noted that when the number of features is greater than the dimension of the input data, n &gt; d, the model is tempted to learn feature detectors with zero or identity functions. A regularization term is usually included to prevent such behavior. In summary, the objective function of autoencoders is defined as </p><formula xml:id="formula_1">J(Θ) = L (X, r Θ (X)) + R (X, Θ) ,<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sparse autoencoders</head><p>A desired property for the new representation of data is sparseness. Getting a more compact (sparse) representation of data means that the model discovers the most representative structure in the data yielding to more expressive power.</p><p>SAE objective function is given by:</p><formula xml:id="formula_2">J sparse (Θ) = 1 2 m i=1 r Θ (x (i) ) -x (i) 2 2 +β n j=1 KL (ρ||ρ j )+ γ 2 W 2 F + W 2 F ,<label>(3)</label></formula><p>where </p><formula xml:id="formula_3">x (i) ∈ R d is the i-th</formula><formula xml:id="formula_4">minimize W n j=1 m i=1 v f j x (i) s.t.WW T = I,<label>(4)</label></formula><p>where</p><formula xml:id="formula_5">W = W T 1 . . . W T n T , f j (x) = W j</formula><p>x is the j-th feature detector, and</p><formula xml:id="formula_6">v : R → R is a smoothed version of the L 1 -norm. We use v (s) = √ s 2 + ,</formula><p>where ∈ R is a smoothing parameter. ICA has been applied successfully in object recognition tasks, however it has two main limitations that come from its orthogonality constraint. It can not learn overcomplete representations and its training procedure with classical optimization techniques requires to solve an eigenvalue problem at each iteration, making it computationally expensive. Le et al. <ref type="bibr" target="#b50">[50]</ref> proposed a soft-version of ICA called reconstruction ICA or RICA, replacing the orthogonality constraint by a reconstruction penalty and defined by:</p><formula xml:id="formula_7">J RICA (W) = λ m m i=1 W T Wx (i) -x (i) 2 2 + m i=1 n j=1 v W j x (i) ,<label>(5)</label></formula><p>Notice that in this case g(s) = W T s. This model finds a set of feature weights W that reconstruct the original data using near orthogonal bases, while keeping the data representation (Wx) sparse. A key advantage of this formulation is that being an unconstrained problem, efficient implementations of gradient-based optimization methods can be applied to find good solutions. Also note that A c c e p t e d M a n u s c r i p t</p><p>RICA model only requires to adjust the hyperparameter λ, in contrast to SAE where a trade-off between γ, β and ρ should be found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topographic ICA</head><p>Inspired by the biological visual system, topographic models seek to organize learned feature detectors such that similar activations are close together, while different ones are set apart. This arrangement follows the visual cortex model where cells have a specific spatial organization and response of neurons change in a systematic way <ref type="bibr" target="#b49">[49]</ref>. Particularly, topographic RICA (TICA) builds a square matrix to organize feature detectors in l groups such that adjacent feature detectors activate in a similar proportion to the same stimulus. TICA cost function is given by:</p><formula xml:id="formula_8">J T ICA (W) = λ m m i=1 W T Wx (i) -x (i) 2 2 + m i=1 l k=1 H k Wx (i) 2 + , (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where l is the number of desired groups in the topography, H ∈ {0, 1} l×n is the topographic organization with H (j) k = 1 if the j-th feature detector belongs to the k-th group, 0 otherwise. This model sets H fixed and learns W. Similarly to RICA, TICA is also unconstrained and it can be treated with efficient optimization solvers like L-BFGS <ref type="bibr" target="#b52">[51]</ref>.</p><p>TICA calculates two types of features: basic features, f j (x) = W j x, and invariant features f * j (x) = H (Wx) 2 . Invariant features group several basic features based on their adjacency in the topographic map. increasing the computational cost of training and prediction. Several efforts <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b53">52]</ref> have dealt with this issue using GPUs implementations. However, under the assumption that histopathology images have particular properties, such as invariance to translation <ref type="bibr" target="#b54">[53]</ref>, part-based representation strategies such as BOF and convolutional neural networks allow us to move from patch representation to image representation in a scalable way. In the present work, both strategies were evaluated. The following subsections discuss them in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Bag of features representation</head><p>The BOF strategy <ref type="bibr" target="#b55">[54]</ref> represents an image as a frequency histogram of an unordered set of individual patches, such set is known as the dictionary. Each patch is represented by an l-dimensional vector. The dictionary D ∈ R R×l  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Convolutional representation</head><p>CNN <ref type="bibr" target="#b56">[55]</ref> apply local feature detectors as filters over the whole image to measure the correspondence between the image and each learned pattern. Then, an aggregation or pooling function is applied to reduce the representation dimensionality. The CNN architecture is depicted in figure <ref type="figure" target="#fig_2">3</ref> and described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convolutional layer</head><p>A single feature detector W j is used as a filter over the image to find where this particular pattern is present in the image. Resultant matrix M j is commonly known as feature map and its size is given by imageSize -f ilterSize + 1 for a squared image of size imageSize and a squared filter of size f ilterSize.</p><p>Because histopathology images are represented on the RGB color space, resultant feature map has 3 matrices which are aggregated by an element-wise summation. Therefore, an image will be represented by a set of n feature maps (or l groups for TICA), one per each feature detector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pooling layer</head><p>Learning n &gt; 3 feature detectors and concatenating resultant feature maps to represent the image lead to greater dimensionality than raw pixels. To reduce of the region that we are going to aggregate) of q (such that p is a multiple of q), then the resultant features are going to be n matrices of m-p+1 q × m-p+1 q size.</p><p>Consequently, the pool size is given by m-p+1 q . Note that m-p+1 q &lt; m, thus the greater the pool size, the smaller the dimension of the resultant features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stacked architecture</head><p>UFL has been successfully applied in different problems (natural language processing, object recognition, speech recognition, among others) using stacked architectures. stacked architectures construct multiple levels of representations by stacking layers over the raw input data. This approach incorporates several advantages like feature re-using, abstraction and invariance leading to more expressive models, i.e. it can represent inputs with a more compact set of features <ref type="bibr" target="#b4">[5]</ref>. Hinton et al. <ref type="bibr" target="#b3">[4]</ref> proposed a strategy to train in an efficient way stacked architectures based on a greedy layer-wise approach. Only one layer is trained at a time, then the output of a trained layer is used as input to the next layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Classification model</head><p>Softmax regression is a multinomial classifier that generalizes the logistic regression binary classifier <ref type="bibr" target="#b57">[56]</ref>. This approach uses a convex cost function and objective function is given by:</p><formula xml:id="formula_10">J (Φ) = - 1 m   m i=1 C j=1 1 y (i) = c log e φcs (i) C l=1 e φ l s (i)   + λ 2 Φ 2 F ,<label>(7)</label></formula><p>where C is the number of classes, Φ ∈ R C×n are the parameters of the model with φ c as the weight vector associated to class c, s (i) = f (x (i) ) is the feature vector for sample x (i) , y (i) ∈ N is the label for s (i) and λ is the regularization parameter. 1 {statement} function outputs 1 if statement is true, 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Visualization</head><p>Most learning-based computer vision models are black-box models, i.e. there is no knowledge about what features describing an input image contributed to the final decision, or what regions in the image are related with certain semantic concepts. In many computer vision applications, e.g. robotics, this is not an issue since the predictions are directly used by another system module, for which interpretability of the prediction does not add useful information. However, in medical image analysis applications, predictions are usually used as support of diagnostic decisions made by a human expert. In this context, interpretability of the system prediction is a valuable asset that helps to judge the potential contribution of the system prediction to the diagnostic process.</p><p>Our proposed framework adds a visualization layer that allows to crack the box getting insights to understand the behavior of the classification framework.</p><p>Particularly we perform two visualizations. On the one hand, we show the patterns that the filters are looking for, and which of those patterns are the most relevant to make the classification (local pattern visualization). On the other hand and, more interesting to pathologist, we highlight regions that, according to the learned model, are related with cancerous patterns (digital staining). The strategies applied to perform such visualizations are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A c c e p t e d M a n u s c r i p t</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local patterns visualization</head><p>The analysis of local feature detectors has two main objectives: to know the patterns that such functions are seeking and to measure how relevant they are to the classification process. We propose two main approaches to fulfill these goals:</p><p>Feature detectors visualization: finding what is the input x that maximizes the activation of a given feature detector f j (x) is interesting because this would tell us what pattern this function is looking for. Note that such pattern is proportional to the filter W j learned in the first layer because the output depends on the linear combination W j x. Then, the pattern can be displayed directly simply by reshaping W j ∈ R d to get an image patch with the same size as input x. Higher layers involve more complex transformations (like pooling or convolution) yielding to a non-convex optimization problem <ref type="bibr" target="#b59">[57]</ref>, nevertheless the solution can be approximated using gradient-based methods to find the optimal stimuli for each feature detector in higher layers.</p><p>Feature detectors organization: we are interested on the patterns organization built by topographic regularization. When images are represented using a BOF strategy and TICA as patch representation, the dictionary D ∈ R R×l contains combinations of topographic groups. At the same time, the softmax classifier learns the weight matrix Φ ∈ R C×R such that φ (r) c links the r-th visual word in the dictionary to the c-th class. Then, the relevance of a given feature detector W j is estimated by relevance Wj = ΦDH (j) , where H (j) is the j-th column of the grouping matrix H and represents the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Digital staining</head><p>In the context of automatic image annotation, interpretability means knowing why the system predicted a particular classification for an input image.</p><p>Interpretability is important when the output of the automatic image annotation system is an asset to support decisions, e.g. in computer assisted medical diagnosis. A histopathology image can have different structures, and it is possible that some of them do not necessarily correspond to the annotated concept of the image. Digital staining is a new mechanism based on thesis that aims to identify high-level concepts in image regions, by highlighting them using information from the classification model and learned feature detectors.</p><p>The digital staining process is performed as follows: when SAE and CNN with pool size of 1 (i.e. pool over all the feature map) represent the content of the image, the softmax classifier learns a set of weights Φ ∈ R C×n such that φ (j) c links the j-th feature detector to the c-th class. Now, let M j be the feature map generated from an image with the feature detector W j , and let φ 1 be the vector related with the positive class (cancer), then  distinguishing tumor and non-tumor regions respectively.</p><formula xml:id="formula_11">DS = n j=1 φ (j) 1 M j ,<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Basal cell carcinoma dataset</head><p>The histopathology BCC dataset comprises 1, 417 images of 300 × 300 pixels in RGB color that correspond to field of views with a 10× magnification and stained with H&amp;E <ref type="bibr" target="#b46">[46]</ref>. These images were manually annotated by an expert pathologist, indicating the presence of any type of BCC (infiltrative/trabecular, morpheiphorm, nodular) and other healthy architectural and morphological patterns (collagen, epidermis, sebaceous glands, eccrine glands, hair follicles and inflammatory infiltration). In summary, the BCC dataset is composed by 899 non-cancerous images and 518 carcinoma images. The figure <ref type="figure" target="#fig_14">4</ref> shows different example images for healthy and pathological tissue.</p><p>A c c e p t e d M a n u s c r i p t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental setup</head><p>Parameter exploration was performed using 5-fold cross validation in a subset of 746 images. The evaluation performance is calculated over an independent test subset with 671 images, reporting the area under the ROC curve (AUC).</p><p>To the purpose of these experiments images were half-scaled getting images of 150 × 150 pixels. The number of feature detectors for all UFL methods was set to 400 and were learned with 100, 000 patches randomly sampled for each layer. The first layer was trained sampling 8 × 8 patches from training dataset, whereas the second layer used 2 × 2 patches.</p><p>Since our main goal was to determine how discriminative the learned features are with respect to the state-of-the-art canonical representations, our baseline, we applied three well known set of hand-crafted descriptors in the automatic histopathology image analysis domain that have been successfully applied to several diagnosis tasks <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b40">41]</ref>: BOF representation with (1) discrete cosine transform (DCT) and ( <ref type="formula" target="#formula_1">2</ref>) Haar-based wavelet transform (Haar) as local features, and</p><p>(3) Haralick features <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b60">58]</ref>. The latter comprises a set of 28 textural features defined by several expressions, some of those related with statistical properties such as correlation, mean, variance among others calculated from the gray-level co-occurrence matrix.</p><p>In order to define a unified, and therefore more comparable and reproducible, pipeline for all image representations, the classification method was fixed to the softmax regression classifier for all experiments. It should be noticed that, since the softmax optimization function is strictly convex <ref type="bibr" target="#b61">[59]</ref>, the L-BFGS algorithm is able to find the global minimum, therefore it is enough to report one run per configuration.</p><p>Regardless of the UFL method applied, preprocessing techniques usually have shown performance improvement in object recognition tasks <ref type="bibr" target="#b62">[60]</ref>. A com-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A c c e p t e d</head><p>M a n u s c r i p t mon preprocessing step is to remove correlations of raw pixels, allowing to focus on properties that are not dependent on covariances, such as sparseness <ref type="bibr" target="#b49">[49]</ref>.</p><p>This decorrelation has two main motivations: to accentuate differences between input features and accelerate gradient-based learning <ref type="bibr" target="#b63">[61]</ref>. This work performs zero-phase component analysis whitening <ref type="bibr" target="#b64">[62]</ref> as a preprocessing step for patches in all experiments. Finally, all optimization functions were minimized using L-BFGS, particularly Mark Schmidt's implementation<ref type="foot" target="#foot_2">2</ref> . All implementations were done in Matlab, based on the popular Stanford UFLDL Tutorial<ref type="foot" target="#foot_3">3</ref> .</p><p>Considering that the H binary matrix in the TICA formulation represents the membership of features to groups in the topography, and that such matrix is fixed, herein, and following the seminal work of Hyvärinen et al. <ref type="bibr" target="#b65">[63]</ref>, the topography is defined as a 2-D torus lattice for both convenience of visualization and to avoid border effects. Specifically, H ∈ {0, 1} 400×400 defines 400 groups, each one composed of a set of 9 features arranged in a 3 × 3 square (displayed in section 3.4). Conversely, each feature belongs to 9 groups that capture a particular topographic property (e.g. orientation or scale).  BOF image representation uses a predefined local patch representation. DCT and Haar have shown to be a good alternative when BOF is applied to represent histopathology images in classification tasks <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b67">64]</ref>. This experiment makes a comparison between these canonical features (DCT and Haar) and features learned by UFL methods (SAE, RICA, TICA) for local patch representation.</p><p>Here, a CNN architecture was used to represent the image globally while the pool size was explored. Results depicted in figure <ref type="figure" target="#fig_16">5</ref> show a clear advantage of learned features over canonical features in terms of AUC performance. Also, the results revealed that the learned features have better performance when the pool size is small, obtaining the best performance for a pool size of 1. In this case, feature activations are aggregated for the whole image independently of their location. This means that the learned features are in fact invariant to translation. This behavior is consistent with the nature of the problem, tumor tissue detection, since cancer cell regions may be present in any region of a histopathology image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Self-taught learning</head><p>Raina et al. <ref type="bibr" target="#b68">[65]</ref> proposed a new framework which involves feature learning from unlabeled data that are not coming from the same generating distribu-A c c e p t e d M a n u s c r i p t tion. This is known as self-taught learning. In order to validate the relevance of this approach in the context of BCC tumor detection, we used three different datasets: 1) original BCC dataset of healthy and cancerous tissues of skin stained with H&amp;E and described in Section 4.1, 2) HistologyDS<ref type="foot" target="#foot_4">4</ref> dataset that comprises ∼ 20, 000 images of four fundamental healthy tissues from different organs using several staining techniques and 3) STL-10 dataset 5 with 100, 000 natural scene images. 100, 000 patches were randomly sampled from each dataset to train an autoencoder and to compare their performance using the CNN global image representation. Results in table <ref type="table" target="#tab_2">1</ref> show that features learned from histological images outperform the ones learned from natural scene images. Firstly, it seems that learned features from BCC and HistologyDS dataset captured better visual patterns related to dyes, edges of large nuclei in different orientations and perhaps most interestingly small dots related to common/healthy nuclear patterns that do not appear in the other feature sets (see experiment 4.7). Secondly and more interesting, the second best result is achieved by the HistologyDS. This is consistent with the other findings <ref type="bibr" target="#b68">[65]</ref>, which had shown that the strategy of learning features from other datasets may produce successful results. In this case, this could be explained because the HistologyDS has high visual variability of cell and tissues from different organs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Global image representation comparison</head><p>In this experiment a comparison between 1-layer CNN and BOF for global image representation is done. Similarly to the UFL setups for learning features described in section 4, the BOF learned a visual dictionary of 400 visual words.</p><p>Page 29 of 51</p><p>A c c e p t e d M a n u s c r i p t Representation AUC (UFL) BCC 0.957 (UFL) HistologyDS 0.941 DCT <ref type="bibr" target="#b44">[44]</ref> 0.916 Haar <ref type="bibr" target="#b44">[44]</ref> 0.915 (UFL) STL-10 <ref type="bibr" target="#b62">[60]</ref> 0.882</p><p>For both global image representation strategies the pool size was set to 1. Results are depicted in figure <ref type="figure" target="#fig_18">6</ref>. It is noteworthy how topographic organization, i.e.</p><p>TICA, improves performance for both, CNN and BOF representations. These results show that BOF image representation is comparable to CNN image representation only when TICA UFL is used. This is consistent with the results reported in figure <ref type="figure" target="#fig_16">5</ref> where TICA shows the best results for UFL.</p><p>CNN is the common approach in UFL methods to move from patch representation to image representation. However, BOF representation can be seen as a new second layer of learning representation with some particularities. Instead of using SAE or RICA models, feature learning in this second layer is done by a K-means algorithm over feature maps from the first layer. This new BOF representation is not a dense representation, such as the feature maps in   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Stacked image representation</head><p>In order to measure how much an additional layer helps, we combine the representation corresponding to the first layer with a second layer by concatenating features from both layers. The second layer learns feature detectors from 100, 000 2 × 2 patches sampled from the first layer with a pooling size of 20 × 20.</p><p>Results are shown in figure <ref type="figure" target="#fig_19">7</ref>, exhibiting an improved performance when features from the first and second layer are combined, obtaining the best overall performance when TICA is used. Features in the second layer correspond to 16 × 16 regions in the images. Results suggest that useful discriminative patterns are found in these regions, complementing those found in the original 8 × 8 regions.</p><p>A c c e p t e d M a n u s c r i p t </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Visualization Primitive features</head><p>Figure <ref type="figure" target="#fig_20">8</ref> shows the encoding filters W learned by SAE, RICA and TICA.</p><p>Notice that, as we detailed in section 3.4, such filters represent the optimal stimuli for each unit. In general, all of them learn to detect primitive shapes like edges and textures such as it had been previously shown in other domains <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b69">66]</ref>. Particularly, SAE discovers some patterns related to nuclear shapes (hightlighted in figure <ref type="figure" target="#fig_20">8</ref>). On the other hand, TICA learns a set of invariances organized in the topographic map (highlighted in the figure <ref type="figure" target="#fig_20">8</ref> (right)). These invariances corresponds to translation (blue square), color (red square), scale (yellow square) and rotation (green square). In BCC histopathology images, these are desirable invariances because they take care of the different visual variations produce by different cell arrangements and types of cut (position and rotation), and differences in staining and digitalization (color and scale).</p><p>Figure <ref type="figure" target="#fig_22">9</ref> shows the relevance of each feature detector over the topographic map using procedure described in subsection 3.   firms that groups, learned in an pure unsupervised way, were able to capture relations between features that belongs to the same class. This is a very interesting result since the model is totally unsupervised, i.e., the visual patterns were found using non-labeled samples.</p><p>Figure <ref type="figure" target="#fig_23">10</ref> shows optimal stimuli for feature detectors in the second layer.</p><p>These results are visually similar to findings that have been previously reported in other automatic image analysis and interpretation domains like action recognition <ref type="bibr" target="#b28">[29]</ref>, where it has been remarked that, while first layer captures low level features like edges, it seems second layer detects more complex shapes like corners and mixture of textures <ref type="bibr" target="#b69">[66]</ref>. These results encourage the training of deeper architectures in order to discover more abstract concepts.</p><p>Page 33 of 51   it on a independent dataset with larger images (1024 × 762 pixels). Figure <ref type="figure" target="#fig_26">11</ref> shows two histopathology images and their respective digital staining images predicted by the model. The top image was diagnosed as BCC morpheaform, while the bottom image contains collagen fibers. Results show that the model is able to perform estimations on larger images while preserving its main features to highlight relevant visual patterns like cell proliferation and peripheral palisade as discussed previously.     Notice that this approach is not directly comparable to traditional features in terms of computational cost, because the feature learning stage is an additional step in the framework. However, once the feature detectors are learned, these may be use with any classification method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">Computational efficiency</head><p>A c c e p t e d M a n u s c r i p t Table <ref type="table" target="#tab_7">4</ref> summarizes the systematic evaluation performed in this work in terms of AUC using a conventional softmax classifier. In addition, we also train a linear SVM model for each representation to validate that our findings are consistent, independently of the selected classifier. First, the results show that learning the representation from data yields better performance than using DCT and Haar canonical feature detectors. However, it is noteworthy that the representation learned with the STL-10 dataset performed worst. This may be explained by the fact that useful patterns for differentiating cancer and noncancer may not be present in a set of natural images. Thus, the model can  The best results were obtained using stacked architectures. This yields hierarchical features which simulate brain's visual cortex by building primitive structures like edges, and then building more complex shapes like corners. These higher-level features improved classification performance in all methods.</p><p>The proposed framework was evaluated in a supervised learning task to distinguish between cancer and non-cancer tissues in a BCC dataset. The frame- </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>A c c e p t e d M a n u s c r i p t the proposed framework</head><label></label><figDesc>outperforms state-of-the-art BCC histopathology image representation and classification methods. The main contributions of this work are: a novel hybrid method combining the state-of-the-art visual representations and learning techniques to integrate UFL in a complete data-driven approach;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of histopathology images from skin biopsies for basal cell carcinoma tumor detection. Healthy tissues: a) collagen, b) sebaceous glands and epidermis, c) pilosebaceous apparatus; and cancerous tissues: d) nodular basal cell carcinoma, e) nodular basal cell carcinoma, f) morpheaform basal cell carcinoma.</figDesc><graphic coords="12,161.46,222.62,85.92,64.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 .</head><label>3</label><figDesc>Unsupervised feature learning for basal cell carcinoma image analysis Feature extraction is a fundamental process for machine learning. Its goal is to extract useful characteristics from the data which are later fed to a learning algorithm. In computer vision, feature extraction corresponds to calculate values from input images. These values (features) represent particular characteristics of the image and are calculated from the raw pixels. The functions used to compute such features are called feature detectors. Traditional approaches in histopathology image analysis are based on standard or hand-crafted feature detectors which are manually selected to fit the problem at hand. Many efforts have focused on improving classifiers performance or enhancing the representation using the domain knowledge. UFL tackles this problem from a different perspective. Instead of designing custom feature detectors, UFL learns them from data in an unsupervised way. Page 13 of 51A c c e p t e d M a n u s c r i p t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overall scheme of the unsupervised feature learning framework for histopathology image analysis.</figDesc><graphic coords="14,142.36,124.80,326.53,253.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>A c c e p t e d M a n u s c r i p t 3 . 1 .</head><label>31</label><figDesc>Feature learningAn UFL model learns a set of feature detectors that can explain better the content of the data. These feature detectors are directly learned from the data through an optimization process. Feature detectors are modeled as linear or non-linear transformations applied to an input image, f j : R d → R, where R d is the image representation space (e.g. d = h • w for grayscale images of h × w pixels). If there are n different features, all the features may be grouped in a unique transformation f : R d → R n such that f (I) = (f 1 (I), . . . , f n (I)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>A c c e p t e d M a n u s c r i p t where X ∈ R d×m is the training dataset of size m with linearized images as columns, L (•) is the loss function of the reconstruction and R (•) the regularization term. Several variants of autoencoders have been developed and the kind of learned feature detectors depends on functions L and R. In this work we evaluated three main UFL approaches [49]: SAE, reconstruct independent component analysis (RICA) and topographic independent component analysis (TICA).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>sample in the training set X, β ∈ R is the hyperparameter that controls the trade-off between regularization and reconstruction, and KL(ρ||ρ j ) = ρ log ρ ρj + (1 -ρ) log 1-ρ 1-ρj is the Kullback-Leibler divergence between two Bernoulli distributions with means ρ ∈ R, the desired sparsity parameter percentage, and ρj ∈ R, the average activation of the j-th feature detector. When ρ is close to zero the second term penalizes high activations of feature detectors, in other words, the model tries to find sparse representations for the data. We chose f (x) = sigmoid(Wx + b) and g (s) = W s + c. Thus, Θ = {W, W , b, c} is the set of parameters, W ∈ R n×d and W ∈ R d×n are the encoder and decoder weight matrices, and b ∈ R n and c ∈ R d are encoder and decoder bias vectors. Finally, the third term regularizes magnitudes of the weights through the Frobenius norm ( • F ), with the hyperparameter γ ∈ R A c c e p t e d M a n u s c r i p t controlling the importance of the term in the objective function. Reconstruct ICA Independent component analysis (ICA) discovers robust representations based on the assumption that images can be reconstructed by a linear combination of statistically independent feature detectors. ICA finds such features by solving the following optimization problem:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>3. 2 .</head><label>2</label><figDesc>Image representation UFL methods are computationally expensive when they are applied to medium and large images (e.g. 100 × 100 and larger). The reason is that the number of the model parameters depends, usually non-linearly, on the size of the input, Page 18 of 51 A c c e p t e d M a n u s c r i p t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>is constructed by selecting the R most common patches in the whole image collection. The BOF representation comprises three main stages: Patch extraction and description: a random set of patches from training images is selected to perform on them a feature extraction process. Dictionary construction: feature vectors are clustered using a clustering algorithm such as K-means. Each cluster centroid corresponds to a visual word in this BOF learned dictionary.Histogram image representation: to represent a full-sized image, the image is split into a regular grid and each patch is represented using the selected UFL Method. Next, a similarity measure between one patch and each element of D is calculated, the one with the highest value is counted up. This procedure is repeated for each patch in the grid producing a histogram with R bins. A c c e p t e d M a n u s c r i p t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Image representation using convolutional approach.</figDesc><graphic coords="20,150.96,124.80,309.33,125.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>A c c e p t e d M a n u s c r i p t the number of</head><label></label><figDesc>parameters required to train the classifier, an aggregation process is done by grouping contiguous regions from each feature map and applying a pooling function like mean or max. This procedure adds local translation invariance to the model. As an example consider an image of m × m pixels and a set of n feature detectors of p × p pixels, resultant feature maps after convolution have (m -p + 1) × (m -p + 1) size. If we set a pool dimension (size</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>therefore a global solution can be found with gradient-based methods. The Page 21 of 51 A c c e p t e d M a n u s c r i p t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>A c c e p t e d M a n u s c r i p t membership ( 1</head><label>1</label><figDesc>or 0) of the feature detector W j to the groups. To locate what feature detectors are related with cancer, relevance of all feature detectors are calculated and organized with respect to the position in the topographic map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>is the sum of the feature maps weighted by the classifier parameters. High values in the DS matrix correspond to regions of the image that, according to the learned model, are related with cancer. To "dye" the image, the DS matrix is transformed to a colormap where high values are red and low ones are blue A c c e p t e d M a n u s c r i p t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example of images from the basal cell carcinoma dataset. First row shows some squared regions from healthy tissues. Second row shows some squared regions from pathological tissues.</figDesc><graphic coords="25,173.37,211.31,68.75,68.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>4. 3 .</head><label>3</label><figDesc>Unsupervised feature learning vs canonical features This first experiment makes a comparison between canonical features and features learned with UFL methods for local patch representation. Canonical features correspond to theoretical modeling of visual content representation of raw data in other transformed space. Examples of this kind of features are DCT and 2D wavelet transforms which, in the case of images, represent the original spatial information of visual content in other 2D frequency space depending on the chosen basis (cosines or wavelets). Page 27 of 51 A c c e p t e d M a n u s c r i p t (a) Learned features. (b) Canonical features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance comparison of learned and canonical features for different pool sizes.</figDesc><graphic coords="28,133.77,134.76,154.66,96.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>CNN, but a discrete representation with a regular grid extraction over the whole image. Hence, we can see the BOF image representation works like a 2-layer model whereas the CNN works like a 1-layer model. Then, the remaining question of this experiment is how the addition of more layers affects the global image representation in a stacked architecture. This is addressed in the next subsection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Comparison of global image representation methods (bag of features (BOF) and convolutional neural networks (CNN)) using three different unsupervised feature learning (UFL) methods: sparse autoencoders (SAE), reconstruct independent component analysis (RICA) and topographic component analysis (TICA).</figDesc><graphic coords="31,228.29,124.80,154.67,96.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Comparison of two-layer architectures using sparse autoencoders (SAE), reconstruct independent component analysis (RICA) and topographic component analysis (TICA) methods.</figDesc><graphic coords="31,219.70,281.29,171.85,107.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Local learned features with different unsupervised feature learning methods. Left: sparse autoencoders learned some features that are visually related with particularities of the histopathology dataset (i.e. nuclei shapes) which are highlighted by red squares. Center: reconstruct independent component analysis. Right: topographic component analysis highlighting some translational (blue), color (red), scale (yellow) and rotational (green) invariances.</figDesc><graphic coords="32,133.77,124.80,103.12,103.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>4 .</head><label>4</label><figDesc>White regions correspond to local detectors highly correlated with the positive class (cancer), while black regions correspond to features associated to the negative class. This figure con-Page 32 of 51A c c e p t e d M a n u s c r i p t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Discriminant map of learned features. Enclosed with red path are related with positive (basal cell carcinoma) class and enclosed by blue path are related with negative (healthy tissue) class. Left: softmax weights mapped back to topographic organization. Center: features learned with topographic component analysis. Right: top-10 of most discriminative features for positive (top) and negative (bottom) classes.</figDesc><graphic coords="33,139.75,124.80,120.30,120.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Selected patches from optimal stimuli of second layer of sparse autoencoders.</figDesc><graphic coords="33,219.70,314.35,171.87,54.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>A c c e p t e d M a n u s c r i p t</head><label></label><figDesc>Digital staining</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>A c c e</head><label></label><figDesc>p t e d M a n u s c r i p t (a) Basal cell carcinoma morpheaform image (cancer). (b) Probability map predicted by the model. (c) Collagen image (non-cancer). (d) Probability map predicted by the model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Digital staining on independent and larger images.</figDesc><graphic coords="36,133.77,403.97,164.98,123.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>A c c e p t e d M a n u s c r i p t</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>not represent in a proper way the content of a histopathology image. Second, TICA model adds invariance properties that significantly improve discriminant capabilities of the classifier. Finally, the visualization of feature detectors in the second layer suggests that the proposed framework is able to learn more abstract concepts when stacked architectures are trained. As a consequence, our best configuration was obtained with the TICA model in a two-layer architecture combining features of both layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>A c c e p t e d M a n u s c r i p t 5 .</head><label>5</label><figDesc>ConclusionsThis paper presented a novel UFL framework for BCC detection, which was systematically evaluated. This framework integrated UFL, supervised learning and visual interpretability for histopathology image analysis. A comprehensive evaluation of different UFL strategies for the new framework was performed on BCC histopathology images. The evaluation shows that, in this particular problem, learned features outperform state-of-the-art canonical representations.Feature learning for histopathology image representation is entirely performed in an way allowing to discover discriminant patterns in the collection without using prior knowledge from pathologists or hand-engineered features. Consistently discovered patterns are related to visual appearance of tumoral cells or nuclei. However these patterns could be confused with cell proliferation patterns in healthy tissues. Others remarkable findings were that learned features by the model provide translation, rotation, scaling and color invariances, which are desirable properties for this kind of images given their visual particularities produced by different cell arrangement, types of cuts, acquisition, staining and digitalization processes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head></head><label></label><figDesc>work outperformed the canonical state-of-the-art representation by 7% in terms of AUC achieving the best results by TICA combined layers obtaining 98.1% in test set. The final stage of the framework includes a noteworthy visualization model Page 39 of 51 A c c e p t e d M a n u s c r i p t to highlight tissue regions that the model finds to be related to the appearance of cancerous tissue, working like a digital staining. This novel technique showed that a trained feature learning model can provide a visual interpretability layer which is able to explain the automatic classification decision by detecting and highlighting textures and discriminant visual structures over the image. Indeed, these resultant salient maps of digital staining are potentially useful to be used as image-based biomarkers, a valuable tool for pathologist diagnosis support and cancer research. Future work includes further evaluation using deeper architectures, supervised feature learning and other types of cancer images using larger whole-slide image collections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>It has different risk factors and its development is mainly due</figDesc><table><row><cell>to ultraviolet radiation exposure. Although it does not usually metastasizes or</cell></row><row><cell>kills, it may cause significant tissue damage, destruction and, in some cases,</cell></row><row><cell>disfigurement. The prognostic is excellent provided there is an appropriate treatment in early stages. Pathologists confirm whether or not this disease is present after a biopsied tissue is evaluated under microscope. In such evalua-tion, physicians aim to recognize some characteristic patterns or complex mixes of patterns. Wong et al. [38] describes the structural patterns that characterize the BCC through 11 different complex patterns. The main challenge for auto-mated tumor detection of BCC is the fact that histopathology images reveal a complex mixture of visual patterns with high variability of biological structures associated to different morphology and architectural arrangements of cells in a n u s c r i p t healthy or pathological tissues. Figure 1 shows histopathology image samples stained with hematoxylin-eosin (H&amp;E) from tumoral and non-tumoral tissue M samples. These images illustrate the high intra-class visual variability in BCC</cell></row><row><cell>diagnosis, which is caused by the presence (or absence) of different morphological and architectural structures, both in healthy tissues (eccrine glands, hair folli-cles, epithelium, collagen, sebaceous glands) and BCC subtypes (morpheaform, nodular and cystic change). In general, histopathology images have high visual variability coming from several sources: cut orientation, staining and luminance, magnification, and digitalization among others. Despite there is a defined protocol for image acqui-A c c e p t e d sition, the human factor introduces variability to the process. As a result, visual</cell></row><row><cell>content representation of these images is highly challenging and many previous</cell></row><row><cell>efforts have tried to design handcrafted and task-oriented visual features [2],</cell></row><row><cell>which are, in many cases, only applicable to the original problem, decreasing</cell></row><row><cell>its reproducibility and generality. Novel approaches have been adapting ideas</cell></row><row><cell>Page 11 of 51</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Self-taught learning results. Area under the curve is reported. Canonical features are included for comparative purposes.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>shows the predictions, as well as the digital staining, for some image</cell></row><row><cell>samples taken from the test set. First row shows the real class of the input</cell></row><row><cell>image shown in the second row. Third and fourth rows show prediction and</cell></row><row><cell>probability of having BCC cancer respectively. Last row displays digital staining</cell></row><row><cell>by highlighting regions from blue to red scale, being red and blue cancerous and</cell></row><row><cell>healthy regions respectively.</cell></row><row><cell>Digital staining results were shown to an expert pathologist. The main</cell></row><row><cell>conclusion is that red regions are related with cell proliferation, a common</cell></row><row><cell>characteristic presents in BCC tumors [67]. Another observation made by the</cell></row><row><cell>pathologist is related to the borders in the cancerous regions that have higher</cell></row><row><cell>intensity values. Such zones usually express a peripheral palisade cells arrange-</cell></row><row><cell>ment, another relevant criteria during BCC diagnosis. The above statements</cell></row><row><cell>would suggest that feature learning strategies are able to capture those kind</cell></row><row><cell>of patterns that are present in the training dataset for both, cancerous and</cell></row><row><cell>non-cancerous images. These results suggest that the proposed digital staining</cell></row><row><cell>could be exploited in other tasks like semantic segmentation. However a caveat</cell></row><row><cell>is that this behavior also manifests in healthy structures where the germinative</cell></row><row><cell>epidermal cells or glandular tissues are present. This happens because the cell</cell></row><row><cell>arrangement in cancerous tissues can be similar to the arrangement in epithelial</cell></row><row><cell>tissues. Also it should be noticed that the preparation and staining processes</cell></row><row><cell>impact the color intensity if there is more hematoxylin-eosin, making the model</cell></row><row><cell>(and even the expert) more prone to highlighting healthy regions. Nonetheless,</cell></row><row><cell>this enhanced image represents an important addition to support the diagnostic</cell></row><row><cell>process since it allows pathologists to understand why the automated classifier</cell></row><row><cell>is suggesting a particular classification.</cell></row><row><cell>To evaluate the suitability of our method in a practical scenario, we applied</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Outputs produced by the system for different cancer and non-cancer input images.</figDesc><table /><note><p>The table rows show from top to bottom: the real image class, the input image, the class predicted by the model, the probability associated to the prediction, and the digital stained image (red stain indicates cancer regions, blue stain indicates normal regions).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>shows training times and feature extraction times for several config-</cell></row><row><cell>urations. Despite UFL stage requires a considerable amount of time to adjust</cell></row><row><cell>the model, this process is done just once. To represent a new set of images,</cell></row><row><cell>learned feature detectors are used out-of-the-box. Additionally, remarkable ef-</cell></row><row><cell>forts has been put to exploit high performance computing architectures such as</cell></row><row><cell>GPUs [68-70] and parallel architectures [52, 71, 72] improving the performance</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Computing time ([h]ours or [s]econds) for feature learning and feature extraction for several configurations. Average time per image is reported for feature extraction.</figDesc><table><row><cell>Unsupervised</cell><cell># of</cell><cell>Training</cell><cell cols="2">Feature extraction</cell></row><row><cell>feature learning</cell><cell>params</cell><cell>time</cell><cell>time (per image)</cell><cell></cell></row><row><cell>method</cell><cell></cell><cell></cell><cell cols="2">pool size=1 pool size=20</cell></row><row><cell>TICA -Layer 1</cell><cell>76800</cell><cell>0.27h</cell><cell>0.42s</cell><cell>0.47s</cell></row><row><cell>TICA -Layer 2</cell><cell>640000</cell><cell>1.56h</cell><cell>0.88s</cell><cell>-</cell></row><row><cell>SAE -Layer 1</cell><cell>154192</cell><cell>0.38h</cell><cell>0.86s</cell><cell>0.85s</cell></row><row><cell>SAE -Layer 2</cell><cell>1282000</cell><cell>2.14h</cell><cell>20.9s</cell><cell>-</cell></row></table><note><p><p>of representation learning methods and making them able to deal with large datasets and big data scenarios.</p>All the experiments were conducted using the 2.40GHz Intel® Xeon® Processor E5645 through a Matlab programming interface. Results show that SAE models are computationally more expensive than TICA models. This is because W and W encoding and decoding matrices are different in SAE, while in TICA, decoding matrix is just the transpose of the encoding matrix W, requiring less parameters to learn. In average, TICA is also faster than SAE to extract features from an image. This is related to the nonlinearity included by the sigmoid activation in the SAE model. The pool size is not very significant in terms of time for feature extraction process. Excluding SAE second layer, any feature extraction model proposed here takes less than 2 seconds to extract features from a new image, making them a feasible method to use in real world scenarios.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Overall classification performance using convolutional neural network as global image representation. Area under the curve is reported. Best results are in bold typeface.</figDesc><table><row><cell>Representation</cell><cell cols="2">Softmax Linear-SVM</cell></row><row><cell cols="2">TICA combined layers 0.981</cell><cell>0.979</cell></row><row><cell>SAE combined layers</cell><cell>0.976</cell><cell>0.977</cell></row><row><cell>TICA First Layer</cell><cell>0.976</cell><cell>0.974</cell></row><row><cell>TICA Second layer</cell><cell>0.971</cell><cell>0.968</cell></row><row><cell>SAE Second layer</cell><cell>0.966</cell><cell>0.964</cell></row><row><cell>SAE First Layer</cell><cell>0.957</cell><cell>0.974</cell></row><row><cell>SAE w/ HistologyDS</cell><cell>0.941</cell><cell>0.971</cell></row><row><cell>DCT[44]</cell><cell>0.916</cell><cell>0.938</cell></row><row><cell>Haar[44]</cell><cell>0.915</cell><cell>0.873</cell></row><row><cell>SAE w/ STL-10[60]</cell><cell>0.882</cell><cell>0.890</cell></row><row><cell>Haralick features</cell><cell>0.717</cell><cell>0.662</cell></row><row><cell>4.9. Overall BCC classification results</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The cancer genome atlas, http://cancergenome.nih.gov/. Accessed February 5,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2015" xml:id="foot_1"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>MinFunc library, http://www.di.ens.fr/~mschmidt/Software/minFunc.html. AccessedFebruary 5, 2015   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>Deep learning tutorial, http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial. AccessedFebruary 5, 2015   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>The histology image dataset, http://www.informed.unal.edu.co/histologyDS. Accessed February</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p><ref type="bibr" target="#b4">5</ref>, 2015<ref type="bibr" target="#b4">5</ref> The STL-10 dataset, http://cs.stanford.edu/~acoates/stl10/. Accessed February 5, 2015</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially funded by projects "Multimodal Image Retrieval to Support Medical Case-Based Scientific Literature Search", ID R1212LAC006 by Microsoft Research LACCIR, "Diseño e implementación de un sistema de cómputo sobre recursos heterogéneos para la identificación de estructuras atmosféricas en predicción climatológica" number 1225-569-34920 through Colciencias contract number 0213-2013 and "Convocatorial del programa nacional de proyectos para el fortalecimiento de la investigación, la creación y la innovación en posgrados de la Universidad Nacional de Colombia 2013 -2015" with proposal number 18722. Cruz-Roa also thanks Colciencias for its support through a doctoral grant in call 528/2011. Arevalo also thanks Colciencias for its support through a doctoral grant in call 617/2013. The authors also thank for K40 Tesla GPU donated by NVIDIA and which was used for some feature learning experiments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Digital pathology image analysis: opportunities and challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<idno type="DOI">10.2217/iim.09.9</idno>
	</analytic>
	<monogr>
		<title level="j">Imaging in Medicine</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="10" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Histology image analysis for carcinoma detection and grading</title>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cmpb.2011.12.007</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Histopathological image analysis: A review. Biomedical Engineering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gurcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boucheron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Can</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Reviews</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="147" to="171" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2013.50</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Comprehensive genomic characterization defines human glioblastoma genes and core pathways</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mclendon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bigner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Van Meir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mastrogianakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">455</biblScope>
			<biblScope unit="issue">7216</biblScope>
			<biblScope unit="page" from="1061" to="1068" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Stanford tissue microarray database</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Prapong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nitzberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="871" to="D877" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>suppl</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computational pathology: Challenges and promises for tissue analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="515" to="530" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Object-and Spatial-Level Quantitative Analysis of Multispectral Histopathology Images for Detection and Characterization of Cancer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Boucheron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Santa Barbara</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Three-dimensional image processing for morphometric analysis of epithelium sections</title>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schindewolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Harms</surname></persName>
		</author>
		<idno type="DOI">10.1002/cyto.990130712</idno>
	</analytic>
	<monogr>
		<title level="j">Cytometry</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="759" to="765" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cell-Graph Mining for Breast Tissue Modeling and Classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bilgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yener</surname></persName>
		</author>
		<idno type="DOI">10.1109/IEMBS.2007.4353540</idno>
	</analytic>
	<monogr>
		<title level="m">EMBS 2007. 29th Annual International Conference of the IEEE</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Akay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Delhomme</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Rousseau</surname></persName>
		</editor>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical &amp; Electronics Engineers (IEEE</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="5311" to="5314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automated grading of prostate cancer using architectural and textural image features</title>
		<author>
			<persName><forename type="first">S</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomaszeweski</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISBI.2007.357094</idno>
	</analytic>
	<monogr>
		<title level="m">Biomedical Imaging: From Nano to Macro, 2007. ISBI 2007. 4th IEEE International Symposium on</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Fessler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Wernick</surname></persName>
		</editor>
		<meeting><address><addrLine>Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical &amp; Electronics Engineers (IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1284" to="1287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Boosting Cascade for Automated Detection of Prostate Cancer from Digitized Histology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomaszeweski</surname></persName>
		</author>
		<idno type="DOI">10.1007/1186676362</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Medical Image Computing and Computer-Assisted Intervention -Volume Part II. MICCAI&apos;06; Berlin, Heidelberg</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Larsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Sporring</surname></persName>
		</editor>
		<meeting>the 9th International Conference on Medical Image Computing and Computer-Assisted Intervention -Volume Part II. MICCAI&apos;06; Berlin, Heidelberg</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="504" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computer-aided Prognosis of Neuroblastoma on Whole-slide Images: Classification of Stromal Development</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sertel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shimada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Catalyurek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Saltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gurcan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patcog.2008.08.027</idno>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1093" to="1103" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-Field-of-View Framework for Distinguishing Tumor Grade in ER+ Breast Cancer From Entire Histopathology Slides</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basavanhally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomaszeweski</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBME.2013.2245129</idno>
	</analytic>
	<monogr>
		<title level="j">Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2089" to="2099" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pca versus lda. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kak</surname></persName>
		</author>
		<idno type="DOI">10.1109/34.908974</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="233" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Principal Component Analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<idno type="DOI">10.1002/0470013192.bsa501</idno>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Second ed.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised learning of shape manifolds</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhalerao</surname></persName>
		</author>
		<idno type="DOI">10.5244/c.21.90</idno>
	</analytic>
	<monogr>
		<title level="m">Procedings of the British Machine Vision Conference 2007. University of Warwick</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Bhalerao</surname></persName>
		</editor>
		<meeting>edings of the British Machine Vision Conference 2007. University of Warwick<address><addrLine>UK</addrLine></address></meeting>
		<imprint>
			<publisher>British Machine Vision Association</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Independent component analysis: algorithms and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="411" to="430" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An introduction to support vector machines and other kernel-based learning methods</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Greedy layer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Conversational speech transcription using context-dependent deep neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<editor>Pieraccini, R., Colombo, A.</editor>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<publisher>International Speech Communication Association</publisher>
			<pubPlace>Florence, Italy</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Building high-level features using large scale unsupervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2013.6639343</idno>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Adams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Zhao</surname></persName>
		</editor>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8595" to="8598" />
		</imprint>
	</monogr>
	<note>2013 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identifying histological elements with convolutional neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Malon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cosatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Graf</surname></persName>
		</author>
		<idno type="DOI">10.1145/1456223.1456316</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Soft Computing As Transdisciplinary Science and Technology. CSTST &apos;08</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Badr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Ohsawa</surname></persName>
		</editor>
		<meeting>the 5th International Conference on Soft Computing As Transdisciplinary Science and Technology. CSTST &apos;08<address><addrLine>Cergy-Pontoise, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="450" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cell nucleus segmentation in color histopathological imagery using convolutional networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>You</surname></persName>
		</author>
		<idno type="DOI">10.1109/CCPR.2010.5659313</idno>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition (CCPR), Chinese Conference on</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</editor>
		<meeting><address><addrLine>Chongqing, China</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A Machine Learning Approach to Classification of Low Resolution Histological Samples</title>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>EPFL, Switzerland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>École Polytechnique Fédérale de Lausanne</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning invariant features of tumor signatures</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spellman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parvin</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISBI.2012.6235544</idno>
	</analytic>
	<monogr>
		<title level="j">Biomedical Imaging</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2011.5995496</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Pinto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Boult</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</editor>
		<meeting><address><addrLine>Colorado Springs, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical &amp; Electronics Engineers (IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3361" to="3368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Automatic detection of invasive ductal carcinoma in whole slide images with convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basavanhally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganesan</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2043872</idno>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging: Digital Pathology</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Gurcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Classification of mitotic figures with convolutional neural networks and seeded blob features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Malon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cosatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Pathology Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mitosis detection in breast cancer histology images with deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sakuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-40763-551</idno>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention -MIC-CAI</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Nagoya, Japan; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8150</biblScope>
			<biblScope unit="page" from="411" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cascaded ensemble of convolutional neural networks and handcrafted features for mitosis detection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basavanhally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2043902</idno>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging: Digital Pathology</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Gurcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">9041</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mitosis detection in breast cancer pathology images by combining handcrafted and convolutional neural network features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basavanhally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<idno type="DOI">10.1117/1.jmi.1.3.034003</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">34003</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mitosis detection in breast cancer histological images An ICPR 2012 contest</title>
		<author>
			<persName><forename type="first">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Racoceanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Loménie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kulikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Irshad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klossa</surname></persName>
		</author>
		<idno type="DOI">10.4103/2153-3539.112693</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of pathology informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Diagnostic Histopathology of Tumors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fletcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Churchill Livingstone</publisher>
		</imprint>
	</monogr>
	<note>3 ed.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Basal cell and squamous cell skin cancers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bichakjian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bowen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the National Comprehensive Cancer Network</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="836" to="864" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Basal cell carcinoma</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Strange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lear</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.327.7418.794</idno>
	</analytic>
	<monogr>
		<title level="j">British Medical Journal (Clinical research ed)</title>
		<imprint>
			<biblScope unit="volume">327</biblScope>
			<biblScope unit="issue">7418</biblScope>
			<biblScope unit="page" from="794" to="798" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A semantic content-based retrieval method for histopathology images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-68636-16</idno>
	</analytic>
	<monogr>
		<title level="m">Information Retrieval Technology</title>
		<title level="s">Lecture Notes in Computer Science. Harbin</title>
		<meeting><address><addrLine>China; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4993</biblScope>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Histopathology image classification using bag of features and kernel functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-02976-917</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence in Medicine</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Combi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Shahar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Abu-Hanna</surname></persName>
		</editor>
		<meeting><address><addrLine>Verona, Italy; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5651</biblScope>
			<biblScope unit="page" from="126" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Visual pattern mining in histology image collections using bag of features</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artmed.2011.04.010</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence in medicine</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="106" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Histopathological Image Classification Using Stain Component Features on a pLSA Model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Romero</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-16687-712</idno>
	</analytic>
	<monogr>
		<title level="m">Progress in Pattern Recognition</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Cesar</surname></persName>
		</editor>
		<meeting><address><addrLine>Sao Paulo, Brazil; Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6419</biblScope>
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A framework for semantic analysis of histopathological images using nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing Congress (CCC)</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Castillo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Duque</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Institute of Electrical &amp; Electronics Engineers</title>
		<author>
			<persName><surname>Colombian</surname></persName>
		</author>
		<author>
			<persName><surname>Manizales</surname></persName>
		</author>
		<idno type="DOI">10.1109/COLOMCC.2011.5936285</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="7" />
			<pubPlace>Colombia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Automatic annotation of histopathological images using a latent topic model based on nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>González</surname></persName>
		</author>
		<idno type="DOI">10.4103/2153-3539.92031</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of pathology informatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A supervised visual model for finding regions of interest in basal cell carcinoma images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Roa-Peña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Romero</surname></persName>
		</author>
		<idno type="DOI">10.1186/1746-1596-6-26</idno>
	</analytic>
	<monogr>
		<title level="j">Diagnostic pathology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Micro-structural tissue analysis for automatic histopathological image annotation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Romero</surname></persName>
		</author>
		<idno type="DOI">10.1002/jemt.21063</idno>
	</analytic>
	<monogr>
		<title level="j">Microscopy research and technique</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="358" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A Deep Learning Architecture for Image Representation, Visual Interpretability and Automated Basal-Cell Carcinoma Cancer Detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Arevalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-40763-550</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention -MICCAI</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Sakuma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">8150</biblScope>
			<biblScope unit="page" from="403" to="410" />
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
			<pubPlace>Nagoya, Japan; Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hybrid image representation learning model with invariant features for basal cell carcinoma detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Arevalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2035530</idno>
	</analytic>
	<monogr>
		<title level="m">IX International Seminar on Medical Information Processing and Analysis</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Brieva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Escalante-Ramírez</surname></persName>
		</editor>
		<meeting><address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Natural image statistics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hurri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Ica with reconstruction cost for efficient overcomplete feature learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karpenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<editor>Shawe-Taylor, J.</editor>
		<imprint>
			<pubPlace>Zemel, A</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1017" to="1025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01589116</idno>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep learning with cots hpc systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Andrew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 30th International Conference on Machine Learning. 3; Atlanta, USA: JMLR Workshop and Conference Proceedings</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</editor>
		<meeting>The 30th International Conference on Machine Learning. 3; Atlanta, USA: JMLR Workshop and Conference Proceedings</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">What the statistics of natural images tell us about visual coding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.952724</idno>
	</analytic>
	<monogr>
		<title level="m">Human Vision, Visual Processing, and Digital Display. International Society for Optics and Photonics</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Rogowitz</surname></persName>
		</editor>
		<meeting><address><addrLine>Los Angeles, USA</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="269" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A bayesian hierarchical model for learning natural scene categories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2005.16</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Tomas</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="524" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.726791</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Keerthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shevade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Poo</surname></persName>
		</author>
		<imprint>
			<publisher>Multicategory Classification by Soft-Max Combination of Binary Classifiers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<idno type="DOI">10.1007/3-540-44938-813</idno>
	</analytic>
	<monogr>
		<title level="m">Multiple Classifier Systems</title>
		<title level="s">2709 of Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Windeatt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Roli</surname></persName>
		</editor>
		<meeting><address><addrLine>Guildford, UK; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Visualizing higher-layer features of a deep network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Montreal</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Textural features for image classification. Systems, Man and Cybernetics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC-3</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC-3</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Dinstein</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC-3</orgName>
			</affiliation>
		</author>
		<idno type="DOI">10.1109/TSMC.1973.4309314</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Regularized logistic regression is strictly convex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D M</forename><surname>Rennie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.; MIT</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Gordon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Dunson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Dudík</surname></persName>
		</editor>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Ft. Lauderdale, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>JMLR W&amp;CP</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Learning invariant feature hierarchies</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fusiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-33863-251</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV. Workshops and Demonstrations</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Florence, Italy; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7583</biblScope>
			<biblScope unit="page" from="496" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The &quot;independent components&quot; of natural scenes are edge filters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">3327</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inki</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title/>
		<idno type="DOI">10.1162/089976601750264992</idno>
	</analytic>
	<monogr>
		<title level="j">Component Analysis. Neural Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1558" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A visual latent semantic approach for automatic analysis and interpretation of anaplastic medulloblastoma virtual slides</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Galaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Judkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ellison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baccon</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-33415-320</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention -MICCAI</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Delingette</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">7510</biblScope>
			<biblScope unit="page" from="157" to="164" />
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
			<pubPlace>Nice, France; Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Self-taught learning: transfer learning from unlabeled data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1145/1273496.1273592</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning. ICML &apos;07</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<meeting>the 24th international conference on Machine learning. ICML &apos;07<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="759" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Sparse deep belief net model for visual area v2</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ekanadham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="873" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Cell proliferation in human basal cell carcinoma</title>
		<author>
			<persName><forename type="first">G</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="724" to="728" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1145/2647868.2654889</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia. MM &apos;14</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Tavanapong</surname></persName>
		</editor>
		<meeting>the ACM International Conference on Multimedia. MM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Pylearn2: a machine learning research library</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<idno>arXiv:13084214</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Torch7: A matlab-like environment for machine learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BigLearn, NIPS Workshop. EPFL-CONF-192376; Granada, Spain: NIPS</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<idno>arXiv:150102876</idno>
		<title level="m">Deep image: Scaling up image recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Large scale distributed deep networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1223" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
