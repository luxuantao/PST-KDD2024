<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ranking Distillation: Learning Compact Ranking Models With High Performance for Recommender System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
							<email>jiaxit@sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University British Columbia</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
							<email>wangk@cs.sfu.ca</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University British Columbia</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ranking Distillation: Learning Compact Ranking Models With High Performance for Recommender System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3219819.3220021</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems → Retrieval models and ranking</term>
					<term>Recommender systems</term>
					<term>Retrieval efficiency</term>
					<term>Recommender System</term>
					<term>Learning to Rank</term>
					<term>Knowledge Transfer</term>
					<term>Model Compression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel way to train ranking models, such as recommender systems, that are both effective and efficient. Knowledge distillation (KD) was shown to be successful in image recognition to achieve both effectiveness and efficiency. We propose a KD technique for learning to rank problems, called ranking distillation (RD). Specifically, we train a smaller student model to learn to rank documents/items from both the training data and the supervision of a larger teacher model. The student model achieves a similar ranking performance to that of the large teacher model, but its smaller model size makes the online inference more efficient. RD is flexible because it is orthogonal to the choices of ranking models for the teacher and student. We address the challenges of RD for ranking problems. The experiments on public data sets and state-of-the-art recommendation models showed that RD achieves its design purposes: the student model learnt with RD has a model size less than half of the teacher model while achieving a ranking performance similar to the teacher model and much better than the student model learnt without RD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Google and Yahoo; personalized item retrieval a.k.a recommender systems for Amazon and Netflix. The core in such systems is a ranking model for computing the relevance score of each (q, d) pair for future use, where q is the query (e.g., keywords for web page retrieval and user profile for recommender systems) and d is a document (e.g., a web page or item). The effectiveness of IR systems largely depends on how well the ranking model performs, whereas the efficiency determines how fast the systems will respond to user queries, a.k.a online inferences.</p><p>Since the 2009 Netflix Prize competition, it is increasingly realized that a simple linear model with few parameters cannot model the complex query-document (user-item) interaction properly, and latent factor models with numerous parameters are shown to have better effectiveness and good representation power <ref type="bibr" target="#b20">[21]</ref>. Recently, with the great impact of neural networks on computer vision <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22]</ref> and natural language processing <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b24">25]</ref>, a new branch of IR using neural networks has shown strong performances. As neural networks have incredible power to automatically capture features, recent works use neural networks to capture semantic representations for both queries and documents, relieving the manual feature engineering work required by other approaches. Several successful ranking models with neural networks have been investigated <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref>. However, the size of such models (in terms of the number of model parameters) increases by an order of magnitude or more than previous methods. While such models have better ranking performance by capturing more query-document interactions, they incur a larger latency at online inference phase when responding to user requests due to the larger model size.</p><p>Balancing effectiveness and efficiency has been a line of recent research <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>. Discrete hashing techniques <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42]</ref> and binary coding of model parameters are suggested to speed up the calculation of the relevance score for a given (q,d) pair. Other works focus on database-related methods, such as pruning and indexing to speed-up retrieval of related items <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b33">34]</ref>, using fast models for candidate generation and applying time-consuming models to the candidates for online inferences <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24]</ref>. These methods either lose much of effectiveness, due to the introduced model constraints, or cannot be easily extended to other models in most cases, due to the model-dependency nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Knowledge Distillation</head><p>Knowledge distillation (KD), a.k.a., knowledge transfer, is a modelindependent strategy for generating a compact model for better inference efficiency while retaining the model effectiveness <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b14">15]</ref>. The idea of KD is shown in Figure <ref type="figure">1a</ref>  from the training set, and a smaller student model is then trained by minimizing two deviations: the deviation from the training set's ground-truth label distribution, and the deviation from the label distribution generated by the teacher model. Then the student model is used for making online inferences. Intuitively, the larger teacher model helps capture more information of the label distribution (for example, outputting a high probability for "tiger" images for a "cat" image query due to correlation), which is used as an additional supervision to the training of the student model. The student model trained with KD has an effectiveness comparable to that of the teacher model <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20]</ref> and can make more efficient online inference due to its small model size.</p><p>Despite of this breakthrough in image recognition, it is not straightforward to apply KD to ranking models and ranking problems (e.g., recommendation). First, the existing KD is designed for classification problems, not for ranking problems. In ranking problems, the focus is on predicting the relative order of documents or items, instead of predicting a label or class as in classification. Second, KD requires computing the label distribution of documents for each query using both teacher and student models, which is feasible for image classification where there are a small number of labels, for example, no more than 1000 for the ImageNet data set; however, for ranking and recommendation problems, the total number of documents or items could be several orders of magnitudes larger, say millions, and computing the distribution for all documents or items for each training instance makes little sense, especially only the highly ranked documents or items near the top of the ranking will matter. We also want to point out that, for context sensitive recommendation, such as sequential recommendation, the items to be recommended usually depend on the user behaviors prior to the recommendation point (e.g., what she has viewed or purchased), and the set of contexts of a user is only known at the recommendation time. This feature requires recommender system to be strictly responsive and makes online inference efficiency particularly important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contributions</head><p>In this work, we study knowledge distillation for the learning to rank problem that is the core in recommender systems and many other IR systems. Our objective is achieving the ranking performance of a large model with the online inference efficiency of a small model. In particular, by fusing the idea of knowledge transfer and learning to rank, we propose a technique called ranking distillation (RD) to learn a compact ranking model that remains effective. The idea is shown in Figure <ref type="figure">1b</ref> where a small student model is trained to learn to rank from two sources of information, i.e., the training set and the top-K documents for each query generated by a large well-trained teacher ranking model. With the large model size, the teacher model captures more ranking patterns from the training set and provides top-K ranked unlabeled documents as an extra training data for the student model. This makes RD differ from KD, as teacher model in KD only generate additional labels on existing data, while RD generate additional training data and labels from unlabeled data set. The student model benefits from the extra training data generated from the teacher, in addition to the data from usual training set, thus, inherits the strong ranking performance of the teacher, but is more efficient for online inferences thanks to its small model size.</p><p>We will examine several key issues of RD, i.e., the problem formulation, the representation of teacher's supervision, and the balance between the trust on the data from the training set and the data generated by the teacher model, and present our solutions. Extensive experiments on recommendation problems and real-world datasets show that the student model achieves a similar or better ranking performance compared to the teacher model while using less than half of model parameters. While the design goal of RD is retaining the teacher's effectiveness (while achieving the student's online inference efficiency), RD exceeds this expectation that the student sometime has a even better ranking performance than the teacher. Similar to KD, RD is orthogonal to the choices of student and teacher models by treating them as black-boxes. To our knowledge, this is the first attempt to adopt the idea of knowledge distillation to large-scale ranking problems.</p><p>In the rest of the paper, we introduce background materials in Section 2, propose ranking distillation for ranking problems in Section 3, present experimental studies in Section 4, and discuss related work in Section 5. We finally conclude with a summary of this work and in Section 6.</p><p>these terms can be replaced with "user profile" and "item" when applied to recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Ranking from scratch</head><p>The learning to rank problem can be summarized as follows: Given a set of queries Q={q</p><formula xml:id="formula_0">1 ,• • • ,q | Q | } and a set of documents D={d 1 ,• • • ,d | D | },</formula><p>we want to retrieve documents that are most relevant to a certain query. The degree of relevance for a query-document pair (q, d) is determined by a relevance score. Sometimes, for a single (q, d) pair, a relevance score y (q) d is labeled by human (or statistical results) as ground-truth, but the number of labeled (q, d) pairs is much smaller compared to the pairs with unknown labels. Such labels can be binary (i.e., relevant/non-relevant) or ordinal (i.e., very relevant/relevant/non-relevant). In order to rank documents for future queries with unknown relevance scores, we need a ranking model to predict their relevance scores. A ranking model M(q, d; θ ) = ŷ(q) d is defined by a set of model parameters θ and computes a relevance score ŷ(q) d given the query q and document d. The model predicted document ranking is supervised by the human-labeled ground truth ranking. The optimal model parameter set θ * is obtained by minimizing a ranking-based loss function:</p><formula xml:id="formula_1">θ * = argmin θ q ∈ Q L R (y (q) , ŷ(q) ).<label>(1)</label></formula><p>For simplicity, we focus on a single query q and omit the superscripts related to queries (i.e., y</p><p>d will becomes y d ). The ranking-based loss could be categorized as point-wise, pairwise, and list-wise. Since the first two are more widely adopted, we don't discuss list-wise loss in this work. The point-wise loss is widely used when relevance labels are binary <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33]</ref>. One typical point-wise loss is taking the negative logarithmic of the likelihood function:</p><formula xml:id="formula_3">L R (y, ŷ) = −( d ∈y d + log(P(rel = 1| ŷd )) + d ∈y d − log(1 − P(rel = 1| ŷd ))),<label>(2)</label></formula><p>where y d+ and y d− are the sets of relevant and non-relevant documents, respectively. We could use the logistic function σ (x) = 1/(1+ e −x ) and P(rel = 1| ŷd ) = σ ( ŷd ) to transform a real-valued relevance score to the probability of a document being relevant (rel = 1). For ordinal relevance labels, pair-wise loss better models the partial order information:</p><formula xml:id="formula_4">L R (y, ŷ) = − d i ,d j ∈C log(P(d i ≻ d j | ŷi , ŷj )),<label>(3)</label></formula><p>where C is the set of document pairs {(d i , d j ) : y i ≻ y j } and the probability P(d i ≻ d j ) can be modeled using the logistic function P(d i ≻ d j |y i , y j ) = σ (y i − y j ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Rethinking Effectiveness and Efficiency</head><p>We consider ranking models with latent factors or neural networks (a.k.a neural ranking models) instead of traditional models (e.g., SVM, tree-based models) for the following reasons. First, these models are well-studied recently for its capability to capture features from a latent space and are shown to be highly effective; indeed, neural ranking models are powerful for capturing rich semantics for queries and documents, which eliminates the tedious and ad-hoc feature extraction and engineering normally required in traditional models. Second, these models usually require many parameters and suffer from efficiency issue when making online inferences. Third, traditional models like SVM usually has convex guarantees and are trained through convex optimization. The objectives of latent factor models and neural networks are usually non-convex <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>, which means that their training processes are more challenging and need more attentions. The goal of ranking models is predicting the rank of documents as accurately as possible near the top positions, through learning from human-labeled ground-truth document ranking. Typically, there are two ways to make a ranking model perform better at top positions: (1) By having a large model size, as long as it doesn't overfit the data, the model could better capture complex querydocument interaction patterns and has more predictive capability. Figure <ref type="figure" target="#fig_1">2a</ref> shows that, when a ranking model has more parameters, it acquires more flexibility to fit the data and has a higher MAP, where the mean average precision (MAP) is more sensitive to the precision at top positions. ( <ref type="formula" target="#formula_3">2</ref>) By having more training data, side information, human-defined rules etc., the model can be trained with more guidance and has less variance in gradients <ref type="bibr" target="#b14">[15]</ref>. Figure <ref type="figure" target="#fig_1">2b</ref> shows that, when more training instances are sampled from the underlying data distribution, a ranking model could achieve a better performance. However, each method has its limitations: method (1) surrenders efficiency for effectiveness whereas method (2) requires additional informative data, which is not always available or is expensive to obtain in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RANKING DISTILLATION</head><p>In this section, we propose ranking distillation (RD) to address the dual goals of effectiveness and efficiency for ranking problems. To address the efficiency of online inference, we use a smaller ranking model so that we can rank documents for a given query more efficiently. To address the effectiveness issue without requiring more training data, we introduce extra information generated from a well-trained teacher model and make the student model as effective as the teacher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the overview of ranking distillation. In the offline training phase (prior to any user query), similar to KD, first we train a large teacher model with a strong ranking performance on the training set. Then for each query, we use the well-trained teacher model to make predictions on unlabeled documents (green part in Figure <ref type="figure" target="#fig_2">3</ref>) and use this extra information for learning the smaller student model. Since the teacher model is allowed to have many parameters, it captures more complex features for ranking and is much powerful, thus, its predictions on unlabeled documents could be used to provide extra information for the student model's training. The student model with fewer parameters is more efficient for online inference, and because of the extra information provided by the teacher model, the student model inherits the high ranking performance of the teacher model. Specifically, the offline training for student model with ranking distillation consists of two steps. First, we train a larger teacher model M T by minimizing a ranking-based loss with the groundtruth ranking from the training data set, as showed in Eqn <ref type="bibr" target="#b0">(1)</ref>. With much more parameters in this model, it captures more patterns from data and thus has a strong performance. We compute the predicted relevance scores of the teacher model M T for unlabeled documents Ō = {d : y d = ∅} and get a top-K unlabeled document ranking π 1..K = (π 1 , . . . , π K ), where π r ∈ D is the r -th document in this ranking. Then, we train a smaller ranking model M S to minimize a ranking loss from the ground-truth ranking in the training data set, as well as a distillation loss with the exemplary top-K ranking on unlabeled document set π 1..k offered by its teacher M T . The overall loss to be minimized is as follows:</p><formula xml:id="formula_5">L(θ S ) = (1 − α)L R (y, ŷ) + α L D (π 1..K , ŷ). (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>Here ŷ is the student model's predicted scores <ref type="foot" target="#foot_1">1</ref> . L R (, ) stands for the ranking-based objective as in Eqn <ref type="bibr" target="#b0">(1)</ref>. The distillation loss, denoted by L D (, ), uses teacher model's top-K ranking on unlabeled documents to guide the student model learning. α is the hyperparameter used for balancing these two losses. For a given query, the top documents ranked by the well-trained teacher can be regarded to have a strong correlation to this query, although they are not labeled in the training set. For example, if a user watches many action movies, the teacher's top-ranked documents may contain some other action movies as well as some adventure movies because they are correlated. In this sense, the proposed RD lets the teacher model teach its student to find the correlations and capture their patterns, thus, makes the student more generalizable and perform well on unseen data in the future. We use the top-K ranking from the teacher instead of the whole ranked list because the noisy ranking at lower positions tends to cause the student model to overfit its teacher and lose generalizability. Besides, only top positions are considered important for ranking problems. K is a hyper-parameter that represents the trust level on the teacher during teaching, i.e., how much we adopt from teacher.</p><p>The choice of the ranking loss L R (, ) follows from different models' preferences and we only focus on the second term L D (, ) in Eqn (4). A question is how much we should trust teacher's top-K ranking, especially for a larger K. In the rest of the section, we consider this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Incorporating Distillation Loss</head><p>We consider the point-wise ranking loss for binary relevance labels for performing distillation, we also tried the pair-wise loss and will discuss their pros and cons later. Similar to Eqn (2), we formalize distillation loss as:</p><formula xml:id="formula_7">L D (π 1..K , ŷ) = − K r =1 w r • log(P(rel = 1| ŷπ r )) = − K r =1 w r • log(σ ( ŷπ r )),<label>(5)</label></formula><p>where σ (•) is the sigmoid function and w r is the weight to be discussed later. There are several differences compared to Eqn (2). First, in Eqn (5), we treat the top-K ranked documents from the teacher model as positive instances and there is no negative instance. Recall that KD causes the student model to output a higher probability for the label "tiger" when the ground-truth label is "cat" because their features captured by the teacher model are correlated. Along this line, we want the student model to rank higher for teacher's top-K ranked documents. As we mentioned above, for the given query, besides the ground-truth positive documents y + , teacher's top-K ranked unlabeled documents are also strongly correlated to this query. These correlations are captured by the well-trained powerful teacher model in the latent space when using latent factor model or neural networks.</p><p>However, as K increases, the relevance of the top-K ranked unlabeld documents becomes weaker. Following the work of learning Algorithm 1 Estimate Student's Ranking for π r Require: Student Model M S (q, d; θ S ), unlabeled document set Ō for a given query q and the hyper-parameter ϵ ŷπ r ← M S (q, π r ; θ S )</p><formula xml:id="formula_8">Initialize n = 0 for t = 1, 2, ...ϵ do Sample a document d from Ō without replacement ŷd ← M S (q, d; θ S ) if ŷd &gt; ŷπ r then n ← n + 1 end if end for rπ r ← n×(| Ō |−1)</formula><p>ϵ + 1 return rπ r from noise labels <ref type="bibr" target="#b25">[26]</ref>, we use a weighted sum over the loss on documents from π 1..K with weight w r on each position r from 1 to K. There are two straightforward choices for w r : w r = 1/r puts more emphasis on the top positions, whereas w r = 1/K weights each position equally. Such weightings are heuristic and pre-determined, may not be flexible enough to deal with general cases. Instead, we introduce two flexible weighting schemes, which were shown to be superior in our experimental studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.1</head><p>Weighting by Position Importance. In this weighting scheme, we assume that the teacher predicted unlabeled documents at top positions are more correlated to the query and are more likely to the positive ground-truth documents, therefore, this weight w a should be inversely proportional to the rank:</p><formula xml:id="formula_9">w a r ∝ r −1 and r ∈ [1, K],<label>(6)</label></formula><p>where r is the rank range from 1 to K. As pointed out above, this scheme pre-determines the weight. Rendle et al <ref type="bibr" target="#b28">[29]</ref> proposed an empirical weight for sampling a single position from a top-K ranking, following a geometric distribution:</p><formula xml:id="formula_10">w a r = ρ(1 − ρ) r and ρ ∈ (0, 1). (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>Following their work, we use a parametrized geometric distribution for weighting the position importance:</p><formula xml:id="formula_12">w a r ∝ e −r /λ and λ ∈ R + , (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>where λ is the hyperparameter that controls the sharpness of the distribution, and is searched through the validation set. When λ is small, this scheme puts more emphasis on top positions, and when λ is large enough, the distribution becomes the uniform distribution. This parametrization is easy to implement and configurable to each kind of situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.2</head><p>Weighting by Ranking Discrepancy. The weighting by position importance is static, meaning that the weight at the same position is fixed during training process. Our second scheme is dynamic that considers the discrepancy between the student-predicted rank and the teacher-predicted rank for a given unlabeled document, and uses it as another weight w b . This weighting scheme allows the training to gradually concentrate on the documents in teacher's top-K ranking that are not well-predicted by the student. The details are as follows.  For the r -th document π r (r ∈ [1, K]) in teacher model's top-K ranking, the teacher-predicted ranking (i.e., r ) is known for us. But we know only the student predicted relevant score ŷπ r instead of its rank without computing relevance scores for all documents. To get the student predicted rank for this document, we apply Weston et al <ref type="bibr" target="#b35">[36]</ref>'s sequential sampling, and do it in a parallel manner <ref type="bibr" target="#b15">[16]</ref>. As described in Algorithm 1, for the r -th document π r , if we want to know its rank in a list of N documents without computing the scores for all documents, we can randomly sample ϵ ∈ [1, N − 1] documents in this list and estimate the relative rank by n/ϵ, where n is the number of documents whose (student) scores are greater than ŷπ r . Then the estimated rank in the whole list is rπ r = n×(N −1) ϵ + 1. When ϵ goes larger, the estimated rank is more close to the actual rank.</p><p>After getting the estimated student's rank rπ r for the r -th document π r in teacher's top-K ranking, the discrepancy between r and r is computed by</p><formula xml:id="formula_14">w b r = tanh(max(µ • (r π r − r ), 0)),<label>(9)</label></formula><p>where tanh(•) is a rescaled logistic function tanh(x) = 2σ (2x)−1 that rescale the output range to [0, 1] when x &gt; 0. The hyper-parameter µ ∈ R + is used to control the sharpness of the tanh function. Eqn (9) gives a dynamic weight: when the student predicted-rank of a document is close to its teacher, we think this document has been well-predicted and impose little loss on it (i.e., w b r ≈ 0); the rest concentrates on the documents (i.e., w b r ≈ 1) whose student predicted-rank is far from the teacher's rank. Note that the ranking discrepancy weight w b is computed for each document in π    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discussion</head><p>Under the paradigm of ranking distillation, for a certain query q, besides the labeled documents, we use a top-K ranking for unlabeled documents generated by a well-trained teacher ranking model M T as extra information to guide the training of the student ranking model M S with less parameters. During the student model training, we use a weighted point-wise ranking loss as the distillation loss and propose two types of flexible weighting schemes, i.e., w a and w b and propose an effective way to fusion them. For the hyperparameters (α, λ, µ, ϵ, K, m), they are dataset-dependent and are determined for each data set through the validation set. Two key factors for the success of ranking distillation are: (1) larger models are capable to capture the complex interaction patterns between queries and documents, thus, their predicted unlabeled documents at top positions are also strongly correlated with the given query and (2) student models with less parameters can learn from the extra-provided helpful information (top-K unlabeled documents in teacher's ranking) and boost their performances. We also tried to use a pair-wise distillation loss when learning from teacher's top-K ranking. Specifically, we use Eqn (3) for the distillation loss by taking the partial order in teacher's top-K ranking as objective. However, the results were disappointing. We found that if we use pair-wise distillation loss to place much focus on the partial order within teacher's ranking, it will produce both upward and downward gradients, making the training unstable and sometimes even fail to converge. However, our weighted point-wise distillation loss that only contains upward gradients doesn't suffer from this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL STUDIES</head><p>We evaluate the performance of ranking distillation on two realworld data sets. The source code and processed data sets are publicly available online 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Task Description. We use recommendation as our task for evaluating the performance of ranking distillation. In this problem, we 2 https://github.com/graytowne/rank_distill have a set of users</p><formula xml:id="formula_15">U = {u 1 , u 2 , • • • , u | U | } and a universe of items I = {i 1 , i 2 , • • • , i | I | }.</formula><p>For recommendation without context information, we can cache the recommendation list for each user <ref type="foot" target="#foot_2">3</ref> . However, for context-aware recommendation, we have to re-compute the recommendation list each time a user comes with a new context, so the online inference efficiency becomes important. The following sequential recommendation is one case of context-aware recommendation. Given a users u with her/his history sequence (i.e., past L interacted items) at time t, S (u,t ) = (S u t −1 , .., S u t −L ), where S u i ∈ I, the goal is to retrieve a list of items for this user that meets her/his future needs. In IR's terms, the query is the user profile (u, S (u,t ) ) at time t, and the document is the item. Note that whenever the user has a new behavior (e.g., watch a video/listen to a music), we have to re-compute the recommendation list as her/his context changes. We also wish to point out that, in general, ranking distillation can be applied to other learning to rank tasks, not just to recommendation. Datasets. We choose two real-world data sets in this work, as they contain numerous sequential signals and thus suitable for sequential recommendation <ref type="bibr" target="#b32">[33]</ref>. Their statistics are described in Table <ref type="table" target="#tab_1">1</ref>. Gowalla<ref type="foot" target="#foot_3">4</ref> was constructed by <ref type="bibr" target="#b6">[7]</ref> and Foursquare was obtained from <ref type="bibr" target="#b37">[38]</ref>. These data sets contain sequences of implicit feedbacks through user-venue check-ins. During the offline training phase, for a user u, we extract every 5 successive items (L = 5) from her sequence as S (u,t ) , and the immediately next item as the groundtruth. Following <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b37">38]</ref>, we hold the first 70% of actions in each user's sequence as the training set and use the next 10% of actions as the validation set to search the optimal hyperparameter settings for all models. The remaining 20% actions in each user's sequence are used as the test set for evaluating a model's performance. Evaluation Metrics. As in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37]</ref>, three different evaluation metrics used are Precision@n (Prec@n), nDCG@n, and Mean Average Precision (MAP). We set n ∈ {3, 5, 10}, as recommendations are top positions of rank lists are more important. To measure the online inference efficiency, we count the number of parameters in each model and report the wall time for making a recommendation list to every user based on her/his last 5 actions in the training data set. While training models efficiently is also important, training is done offline before the recommendation phase starts, and our focus is the online inference efficiency where the user is waiting for the responses from the system. Teacher/Student Models. We apply the proposed ranking distillation to two sequential recommendation models that have been shown to have strong performances:</p><p>• Fossil. Factorized Sequential Prediction with Item Similarity ModeLs (Fossil) <ref type="bibr" target="#b12">[13]</ref> models sequential patterns and user Table <ref type="table">2</ref>: Performance comparison. <ref type="bibr" target="#b0">(1)</ref> The performance of the models with ranking distillation, Fossil-RD and Caser-RD, always has statistically significant improvements over the student-only models, Fossil-S and Caser-S. (2) The performance of the models with ranking distillation, Fossil-RD and Caser-RD, has no significant degradation from that of the teacher models, Fossil-T and Caser-T. We use the one-tail t-test with significance level at 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gowalla Model</head><p>Prec@3 Prec@5 Prec@10 nDCG@3 nDCG@5 nDCG@10 MAP  <ref type="bibr" target="#b32">[33]</ref> incorporates the Convolutional Neural Network and latent factor model to learn sequential patterns as well as user preferences. It uses a point-wise ranking loss. To apply ranking distillation, we adopt as many parameters as possible for the teacher model to achieve a good performance on each data set. These well-trained teacher models are denoted by Fossil-T and Caser-T. We then use these models to teach smaller student models denoted by Fossil-RD and Caser-RD by minimizing the ranking distillation loss in Eqn (4). The model sizes of the student models are gradually increased until the models reach a comparable performance to their teachers. Fossil-S and Caser-S denote the student models trained with only ranking loss, i.e., without the help from the teacher. Note that the increasing in model sizes is achieved by using larger dimensions for embeddings, without any changes to the model structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fossil</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Overall Results</head><p>The results of each method are summarized in Table <ref type="table">2</ref>. We also included three non-sequential recommendation baselines: the popularity (in all users' sequences) based item recommendation (POP), the item based Collaborative Filtering 5 (ItemCF) <ref type="bibr" target="#b31">[32]</ref>, and the 5 We use Jaccard similarity measure and set the number of nearest neighbor to 20. Bayesian personalized ranking (BPR) <ref type="bibr" target="#b29">[30]</ref>. Clearly, the performance of these non-sequential baselines is worse than that of the sequential recommenders, i.e., Fossil and Caser. The teacher models, i.e., Fossil-T and Caser-T, have a better performance than the student-only models, i.e., Fossil-S and Caser-S, indicating that a larger model size provides more flexibility to fit the complex data with more predictive power. The effectiveness of ranking distillation is manifested by the significantly better performance of Fossil-RD and Caser-RD compared to Fossil-S and Caser-S, and by the similar performance of Fossil-RD and Caser-RD compared to Fossil-T and Caser-T. In other words, thanks to the knowledge transfer of ranking distillation, we are able to learn a student model that has fewer parameters but similar performance as the teacher model. Surprisingly, student models with ranking distillation often have even better performance than their teachers. This finding is consistent with <ref type="bibr" target="#b19">[20]</ref> and we will explain possible reasons in Section 4.3.</p><p>The online inference efficiency is measured by the model size ( number of model parameters) and is shown in Table <ref type="table" target="#tab_3">3</ref>. Note that Fossil-S and Caser-S have the same model size as Fossil-RD and Caser-RD. All inferences were implemented using PyTorch with CUDA from GTX1070 GPU and Intel i7-6700K CPU. Fossil-RD and Caser-RD nearly half down the model size compared to their teacher models, Fossil-T and Caser-T. This reduction in model size is translated into a similar reduction in online inference time. In many practical applications, the data set is much larger than the data sets considered here in terms of the numbers of users and items; for example, Youtube could have 30 million active users per day and 1.3 billion of items 6 . For such large data sets, online inference could be more time-consuming and the reduction in model size has more privileges. Also, for models that are much more complicated than Fossil and Caser, the reduction in model size could yield a larger reduction in online inference time than reported here.</p><p>In conclusion, the findings in Table <ref type="table">2</ref> and 3 together confirm that ranking distillation helps generate compact models with no or little compromise on effectiveness, and these advantages are independent of the choices of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Effects of Model Size and Distillation Loss</head><p>In this experiment, we study the impact of model size on the student model's performance (i.e., MAP). We consider only Caser because the results for Fossil are similar. Figure <ref type="figure" target="#fig_7">5a</ref> shows the results. Caser-S and Caser-RD perform better when the model size goes up, but there is always a gap. Caser-RD reaches a similar performance to its teacher with the medium model size, which is about 50% of the teacher model size.</p><p>Figure <ref type="figure" target="#fig_7">5b</ref> shows the impact of ranking distillation on the student model's MAP iteration by iteration. We compare four models:  Case-S, Caser-T, Caser-RD, and Caser-S-RD. The last model minimizes ranking loss during the first 30 iterations and adds distillation loss after that. Caser-RD outperforms Caser-S all the time. Caser-S reaches its limit after 50 iterations on Gowalla and 70 iterations on Foursquare. Caser-S-RD performs similarly to Caser-S during the first 30 iterations, but catches up with the Caser-RD at the end, indicating the impressive effectiveness of ranking distillation. Caser-T performs well at first but tends to get overfitted after about 60 iterations due to its large model size and the sparse recommendation data sets. In contrast, Caser-RD and Caser-S-RD, which have smaller model sizes, are more robust to overfitting issue, though their training is partially supervised by the teacher. This finding reveals another advantage of ranking distillation. Figure <ref type="figure" target="#fig_9">6</ref> shows the MAP for various balancing parameter α to explore models' performance when balancing ranking loss and distillation loss. For Gowalla data, the best performance is achieved when α is around 0.5. But for Foursquare data, the best performance is achieved when α is around 0.3, indicating too much concentrate on distillation loss leads to a bad performance. On both data sets, either discarding ranking loss or discarding distillation loss gives poor results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Effects of Weighting Schemes</head><p>Table <ref type="table" target="#tab_4">4</ref> shows the effects of the proposed weighting schemes in our ranking distillation. For the weight w r for r -th document in the teacher's top-K ranking, we used the equal weight (w r = 1/K) as the baseline and considered the weighting by position importance (w r = w a r ), the weighting by ranking discrepancy (w r = w b r ), and the hybrid weighting (w r ∝ w a r • w b r ). The equal weight performs the worst. The position importance weighting is much better, suggesting that within the teacher's top-K ranking, documents at top positions are more related to the positive ground truth. The ranking discrepancy weighting only doesn't give impressive results, but when used with the position importance weighting, the hybrid weighting yields the best results on both data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>In this section, we compared our works with several related research areas. Knowledge Distillation Knowledge distillation has been used in image recognition <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">31]</ref> and neural machine translation <ref type="bibr" target="#b19">[20]</ref> as a way to generate compact models. As pointed out in Introduction, it is not straightforward to apply KD to ranking models and new issues must be addressed. In the context of ranking problems, the most relevant work is <ref type="bibr" target="#b5">[6]</ref>, which uses knowledge distillation for image retrieval. This method applies the sampling technique to rank a sample of the image from all data each time. In general, training on a sample works if the sample shares similar patterns with the rest of data through some content information, such as image contents in the case of <ref type="bibr" target="#b5">[6]</ref>. But this technique is not applicable to training a recommender model when items and users are represented by IDs with no content information, as in the case of collaborative filtering. In this case, the recommender model training cannot be easily generalize to all users and items. Semi-Supervised Learning Another related research area is semisupervised learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b42">43]</ref>. Unlike the teacher-student model learning paradigm in knowledge distillation and in our work, semisupervised learning usually trains a single model and utilizes weaklabeled or unlabeled data as well as the labeled data to gain a better performance. Several works in information retrieval followed this direction, using weak-labeled or unlabeled data to construct test collections <ref type="bibr" target="#b1">[2]</ref>, to provide extra features <ref type="bibr" target="#b10">[11]</ref> and labels <ref type="bibr" target="#b9">[10]</ref> for ranking model training. The basic idea of ranking distillation and semi-supervised learning is similar as they both utilize unlabeled data while with different purpose. Transfer Learning for Recommender System Transfer learning has been widely used in the field of recommender systems <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref>. These methods mainly focus on how to transfer knowledge (e.g., user rating patterns) from a source domain (e.g., movies) to a target domain (e.g., musics) for improving the recommendation performance. If we consider the student as a target model and the teacher as a source model, our teacher-student learning can be seen as a special transfer learning. However, unlike transfer learning, our teacher-student learning does not require two domains because the teacher and student models are learned from the same domain. Having a compact student model to enhance online inference efficiency is another purpose of our teacher-student learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>The proposed ranking distillation enables generating compact ranking models for better online inference efficiency without scarifying the ranking performance. The idea is training a teacher model with more parameters to teach a student model with fewer parameters to rank unlabeled documents. While the student model is compact, its training benefits from the extra supervision of the teacher, in addition to the usual ground truth from the training data, making the student model comparable with the teacher model in the ranking performance. This paper focused on several key issues of ranking distillation, i.e., the problem formulation, the representation of teacher's supervision, and the balance between the trust on the training data and the trust on the teacher, and presented our solutions. The evaluation on real data sets supported our claims.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: (a) Knowledge Distillation: given an input, student model learns to minimize the KL Divergence of its label distribution and teacher model's. (b) Ranking Distillation: given an query, student model learns to give higher rank for it's teacher model's top-K ranking of documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Two ways of boosting mean average precision (MAP) on Gowalla data for recommendation. (a) shows that a larger model size in number of parameters, indicated by the bars, leads to a higher MAP. (b) shows that a larger sample size of training instances leads to a higher MAP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The learning paradigm with ranking distillation.We first train a teacher model and let it predict a top-K ranked list of unlabeled (unobserved) documents for a given query q. The student model is then supervised by both ground-truth ranking from the training data set and teacher model's top-K ranking on unlabeled documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An illustration of hybrid weighting scheme. We use K = 3 in this example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>1..K during training. So in practice, we choose ϵ ≪ | Ô| for training efficiency. While extra computation used to compute relevance scores for sampled ϵ documents, we still boost the whole offline training process. Because the dynamic weight allows the training to focus on the erroneous parts in the distillation loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3. 2 . 3</head><label>23</label><figDesc>Hybrid Weighting Scheme. The hybrid weighting combines the weight w a by position importance, and the weight w b by ranking discrepancy: w r = (w a r • w b r )/( K i=1 w a i • w b i ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4</head><label>4</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Mean average precision vs. (a) model size and (b) the choice of distillation loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>6 https://fortunelords.com/youtube-statistics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: MAP vs. balancing parameter α</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the data sets the estimated student ranking of rπ r is not accurate during the first few iterations, we use only w a during the first m iterations to warm up the model, and then use the hybrid weighting to make training focus on the erroneous parts in distillation loss. m should be determined via the validation set. In our experiments, m is usually set to more than half of the total training iterations.</figDesc><table><row><cell>Datasets</cell><cell>#users</cell><cell>#items</cell><cell>avg. actions per user</cell><cell>(u, S (u,t ) ) pairs</cell><cell>Sparsity</cell></row><row><cell>Gowalla</cell><cell>13.1k</cell><cell>14.0k</cell><cell>40.74</cell><cell>367.6k</cell><cell>99.71%</cell></row><row><cell>Foursquare</cell><cell>10.1k</cell><cell>23.4k</cell><cell>30.16</cell><cell>198.9k</cell><cell>99.87%</cell></row><row><cell cols="3">illustrates the advantages of hybrid weighting over weighting only</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">by position importance. Our experiments show that this hybrid</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">weighting gives better results in general. In the actual implemen-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>tation, since</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Model compactness and online inference efficiency.</figDesc><table><row><cell cols="6">Time (seconds) indicates the wall time used for generating</cell></row><row><cell cols="6">a recommendation list for every user. Ratio is the student</cell></row><row><cell cols="6">model's parameter size relative to the teacher model's pa-</cell></row><row><cell>rameter size.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Datasets Model</cell><cell cols="4">Time (CPU) (GPU) Time #Params Ratio</cell></row><row><cell></cell><cell>Fossil-T</cell><cell>9.32s</cell><cell>3.72s</cell><cell>1.48M</cell><cell>100%</cell></row><row><cell>Gowalla</cell><cell>Fossil-RD Caser-T</cell><cell>4.99s 38.58s</cell><cell>2.11s 4.52s</cell><cell>0.64M 5.58M</cell><cell>43.2% 100%</cell></row><row><cell></cell><cell cols="2">Caser-RD 18.63s</cell><cell>2.99s</cell><cell>2.79M</cell><cell>50.0%</cell></row><row><cell></cell><cell>Fossil-T</cell><cell>6.35s</cell><cell>2.47s</cell><cell>1.01M</cell><cell>100%</cell></row><row><cell>Foursquare</cell><cell>Fossil-RD Caser-T</cell><cell>3.86s 23.89s</cell><cell>2.01s 2.95s</cell><cell>0.54M 4.06M</cell><cell>53.5% 100%</cell></row><row><cell></cell><cell cols="2">Caser-RD 11.65s</cell><cell>1.96s</cell><cell>1.64M</cell><cell>40.4%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance of Caser-RD with different choices of weighting scheme on two data sets.</figDesc><table><row><cell cols="4">Datasets Weighting P@10 nDCG@10</cell><cell>MAP</cell></row><row><cell>Gowalla</cell><cell>w r = 1/K w r = w a r w r = w b r</cell><cell>0.0843 0.0850 0.0851</cell><cell>0.1198 0.1230 0.1227</cell><cell>0.0925 0.0945 0.0937</cell></row><row><cell></cell><cell>hybrid</cell><cell>0.0878</cell><cell>0.1283</cell><cell>0.0969</cell></row><row><cell>Foursquare</cell><cell>w r = 1/K w r = w a r w r = w b r</cell><cell>0.0424 0.0423 0.0429</cell><cell>0.1046 0.1052 0.1035</cell><cell>0.0914 0.0929 0.0912</cell></row><row><cell></cell><cell>hybrid</cell><cell>0.0444</cell><cell>0.1076</cell><cell>0.0952</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">BACKGROUNDSWe first review the learning to rank problem, then revisit the issues of effectiveness and efficiency in the problem, which serves to motivate our ranking distillation. Without loss of generality, we use the IR terms "query" q and "document" d in our discussion, but</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1">When using point-wise and pair-wise losses, we only need to compute the student's predictions for a subset of documents, instead of all documents, for a given query.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">We suppose the recommendation model doesn't change immediately whenever new observed data come, which is common in real-world cases.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://snap.stanford.edu/data/loc-gowalla.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The work of the second author is partially supported by a Discovery Grant from Natural Sciences and Engineering Research Council of Canada.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Large scale distributed neural network training through online distillation</title>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ormándi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03235</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pseudo test collections for learning web search ranking functions</title>
		<author>
			<persName><forename type="first">Nima</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Research and development in Information Retrieval</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1073" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Do deep nets really need to be deep?</title>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2654" to="2662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised learning (chapelle, o</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<editor>. et al.</editor>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="542" to="542" />
			<date type="published" when="2006">2009. 2006. 2009</date>
		</imprint>
	</monogr>
	<note>book reviews</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to rank features for recommendation over multiple categories</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International ACM SIGIR conference on Research and Development in Information Retrieval</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="305" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01220</idno>
		<title level="m">DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transfer</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Friendship and mobility: user movement in location-based social networks</title>
		<author>
			<persName><forename type="first">Eunjoon</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1082" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The loss surfaces of multilayer networks</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Choromanska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gérard</forename><surname>Ben Arous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="192" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Recommender systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.08803</idno>
		<title level="m">Neural Ranking Models with Weak Supervision</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to Rank with Labeled Features</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on the Theory of Information Retrieval</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="41" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cross-domain recommender systems: A survey of the state of the art</title>
		<author>
			<persName><forename type="first">Ignacio</forename><surname>Fernández-Tobías</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iván</forename><surname>Cantador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marius</forename><surname>Kaminskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spanish Conference on Information Retrieval. sn</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Collaborative metric learning</title>
		<author>
			<persName><forename type="first">Cheng-Kang</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="193" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanketh</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep learning without poor local minima</title>
		<author>
			<persName><forename type="first">Kenji</forename><surname>Kawaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="586" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Sentence Classification</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods on Natural Language Processing. ACL</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1756" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.07947</idno>
		<title level="m">Sequence-level knowledge distillation</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">FEXIPRO: Fast and Exact Inner Product Retrieval in Recommender Systems</title>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename><surname>Tsz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Man</forename><forename type="middle">Lung</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><surname>Mamoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Management of Data</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="835" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Related pins at pinterest: The evolution of a real-world recommender system</title>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>David C Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Shiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">C</forename><surname>Kislyuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhigang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="583" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Recurrent neural network based language model</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-01">Jan Cernockỳ, and Sanjeev Khudanpur. 2010</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName><forename type="first">Nagarajan</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><forename type="middle">K</forename><surname>Inderjit S Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambuj</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1196" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Text Matching As Image Recognition</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2793" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05649</idno>
		<title level="m">DeepRank: A New Deep Architecture for Relevance Ranking in Information Retrieval</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving pairwise learning for item recommendation from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Search and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="273" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
				<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">Badrul</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Web Search and Data Mining</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Lemp: Fast retrieval of large entries in a matrix product</title>
		<author>
			<persName><forename type="first">Christina</forename><surname>Teflioudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Mykytiuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Management of Data</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="107" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large scale image annotation: learning to rank with joint word-image embeddings</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="21" to="35" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">End-to-End Neural Ad-hoc Ranking with Kernel Pooling</title>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International ACM SIGIR conference on Research and Development in Information Retrieval</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Graph-based point-of-interest recommendation with geographical and temporal influences</title>
		<author>
			<persName><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information and Knowledge Management</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="659" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discrete collaborative filtering</title>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fumin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Research and Development in Information Retrieval</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Discrete Personalized Ranking for Fast Collaborative Filtering from Implicit Feedback</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guowu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1669" to="1675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Preference preserving hashing for efficient recommendation</title>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingyun</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Research and Development in Information Retrieval</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning binary codes for collaborative filtering</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="498" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
