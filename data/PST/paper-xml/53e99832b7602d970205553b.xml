<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Phonocardiography Signal Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-03">March 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Abbas</forename><forename type="middle">K</forename><surname>Abbas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rasha</forename><surname>Bassam</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rasha</forename><forename type="middle">Bassam</forename><surname>Aachen</surname></persName>
						</author>
						<author>
							<persName><surname>Germany</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">RWTH Aachen University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Aachen University of Applied Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Phonocardiography Signal Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-03">March 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">0C0296E324821C7E4DB0E12441C6F450</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>phonocardiography</term>
					<term>auscultation technique</term>
					<term>signal processing</term>
					<term>signal filtering</term>
					<term>heart sounds</term>
					<term>stethoscope microphone</term>
					<term>cardiac acoustic modeling</term>
					<term>wavelets analysis</term>
					<term>data classification</term>
					<term>spectral estimation and analysis</term>
					<term>PCG classification</term>
					<term>phonocardiography calibration</term>
					<term>intracardiac phonocardiography</term>
					<term>cardiac acoustic imaging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The auscultation method is an important diagnostic indicator for hemodynamic anomalies. Heart sound classification and analysis play an important role in the auscultative diagnosis. The term phonocardiography refers to the tracing technique of heart sounds and the recording of cardiac acoustics vibration by means of microphone-transducer. Therefore, understanding the nature and source of this signal is important to give us a tendency for developing a competent tool for further analysis and processing, in order to enhance and optimize cardiac clinical diagnostic approach. This book gives the reader an inclusive view of the main aspects in phonocardiography signal processing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>List of Symbols</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction to Phonocardiography Signal Processing 1.1 INTRODUCTION</head><p>Heart sounds result from the interplay of the dynamic events associated with the contraction and relaxation of the atria and ventricles, valve movements, and blood flow. They can be heard from the chest through a stethoscope, a device commonly used for screening and diagnosis in primary health care. The art of evaluating the acoustic properties of heart sounds and murmurs, including the intensity, frequency, duration, number, and quality of the sounds, are known as cardiac auscultation.</p><p>Cardiac auscultation is one of the oldest means for assessing the heart condition, especially the function of heart valves. However, the traditional auscultation involves subjective judgment by the clinicians, which introduces variability in the perception and interpretation of the sounds, thereby affecting diagnostic accuracy.</p><p>With the assistance of electronic devices, phonocardiography (noninvasive technique)-a graphic recording of heart sounds-can be obtained, leading to more objective analysis and interpretation. In the earlier days, phonocardiography devices were used to document the timings and relative intensities of the components of heart sounds. However, they were generally inconvenient to use.</p><p>Further improvement in analog and digital microelectronics in the past decades has led to the development of the electronic stethoscope and its integrative functionality. These portable electronic stethoscopes allow clinicians to apply both auscultation and phonocardiography more conveniently. The new stethoscopes have also opened the possibilities for the application of advanced signal processing and data analysis techniques in the diagnosis of heart diseases. The practice of cardiac auscultation has come to a new era <ref type="bibr" target="#b0">[1]</ref>.</p><p>In the following chapters of this book, a focus on the biomedical engineering application of cardiac auscultation will considered, regarding the mechanical design, signal processing, data mining, clinical aided diagnosis, and medical standardization of this effective clinical technique.</p><p>Due to the growing field of dynamic biomedical signal modeling and system identification, additional mathematical analysis and modeling of stethoscope operation will be illustrated in a separated chapter. The different methods and a novel analysis algorithm for dynamic assessment of cardiac acoustics signal, such as PCG but not limited to, will improve the associated researchers for better understanding of PCG signal nature and its reflection on integrative clinical diagnosis of cardiomyopathy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">SIGNAL PROCESSING</head><p>What is signal processing? This question will be answered by carefully defining each of the words signal and the processing. Signal is a function of a set of independent variables, with time being perhaps the most prevalent single variable. The signal itself carries some kind of information available for observation. Processing is mean operating in some fashion on signal to extract some useful information. In many cases this processing will be a nondestructive "transformation" of the given data signal; however, some important processing methods turn out to be irreversible and thus destructive <ref type="bibr" target="#b1">[2]</ref>.</p><p>Our world is full in signals-some of these signals are natural, but most of the signals are man made. Some signals are necessary (speech), some are pleasant (music), while many are unwanted or unnecessary in a given situation. In an engineering context, signals are carriers of information, both useful and unwanted. Therefore, extracting or changing the useful information from a mix of conflicting information is the simplest form of signal processing. More generally, signal processing is an operation designed for extracting, enhancing, storing, and transmitting useful information.</p><p>The distinction between useful and unwanted information is often subjective as well as objective. Hence, signal processing tends to be application dependent <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1">OVERVIEW OF SIGNAL PROCESSING</head><p>Originally, signal processing was done only on analog or continuous time signals using analog signals processing (ASP). Until the late 1950s digital computers were not commercially available. When they did become commercially available they were large and expensive, and they were used to simulate the performance of analog signal processing to judge its effectiveness. These simulations, however, led to digital processor code that simulated or performed nearly the same task on samples of the signals that the analog simulation coding of the analog system was actually a digital signal processing (DSP) system that worked on samples of the input and output at discrete time intervals. But implementing signal processing digitally instead of using analog systems was still out of the question.</p><p>The first problem was that an analog input signal had to be represented as a sequence of samples of the signal, which were then converted to the computer's numerical representation. The same process would have to be applied in reverse to the output of the digitally processed signal. The second problem was that because the processing was done on very large, slow, and expensive computers, practical real-time processing between samples of the signal was impossible. The signals that we encounter in practice are mostly analog signals. These signals, which vary continuously in time and amplitude, are processed using electrical networks containing active and passive circuit elements. This approach is known as analog signal processing (ASP). They can also be processed using digital hardware, however, one needs to convert analog signals into a form suitable for digital hardware: this form of the signal is called a digital signal and it takes one of the finite numbers of values at specific instances in time, and hence, it can be represented by binary numbers, or bits.</p><p>The processing of digital signals is called DSP <ref type="bibr" target="#b2">[3]</ref>. Two conceptual schemes for the processing of signals are illustrated in Fig. <ref type="figure">1</ref>.1. The digital processing of analog signals requires an analog-to-digital converter (ADC) for sampling the analog signal and a digital-to-analog converter (DAC) to convert the processed digital signal back to analog form <ref type="bibr" target="#b3">[4]</ref>. It appears from the above two approaches to signal processing, analog and digital, that the DSP approach is the more complicated, containing more components than the ASP. Therefore, one might ask a question: Why process signals digitally? The answer lies in many advantages offered by DSP. Some of the advantages of a DSP system over analog circuitry are summarized as follows <ref type="bibr" target="#b4">[5]</ref>:</p><p>• Flexibility. Function of DSP system can be easily modified and upgraded with software that has implemented the specific algorithm for using the same hardware. One can design a DSP system that can be programmed to perform a wide variety of tasks by executing different software modules.</p><p>• Reproducibility. The performance of a DSP system can be repeated precisely from one unit to another. This is because the signal processing of DSP system works directly with binary sequences.</p><p>• Reliability. The memory and logic of DSP hardware does not deteriorate with age. Therefore, the field performance of DSP systems will not drift with changing environmental conditions or aged electronic components as their analog counterparts do.</p><p>• Complexity. Using DSP allows sophisticated applications such as speech or image recognition to implement for lightweight and low-power portable devices. This is impractical using traditional analog techniques With the rapid evolution in technology in the past several years, DSP systems have a lower overall coast compared to analog systems. The principal disadvantage of DSP is the speed of operations, especially at very high frequencies.</p><p>Primarily due to the above advantages, DSP is now becoming a first choice in many technologies and applications, such as consumer electronics, communications, wireless telephones, and medical engineering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">APPLICATION OF SIGNAL PROCESSING IN BIOMEDICAL ENGINEERING</head><p>Several review articles on medical imaging and biosignals <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b16">[17]</ref> have provided a detailed description of the mainstream signal processing functions along with their associated implementation considerations. These functions will be the effective techniques in the biomedical-biosignals processing and analysis schemes. In the following chapters, the different and several signal processing methods will be presented and discussed, focusing on phonocardiography signal processing and higher-order analysis, such as (classification, data clustering, statistical signal processing, and cardiac acoustic modeling and identification) will be presented. As Fig. <ref type="figure">1</ref>.2 displays the block diagram of the general biomedical signal processing application, this approach can be integrated as a computational core for computer aided diagnosis system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">CARDIOVASCULAR PHYSIOLOGY</head><p>The heart is one of the most important organs of the human body. It is responsible for pumping deoxygenated blood to the lungs, where carbon dioxide-oxygen (CO 2 -O 2 ) exchange takes place, and pumping oxygenated blood throughout the body. Anatomically, the heart is divided into two sides: the left side and the right side, which are separated by the septum. Each side is further divided into two chambers: the atrium and the ventricle.</p><p>As illustrated in Fig. <ref type="figure">1</ref>.3 <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, heart valves exist between the atria and the ventricles and between the ventricles and the major arteries from the heart, which permit blood flow only in one direction. Such valves include the tricuspid valve, the mitral valve, the pulmonary valve, and the aortic valve. The tricuspid and mitral valves are often collectively called the atrioventricular valves, since they direct blood flow from the atria to the ventricles. The competence of the atrioventricular valves depends not only on the proper functioning of the valve leaflets themselves but also on the strong fibrous strands, called chordate tendineae, which are attached to the free edges and ventricular surfaces of the valve cusps. These strands are, in turn, attached to the finger-like projections of the muscle tissue from the endocardium called the papillary muscles <ref type="bibr" target="#b18">[19]</ref>. The heart can be classified from a hemodynamics point of view as a simple reciprocating pump. The mechanical principles of a reciprocating pump are illustrated in Fig. <ref type="figure">1</ref>.3. The pumping chambers have a variable volume and input and output ports. A one-way valve in the input port is oriented such that it opens only when the pressure in the input chamber exceeds the pressure within the pumping chamber. Another one-way valve in the output port opens only when pressure in the pumping chamber exceeds the pressure in the output chamber. The rod and crankshaft will cause the diaphragm to move back and forth. The chamber's volume changes as the piston moves, causing the pressure within to rise and fall. In the heart, the change in volume is the result of contraction and relaxation of the cardiac muscle that makes up the ventricular walls.</p><p>One complete rotation of the crankshaft will result in one pump cycle. Each cycle, in turn, consists of a filling phase and an ejection phase. The filling phase occurs as the pumping chamber's volume is increasing and drawing fluid through the input port. During the ejection phase, the pumping chamber's volume is decreasing and fluid is ejected through the output port. The volume of fluid ejected during one pump cycle is referred as the stroke volume and the fluid volume pumped each minute can be determined by simply multiplying the stroke volume times the number of pump cycles per minute.</p><p>The aortic and pulmonary valves are called the semilunar valves as they have a half-moonshaped structure that prevents the backflow of blood from the aorta or the pulmonary artery into the ventricles. The heart acts like a pump, generating the required pressure to pump blood through the arterial circulation. The process consists of synchronized activities of the atria and the ventricles. First, the atria contract (atria systole) pumping the blood into the ventricles. As the atria begin to relax (atrial diastole), the ventricles contract to force blood into the aorta and the pulmonary artery (ventricular systole). Then the ventricles relax (ventricular diastole). During this phase, both the atria and the ventricles relax until atrial systole occurs again. The entire process is known as the cardiac cycle.</p><p>The diagram shown in Fig. <ref type="figure">1</ref>.4 consists of three main stages: (1) signal data acquisition, (2) signal pre-processing, and (3) signal post-processing and analysis, in which this block diagram shows the general biomedical signal processing and analysis, as an integrative approache for computeraided diagnosis. Figure <ref type="figure">1</ref>.4 displays the different interactions of the cardiac electrical activity, the inter-dynamics between the different systems involved, and the various electrical signals that represent the different cardiac activities. The electrical conduction system is the main rate controller, and it is regulated by the autonomous nervous system. The electrical activity results in action potentials that are conducted through the heart muscle by a specialized conductive tissue system, and can be measured as voltage differences on the body surface, using ECG. The electrical activity triggers the mechanical contraction.</p><p>The mechanical activity of the heart involves contraction of myocardial cells, opening/closing of valves, and flow of blood to and from the heart chambers. This activity is modulated by changes in the contractility of the heart, the compliance of the chamber walls and arteries and the developed pressure gradients. The mechanical activity can be also examined using ultrasound imaging.</p><p>The peripheral blood flows in the arteries and veins is also modulated by mechanical properties of the tissue. The flow of blood can be imaged by Doppler-echo, and the pulse-wave can be captured in one of the peripheral arteries. The different types of signals give us various pieces of information about the cardiac activity. Integrating this information may yield a better ability to assess the condition of the cardiovascular system. The detailed events in the cardiac cycle will explained in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">CARDIAC CYCLE</head><p>The heart is actually composed of two separate pumps, one on the right side that supplies the pulmonary circulation and one on the left that supplies the systemic circulation. The principles that regulate the flow into and out of the heart's ventricles are somehow different from the action of the illustrated mechanical pump, as in Fig. <ref type="figure">1</ref>.3, which has a fixed stroke volume. The temporal relationships between ventricular contraction and blood flow in the heart are illustrated in Fig. <ref type="figure">1.</ref>3. When the ventricular muscle is relaxed, a period referred to as diastole, the pressure in the ventricle will be less than the pressures within the veins and atria, because the ventricle will relax under closed semilunar valves and closed atreoventricular valves, causing blood to flow into the ventricles through the atrioventricular (mitral on the left and tricuspid on the right) valves.</p><p>The relaxed ventricle cannot create a negative pressure to pull blood into it. Instead, the ventricular lumen can only be distended passively with blood under a positive pressure. That pressure must be generated in the veins that feed the heart. Because ventricular filling is in proportion to venous pressure, the heart's stroke volume is quite variable.</p><p>After the end of diastole, the atria will start to contract to push the blood through the atreoventricular valve to the ventricle, and because there are no valves between the atria and the veins, much of the atrial blood is actually forced back into the veins. Nevertheless, atrial contraction will push additional blood into the ventricles, causing further increases in ventricular pressure and volume. Although the benefit of atrial contraction at normal resting condition of the body may be negligible, it can substantially increase ventricular filling at exercise and high heart rates when diastolic filling time is curtailed or the need for extra cardiac output is needed. As the ventricular musculature contracts, a period termed systole, the force in the walls is transmitted to the blood within the ventricular lumen. Ventricular pressure increases and as it rises above atrial pressure, so the atrioventricular valves will close. The heart now begins a period of isovolumetric contraction as pressure builds in the lumen. No blood can enter or leave the ventricle because both the inflow and the outflow valves are closed. When pressure in the ventricular lumen finally exceeds that in the outflow vessel (the aorta for the left heart and the pulmonary artery for the right heart), the semilunar valves (aortic on the left and pulmonary on the right) will be opened and blood is ejected.</p><p>The heart now begins a period of isovolumetric contraction as pressure builds in the lumen. No blood can enter or leave the ventricle because both the inflow and the outflow valves are closed. When pressure in the ventricular lumen finally exceeds that in the outflow vessel (the aorta for the left heart and the pulmonary artery for the right heart), the semilunar valves (aortic on the left and pulmonary on the right) open and blood is ejected.</p><p>As systole ends, the ventricular musculature relaxes and the force exerted on the blood in the ventricular lumen subsides. Ventricular pressure falls below outflow pressure in the outflow vessel and the semilunar valves close. At this point, both the semilunar and the atrioventricular valves are closed so that a second isovolumetric period occurs. Atrial blood will not flow into the ventricles until relaxation has proceeded to the point when ventricular pressure falls below atrial pressure. When that occurs, the atrioventricular (AV) valves open and the filling phase of the cardiac cycle once again repeats itself. 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6">CARDIAC PRESSURE PROFILE</head><p>The physician can best appreciate the events of the cardiac cycle by measuring the pressures at various locations in the cardiovascular system with a catheter. Cardiac catheterization has become a powerful tool for the diagnosis of cardiac disease and the student must, therefore, become thoroughly familiar with the pressure profiles in the atria, ventricles, and great vessels. Formally, seven distinct phases during a single cardiac cycle are recognized. Figure <ref type="figure">1</ref>.4 illustrates how aortic pressure, left ventricular pressure, left atrial pressure, left ventricular volume, and the ECG are temporally correlated throughout these seven phases.</p><p>Period A in Fig. <ref type="figure">1</ref>.5 represents atrial systole. Note that contraction of the left atrium causes both the left ventricular and left atrial pressure to rise by a few mmHg. This rise in the atrial pressure is called the A wave. As the atrium begins to relax, atrial pressure falls causing the X wave. The volume of blood present in the ventricle at the end of atrial systole is termed the end-diastolic volume. In period B, the isovolumetric period of contraction, ventricular pressure is seen to separate from atrial pressure because of closure of the mitral valve. The upward movement of the mitral valve into the atrium causes the C wave. This is followed by a second fall in atrial pressure, the X 0 wave. 1 Medical auscultation technique applied to any acoustic measurement in human body. The isovolumetric period ends as left ventricular pressure reaches arterial pressure and the aortic valve opens. During period C, most of the stroke volume is ejected into the aorta, as shown by the volume trace; hence, the term rapid ejection phase. The next phase, D, is termed the reduced ejection period. During both ejection periods, the aortic valve opens, making the aorta and left ventricle a common chamber and the pressure within them nearly equal.</p><p>During rapid ejection the velocity at which blood is being ejected is increasing, causing ventricular pressure to slightly lead that in the aorta by a few mmHg. As the rate of ejection slows during the reduced ejection period, the inertia of the decelerating column of blood traveling down the aorta reverses the gradient causing aortic pressure to slightly lead ventricular pressure. As the ventricle begins to relax, pressure in the ventricle falls. As blood begins to flow backward across the aortic valve, it closes its leaflets. That momentary retrograde flow of blood at the aortic valve and its abrupt deceleration as the valve snaps closed cause a small rebound in the aortic pressure trace called the dicrotic notch.</p><p>The volume of blood left in the ventricle at aortic valve closure is termed the end-systolic volume. During the isovolumetric period of relaxation, E, left ventricular and aortic pressure separate and ventricular pressure continues to fall. The isovolumetric relaxation period ends when ventricular pressure reaches below the left atrial pressure and the mitral valve opens. Although the mitral valve is closed during ventricular systole, ventricular contraction causes bulging of the atreoventricular valve into the atria and cause its pressure to rise slightly, generating the V wave in the atrial pressure tracing. This elevated pressure causes blood to surge into the ventricle as soon as the mitral valve opens. For that reason, period F is called the rapid filling phase. The abrupt fall in atrial pressure during the rapid filling phase gives rise to the Y wave. During the remainder of diastole, the reduced ventricular filling period, the pressure within the ventricle has equilibrated with atrial pressure, and little additional blood enters the ventricle. As atrial blood fills the ventricle, atrial pressure rises once more as the H wave.</p><p>The pressure in the aorta is the arterial blood pressure. The peak pressure during ejection is referred to as the systolic pressure, whereas the lowest pressure just prior to aortic valve opening is called the diastolic pressure.</p><p>Since the diagram in Figs. <ref type="bibr">1.4</ref> and Fig. <ref type="figure">1</ref>.5 is for the illustration of cardiac cycle events in the left heart and the aortic zone, the pressure relationships within the right heart and pulmonary artery are also illustrated in Fig. <ref type="figure">1</ref>.5 (lower part of the figure) and they are virtually identical to those of the left heart, with the exception that the pressures are only about one-fifth as great.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.7">VENTRICULAR PRESSURE-VOLUME LOOPS</head><p>The function of the left ventricle can be observed over an entire cardiac cycle (diastole plus systole) by combining the two pressure-volume relationships. By connecting these two pressure-volume curves, it is possible to construct a so-called ventricular pressure-volume loop (Fig. <ref type="bibr">1.6)</ref>. Recall that the systolic pressure-volume relationship in Fig. <ref type="figure">1</ref>.5 shows the maximum developed ventricular pressure for a given ventricular volume. To facilitate understanding, a portion of that systolic pressure-volume curve is superimposed as a gold line on the ventricular pressure-volume loop. The line shows the maximum possible pressure that can be developed for a given ventricular volume during systole, i.e., when the ventricle is contracting. Note that point (3) in Fig. <ref type="figure">1</ref>.5 on the pressure-volume loop touches the systolic pressurevolume curve. Also, it may not be evident that the portion of the loop between points 4 and 1 corresponds to a portion of the diastolic pressure-volume curve. The ventricular pressure-volume loop shown in Fig. <ref type="figure">1</ref>.6 describes one complete cycle of ventricular contraction, ejection, relaxation, and refilling as follows:</p><p>• Isovolumetric contraction phase (1→2). Begin the cycle at point 1, which marks the end of diastole. The left ventricle has filled with blood from the left atrium, and its volume is the end-diastolic volume, 140 mL. The corresponding pressure is quite low because the ventricular muscle is relaxed. At this point, the ventricle is activated, it contracts, and ventricular pressure increases dramatically. Because all valves are closed, no blood can be ejected from the left ventricle, and ventricular volume is constant, although ventricular pressure becomes quite high at point 2. Thus, this phase of the cycle is called isovolumetric contraction.</p><p>• Ventricular ejection phase (2→3). At point 2, left ventricular pressure becomes higher than aortic pressure, causing the aortic valve to open. (You may wonder why the pressure at point 2 does not reach the systolic pressure-volume curve shown by the dashed gold line. The simple reason is that it does not have to. The pressure at point 2 is determined by aortic pressure.</p><p>Once ventricular pressure reaches the value of aortic pressure, the aortic valve opens and the rest of the contraction is used for ejection of the stroke volume through the open aortic valve.) Once the valve is open, blood is rapidly ejected, driven by the pressure gradient between the left ventricle and the aorta. During this phase, left ventricular pressure remains high because the ventricle is still contracting. Ventricular volume decreases dramatically, however, as blood is ejected into the aorta. The volume remaining in the ventricle at point 3 is the end-systolic volume, 70 mL. The width of the pressure-volume loop is the volume of blood ejected, or the stroke volume. The stroke volume in this ventricular cycle is 70 mL (140-70 mL).</p><p>• Isovolumetric relaxation phase (3→4). At point 3, systole ends and the ventricle relaxes. Ventricular pressure decreases below aortic pressure and the aortic valve closes. Although ventricular pressure decreases rapidly during this phase, ventricular volume remains constant (isovolumetric) at the end-systolic value of 70 mL because all valves are closed again.</p><p>• Ventricular filling phase (4→1). At point 4, ventricular pressure has fallen to a level that now is less than left atrial pressure, causing the mitral (AV) valve to open. The left ventricle fills with blood from the left atrium passively and also actively, as a result of atrial contraction in the next cycle. Left ventricular volume increases back to the end-diastolic volume of 140 mL. During this last phase, the ventricular muscle is relaxed, and pressure increases only slightly as the compliant ventricle fills with blood.</p><p>Ventricular pressure-volume loops can be used to visualize the effects of changes in preload (i.e., changes in venous return or end-diastolic volume), changes in afterload (i.e., changes in aortic pressure), or changes in contractility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.8">CARDIAC ELECTRICAL CONDUCTION SYSTEM</head><p>The periodic activity of the heart is controlled by an electrical conducting system. The electrical signal originates in specialized pacemaker cells in the right atrium (the sino-atria node), and is propagated through the atria to the AV-node (a delay junction) and to the ventricles. The main events in generating and propagating the bio-action potential of the cardiac tissue are illustrated in Fig. <ref type="figure">1</ref>.7.The electrical action potential excites the muscle cells and causes the mechanical contraction of the heart chambers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.9">PHYSIOLOGY OF THE HEART SOUND</head><p>During the systolic and the diastolic phase of the cardiac cycle, audible sounds are produced from the opening and the closing of the heart valves, the flow of blood in the heart, and the vibration of heart muscles. Usually, four heart sounds are generated in a cardiac cycle. The first heart sound and the second heart sound can be easily heard in a normal heart through a stethoscope placed on a proper area on the chest. The normal third heart sound is audible in children and adolescents but not in most adults.</p><p>The fourth heart sound is seldom audible in normal individuals through the conventional mechanical stethoscopes but can be detected by sensors with high sensitivity, such as electronic stethoscopes and phonocardiography systems. Sounds other than these four, called murmurs, are abnormal sounds resulting from valve problems, or sounds made by artificial pacemakers or prosthetic valves. See Fig. <ref type="figure">1</ref>.4 <ref type="bibr" target="#b20">[21]</ref> for an illustration of how the four heart sounds are correlated to the electrical and mechanical events of the cardiac cycle.</p><p>The first heart sound (S 1 ) occurs at the onset of ventricular systole. It can be most clearly heard at the apex and the fourth intercostal spaces along the left sternal border. It is characterized by higher amplitude and longer duration in comparison with other heart sounds. It has two major highfrequency components that can be easily heard at bedside. Although controversy exists regarding the mechanism of S 1 <ref type="bibr" target="#b2">[3]</ref>, the most compelling evidence indicates that the components result from the closure of the mitral and tricuspid valves and the vibrations set up in the valve cusps, chordate, papillary, muscles, and ventricular walls before aortic ejection <ref type="bibr" target="#b20">[21]</ref>. S 1 lasts for an average period of 100-200ms. Its frequency components lie in the range of 10-200 Hz.</p><p>The acoustic properties of S 1 are able to reveal the strength of the myocardial systole and the status of the atrioventricular valves' function. As a result of the asynchronous closure of the tricuspid and mitral valves, the two components of S 1 are often separated by a time delay of 20-30 ms. This delay is known as the (split) in the medical community and is of significant diagnostic importance. An abnormally large splitting is often a sign of heart problem. The second heart sound (S 2 ) occurs within a short period once the ventricular diastole starts. It coincides with the completion of the T-wave of the electrocardiogram (ECG).</p><p>These sounds can be clearly heard when the stethoscope is firmly applied against the skin at the second or third intercostals space along the left sternal border. S 2 consists of two high-frequency components, one because of the closure of the aortic valve and the other because of the closure of the pulmonary valve. At the onset of ventricular diastole, the systolic ejection into the aorta and the pulmonary artery declines and the rising pressure in these vessels exceeds the pressure in the respective ventricles, thus reversing the flow and causing the closure of their valves. The second heart sound usually has higher-frequency components as compared with the first heart sound. As a result of the higher pressure in the aorta compared with the pulmonary artery, the aortic valve tends to close before the pulmonary valve, so the second heart sound may have an audible split.</p><p>In normal individuals, respiratory variations exist in the splitting of S 2 . During expiration phase, the interval between the two components is small (less than 30 ms). However, during inspiration, the splitting of the two components is evident. Clinical evaluation of the second heart sound is a bedside technique that is considered to be a most valuable screening test for heart disease. Many heart diseases are associated with the characteristic changes in the intensities of or the time relation between the two components of S 2 . The ability to estimate these changes offers important diagnostic clues <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. S 1 and S 2 were basically the main two heart sounds that were used for most of the clinical assessment based on the phonocardiography auscultation procedure.</p><p>The third and fourth heart sounds, also called gallop sounds, are low-frequency sounds occurring in early and late diastole, respectively, under highly variable physiological and pathological conditions. Deceleration of mitral flow by ventricular walls may represent a key mechanism in the genesis of both sounds <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23]</ref>. The third heart sound (S 3 ) occurs in the rapid filling period of early diastole. It is produced by vibrations of the ventricular walls when suddenly distended by the rush of inflow resulting from the pressure difference between ventricles and atria. The audibility of S 3 may be physiological in young people or in some adults, but it is pathological in people with congestive heart failure or ventricular dilatation.</p><p>The presence of the third heart sound in patients with valvular heart disease is often regarded as a sign of heart failure, but it also depends on the type of valvular disease <ref type="bibr" target="#b21">[22]</ref>. In patients with mitral regurgitation, the third heart sound is common but does not necessarily reflect left ventricular systolic dysfunction or increased filling pressure. In patients with aortic stenosis, third heart sounds are uncommon but usually indicate the presence of systolic dysfunction and elevated filling pressure. The fourth heart sound (S 4 ) occurs in late diastole and just before S 1 . It is produced by vibrations in expanding ventricles when atria contract. Thus, S 4 is rarely heard in a normal heart. The abnormally audible S 4 results from the reduced distensibility of one or both ventricles. As a result of the stiff ventricles, the force of atrial contraction increases, causing sharp movement of the ventricular wall and the emission of a prominent S 4 <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">24]</ref>. Most murmurs are the result of turbulent blood flow, which produces a series of vibrations in the cardiac structure. Murmurs during the early systolic phase are common in children, and they are normally heard in nearly all adults after exercise. Abnormal murmurs may be caused by stenosis and insufficiencies (leaks) at the aortic, pulmonary, or mitral valves <ref type="bibr" target="#b22">[23]</ref>. It is important from a diagnostic point of view to note the time and the location of murmurs. The identification of murmurs may assist the diagnosis of heart defections like aortic stenosis, mitral and tricuspid regurgitation, etc.<ref type="foot" target="#foot_0">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.10">ABNORMAL HEART SOUND PATTERN</head><p>Dealing with the cardiac sound abnormalities (in Fig. <ref type="figure">1</ref>.8 and Fig. <ref type="figure">1</ref>.9), there are many cardiac defects that can lead to the production of additional (excessive) or modified heart sounds. Some of these abnormalities will be presented below. There are many web sites where one can download and listen to electronically recorded heart sounds as *.wav files. Also, in Canada, McGill University's Physiology and Music Departments have an unique Medical Informatics web site at which the viewer can listen to various cardiac sounds (normal and abnormal) at different chest recording sites. In addition, the viewer can download 3-D, colored-mesh, time-frequency spectrograms covering several cardiac cycles of a particular sound, as well as read text about the source and significance of the sound (Glass, 1997).  A major source of anomalous heart sounds is damaged heart valves. Heart valves, in particular the left heart valves, can either fail to open properly (they are stenosed) or they cannot close properly (they are incompetent), causing a backflow of blood, or regurgitation. A major source of heart valve damage can be infection by a hemolytic streptococcus, such as scarlet fever, sore throat, or middle ear infection. A serious complication is rheumatic fever, one of the characteristics of which is carditis and valvular damage. The streptococcus bacteria manufacture a protein called the (M antigen) to which the immune system forms antibodies.</p><p>Unfortunately, these antibodies also attack certain body tissues, notably the joints and the heart. Guyton (1991) states: "In rheumatic fever, large hemorrhagic, fibrinous, bulbous lesions grow along the inflamed edges of the heart valves." The scarring from this autoimmune inflammation leaves permanent valve damage. The valves of the left heart (aortic and mitral) are the most prone to damage by antibodies.</p><p>Table <ref type="table" target="#tab_2">1</ref>.1 shows the principle characteristics of the heart mummers which derived spatially and have clinical importance in diagnosis in heart valve abnormalities and describes the different heart sound and the origin of each one. In aortic valve stenosis, the valve cannot open properly; there is an abnormally high hydraulic resistance against which the left ventricle must pump. Thus, the peak left ventricular pressure can rise as high as 300 mmHg, while the aortic pressure remains in the normal range.The exiting blood is forced through the small aperture at very high velocity, causing turbulence and enhanced vibration of the root of the aorta. This vibration causes a loud murmur during systole that is characteristic of aortic stenosis. Aortic regurgitation, on the other hand, occurs because the damaged aortic valve does not close completely. Fig. <ref type="figure">1</ref>.11 shows a schematic representation of typical cardiac variables: the ECG, the logic states of the heart valves, low-and high-frequency phonocardiograms, a recording of a vessel pulse (carotid artery), and of the heart apex pulse (apexcardiogram). The heart cycle is divided into specific intervals according to the valve states of the left heart. The left ventricular systole is composed of the isovolumetric contraction and the ejection period; the left ventricular diastole covers the isovolumetric relaxation and the left ventricular filling (successively, the rapid filling, the slow filling, and the atrial contraction). A similar figure could be given for the right heart; valve phenomena are approximately synchronous with those of the left heart. Small time shifts are typical: mitral valve closure precedes tricuspid closure and aortic valve closure precedes pulmonary closure. The low-frequency PCG shows the four normal heart sounds (I, II, III, and IV). In the high frequency, trace III and IV have disappeared and splitting is visible in I and in II. Again, there is a high-velocity jet of blood forced back into the left ventricle by aortic backpressure during diastole (when the left ventricle is relaxed). This back-pressure makes it difficult for the left atrium to fill the left ventricle, and, of course, the heart must work harder to pump a given volume of blood into the aorta. The aortic regurgitation murmur is also of relatively high pitch, and has a swishing quality <ref type="bibr">(Guyton, 2005, [20]</ref>).</p><p>In mitral valve stenosis, Fig. <ref type="figure">1</ref>.9, the murmur occurs in the last two thirds of diastole, caused by blood's jetting through the valve from the left atrium to the left ventricle. Because of the low peak pressure in the left atrium, a weak, very low-frequency sound is produced.The mitral stenotic murmur often cannot be heard; its vibration must be felt, or seen on an oscilloscope from a microphone output. Another audible clue to mitral stenosis is an opening snap of the mitral valve, closely following the normal S 2 .</p><p>Mitral valve regurgitation takes place during systole. As the left ventricle contacts, it forces a high-velocity jet of blood back through the mitral valve, making the walls of the left atrium vibrate. The frequencies and amplitude of mitral valve regurgitation murmur are lower than aortic valve stenosis murmur because the left atrium is not as resonant as the root of the aorta. Also, the sound has farther to travel from the left atrium to the front of the chest. Another cardiac defect that can be diagnosed by hearing the S 2 sound (split) is a left or right bundle branch block. The synchronization of the contraction of the muscle of the left and right ventricles is accomplished by the wave of electrical depolarization that propagates from the AV node, down the bundle of His, which bifurcates into the left and right bundle branches that run down on each side of the ventricular septum. Near the apex of the heart, the bundle branches branch extensively into the Purkinje fibers, which invade the inner ventricular cardiac muscle syncytium, carrying the electrical activity that triggers ventricular contraction. See Fig. <ref type="figure">1</ref>.11 for a time-domain schematic of where certain heart sounds occur in the cardiac cycle. If the bundle branch fibers on the right side of the septum are damaged by myocardial infarction, the contraction of the right ventricle will lag that of the right, and the sound associated with the aortic valve's closing will lead that sound caused by the pulmonary valve. This split in sound S 2 is heard regardless of the state of inhale or exhale. A left bundle branch block will delay the contraction of the left ventricle, hence delay the aortic valve sound with respect to that of the pulmonary valve.This condition causes reverse splitting of S 2 during expiration, but is absent on inspiration. Other causes of the reverse split include premature right ventricular contraction (as opposed to a delayed left ventricular systole), or systemic hypertension (high venous return pressure).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.10.1">HEART SOUND AS HEMODYNAMIC INDEX</head><p>There is a direct relation between the intensity and the frequency of sound II and the slope of ventricular pressure falling during its volumetric relaxation. Stiffening of the valve leaflets results in a reduction of sound II. A higher valve radius or a lowered blood viscosity gives rise to an increased second sound. Cardiovascular pathologies can have an effect on timing and intensities of the second heart sound components. Wide splitting of sound II can be due to delayed pulmonary valve closure or advanced aortic valve closure. Delayed pulmonary valve closure can be caused by right bundle branch block, pulmonary stenosis, pulmonary hypertension, and atrial septum defect; advanced aortic valve closure can result from mitral regurgitation and ventricular septum defect. Paradoxical splitting of sound II can be due to delayed aortic valve closure or advanced pulmonary valve closure.</p><p>Delayed aortic valve closure can be caused by left bundle branch block, aortic stenosis, and arteriosclerotic heart disease. Advanced pulmonary valve closure can be caused by tricuspid regurgitation and advanced right ventricular activation. IIA and IIP, respectively, can be absent in severe aortic and pulmonary valve stenosis. IIA is decreased in aortic regurgitation and in pathologically diminished left ventricular performance. The third sound (III) occurs during the rapid passive filling period of the ventricle. It is believed that III is initiated by the sudden deceleration of blood flow when the ventricle reaches its limit of distensibility, causing vibrations of the ventricular wall. It can often be heard in normal children and adolescents, but can also be registered in adults (although not heard) in the low-frequency channel. It is a weak and low-pitched (low-frequency) sound. Disappearance of III is a result of aging as a consequence of increasing myocardial mass having a damping effect on vibrations. High filling rate or altered physical properties of the ventricle may cause an increased third sound. If III reappears with aging (beyond the age of 40 years), it is pathological in most cases. A pathological sound III is found in mitral regurgitation, aortic stenosis, and ischemic heart disease. The fourth sound (IV) coincides with the atrial contraction and thus the originated increased blood flow through the mitral valve with consequences as mentioned for the third sound. It is seldom heard in normal cases, sometimes in older people, but is registered more often in the low-frequency channel. The sound is increased in cases of augmented ventricular filling or reduced ventricular distensibility.</p><p>A pathological sound IV is found in mitral regurgitation, aortic stenosis, hypertensive cardiovascular disease, and ischemic heart disease. Besides these four sounds, some pathological heart sounds may be present. Among the systolic sounds there is the ejection sound and the non-ejection systolic click.The ejection sound can be found in different pathological conditions such as congenital aortic or pulmonary valvular stenosis where opening of the cusps is restricted. A non-ejection systolic click may be associated with a sudden mitral valve prolapsed into the left atrium. An opening snap, a diastolic sound, may occur at the time of the opening of the mitral valve, for example, in cases with valve stenosis.</p><p>Heart murmurs are assumed to be caused by different mechanisms as compared to heart sounds. In fact, most murmurs result from turbulence in blood flow and occur as random signals.</p><p>In normal blood vessels at normal velocity values blood flow is laminar, that is, in layers, and no turbulence is observed. In a normal resting human, there may be turbulent flow only in the vicinity of the aortic and pulmonary valves. As flow turbulence, a phenomenon that is generally irregular and random, is associated with pressure turbulence and, consequently, vessel wall vibration, acoustic phenomena may be observed. For flow in a smooth straight tube, the value of the Reynolds number, a dimensionless hydrodynamic parameter, determines the occurrence of turbulence. This number is proportional to the flow velocity and the tube diameter, and inversely proportional to the viscosity of the fluid. If this number exceeds a threshold value, laminar flow becomes turbulent.</p><p>According to this theory, so-called innocent murmurs can be explained: They are produced if cardiac output is raised or when blood viscosity is lowered; they are generally early or mid-systolic, have a short duration, and coincide with maximum ventricular outflow.Turbulence, and thus intensity, of the murmur increase with flow velocity.</p><p>Pathological murmurs may be originated at normal flow rate through a restricted or irregular valve opening (e.g., in cases of valve stenosis) or by an abnormal flow direction caused by an insufficient (leaking) valve or a communication between the left and the right heart. As such systolic, diastolic, or even continuous murmurs may be observed. Systolic ejection murmurs occur in aortic and in pulmonary stenosis (valvular or non-valvular): diastolic filling murmurs in mitral and tricuspid stenosis. Aortic and pulmonary regurgitation causes diastolic murmurs; mitral and tricuspid regurgitation causes systolic murmurs. A systolic murmur and a diastolic murmur can be observed in ventricular septal defect.</p><p>Continuous murmurs occur in patent ductus arteriosus (a connection between pulmonary artery and aorta). Musical murmurs occur as deterministic signals and are caused by harmonic vibration of structures (such as a valve leaflet, ruptured chordae tendinae, malfunctioning prosthetic valve) in the absence of flow turbulence; these are seldom observed. The location of the chest wall where a specific sound or murmur is best observed (in comparison with the other phenomena) may help in discriminating the source of the sound or the murmur <ref type="bibr" target="#b23">[24]</ref>. These locations are dependent, not only on the distance to the source, but also on the vibration direction. Sounds or murmurs with an aortic valve origin are preferably investigated at the second intercostal space right of the sternum and those of pulmonary origin left of the sternum. The right ventricular area corresponds with the lower part of the sternum at the fourth intercostal space level, the left ventricular area between the sternum and the apex point of the heart (at the fifth intercostal space level). Furthermore, specific physiological maneuvers influencing cardiac hemodynamics may be used for obtaining better evaluation of heart sounds and murmurs. In conclusion, the existence, timing, location at the chest wall, duration, relative intensity and intensity pattern, and frequency content of murmurs and/or pathological sound complexes form the basis of auscultatory, and/or phonocardiographic diagnosis of cardiac disease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.11">AUSCULTATION TECHNIQUE</head><p>Before the 19th century, physicians could listen to the heart only by applying their ear directly to the chest. This immediate auscultation suffered from social and technical limitations, which resulted in its disfavor. The invention of the stethoscope and cardiac auscultation technique by Laennec (1781-1826) in 1816 (see Fig. <ref type="figure">1</ref>.10), introduced a practical method of bedside examination, which became known as mediate auscultation. Over the past two centuries, many illustrious physicians have used this technique to provide an explanation of the sounds and noises heard in the normal and diseased heart. The sounds of the normal human heart can be represented by a simple onomatopoeic simulation: (. . . lubb-dup. . . .). Two sounds can clearly be identified, the first being duller than the second. A heart sound or a heart sound component is defined as a single audible event preceded and followed by a pause. As such, splitting of a sound occurs as one can clearly distinguish two components separated by a small pause. The closest splitting that can be appreciated is ≈20-30 ms. Similar guidelines are followed for the identification of phonocardiographic recordings: A sound is a complex of succeeding positive and negative deflections alternating with respect to the baseline, preceded and followed by a pause.</p><p>A sound is said to be split if a small pause between the components can be perceived. At this point, the effect of frequency filtering may be important: splitting, being invisible on a low-frequency recording, and may become recognizable on a high-frequency recording. Summarizing, in clinical PCG primarily the envelope of the recorded signal is regarded and can be stated, not the actual waveform as, for example, in ECG, blood pressure, and velocity recordings. As spectral performance of phonocardiography may exceed the possibilities of human hearing, inaudible, low-frequency phenomena can be recorded; they are also indicated as (inaudible) sounds. Acoustic phenomena originated by the heart are classified into two categories: heart sounds and heart murmurs.</p><p>Although the distinction between them is not strict, one can state that heart sounds have a more transient, musical character (cf. the touching of a string) and a short duration, whereas most murmurs have a predominantly noisy character and generally (but not always) a longer duration (e.g., a "blowing" murmur, a "rumbling" murmur). It is also believed that the genesis of both types is different: Heart sounds are indicated as types of resonant phenomena of cardiac structures and blood as a consequence of one or more sudden events in the cardiohemic system (such as valve closure), and most heart murmurs are said to be originated by blood flow turbulence. Many aspects of the problem of the genesis of these phenomena are still being discussed, including the relative importance of the valves and of the cardiohemic system in the generation of heart sounds (valvular theory versus cardiohemic theory).</p><p>Four normal heart sounds can be described in Fig. <ref type="figure">1</ref>.12 and can be acquired from four heart sites. As shown in Fig. <ref type="figure">1</ref>.11 they are: I, II, III, and IV (also indicated as S 1 , S 2 , S 3 , S 4 ).The two having the largest intensity, that is, the first (I, S 1 ) and the second (II, S 2 ) sound, are initially related to valve closure. The third (III, S 3 ) and the fourth (IV, S 4 ) sound, appearing extremely weak and dull and observable only in a restricted group of people, are not related to valve effects. The so-called closing sounds (I and II) are not originated by the cooptation of the valve leaflets (as the slamming of a door). On the contrary, it is most probably a matter of resonant-like interaction between two cardiohemic compartments suddenly separated by an elastic interface (the closed valve leaflets) interrupting blood flow: Vibration is generated at the site of the valve with a main direction perpendicular to the valve orifice plane and dependent on the rapid development of a pressure difference over the closed valve. In the case of the first sound, this phenomenon is combined with the effect of a sudden contraction of cardiac ventricular muscle.</p><p>Pathologies of the cardiovascular system which occur due to different etiology, e.g., congenital heart valve defects, stenotic valve, and regurgitated valve as illustrated in Fig. <ref type="figure">1</ref>.13, can affect the normal sounds with respect to intensity, frequency content, and timing of components (splitting) <ref type="bibr" target="#b24">[25]</ref>. The first heart sound (I) occurs following the closing of the mitral valve and of the tricuspid valve, during the isovolumetric contraction period, and, furthermore, during the opening of the aortic valve and the beginning of ejection. In a medium-or high-frequency recording, a splitting of the first sound may be observed. Components related to the closing of the mitral valve (Ia, M1), the closing of the tricuspid valve (Ib, T1), and the opening of the aortic valve may be observed. There is a direct  ventricular filling; both components may fuse together at the end of expiration. Paradoxical splitting (the pulmonary component preceding the aortic one) is pathological. The pulmonary component normally has a lower intensity; an increased intensity with respect to the aortic component is generally abnormal.</p><p>As Table <ref type="table" target="#tab_2">1</ref>.2 indicates, the major pathological conditions of the heart valves and its correlated occurrence in the cardiac cycle heart sounds are heavily attenuated during their travel from the heart and major blood vessels, through the body tissues, to the body surface. The most compressible tissues, such as the lung and the fat layers, usually contribute the most to the attenuation of the transmitted sounds. To clearly perceive various heart sounds, optimal recording sites are defined, which are the locations where the sound is transmitted through solid tissues or through a minimal thickness of an inflated lung. As mentioned before, four basic chest locations exist is illustrated in Fig. <ref type="figure">1</ref>.12 <ref type="bibr" target="#b22">[23]</ref> where the intensity of sound from the four valves is maximized. As heart sounds and murmurs have low amplitudes, extraneous noise level in the surrounding area of the patient must be minimized. The auscultation results can be vastly improved if the room is kept as quiet as possible before auscultation begins. The patients should be recumbent and completely relaxed. They need to hold their breaths so that the noise from their breath and the baseline wandering caused by movement can be minimized <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27]</ref>. Table <ref type="table" target="#tab_2">1</ref>.3 illustrates the varieties of cardiac murmurs that are associated with systolic and diastolic phased of the cardiac cycle. It lists the focal cardiac murmurs and their related criteria of S 1 and S 2 in systolic and diastolic phases in the cardiac cycle, in addition it shows the hemodynamic </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.12">SUMMARY</head><p>The main outline of this chapter is the focus on the basic physiology of cardiac system and cardiac cycle, with intensive illustration of the heart sound associative events in this cycle. The introductory section for the main physiological basis of circulation, heart valve actions and electrical events as a bundle information was intended to give the reader an overview of how heart sounds originated.</p><p>The principal mechanical and electrical events, and definitely the generation of the heart sounds in synchronization with other cardiac events (cardiac chambers blood pressure, electrical activity of the heart and respiration rate) can be synchronized of different time-traces and described in various states to represent physiological events of cardiovascular system.</p><p>C H A P T E R 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phonocardiography Acoustics Measurement 2.1 DYNAMICS OF PHONOCARDIOGRAPHY</head><p>Mechanical heart action is accompanied by audible noise phenomena, which are easy to perceive when the ear is placed on to a person's chest wall. These cardiovascular sounds can be designated as being weak in comparison with other physiological sounds, such as speech, stomach and intestine rumbling, and even respiration noises. In fact, the latter can be heard at a certain distance from the subject, which is not true for heart noises (provided one overlooks cases of artificial heart valves). The frequency content of heart sounds is situated between 20 and 1000 Hz, the lower limit being set by the ability of human hearing. Sounds from mechanical valve prostheses may largely exceed the upper limit. Examination of cardiovascular sounds for diagnostic purposes through the human hearing sense, auscultation, has been commonly practiced for a long time <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25]</ref>. The only technology involved is the stethoscope, establishing a closed air compartment between a part of the person's chest surface and the physician's ear orifice. This investigation method, however, being completely psychophysical and thus subjective, has proved its benefit and continues to be an important tool in cardiovascular diagnosis. Phonocardiography (PCG) can simply be defined as the method for obtaining recordings of cardiovascular sound, that is, the phenomena perceivable by auscultation. The origin of this method is strongly anchored in auscultation. The recordings of sounds are evaluated, on paper or computer screen, possibly in the presence of other synchronous signals (e.g., the electrocardiogram, ECG), partly psychophysically with another human sense, the eye, in examining waveform patterns and their relation with the other signals.</p><p>Phonocardiographic signals are examined with respect to the occurrence of pathological patterns, relative intensities and intensity variations, timing, and duration of events. Evidently, more objective evaluation can be performed ranging from simple accurate timing of phenomena to advanced waveform analysis and comparing recorded results with waveforms from data banks. The typical PCG signal recording was illustrated in Fig. <ref type="figure" target="#fig_62">2</ref>.1 as it shows successive eight-phonocardiography trace with clinical annotated markers.</p><p>The importance of auscultation can be explained by the simplicity of the technique and by the strong abilities of the human ear with respect to pattern recognition in acoustic phenomena. There are different PCG signal patterns which can be differentiated from the clinical experience; some of these pattern were shown in Fig. <ref type="figure" target="#fig_62">2</ref>.2a. For obtaining equivalent information with phonocardiography, a single recording fails to be sufficient.   A set of frequency filtered signals, each of them emphasizing gradually higher-frequency components (by using high-pass or band-pass filters-HPF, BPF), is needed. In this way, visual inspection of sound phenomena in different frequency ranges, adapted by a compensating amplification for the intensity falloff of heart sounds toward higher frequencies, is made possible, thus rendering the method equivalent to the hearing performance: pattern recognition abilities and increasing sensitivity toward higher frequencies (within the above-mentioned frequency range). Laennec (1781-1826) was the first one who listened to the sounds of the heart, not only directly with his ear to the chest but also through his invention of the stethoscope which provided the basis of contemporary auscultation. As physiological knowledge increased through the following decades, faulty interpretations of heart sounds were progressively eliminated. The first transduction of heart sounds was made by Huerthle (1895), who connected a microphone to a prepared frog nerve-muscle tissue. Einthoven (1907) was the first to record phonocardiograms with the aid of a carbon microphone and a string galvanometer for recording muscular acoustic vibration <ref type="bibr" target="#b27">[28]</ref>.</p><p>A large number of researchers and investigators were involved in the development of filters to achieve a separation of frequency phenomena such as the vacuum tube, and thus electronic amplification became available. The evolution of PCG was strongly coupled with auscultatory findings and the development was predominantly driven by clinicians. As a result, a large variety of apparatus has been designed, mostly according to the specific needs of a clinic or the scientific interests of a medical researcher. During the 1960s, the necessity for standardization was strongly required. Standardization committees made valuable proposals <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b26">27]</ref> but the impact on clinical phonocardiographic apparatus design was limited. Fig. <ref type="figure" target="#fig_62">2</ref>.3 illustrates the PCG audible range which can be considered in synthesis and development of the accurate spectral and frequency segmentation of cardiac auscultatory waveforms.</p><p>During the 1970s and the beginning of the 1980s, fundamental research on physical aspects of recording, genesis, and transmission of heart sound was performed <ref type="bibr" target="#b24">[25]</ref> which, together with other clinical investigations, improved the understanding of the heart sound phenomena. At the same time, ultrasonic methods for heart investigation became available and gradually improved. Doppler and echocardiography provided information closer related to heart action in terms of heart valve and wall movement, and blood velocity. Moreover, obtaining high-quality recordings of heart sound with a high signal-to-noise ratio (SNR) is difficult. Hampering elements are the inevitable presence of noise (background noise, respiration noise, muscle tremors, stomach rumbling), non-optimal recording sites, weak sounds (obese patients), and so on. Thus, interest in PCG gradually decreased. In describing the state of the art, PCG is usually compared with ECG, the electrical counterpart, also a non-invasive method. The ECG, being a simple recording of electrical potential differences, was easily standardized, thus independent of apparatus design and completely quantitative with the millivolt scale on its ordinate axis <ref type="bibr" target="#b26">[27]</ref>. Phonocardiography has not reached the same level of standardization, remains apparatus dependent, and thus semi quantitative. Nowadays, Doppler echocardiography and cardiac imaging techniques largely exceed the possibilities of PCG and make it redundant for clinical diagnosis. The presentation of echocardiography imaging and high definition  electronic stethoscope (combined with PC and acquisition software), as a modern concept for PCG, may gain importance for clinical purposes. The generation of sounds is one of the many observable mechanical effects caused by heart action: contraction and relaxation of cardiac muscle, pressure rising and falling in the heart cavities, valve opening and closure, blood flowing, and discontinuation of flow. In the next section, further details will be given on the physiological significance, the physical aspects and recording methods, processing, and physical modeling of heart sounds. Special attention will also given to the electronic stethoscope and biomedical instrumentation aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">VIBRATORY PCG SIGNAL SPECTRUM</head><p>The displacement of the chest wall over the pericardial area represents a periodic, complex wave, which is the result of the superimposition (or addition) of pure sinusoidal waves of different frequencies and various amplitudes, as conducted by Kisie et al. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>. This definition is far more comprehensive than an older one, advocated by clinical cardiologists, which restricted phonocardiography to the recording of clinically audible vibrations. This classical definition is gradually being discarded. PCG signals can be analyzed using Fourier's analysis by separating them into a number of sinusoidal or harmonic components of the fundamental frequency w-f , which is that of the heart beat. It must be stressed that the complex wave representing the displacement of the chest wall constitutes a single physical entity. The method recording it should actually be called vibrocardiography but the name phonocardiography is retained, partly because of tradition and partly because sound is a physical phenomenon, whether audible or not. The frequency range and energy distribution of the audible vibrocardiography or (phonocardiography) signal were displayed in Fig. <ref type="figure" target="#fig_62">2</ref>.5, where the threshold of the audible heart murmurs has a cut-off of 57 Hz with energy level 0.98 Dyne/cm 2 , and the scheme of phonocardiography sound pressure level was shown in Fig. <ref type="figure" target="#fig_62">2</ref>.6.</p><p>The total vibratory spectrum can be divided into various bands:</p><p>1. From 0-5 Hz. This band of vibrations corresponds to the visible and easily palpable motions of the chest wall. It includes the apex beat, the epigastric beat, and several other motions of various intercostals spaces. Studies by McKinney, Hess, Weitz, Weber and Paccon, was investigated <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref> (cardiogram, epigastric tracing, ultra-low frequency tracing of the chest), by Johnston and Otto <ref type="bibr" target="#b22">[23]</ref> (linear tracing), and by Edelman <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref>(ultra-low frequency tracing, kineto cardiogram). This band is definitely subsonic because it is below the threshold of hearing. It is possible that the ballistic motions of the chest in tote are better recorded by Edelman's method (fixed pickup) while the intrinsic vibrations of the wall is better recorded by pickups which (float) with the wall itself.</p><p>2. From 5-25 Hz. This band includes the vibrations which are now called low-frequency vibrations. It barely overlaps the audible range been particularly studied by means of electromagnetic pickups which give an acceleration tracing by Rosa <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref> and by <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. It was also studied by Mannheimer <ref type="bibr" target="#b20">[21]</ref> (displacement tracing). This band is partly infrasonic (5-15 Hz) and partly subliminal (15-25 Hz); therefore, it is partly in that range where large vibrations may be perceived by the human ear.</p><p>3. From 25-120 Hz. This band was studied by Mannheimer <ref type="bibr" target="#b28">[29]</ref>. It was reproduced by the (stethoscopes) method of Rappaport and Sprague <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b27">28]</ref>, through the use of the stethocardiette (by the more modern twin beam). The most important octave band (60-120 Hz) included in this wider band is fairly well studied by the devices of Butterworth <ref type="bibr" target="#b13">[14]</ref>, Maass,  Weber, and Holldack <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b25">26]</ref>. This band is partly subliminal, because the perceptivity of the aer is poor between 25 and 50, and is definitely auditory above 50.</p><p>4. From 120-240 Hz. It corresponds to the best area of recording of most apparatus and is in the auditory range. It was studied by Mannheimer <ref type="bibr" target="#b31">[32]</ref>, Maass and Weber <ref type="bibr" target="#b32">[33]</ref> and Holldack <ref type="bibr" target="#b30">[31]</ref>; it corresponds to the low channel of Leatham <ref type="bibr" target="#b33">[34]</ref>, one of the channels of Butterworth <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b34">35]</ref>. 5. From 240-500 Hz. It corresponds to a fairly good area of recording of many apparatus. It is approximately represented by the (logarithmic) method of Rappaport and Sprague <ref type="bibr" target="#b29">[30]</ref>. It corresponds to the middle channel of Leatham <ref type="bibr" target="#b33">[34]</ref>, to one channel of Butterworth <ref type="bibr" target="#b33">[34]</ref>, to one channel of Maass and Weber <ref type="bibr" target="#b32">[33]</ref>, and Holldack <ref type="bibr" target="#b30">[31]</ref>. It is still within the auditory range.</p><p>6. From 500-1000 Hz. This large band corresponds already to the area of the spectrum where sounds originating in the heart and recorded from the chest wall are of extremely reduced magnitude.Therefore, audibility may be limited or even null, not on account of frequency threshold, but on account of poor magnitude. Records have been taken in this band by Mannheimer <ref type="bibr" target="#b30">[31]</ref>,</p><p>Maass and Weber <ref type="bibr" target="#b32">[33]</ref>, Holldack <ref type="bibr" target="#b30">[31]</ref>, Leatham <ref type="bibr" target="#b33">[34]</ref>, and Luisada et al. <ref type="bibr" target="#b34">[35]</ref>. However, most of these records are not illustrative on account of either inadequate magnification or high (noise) level. Good tracings, on the other hand, have been recorded by Luisada and Zalter through the use of a specially built phonocardiograph <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>7. From 1000-2000 Hz. This band is usually subliminal on account of poor magnitude of the vibrations. Only two apparatus seem able to record vibrations due to cardiac dynamics, in a few normal subjects and in some cardiac patients. One is that of Butterworth (full rotation) <ref type="bibr" target="#b13">[14]</ref> and the other is that of Luisada and Zalter <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>. These (high frequency) vibrations are being the object of further research in phonocardiography processing <ref type="bibr" target="#b32">[33]</ref>. Traces for different frequency bandwidth of phonocardiography sounds were shown in Fig. <ref type="figure" target="#fig_62">2</ref>.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">BAND-PASS FILTER VERSUS HIGH-PASS FILTER</head><p>It has been known for a long time that (linear) cardiac transducers are inadequate for recording the vibrations of the chest wall which have the greatest clinical significance, i.e., the mediumfrequency components between 100 and 300 Hz. This is because these vibrations are overshadowed by the much larger amplitude of the low-frequency components, which are simultaneously picked up by the transducer. Three methods have been developed for the study of these medium frequency components, and even more for those of high frequency:</p><p>• The use of an equalizer (microphone buffering module);</p><p>• The use of a high pass filters HPF-module;</p><p>• The use of a band pass filters LPF-module <ref type="foot" target="#foot_1">2</ref> .</p><p>Equalizers have been preferred by certain companies because of economic considerations. Their use permits to obtain an overall picture of the vibratory spectrum. However, the use of an equalizer is equivalent to the application of a fixed high-pass filter with inadequate slope and does not lend itself to the scanning of the spectrum and study of the best frequency bands. Equalizers are being used in the apparatus of the Cardionics Company and Littmann Company.</p><p>High-pass filters have been preferred by Swedish, British, and German companies. Their use is based on the principle that, in these filters, the vibrations below the cut-off frequency are attenuated by the device while those above the cut-off frequency are attenuated by the normal (physical and physiological) slope of attenuation. Thus, a triangular curve is obtained.</p><p>A band-pass filter is a combination of a high-pass with a low-pass filter. Its use is preferred since the sharper attenuation of the high vibrations contributes to the clarity of the baseline by excluding extrinsic vibrations generated in either the room, the patient, or the apparatus.</p><p>Amplification is the degree of amplification necessary for obtaining a significant tracing obviously increases from the low bands to the high bands. Certain apparatus (like the Elema ® ) have a preset degree of amplification, which automatically increases by a certain ratio when a higher band of frequency is selected. In addition, some modern E-stethoscope system like (Cardionics ® ) which is illustrated in Fig. <ref type="figure" target="#fig_62">2</ref>.8, have equipped filtered the PCG trace in different frequency-bands. This ratio is based on the physical decrease of amplitude of higher frequencies, i.e., on a slope of 10 db/octave. Actually, the degree of amplification which is needed varies from case to case, and at times there is need of greater amplification for a certain band. In recent studies, which based on the use of a calibrated linear phonocardiograph, the use of one galvanometer only, and the observation of the degree of amplification needed in order to record the heart sounds with the same magnitude in the various bands.</p><p>This study was accomplished in several individuals, either normal or with cardiac murmurs, and in normal, large dogs. Surprisingly, it was ascertained that the amplification needed was between -4 and -8 db per octave, a range which is definitely below that of the physical decrement of vibrations (-12 db/octave so-called law of the square) and below any theoretical anticipation.</p><p>This can be explained in the following way.The heart generates vibrations of different frequencies and magnitudes. When traced phonocardiography in the various frequency bands was recorded, vibrations of the same magnitude was obtained. It is apparent that certain vibrations of medium high frequency are generated with a greater magnitude than anticipated by a purely physical law. This problem is further complicated by the transmission through the mediastinum and lungs and by the resonance of the chest wall. Further systematic and pilot-study should be performed for different phonocardiography frequency bandwidths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">PHONOCARDIOGRAPHY CALIBRATION</head><p>This calibration is based on the absolute linearity of the various components of a system. It was described by Mannheimer <ref type="bibr" target="#b30">[31]</ref> and in 1939, it was revived by <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>. In their apparatus, amplification is measured in decibels, and similar tracings can be taken with identical amplification for the same frequency band. At present, three methods can be used for studying selected bands of frequencies:</p><p>(a) Use of high-pass or band-pass filters for recording and comparing simultaneous (multichannel phone) or subsequent (single channel phone) tracings of heart sounds and murmurs in various adjoining octave bands. This is the most commonly used method and was pioneered by <ref type="bibr" target="#b30">[31]</ref>.</p><p>(b) Use of a variable band-pass filter; setting of both high-and low-pass filters at the same time; and subsequent records in that extremely narrow band which is allowed to pass in such technical conditions. This method was advocated by <ref type="bibr" target="#b28">[29]</ref>.</p><p>(c) Use of a spectral analyzer, as advocated by <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref>. This is based on a device originally developed by Fletcher for the study of speech frequencies and intensities.</p><p>Apparent splitting of 1st and 2nd heart sound in both phono-tracings was done in which stethoscopict tracing reveals a few slow vibrations in presystole; a complex first sound and a complex second sound.</p><p>In the recent medical auscultation instrumentation, the calibration procedure was made in automated steps to reduce the time and cost for a reliable and precise cardiac acoustic measurements. One of the modern automated calibrated device from (Cardionics, Inc. USA) with its stethoscope digital simulator system, as illustrated in Fig. <ref type="figure" target="#fig_62">2</ref>.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">INVESTIGATION OF NORMAL CARDIAC CYCLE IN MULTI-FREQUENCY BAND</head><p>The various phases of the cardiac cycle can be identified by means of an electrocardiogram plus simultaneous tracings of right or left atrial, right ventricular, and left ventricular pressures. This can be easily done in animals by venous and arterial catheterization. Other tracings of the vibrations of the chest wall can be recorded at the same time in the low, medium, or high frequency bands. The data obtained in this way can be compared with those obtained during clinical catheterization and with clinical tracings, where an electrocardiogram and an aortic pulse tracing is compared with phonocardiogram in various frequency bands.</p><p>The various phases of the cardiac cycle, identified by <ref type="bibr" target="#b32">[33]</ref> and, more recently, by <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b35">36]</ref>, will be re-examined on the basis of the clinical data supplied by the various types of phonocardiogram modules.</p><p>Presystole. The ultra-low frequency tracing (linear) reveals a diphase wave (negative positive) at the apex and either a positive or a diphasic wave (positive-negative) at the epigastrium. According to other investigators the first phase was caused by right atrial activity and the second by left atrial activity <ref type="bibr" target="#b29">[30]</ref>. In Fig. <ref type="figure" target="#fig_62">2</ref>.10 (A) tracings in a normal young man of 17 was recorded, from above: Electrocardiogram, Phono (Stethoscope) at 3rd left inter-space, Phono (range 60-120) same area, Phono (range 480-1000)-same area, Plamno (range 1000-2000)-same area. Tracings 1 and 2 are simultaneous; the others have been exactly superimposed. (B) and (C) tracings recorded over the 2 nd left interspace in a man with pulmonary hypertension case. The lower tracing (240/480) reveals that the pulmonary component is larger than the aortic. (C) The lower tracing (750/1000) reveals that the pulmonary component has the same amplitude as the aortic. In both cases, the atrial contraction would be transmitted, first to the respective ventricle and then to the chest or abdominal walls. The end of the second phase occurs prior to the Q wave of the ECG. The low-frequency tracing (5-25 acceleration) reveals three waves of atrial origin during the P-Q interval of the ECG according to <ref type="bibr" target="#b27">[28]</ref>, and one diphasic or triphasic wave according to <ref type="bibr" target="#b29">[30]</ref>.</p><p>The phonocardiogram in the medium frequency range (30-60 Hz) reveals a diphasic or triphasic slow wave <ref type="bibr" target="#b36">[37]</ref>. Occasionally, three or four small vibrations can be recorded. It has been stated that this wave may fuse with the first sound and even occur alter the Q wave of the ECG <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b36">37]</ref>. However, this is still open to question because the first sound itself starts with a slow vibration which is present even in cases of atrial fibrillation <ref type="bibr" target="#b35">[36]</ref>. A possible exception is represented by children or adolescents with a short P-R interval. Ventricular Systole. The ventricular systole was divided long ago into isometric tension period (ITP) and isotonic ejection period (IEP) <ref type="bibr" target="#b33">[34]</ref>. More recently, several further divisions were made, so that now the following research work are admitted <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>• Electro-presser latent period, from Q to the initial slow rise of (left) intra-ventricular pressure.</p><p>• Mechano-acoustic interval, from the initial rise of (left) intra-ventricular pressure(IVP) to the closure of the mitral valve and the beginning of the rapid rise of pressure in the ventricles. This phase is terminated by the first group of rapid vibrations of the first sound and was called entrant phase by <ref type="bibr" target="#b36">[37]</ref>.</p><p>• Phase of rapid rise of pressure, from the closure of the mitral valve to the opening of the aortic valve and, in the phonocardiogram, from the first to the second main group of vibrations of the first sound S-1 <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b44">45]</ref>.</p><p>The phase of expulsion or ejection was divided by <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> into maximal ejection, lasting until the top of the aortic pressure curve, and reduced ejection, from this point to the incisura of the aortic pulse; it is followed by relaxation of the ventricles during the phase of protodiastole.</p><p>The ultra-low frequency tracing (linear) with the pickup applied to the apex <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b46">47]</ref>; Kinetocardiogram <ref type="bibr" target="#b48">[49]</ref> often reveals two distinct waves, one during the entrant phase (or mechano-acoustic interval), and another during the phase of rapid rise (actual isometric phase). The phase of ejection is typically revealed by a (systolic collapse), caused by the reduced volume of the ventricular mass, unless motion of the apex maintains contact of the cardiac wall with the chest wall and causes a systolic plateau. End of systole is marked by a positive wave or notch <ref type="bibr" target="#b46">[47]</ref>.</p><p>The low-frequency acceleration tracings <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref> show a complex ABC during the RS complex of the ECG. This coincides with the first slow vibration of the first sound and the slow rise of pressure in the ventricles (mechano-acoustic interval). A second complex CDE occurs during the S wave and the ST junction; it coincides with the first group of large vibrations of the first sound. A third complex EFG occurs during the upstroke of the carotid tracing and coincides with the second main group of vibrations of the first sound. Afterward, there is a GHI complex which coincides with the rise of the T-wave and the carotid shoulder, and an IJK complex at the peal of T, which ends with the initial vibrations of the second sound. To amplify the gain response of this PCG low frequency band by using digital infinite impulse (IIR) low-pass filter with 6th order to attenuate high-frequency component in PCG trace. Fig. <ref type="figure" target="#fig_62">2</ref>.11 represents the IIR-LPF (low-pass filtering) response of two PCG signal trace. This response indicating the robustness of combining LPF-filtering for synchronous acquisition of two PCG trace.</p><p>The phonocardiogram in the medium-low range (60-120 Hz) shows a small initial vibration of extremely low frequency and magnitude during the mechano-acoustic interval. It then shows a central phase of four large diphasic vibrations <ref type="bibr">(Luisada,</ref><ref type="bibr" target="#b34">[35]</ref>), which can often be divided in two main groups coinciding with the valvular events of the heart <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref>; these are separated in the adult by an interval of 0.04-0.05 sec. It has been shown that the peaks of these large vibrations may be identified through right and left heart catheterization, and can be shown to coincide with the four valvular events <ref type="bibr" target="#b43">[44]</ref>.</p><p>These, as known, succeed each other in the following sequence: Mitral closure, tricuspid closure, pulmonary opening, aortic opening <ref type="bibr" target="#b35">[36]</ref>. For this reason, the symbols M, T, P, A, referring to the four valves, were suggested for the main four vibrations, if they can be identified <ref type="bibr" target="#b42">[43]</ref>.</p><p>It is unfortunate that not in all persons such a clear cut distinction can be made and that additional, smaller waves damaged at times this desirable clear cut picture. It is obvious that, if both valvular closures and valvular openings are accompanied by vibrations, the interpretation of the mechanism of production of the first heart tone (or sound) will require a revision. Subsequent to the opening of the aortic valve, the medium-low frequency tracing often presents from one to three vibrations in decrescendo which seem connected with the early phase of ejection and which usually terminate with the peak of the aortic pulse. They have been explained with vibrations of the aortic and pulmonary walls. The second half of systole is usually clear of vibrations, but there may be one or two small vibrations during mid-systole.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medium-high frequency vibrations bands [120-240 Hz and 240-480 Hz].</head><p>In these bands (or only in the latter), a fairly good unitary pattern occurs, as shown by <ref type="bibr" target="#b43">[44]</ref>.The first heart tone often becomes split into two phases, separated by an interval of 0.04-0.05 sec; or there are two larger vibrations within a series of 3-5 smaller ones. There is no discussion about explaining the first larger vibration of normal subjects with the mitral closure, in regard to the second, which Leatham <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref> explained as due to tricuspid closure; on the contrary, explanation of the opening of the aortic valve <ref type="bibr" target="#b32">[33]</ref> was performed. This interpretation is based on the following facts:</p><p>(1) The initiation of activation of the left ventricle normally precedes that of the right by a very small interval. A mechanical precession of the left ventricular contraction was already proved in dogs, by Hamilton and confirmed by <ref type="bibr" target="#b35">[36]</ref>, and was ascertained in man by <ref type="bibr" target="#b37">[38]</ref>. This precession is only 13 msec, and has individual variations of not more than 4 msec. In other words, the synchronization between the starting of contraction of the two ventricles is practically not more than 17 msec and may be only 9 msec.</p><p>There may be respiratory variations; this interval is further decreased by the fact that the methane-acoustic interval of the left ventricle is longer than that of the right: closure of the mitral valve is slightly delayed by higher pressure in the left atrium.</p><p>Therefore, it is impossible to explain two groups of sound vibrations usually separated by 0.04-0.05 sec. with two mechanical events which are separated by only 0.01-0.015.</p><p>(2) The interval between mitral closure and aortic opening (left ventricular isometric tension period) was evaluated in the dog by Whoor's as of the order of 0.05 sec interval. and Braunwald et al. for man with a 0.06 sec interval, which is practically identical with that found between the two above groups of vibrations.</p><p>(3) The interval between the first and the second large vibration does not vary when right ventricular contraction is experimentally delayed, and may even increase when the latter is not delayed. It is obvious that a delay of right ventricular contraction should increase the interval between the large vibrations if the second group of vibrations were due to tricuspid closure.</p><p>(4) In cases of mitral stenosis and atrial fibrillation, it is accepted that mitral closure is delayed and is either simultaneous with or follows tricuspid closure. Short diastole would theoretically further delays mitral closure on account of higher left atrial pressure. However, in these circumstances, one may find a split first sound with an interval of 0.05-0.06 sec between the signal components.</p><p>If the second was (mitral), the interval of (0.15 sec) between Q of the ECG and this sound, which was found, would be far too long to be accepted.</p><p>(5) The second large vibration coincides with the rise in pressure of the aorta and may coincide with or slightly below that of the pulmonary artery. The precession of this sound over aortic rise of pressure, may have been due to incorrect interpretation of that small rise of pressure in the aorta, which occurs during isometric contraction <ref type="bibr" target="#b38">[39]</ref>.</p><p>This leads to discussion of the so-called ejection sound (so named by Leathiam). Such a sound is a new phenomenon which arises in cases of stenosis of the aorta or phonic valve or in cases with dilatation of the aorta or pulmonary artery and allows the opening of the semilunar valves.</p><p>On the contrary, McMontry since 1953 <ref type="bibr" target="#b32">[33]</ref> concluded that such a sound represents, in the majority of cases, an accentuation and delay of the second group of vibrations of the first sound, possibly related to an abnormal gradient of pressure across the valve or disturbed flow in the vessel.</p><p>(In particular, it represents the accentuation of either (P) or (A) according to whether the pulmonary valve or artery is involved, or the aortic valve or aorta.) Lie et al. <ref type="bibr" target="#b38">[39]</ref> also admitted that, in certain cases with dilatation of one of the large arteries, a slower vibration occurs during the early phase of ejection (ascending 1) ranch of the pulse). This contention is proved by the following facts:</p><p>1. It is not clear in previous research the ability to demonstrate three groups of high-pitched vibrations (mitral closure, tricuspid closure, ejection sound) over the same part.</p><p>2. Catheterization of either pulmonary artery or the aorta shows the rise of pressure coinciding with and not following the so-called ejection sound <ref type="bibr" target="#b40">[41]</ref>. Studying this large sound in cases of congenital heart disease confirmed that it represents a pathological accentuation (and occasionally a delay) of a normal component of the first tone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">HIGH-FREQUENCY VIBRATIONS BANDS [500-1000 HZ AND 1000-2000 HZ]</head><p>These can be recorded only through great amplification (60-100 dB) and only in young individuals with a thin or flat thorax wall. The highest band, particularly, is only exceptionally recorded. On the other hand, an intermediate band (750-1500) can be studied in a greater number of individuals. At or within the apex, and sometimes also in the 3rd left interspace, one can obtain either one or two large vibrations. When only one is recorded, it coincides with the first larger vibration of the medium-high bands; when two are recorded, the second coincides with the second larger of such bands. Occasionally, either of the larger vibrations is accompanied by a smaller one, either before or after onset.</p><p>As in the previously described bands, the investigations explain these vibrations of high frequency and low magnitude as coinciding with the events of the left heart (mitral closure-aortic opening). It is interesting to note that occasionally a tiny vibration at mid-systole coincides with the G peak of the low-frequency tracing or occurs in late systole. It is a general rule that the vibrations of high frequency and small intensity (300 Hz and above) take place at the beginning of each sound, tone, or component. They are immediately followed by vibrations which have a lower frequency, a greater intensity, and often a longer duration.</p><p>If the tracing is recorded at the base, usually the aortic component is revealed by a large vibration while the pulmonary is revealed by either a tiny vibration or not at all. In severe pulmonary hypertension, the pulmonary component is often larger than the aortic and may even be the only one recorded. At the midprecordium or apex usually one can record either only the vibration corresponding to mitral closure (1st tone) or this plus that of aortic closure (2-nd tone).</p><p>Diastole phase according to <ref type="bibr" target="#b36">[37]</ref>, can be divided into rapid filling and mid slow filling (or diastasis). It is interesting that newer studies <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref> have shown that the phase of rapid filling is partly aided by the elastic recoil of the ventricular walls causing a partly active diastole.</p><p>Proto-diastole Isometric Relaxation. The former phase, according to <ref type="bibr" target="#b41">[42]</ref>, lasts from the beginning to the peak of the incisura of the aortic tracing (closure of the aortic valve); the latter, from the closure of the aortic valve to the opening of the mitral valve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">ULTRA-LOW FREQUENCY TRACING (LINEAR FREQUENCY BAND)</head><p>This tracing normally presents a descending limb to the peak IIa (closure of the aortic valve) to the trough O (or IIb) which marks the lowest point of the tracing <ref type="bibr" target="#b42">[43]</ref>. This point indicates tricuspid opening, if the tracing is recorded at the epigastrium (often, in this area, there is a mirror-like pattern: low point II a, peak IIb), and mitral opening, if it is recorded at the apex <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b42">43]</ref>. In low-frequency tracing (5-25 acceleration), the end of the T-wave of the ECG and the first vibration of the 2nd heart sound are simultaneous with the K-wave of this acceleration tracing. Closure of the aortic valve is accompanied by the complex KLM, while the peak M coincides with the opening of the AV valves <ref type="bibr" target="#b43">[44]</ref>.</p><p>During this phase, the tracing rises from the lowest point (point (O) or IIb) to a high position, marking the maximum of rapid filling and coinciding with the 3 rd sound. This part of the tracing is the most commonly reproducible and, therefore, the most useful for identifying a 3 rd sound <ref type="bibr" target="#b38">[39]</ref>.</p><p>The peak usually coincides with the 3 rd heart sound and the maximal of the phase of rapid filling. The OP complex occurs during the phase of diastasis, if this phase is not abbreviated by tachycardia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.5">MEDIUM-LOW FREQUENCY TRACING [60-120 HZ]</head><p>This tracing usually reveals the complex of the second heart tone with two-to-four large vibrations. Frequently, two larger components can be recognized within the central part of this tone (aortic and pulmonary closures) <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b41">42]</ref>. The opening of the mitral valve is not revealed by this tracing in normal subjects. Pavlopoulos et al thought that, in race normal cases, a small vibration of lower frequency occurred at the time of mitral opening <ref type="bibr" target="#b34">[35]</ref>. However, in retrospect, the vibration might have been a deformed picture of the pulmonary component, even though recorded at the 4 th left interspace. On the other hand, in cases of mitral stenosis, this vibration is well recorded (opening snap).</p><p>In this phase, a small vibration may occur in coincidence with tile peak of rapid filling (3 rd sound). It may be much larger in cases with increased pressure of the atria (triple rhythms or gallops) and it may be split <ref type="bibr" target="#b44">[45]</ref>, thus simulating the occurrence of a 5 th sound <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.6">MEDIUM-HIGH FREQUENCY BAND [120-240 HZ AND 240-480 HZ]</head><p>In these bands, two large vibrations emerge within the 2nd heart tone. There is no discussion among the various researchers in the identification of the first with the closure of the aortic valve, and the second with that of the pulmonary valve. The best place for recording both of them is the 3rd left interspace. Usually only the first of them (aortic component) is transmitted to the 2nd right interspace and toward the apex while the second (pulmonary component) may do so in cases of pulmonary hypertension.</p><p>A delay in the pulmonary component occurs in pulmonary hypertension, pulmonary stenosis, and right bundle branch block. A delay in the aortic component, on the other hand, occurs in aortic stenos is or left bundle branch block. The mitral opening snap is recorded best in these bands. It is often of small amplitude and high pitch.</p><p>In normal subjects, no vibrations are recorded. In cases with pathological triple rhythms, the 3 rd sound is usually best recorded in the band 120-240 but, in certain cases, is well recorded above 500 and may reach even higher frequencies. This points out the difficulty of an absolute differentiation between a (gallop) sound and an (opening snap) of the mitral valve on the basis of frequency alone.</p><p>The opening snap, usually of a higher pitch than the (gallop), is best shown in the bands 120-240 or 240-480 (occasionally even higher), and is still recorded as a small twitch above 750 and even above 1000. Therefore, even though the opening snap is higher pitched than the (gallop) sound, there is an overlapping of the bands in which they are recorded best, and other elements have to be taken into consideration for the differential diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.7">THE HEART TONES PRODUCTION MECHANISM</head><p>Numerous studies have been devoted to this problem, and in particular to the mechanism of the first heart tone. We shall quote here only those from our group <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36]</ref>, which discuss previous experimental work by others and contribute to clarification of this problem. According to recent interpretations <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31]</ref>, the vibrations of the heart tones are due to the rapid changes in the pressure of the blood (and of the cardiac walls surrounding it) whenever a rapid acceleration or deceleration occurs in coincidence with, but not caused by, the valvular movements.</p><p>Aortic valve opening, for example, will cause a sudden acceleration of the left ventricular blood, which is being ejected, plus a ram effect of this blood against the static blood contained in the aorta. In an elastic chamber filled with fluid, any sudden motion throws the entire system into vibration, the momentum of the fluid causing an overstretch of the elastic walls, followed by a recoil and a displacement of fluid in the opposite direction. The intensity of a sound seems to be proportional to the rate of change of the velocity of the blood while its frequency seems to be connected with the relationship between vibrating mass and elasticity of the walls. Studies of the heart tones made in the different frequency bands have shown <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b42">43]</ref> that all four valvular events involved in the first tone are revealed by a medium-low frequency band (60-120 Hz).</p><p>On the contrary, the higher bands, and especially that between 500 and 1000, usually reveal the events of the left heart: a vibration due to mitral closure is best recorded in the 3rd-4th interspaced (1 st tone); a vibration due to aortic closure is best recorded at the base (2 nd tone). Pulmonary closure (2 nd tone) is revealed in this band as a small vibration, except in cases of severe pulmonary hypertension.</p><p>The 3 rd and 4 th tones are usually best revealed by the ultra-low and low-frequency bands (apex cardiogram or (kinetocardiogram); low-frequency acceleration tracing in the 5-25 band; displacement tracing in the 15-30 band). It is interesting to note that the high-frequency tracing may occasionally reveal a tiny vibration in systole which corresponds to the H wave of the low-frequency tracing. This indicates the existence of a small, high-pitched overtone coincides with the peak of the aortic pulse.</p><p>The 3 rd and 4 th tone have been the object of numerous studies. The opinion which seems to gather the best experimental and clinical support is that they are caused by the onrush of blood into the ventricles during the two phases of accelerated filling in early diastole and presystole. As such, they seem to be generated in the ventricular walls, and intracardiac phonocardiogram confirms this point of view. Earlier vibrations recorded by the esophageal method may be more closely connected with the atrial contraction (4 th tone). Speculations dealing with a valvular origin of these tones are periodically presented, in regard to the 3 rd tone, they do not seem to be acceptable. In regard to the 4 th <ref type="bibr" target="#b36">[37]</ref>, it is likely that two separate components, one valvular and one myocardial, occasionally take place. It is still open for discussion, however, whether the valvular component is recorded in cases other than complete AV-block pathology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">STETHOSCOPE TRANSDUCER MODELING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">MICROPHONE TRANSDUCER</head><p>There are different types of microphones are suitable for picking up air-coupled body sounds from the skin. These include the following entitites:</p><p>• Capacitor microphones, where the induced vibration of a metalized mylar film (forming one plate of a capacitor) changes the capacitance between it and a fixed plate, inducing a change in the capacitor voltage under conditions of constant charge.</p><p>• Crystal or piezoelectric microphones, in which air-coupled sound pressure vibrates a piezocrystal, directly generating a voltage proportional to (dp/dt), where p is the sound pressure at the microphone.</p><p>• Electret microphones are variable capacitor sensors in which one plate has a permanent electrostatic charge on it, while the moving plate varies the capacitance, inducing a voltage which is amplified. Electret microphones are small in size, and found in hearing aids, tape recorders, computers, etc.</p><p>Microphones generally have a high-frequency response that is quite adequate for endogenous body sounds. It is their low-frequency response that can be lacking. Indeed, some heart sounds are subsonic, ranging from 0.1-20 Hz (Webster, 1992), while 0.1-10 Hz is generally inaudible, and sound with energy from 10 to 20 Hz can be sensed as subsonic pressure by some listeners.</p><p>To record body sounds, a pair of B&amp;K model 4117 piezoelectric microphones was modified to cover down to &lt; 1 Hz by inserting a fine, stainless steel wire into the pressure relief hole that vents the space in back of the piezo-bender element. The wire increased the acoustic impedance of the vent hole and thus increased the low-frequency time constant τ of the microphone from about 0.05 sec (corresponding to a -3dB frequency of c.a. 3 Hz) to &lt; 0.15 seconds, giving a -3dB frequency &lt; 1 Hz.</p><p>The high (-3dB) frequency of the 4117 microphones was 10 kHz. The voltage sensitivity of the M4117 microphone at mid-frequencies range is about 3 mV/Pa (3 mV/10 mbar). Typical cardiac 3D microphone internal structure was shown as in Fig. <ref type="figure" target="#fig_62">2</ref>.12, where it consist of four main components; (1) external crystal (piezoelectric); (2) ground-cage, (3) oscillating drum, and (4) excitation source. Another high-quality B&amp;K microphone of the model 4135 quarter-inch condenser microphone was used. This research-grade device had a high-frequency, 3dB frequency in excess of 100 kHz and a total capacitance of 6.4 pF with a diaphragm-to-plate spacing of 18 μm. For body sounds, the low-frequency end of the 4135's frequency response is of interest. Three factors affect the 4135 microphone's frequency response:</p><p>1. The acoustic time constant formed by the acoustic capacitance (due to the volume between the moving (front) diaphragm and the insulator supporting the fixed plate), and the acoustic resistance of the small pressure equalization tube venting this volume. As in the case described before, the acoustic resistance can be increased by inserting a fine wire into the tube; this raises the acoustic time constant, and lowers the low -3dB frequency.</p><p>2. The low -3dB frequency is affected by the electrical time constant of the parallel RC circuit shunting the microphone capacitance as illustrated in Fig. <ref type="figure" target="#fig_62">2</ref>.13.</p><p>3. The mechanical resonance frequency of the vibrating membrane and its mass generally set the high-frequency end of the microphone's response. The smaller and thinner the diaphragm, the higher will be its upper -3dB frequency. The capacitance change of a microphone over time can be expressed as in the following equation, where C 0 : the output capacitance of the microphone, δC: change of microphone capacitance, and ω: microphone cage natural frequency of oscillation.</p><formula xml:id="formula_0">C(t) = C 0 + δCsin(ωt). (2.1)</formula><p>This expression for C(t) is substituted in the voltage equivalent microphone equation, and the resulting equation is differentiated with respect to time. This results in a first-order nonlinear ordinary differential equation (ODE) in the loop current, i(t), which is solved to yield a frequency response function, which can be written as follows:</p><formula xml:id="formula_1">i(t) = V s δC/C 0 √ [R 2 s +1/(ωC 0 )] sin(ωt + φ 1 ) - V s R s δC/C 2 0 √ [R 2 s +1/(ωC 0 )] sin(2ωt + φ 1 + φ 2 ) + Higher-order harmonics,<label>(2.2)</label></formula><p>where V s is the microphone DC excitation voltage and R s is the source impedance. Note that</p><formula xml:id="formula_2">φ 1 = tan -1 [1/(ωR s C 0 ] and φ 2 = tan -1 [1/(ω2.R s C 0 ].</formula><p>When δC 0 /C &lt;&lt; 1, the fundamental frequency term dominates, and the ac small-signal output of the microphone (superimposed on the dc voltage, V s , can be written as a frequency response function:</p><formula xml:id="formula_3">V * δC (j ω) = V s R s ω 1 + (ωC 0 R s ) 2 . (2.3)</formula><p>Olson et al. <ref type="bibr" target="#b14">[15]</ref> points out that this is the same result obtained if placing an open-circuit (Thevenin) voltage of V oc = V s (δ/C 0 sin(ωt + φ 1 )) in series with C 0 and R s in the loop, and observe v o (t) across R s . From Equ. 2.3, we see that the low corner frequency is f Lo =1/(2π R s C 0 )Hz. For example, if C 0 =7 pF, and R s =10 ohms, then f Lo =2.3 Hz. The equivalent electrical circuit of the cardiac microphone is illustrated in Fig. <ref type="figure" target="#fig_62">2</ref>.14.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">ACOUSTIC COUPLING</head><p>No matter which kind of sensor is used to detect endogenous sounds waveform over the patient skin, there is a problem in efficiently coupling the sound mechanical vibrations from within the body to the microphone (or the eardrum). Since the days of Laennec and his first stethoscope, a bell-shaped or conical interface has been used to effectively couple a relatively large area of low-amplitude acoustic vibrations on the skin to a small area of larger amplitude vibrations in the ear tube(s). This bell-shaped interface is in fact an inverse horn (at that time, literally cow horns), which were used pre 20th century as hearing aids. Note that the pinna of the human ear is an effective inverse horn, matching the low acoustical impedance of open space to the higher impedance of the ear canal and eardrum. Like all horns, the pinna exhibits combfilter properties, attenuating certain high frequencies in narrow bands around 8 and 13 kHz <ref type="bibr" target="#b36">[37]</ref>. Regular horns were first used as speaking trumpets, later as output devices for early mechanical record-players; here the lateral displacement of the needle on the disk vibrated a mica diaphragm (c. 2 in. in diameter). A horn was used to couple those vibrations to a room and listeners. Most acoustics textbooks describe horns in the role of coupling sound from a small-diameter, vibrating piston to a large-diameter opening into free space (the room).</p><p>In examining endogenous body sounds, the opposite events occur. A large area of smallamplitude acoustic vibrations on the skin is transformed by the inverse horn to a small area of large-amplitude vibrations (at the eardrum or microphone). It is beyond the scope of this section to mathematically analyze the acoustics of direct and inverse horns. However, we will examine them heuristically. Basically, horns and inverse horns are acoustic impedance-matching systems. They attempt to couple the acoustic radiation impedance of the source to the acoustic impedance of the horn termination.The termination in the case of a stethoscope is the rather complex input impedance of the coupling tubes (or tube, in Laennec's instrument); in the case of a microphone, it is the moving diaphragm. If impedances are not matched, sound transmission will not be efficient, because there will be reflections at interfaces between any two media with different acoustic impedance characteristic; e.g., at the skin-air interface, and at the air-microphone interface. The characteristic acoustic impedance of a medium is a real number defined simply by <ref type="bibr" target="#b36">[37]</ref>:</p><formula xml:id="formula_4">Z ch = ρ(c)cgs.ohms.(ML 2 T 1 ).</formula><p>(2.4)</p><p>For air, the density, ρ, is a function of atmospheric pressure, temperature, and relative humidity. The velocity of sound, c, in air is not only a function of atmospheric pressure, temperature, and relative humidity, but also of frequency. Thus, the Z ch of air can vary over a broad range, varying from c. 40-48 cgs ohms (43 is often taken as a compromise or typical value). An average Z ch for body tissues (skin, muscle, fat, connective tissue, organs, blood) is c. 2x10 5 cgs ohms. Thus, we see that there is an enormous impedance mismatch in sound going from the body to air, and much intensity is reflected back internally. Clearly, there will be better sound transmission through the skin when the skin sees a much larger acoustical impedance looking into the throat of the inverse horn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">SUMMARY</head><p>The summary of this chapter is as follows: Different PCG signal bandwidth was illustrated and the PCG filtering concepts, calibration, and system approach have been considered. Cardiac microphone and stethoscope system with PCG-signal acquisition calibration were explained in response to activeinput signal scheme.The modeling of cardiac microphone as equivalent circuit was also demonstrated with a listing of main types of microphone and it's application in auscultation strategy.The impedance circuit for the acoustic signal propagation inside thorax cavity.</p><p>C H A P T E R 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PCG Signal Processing Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PHONOCARDIOGRAPHY SIGNAL PRESENTATION</head><p>Phonocardiography (PCG) is a useful technique for registering heart sounds and murmurs. It was developed in the early days to overcome the deficiencies of the acoustical stethoscope properties.</p><p>A phonocardiogram, which is the graphic representation of the heart sounds and murmurs, can document the timings and annotates the different relative intensities of heart sounds and murmurs.</p><p>Cardiologists can then evaluate a phonocardiogram based on the changes in the wave shape i.e., morphology) and the timing parameters (temporal characteristics). A number of other heartrelated variables may also be recorded simultaneously with the phonocardiogram, including the ECG, carotid arterial pulse, jugular venous pulse, and apex cardiogram. Such information allows clinicians to evaluate the heart sounds of a patient with respect to the electrical and mechanical events of the cardiac cycle.</p><p>Although phonocardiography can record and store auscultatory findings accurately, its usage as a diagnostic tool is quite uncommon because of the required critical procedures and complicated instrumentation. A standard procedure to record the phonocardiograms requires a specially designed, acoustically quiet room <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. In terms of equipment, because phonocardiographic devices were introduced before compact analog integrated circuits were available, they are typically large, noisy, and inconvenient to use. With the introduction of the electronic stethoscope, phonocardiography may possibly make a comeback in clinical practice.</p><p>The newly developed electronic stethoscopes are more compact, robust to noise, immune to disturbance, and much more convenient for diagnostic use. They permit a digital recording of heart sounds, and therefore allow clinicians to perform analysis of the phonocardiogram on a PC platform.The phonocardiogram may have even greater diagnostic importance in the future as further improvements are made in the electronic measurement technology and signal processing algorithms.</p><p>These algorithms can help to represent the heart sound as a set of characteristic signal components, which may form the detection basis of various heart diseases. Much of the research effort has been devoted to the exploration of signal processing methods with reduced sensitivity to the recorded noise and improved identification of the exact start and end points of major heart sounds (i.e., S 1 , S 2 , and murmurs). In general, three ways to represent and characterize heart sound exist:</p><p>• spectrum estimation;</p><p>• time-frequency analysis;</p><p>• nonlinear analysis.</p><p>The most popular method to represent heart sound components in the past was spectrum estimation. A variety of techniques have been developed to analyze the frequency contents of heart sound. Earlier studies used spectral estimation techniques to extract features in the frequency domain <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref>. Classical methods for power spectral density (PSD) estimation employ various windowing and averaging functions to improve the statistical stability of the spectrum obtained by Fast Fourier Transform (FFT) (.g., the Welch periodogram method).</p><p>Early researches have demonstrated some success in distinguishing normal from abnormal patients based on the average power spectrum of diastolic heart sounds, estimated by traditional FFT methods <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref>. Despite the success, classical methods may not provide an accurate power spectrum when the signal-to-noise ratio (SNR) is low and the length of the desired signal is short <ref type="bibr" target="#b44">[45]</ref>. An alternative spectral estimation technique is the parametric modeling method (e.g., autoregressive (AR), moving average (MA), and autoregressive moving average (ARMA)). Parametric modeling involves choosing an appropriate model for the signal and estimating the model parameters. These parameters can then be used to characterize the power spectrum of the signal, to classify the signal, or to perform data compression and pattern recognition tasks.</p><p>Among these modeling techniques, AR modeling shows outstanding performance when the signal has very sharp peaks. The ARMA model can be used to model signals with sharp frequency peaks and valleys. The studies have shown that the application of parametric modeling methods to signal identification can provide a good estimation of spectral features, particularly for a signal with low SNR, which led to the use of model-based methods in the analysis of heart sounds and the detection of features associated with coronary artery diseases <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b51">52]</ref>.</p><p>Another class of spectral estimation techniques is nonparametric Eigen-analysis based method, which is based on Eigen decomposition of the data or its autocorrelation matrix. The eigenvector method (or the minimum-norm method) can be used to extract the signal buried in noise. These methods should be extended in the next chapters with a deepening in spectral estimation approach.</p><p>In theory, the eigenvector method has infinite resolution and provides an accurate spectral estimation regardless of the SNR. In relevant studies of acoustical detection of coronary artery disease by Akay et al., the eigenvector method has demonstrated the best diagnostic performance when compared with the other spectral estimation methods like FFT, AR, and ARMA <ref type="bibr" target="#b50">[51]</ref>. In general, the parametric spectral estimators (AR and ARMA) and the eigenvector methods offer the promise of higher resolution over the FFT. However, the major shortcomings of AR, ARMA, and eigenvector methods are that in each case poor spectral estimation occurs if the assumed model is inappropriate or if the model orders chosen are incorrect <ref type="bibr" target="#b49">[50]</ref>.</p><p>Early methods of frequency domain analysis were mostly based on the direct applications of Fourier transform or autoregressive spectral estimation techniques. However, if the statistical properties of the signal change with time (i.e., non stationary), the direct application of these techniques may be inappropriate as important time events like frequency variation would be lost in the trans-formation process. As heart sounds are non stationary in nature, more recent research adopts the time-frequency analysis in order to capture the temporal variation in the heart sound signal <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DENOISING AND SIGNAL FILTERING TECHNIQUES</head><p>One of the major problems with recording heart sounds is noise parasitic effects. In practice, the noise source may be composed of instrumentation noise, ambient noise, respiratory noise, thoracic muscular noise, peristaltic intestine noise, and fetal breath sounds if the subject is pregnant.</p><p>The contribution of each source may vary significantly depending on the technical characteristics of the recording instrumentation, sensor detection bandwidth, the recording environment, and the physiological status of the subject. Currently, no way exists of knowing a priori what the particular noise component is, or determining the noise component once measurements have been made.</p><p>A reasonable solution to noise reduction can be carried out in two parts. First, extraneous noises must be minimized in the vicinity of the patient during recording. Second, various signal processing methods, such as notch filtering <ref type="bibr" target="#b53">[54]</ref>, averaging <ref type="bibr" target="#b56">[57]</ref>, adaptive filtering <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>, and wavelet decomposition <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b60">61]</ref>, can be designed and implemented by hardware or software to remove the noise, based on the assumption that the noise is an additive white noise. Although these methods have been prove effective and robust results, more research is required to determine what kind of noise and disturbance could corrupt the recorded heart sounds so that a system could employ different denoising (filtering) techniques based on the specific noise present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">PCG SIGNAL PRESENTATION</head><p>Physical modeling aims at the localization of a specific sound source in the heart and, by analyzing the externally recorded vibration signals, at the quantification of the constitutive properties of the cardiac structures involved (e.g., stiffness of a valve leaflet, myocardial contractility) and of the driving forces, which set these structures into vibration.</p><p>The physical situation is extremely complicated. The vibration source is situated within the cardiac structures (having viscoelastic properties) containing and driving blood (a viscous fluid). The transmission medium, (the tissues between the heart and the chest wall) is viscoelastic and inhomogeneous. Transmission in such a viscoelastic medium implies compression and shear waves, which both contribute to the vibrations at the chest wall <ref type="bibr" target="#b59">[60]</ref>. It is not simply a problem of acoustic pressure as in a perfect fluid. Distortion due to transmission seems obvious.</p><p>In order to study transmission and to relate chest wall vibrations to properties of cardiac structures and hemodynamic variables, advanced signal processing techniques are used. A broad review is given by Durand et al. <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b59">60]</ref>. As the chest wall vibratory phenomenon is represented by a spatiotemporal kinematic function, it can principally be approached in two ways: by sampling in time, as a set of images of chest wall movement, or by sampling in space by a set of time signals obtained with multisite recording. Multi-site heart sound recording implies a large set of pickups (preferably light-weight, thus inducing minimal loading). In this way, spatial distribution of vibration waveforms on the chest wall can be derived. Based on the results of such a method a physical model for heart sound genesis has been presented that can analytically be solved in a viscoelastic medium: a sphere vibrating along the axis of the valve orifice <ref type="bibr" target="#b59">[60]</ref>.</p><p>This mechanical dipole model agrees to the idea of sound generation as a resonant like vibration of the closed elastic valve leaflets and the surrounding blood mass. With this model a typical inversion of vibration waveforms on the chest wall could be explained: The phase reversal is most expressed for the second sound, according to the anatomical position and direction of the aortic orifice. The model has been used to calculate source functions (the inverse problem). Spatial parameters on vibration waveforms have been formulated (22-25 mV) <ref type="bibr" target="#b60">[61]</ref>.</p><p>The phonocardiography signal processing loop was shown in Fig. <ref type="figure">1</ref>.3, in which inside the PCG kernel signal analysis there are many different processing steps occur such as preprocessing, dynamic characteristics, adaptive filtering, parametric estimation, computational intelligence, STFT temporal characteristics, simulation hemodynamics, and cardiac acoustic model estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">CARDIAC SOUND MODELING AND IDENTIFICATION</head><p>The central inspiration for model construction is to deepen the knowledge for the physical systems and gain understanding about the physical world. A mathematical model is often realized by a set of equations that review available knowledge and set up rules for how this knowledge interacts. Mathematical models can be developed in different ways: purely theoretically based on the physical relationships which are a priori known about the system, purely empirically by experiments on the already existing system, or by a sensible combination of both ways. Models obtained by the first method are often called a priori, first principle or theoretical models, while models obtained in the second way are called a posteriori or experimental (black-box) models. In case of theoretical analysis, the dynamic properties of the system are primarily taken care of by the respective balance equations. These balances are established by the laws of conservation supplemented with the necessary state-equations and phenomenological laws. Theoretical model building becomes unavoidable if experiments in the respective plant cannot or must not be carried out. If the plant to be modeled does not yet exist, theoretical modeling is the only possibility to obtain a mathematical model.</p><p>Modeling the cardiovascular system requires multivariate, multi-scale, multi-organ integration of information, making it an extremely complex task. The purpose of this section is not to delve into these details but rather to look at two simple models able to reproduce S 1 and S 2 . Neither of the models is able to explain the genesis of the heart sounds. However, they do provide adequate representations of the PCG signal, and accordingly, the models can be used to simulate heart sounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">S 1 CARDIAC SOUND MODELING</head><p>The first cardiac sound (S 1 ) model is somehow precursively approach since the underlying mechanisms of the sound are not fully understood. Based on observations from superficial chest recordings, Chen et al. <ref type="bibr" target="#b63">[64]</ref> suggested a model consisting of two valvular components with constant frequency and one myocardial component with instantaneously increasing frequency. The basic idea is that harmonic oscillations associated with atrioventricular valve closure are dampened by the acoustic transmission to the thoracic surface. The valvular components s v (t) are modeled as a set of transient deterministic signals according to equation 3.1, where N is the number of components, A i is the amplitude, and φ i is the frequency function of the ith sinusoid.</p><formula xml:id="formula_5">s v (t) = N i=1 A i (t)sin(φ i (t)) (3.1)</formula><p>The myocardial compartment, coupled with myocardial torsion tension, can be modeled with an modulated amplitude with linear chirp signal according to equation 3.2. A m (t) is the amplitude modulating wave, φm(t) is the frequency function, and s m is the myocardial component. The frequency of the signal increases during myocardial contraction and levels out as the force plateau is reached <ref type="bibr" target="#b64">[65]</ref>.</p><formula xml:id="formula_6">s m (t) = A m (t)sin(φ m (t)). (3.2)</formula><p>Since the valves close after contraction, the valvular components and the myocardial component are separated by a time delay t 0 before deriving the final S 1 model (equation 3.3). Figure <ref type="figure" target="#fig_63">3</ref>.2 shows the spectrogram of an acquired PCG signal of mitral stenosis (MS) or regurgitation case (MR).  As indicated by Bartels et al. <ref type="bibr" target="#b63">[64]</ref> and Longhini et al. <ref type="bibr" target="#b64">[65]</ref>, the resonance frequencies of Ao2 and Pl2 are proportional to the aortic pressure and the pulmonary artery pressure, respectively. This is reasonable since these pressures cause tension in the cardiac structures which affects the frequency of the vibrations. With decreasing pressure in end systole and early diastole, it is thus expected that the instantaneous frequency will decay. According to this hypothesis, A2 and P2 should be composed of short duration frequency modulated transient signals <ref type="bibr" target="#b62">[63]</ref>, giving an S 2 model consisting of two narrow-band chirp signals; see equation 3.4. A(t) and φ(t) are instantaneous amplitude and phase functions, and t 0 is the splitting interval between the onset of Ao2 and Pl2:</p><formula xml:id="formula_7">s 1 (t) = s m (t) + 0, if 0 ≤ t ≤ t 0 ; s v (t -t 0 ), t ≥ t 0 . (3.3)</formula><formula xml:id="formula_8">S 2 (t) = A A (t)sin(φ A (t)) + A P (t -t 0 )sin(φ P (t)) (3.4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">MODELING ABNORMAL HEART SOUND S 3 AND S 4</head><p>Physical modeling aims at the quantification of the constitutive properties of cardiac structures (e.g., of the valve leaflets) and the driving forces (e.g., blood pressure). For example, with respect to the second sound, the aortic valve was modeled as a circular elastic membrane, it was allowed to vibrate in interaction with the surrounding blood mass <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b65">66]</ref>. Typical characteristics of IIA and IIP (respectively, aortic and pulmonary heart sound) could thus be explained, for example, the reduction of amplitude and frequency shift (toward higher frequencies) can be referred as a consequence of the following:</p><p>• valve stiffening pathologies;</p><p>• diminishing of amplitude in patients with poor ventricular performance (characterized by a slow pressure drop in the ventricle during the isovolumic relaxation);</p><p>• augmentation of amplitude in cases of anemia (implying reduced blood viscosity and thus reduced damping in the resonant system).</p><p>In a different model, the ventricle is modeled as a finite thick-walled cylinder and the amplitude spectra of computed vibration waveforms contain information concerning the active elastic state of muscular fibers that is dependent on cardiac contractility <ref type="bibr" target="#b26">[27]</ref>.</p><p>Transmission of vibrations by comparing vibrations at the epicardial surface and at the chest wall has been studied <ref type="bibr" target="#b63">[64]</ref>. Esophageal PCG (ePCG) proved to be beneficial for recording vibrations originated at the mitral valve <ref type="bibr" target="#b65">[66]</ref>. The disappearance of the third sound with aging was explained with the ventricle modeled as a viscoelastic oscillating system with increasing mass during growth <ref type="bibr" target="#b67">[68]</ref>.</p><p>Spectral analysis of the pulmonary component of the second sound reveals information on the pressure in the pulmonary artery <ref type="bibr" target="#b68">[69]</ref>. Frequency content and timing of heart vibrations is of major importance; time-frequency analysis of signals is thus performed. Classical Fourier analysis uses harmonic signals (sine and cosine waves) as basic signals. The frequencies of the harmonics are multiples of the fundamental frequency and the signal can be composed by summing the sine and cosine waves multiplied with the Fourier coefficients. Sine waves have an infinite duration and the method is thus beneficial for periodic functions. A phonocardiogram can be considered as a periodic function, but it is composed of a number of phenomena shifted in time with specific frequency content (heart sound components and murmurs). The following MATLAB code displays the initialization and plotting PCG-parameters, in addition to noise function applied to the PCG signals as well. When applying classical Fourier analysis, information on timing is lost. Thus, Fourier analysis has to be performed on shorter time intervals (by dividing the heart cycle into subsequent small intervals) resulting in time and frequency information.  % define PCG signal coefficients and initialization parameters % p0=0.02; p1=0.52; p2=0.63; p3=1.028; % w0=p0-0.24; w1=p1-0.172; w2=p2-0.78; w3=p3-0.129; n=1024; name='gaussiannoise'; % filtered gaussian noise name='piece-regular'; % piecewise regular f=load_signal(name, n); sigma=0.03*(max(f )-min(f )); % noise level fn=f+sigma*randn(1,n); % noisy signal % plot signals subplot(2,1,1); plot(f ); axis tight; title('Original'); subplot(2,1,2); plot(fn); axis tight; title('Noisy');</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">MODEL-BASED PHONOCARDIOGRAPHY ACOUSTIC SIGNAL PROCESSING 61</head><p>To minimize errors resulting from calculating in these small intervals, mathematical techniques have to be applied to overcome the aliasing error originated from lower sampling frequency. Fig. <ref type="figure" target="#fig_63">3</ref>.4 shows the various power-spectrum content of different PCG signals in frequency domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">MODEL-BASED PHONOCARDIOGRAPHY ACOUSTIC SIGNAL PROCESSING</head><p>The detection and localization of an acoustic source has long been the motivation of early ultrasonic systems. The need for more precise phonocardiography signal processing techniques has been apparent for quite some time. It has often been contemplated that the incorporation of cardiac acoustic propagation models into signal processing schemes can offer more useful information necessary to improve overall processor performance and to achieve the desired enhancement/detection/localization even under noisy and disturbance conditions. Model-based techniques offer high expectations of performance, since a processor based on the predicted physiological phenomenology that inherently has generated the measured signal must produce a better (minimum error variance) estimate then one that does not. The uncertainty of the myocardial acoustic medium also motivates the use of stochastic models to capture the random and often non-stationary nature of the phenomena ranging from ambient noise and sever murmur conditions. Therefore, processors that do not take these effects into account are susceptible to large estimation errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">FUTURE PERSPECTIVES</head><p>The extraordinary computational power and miniature size of the microprocessors today may also permit the incorporation of analysis software into the stethoscope for heart sound analysis, or even the  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1">PACEMAKER HEART SOUND ACOUSTIC DETECTION</head><p>This approach is considered as a cutting edge technology in the field of intelligent phonocardiography clinical diagnosis module. The basic idea behind this technique was to develop and optimize the mobile auscultation system in order to integrate many of advanced concepts in PCG signal processing and pattern classification with the cardiac pacemaker system, which in proud consist of the last 40 years of PCG signal researches and investigation in this field. The first model prototype with enhanced criteria was introduced in 2005 in PalmMed Trend (Los Angeles), which is a technical symposium for recently invention in medical technology. This system composed of palmtop with windows mobile CE operating system. The PCG signal which involved in integrating cardiac acoustic with pacing therapy control loop, demonstrates robust response for DVI and VVT pacing mode of cardiac pacemaker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2">PHYSIOLOGICAL MONITORING OF BLOOD PRESSURE WITH PHONOCARDIOGRAPHY</head><p>Blood pressure is an important signal in determining the functional integrity of the cardiovascular system. Scientists and physicians have been interested in blood pressure measurement for a long time. The first blood pressure measurement is attributed to Reverend Stephen Hales, who in the early 18th century connected water-filled glass tubes in the arteries of animals and correlated their blood pressures to the height of the column of fluid in the tubes.</p><p>It was not until the early 20th century that the blood pressure measurement was introduced into clinical medicine, albeit with many limitations. Blood pressure measurement techniques are generally put into two broad classes: direct and indirect. Direct techniques of blood pressure measurement were invasive techniques, involving a catheter being inserted into the vascular system. The indirect techniques are noninvasive, with improved patient comfort and safety, but at the expense of accuracy. The accuracy gap between the invasive and the noninvasive methods, however, has been narrowing with the increasing computational power available in portable units, which can crunch elaborate signal processing algorithms in a fraction of a second. During a cardiac cycle, blood pressure goes through changes, which correspond to the contraction and relaxation of the cardiac muscle, with terminology that identifies different aspects of the cycle.</p><p>The maximum and minimum pressures over a cardiac cycle are called the systolic and diastolic pressures, respectively.The time average of the cardiac pressure over a cycle is called the mean pressure, and the difference between the systolic and diastolic pressures is called the pulse pressure. Normal blood pressure varies with age, state of health, and other individual conditions. An infant's typical blood pressure is 80/50 mmHg (10.66/6.66kPa) (systolic/diastolic). The normal blood pressure increases gradually and reaches 120/80 (15.99/10.66 kPa) for a young adult. Blood pressure is lower during sleep and during pregnancy. Many people experience higher blood pressures in the medical clinic, a phenomenon called the white coat effect.</p><p>In the traditional, manual, indirect measurement system, an occluding cuff is inflated and a stethoscope is used to listen to the sounds made by the blood flow in the arteries (Fig. <ref type="figure" target="#fig_63">3</ref>.6), called Korotokov sounds. When the cuff pressure is above the systolic pressure, blood cannot flow, and no sound is heard. When the cuff pressure is below the diastolic pressure, again, no sound is heard.</p><p>A manometer connected to the cuff is used to identify the pressures where the transition from silence to sound to silence is made. This combination of a cuff, an inflating bulb with a release valve, and a manometer is called a sphygmomanometer and the method an auscultatory technique. Usually, the cuff is placed right above the elbow, elevated to the approximate height of the heart, and the stethoscope is placed over the brachial artery. It is possible to palpate the presence of pulse under the cuff, rather than to use a stethoscope to listen to the sounds. The latter approach works especially well in noisy places where it is hard to hear the heart sounds.</p><p>The use of the PCG signal to identified blood pressure information was a newly developed method which is used recently as an alternative to direct oscillometric blood pressure method. The first adaptable technique was developed by Cornell et al. <ref type="bibr">[2004]</ref>. The wavelet decomposition system was used for separation and identification of the blood pressure and hemodynamic information from the phonocardiography traces.</p><p>This method has various sources of potential error. Most of these sources are due to misplacement of the cuff, problems with hearing soft sounds, and the using of wrong cuff size. Using a small cuff on a large size arm would result in overestimating the blood pressure, and vice versa. Nevertheless, an auscultatory measurement performed by an expert health care professional using a clinical graded sphygmomanometer is considered to be the gold standard in noninvasive measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.3">AUTOMATED BLOOD PRESSURE-PCG BASED MEASUREMENT</head><p>In the earlier measurement units, it was a combination of hardware and software that controlled the various aspects of the automated measurement (or estimation) of blood pressure. With the increasing computational power of micro-controllers units (MCU), all decision making and control are now implemented in software and with more elaborate algorithms. Here are some functions that are included in a measurement system. Refer to Fig. <ref type="figure" target="#fig_63">3</ref>.7 for a typical organization of such algorithms and application in blood pressure measurement system.</p><p>• Inflation/deflation control: Whether data collection is done during inflation or deflation, continuously or in steps, there are many challenges to appropriately control the air pump. This include maintaining a smooth baseline cuff pressure without filtering out the arterial variations; adjusting the pump speed to variations arising from different cuff sizes, arm sizes, and cuff tightness; and selecting the range of cuff pressures for which data will be collected. • Pulse detection: This is a fundamental part of extracting features from raw cuff pressure data. It becomes especially challenging when conditions, such as arrhythmia, or tremors, affect the regularity of pulses. Pattern recognition techniques with features found in time, frequency, or wavelet domains are used to deal with difficult situations.</p><p>• Blood pressure estimation: The indirect method of measurement is a process of estimating pressures with the use of features extracted from cuff-pressures or other transducer data. This algorithm used to be limited to linear interpolation. Recently, more elaborate decision-making and modeling tools such as nonlinear regression, neural networks, and fuzzy logic are also being used for this purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.4">TRANSIT TIMES EXTRACTION AND ESTIMATION</head><p>The use of the PCG signal to identified blood pressure and pulse transit time information was a newly developed method which is used recently as an alternative to direct oscillometric blood pressure method. The first adaptable technique was developed by Cornell et al. <ref type="bibr">[2004]</ref>. The wavelet decomposition system was used for extraction the spatial information and the temporal characteristics of the PCG-signal waveform to be correlated in time domain with the blood pressure profile to set up timing-frame for pulse transient time (PTT) paradigm. As monitoring blood pressure (BP) response during postural changes can test the sympathetic functions of the autonomic nervous system <ref type="bibr" target="#b19">[20]</ref>, parameters that can relate to the observed BP changes are clinically useful. The examination of the typical time delay value between the first heart sound (S 1 ) of PCG and the upstroke of the corresponding photoplethysmography (PPG) signals or vascular transit time (VTT) of healthy adults should be done in addition to the determination of the effect of hemodynamic turbulences on VTT when the measured periphery adopts different postures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.5">HEMODYNAMICS AND TRANSIT INTERVALS MODULATION</head><p>Also, the association of the observed VTT changes with corresponding BP changes should be considered in the computation. Finally, the regression of equations to relate VTT and BP during postural changes should also be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">SUMMARY</head><p>The phonocardiography signal processing (Fig. <ref type="figure" target="#fig_63">3</ref>.7) plays a vital role in development intelligent stethoscopic system as an integrated approach for smart auscultation technique.</p><p>The signal processing methods vary in its final application field where for spatially based signal processing the resulted processed PCG signal can be used in automated diagnosis of cardiac valve insufficiency, and this method can be further integrated to be a clinical diagnostic tool.</p><p>Key points can be summarized as follows:</p><p>• PCG signal processing fundamentals;</p><p>• Fourier transform of PCG signal;</p><p>• Temporal analysis technique, frequency-adapted signal processing, and representation;</p><p>• Spectral analysis of PCG signal;</p><p>• Electronic cardiac stethoscope signal processing aspects, including pre-filtering, signal buffering, Fourier transform, and signal presentation.</p><p>C H A P T E R 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phonocardiography Wavelets Analysis 4.1 WAVELETS</head><p>Wavelets have been found to be very useful in many scientific and engineering applications, including signal processing, communication, video and image compression, medical imaging, and scientific visualization. The concept of wavelets can be viewed as a synthesis of ideas that originated during the last several decades in engineering, physics, and pure mathematics. However, wavelet is a rather simple mathematical tool with a great variety of possible applications.The subject of wavelets is often introduced at a high level of mathematical sophistication. The goal of this chapter is to develop a basic understanding of wavelets, their origin, and their relation to scaling functions, using the theory of multi-resolution analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">HISTORICAL PERSPECTIVE</head><p>Prior to the 1930s, the main tools of mathematics for solving scientific and engineering problems traced back to Joseph Fourier (1807) with his theory of frequency analysis. He proposed that any 20-periodic function f(t) can be represented by a linear combination of cosines and sines components:</p><formula xml:id="formula_9">f (t) = a 0 + inf k=1 (a k cos(kt) + b k sin(kt)). (<label>4.1)</label></formula><p>The coefficients a 0 , a k , b k are the Fourier coefficients of the series and are given by</p><formula xml:id="formula_10">a 0 = 1 2π f (t)dt. (4.2) a k = 1 2π f (t)cos(kt)dt. (4.3) b k = 1 2π f (t)sin(kt)dt. (4.4)</formula><p>After 1807, mathematicians gradually were led from the notion of frequency analysis to the notion of scale analysis that is, analyzing f(t) by creating a mathematical structure that varies in scale. A. Haar, in his thesis <ref type="bibr">(1909)</ref>, was the first to mention the using of wavelets. An important property of the wavelets he used is that they have compact support, which means that the function vanishes outside a finite interval. Unfortunately, Haar wavelets are not continuously differentiable, which limits their application. From 1930s-1960s, several groups, working independently, researched the representation of functions using scale-varying basis functions. By using one such function, the Haar basis function, Paul Levy investigated Brownian motion and thereby laid the foundation for the modern theory of random processes. Levy found that the Haar basis function is superior to the Fourier basis functions for studying small and complicated details in Brownian motion. Also during the 1930s, research was done by Littlewood et al. <ref type="bibr" target="#b72">[73]</ref> on computing the energy of a time-function f(t):</p><formula xml:id="formula_11">energy = 1 2π |f (t)| 2 dt. (4.5)</formula><p>Their computation produced different results when the energy was concentrated around a few points and when it was distributed over a larger interval. This observation disturbed many scientists, since it indicates that energy might not be conserved. Later on, they discovered a function that can both vary in scale and conserve energy at the same time, when computing the functional energy. David Maar applied this work in developing an efficient algorithm for numerical image processing using wavelets in the early 1980s. Between 1960 and 1980, the mathematicians Guido Weiss and Ronald Coifman studied the simplest elements of a function space, called atoms, with the goals of finding the atoms for a common function and finding the construction rules that allow the reconstruction of all the elements of the function space using these atoms. In 1980, Grossman and Morlet <ref type="bibr" target="#b70">[71]</ref> recasted the study of quantum physics in the context of wavelets using the concept of frames. Morlet introduced the term wavelets as an abbreviation of wavelet of constant shape. These new insights into using wavelets provided a totally new way of thinking about physical reality. In 1985, Stephane Mallat applied wavelets to his work in digital signal processing. He discovered a relationship between quadrature mirror filters, the pyramid algorithm, and orthonormal wavelet bases. Inspired by these results, Y. Meyer constructed the first nontrivial wavelets. Unlike the Haar wavelets, the Meyer wavelets are continuously differentiable; however, they do not have compact support. In the early 1990s, Ingrid Daubechies used Mallat's work to construct a set of orthonormal wavelet basis functions that are perhaps the most elegant, and have become the cornerstone of wavelet applications today. The development of wavelets is an emerging field comprising ideas from many different fields. The foundations of wavelet theory have been completed, and current research is in the refinement stage. The refinement involves generalizations and extensions of wavelets, such as extending wavelet packet techniques. The future of wavelets depends on the possibility of applications. Wavelets decomposition (Fig. <ref type="figure" target="#fig_45">4</ref>.1) have so far been limited in practical applications by their lack of compact support.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">FOURIER ANALYSIS</head><p>Time-series data have traditionally been analyzed in either the time or the frequency domain. Fourier analysis is quite useful in identifying frequency components of a signal, but it cannot describe when those frequency components occurred, since it lacks time resolution. This is particularly important for signals with time-varying frequency content, as in human speech and video images. Figure <ref type="figure" target="#fig_45">4</ref>.2 shows the Fourier analysis of phonocardiography, the phase trace of it and the FFTamplitude of the same PCG signal. The DFT has symmetry properties almost exactly the same as the continuous Fourier transform. Approximation of a function by samples, and approximation of the Fourier integral by the DFT, requires multiplication by a matrix which involves on the order of (n) arithmetic operations. However, if two samples are uniformly spaced, then the Fourier matrix can be factored into a product of just a few sparse matrices, and the resulting factors can be applied to a vector in a total order of n log(n) arithmetic operations. This technique is the so-called Fast Fourier Transform (FFT). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">WAVELETS VERSUS FOURIER ANALYSIS</head><p>The FFT and the discrete wavelet transform (DWT) are both linear operations that generate a data structure containing (n) segments of various lengths, usually filling and transforming them into a different data vector of length 2 n . The mathematical properties of the matrices involved in the transforms are similar as well.</p><p>The inverse transform matrix for both the FFT and the DWT is the transpose of the original. As a result, both transforms can be viewed as a rotation in function space to a different domain <ref type="bibr" target="#b67">[68]</ref>.</p><p>For the FFT, the new domain contains basis functions that are sines and cosines. For the wavelet transform, the new domain contains more complicated basis functions called wavelets, mother wavelets, or analyzing wavelets. Both transforms have another similarity; the basis functions are localized in frequency, making mathematical tools such as power spectra (how much power is contained in a frequency interval) and scalograms useful at picking out frequencies and calculating power distributions.</p><p>The most interesting dissimilarity between these two kinds of transforms is that individual wavelet functions are localized in space, while Fourier sine and cosine functions are not. This localization in space, along with wavelets localization in frequency, makes many functions and operators using wavelets sparse when transformed into the wavelet domain. This sparseness, in turn, makes wavelets useful for a number of applications such as data compression, feature detection in images, and noise removal from time series. One way to see the time frequency resolution difference between the two transforms is to look at the basis function coverage of the time frequency plane <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b64">65]</ref>.</p><p>The square-wave window truncates the sine or cosine function to particular width. Because a single window is used for all frequencies in the WFT, the resolution of the analysis is the same at all locations in the time frequency plane. An advantage of wavelet transform is that the windows vary. In order to isolate signal discontinuities, one would like to have some very short basis functions. At the same time, in order to obtain detailed frequency analysis, one would like to have some very long basis functions.</p><p>A way to achieve this is to have short high-frequency basis functions and long low-frequency ones. This medium is exactly what you get with wavelet transform and this is shown in Fig. <ref type="figure" target="#fig_45">4</ref>.3, in which it gives the illustration of continuous wavelet analysis (CWT) based on Haar transformation function for a three cases (normal, valve regurgitation and stenosis).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">HAAR WAVELET</head><p>The Haar scaling function and Haar wavelet are a very simple example to illustrate many nice properties of scaling functions and wavelets, and are of practical use as well. The Haar scaling function is defined by:</p><formula xml:id="formula_12">φ(t) = 10 ≤ x ≤ 1 0, otherwise . (<label>4.6)</label></formula><p>The two-scale relation can be expressed as a summation:</p><formula xml:id="formula_13">H 2 = 2 k=0 p k φ(2t -k) (4.7)</formula><p>or</p><formula xml:id="formula_14">φ(t) = φ(2t) + φ(2t -1)<label>(4.8)</label></formula><p>The Haar wavelet corresponding to the Haar scaling function is given by:</p><formula xml:id="formula_15">(t) = ⎧ ⎪ ⎨ ⎪ ⎩ -1 f or 0 ≤ x ≤ 1 2 -1 f or 1 2 ≤ x ≤ 1 0 f or otherwise . (4.9)</formula><p>The construction of the two-scale relation for the Haar wavelet is easily computed as follows:</p><formula xml:id="formula_16">ψ(2t) = φ(2t) -φ(2t -1). (4.10)</formula><p>The two-scale relations express φ(t) in terms of φ(2t) and φ(2t -1), while the other two-scale relations are for Haar wavelets express ψ(t) in terms of φ(2t) and φ(2t -1). The reconstruction relations can be written in the matrix form: </p><formula xml:id="formula_17">φ(t) ψ(t) = 1 1 -1 1 = φ(2t) φ(2t -1) . (4.11)</formula><p>The decomposition relations are easily derived by just inverting the reconstruction relations as follows: </p><formula xml:id="formula_18">φ(2t) π(2t -1) = 1 2 1 2 -1 2 1 2 = φ(t) ψ(t) . (<label>4</label></formula><formula xml:id="formula_19">φ D 3 = 3 k=0 p k φ(2t -k) (4.13)</formula><p>where two-scale sequence p k are expressed as below:</p><formula xml:id="formula_20">p 1 , p 2 , p 3 , p 4 = 1 + √ 3 4 , 3 + √ 3 4 , 3 - √ 3 4 , 1 - √ 3 4 . (4.14)</formula><p>The normalized process of heart sound signal, and (N) was signal length of 20 ms. An initial threshold was set to 0.2 times of the maximum amplitude to identify S 1 and S 2 . Then, a limit window of 50 ms was slid throughout the whole set of the average Shannon energy signals. The threshold was adjusted to attain the required peaks. Based on the R-R intervals and by observing the pause lengths, S 1 and S 2 were then identified separately. Thus, the acquired signals were segmented into cycles. It is known that pathological murmurs are commonly heard in patients with cardiac abnormalities such as valvular disease mitral regurgitation (MR cases), shunts or narrowed vessels <ref type="bibr" target="#b66">[67]</ref>. Based on this understanding, the additional detectable heart sound components in each segmented cycle using the segmentation procedures were considered as murmurs.</p><p>Performance of heart sound signal characterization depends on PCG component identification and its characteristics, which is based on PCG signal classification and the threshold of heart cycle. Shannon energy was adjusted until all possible components were identified. Thereafter, the amplitude, frequency, time-span, and interval (including systolic and diastolic intervals) should determined. In general, the two-scale sequence for any PCG scaling functions has the property as presented below:</p><formula xml:id="formula_21">k p 2k = k p 2k-1 = 1. (4.15)</formula><p>There is no closed form for φ D 3 . The Haar wavelet is the simplest one; it has many φ D 3 applications. However, it has the drawback of discontinuity. It consists entirely of rectangular functions and cannot reproduce even linear functions smoothly in finite series for practical use. On the other hand, Bspline wavelets have higher continuity than Haar wavelets. They are more suitable for representing any continuous function. However, the complications of calculating its wavelet decomposition and reconstruction relation coefficients have limited its usefulness. The MATLAB code for wavelet analysis is shown below.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">SUBBAND CODING</head><p>One of the main applications of subband coding is compression. A key concept in signal analysis is that of localization in time and frequency. Another important intuitive concept is that of multiresolution, or the idea that one can consider a signal at different levels of resolution. These notions are particularly evident in image processing and computer vision, where coarse versions of images are often used as a first approximation in computational algorithms. In signal processing, a lowpass and sub-sampled version is often a good coarse approximation for many real-life signals. This intuitive paradigm leads to the mathematical framework for wavelet constructions <ref type="bibr" target="#b71">[72]</ref>. The wavelet decomposition is a successive approximation method that adds more and more projections onto detail spaces, or spaces spanned by wavelets and their shifts at different scales.</p><p>In addition, this multi-resolution approximation is well suited to many applications. That is true in cases where successive approximation is useful; for example, in browsing through image databases, as is done for instance on the World-Wide Web. Rather than downloading each full image, which would be time consuming, one only needs to download a coarse version, which can be done relatively fast. Then, one can fetch the rest, if the image seems of interest.</p><p>Similarly, for communication applications, multi-resolution approximation leads to transmission methods, where a coarse version of a signal is better protected against transmission errors than the detailed information. The assumption is that the coarse version is probably more useful than the detail.</p><p>There are many techniques for image coding; the subband coding method is the most successful today because it gives a fine details of the signal over a wide range of frequencies. The pyramid coding is effective for high-bit-rate compression, while transform coding based on the discrete cosine transform has become the Joint Photographer Expert Group ( JPEG) standard. The subband coding using wavelets transform (the tree-structured filter-bank approach) avoids blocking at medium bit rates, because its basis functions have variable length. It uses an adapted basis (the transformation depends on the signal). Long basis functions represent fat background (low frequency), and short basis functions represent regions with texture.</p><p>This feature is good for image enhancement, image edge detection, image classification, videoconferencing, video on demand, tissue, and cancer cell detection <ref type="bibr" target="#b73">[74]</ref>. Due to its adapted basis functions, one can also develop a set of algorithms for adaptive filtering systems <ref type="bibr" target="#b74">[75]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">WAVELETS DECOMPOSITION</head><p>A wavelet allows one to do multi-resolution analysis, which helps to achieve both time and frequency localization. Here, the scale (or resolution, actually it is the inverse of frequency) that we use to look at data plays a vital role. Wavelet algorithms process data at different scales or resolutions.</p><p>Figure <ref type="figure" target="#fig_45">4</ref>.6 shows the decomposition of PCG signal based on wavelets approach. If we look at a signal with a large (window), we would notice gross (or averaged) features. Similarly, if we look at a signal with a small (window), we would notice detailed features. Thus, by using varying resolution, the problem that was there with Short Time Fourier Transform (STFT) will be solved, due to the use of fixed window size (or resolution).</p><p>The core of a wavelet analysis procedure is the choice of a wavelet prototype function, called a mother wavelet. Temporal analysis is performed with a contracted, high-frequency version of the prototype wavelet, while frequency analysis is performed with a dilated, low-frequency version of the same wavelet.</p><p>Because the original signal can be represented in terms of a wavelet expansion (using coefficients in a linear combination of the wavelet transform), data operation can be performed using just the corresponding wavelet coefficients. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">CONTINUOUS WAVELET TRANSFORM</head><p>Continuous wavelet transform can be formally written as:</p><formula xml:id="formula_22">γ (s, τ ) = f (t) * s,τ (t)dt. (4.16)</formula><p>The * denotes complex conjugation. This equation shows how a function f(t) is decomposed into a set of basis functions s; (t), called wavelets. The variables s and τ , scale and translation, are the new dimensions after the wavelet transform. The wavelets are generated from a single basic wavelet (t) (that satisfies some conditions like admissibility etc.), the so-called mother wavelet, by scaling and translation</p><formula xml:id="formula_23">s,τ = 1 √ s 1 ( t -s s ). (4.17)</formula><p>Here, (s) is the scale factor, s 1 is the translation factor and the factor s 1 =2 is used for energy normalization across the different scales. It should be noted that in the above equations the wavelet basis functions are not specified. This is the main difference between the Fourier transform and the wavelet transform. The theory of wavelet transforms deals with the general properties of wavelet. Thus, it defines a framework, based on which one can design the wavelet he wants. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">DISCRETE WAVELET TRANSFORM</head><p>The continuous wavelet transform (CWT) described in the last section has redundancy. CWT is calculated by continuously shifting a continuously scalable function over a signal and determining the correlation between them. It is clear that these scaled functions will be near an orthonormal basis and the obtained wavelet coefficients will therefore be highly redundant. To remove this redundancy discrete wavelet transform (DWT) (Fig. <ref type="figure" target="#fig_45">4</ref>.8) is used.</p><p>In DWT the scale and translation parameters are chosen such that the resulting wavelet set forms an orthogonal set, i.e., the inner product of the individual wavelets are equal to zero. Discrete wavelets are not continuously scalable and translatable but can only be scaled and translated in discrete steps. This is achieved by modifying the wavelet representation as:</p><formula xml:id="formula_24">s,τ = 1 s s 0 ( t -τ τ 0 s s 0 s s 0 ). (<label>4.18)</label></formula><p>Here, s and τ are integers and s s 0 is a fixed dilation step. τ 0 is the translation factor and it depends on the dilation step. The effect of discretizing the wavelet is that the time-scale space is now sampled at discrete intervals. When the s 0 =2, the sampling of the frequency axis corresponds to dyadic sampling will choose. For the translation factor we generally choose τ 0 =1. In that case, the previous equation becomes:</p><formula xml:id="formula_25">s,τ = 1 √ 2 s ( t -τ 2 s 2 s ). (<label>4.19)</label></formula><p>Table <ref type="table">4</ref>.1 presents the identified percentage of S 1 and S 1 waveforms in the PCG data set and the corresponding energy value and entropy P CG based on adaptive wavelet analysis. As indicated in this table, the minimum error value is 0.0021 and the maximum one is 0.0051 which show an acceptable range of biased error during classification process of PCG signals.</p><p>In comparison with the other wavelet decomposition method the adaptive Db-wavelet shows a considerable degree of superiority among other wavelet decomposition technique such as Haar and biorthogonal methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">PATTERN DETECTION BASED ON ADAPTIVE WAVELETS ANALYSIS</head><p>The principle for designing a new wavelet for CWT, is to approximate a given pattern using Least squares Optimization (LEO), as the results of this wavelets analysis illustrated in Fig. <ref type="figure" target="#fig_45">4</ref>.9, where   under some constraints leading to an admissible wavelet; which is well suited for the pattern detection using the continuous wavelet transform.</p><p>The adaptive pattern detection have a prospect application in phonocardiography pattern localization with wavelets decomposition.</p><p>As Fig. <ref type="figure" target="#fig_45">4</ref>.5 shows previously, the localization of the cardiac hemodynamic events during aortic stenosis (AS) based on adaptive wavelet algorithm, is more obviously and delineated results other than wavelet decomposition algorithm. In spite, the Db-wavelets algorithm also shows stability and robustness in identification and extracting of hemodynamic information from the PCG signal.</p><p>Referring to other research work in adaptive pattern detection of cardiac event as automated annotation, which could help for fusion of the two clinical cardiac valve investigation methods (e.g., echocardiography and adaptive PCG pattern detection) to perform a linear and efficient diagnostic interpretation and analysis. The use of Shannon wavelet template, as shown in Fig. <ref type="figure" target="#fig_45">4</ref>.10, in PCG decomposition will improve the results obtained to some extents <ref type="bibr" target="#b75">[76]</ref>.</p><p>The wavelet decomposition of PCG vector can be done as in the following equation:  The systematic continuous transformation can also used for synthesis the new wavelets template to be embedded in the adaptive pattern localization:</p><formula xml:id="formula_26">S(t, w) = z(t + τ/2)z * (t -τ/2)</formula><formula xml:id="formula_27">S(t, w) = 1 τ 2 /σ s(u + τ/2)s * (u -τ/2)e [(u-t) 2 /(4τ 2 /sigma)]-iωt dτ du. (4.23)</formula><p>However, some of the results obtained through biorthogaonal decomposition (Bior-wavelet methods) show acceptable results to some degree, the Debauches (DbW) and adaptive wavelets (AWT) are more robust in dynamic PCG signal analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">SUMMARY</head><p>In the previous sections, the wavelet analysis of phonocardiography signal was discussed. Different approaches of wavelet transformations including (Haar, Debauches, Bi-orthogonal, and STFT) were touched in this chapter, in addition to the use of continuous wavelet transformation in the analysis, classification, and identification of a varieties of heart sounds traces.</p><p>The wavelets is considerably a powerful tool in biomedical signal analysis and processing. The adaptive wavelets analysis and decomposition were also illustrated, in which the combined PCG-signal wavelet decomposition and reconstruction is of stable methods for localization and investigation of the temporal characteristics and related spectral and spatial parameters.</p><p>As a summary of this chapter, the following assumptions and remarks can be helpful for further advances in wavelets adaptive signal processing and other wavelet derivatives algorithm.</p><p>• The use of higher-order wavelets to perform more complex pattern classification and spectral analysis of PCG signals. C H A P T E R 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phonocardiography Spectral Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">PCG SIGNAL SPECTRAL ANALYSIS</head><p>Heart sounds are complex and highly non-stationary signals in their nature and have been known to be quasi-stationary signals for a long time. The "heart beats" associated with these sounds are reacted in the signal by periods of relatively high activity and rhythmic energy style, alternating with comparatively intervals of low activity. Accordingly, PCG Spectrometric properties can be extracted by different methods using (e.g., Short-Time Fourier Transformation (STFT)), as it estimates the power spectral density (PSD) of successive waveform and computed these transformation will lead to periodic estimation of energy spikes within the acoustical waveform.</p><p>The PCG spectral analysis will be considered in this chapter; treat of, determining the distribution in frequency of the power of a time series signal from a finite set of measurements. Spectral analysis has found wide applications in diverse fields such as, radar, sonar, speech, biomedicine, economics, geophysics, and others; in which the spectral contents of signals are of interest. For example, in radar and sonar systems, the locations of the sources or targets can be estimated by measuring the spectral contents of the received signals.</p><p>In the biomedical engineering application, the spectral analysis of the signals from a patient provides doctors useful information for diagnosis purpose. In practice, the observed data are often of finite time-duration; hence, the quality of the spectral estimation is usually limited by the shortness of the available data record.</p><p>As a general rule for stationary random signals, the longer the data record, the better the spectral estimation that can be obtained. For deterministic signals, however, the spectral characteristics are described by an arbitrary length of data, the main goal being to select a data record as short as possible so that different signal components can be measured and resolved.</p><p>There are two broad classes of spectral analysis approaches: nonparametric methods and parametric (model-based) methods.The nonparametric methods-such as periodogram, Blackman-Tukey, and minimum variance spectral estimators-do not impose any model assumption on the data, other than wide-sense stationarity.</p><p>The parametric spectral estimation approaches, on the other hand, assume that the measurement data satisfy a generating model by which the spectral estimation problem is usually converted to that of determining the parameters of the assumed signal model. Two kinds of models are widely assumed and used within the parametric methods, according to different spectral characteristics of the signals: the rational transfer function (RTF) model and the sinusoidal signal model.</p><p>The RTF models, including autocorrelation (AR), moving average (MA), and autocorrelation moving average (ARMA) types are usually used to analyze the signals with continuous spectra, while the sinusoidal signal model is a good approximation of signals with discrete spectral patterns.</p><p>The discussion of PCG spectral analysis will divided into two parts: stationary spectral analysis and non-stationary spectral analysis.</p><p>In the first part, the nonparametric spectral estimation methods will introduced, along with the parametric methods for rational spectral analysis and sinusoidal spectral analysis.</p><p>In the second part, study of two non-stationary spectral analysis examples: damped sinusoidal parameter estimation, as approximation to the PCG-signal components, and instantaneous frequency measurement.</p><p>The typical spectral distribution of PCG signal can be well demonstrated in Fig. <ref type="figure">5</ref>.1, as the indication of normal frequency PCG signal trace distribution, as well as the pathological PCG traces (pulmonary and mitral valve regurgitation) can be observed as spectral distribution as shown in Figs. 5.1 and 5.2. This pathological condition related to the valvular diseases such as mitral valve regurgitation (MVR), which is considered in many PCG signal processing problems <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. The other cardiovascular pathologies also can be considered for spectral analysis and further post-processing steps. Some of investigators were focused on metabolic cardiac disorders such as diabetes mallietus (DM) and congestive heart disease (CHD), which shows some distinct characteristics in frequency domain as a priori-assumption for the spectral PCG-signal processing <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">ENERGY SPECTRAL DENSITY OF DETERMINISTIC SIGNALS X(t) represents a continuous-time signal of interest;</head><p>x(n) denotes the sequence obtained by sampling x, suppose that x C at some uniform sampling rate F s ; that is,</p><formula xml:id="formula_28">x(n) = x c (n/F s ).</formula><p>(5.1)</p><p>If x(n) has finite energy, then the quantity S(ω) can be interpreted as the distribution of the signal energy as a function of frequency and, hence, it is called the energy spectral density of the signal.</p><p>Here, the frequency is measured in radians per sampling interval, which corresponds to the physical frequency F/2.F s and corresponding unit in hertz. Note that the total energy of the signal is the integral of S(ω) over the interval (t,s) (within a constant scale 1/2).</p><p>If the autocorrelation function (ACF) of the deterministic signals (e.g., PCG signal) can be defined as x, therefore, the PCG signal energy index can be obtained from integration of ACF in frequency domain.</p><p>The flow diagram of the PCG signal energy detection based on spectral estimation is presented in Fig. <ref type="figure">5</ref>.3, where three PCG microphone transducers were acquired and the PCG signals sampled at Shannon frequency F s , then the PCG signals are band-passed filtered and the relevant spectral estimation was derived. Further higher-order statistics algorithm was applied to the PCG spectral patterns, such as a k-mean clustering method and the energy signature identification of the heart was detected and evaluated <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b76">77]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">PCG SPECTRAL ESTIMATION</head><p>PCG spectra contain vast number of distinct harmonics categories that would be useful to be identified as a clustering scheme in any data classification algorithms. The majority of these spectra, although, belong to specific valvular pathologies which have a distinct energy (intensity) level in STFT plot. This realness would be an attractive point to consider such variation as clustering index, as this will considerably orientate the classifier algorithm to stable entropy value.</p><p>The spectral information characteristics of PCG lie within a frequency band of (54-520 Hz), and this band depend on digital stethoscopic interface and resolution of data converters in instrumentation platform. This criteria constitutes the basis for heart sounds spectral pattern classification technique, in which the dependency on frequency (spectral) characteristics.</p><p>The block diagram for overall spectral classification system is demonstrated in Fig. <ref type="figure">5</ref>.3. Several patterns can be derived from the input-vector of PCG signal, in which they are processed with a specific FIR-filter length.</p><p>The most recognizable patterns in PCG are systolic, diastolic, pre-systolic, and post-diastolic peaks, of successive heart sound (S 1 , S 2 , S 3 , and S 4 ), which are shown in Fig. <ref type="figure">5</ref>.1. Most of cardiologists prefer the base-diagnosis on two categories of PCG, S 1 and S 2 , so that they can discriminate the hemodynamics turbulences (normal-level deviating blood flow) and cardiovascular anomalies in an appropriate method.</p><p>The spectra stamp can be oriented in three schema (supraspectra, infraspecta, and mid-spectra) which represent the intensity harmonics of PCG waveform. The correlation indicator between two intensity peaks of PCG, where it gives a defined index for clustering profile M j -P CG of PCG signal, which in turn apply a segmental cluster for input data vector <ref type="bibr" target="#b78">[79]</ref>.</p><p>Systolic and diastolic murmur frequencies are classified by the frequency band containing the largest power value in the tenth (s) of the systole/diastole corresponding to the found maximum values of (SI/DI). If the largest power value is found in one of the two lowest frequency bands (containing frequencies below 125 Hz), the murmur is classified as a low-frequency murmur. If the largest power value is found in one of the eight highest frequency bands (containing frequencies above 250 Hz), the murmur is classified as a high-frequency murmur. If the none of the above is the case, the murmur is classified as a medium-frequency murmur <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b76">77]</ref>.</p><p>• The PCG spectral estimation: This result is obtained by using Db-wavelets decomposition techniques for a set of PCG signal as below:</p><formula xml:id="formula_29">y[n] = (x P CG * g)[n] = ∞ k=-∞ x P CG [k]g[n -k]. (5.2)</formula><p>Extracting the PCG diastolic low-frequency components as in Eq. (5.1):</p><formula xml:id="formula_30">y lowP CG(diastolic) [n] = ∞ k=-∞ x P CG [k]g[2n -k]. (5.3)</formula><p>And for PCG systolic high-frequency components:</p><formula xml:id="formula_31">y highP CG(diastolic) [n] = ∞ k=-∞ x P CG [k]h[2n -k].</formula><p>(5.4)</p><p>Based on the spectral characteristic features extracted from the heart sound signal, the nature of the heart sound can be identified using pattern recognition techniques. A number of pattern recognition and classification schemes have been implemented for the analysis of heart sounds. The classical pattern recognition techniques, includes the Gaussian-Bayes classifier, the K-nearest neighbor classifier (k-mean clustering), and higher-order classification algorithms. The Gaussian-Bayes classifier is the most popular parametric technique of supervised pattern recognition. It is considered optimal when the probability density functions (p.d.f ) of the patterns in the feature space are known (a pattern is defined as an N-dimensional vector composed of (N) features), but it needs high computational efficiency and pre-definition of a priori conditions to increase the accuracy of this classifier type <ref type="bibr" target="#b78">[79]</ref>.</p><p>The K-nearest neighbor classifier is a nonparametric approach, which is useful when the probability density functions are difficult to estimate or cannot be estimated <ref type="bibr" target="#b79">[80]</ref>.</p><p>The nearest neighbor method is an intuitive approach based on distance measurements, motivated by the fact that patterns belonging to the same class should be close to each other in the feature space. Joo et al <ref type="bibr" target="#b79">[80]</ref>. demonstrated the diagnostic potential of a Gaussian-Bayes classifier for detecting degenerated bioprostheses implanted in the aortic valve position. A detailed discussion will be presented in chapter six, with different PCG-classifiers and its relation with spectral estimation approach <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b81">82]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NONPARAMETRIC METHOD FOR PHONOCARDIOGRAPHY SPECTRAL ESTIMATION</head><p>The spectral estimation methods are based on the discrete Fourier transform (DFT) of either the signal segment or its autocorrelation sequence. In contrast, parametric methods assume that the available signal segment has been generated by a specific parametric model (e.g., a pole-zero or harmonic model). Since the choice of an inappropriate signal model will lead to erroneous results, the successful application of parametric techniques, without sufficient a priori information, is very difficult in practice. If adopting a deterministic signal model, the mathematical tools for spectral analysis are the Fourier series, which is discussed in chapter four.</p><p>It should be stressed at this point that applying any of these tools requires that the signal values in the entire time interval from -∞ to +∞ be available. If it is known a priori that a signal is periodic, then only one period is needed. The rationale for defining and studying various spectra for deterministic signals is threefold. First, we note that every realization (or sample function) of a stochastic process is a deterministic function.</p><p>Therefore, we can use the Fourier series and transforms to compute a spectrum for stationary processes. Second, deterministic functions and sequences are used in many aspects of the study of stationary processes, for example, the autocorrelation sequence, which is a deterministic sequence. Third, the various spectra that can be defined for deterministic signals can be used to summarize important features of stationary processes.</p><p>Most practical applications of spectrum estimation involve continuous-time signals. For example, in speech analysis we use spectrum estimation to determine the pitch of the glottal excitation and the formants of the vocal tract <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b74">75]</ref>. In electroencephalography (EEG), we use spectrum estimation to study sleep disorders and the effect of medication on the functioning of the brain <ref type="bibr" target="#b75">[76]</ref>. Another application is in ultrasonic Doppler radar, where the frequency shift between the transmitted and the received waveform is used to determine the radial velocity of the target <ref type="bibr" target="#b82">[83]</ref>.</p><p>The main numerical computation of the spectrum of a continuous-time signal involves the following three steps.</p><p>1. Sampling the continuous-time signal to obtain a sequence of samples.</p><p>2. Collecting a finite number of contiguous samples (data segment or block), to use for the computation of the spectrum. This operation, which usually includes weighting of the signal samples, is known as windowing, or tapering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Computing the values of the spectrum at the desired set of frequencies.</head><p>This last step, is usually implemented using some efficient implementation of the DFT. The above processing steps, which are necessary for DFT-based spectrum estimation, are shown in Fig. <ref type="figure">5</ref>.4.The continuous-time signal is first processed through a low-pass (anti-aliasing) filter and then sampled to obtain a discrete-time signal. Data samples of frame length N with frame overlap N 0 are selected and then conditioned using a window. Finally, a suitable-length DFT of the windowed data is taken as an estimate of its spectrum, which is then analyzed. In this section, we discuss in detail the effects of each of these operations on the accuracy of the computed spectrum. The understanding of the implications of these effects is very important in all practical applications of spectrum estimation. The above processing steps, which are necessary for DFT-based spectrum estimation, are illustrated in Fig. <ref type="figure">5</ref>.4.The continuous-time signal is first processed through a low-pass (anti-aliasing) filter and then sampled to obtain a discrete-time signal. Data samples of frame length N with frame overlap N 0 are selected and then conditioned using a window.</p><p>Finally, a suitable-length DFT of the windowed data is taken as an estimate of its spectrum, which is then analyzed. In this section, we discuss in detail the effects of each of these operations on the accuracy of the computed spectrum. The understanding of the implications of these effects is very important in all practical applications of spectrum estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">EFFECT OF SIGNAL SAMPLING</head><p>The continuous-time signal s c (t), whose spectrum we seek to estimate, is first passed through a low-pass filter, also known as an anti-aliasing filter H lp (F), in order to minimize the aliasing error after sampling. The antialiased signal x c (t) is then sampled through an analog-to-digital converter (ADC) to generate the discrete-time sequence x(n), that is,</p><formula xml:id="formula_32">x(n) = x c (t) t=n/F s .</formula><p>(</p><p>From the sampling theorem which introduced before</p><formula xml:id="formula_34">X(e j 2πF /F s ) = F s ∞ l=-∞ X c (F -lF s ), (<label>5.6)</label></formula><p>where X c (F)=H lp (F)S c (F). notice that the spectrum of the discrete-time signal x(n) is a periodic replication of X c (F ). Overlapping of the replicas X c (F-l F s ) results in aliasing. Since any practical anti-aliasing filter does not have infinite attenuation in the stop-band, some nonzero overlap of frequencies higher than F s/2 should be expected within the band of frequencies of interest in x(n). These aliased frequencies give rise to the aliasing error, which, in any practical signal, is unavoidable. It can be made negligible by a properly designed anti-aliasing filter H lp .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">WINDOWING, PERIODIC EXTENSION, AND EXTRAPOLATION</head><p>In practical signal spectral estimation application, the spectrum of a signal by using a finite-duration segment can be computed. The reason is threefold:</p><p>1. The spectral composition of the signal changes with time.</p><p>2. There is only a finite set of data at this disposal.</p><p>3. The computational complexity should be kept to an acceptable level.</p><p>Therefore, it is necessary to partition x(n) into blocks (or frames) of data prior to processing. This operation is called frame blocking, and it is characterized by two parameters: the length of frame N and the overlap between frames N 0 (see Fig. <ref type="figure">5</ref>.4). Therefore, the central problem in practical frequency analysis can be stated as follows: Determine the spectrum of a signal x(n) (-∞ &lt; n &lt; ∞), from its values in a finite interval (0 ≤ n ≤ N-1), that is, from a finite-duration segment.</p><p>Since x(n) is unknown for n &lt; 0 and n ≥ N, it is difficult to say, without having sufficient a priori information, whether the signal is periodic or aperiodic. If we can reasonably assume that the signal is periodic with fundamental period N, we can easily determine its spectrum by computing its Fourier series, using the DFT method.</p><p>However, in most practical applications, This assumption can not be considered, because the available data block could be either part of the signal period of a periodic function or a segment from an aperiodic function. In such cases, the spectrum of the signal cannot be determined without assigning values to the signal samples outside the available interval. There are three methods to deal with this issue:</p><p>1. Periodic extension method. This method is based on assumption that x(n) is periodic with period N, that is, x(n)=x(n+N) for all n and the Fourier series coefficients can be computed, using the DFT-method.</p><p>2. Windowing-method.This process can be initialized by supposing that the signal is zero outside the interval of observation, that is, x(n)=0 for n &lt; 0 and n ≥ N.This is equivalent to multiplying the signal with the rectangular window.</p><p>3. Extrapolation method. This process uses a priori information (pre-assumption) about the signal to extrapolate (i.e., determine its values for n &lt; 0 and n ≥ N) outside the available interval and then determine its spectrum by using the DTFT.</p><p>The periodic extension and windowing can be considered the simplest forms of extrapolation. It should be obvious that a successful extrapolation results in better spectrum estimates than periodic extension or windowing. Periodic extension is a straightforward application of the DFT, whereas extrapolation requires some form of a sophisticated signal model, as previously introduced of the nonparametric spectral estimation methods. Therefore, we can considering the PCG-spectral estimation technique, based on non-parametric method. Firstly, the PCG-periodogram estimator will introduced, and analysis of its statistical properties in terms of the bias and the variance of the PSD estimate will discussed. Since the periodogram estimator has a high variance, even for large sample length, several modified methods such as Bartlet <ref type="bibr" target="#b70">[71]</ref>, Welch <ref type="bibr" target="#b72">[73]</ref>, and Blackman-Tukey <ref type="bibr" target="#b73">[74]</ref> methods are then discussed. Finally, the minimum variance spectral estimator is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">PERIODOGRAM METHOD</head><p>The periodogram spectral estimator of a phonocardiography (PCG) is defined based on the Power Spectral Density (PSD) equation as follows:</p><formula xml:id="formula_35">RPCG (ω) = 1 N N -1 n=0 x(n)e -jωn 2 = 1 N |X(ω)| 2 , (<label>5.7)</label></formula><p>where RPCG (ω) is the periodogram of PCG-spectral estimation, and the PSD equation can be represented as follows:</p><formula xml:id="formula_36">R P CG (ω) = lim x→0 E ⎡ ⎣ 1 N N -1 n=0 x(n)e -jωn 2 ⎤ ⎦ , (<label>5.8)</label></formula><p>where X(ω)is the Fourier transform of the sample sequence x(n). Note that the implementation of the periodogram estimator involves performing discrete Fourier transform (DFT) on x(n), followed by calculating the PSD directly. Specifically, given (N) data points x(0), x(1),. . ., x(N-1), we compute the N-point DFT at frequency.</p><formula xml:id="formula_37">ω = 2π N k, k =0,1,...,N-1.</formula><p>(5.9) that yields the samples of the periodogram</p><formula xml:id="formula_38">R1 ( 2π N k) = 1 N N -1 n=0 x(n)e -j 2πn k N 2</formula><p>, k =0,1,...,N-1.</p><p>(5.10)</p><p>In practice, however, when the data length N is small, the estimated PSD computed by Eq. (5.8) does not provide a good representation of the continuous spectrum estimate due to the small number of samples. In order to get a more complete description about the estimated PSD, it is necessary to evaluate RPCG (ω) at more dense PCG frequencies. This can be achieved by increasing the sequence length via zero padding. Specifically, if the data length is increased to L (L&gt;N), evaluating L-point DFT yields the following:</p><formula xml:id="formula_39">R2 ( 2π L k) = 1 N N -1 n=0 x(n)e -j 2πn k L 2</formula><p>, k =0,1,...,L-1.</p><p>(5.11)</p><p>Figure <ref type="figure">5</ref>.5 illustrates the correlation matrix of PCG signal after applying the periodogram evaluation process described above. This figure plotting the correlation-index derived from Eq. (5.11) against PCG intensity amplitude, to identify the spectral properties of phonocardiography traces. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">MODIFIED PERIODOGRAM METHOD</head><p>The Bartlett method <ref type="bibr" target="#b77">[78]</ref> and the Welch method <ref type="bibr" target="#b78">[79]</ref> are two modified periodogram methods. These methods aim at reducing the variance of the periodogram estimate by splitting up the N available observations into K segments, and then averaging the periodograms computed from each segments for each value of ω. Therefore let us consider the following:</p><formula xml:id="formula_40">x i (n) = x(n + iD), i = 0, 1, ..., K -1; n=0, 1,...,M-1.</formula><p>(5.12) Denote the observations of the i th segment, where (iD) is the starting point of the i th segment. The Bartlett method takes D=M, and N=L.M; thus, data samples in successive segments are not overlapped. In the Welch method, one chooses D=M/2 and obtains overlapped data samples in successive segments. For example, if D=M/2, there is 50% overlapping between successive data segments, and K=2L segments are obtained.</p><p>Let's assume the equations below.</p><formula xml:id="formula_41">Ri (ω) = 1 M M-1 n=0 x i (n)e -jω<label>2</label></formula><p>(5.13) represents the periodogram of the ith segment. The Bartlett spectral estimator is defined as</p><formula xml:id="formula_42">RB (ω) = 1 L L-1 i=0</formula><p>Ri (ω).</p><p>(5.14)</p><p>The Welch spectral estimator is defined as:</p><formula xml:id="formula_43">RW (ω) = 1 K K-1 i=0 Ri M (ω), (<label>5.15)</label></formula><p>where R i M (ω) is the window-based periodogram, given by:</p><formula xml:id="formula_44">Ri M (ω) = 1 MP M-1 n=0 x i ω(n)e -jω<label>2</label></formula><p>(5.16) with P the (power) of the PCG-signal time window w(n),</p><formula xml:id="formula_45">P = 1 K M-1 n=0 ω 2 (n).</formula><p>(5.17)</p><p>It is noted that in the Welch method, the data samples in each segment are windowed before they are Fourier transformed via FFT-method. The statistical properties of the Bartlett estimator are easily obtained. First, the expected value of RB (ω) is given by:</p><formula xml:id="formula_46">E RB (ω) = 1 L E Ri (ω) = 1 2π π -π R(α)W M B (ω -α)dα (5.18) W (N) B (ω) = 1 N sin(ω2N sin(ω2N 2 (5.19)</formula><p>which is the Fourier transform of the so-called Bartlett window with length N, described as follows:</p><formula xml:id="formula_47">W N B (k) = 1 -|k| N ,if |k| ≤ N -1 0, otherwise .</formula><p>(5.20) The existing PCG signal acquisition techniques can be separated into invasive techniques, which make measurements inside the body, and noninvasive, which operate external to the body. Noninvasive methods can be further divided into active methods, which transmit and receive a signal, and passive methods, which merely listen to signals generated by myocardium vibration <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b78">79]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">PARAMETRIC METHOD FOR PHONOCARDIOGRAPHY SPECTRAL ESTIMATION</head><p>By assuming that, the PCG signal generated by passing a zero-mean white noise process u(n) through a linear time invariant (LTI) system; that is, accordingly, the definition of an ARMA signal is obtained by filtering a white noise process through a pole-zero system. The ARMA models are suitable for describing signals whose spectra have both sharp peaks and deep nulls by relatively lower orders where</p><formula xml:id="formula_48">x(n) = - p k=1 a(k)x(n -k) + q k=0 b(k)u(n -k), (<label>5.21)</label></formula><p>where u(n) is called driving noise, and without loss of generality, b(0)=1. The corresponding system transfer function is as follows:</p><formula xml:id="formula_49">H (z) = B(z) A(z) , (<label>5.22)</label></formula><p>where</p><formula xml:id="formula_50">A(z) = 1 + p k=1 a(k)z -k (5.23)</formula><p>and</p><formula xml:id="formula_51">B(z) = q k=0 b(k)z -k . (5.24)</formula><p>Therefore, the three rational transfer function model derived is as follows:</p><formula xml:id="formula_52">H (z) = 1 + p k=1 a(k)z -k q k=0 b(k)z -k .</formula><p>(5.25)</p><p>• Autoregressive moving average (ARMA) model. The one pole-zero model in Eq. (5.25) is said to be an ARMA model of orders p and q and is denoted as ARMA (p,q). a(k) and b(k)'s (p and (q) are referred to as AR and MA coefficients orders, respectively.</p><p>• Autoregressive (AR) Model. If q=0, the model in Eq. (5.25) is simplified to an all-pole model with order p and is referred to as an AR(p)model.</p><p>• Moving average (MA) model. If p=0, the model in Eq. (5.25) is reduced to an all-zero model with order q, and is called MA(q) model.</p><p>The ARMA spectral estimation can be defined through auto-correlation function of ARMA transfer function model as follows:</p><formula xml:id="formula_53">r(m) = - p k=1 a k r(m -k) + σ 2 q-m k=1 h k b(k + m), m=0,1,...,q; - p k=1 a k r(m -k), m ≥ q + 1;</formula><p>(5.26) Error biased value of estimated PCG signal was presented in Fig. <ref type="figure">5</ref>.6, which is denoted as (erb-plot) of the stationary spectral behavior of the PCG-signals. Therefore, the ARMA parameters appear in a nonlinear fashion through the unknown impulse response h(n). If the optimum modeling is required, it is necessary to solve the least mean square solution of the highly nonlinear Yule-Walker equations. To obtain such a solution, nonlinear iterative techniques are employed, which are not only computationally expensive, but also suffer from the local convergence effect.</p><p>A considerable simplicity in computation may be achieved, via the suboptimal techniques in which the AR and MA part coefficients are estimated separately. At that point, it is possible to estimate the AR parameters via a linear procedure. After the AR parameters are obtained. The AR polynomial to filter the observed data will be used, and obtaining a pure MA(q) process, whose parameters can be estimated via the approaches developed in the preceding subsection.</p><p>AR Parameter Estimation. Choosing m≥q+1 in Eq. (5.27), and the following equation is obtained: p k=0 a k r(mk), m=q+1,q+2,...,q+n.</p><p>(5.27) Equation ( <ref type="formula" target="#formula_33">5</ref>.27) establishes a linear relation between the AR parameters and the ACFs of the observed signals. To determine the AR parameters, one may adopt the first p linear equations (i.e., q+1 ≤ m ≤ q+p) and then solve the resultant system of equations. When the ACFs are truly known, this set of equations is enough to yield a unique and accurate solution to the AR parameter estimates.</p><p>In practice, since the sample ACF estimates are used, the AR parameter estimates obtained by this method may be poor due to the estimation errors of the sample ACF estimates. This deficiency may also be interpreted by the fact that only subset lags of ACF's are used. In fact, Eq. (5.27) is satisfied for any m ≥ q+1.</p><p>To obtain better AR parameter estimates, one reasonable choice is to employ more than the minimal number (i.e., p) of the extended Yule-Walker equations. This results in an overdetermined set of linear equations which can be solved via least square (LS) or total least square (TLS) techniques. The adaptive filtering architecture, which is used in PCG signal spectral estimation, can be observed in Fig. <ref type="figure">5</ref>.7 where the ARMA-PCG model based on auto correlation function used in define adapted filtering response in the presence of background noise signal n(t) or k[n] as displayed in Fig. <ref type="figure">5</ref>.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">ARMA MODELING APPROACH</head><p>For the clarity of statement, the real-valued signals should only be considered in developing the ARMA modeling approach for sinusoidal frequency estimation. The sinusoids in additive white noise satisfy a special ARMA model by which an ARMA modeling approach is developed for estimating the sinusoidal parameters was firstly, approved.</p><p>To motivate the selection of an ARMA process as the appropriate model for sinusoids in white noise, let us consider the following trigonometric identity:</p><formula xml:id="formula_54">cos( n) = -2.cos cos[ (n -1)] -cos[ (n -2)]</formula><p>(5.28)</p><p>for -π ≤ ≤ π . Let x(n)=cos n, a(1)=2cos , and a(2)=1; the single real sinusoidal component x(n) can be generated via the second-order difference equation:</p><formula xml:id="formula_55">x(n) = -a(1)x(n -1) -a(2)x(n -2) (5.29)</formula><p>with the initial values to be x(-1)=-1, x(-2)=0. This difference equation has the characteristics polynomial expression</p><formula xml:id="formula_56">1 + a(1)z -1 + a(2)z -2</formula><p>(5.30) whose roots are z 1 =e jω and z 2 =z * 1=e j . The sinusoidal frequency is determined from the roots as follows:</p><p>= tan -1 (I mz 1 /Rez 1 ).</p><p>(5.31)</p><p>The block diagram of the overall ARMA model system can be identified through the zero's and pole's transfer function estimation process as shown in Fig. <ref type="figure">5</ref>.8. The other modified method for estimating PCG parametric model was based on adaptive regressive-parametric modeling, which will not be considered here because it belongs to the nonlinear processing approach of PCG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">PHONOCARDIOGRAPHY ESPRIT METHOD</head><p>ESPRIT (Estimation of Signal Parameters via Rotational Invariance Techniques <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b74">75]</ref>) is another Eigen-decomposition method for estimating sinusoidal frequency parameters. It produce the sinusoidal frequency estimates by computing the generalized eigenvalues of two well-constructed matrices. We again, consider the complex-valued case. Using the notations defined in the MUSIC method, and denoting the following formula:</p><formula xml:id="formula_57">z(n) = [y(n + 1), y(n + 2), ..., y(n + m)] T .</formula><p>(5.32)</p><p>Therefore, along with Eqs. (5.26) and (5.27) the following can produce:</p><formula xml:id="formula_58">z(n) = A x(n) + w(n + 1)</formula><p>where is a p× p diagonal matrix.</p><p>= diag[e jω 1 , e jω 2 , e jω p ] (5.33) which relates the time-displaced vector y(n) and z(n), and hence, is called a rotation operator. The cross-correlation matrix of the data vectors y(n) and z(n)is: <ref type="bibr">.34)</ref> where, Q=identity matrix.</p><formula xml:id="formula_59">R 1 = E[y(n)z H (n)] = AP H A H + σ 2 Q. (<label>5</label></formula><formula xml:id="formula_60">⎡ ⎢ ⎢ ⎢ ⎣ 1 0 . . . 0 0 0 1 . . . 0 0 . . . . . . . . . . . . 0 0 0 . . . 1 0 ⎤ ⎥ ⎥ ⎥ ⎦</formula><p>On the other hand, direct calculation of R 1 yields, and by constructing the following two matrices:</p><formula xml:id="formula_61">R 1 = ⎡ ⎢ ⎢ ⎢ ⎣ r y (</formula><formula xml:id="formula_62">C 1 = R -σ 2 I = AP A H (5.36) C 2 = R 1 -σ 2 Q = AP H A H</formula><p>and consider the matrix (C 1 -λC 2 );</p><formula xml:id="formula_63">C 2 λC 1 = AP (I -λ H )A H (5.37)</formula><p>Paularj, Roy, and Kailath <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b69">70]</ref> have shown that matrix pair (C 1 ,C 2 ) has (p) generalized eigenvalues at λ(i). e jω i, i=1, 2, ..., p, and (m-p) generalized eigenvalues being zero.</p><p>Using the above results, the ESPRIT algorithm can be summarized as follows:</p><p>• Step 1. Calculating the sample ACF's ry(m), m=0,1,. . ., m., using a standard biased formula, and construct the matrices R and R 1 using Eqs. (5.35) and (5.36).</p><p>• Step 2. Computing the eigenvalues of R, and obtain the estimate of noise variance σ .</p><formula xml:id="formula_64">• Step 3. Computing Ĉ1 .R ...2 Î and Ĉ1 .R 1 ...2 Q • Step 4.</formula><p>Computing the generalized eigenvalues of the matrix pair ( Ĉ1 , Ĉ2 ).The (p) generalized eigenvalues which lie on (or near) the unit circle determine the diagonal elements of , and hence, the sinusoidal frequencies. The remaining (m.p) eigenvalues will lie at (or near) the origin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">SPECTRAL-WINDOW METHOD FOR PCG-SIGNAL PROCESSING</head><p>Any signal in the world can be described in different coordinate systems and that there is engineering value in examining a signal described in an alternate basis-system. One basis system that is particularly useful is the set of complex exponentials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">SPECTRAL-WINDOW METHOD FOR PCG-SIGNAL PROCESSING 103</head><p>The attraction of this basis set is that complex exponentials are the eigen-functions and eigen-series of linear time invariant (LTI) differential and difference operators, respectively. Put in its simplest form, this means that when a sine wave is applied to an LTI filter the steady-state system response is a scaled version of the same sine wave.</p><p>The system model can only affect the complex amplitude (magnitude and phase) of the sine wave but can never change its frequency. Consequently, complex sinusoids have become a standard tool to probe and describe LTI systems. The process of describing a signal as a summation of scaled sinusoids is standard Fourier transform analysis.</p><p>The Fourier transform and Fourier series, shown in Eq. <ref type="bibr">(5.38)</ref>, permits us to describe signals equally well in both the time domain and the frequency domain:</p><formula xml:id="formula_65">H (ω) = inf -inf h(t)e -jωt dt</formula><p>(5.38)</p><formula xml:id="formula_66">H (θ) = inf -inf h(n)e -jθn ,</formula><p>(5.39)</p><formula xml:id="formula_67">h(t) = 1 2π + inf -inf h(ω)e +jωt dω,<label>(5.40</label></formula><p>)</p><formula xml:id="formula_68">h(n) = 1 2π +π -π h(θ )e +jθn dθ.</formula><p>(5.41)</p><p>Since the complex exponentials have infinite support, the limits of integration in the forward transform (time-to-frequency) are from minus to plus infinity. As observed earlier, all signals of engineering interest have finite support, which motivates us to modify the limits of integration of the Fourier transform to reflect this restriction. This is shown in Eq. (5.42), where T SU P and (n) define the finite supports of the signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H SU P (ω) =</head><p>T SU P h(t)e -jωt dt (5.42)</p><formula xml:id="formula_69">H SU P (θ ) SU P = N h(n)e -jθn , (5.43) h(t) = 1 2π + inf -inf</formula><p>H SU P e +jωt dω, (5.44)</p><formula xml:id="formula_70">h(n) = 1 2π +π -π</formula><p>H SU P e +jθn dθ, <ref type="bibr">(5.45)</ref> The two versions of the transform can be merged in a single compact form, if we use a finite support window to limit the signal to the appropriate finite support interval, as opposed to using the limits of integration or limits of summation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">DIGITAL STETHOSCOPE SYSTEM (DS)</head><p>The main elements of a Digital Stethoscope are the sensor unit that captures the heart and lung sounds (also known as auscultations), digitization, and digital processing of the auscultations for noise reduction, filtering and amplification. Sort of intelligent algorithms for heart rate detection and cardiac abnormalities detection may also be integrated in the DS-module.</p><p>Power source and battery management are key in this ultra-portable medical diagnostic tools, where key design considerations are ultra-low power consumption and high efficiency driven by the need for extended battery life, and high precision with a fast response time allowing quick determination of the patient's health status.</p><p>Additional requirements may drive the need for recording the auscultations, cabled, or wireless interfaces for transmission of the auscultations.</p><p>In addition, to enable ease of use, features like touch screen control and display back lighting are important for the device usability. Adding all these features without significantly increasing power consumption is a huge challenge. The selection of micro-processors units, instrumentation and buffer amplifiers, power sources and voltage regulators, Audio Codecs (ACOD) system, and both wired and wireless interface devices and ports provides the ideal tool box for digital stethoscope applications <ref type="bibr" target="#b79">[80]</ref>.</p><p>The main components of the cutting edge digital stethoscope and other clinical data fusion are shown in figure below where the use of low-power micro controller unit (MCU) in a portable medical instrumentation will assist in discretization and integration of multi-parametric cardiac diagnosis system.</p><p>The common core subsystems of a digital stethoscope are the following:</p><p>• Analog Front-End/Sensor Interface and Codec auscultations signal input is amplified and then digitized by the Audio Codec. Auscultations signal after being digitized and subjected to signal processing, is converted to analog and sent to the stethoscope earpieces.</p><p>• Low power micro-processor unit: Processors capable of executing all of the digital stethoscopes signal processing including key functions such as noise reduction, algorithms for heart rate detection, and heart defect detection while maintaining a very low constant current draw from the battery are good fit. The ability to control interfacing with memory and peripheral devices will be helpful.</p><p>Given the nature of the device, processors that can manage the digital display and keyed functions allowing auscultation waveforms to be displayed and manipulated without additional components are ideal.</p><p>• Data Storage and Transmission: The auscultations can be recorded on MMC/SD card, or on a USB device. It can also be transmitted via wireless capability such as Bluetooth ® and wireless transmission communication protocols such as IEEE 802.14 communication standards. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">VISUAL ELECTRONIC STETHOSCOPE</head><p>Another variation of the digital stethoscope is the visual electronic stethoscope system (VES) which is considered a cutting-edge technology in modern auscultation instrumentation. The basic configuration of the multifunction stethoscope unit which mean it is capable of recording analysis and output preliminary diagnostic index for a clinical cardiac test paradigm. The prototype of this device is shown in Fig. <ref type="figure">5</ref>.10, which is developed by Contec Medical System Co. Ltd. CMS, Hukun, China. The first version of this stethoscope was based on the simple implementation of FFT in the signal processing chain with single channel buffering unit.</p><p>The direct display of PCG waveform on LCD, accompanied with other cardiac physiological parameters, is one of the attractive points in design. Further development and research toward a front-end cardiac visual stethoscope to map the four-auscultation sites on the thorax. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">SUMMARY</head><p>The main points of this chapter are as follows.</p><p>1. The spectral PCG signal analysis is an energetic tool for inspection of various cardiovascular disorders and their characteristics associated with variation in spectral attributes.</p><p>2. The two categories of spectral signal processing parametric and non-parametric, show interesting uses for detection of early and late cardiac diastolic index for several pathological conditions.</p><p>3. All the heart sound components, i.e., S 1 , S 2 , S 3 , murmurs, and sound splits, were clearly separated in time and frequency. High resolution of generated heart sound images, in both time and pitch, are demonstrated, presenting a distinctly improved quality to classical spectrogram images (based on SFFT).</p><p>The resulting visual images have self-referencing quality, whereby particular features and their changes become obvious at once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">SUMMARY 107</head><p>4. characterization of heart sounds and uses both visual images derived from spectral plot and a system of integral plots that characterize time averaged and instantaneous sound intensity and frequency variations.</p><p>5. The digital stethoscope utilizes several spectral PCG signal processing in order to enhance its performance and ability to immediate diagnosis several hemodynamic disorders.</p><p>C H A P T E R 6</p><p>PCG Pattern Classification</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">INTRODUCTION</head><p>PCG pattern classification, also known as auscultation pattern recognition, was one of the efficient computer-based methods applied to a medical decision-making system. The PCG classification, naturally, is based upon heart sound features. These PCG features can be represented as a set of electrical measurement of cardiac acoustic observations. These measurements can also be represented in vector notation. Data features may also result from applying a feature extraction algorithm or operator to the input PCG data set. Significant computational effort may be required in feature extraction and the extracted features may contain errors or noise. Features may be represented by continuous, discrete, or discrete-binary variables.</p><p>Figure <ref type="figure">6</ref>.1 presents the substantial block diagram of phonocardiography pattern classification method, the input of the system is the physiological signal, which represented here is the phonocardiography acoustic signal (X pcg (t)) as a function of time. While the output of pattern recognition system could be statistical or syntactic representation, it depends on which computational method is used for feature extraction. Generally, PCG Pattern recognition is interpreted in two ways. The most general definition includes recognition of patterns in any type of PCG dataset and is called uniform PCG pattern classification. It discriminates peaks of heart sounds as excitation source for circulation hemodynamic, and is also called adaptive pattern clustering which magnifies and observes the spectral characteristics associated with PCG waveform turbulences and differentiate between them as clinical diagnostic indices or auscultation features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">PCG PATTERN CLASSIFICATION METHODS</head><p>PCG spectra contain a vast number of definite harmonics categories that would be useful in identifying clustering scheme in any data classification algorithms. The majority of these spectra belong to specific valvular pathologies having a distinct energy (intensity) level in STFT plot. This would be an attractive point to consider such variation as clustering point.</p><p>Considerably, this will orientate the classifier algorithm to a stable entropy value. The spectral information characteristics of PCG lie within a frequency band of 54-520 Hz and this band depends on digital stethoscopic interface and resolution of data converters in instrumentation platform.</p><p>This criteria is considered as an essential basis for PCG pattern classification technique in which the dependency on frequency (spectral) characteristics can be identified.</p><p>A block diagram for overall spectral classification system is demonstrated in Fig. <ref type="figure">6</ref>.2 <ref type="bibr" target="#b80">[81]</ref>, where several patterns can be derived from the vector input PCG signal, in which they process with a specific FIR-filter length. The most recognized patterns in PCG are systolic and diastolic and presystolic and post-diastolic peaks of sound (S 1 , S 2 , S 3 , and S 4 ). Most cardiologists prefer the base diagnosis of PCG signal, which is based on the two distinct peaks of PCG: S 1 and S 2 . Therefore, they can discriminate the hemodynamics turbulences in the appropriate method. Additionally, they can sue the spectra stamp which can be oriented in three schema (supraspectra, infraspectra, and mid-spectra). These spectral segments represent the intensity harmonics for PCG waveform over defined time interval.</p><p>Correlation between two intensity peaks of PCG gives a defined index for clustering profile M j -P CG of PCG signal which in turn applies a segmental cluster for input vector <ref type="bibr" target="#b80">[81]</ref>.</p><p>Systolic and diastolic murmur frequencies are classified according to the frequency band containing the largest power value in the tenth (s) of the systole/diastole, corresponding to the found maximum values of systolic interval (SI) and the diastolic interval (DI) (SI/DI). If the largest power value is found in one of the two lowest frequency bands (containing frequencies below 125 Hz), the murmur is classified as a low-frequency murmur. If the largest power value is found in one of the eight highest frequency bands (containing frequencies above 250 Hz), the murmur is classified as a high-frequency murmur. If none of the above is the case, the murmur is classified as a medium-frequency murmur <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">K-MEANS CLUSTERING METHOD 111</head><p>Figure <ref type="figure">6</ref>.2: PCG signal pattern classification method as integrated in clinical-aided diagnosis system; during the first stage, the separation of systolic and diastolic component by aiding a wavelet-decomposition method, with definition of hyperplane using K-mean clustering technique. The complete analysis can be performed on medical console and the data can be transmitted to remote personal digital assistance (PDA) terminal through a wireless (Wi-Fi) communication protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">K-MEANS CLUSTERING METHOD</head><p>K-means clustering <ref type="bibr" target="#b65">[66]</ref> differs in two important aspects from hierarchical clustering. Firstly, the K-means clustering requires the number of clusters-k beforehand. Secondly, it is not a hierarchicalbased method; instead, it partitions the data set into (K) disjoint subsets. Again, the clustering is basically determined by the distances between objects. The K-means algorithm has the following structure: Algorithm applied to the PCG data vectors: K-means clustering approach; 1. Assign each object randomly to one of the clusters k=1,. . .,K.  The initialization step can be adapted to speed up the convergence. Instead of randomly labeling the data, K randomly chosen objects are taken as cluster means. Then the procedure enters the loop in step 3. Note again that the procedure depends on distances, in this case between the objects z i and the means μ k . Scaling the feature space will here also change the final clustering result.</p><p>An advantage of K-means clustering is that it is very easy to implement. On the other hand, it is unstable: running the procedure several times will give several different results. Depending on the random initialization, the algorithm will converge to different (local) minima.</p><p>In particular, when a high number of clusters is requested, it often happens that some clusters do not gain sufficient support and are ignored. The effective number of clusters then becomes much less than K.</p><p>In Fig. <ref type="figure">6</ref>.3 the result of a K-means clustering is shown for a simple 2D data set representation. The means are indicated by the circles. At the start of the optimization, i.e., at the start of the trajectory, each mean coincides with a data object. After 10 iteration steps, the solution converged. The result of the last iteration is indicated by (x). In this case, the number of clusters in the data and the predefined K=3 match. A fairly stable solution is found. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">FUZZY C-MEANS CLASSIFICATION ALGORITHM</head><p>Fuzzy systems are currently finding practical applications, ranging from (soft) regulatory control in a variety of consumer (e.g., automotive, electro-mechanical, air-vacuum machine products, to accurate modeling of non-linear systems such as missile-guidance system, patient-ventilation device, cardiac pacemaker system, insulin-pumping unit <ref type="bibr" target="#b86">[87]</ref>. Recently, a vast number of research focusing on analysis and pattern classification of biosignals based on fuzzy clustering methods; multi-resolution signal analysis and hybrid neuro-fuzzy network.</p><p>The development of the fuzzy c-means algorithm (FCM) <ref type="bibr" target="#b85">[86,</ref><ref type="bibr" target="#b87">88]</ref> was the birth of all clustering techniques corresponding to probabilistic clustering algorithm. The first version developed by Duda and Hart <ref type="bibr" target="#b79">[80]</ref>, by which they performed a hard cluster partition corresponding to definition of data cluster partition (hard c-means or hard ISODATA algorithm). In order to treat data belonging to several clusters to the same extent in an appropriate manner, Dunn <ref type="bibr" target="#b86">[87]</ref> introduced a fuzzy version of this algorithm.</p><p>It was generalized once more in the final version by Bezdek <ref type="bibr" target="#b87">[88]</ref> and his introduction of the data fuzzifier module. The resulting fuzzy c-means algorithm recognizes spherical clouds of points in a p-dimensional space, which represents the phonocardiography data channels from at least a two-channel description.</p><p>The clusters are assumed to be of approximately the same size. Each cluster is represented by its center. This representation of a cluster is also called a prototype, since it is often regarded as a representative of all data assigned to the cluster. As a measure for the distance, the Euclidean distance between a datum and a prototype is used.</p><p>The c-mean fuzzy clustering algorithm, is discussed here, was based on objective functions ( J), which are mathematical criteria that quantify the goodness of cluster models that are comprised of prototypes and data partition.</p><p>Objective functions serve as cost functions that have to be minimized to obtain optimal cluster solutions. Thus, for each of the following cluster models the respective objective function expresses desired properties of what should be regarded as (best) results of the cluster algorithm.</p><p>In fuzzy clustering approach, the PCG data clustering have to be parameterized into four distinct criteria: intensity, frequency, spectral variation, and phase-shift. These criteria allow the partitioning of different clusters into an optimal cluster solution and for more than two classification of heart sounds specifications.</p><p>Having defined such a criterion of optimality, the clustering task can be formulated as a function optimization problem. That is, the algorithms determine the best decomposition of a dataset into a predefined number of clusters by minimizing their objective function. The steps of the algorithms follow from the optimization scheme that they apply to approach the optimum of ( J).</p><p>Thus, in this presentation of the hard, fuzzy, and possibilistic c-means the respective objective functions first were discussed. In fuzzy clustering, each point has a degree of belonging to clusters, as in fuzzy logic, rather than belonging completely to just one cluster. Thus, points on the edge of a cluster, may be in the cluster to a lesser degree than points in the center of cluster. For each point (x) there is a coefficient giving the degree of being in the k th cluster u k-P CGsignal (x). Usually, the sum of those coefficients is defined to be unity-value:</p><formula xml:id="formula_71">∀x N k=1 u k(P CG-signal) (x) = 1 (6.1)</formula><p>according to the fuzzy c-means approach, the centroid of a PCG-data vector cluster is the mean of all data points, weighted by their degree of likelihood to the cluster (N). For the definition of cluster centroid, which is the principal step in c-mean classification technique:</p><formula xml:id="formula_72">C k = x-P CG u k (x) m x x-P CG u k (x) m . (6.2)</formula><p>Then the degree of likelihood (similarity) is related to the inverse of the distance to the data cluster center</p><formula xml:id="formula_73">u k-P CG (x) = 1 d(C k-P CG , x) , (<label>6.3)</label></formula><p>hence the coefficients are normalized and fuzzified with a real parameter (m = 1), so that their sum is ( <ref type="formula">1</ref>)</p><formula xml:id="formula_74">u k-P CG (x) = 1 j d(C k-P CG ,x) d(C k-P CG ,x) 2/(m-1) . (6.4)</formula><p>For m=2, this is equivalent to normalizing the coefficient linearly to make their sum 1. When m is close to 1, then the cluster center closest to the point is given much more weight than the others, and the algorithm is similar to k-means algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">PRINCIPAL COMPONENT ANALYSIS (PCA)</head><p>The main purpose of principal component analysis (PCA) is to reduce the dataset dimensionality from (p) to (d), where d &lt; p, while at the same time accounting for as much of the variation in the original data set as possible. With PCA, we transform the data to a new set of coordinates or variables that are a linear combination of the original variables. In addition, the observations in the new principal component space are uncorrelated. The hope is that this could gain information and understanding of the data by looking at the observations in the new space. PCA is mathematically defined <ref type="bibr" target="#b84">[85]</ref> as an orthogonal linear transformation that transforms the data to a new coordinate system such that the greatest variance by any projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on. PCA is theoretically the optimum transform for a given data in least square terms.</p><p>PCA can be used for dimensionality reduction in many biomedical and clinical data sets by retaining those characteristics of the data set that contribute most to its variance, by keeping lowerorder principal components, and by ignoring higher-order ones. Such low-order components often contain the (most important) aspects of the data. However, depending on the application this may not always be the case.</p><p>The complete block diagram of principal component analysis technique (PCA) for the phonocardiography signal (PCG) is shown in Fig. <ref type="figure">6</ref>.4, as a assisted clinical data classification module, which implemented in the ICU-online patient monitoring system. The application of PCA-analysis in For a PCG-data matrix, X T P CG , with zero empirical mean (the empirical mean of the distribution has been subtracted from the data set in previous filtering stage), where each row represents a different repetition of the auscultation experiment, and each column gives the results from a particular probe, the PCA transformation is given by:</p><formula xml:id="formula_75">Y T = X T P CG W = V , (6.5)</formula><p>where V W T is the singular value decomposition (SVD) of X T . PCA algorithm has the distinction of being the optimal linear transformation for keeping the subspace that has largest variance value. This advantage, however, comes at the cost of greater computational efficiency if compared, for example, to the discrete cosine transform (DCT). Figure <ref type="figure">6</ref>.5 shows the performance results for PCA algorithm applied to phonocardiography signals data vectors, where the above two plots display the signal inference index (SIR) for the seven PCG set indicating a robustness in discrimination of temporal variation in PCG signal.</p><p>The straightforward implementation of PCA-algorithm in different computational platform makes it attractive for different biomedical and biosignals higher-order classification and pattern recognition application. Moreover, the ability of PCA algorithm to reduce the clinical data high dimensionality, which may consume a vast amount of memory during continuous/real-time monitoring and recorded of the physiological signals. This make PCA-algorithm a favorable choice, for medical data abstraction system and in prototyping clinical decision making system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">HIGHER-ORDER STATISTICS PCG CLASSIFICATION PCG-HOS</head><p>Higher-order statistics (HOS) measures are extensions of second-order measures (such as the autocorrelation function (ACF) and power spectrum (PS)) to higher orders. The second-order measures work fine if the signal has a Gaussian (normal) probability density function, but as mentioned above, many real-life signals are non-Gaussian.</p><p>The easiest way to introduce the HOS measures is just to show some definitions, so that the reader can see how they are related to the familiar second-order measures. Here are definitions for the time-domain and frequency-domain third-order HOS measures, assuming a zero-mean, discrete signal x(n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time domain measures:</head><p>In the time domain, the second-order measure is the autocorrelation function,</p><formula xml:id="formula_76">R(m) = x(n)x(n + m) , (6.6)</formula><p>where &lt;&gt; is the expectation statistics operator. The third-order measure is called the third-order moment M(m1, m2) = x(n), x(n + m1), x(n + m2) . (6.7)</p><p>Note that the third-order moment depends on two independent lags, m1 and m2. Higher-order moments can be formed in a similar way by adding lag terms to the above equation. The signal cumulants can be easily derived from the moments. The bottom graph represents decomposed PCG trace with PCA-algorithm, according to Eq. 6.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frequency domain measures:</head><p>In the frequency domain, the second-order measure is called the power spectrum P(k), and it can be calculated in two ways:</p><p>• Taking a Discrete Fourier Transform (DFT) of the autocorrelation function R(m); P(k)=DFT[R(m)];</p><p>or:</p><p>• Multiplying together the signal Fourier Transform X(k) with its complex conjugate; P(k)=X(k) X*(k)</p><p>At third-order the bispectrum B(k,l) can be calculated in a similar way:</p><p>• Taking a Double Discrete Fourier Transform (DDFT) of the third-order cumulant; B(k,l)=DDFT[M(m1,m2)];</p><p>or:</p><p>• Form a product of Fourier Transforms at different frequencies:</p><formula xml:id="formula_77">B(k, l) = X(k)X(l)X * (k + l). (<label>6.8)</label></formula><p>The main parameters to be consider when dealing with (HOS) pattern classification which can summarized as below:</p><p>• Moments: Moments are statistical measures which characterize signal properties. We are used to using the mean and variance (the first and second moments, respectively) to characterize a signal's probability distribution, but unless the signal is Gaussian (Normal) then moments of higher orders are needed to fully describe the distribution. In practice, in HOS we usually use the cumulants rather than the moments.</p><p>• Cumulants: The n th order cumulant is a function of the moments of orders up to (and including) (n). For reasons of mathematical convenience, HOS equations/discussions most often deal with a signal's cumulants rather than the signal's moments.</p><p>• Polyspectra: This term is used to describe the family of all frequency-domain spectra, including the second order. Most HOS work on polyspectra focusing attention on the bispectrum (thirdorder polyspectrum) and the trispectrum (fourth-order polyspectrum).</p><p>• Bicoherence: This is used to denote a normalized version of the bispectrum. The bicoherence takes values bounded between 0 and 1, which make it a convenient measure for quantifying the extent of phase coupling in a signal. The normalization arises because of variance problems of the bispectral estimators for which there is insufficient space to explain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">INDEPENDENT COMPONENT ANALYSIS (ICA) METHOD</head><p>The ICA approach and blind signal extraction methods are promising techniques for the extraction of useful signals from the EEG, ECG, EMG, and PCG recorded raw data as well. The ECG/PCG data can be first decomposed into useful signal and noise subspaces using standard techniques like local and robust principal component analysis (PCA), singular value decomposition (SVD), and nonlinear adaptive filtering.</p><p>The ICA approach enables us to project each independent component (independent "cardiac acoustic source") onto an activation map at the thorax level. For each acoustic activation map, an ECG/PCG source localization procedure can be performed, looking only for a single source (or dual source) per map. By localizing multiple dipoles independently, dramatic reduction of the complexity of the computation, and increase the likelihood of efficiently converging to the correct and reliable solution.</p><p>The concept of independent component analysis (ICA) lies in the fact that the signals may be decomposed into their constituent independent components. In places where the combined source signals can be assumed independent from each other, this concept plays a crucial role in separation and denoising the signals. A measure of independence may easily be described to evaluate the independence of the decomposed components. Generally, considering the multichannel signal as y(n) and the constituent signal components as y i (n), the y i (n) are independent if:</p><formula xml:id="formula_78">P Y (y(n)) = m i=1 p y (y i (n)), for all n,<label>(6.9)</label></formula><p>where P Y is the joint probability distribution, p y (y i (n)) are the marginal distributions, and m is the number of independent components. An important application of ICA is in blind source separation (BSS). BSS is an approach to estimate and recover the independent source signals using only the information of their mixtures observed at the recording channels.</p><p>Due to its variety of applications, BSS has attracted much attention recently. BSS of acoustic signals is often referred to as the (cocktail party problem) <ref type="bibr" target="#b82">[83]</ref>, which means separation of individual sounds from a number of recordings in an uncontrolled environment such as a cocktail party. As expected, ICA can be useful if the original sources are independent, i.e.,</p><formula xml:id="formula_79">(p(s(n)) = m i=1 p i (s i (n))). (<label>6.10)</label></formula><p>A perfect separation of the signals requires taking into account the structure of the mixing process. In a real-life application, however, this process is unknown, but some assumptions may be made about the source statistics. Generally, the BSS algorithms do not make realistic assumptions about the environment in order to make the problem more tractable. There are typically three assumptions about the mixing medium. The most simple but widely used case is the instantaneous case, where the source signals arrive at the sensors at the same time.</p><p>Figure <ref type="figure">6</ref>.6 displays the interconnection diagram of ICA-PCG signals classification escorted with localization of sound sources based on active switching of multichannel acquisition system. In addition, the auto-generated annotation mechanism will be implemented in this ICA-decomposition model too. This configuration was also integrated in clinical decision making profile, which will be used widely in modern medical instrumentation platforms. This has been considered for separation of biological acoustic signals such as the PCG, where the signals have narrow bandwidths and the sampling frequency is normally low. The BSS model in this case can be easily formulated as follows:</p><formula xml:id="formula_80">x(n) = H.s(n) + v(n) (6.11)</formula><p>where m ×1 s(n), n e ×1 x(n), and n e ×1 v(n) denote, respectively, the vectors of source signals, observed signals, and noise at discrete time (n). H is the mixing matrix of size n em . The separation is performed by means of a separating m×ne matrix, W, which uses only the information about x(n) to reconstruct the original source signals (or the independent components) as follows:</p><formula xml:id="formula_81">y(n) = W.x(n). (<label>6.12)</label></formula><p>In acoustic applications, however, there are usually time lags between the arrival of the signals at the sensors. The signals also may arrive through multiple paths. This type of mixing model is called a convoluting model which is demonstrated in Fig. <ref type="figure">6</ref>.6 where an adaptive ICA algorithm and preweighting function g(y 1 ) are used together to output classified PCG vector. One example is in places where the acoustic properties of the environment vary, such as a room environment surrounded by walls, or nearby vibration sources. Based on these assumptions, the convoluting mixing model can be classified into two more types: anechoic and echoic. In both cases, the vector representations of mixing and separating processes are changed to x(n)=H(n) * s(n)+v(n) and y(n)=W(n) * x(n), respectively, where ( * ) denotes the convolution operation. In an anechoic model which is in this case the phonocardiography auscultation, however, the expansion of the mixing process may be given as:</p><formula xml:id="formula_82">x i (n) = M j =1 h ij s j (n.δ ij ) + v i (n), for i=1,. . .,N,<label>(6.13)</label></formula><p>where the attenuation, h ij , and delay, δ ij , of source (j) to sensor (i) would be determined by the physical position of the source relative to the sensors. Then the unmixing process will be given as:</p><formula xml:id="formula_83">y i (m) = M j =1</formula><p>w ij x i (mδ ij ), for i=1,. . .,M, (</p><p>where the w ji 's are the elements of (W). In an echoic mixing environment, it is expected that the signals from the same sources reach to the sensors through multiple paths. Therefore, the expansion of the mixing and separating models will be changed to the following mode:</p><formula xml:id="formula_85">x i (n) = M j =1 K k=1 h k ij s j (n -δ k ij ) + v i (n), for i=1,. . .,N,<label>(6.15)</label></formula><p>where K denotes the number of paths and v i (n) is the accumulated noise at cardiac sensor (i). The unmixing process will be formulated similarly to the anechoic one. Obviously, for a known number of signal sources an accurate result may be expected if the number of paths is known. The aim of BSS using ICA is to estimate an unmixing matrix (W) such that Y=W.X best approximates the independent sources S, where Y and X are, respectively, matrices with columns y</p><formula xml:id="formula_86">(n)=[y 1 (n), y 2 (n), . . . , y m (n)] T and x(n)=[x 1 (n), x 2 (n), . . . ,x n e(n)] T .</formula><p>In any case, the unmixing matrix for the instantaneous case is expected to be equal to the inverse of the mixing matrix, i.e., W=H -1 . However, in all ICA's algorithms based upon restoring independence, the separation is subjected to permutation and scaling ambiguities in the output independent components, i.e., W=PDH -1 , where P and D are the permutation and scaling matrices, respectively. ICA performance analysis results and the S 1 , S 2 separation scheme is shown in Fig. <ref type="figure">6</ref>.8 where the signal inference ration (SIR) and 3D performance matrix were presents (above) and the spectral profile of first and second heart sound of successive two heart cycle were presents (below) by defining frequency and PCG interval against time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8">PCG CLASSIFICATION BASED ON ARTIFICIAL NEURAL NETWORK (ANN)</head><p>Artificial neural networks (ANN) are valuable tools used in complex pattern recognition and classification tasks. They are semi-parametric, data-driven models capable of learning complex and highly non-linear mappings. As an ANN can assimilate subtleties that may not be apparent in an explicit fashion for human analysis, there is possibility of an ANN model to improve the accuracy of diagnosis-performance in medical care problems.</p><p>More recently, investigators have attempted to perform diagnostic analysis of phonocardiograms applying the interpretive methods used by physicians. A team from the University of Paderborn (Germany) has attempted to apply wavelet analysis techniques for processing heart sounds to obtain information considered useful by physicians in auscultation <ref type="bibr" target="#b83">[84]</ref>. In their investigation, a neural network was utilized as an aid in processing the phonocardiogram to derive parameters of importance in clinical diagnosis. With a limited data set, the investigators were able to demonstrate the value of their approach. Other investigators have delved into joint-time frequency analysis for diagnostic assessment of phonocardiography signals <ref type="bibr" target="#b86">[87,</ref><ref type="bibr" target="#b87">88]</ref>, with primary results of limited consequence. Within a neural network, the links among units are locally stored as inherent rules, either explicitly or implicitly, when they are expressed analytically. Each unit alone has certain simple properties, but when interacting with each other, such as cooperating and competing, a neural network as an entity is able to complete many complex computational tasks.</p><p>A general architecture for neural networks is shown in Fig. <ref type="figure">6</ref>.9. The processing within a neural network may be viewed as a functional mapping from input space to output space. In principle, a unit in a neural network can be represented using a mathematical function, and the weights associated with the unit can be represented in forms of coefficients of that function.</p><p>The functional aggregation among different units, which creates the mapping from input to output space, is determined through both algorithm and architecture of a neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.1">GENERAL CONCEPT OF ANN</head><p>Since the early days of computer science it has become evident that conventional computers lack certain abilities that every human being possesses. In particular, these machines do not display a form of intelligent behavior. There have been two approaches geared at improving this situation. One is based on symbolism and the other one is based on connectionism. The former approach models intelligence in terms of computer programs which are able to manipulate symbols given a certain amount of (knowledge) and following a certain set of rules.</p><p>The connectionist approach to introducing intelligence to computer systems relies on the hope that it is possible to model the structure of the biological neural systems such as the human brain. A biological nervous system consists of a network of neurons which continually receive and transmit signals. A simple model of a biological neuron, consists of a processing element receiving several inputs.</p><p>In Fig. <ref type="figure">6</ref>.9, the symbols x 1 , ...,x n represent the strengths of (1xn) the impulses. The synaptic weights or connection strengths-denoted by the symbols w 1 ,...,w n -interpret the role that the synapses play in the transmission of impulses. The output signal is represented by the symbol (y). The dependence of the output y on the inputs x 1 , ...,x n is given by the following rule: where θ is a threshold value or bias and f is the neuron's activation function. One of the most commonly used activation functions is the Heaviside step function (Dirac delta function), in some terminology given by f : R → R</p><formula xml:id="formula_87">y = f n i=1 w i .x i -θ , (<label>6.16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H (x) =</head><p>x inf δ(t)dt. (6.17)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.2">NEURAL NETWORK TOPOLOGIES</head><p>The neurons in an artificial neural network are sometimes also called nodes or units. The topology of a neural network refers to its framework and its interconnection scheme. In many cases, the framework of a neural network consists of several layers of nodes. The literature on neural networks distinguishes between the following types of layers:</p><p>• Input Layer: A layer of neurons which receive external input from outside the network.</p><p>• Output Layer: The layer of neurons which produces the output of the network.</p><p>• Hidden Layer: A layer composed of neurons whose interaction is restricted to other neurons in the network.</p><p>A neural network is called a single-layer neural network if it has no hidden layers of nodes, or equivalently if it has just one layer of weights. A multilayer neural network is equipped with one or more hidden layer of nodes. A feed forward neural network refers to a neural network whose connections point in the direction of the output layer.</p><p>A recurrent neural network has connections between nodes of the same layer and/or connections pointing in the direction of the input layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.3">PCG DIAGNOSIS WITH SELF-ORGANIZING MAPPING (SOM)</head><p>In a self-organizing map (SOM), in reference to Kohonen et al. <ref type="bibr" target="#b88">[89]</ref>, the neurons are placed at the nodes of a lattice, and they become selectively tuned to various input patterns (vectors) in the course of a competitive learning process.</p><p>The process is characterized by the formation of a topographic map in which the spatial locations (i.e., coordinates) of the neurons in the lattice correspond to intrinsic features of the input patterns. Figure <ref type="figure">6</ref>.10 illustrates the basic idea of an SOM, assuming the use of a two-dimensional lattice of neurons as the network structure. In reality, the SOM belongs to the class of vector coding algorithms <ref type="bibr" target="#b89">[90]</ref>; that is, a fixed number of code words are placed into a higher-dimensional input space, thereby facilitating data compression.</p><p>An integral feature of the SOM algorithm is the neighborhood function centered around a neuron that wins the competitive process. The neighborhood function starts by enclosing the entire lattice initially and is then allowed to shrink gradually until it encompasses the winning neuron. The algorithm exhibits two distinct phases in its operation.</p><p>1. Ordering phase, during which the topological ordering of the weight vectors takes place.</p><p>2. Convergence phase, during which the computational map is fine tuned.</p><p>Generally, the SOM algorithm exhibits the following properties.</p><p>1. Approximation of the continuous input space by the weight vectors of the discrete lattice.</p><p>2. Topological ordering exemplified by the fact that the spatial location of a neuron in the lattice corresponds to a particular feature of the input signal pattern.</p><p>3. The feature map computed by the algorithm reflects variations in the statistics of the input distribution.</p><p>4. SOM may be viewed as a nonlinear form of principal components analysis (PCA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.4">SELF-ORGANIZATION PRINCIPLE</head><p>Self-organizing in networks is one of the most fascinating topics in the neural network field. Such networks can learn to detect regularities and correlations in their input and adapt their future responses to that input accordingly. The neurons of competitive networks learn to recognize groups of similar input vectors. Self-organizing maps learn to recognize groups of similar input vectors in such a way that neurons physically near each other in the neuron layer respond to similar input vectors. The weight matrix of the SOM can be computed iteratively as the progress of neural network training epoch were determined, Fig. <ref type="figure">6</ref>.12 illustrates SOM weighting matrix which are used to classify PCG-signals. Self-organizing feature maps topologically emulate salient features in the input signal space at the neural network output without explicitly using supervision or even reinforcement of correct output behavior. The network's output neurons are usually conveniently arranged in single one-dimensional or two-dimensional layers. Full connectivity to the inputs is tacitly assumed. Lateral positive and negative feedback connections are also applied to help in convincingly deciding the outcome o f competitive learning. Winning a competition lets a specific output neuron reach (on state) and thus updates its weights and the weights of its surrounding neighborhood. Normalization of all weights, in addition to controlling the size of surrounding neighborhoods, usually improves the network performance by equalizing the relative changes in weight connections.</p><p>Neuron activities and interactions can be represented by a set of discrete nonlinear mathematical equations, as proposed by Kohonen <ref type="bibr" target="#b88">[89]</ref>. Therefore, the strengths of interconnecting weights are expressed in an n×m weight matrix W(k), and the lateral feed-back coefficients are similarly collected in an n×n matrix C, which has a symmetrical band structure.</p><p>Furthermore, the width of this band structure determines the effective size of neighborhoods surrounding each output neuron: Let n be the total number of output layer neurons, and let Y(k)∈R be the neuron outputs at the kth discrete iteration step. Let X(k)∈R m and U(k)∈R n be the input stimuli vector and the net weighted sum. Finally, consider a nonlinear activation function designated by: : R n → R n . Then the output neuron activity is modeled with following:</p><formula xml:id="formula_88">Y (k + 1) = φ[V (k)] (6.18) V (k) = U(k) + βC(k)Y (k) (6.19) U(k) = W (k)X(k) (6.20)</formula><p>and (β) reflects a scalar relaxation factor that increases or decreases the effect of lateral feedback connections. The set of Eqs. (6.18)-(6.20), may be solved assuming typical center-surrounding input vector patterns X(k). Considerable simplification is effected if is taken to be piecewise linear and if</p><formula xml:id="formula_89">C(k) = C.</formula><p>These assumptions produce an emergent output neuron behavior that amounts to be omitted lateral feedback and using a variable-size surrounding neighborhood that depends on k. The concept of neighborhood allows gradually decoupling topological groups of output layer neurons, which is similar to fuzzy system membership functions. Figures 6.12 and 6.13 display the weight's plot of four PCG signal vectors by using centersurrounding input vector as reference pattern for SOM network training, which results in spatial distribution of PCCG patterns according to the intensity of the signal and its associated temporal characteristics variations. For advanced application of PCG-SOM data clustering, which can be used to identify gradations of murmurs and other heart sounds disorders, Figs. 6.14 and 6.15(a) shows the weights plot of six different PCG data vector of different valvular hemodynamic conditions. The color labeling of each PCG vector was assigned in the correlation matrix plot in Fig. <ref type="figure">6</ref>.15(b). The weight's matrix represents the degree of probabilistic mapping of input PCG signal vectors, in which the dense areas of the plot indicate that the network energy have a high level. This also reflects the classified pattern clustered in this high energy zones.</p><p>Self-organizing maps differ from conventional competitive learning in terms of which neurons get their weights updated. Instead of updating only the winner, feature maps update the weights of the winner and its neighbors. The result is that neighboring neurons tend to have similar weight vectors and are responsive to similar input vectors. The SOM technique, appears to be a robust technique in classifying the phonocardiography signals, in spite of it's complex characteristics and computational efforts cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.9">BAYES CLASSIFIER</head><p>Bayesian classifier, sometimes referred to as Naive Bayes classifier, pointed to statistics dealing with a simple probabilistic classifier based on applying Bayes' theorem with strong independence assumptions. A more descriptive term for the underlying probability model would be (independent feature model).</p><p>For simplification, a naive Bayes classifier assumes that the presence (or absence) of a particular feature of a class is unrelated to the presence (or absence) of any other feature, e.g., a ball may be considered to be an geometric-shape if it is round, and have the same diameter for each point on its surface. Even though these features depend on the existence of the other features, a naive Bayes classifier considers all of these properties to independently contribute to the probability that this shape is a ball.</p><p>Depending on the precise nature of the probability statistics model, naive Bayes classifiers can be trained very efficiently in a supervised learning scheme. In many practical applications, parameter estimation for naive Bayes models uses the method of maximum likelihood; in other words, one can work with the naive Bayes model without believing in Bayesian probability or using any Bayesian methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.9.1">PCG SIGNAL BAYESIAN PARAMETER ESTIMATION</head><p>All Bayes model parameters (i.e., class priors and feature probability distributions) can be approximated with relative frequencies from the training set.These are maximum likelihood estimates of the probabilities. Non-discrete features need to be discretized first. Discretization can be unsupervised (ad-hoc selection of bins) or supervised (binning guided by information in training data).</p><p>If a given class and feature value never occur together in the training set, in this case the presence of PCG S 1 and S 2 then the frequency-based probability estimate will be zero.</p><p>This is problematic since it will wipe out all information in the other probabilities when they are multiplied, when the repetition of cardiac cycle may occur in random sequence or in semi-linear profile. It is therefore often desirable to incorporate a small-sample correction in all probability estimates such that no probability is ever set to be exactly zero.</p><p>Generally speaking the derivation of the independent feature model, that is, the naive Bayes probability model.</p><p>The naive Bayes classifier combines this model with a decision rule. One common rule is to pick the hypothesis that is most probable; this is known as the maximum a posteriori or MAP decision rule. The corresponding classifier is the function classify defined as follows:</p><formula xml:id="formula_90">(f 1 , ..., f 2 ) = argmax c p(C = c) n i=1 p(F i = f i |C = c) .</formula><p>(6.21)</p><p>In Eq. (6.21), the denotes as the classification scheme of given dataset p(F i ). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.10">PHONOCARDIOGRAPHY HEMODYNAMIC IDENTIFICATION</head><p>The adaptive k-mean clustering relates to a procedure for extracting information from a PCG signal obtained from a cardiac acoustic transducer and subjected to signal processing in order to aid evaluation and diagnosis of heart conditions. The method furthermore relates to techniques forming part of such extraction and apparatus to perform such feature extraction as well as coding the features to aid the ability to distinguish between related features. Signals obtained by means of a transducer are phonocardiographic representations of sounds traditionally listened to by means of a stethoscope.</p><p>Training in auscultation takes a long time and requires an aptitude for recognizing and classifying aural cues, frequently in a noisy environment.Twenty to thirty different conditions may need to be differentiated, and within each, the severity evaluated. Furthermore, there may be combinations among these. These factors contribute to explaining why not all physicians perform equally well when diagnosing heart conditions, and why it may be time-cost operation.</p><p>One of the interesting hemodynamic parameter estimation methods was achieved by phonocardiography, where the PCG signal act as a derivative for intra-cardiac pressure, by which we can considering the acceleration variable as second derivative of mechanical displacement or (pressure) and we can summarize the main aspects of this method by the following:</p><p>1. The phonocardiogram in this approach was internally recorded by using cardiovascular catheterization method, as this method will be discussed in next section in intra-cardiac phonocardiography acquisition.</p><p>2. The order of the signal derivative depends on the microphone-transducer type of mechanical energy conversion profile (displacement, velocity, acceleration).</p><p>3. There is a good similarity between the LV phonocardiogram and the LVP second derivative, and between the aortic phonocardiogram and the aortic pressure second derivative.</p><p>4. Dual integration of the PCG-signal can be useful for intra-cardiac pressure estimation, or at least may provide a good feature vector for estimating the pressure using advanced statistical technique.</p><p>The so-called first (S 1 ) and second (S 2 ) heart sound are very important markers in the assessment of a heart sound signal. These sounds are directly related to the functioning of the heart valves, in that S 1 is caused by the closure of the atrioventricular valves and contraction of the ventricles and S 2 is caused by the closure of the aortic and pulmonary valves. A number of techniques are relate to the extraction of the S 1 and S 2 signals, such as Kimberly methods and Wiener-Fassbinder technique <ref type="bibr" target="#b90">[91]</ref>, which concerns the measurement of the time interval between the S 1 and S 2 signals in relation to the heart rate in order to determine the degree of coronary artery disease. The measurement is based on peak detection and autocorrelation and it may be considered a relatively slow process.</p><p>The detection of S 1 and S 2 is obtained by performing the steps of feature extraction and classification based on the energy distribution over time in a feature time function. The feature extraction is performed by the steps of bandpass filtering, followed by instantaneous power and lowpass filtering. This generates a series of signal peaks or (hills), each relating to either an S 1 or an S 2 , and a signal classification step determines which (hill) is to be regarded as either an S 1 or an S 2 , whereby a systole is correctly identified a different category of signals related to various cardiac hemodynamic conditions is generally known as murmurs. The known procedures of isolating and categorizing murmurs are generally dependent on the simultaneous recording of electrocardiographic (ECG) data, by using electronic stethoscope acquisition system such as, Medtronic</p><p>® and Philips ® MS-Trend2300, and this complicates the practical use of auscultation techniques considerably. The above solutions are very complex and rely on techniques that are equivalent to a long averaging time. According to the research by author, a method has been derived which is more precise and obtains a faster result. This is obtained by a sequence of steps, comprising an optional adaptive noise reduction, detection of S 1 and S 2 , e.g., by means of the feature extraction procedure mentioned above, enhancement of the signal by elimination of the S 1 and S 2 contributions, performing spectral analysis and feature enhancement in order to obtain the energy content present in areas of a timefrequency representation delimited by frequency band times time interval in the form of energy distributions, classifying the energy distributions according to pre-defined criteria, and comparing the energy distributions to a paradigm of distributions related to known medical conditions and extracting information by comparing the enhanced signal to stored time functions.</p><p>The correct placement in time of S 1 and S 2 permits the energy relating to these sounds to be eliminated in the signal processing, and the resulting sound (including murmurs, regurgitation, etc.) is a useful starting signal for further analysis, because it increases the dynamic range of the remaining signal.</p><p>It also permits presenting the remaining signal to the ears with a superposition of correctly placed but (neutral) S 1 and S 2 contributions as mere time markers, but without any signal that the listener needs to process in the listening process. Diagnostic classification and evaluation is obtained by identifying specific features in order to extract characteristic patterns which are compared to a library of patterns typical of various kinds of heart disorder, and the closeness of the measured signal to these patterns.</p><p>Enhanced appreciation and identification of the heart sound features is obtained by placing the extracted features in a synthetic acoustic environment relying on supplying different signals to the ears of a listener by means of headphones. This is obtained by means of so-called Head Related Transfer Functions, or HRTF. A specific procedure of the technique is characteristic in that first and second heart sounds are detected and placed correctly on a time axis by performing the steps of feature extraction and classification based on the energy distribution over time in a feature time function by the steps of bandpass filtering, followed by instantaneous power and low-pass filtering of the original phonocardiographic signal.</p><p>The 3D-PCG feature mapping based on K-mean clustering was represents in Fig. <ref type="figure">6</ref>.17 with the allocation of intensity variation in time and frequency domain, which have a lasting influence on wide cardiomyopathic cases, e.g., dilated cardiomyopathy (DCM), ventricular septal defect (VSD), and restrictive cardiomyopathy (RCM), by which a deviation in temporal and spatial characteristics can be observed. An embodiment of the techniques is particular in that it comprises the steps of extracting the first and second heart sounds by classification according to energy levels, eliminating the contribution of the said first and second heart sounds from the signal, performing spectral analysis and feature enhancement in order to obtain the energy content present in areas of a time-frequency representation delimited by frequency band times time interval in the form of energy distributions, classifying the energy distributions according to pre-defined criteria comparing the energy distributions to a descriptive distributions related to known medical conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11.">PCG PATTERN CLASSIFICATION APPLICATION EXAMPLE 137</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11">PCG PATTERN CLASSIFICATION APPLICATION EXAMPLE</head><p>The input for the procedure consists of 45 seconds of heart sound signal, sampled at a rate of 2000 Hz and read into a digital register subsequent to analog-to-digital conversion ADC. The procedure is described with reference to modern digital technology, however in principle, the various classification and sorting of time intervals and levels may be performed by analog means on DC voltages and traditional gates.</p><p>The transduction for S 1 and S 2 essentially consists of two separate processes: a feature extraction part and a classification part. The purpose of the feature extraction is to transform the input signal to a domain, in which the respective location in time of S 1 and S 2 is more distinct than in the original signal. The classification part determines the precise location of S 1 and S 2 and correctly identifies them as such hemodynamic index. Figure <ref type="figure">6</ref>.17(d) demonstrates how murmurs may be observed in a contouring spectrogram plotting of a time function of an original heart sounds as a correlation between PCG intensities. The spectrogram is obtained by Fast Fourier Transform. The first and second heart sounds, S 1 and S 2 , have only a low-frequency content compared to the broad-band nature of the murmurs, and for this reason the signal is band-pass filtered by convolution of the original signal with the impulse response function of a bandpass filter. The corresponding spectrogram peaks of higher energy are visible but not clearly identifiable.</p><p>In order to obtain a time function of the occurrence of these higher energies, the time marginal distribution of the spectrogram is performed according to Eq. (6.13). Hereby a final PCG feature is obtained as a discrete time function. In essence, this time function, is obtained by bandpass filtering, instantaneous power extraction and lowpass filtering.</p><p>It is now clear that the final feature displays a hill every time an S 1 or S 2 occurs in the heart signal. As the magnitudes of the hills corresponding to S 1 and S 2 are comparable, it is necessary to distinguish between them by applying classification rules. First, all hills in the final feature must be identified. This is obtained for all samples of the time function which fulfill the following criteria: feature (k-l)&lt; feature (k) and feature (k) and g t ; feature (k+1).</p><p>The next step is to construct (a) table of possible systoles. A systole is a-pair of hills (S l and S 2 ) constrained by the time distance between the hills.</p><p>The time distance must fall within the following limits: 230 ms &lt; T &lt; 500 ms for human hearts.</p><p>The final sequences of systoles is determined by finding the sequence of systoles in the table having maximum energy that fulfill the following constraints:</p><p>• Systole time deviation &lt;18%-time between systoles (diastole)&gt; 0.9 times systole timeamplitude deviation of S 2 ; and</p><p>• it is 500%-amplitude deviation of S 2 &lt; 500%-in the case of overlapping systoles, the systole with maximum energy must be selected.</p><p>The result of the heart sounds identification is displayed in Fig. <ref type="figure">6</ref>.16, in which the dominant PCG features represent in a black line with different intensity levels. These peaks of intensity annotate the time position of a first heart sound S 1 and a second heart sound S 2 .</p><p>With the time positions of the first (S 1 ) and second (S 2 ) heart sounds which are correctly detected in the signal domain (given as sample numbers and a class number corresponding to positions measured in milliseconds) it is now possible to evaluate the much weaker sounds, the heart murmurs PCG traces. In the following, these detected PCG-signal time positions will be referred to as S 1 markers and S 2 markers, respectively. Reference is again made to Fig. <ref type="figure">6</ref>.16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11.1">DELIMITATION OF SYSTOLES AND DIASTOLES ASSESSMENT</head><p>Only the systole and diastole parts of the heart sound signal are used for the murmur detection. All periods, beginning 50 ms after an S 1 marker and ending 50 ms before the immediately following S 2 marker, are defined as systoles. Correspondingly, all periods, beginning 50 ms after an marker and ending 50 ms before the immediately following S 2 marker, are defined as diastoles. This is a primitive, but efficient manner of eliminating the influence of the very energetic first and second heart sounds. At later stage-in the performance of the procedure some corrections are made (side below), but it may be more advantageous to perform the elimination using more refined approaches at this early stage in the procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11.2">TIME AND FREQUENCY DECOMPOSITION OF SYSTOLES AND DIASTOLES</head><p>The sound energy content in the sound signal is calculated by means of a spectrogram based on the Discrete Fourier Transform (DFT) using a vector length which is a power of 2, such as 16. In order to be able to classify murmurs regarding frequency contents and time distribution, each systole and diastole is decomposed into 14 frequency bands and 10 time slices, the two lowest frequency bands being discarded.</p><p>The 14 frequency bands cover the frequency range from 62.5-500 Hz, each having a width of 31.25 Hz. Before computation of the spectrogram, the sound signal is differentiated twice (corresponding to a second order high-pass filtration) in order to take into account the frequency characteristics of the human hearing, being more sensitive to higher than lower frequencies within the frequency range in question. It is considered that a parallel bank of band pass filters will perform faster in the present environment. The 10 time slices for a given systole or diastole all have the same width, corresponding to (1/10) of the total length of the systole/diastole.</p><p>The combination of frequency bands and time slices creates a 14x10 matrix for each systole/diastole. For each element in these matrices, the energy content is divided by the width of the relevant time slice, thus yielding matrices containing the heart sound power (energy per time, energy flow rate) for the 140 time/frequency elements of each systole/diastole phase <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b92">93]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11.3">EXTRACTION OF PCG POWER AND FREQUENCY FEATURE</head><p>VECTORS A systole power (SP) vector with 10 elements is constructed by summing the 14 standard power values for each of the 10 time slices. Thus, the SP vector consists of the column sums for the S matrix. A diastole power vector (DP) is constructed in the same way. A systole mean frequency (SMF) vector (also with 10 elements) is calculated by weighting the power value for each frequency band with the mean frequency of the corresponding band, summing the 14 results, and dividing the sum with the corresponding element in the SP vector. Correspondingly, a diastole mean frequency (DMF) vector is calculated according to the power-weighting algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11.4">CORRECTION OF FEATURE VECTORS FOR S 1 /S 2 REMNANTS</head><p>The phonocardiography feature vector (PCGFV) is one of the discriminative index for the systolicdiastolic hemodynamic instabilities. The processing method for extraction the PCGFV vector can be obtained using regressive-time delay technique. The determination of PCG features and its corresponding vectors, will vary during the online-identification of S 1 and S 2 components.</p><p>The compensation of this problem will be applied using a correlogram of both signals, which is graphical representation of the autocorrelations ρ i versus f the time lags of the PCG trace. To verify the stability of feature-detection and quantifying the remnant error ( i ) value during this process, a correction function, (ψ(i)), applied to the output PCG-feature vector, obtains the mean corrected S 1 and S 2 profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.12">FUTURE TRENDS IN PHONOCARDIOGRAPHY PATTERN CLASSIFICATION</head><p>A further advantageous of the automated K-mean (AKM) clustering algorithm application for extracting murmur-information is particular in that it comprises the steps of obtaining a digital representation of heart sounds for a predetermined number of seconds.</p><p>In addition to that, the identifying the time of occurrence of the first and second heart sounds in each cycle, windowing the parts of heart sounds falling between the first and second heart sounds, and second and first heart sounds, respectively. The decomposition of the signals into a predetermined first number n 1 of frequency bands, each band being decomposed into a predetermined second number n 2 of time-slices, obtaining a systole (SP) and a diastole (DP) power vector consisting of the sum of n 1 powers measured in each of the n 2 time slices, for each combination of a frequency band and a time slice.</p><p>The power values from the different systoles are compared, and the median value are chosen to be the standard value for a power vector. By obtaining a systole (SMF) and a diastole (DMF) mean frequency vector using the weighting of a power value for each of n l frequency bands with the mean frequency of the corresponding band, summing the results and dividing the sum by the corresponding element in the respective systole or diastole power vector, while using the time of occurrence of the intensity vectors of the various classes for classifying the time distribution of murmurs.</p><p>A further embodiment of the AKM is particular in that it comprises a step preceding the step of obtaining systole and diastole murmur intensity vectors SI and DI, namely refining the windowing by setting the values of SP, DP, SMF, and DMF of the first or last elements equal to the second or last-but-one values, respectively, if the values of the first or last elements of the corresponding vectors fulfill predetermined deviation criteria.</p><p>A further embodiment of AKM is particular in that still further steps are included, namely subjecting the signal to double differentiation before decomposition, obtaining a systole (SI) and diastole (DI) murmur intensity vector, respectively, by taking the logarithm of the corresponding SP and DP vectors, classifying the obtained logarithmic vectors into murmur intensity classes, and comparing the energy distributions to a catalogue of distributions related to known medical conditions.</p><p>An apparatus for performing the basic procedure of automated PCG diagnosis system is particular in that it comprises analog-to-digital converter ADC means for converting a heart sound signal into sampled data, means for extracting the first and second heart sounds by classification according to energy levels, means for eliminating the contribution of the first and second heart sounds from the signal.</p><p>A method for performing spectral analysis, performing feature enhancement, and multiplication means for obtaining the energy content present in areas of a time-frequency representation are delimited by frequency band multiplied by time interval in the form of energy distributions means for classifying the energy distributions according to pre-defined criteria.</p><p>The comparator for comparing the energy distributions to a catalog of PCG patterns was set for a relevance to known medical conditions .</p><p>The manifestation of the Automated PCG classifier system is particular in that signal processing means are used to produce a spatial sound distribution based on frequency, a low frequency band being delivered to a first earpiece of a headphone and a high frequency band being delivered to a second earpieces of the headphone, the frequency bands containing first and second heart sounds and murmur sounds respectively.</p><p>Moreover, the diligence of the apparatus is particular in that, the signal processing means, produce a temporal sound distribution, sound signals being first delivered to a first earpiece of the headphone and then being delivered to a second earpiece of the headphone. A further embodiment of the apparatus is particular in that the signal processing comprise at least one Wiener filter module or other comparable filtering system functionality <ref type="bibr" target="#b93">[94,</ref><ref type="bibr" target="#b96">97]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.13">SUMMARY</head><p>PCG signal pattern classification can be falls into the following categories.</p><p>• Supervised PCG pattern classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.13.">SUMMARY 141</head><p>• Unsupervised PCG pattern classification.</p><p>• Higher-order statistics pattern classification.</p><p>• Independent component analysis (ICA) and application of mixture model ICA-MM technique.</p><p>• PCA PCG pattern classification technique.</p><p>• Self organized mapping (SOM), as a supervised adaptive classification technique.</p><p>• Bayesian classification as one of higher-order statistical approach in PCG data clustering.</p><p>C H A P T E R 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Special Application of Phonocardiography 7.1 INTRODUCTION</head><p>Phonocardiography has an additional potential application that may be a valuable tool in primary clinical diagnosis and in cardiac monitoring functions. These applications, in some selected patients, tends to be obvious to monitor. One of these applications is analysis of the frequency of the second sound as a noninvasive indicator of sub-clinical stiffening of the aortic valve. Such analysis may be useful in identifying mild aortic stenosis. Early diagnosis in such patients may be advantageous because the prophylactic use of antibiotics is sometimes required. Previously, we mentioned that the phonocardiography is a passive and fully non-invasive acoustic recording that provides an alternative low-cost measurement method. From this point, the development and optimization of a special clinical and medical diagnosis application, established upon phonocardiography, has been raised and grown over the past decades. In the following sections, Lighting of the main applications based on phonocardiography was achieved. Discussion of the principal and substantial PCG application occurred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">FETAL PHONOCARDIOGRAPHY SIGNAL PROCESSING</head><p>Fetal phonography is the recoding of the fetal physiological sounds. Phonocardiography, specifically, involves the acquisition and recording of fetal heart sounds. In both cases, this is achieved by sensing a fetal acoustic vibrations incident on the maternal abdomen. Fetal phonocardiography (fPCG) has a history dating as far back as the mid 19th century, and is reviewed in <ref type="bibr" target="#b86">[87]</ref>.</p><p>Up until now, the fPCG clinical data obtained using phonocardiography acquisition for fetal monitoring presented poorly in comparison with those obtained using Doppler ultrasound techniques with a research conducted by <ref type="bibr" target="#b87">[88]</ref>. Ultrasonography currently dominates fetal heart monitoring practice.</p><p>Figure <ref type="figure" target="#fig_81">7</ref>.1 presents the fetal phonocardiography tracing in accompanying fetal electrocardiography (fECG) which can be acquired using fECG-electrodes, and is evident to the physiological status of the fetus.</p><p>The lack of success of phonographic monitoring systems is attributed to inappropriate cardiac transducer design and physical limitation for PCG signal detection; typically, the transducers used for fetal heart monitoring were variants of those used for adults.The resulting signal had a poor signal to noise ratio. This required heavy filtering which in turn led to spatial attenuation of potentially important signal information.</p><p>The design of compliance matched phonography transducers <ref type="bibr" target="#b87">[88,</ref><ref type="bibr" target="#b88">89]</ref> and represents a considerable improvement over earlier designs. Firstly, the phonography signals acquired potentially have a signal to noise ratio sufficient that heavy filtering is redundant. Secondly, these phonography sensors can characteristically operate over a wide range of fetal vibrations. Considering these factors has given rise to the concept of wide-frequency bandwidth fetal phonography.</p><p>Wide-frequency bandwidth fetal phonography enables recording of low-frequency vibrations arising from activities such as fetal breathing and movements, in addition to the higher frequency vibrations arising from heart sounds. Even though phonography microphone transducer development is at an advanced stage, adaptive and robust signal processing techniques allowing routine estimation and parameter identification of fetal activities are still blossoming. However, the advancement of the real-time signal processing would be engaged to develop linear and stable fPCG clinical diagnosis.</p><p>Figure <ref type="figure" target="#fig_81">7</ref>.2 illustrates the data acquisition system of fPCG-signals composed of highly sensitive microphone transducer with band-pass filtering and low-pass filtering module. The purpose of this stage is to attenuate any noise contamination originated from the mother internal organs movement. Moreover, the narrow-bandwidth ADC-unit should be selected carefully to obtain accurate information from sampled fPCG-signals. Accordingly, analysis of wide bandwidth phonography and phonocardiography signals obtained using the latest transducers remains at an experimental stage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">FETAL SOUND DETECTION MEDICAL SENSORS</head><p>The practice of using FHR to assess fetal status was derived from the very simple sensor in the form of the fetal stethoscope, or fetoscope. This is essentially a conical tube-geometry held in contact with the maternal abdomen, which allows a doctor or nurse to attempt to listen to sound acoustic waves produced by the fetus. Among the mixture of sounds heard, the fetal heart sounds, produced by valve opening and closing and by blood flow, may be perceived. When these heart sounds are clear, it is then possible to calculate manually the mean heart rate, say over 30-60 s.</p><p>It is also possible, with experience, to perceive changes in FHR, such as bradycardia. The use of a microphone in place of the simple fetoscope allows electronic recording of sounds detected from the maternal abdominal wall. The sounds detected include fetal heart sounds, thereby enabling the fetal phonocardiogram to be recorded <ref type="bibr" target="#b81">[82]</ref>. However, the fetal heart sound is heard among a collection of other sounds. These may be due to movement of the fetus or the mother, maternal heart and breathing sounds, and also noises from the surrounding environment. Thus, processing of the phono-acoustic signal is essential in order to extract useful information from the fetus.</p><p>Although simple microphones were used widely in most commercially available fetal monitoring instruments, there was some attempt to improve the performance of phonocardiography by matching a suitable transducer to the mechanical properties of the tissues to which it was attached <ref type="bibr" target="#b79">[80]</ref>. Such an approach was then used to achieve a transducer design with a wide bandwidth for fetal phonocardiography with compliance matched to the maternal abdominal wall <ref type="bibr" target="#b83">[84]</ref>. The drawbacks arising from the limited low-frequency response of piezoelectric crystals were overcome in a compliance-matched transducer design dependent upon inductive principles <ref type="bibr" target="#b84">[85]</ref>.</p><p>The transducer INPHO has a polypropylene membrane that can be stretched to an appropriate tension in order to achieve the required compliance. It has a frequency response flat to within 3 dB from 0.1-200 Hz. It was shown that appropriate adaptive filtering can separate fetal heart sounds (&gt;10 Hz) from fetal breathing movements (0.5-2.0 Hz) as well as eliminate the influence of maternal breathing movements <ref type="bibr" target="#b85">[86]</ref>. It was also reported that the attachment of this transducer was best achieved using a double-sided adhesive disc rather than by means of belts or straps, since the latter interfered with compliance matching. Although fetal phonocardiography had lost popularity in recent years, new work describes a low-cost monitor based on phonocardiography and advanced signal processing <ref type="bibr" target="#b86">[87]</ref>.</p><p>The two-channel phonocardiographic device is said to provide performance for FHR variability monitoring comparable to that of ultrasound cardiography. The system was developed for home care use, offering an optimal trade-off between complexity and performance in a low-cost, stand-alone, embedded modular battery-powered instrument. The developed system provided 83% accuracy compared with the simultaneously recorded reference ultrasound records <ref type="bibr" target="#b87">[88]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">CHALLENGES AND MOTIVATION</head><p>Fetal phonocardiography is considered one of physiological signals which significantly can be used as clinical index for the healthy status of the fetus. Therefore, the analysis of phonocardiography faces a variety of challenges as described below.</p><p>The main challenge which faces the fetal PCG (fPCG) is the considerable acoustic impedance and scattering effect of the acoustic wave propagated from the fetus heart to the microphone transducer.</p><p>In addition to that, the principal drawback to phonocardiographically derived fetal heart recording (FHR) systems is that they are extremely sensitive to ambient noise such as maternal bowel sounds, voices in the room, certain air-conditioning systems, and especially, noise produced by any movement of the microphone or the bed clothing against the microphone.</p><p>In addition, any fetal kicking or motion produces a very loud noise that will saturate the automatic gain system on the monitor's amplifier, resulting in complete loss of recording for several seconds while waiting for the amplifier to reopen. For this reason, a manual gain control offers a great advantage when using abdominal fetal phonocardiography for recording heart rate. Furthermore, because of the high sensitivity to ambient noise, the technique is unsatisfactory for monitoring during the active phase of labor.</p><p>The current role of phonocardiographic FHR recording is quite limited but should be considered if abdominal fetal ECG and Doppler do not produce satisfactory recordings. Today, it would have to be considered below Doppler in a ranking of preferred methods of ante partum FHR recording. Both the abdominal fetal ECG and phonocardiographic FHR are rarely employed means of fetal monitoring, but are of historic significance.</p><p>The considerable features that differentiate phonography from ultrasonography and fetal electrocardiography (fECG) are the following:</p><p>1. The most up-to-date phonography transducers are able to sense fetal acoustic vibrations over a wide frequency range, and therefore can record a range of fetal activities <ref type="bibr" target="#b90">[91]</ref>.</p><p>2. Phonography is a non-invasive technique, imparts no energy to the fetus, and consequently, is inherently safe for long-term clinical monitoring of the fetus health status.</p><p>3. The modern phonography transducers are sufficiently sensitive that fetal activity can still be recorded after the position of the fetus, relative to the transducer. This is in direct contrast to Doppler ultrasound systems for which fetal movements must be tracked. In this respect, modern phonographic systems may have a reduced requirement for skilled operators.</p><p>4. The most recent phonocardiography techniques have the capability for long-term simultaneous monitoring of a range of fetal cardiac activities. This ensures that, potentially, phonography has an important role in antepartum fetal health care.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">INTRACARDIAC PHONOCARDIOGRAPHY (ICP) SIGNAL PROCESSING</head><p>Intracardiac phonocardiography (ICP) is another step in the development of the scientific basis for auscultation, one of many that date from immediate auscultation and extend through echophonocardiography and nuclear cardiology diagnosis tools such as cardioSPECT and PET-imaging modalities. The 55-year history of intracardiac phonocardiography, relatively brief in duration, is quite diverse due to the interrelations with other investigative and diagnostic methods that were evolving during the same era. In the classical auscultation method, external phonocardiography, pressure manometer, and recording device development were the evolutionary forerunners of intracardiac phonocardiography, while cardiac catheterization techniques were the vehicle for implementation <ref type="bibr" target="#b88">[89]</ref>.</p><p>The ICP, as an investigative and clinically diagnostic method, has conveyed a vast amount of information which confirmed certain traditional concepts and upset others. Early enthusiastic investigators frequently overemphasized the role of ICP in diagnosis; this misplaced emphasis tended to obscure certain fundamental contributions.</p><p>In a more conservative vein, Leathaml observed that intracardiac phonocardiography has mainly served to confirm or consolidate facts which were already known, or have been ascertained in the last 50 years using multichannel external recording platform. Yamakawa et al. used the term intracardiac phonocardiography in his study in which a condenser microphone was adapted to a vascular catheter <ref type="bibr" target="#b89">[90]</ref>, and vascular and cardiac sounds were recorded in 20 dogs and 3 humans; illustrated tracings from the animal studies were published. There were no published records of the patient studies, and apparently there were severe limitations inherent in the initial methodology.</p><p>Three recorded heart sounds and murmurs in the lesser circulation with a barium titanate transducer and noted technique was capable of localizing heart sounds and murmurs to an extent not previously possible. The frequency response of the catheter preamplifier system was linear over the range of heart sounds; however, since the response of the barium titanate dropped off sharply below 10 Hz, it was not possible to record simultaneous intracardiac pressures waveform.</p><p>A double lumen catheter was used to record pressure with an external manometer. These and additional studies in acquired and congenital heart disease were the initial ICP studies in the United States. The instrumentation and usage gave the entire field a worldwide impetus.  heart, and was adapted or modified in a number of laboratories. An important outgrowth of these studies was the proposal by <ref type="bibr" target="#b87">[88]</ref> for revision of the classic auscultatory areas. The auscultatory areas were renamed according to the chamber or vessel in which a given sound or murmur was best recognized by intracardiac phonocardiography. Murmurs were further described as originating in the inflow or outflow tracts of the left and right heart. Grant's earlier physiologic concepts of ventricular inflow and outflow tracts were coupled to this anatomic and auscultatory framework.</p><p>It is possible to take the matter a step further; for example, Leatham's classification of murmurs is easily adapted to this approach. The principals gained from intra-cardiac phonocardiography provide a solid basis for the practice and teaching of cardiac auscultation technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">ICP MEASUREMENT DEVICE</head><p>An inductance micro-transducer for intravascular pressure was described by Gauer and Gienappl and its evaluation and application were presented in 1951 <ref type="bibr" target="#b91">[92]</ref>. The Allard-Laurens variation consisted of a single coil with a central core suspended between two diaphragms; displacement altered the selfinductance of the coil in a linear pattern.The experimental setup of ICP-signal clinical measurement system as a part of catheterization module was illustrated in Fig. <ref type="figure" target="#fig_81">7</ref>.4, which describes four basic intra-cardiac inlets and cardiac microphone mounted in the wall of Swan-like catheter to detect the ICP-acoustic signals. Soulie et al. <ref type="bibr" target="#b93">[94]</ref> presented an extensive experience with simultaneously recorded intra-cardiac sound and pressure (ICSP) in acquired and congenital heart disease. Soulie re-emphasized the contribution of turbulence in the production of certain murmurs, and anticipated the flow velocity measurements of the 1970s. He considered extra-cardiac auscultation over the thorax to be a resultant of complex and disjointed vibratory phenomena, the components of which had timing that was different from one cavity to the other. Murmurs recorded in a cardiac or vascular chamber were propagated in the direction of the jet or turbulent flow which produced them, and they tended to stay localized in the cavity of their origin.</p><p>Additionally, the use of ICP measurement profile can also be applied to identify the arterial pressure sound patterns which can be quantified through gradual increase of the arterial sound pressure (Pressure dyne PD) in variable cardiac valvular disorders ranging from aortic insufficiency to sever aortic stenosis. Figure <ref type="figure" target="#fig_81">7</ref>.5 presents the different recorded trace of ICP signal as a function of intra-arterial sound pressure level. Millar <ref type="bibr" target="#b90">[91]</ref> developed catheter mounted pressure transducers constructed from a pair of matched, unbounded silicon elements, geometrically arranged to act, respectively, in compression and extension upon application of pressure. The improvement of the intrinsic gauge sensitivity, thermal stability, drift characteristics, linearity, and mechanical durability represented a significant technical advance in catheter-tip pressure transduction mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">ICP SIGNAL PROCESSING</head><p>The main problem of ICP signal is the artifact production and recognition has existed throughout the history of ICSP recording, but has diminished with each technological development. Careful auscultation prior to study, correlation during study with external phonocardiography and echocardiography, amplification of ICP during the study, a careful search for reproducibility of recorded phenomena, and correlation of recordings with increasingly refined catheterization-angiographic and echophonocardiography techniques have reduced the potential for artifact error. The direct calibration of intracardiac cardiovascular sound was performed by Soulie et al. <ref type="bibr" target="#b93">[94]</ref> with a cardiac acoustic transducer calibrated in units of SI-pressure (mmHg).</p><p>The signal processing structure for the ICP components was presented in Fig. <ref type="figure" target="#fig_81">7</ref>.6, where the ICP signal is low-pass filtered, and the baseline recordings buffered actively. Succeeding that the fast Fourier transform (FFT) applied to the buffered signal. Furthermore, the valvular components can also be identified. The four specific heart sounds, S 1 , S 2 , S 3 , and S 4 , can also be extracted using feature-vector computation based on radial basis artificial neural network (RBANN)-system. Moreover, the accompanied pressure profile of the left atrium and ventricle was determined in this computational schema.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.3">ICP ACOUSTIC TRANSMISSION PROPERTIES</head><p>Feruglio <ref type="bibr" target="#b92">[93]</ref> and Silin <ref type="bibr" target="#b97">[98]</ref> reviewed the available techniques for detecting intra-cardiac acoustics and introduced the vibrocatheter (a catheter with lateral opening near the tip covered with a thin latex cuff connected to the tubing of binaural stethoscope for direct auscultation, or to a piezoelectric microphone to record the intra-cardiac phonocardiogram). Observations in valvular and congenital heart disease with this system were similar to those obtained with the methods described earlier in this book.</p><p>The innovative use of the system consisted of delivery of sounds of known frequency content or intensity into the heart; the vibrocatheter was connected to a magneto-dynamics unit of an acoustically insulated loud speaker connected to a variable-frequency oscillator or tape recorder. The artificial sounds delivered into the heart were then recorded from chest surface sites in order to study the modifying effects of sound transmission from cardiac chambers to chest wall.</p><p>The attenuation of cardiovascular sound depended on the site of intra-thoracic production, the frequency components of the sounds, and the characteristics of the conducting tissues. The maximal attenuation occurred, when sound originated in the right and left pulmonary arteries; attenuation was less when sound arose in the right atrium and main pulmonary artery; sound was well conducted to the chest wall from the right ventricle.</p><p>The distance from sound source to chest wall and the interposition of poorly conducting tissues were considered to be the reasons for the different degrees of attenuation. Frequencies below 100 Hz and above 350 Hz were greatly attenuated; frequencies of about 200 Hz were conducted with little attenuation (presumably because these frequencies were in the same general range as the natural frequency of the thorax).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">SEPARATION OF PHONOCARDIOGRAPHY FROM PHONOSPIROGRAPHY SIGNAL</head><p>Lung sounds produce an incessant noise during phonocardiography recordings that causes an intrusive, quasi-periodic acoustic interference that influences the clinical phonocardiography auscultatory interpretation. The introduction of pseudo-periodicities, due to lung sounds overlapping, mask the relevant signal and modifying the energy distribution in the PCG spectral band, in order to conduct a proper PCG-signal analysis <ref type="bibr" target="#b96">[97]</ref>. This lung sound interference problem needs an effective reduction of this sound parasitic effect-over the disturbed phonocardiography signal to yield a successful heart PCG interpretation and identification. Generally, there are three approaches for lung sound cancellation which are as follows:</p><p>• Low-pass filtering (LPF) of the PCG signal, which attenuate the low-frequency component of lung sound.</p><p>• Application of autocorrelation function (ACF) to cancel down the redundancy harmonic of the phonospirography signals.</p><p>• Online subtraction of two successive S 1 and S 2 PCG signal with time delay (T h ) from each other and multiply with constant gain level.</p><p>The simplest technique, which is illustrate in Fig. <ref type="figure" target="#fig_81">7</ref>.7, can be implemented in a hardware-approach based on adaptive IIR-filter that added the estimated noise-source with PCG-source to cancel out this noise effect. This versatile approach is flexible in reverse direction, where the required task is to segregate lung sound (LS) as dominant signal from PCG-signal. The other technique which is used for suppression respiratory acoustic vibration from phonocardiography signals is by using adaptive cancellation. Adaptive noise canceling relies on the use of noise canceling by subtracting noise from a received signal, an operation controlled in an adaptive manner for the purpose of improved signalto-noise ratio (SNR). Ordinarily, it is inadvisable to subtract noise from a received signal, because such an operation could produce disastrous results by causing an increase in the average power of the output noise. However, when proper provisions are made and filtering and subtraction are controlled by an adaptive process, it is possible to achieve a superior system performance compared to direct filtering of the received signal <ref type="bibr" target="#b94">[95]</ref>.</p><p>Basically, an adaptive noise canceler is a dual-input, closed-loop adaptive feedback system as illustrated in Fig. <ref type="figure" target="#fig_81">7</ref>.8. The two inputs of the system are derived from a pair of cardiac microphone sensors: a primary sensor and a reference (auxiliary) sensor. Another variation of respiratory sound cancellation is based on recording the two-acoustic traces via modeling PSG and PCG signals coincidentally to separate each other. Moreover, the clinical pulmonary function can also be derived from the acquired lung sounds, and in addition, the other buffering parameters can be used for the calibration purposes of the PSG-signal and PCG signal together.</p><p>This concept is presented in Fig. <ref type="figure" target="#fig_81">7</ref>.9. The use of respiratory acoustic (lung sound) signal to calibrate against phonocardiography signal has been used to cancel the effect of lung sound, which propagate with PCG signal. Specifically, the following assumptions were derived:</p><p>1. The primary sensor receives an information-bearing signal s(n) corrupted by additive noise v 0 (n), as shown by the following formula:</p><formula xml:id="formula_91">d(n) = s(n) + v 0 (n). (7.1)</formula><p>The signal s(n) and the noise v 0 (n) are uncorrelated with each other; that is,</p><formula xml:id="formula_92">E[s(n)v 1 (n -k)] = 0 for all k,<label>(7.2)</label></formula><p>Figure <ref type="figure" target="#fig_81">7</ref>.9: The schematic of cardio-respiratory sound recording and modeling loop. This system is used to conduct a correlation analysis and system identification between cardiac acoustics and respiratory acoustics, in which the tracheal sound and lung sounds recording synchronously to be used in calibration process for phonocardiography <ref type="bibr" target="#b100">[101]</ref>.</p><p>where s(n) and v 0 (n) are assumed to be real valued.</p><p>2. The reference sensor receives a noise v 1 (n) that is uncorrelated with the signal s(n), but correlated with the noise v 0 (n) in the primary sensor output in an unknown way; that is,</p><formula xml:id="formula_93">E[s(n)v 1 (n -k)] = 0 for all k (7.3)</formula><p>and</p><formula xml:id="formula_94">E[v 0 (n)v 1 (n -k)] = p(k), (<label>7.4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">PHONOCARDIOGRAM CARDIAC PACEMAKER DRIVEN SYSTEM</head><p>In a normal heart, the sinus node, the heart's natural pacemaker, generates electrical signals, called action potentials, which propagate through an electrical conduction system to various regions of the heart to excite myocardial tissues in these regions. Coordinated delays in the propagations of the action potentials in a normal electrical conduction system cause the various regions of the heart to contract in synchrony such that the pumping functions are performed efficiently. Thus, the normal pumping functions of the heart, indicated by hemodynamic performance, require a normal electrical system to generate the action potentials and deliver them to designated portions of the myocardium with proper timing, a normal myocardium capable of contracting with sufficient strength, and a normal electromechanical association such that all regions of the heart are excitable by the action potentials.</p><p>The function of the electrical system is indicated by electrocardiography (ECG) with at least two electrodes placed in or about the heart to sense the action potentials. When the heart functions irregularly or abnormally, one or more ECG signals indicate that contractions at various cardiac regions are chaotic and unsynchronized <ref type="bibr" target="#b98">[99]</ref>.</p><p>Such conditions, which are related to irregular or other abnormal cardiac rhythms, are known as cardiac arrhythmias. Cardiac arrhythmias result in a reduced pumping efficiency of the heart, and hence, diminished blood circulation.</p><p>Examples of such arrhythmias include bradyarrhythmias, that is, hearts that beat too slowly or irregularly, and tachyarrhythmias, which is disturbance of the heart's rhythm characterized by rapid and irregular beating. A patient may also suffer from weakened contraction strength related to deterioration of the myocardium. This further reduces the pumping efficiency.</p><p>For example, a heart failure patient suffers from an abnormal electrical conduction system with excessive conduction delays and deteriorated heart muscles that result in asynchronous and weak heart contractions, and hence, reduced pumping efficiency, or insufficient hemodynamic performance.</p><p>The phonocardiography recording during such a case is displayed in Fig. <ref type="figure" target="#fig_81">7</ref>.10 A cardiac rhythm management system includes a cardiac rhythm management device used to restore the heart's pumping function, or hemodynamic performance. Cardiac rhythm management devices include, among other things, pacemakers, also referred to as pacers. Pacemakers are often used to treat patients with bradyarrhythmias. Such cardiac pacemakers may coordinate atrial and ventricular contractions to improve the heart's pumping efficiency. Cardiac rhythm management devices may include defibrillators that deliver higher-energy electrical stimuli to the heart.</p><p>Such defibrillators may also include cardioverters, which synchronize the delivery of such stimuli to portions of sensed intrinsic heart activity signals. Defibrillators are often used to treat patients with tachyarrhythmias. In addition to pacemakers and defibrillators, cardiac rhythm management devices also include, among other things, devices that combine the functions of pacemakers The effectiveness of a cardiac rhythm management therapy is measured by its ability to restore the heart's pumping efficiency, or the hemodynamic performance, which depends on the conditions of the heart's electrical system, the myocardium, and the electromechanical association. Therefore, in addition to the ECG indicative of activities of the heart's electrical system, there is a need to measure the heart's mechanical activities indicative of the hemodynamic performance in response to the therapy, especially when the patient suffers from a deteriorated myocardium and/or poor electromechanical association.</p><p>For these and other reasons, there is a need for evaluating therapies by monitoring both electrical and mechanical activities of the heart, to give a comprehensive prospect for the actual status of the heart during pacing therapy <ref type="bibr" target="#b93">[94,</ref><ref type="bibr" target="#b97">98,</ref><ref type="bibr" target="#b98">99]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">BASIS OF CARDIAC SUPPORTIVE DEVICE</head><p>Most cardiac medical devices that automatically detect events in the cardiac cycle, utilize the ECG signal as the main source of information about the heart activity. Although the ECG signal represents the operation of the electrical conduction system that triggers the contraction of the heart muscle, it has several limitations.</p><p>The heart sounds or the recorded phonocardiography (PCG) traces, being a direct expression of the mechanical activity of the cardiovascular system, is potentially an additional source of information for identifying significant events in the cardiac cycle and detecting non-regular heart activity.</p><p>The spectrum application of the PCG signal in the cardiac pacing outlook is illustrates in Fig. <ref type="figure" target="#fig_81">7</ref>.11, where the utilization of acoustic sensing component in the external cage of the pacemaker- system is used as a hemodynamic derived signal to actuate pacemaker responsively. The principal application of PCG signal in automated cardiac assisted device can be listed as below:</p><p>• A left ventricular assist device (LVAD) is a battery-operated, mechanical pump-type device that's surgically implanted. It helps maintain the pumping ability of a heart that can't effectively work on its own.</p><p>• An Intra-Aortic Balloon Pump (IABP) is a small device that is placed in the thoracic aorta, and uses both ECG and aortic pressure waveforms to time inflation and deflation of a balloon that increase or decrease the aortic pressure, and thus improves the blood flow to the arteries and reduces the workload of the heart</p><p>• Implantable cardioverter defibrillator (ICD) and automatic external defibrillator (AED) are devices that sense the cardiac rhythm, monitor, and treat life-threatening arrhythmia such as ventricular tachycardia or fibrillation. When such abnormal rhythm is detected, the device shocks the heart to restore the normal rhythm.</p><p>The productive research direction toward the development of the phonocardiography based on adaptive ICD will turn the concept of invasive sensing mode to the non-invasive mode by the use of wireless data communication between the microphone-terminal unit and pacemaker base receiving unit.</p><p>A cardiac rhythm management system provides a phonocardiographic image indicative of a heart's mechanical events related to hemodynamic performance to allow, among other things, diagnosis of cardiac conditions and evaluation of therapies treating the cardiac conditions. The phonocardiographic image includes a stack of acoustic sensor signal segments representing multiple cardiac cycles. Each acoustic sensor signal segment includes indications of heart sounds related to the heart's mechanical events and representations of the heart's electrical events. The diagnosis and/or therapy evaluation are performed by observing or detecting at least an occurrence of a particular heart sound related to a cardiac time interval or a trend of a particular time interval between an electrical event and a mechanical event over the cardiac time interval <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b98">99]</ref>. The main architecture of the phonocardiographic pacemaker driven system consists of the following:</p><p>(A)-Pacing pulses delivery system to the heart muscle, which comprises:</p><p>• electrical sensing circuit to sense a cardiac signal; a pacing-therapy(stimulation) circuit to deliver the pacing pulses;</p><p>• vibro-acoustic sensor to produce an acoustic sensor signal indicative of heart sounds;</p><p>• supervisory controller coupled to the therapy circuit, which includes:</p><p>A-Therapy protocol synthesizer adapted to generate a sequence of pacing parameters.</p><p>B-An automatic therapy protocol execution module adapted to time pacing pulse deliveries each associated with one parameter of the sequence of pacing parameters.</p><p>C-Processor coupled to the sensing circuit, the acoustic sensor, and the controller, the processor including an image formation module adapted to produce a phonocardiographic image based on the cardiac signal and the acoustic sensor signal.</p><p>The accoustince-derived signal from the microphone sensor mounted on the pacemaker cage will be further processed and analyzed using FFT-processing module. Moreover, the selective bandwith IIR filter can be used to compensate possible drift in the received acoustic signal during cardiac cycle phases.</p><p>(B)-The phonocardiographic derived-image including a stack of segments of the acoustic sensor signal aligned by a selected type of the cardiac events and grouped by at least parameters of the sequence of pacing parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7">SUMMARY</head><p>To conclude this chapter, we summarize the following points.</p><p>1. The phonocardiography can be used as a mutual tool in many clinical and biomedical engineering application such as blood pressure measurement technique, cardiac pacemaker, intracardiac vital parameters, and hemodynamic diagnosis instruments.</p><p>2. The ability to use fetal phonocardiography (fPCG) in the diagnostic index of the fetus has been discussed and evaluated through many trials and the synchronization of PCG records with other vital signals was also set.</p><p>3. Intra-cardiac phonocardiography signal recording and analysis is a challenging technique that has many complications and obstacles to replace other invasive-parameters. The ICP signal is highly sensitive to noise.</p><p>4. Separation of heart sound (HS) from lung sound (LS) also composed of determination of two different signals that may interfere with the detection process for both of them. Adaptive noise cancellation is considered as a steady method to solve such problem.</p><p>5. Promotive researches toward developing a new sensing mechanism for implantable cardiac pacemaker as the basis for adaptive rate responsive pacemaker system was discussed. The evolution of such sensing technique based on cardiac acoustic waveform, i.e., PCG signal will make the stimulus response of the pacemaker to behave in linear patterns This method is still under development and it is nascent technology in the cardiac pacing therapy. Although, it will assist in formulating a potential pacing-sensing approach.</p><p>C H A P T E R 8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phonocardiography Acoustic</head><p>Imaging and Mapping</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">INTRODUCTION</head><p>The nature of phonocardiography is an acoustic vibratory signal; therefore, one of the perspective application of this signal is to develop a novel technique to synthesis a multichannel-acoustic imaging platform based on real-time synthesized acquisition (RTSA), in order to reconstruct a medical readable anatomical and physiological images. This technique, also denoted as acoustic camera module, in which its function is to localize cardiac acoustic vibration sources. The functionality of this acoustic image was to identify the hemodynamic turbulences and abnormal blood flow patterns associated with varieties of cardiovascular pathologies. In this chapter, the possible road map to build up and express the principals for such a type of medical imaging technique will be discussed and illustrated.</p><p>The previous chapters have intensively illustrated the benefits and horizons of the phonocardiography application, which assists the physician and cardiologist in dealing with varieties of cardiac sounds patterns. It is based on the time domain visualization of cardiac acoustic signals.</p><p>The broad idea of this approach has been adopted from the ECG temporal and spatial analysis, where the time domain electro-physiological waveform is analyzed and reconstructed by specialized electrical impedance tomography methods such as wavelets transformation, adaptive beam-forming algorithms, and other related acoustic image formation and reconstruction methods. However, such an approach is not appropriate for acoustic signals because listening to the signal (i.e., auscultation) differs from viewing the time domain waveform, especially since acoustic events may happen simultaneously at different frequency ranges.</p><p>Cardiologists have tried to see in the waveform what should be heard (since the extensive cardiac auscultation knowledge, gathered over nearly 200 years, describes the cardiac acoustical phenomena). For this reason, the phonocardiography technique was, and still is, rejected by the medical community, although some of the trails have proved that it can be a competitive diagnostic technique from the cost point of view and the methods of analysis.</p><p>Phonocardiography acoustic tomography imaging (PATI) may be improved by multi-band analysis, multi-sensor array signal processing where several waveforms related to specific sub-bands are filtered out and often processed in a non-linear mode. Such improvements allow physicians and biomedical engineers to identify and reconstruct acoustic events related to different frequencies.</p><p>Conversely, this approach is still inadequate due to nonlinear complexity of sound perception and detection, and indeed due to the lack of adequate acoustic tomography image reconstruction algorithms.</p><p>Cardiac energy propagation in human body tissue in the audible frequency, range from 101-103 Hz which is equivalent to 900 Hz of bandwidth, which has a considerable shear-wave component when contrasted to compression waves in the ultrasound band from 104-107 Hz. This dispersive, shear wave propagation is characterized by wavelengths on the order of a few centimeters. Therefore, a multiple wavelength array aperture and frequency partition signal processing make it reasonable to compensate for frequency-dependent wave speed and form images with an aperture near-field focused beam that scans the chest volume.</p><p>The use of passive listening (auscultation) techniques to recognize arteria1 and cardiac valve unstable blood flow has been previously suggested for the detection of both coronary and cranial blood flow pathologies and circulation lesions.</p><p>In recent times, the opportunity of locating such arterial irregularities using near-field focused beam forming techniques has been suggested as a procedure that would enhance cardiac auscultation performance and provide a non-invasive, diagnostic screening device <ref type="bibr" target="#b101">[102]</ref>. For coronary arterial diseases and heart valves problem, this technique requires a positioning of an array of spatially diverse cardiac microphone sensors on the external chest wall near the region of interest and situated with moderately unobstructed paths through the intercostals spaces between the ribs of the subject to the location of the turbulence. The sensor outputs are processed to generate an image of the vibration energy field in the volume beneath the acoustic sensor array.</p><p>The process locates the vibration source by back propagating the sensor signals using beam formation methods. The vibration source mapping itself would be further processed using adaptive radon transformation. This inverse acoustic mapping of the sensor outputs requires an assumed average shear-energy wave speed <ref type="bibr" target="#b99">[100,</ref><ref type="bibr" target="#b100">101]</ref> and the wave equation-based model for the propagation including geometrical Euclidean distance transit time, a homogeneous medium, and a geometric distribution (loss) model. Figure <ref type="figure">8</ref>.1 presents the block diagram of the cardiac acoustic imaging system based on realtime phonocardiography signal acquisition, with a defined number of cardiac microphones placed on the circumstance of the wearable textile embedded electrodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">MOTIVATION AND PROBLEM FORMULATION</head><p>The main problems that face the researcher in the field of acoustic imaging is the transmission acoustic impedance and the scattering effect of the acoustic waves from their sources. To avoid such a complication the first hint is to use high-sensitivity acoustic transducer or sensor to increase the SNR ratio in the post-processing stage. The first trail on cardiac acoustic mapping was done by Kompis et al. <ref type="bibr" target="#b101">[102]</ref> in which they developed an acoustic array platform with simultaneous recording of 8-16 microphone elements. The concurrent data acquisition mode of PATI-technique faces many problems, in the sense of sampling rate, filtering bandwidth, the synchronization of microphone signal ADC-conversion and reconstruction time. These impediments should be considered in future optimization and enhancement of the PATI-method. The anatomical-thorax model is composed of five different components of substantially different acoustic characteristics; this is effectively be illustrated in Fig. <ref type="figure">8</ref>.2, where these components can be distinguished as follows:</p><p>• Myocardial tissue, which consists mainly of the heart muscle and associated coronary vasculature networks and the aortic components.</p><p>• Respiratory-airways which consist of bronchial tree, inferior part of larynx, and pleural space, including pleural fluid.</p><p>• Lung lobules with their parenchyma-compartment.</p><p>• The rib-cage which represents the grounded-compartment of thorax and the cardiac acoustic model.</p><p>• Muscular compartment (pectoralis major and pectoralis minor). Acoustic properties of the solid components of the thorax, such as the chest wall and the heart, are relatively well known. Sound speeds in these tissues are approximately 1,500 m/s, and damping is relatively low. In the larger airways (i.e., diameter of approximately 0.8 mm) of animal models, sound propagates at speeds (mean 95% confidence limit) of 268±44 m/s the acoustic properties of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.">PATI-EXPERIMENTAL SETUP AND SYSTEM PROTOTYPING 167</head><p>the lung parenchyma, which fills a substantial portion of the human thorax, is a function of the air content of the lung. Parenchymal sound speed was estimated to be relatively low, i.e., between 23 m/s and 60 m/s, depending on air content. The sound speed reaches a minimum at lung densities that are slightly higher than those at resting volume, and increases from this minimal value of approximately 23 m/s for both higher and lower densities. Therefore, under physiologic conditions, the sound speed is slightly higher in the upper parts of the lung and after inspiration. At resting volume, sound speed is likely closer to 30 m/s than to 60 m/s. As previously noted, the damping characteristics of the lung parenchyma, increases with frequency.</p><p>At low audible frequencies, for example 400 Hz, damping is estimated to be only from 0.5-1.0 decibel per centimeter(dB/Cm). Aside from these differences in acoustic properties, the geometrical contribution will be significant to the complexity of cardiac acoustics.</p><p>High-frequency sounds are known to travel further within the airway-branching structure, while low-frequency sounds appear to exit predominantly in the large airways via wall motion. Reflections, multiple delays, and interference of acoustic signals, as well as a left-to-right asymmetry of thoracic transmission, will also contribute to the complexity of cardio-thoracic acoustic transmission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">PATI-EXPERIMENTAL SETUP AND SYSTEM PROTOTYPING</head><p>The experimental setup for the phonocardiography acoustic imaging is illustrated in Fig. <ref type="figure">8</ref>.1, where the electrode (cardiac microphones placement) will place in a sensor matrix for picking up the acoustic vibration of the heart mechanical movement and blood flow information accompanied with it. The sensor matrix is composed of 16x8 microphone elements, by which this matrix will cover the thorax (chest region) anatomically. This sensor distribution will make the acoustic detection as high as possible but in addition it will set the slicing approach of acoustic imaging of thorax cavity but with a limited number of slices. By using simultaneous multi-cardiac sensor recordings of cardiac sounds (PCG-signals) from the chest wall, an acoustic imaging of the chest has recently been investigated for detecting plausible different patterns between healthy individuals and patients <ref type="bibr" target="#b101">[102]</ref>. In that study, a new method for acoustic imaging of the cardiac system was developed and evaluated by a physical model of the cardiac-lung compartment as well as experimental data on four subjects and one patient.</p><p>The sound speed, sound wavelengths at the frequencies of diagnostic values, and the geometrical properties of the heart were taken into consideration in developing a model for acoustic imaging to provide a spatial representation of the intra-thoracic sounds as opposed to the mapping of sounds on the thoracic surface.</p><p>The acoustic imaging model was developed based on the calculation of a 3D acoustic-array data obtained from the acquired <ref type="bibr" target="#b108">[109]</ref>. For convenient declaration of the basic assumption to treat the acoustic mapping problem, the following premise can be considered.The acoustic imaging algorithm tests the hypothesis that it contains the only relevant acoustic source.</p><p>A hypothetical source signal is calculated by a least-squares estimation (LSE) method to explain a maximum of the signal variance σ in all microphone signals as follows. Let p i (i=1,...,CM) be the positions of CM cardiac microphones on the thoracic surface and D i (t) the signals recorded at these microphones, where (t) represents time.</p><p>Assuming a uniform sound propagation throughout the thorax anatomical structure (linear wave propagation), sound speed (c), damping factor per unit length (d), the signal φ(y,t) emitted by this hypothetical source at the spatial location, (y) can be estimated by solving the linear system Equs. (8.1)-(8.3), which illustrates the signal characterization of phonocardiography acoustic imaging: The dynamic range of amplifier in data acquisition module will be in range of (100-1000 Hz) with noise attenuation level less than (-3 dB). Therefore, the gain schedule of the acquisition channel must be set to the stable region of amplification to avoid any superimposed disturbance signals. The amplifier array should be arranged in a phase array module. The pre-filtering stage, followed the amplification stage with a band-pass filtering (BPF) module, to buffer any frequency drift in acoustic sensor detection channel. The acoustic array processing was constituted of linear signal processing element with adaptive gain amplifier (AGA); further image reconstruction system (IRS) of the detected acoustic signals would be achieved in high-performance computational PC platform with 64-bit AMD ® processor and 4048 MB RAM-system.</p><formula xml:id="formula_95">D 1 (t -|p 1 -y| /c) =</formula><p>The image reconstruction workstation operated on Windows ® platform. The radon transformation technique is used to reconstruct acoustic energy mapping of phonocardiography signals; however, the main reconstruction algorithm utilizes adaptive beam-forming approach for sped-up signal processing and frame acquisition rate. The image coordinated of the acquired phonocardiography acoustic mapping will be of transverse plane with inverse z-axis model to be analogous to the anatomical myocardial coordinate system. The processing algorithm of the acquired acoustic signals in imaging approach will fall into two categories. The first is adaptive beam forming algorithm, which is applied to the filtered PCG signal detected from the cardiac microphone. The input PCG signal to the adaptive beam-forming profile will be as follows: <ref type="bibr">(8.4)</ref> where the output signal from the adaptive beam-forming unit will be as follows:</p><formula xml:id="formula_96">X det = L l=0 l + M m=0 E m ,</formula><formula xml:id="formula_97">Y det = M m=0 m + X det . (8.5)</formula><p>The parameterized coefficients of the vibro-acoustics signal will be stored in filter-array memory for breath of time-delay (Td). Figure <ref type="figure">8</ref>.2 illustrates the principal signal processing sequences in phonocardiography acoustic imaging approach. The second approach is the online-Radon transformation with application of back projection algorithm. The block diagram of the phase array processing for the cardiac acoustic imaging is presented in Fig. <ref type="figure">8</ref>.3 where the adaptive-filtering kernel applied to the preprocessed PCG signals, with active channel scanning and feature-based extraction technique to be embedded in the imagereconstruction system (IRS). In this schematic, the phonocardiography signals were multiplexed into a pre-filtering stage, pre-processed through acoustic buffering, and digitally converted using 32-bit sampling resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">ACOUSTIC ARRAY SIGNAL PROCESSING</head><p>Various acoustic array configurations have been studied to improve spatial resolution for separating several closely spaced targets and vibration sources in tight formations using unattended acoustic arrays. The application of the acoustic array processing in formation and reconstruction of cardiac acoustic image is still limited in use and needs to improve the received signal quality form the cardiac microphone detectors.</p><p>To extend the array aperture as a cardiac detector matrix, it is customary to employ sparse array configurations with uniform inter-array spacing wider than the half-wavelength of phonocardiography signals for intra-subarray spacing, hence achieving more accurate direction of arrival (DOA) for the PCG signal estimates without using extra hardware configuration. However, this larger inter-array positioning results in ambiguous PCG-DOA estimates.</p><p>To resolve this ambiguity, sparse arrays with multiple invariance properties could be deployed. Alternatively, one can design regular or random sparse array configurations that provide frequency diversity, in which case every subarray is designed for a particular band of frequencies.</p><p>Additionally, we present a Capon DOA algorithm that exploits the specific geometry of each array configuration. Simulation results are conducted before any realization and implementation of acoustic image system, but it is still prospective imaging modalities to investigate the hemodynamics of the myocardium and vascular pathologies in simple and low-cost profile. Another alternative  <ref type="bibr" target="#b102">[103]</ref>, where he used the posterior microphone sensor pad to rest the patient back (posterior surface of thorax) to simultaneous phonocardiography signal acquisition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.1">ADAPTIVE BEAM-FORMING IN CARDIAC ACOUSTIC IMAGING</head><p>In this section, the spatial form of adaptive signal processing that finds practical use in radar, sonar, communications, geophysical exploration, astrophysical exploration, and biomedical signal processing will be described. In the particular type of spatial filtering of interest to us in this book, a number of independent sensors are placed at different points in space to "listen" to the received signal and in this case it is the phonocardiography signals detected by cardiac microphones.</p><p>In effect, the sensors provide means of sampling the received signal in space. The set of sensor outputs collected at a particular instant of time constitutes a snapshot. Thus, a snapshot of data in spatial filtering (for the case when the sensors lie uniformly on a straight line) plays a role analogous to that of a set of consecutive tap inputs that exist in a transversal filter at a particular instant of time. In radar imaging, the sensors consist of antenna elements (e.g., dipoles, horns, slotted waveguides) that respond to incident electromagnetic waves.</p><p>In sonar method, the sensors consist of hydrophones designed to respond to acoustic waves. In any event, spatial filtering, known as beam forming, is used in these systems to distinguish between the spatial properties of signal and noise.</p><p>The device used to carry out the beam forming is called a beam former. The term beam former is derived from the fact that the early forms of antennas (spatial filters) were designed to form pencil beams, so as to receive a signal radiating from a specific direction and attenuate signals radiating from other directions of no interest <ref type="bibr" target="#b105">[106]</ref>.</p><p>Note that the beam forming applies to the radiation (transmission) or reception of energy. Figure <ref type="figure">8</ref>.4 shows the spatial mapping of different cardiac-microphone location, by using adaptive PCG beam forming reconstruction, where the spatial-deviation is considered as an binomial function of received microphone intensities. In a primitive type of spatial filtering, known as the delay-and- sum beam former, the various sensor outputs are delayed (by appropriate amounts to align spatial components coming from the direction of a target) and then summed. As Fig. <ref type="figure">8</ref>.5 illustrates, five microphone locations are specified for covering the all direction-of-arrival (DOA) of the heart acoustic waves. Accordingly, for a single target the average power at the output of the delay-andsum beam former is maximized when it is steered toward the target. However, a major limitation of the delay-and-sum beam former, even so, is that it has no provisions for dealing with sources of interference. The dynamic properties of the heart acoustic vibration, shows a nonlinear behavior, and this is due to the propagation in a non-homogeneous medium through thoracic cavity. Additionally, the curvature of the microphone array is not symmetric due to the geometric parameters of the thorax.</p><p>In order to enable a beam former to respond to an unknown interference environment, it has to be made adaptive in such a way that it places nulls in the direction(s) of the source(s) of interference automatically and in real time.</p><p>By a similar approach, the output signal-to-noise ratio of the system is increased, and the directional response of the system is thereby improved.This method was also applied in localizing the acoustic source in many engineering and medical applications (e.g., infra-oceanic acoustic mapping and vital signal monitoring based on sonar-wave <ref type="bibr" target="#b102">[103,</ref><ref type="bibr" target="#b104">105]</ref>).</p><p>The localization of the acoustic source can be illustrated in a delay-source-receiver method, which is considered as a robust and effective method for heart sound localization. The method is simply based on the delay between signals received at two microphones is found by cross-correlation. For instance, delay1-2 is the delay between the time it takes for the signal to arrive at microphone 1 compared to microphone 2. Then, the delay is converted from sampled time units to distance units, as in Equ. <ref type="bibr">(8.2)</ref>. This new delay, delta1-2, represents the difference between the distance from microphone (mic1) to the source and from microphone (mic2) to the source (as shown in Fig. <ref type="figure">8</ref> This two equation, with two unknown variables, which can be solved through any technical computation language such as MATLAB ® or LabVIEW ® computation software platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.2">ADAPTIVE BEAM FORMER WITH MINIMUM-VARIANCE DISTORTIONLESS RESPONSE</head><p>Consider the adaptive beam former module that uses a linear array of (M) identical sensors, as presented in Fig. <ref type="figure">8</ref>.5. The individual sensor outputs, assumed to be in baseband form, are weighted and then summed. The beam former has to satisfy two requirements:</p><p>1. A steering capability whereby the target signal is always protected.</p><p>2. The effects of sources of interference whereby; the effects are minimized.</p><p>One method of providing for these two requirements is to minimize the variance (i.e., average power) of the beam former output, subject to the constraint that during the process of adaptation the weights satisfy the condition. Thus, the target signal steering and source inference will affect the target-image reconstruction with a considerable delay-time <ref type="bibr" target="#b106">[107,</ref><ref type="bibr" target="#b107">108]</ref>.</p><p>w H (n)s(φ) = 1 for all n and φ = φ t , <ref type="bibr">(8.10)</ref> where w(n) is the M×1 weight vector, and s(φ) is an M×1 steering vector. The superscript H denotes Hermitian transposition (i.e., transposition combined with complex signal conjugation). In this application, the baseband data are complex valued, hence the need for complex conjugation. The value of the electrical angle φ=φ t is determined by the direction of the target. The angle φ is itself measured with sensor (1) (at the top end of the array) and treated as the point of reference. The dependence of vector s(φ) on the angle φ is defined by: s(φ) = [1, e -jφ , ..., e -j (M-1)φ ] T . <ref type="bibr">(8.11)</ref> The angle φ is itself related to incidence angle θ of a plane wave, measured with respect to the normal to the linear array as follows: φ = 2πd λ sin(θ ), <ref type="bibr">(8.12)</ref> where (d) is the spacing between adjacent sensors of the array and λ is the wavelength. The incidence angle (θ) lies inside the range -π /2 to π /2. The permissible values that the angle φ may assume lie inside the range (-π to π). This means that we must choose the spacing d &lt; λ/2, so that there is a one-to-one correspondence between the values of φ and θ without ambiguity. The condition d &lt; λ/2 may be viewed as the spatial analog of the sampling theorem. Figure <ref type="figure">8</ref>.6 displays the general schematic of PATI-imaging technique, where (A) cylindrical model of cardiac microphone positions, (B) a corresponding chest x-ray radiography shows, the planar view of thorax anatomy, and (C) reconstructed acoustic mapping for microphones intensity and the spatial location of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.3">HEART SOUNDS PHYSIOLOGICAL MODELING BASED ON PATI METHOD</head><p>The present interaction between medical imaging and modeling is mutual validation-the process of comparing data from model and imaging systems. This integration has numerous advantages from both modeling and imaging perspectives. Firstly, validating model predictions against imaging data provides a mechanism for testing that the model captures all the key physiological components of the system. This is performed for a prescribed set of parameter values <ref type="bibr" target="#b109">[110,</ref><ref type="bibr" target="#b111">112]</ref>, and once completed, the model is a powerful tool to establish predictions of the system properties in new regimes.</p><p>From an imaging perspective, models can be used to extract information that is not directly available from the images themselves and thus will assist in the clinical diagnosis. For example, the mechanical stress or work of a contractile tissue cannot be detected directly from an image but is straightforward to extract from a model parameterized from same information.</p><p>This simulation-based imaging (in silico) approach provides significant capacity to define new metrics for focusing clinical trials <ref type="bibr" target="#b111">[112,</ref><ref type="bibr" target="#b114">115,</ref><ref type="bibr" target="#b115">116]</ref>, optimizing patient selection and customizing therapy <ref type="bibr" target="#b105">[106,</ref><ref type="bibr" target="#b106">107]</ref>. The relationship between the new invited modality of (PATI) as cardiac acoustic mapping technique and relevant physiological modeling approach for the cardiac hemodynamics is mutually connected in its nature and have consisted application in physio-acoustic system identification.</p><p>The use of PATI technique will be such a prospective research in modeling and simulation cardiac acoustic dynamics in accompanied with multi-modality medical imaging such as highresolution computerized tomography (Hi-Rez CT). Figure <ref type="figure">8</ref>.7 shows the image reconstruction of various microphone located spatially, which detects the defined target acoustic variation in a geometric setting. The advances in the real-time image reconstruction <ref type="bibr" target="#b110">[111,</ref><ref type="bibr" target="#b112">113,</ref><ref type="bibr" target="#b113">114,</ref><ref type="bibr" target="#b116">117]</ref> and image acquisition optimization will also reflect on the further development of the precise and accurate cardiac acoustic imaging <ref type="bibr" target="#b107">[108,</ref><ref type="bibr" target="#b109">110]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">SUMMARY</head><p>The cardiac acoustic imaging method is considerably non-competitive to other medical imaging modalities such as the x-ray, CT, MRI, and PET-imaging techniques in terms of the anatomical and physiological information that they supply. The preliminary experimental results are encour- aging and motivates researcher to be open to a new diagnostic possibility. To stand that further optimization and development in cardiac microphone sensor technology, hardware design, signal processing algorithms, and advances in information technology to reduce the computational cost of the algorithm, the PATI-imaging technique may become a routine monitoring technique before using the other conventional methods, due to its noninvasive approach and simple implementation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5.">SUMMARY 177</head><p>In addition, the technical complications and the deficiency in the cardiac acoustic image quality can also be improve by synchronized compensation of additive noise and acoustic disturbances which may infer spatial and temporal representation of the detected PCG signals.</p><p>Although this new medical imaging suffers from a low spatial and temporal resolution, it could be proved to be a good choice for low-cost and mobility strategy in cardiac imaging, rather than the ultrasound imaging and SPECT imaging module. The expected research direction should be guided to improve the image quality, increase the SNR value of the acoustic detectors, and enhance the microphone-matrix design to be a good choice for clinical imaging application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feedback from Clinical and Biomedical Aspects</head><p>The new direction of medical engineering toward more automated and intelligent systems reflects on the future trends of many clinical applications of biomedical signal processing, and this indeed will optimize both the diagnostic methods and the philosophy of clinical and medical data interpretation-analysis loop. Moreover, the use of the new embedded technology, artificial intelligence, higher computational algorithms, and state-of-the-art biomedical devices will make the health care process and its collaterals more effective in assigning, integrating and delivering the suitable medical care to the vast number of patients.</p><p>In addition, the rapid and expected needs in developing and enhancing the quality of life will lead to increasing expectations for the inventing and synthesis of new medical technologies originated from current trends in development and practical application of the life sciences. The development of non-invasive biomedical instrumentation technology to measure and transduce the physiological information and signals generated by the living subject in a minimally invasive and continuous fashion, was responsible for the establishment of the reasonable concept of patient monitoring.Therefore, the impression of cardiac acoustic signal signature on the clinical and medical practicing will increase in its impression, and will be of great interest for biomedical and clinical engineers who work in the physiological and bioacoustics field.</p><p>Although this field has many technical and physical obstacles, but it is considered a straightforward and easy-to-handle medical diagnostic procedure. The phonocardiography and auscultation technique is still nascent, compared to advanced analysis methods. On the other hand, the slow development curve of cardiac-acoustics analysis itself provides an open field for promoting research and investigation. The advanced technique of heart sound analysis and processing should be more impressive and robust, in order to make the cardiac auscultation method more productive in clinical diagnosis and medical primary care. The combination of multiple points of view, from clinical and engineering specialists, will be of a great influence on maturity of biomedical instrumentation and medical technology.</p><p>This book, from the authros' point of view, provides a good reference for the biomedical engineering student who seeks productive resources in phonocardiography signal processing and its related fields of interests. The book also presents a relatively new approach in cardiac acoustic mapping, which seems to be of a great privilege for advanced research in bioacoustics. Additionally, this will require appropriate post-processing techniques that efficiently deal with phonocardiography signal.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 . 1 :</head><label>11</label><figDesc>Figure 1.1: Analog and digital signal processing concepts.</figDesc><graphic coords="27,148.11,239.93,329.90,86.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 . 2 :</head><label>12</label><figDesc>Figure 1.2: Block diagram of the general biomedical signal processing and analysis, as an integrative approach for computer-aided diagnosis system.</figDesc><graphic coords="28,137.80,360.24,350.50,190.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 . 3 :</head><label>13</label><figDesc>Figure 1.3: Right side: vertical section of the cardiac muscle shows the internal structure of the heart. Left side: schematic representation of a reciprocating type pump having a pumping chamber and input output ports with oppositely oriented valves.</figDesc><graphic coords="29,143.47,306.48,337.76,255.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 . 4 :</head><label>14</label><figDesc>Figure 1.4: Cardiac cycle events occurring in the left ventricle. Above: Pressure profile of the ventricle and atrium. Middle: Volume profile of the left ventricle. Below: Phonocardiographgy signals. This diagram consists of three main stages: (1) signal data acquisition, (2) signal pre-processing, and (3) signal postprocessing and analysis.</figDesc><graphic coords="31,141.88,135.60,345.20,351.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 . 5 :</head><label>15</label><figDesc>Figure 1.5: Phonocardiography synchronization with hemodynamic tracing in cardiac cycle showing the fundamental events of this cycle and the associated electrical, mechanical, acoustic annotation, and pressure waveform for corresponding cycle events.</figDesc><graphic coords="33,127.49,439.59,371.20,169.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1. 7 . 11 Figure 1 . 6 :</head><label>71116</label><figDesc>Figure 1.6: Schematic diagram of left ventricular pressure volume loop.</figDesc><graphic coords="35,121.42,132.28,382.00,340.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 1 . 7 :</head><label>17</label><figDesc>Figure 1.7: Right side: Cardiac electrical conduction system morphology and timing of action potentials from different regions of the heart. Left side: related ECG signal as measured on the body surface.</figDesc><graphic coords="37,122.78,130.14,382.91,404.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 1 . 8 :</head><label>18</label><figDesc>Figure 1.8: Pressure diagram of left ventricle (LV) and left atrium (LA) versus heart sound trace showing related heart sounds mummers in the case of aortic stenosis (AS) disorder.</figDesc><graphic coords="40,144.94,149.06,336.25,218.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 1 . 9 :</head><label>19</label><figDesc>Figure 1.9: Cardiac cycle events for mitral valve stenosis disorder. Above: the carotid artery pulse. Below: mitral stenosis murmurs (MSM) and early systolic murmur (ES).</figDesc><graphic coords="40,144.89,428.85,336.34,182.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 1 . 10 :</head><label>110</label><figDesc>Figure 1.10: Rene Theophile Hyacinthe Laennec the inviter of stethoscope (Photograph courtesy of the National Library of Medicine).</figDesc><graphic coords="45,189.36,179.05,251.39,296.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 1 . 11 :</head><label>111</label><figDesc>Figure 1.11: The ECG, PCG (low and high filtered), carotid pulse, apex cardiogram, and logic states (high-open) of left heart valves, mitral and aortic valve, right heart valves, and tricuspid and pulmonary valve. Left heart mechanical intervals are indicated by vertical lines: isovolumetric contraction (1), ejection (2), isovolumetric relaxation (3), and filling (4) (rapid filling, slow filling, atrial contraction). The low-frequency PCG shows the four normal heart sounds (I, II, III, and IV). In the high-frequency trace, III and IV have disappeared and splitting is visible in I [Ia and Ib (and even a small Ic due to ejection)] and in II [IIA (aortic valve) and IIP (pulmonary valve)]. Systolic intervals LVEP (on carotid curve) and Q-IIA (on ECG and PCG) are indicated.</figDesc><graphic coords="47,119.83,142.50,381.07,394.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 1 . 12 : 25 Figure 1 . 13 :</head><label>11225113</label><figDesc>Figure 1.12: Main cardiac auscultation site used for acquiring heart sound, as indicated by American Heart Association(Ref:AHA, 1987)</figDesc><graphic coords="48,142.79,133.83,344.35,246.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 2 . 1 :</head><label>21</label><figDesc>Figure 2.1: Phonocardiography trace with 8 successive S 1 -S 2 waveform.</figDesc><graphic coords="54,146.23,150.84,335.97,202.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 2 . 2 :</head><label>22</label><figDesc>Figure 2.2: (a) PCG signal recording with different filtering coefficient for different corresponding heart sound class</figDesc><graphic coords="54,98.84,385.17,428.41,225.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 2 . 2 :</head><label>22</label><figDesc>Figure 2.2: (b) Energy level of the PCG signal for 100-200Hz frequency with phase line of 0-25 rad and PCG amplifier gain range of 2 mV, observe that the maxium detectable energy occurred at low phase difference at the high PCG gain profile.</figDesc><graphic coords="55,105.79,163.26,431.80,406.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 2 . 3 :</head><label>23</label><figDesc>Figure 2.3: Audible range of phonocardiography signal spectrum.</figDesc><graphic coords="57,182.95,134.43,256.56,209.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 2 . 4 :</head><label>24</label><figDesc>Figure 2.4: Echocardiogram of the heart valves dynamics and the blood flow dynamics through them.</figDesc><graphic coords="57,148.11,442.77,329.90,123.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 2 . 5 :</head><label>25</label><figDesc>Figure 2.5: Frequency ranges and energy level of audible heart sounds and murmurs.</figDesc><graphic coords="59,166.00,400.53,296.58,235.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 2 . 6 :</head><label>26</label><figDesc>Figure 2.6: Phonocardiography sound pressure level in clinical application spectrum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 2 . 7 :</head><label>27</label><figDesc>Figure 2.7: Phonocardiography signal tracing scheme for different frequency bandwidth.</figDesc><graphic coords="60,122.42,232.62,381.35,287.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 2 . 8 :</head><label>28</label><figDesc>Figure 2.8: Electronic stethoscope system with ability to store and record phonocardiography traces [Ref: Cardionics Inc. 2008, USA].</figDesc><graphic coords="62,146.79,224.62,329.90,213.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 2 . 9 :</head><label>29</label><figDesc>Figure 2.9: Automated phonocardiography analyser that is based on multichannel acoustic equalization. This module is also used as a training simulator for cardiac auscultation purposes. Cardionics Inc. for digital sthetoscope</figDesc><graphic coords="64,168.74,138.36,288.70,246.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 2 . 10 :</head><label>210</label><figDesc>Figure 2.10: Normal young subject recorded tracing. Above: Electrocardiogram (ECG), Phonocardiography(PCG) at 3 rd left inter-space, PCG (60-120Hz), PCG (480-1000Hz)-same area, PCG (1000-2000Hz). PCG tracings 1, 2, 3 are simultaneous; the others are identically superimposed. To be observed.: the division of the 1 st sound to two groups of vibrations to all filtered tracings and their relationship. (B) and (C) Tracings recorded over the 2 nd left inter-space in subject with pulmonary hypertension(PH). (B) The lower tracing (240/480) reveals that the pulmonary component is larger than the aortic.(C) The lower tracing (750-1000) reveals that the pulmonary component has the same amplitude as the aortic.</figDesc><graphic coords="65,140.65,154.43,344.46,392.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 2 . 11 :</head><label>211</label><figDesc>Figure 2.11: Filter response of low-pass filter apply to phonocardiography signal. The response vary in a nonlinear zone due to redundant noise in the stethoscope unit.</figDesc><graphic coords="67,173.08,136.42,273.97,254.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 2 . 12 :</head><label>212</label><figDesc>Figure 2.12: 3D diagram of cardiac microphone structure and equivalent electrical circuit.</figDesc><graphic coords="73,179.05,184.46,292.22,262.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 2 . 13 :</head><label>213</label><figDesc>Figure 2.13: A cross-section of a capacitor microphone used in phonocardiography acquisition.</figDesc><graphic coords="74,187.93,197.40,250.26,192.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 2 . 14 :</head><label>214</label><figDesc>Figure 2.14: (a) Schematic diagram of equivalent circuits which represents the cardiac microphone system; (b)r Simplified linear circuit of the cardiac capacitive-microphone.</figDesc><graphic coords="75,185.75,207.87,253.42,240.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 3 . 1 :</head><label>31</label><figDesc>Figure 3.1: Phonocardiography signal processing loop.</figDesc><graphic coords="80,147.48,136.88,331.13,181.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 3 . 2 :</head><label>32</label><figDesc>Figure 3.2: Mitral stenosis (MS) spectrogram of an acquired PCG signal.</figDesc><graphic coords="82,147.63,137.90,330.87,188.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>3. 4 . 2 S 2</head><label>422</label><figDesc>CARDIAC SOUND MODELINGCompared to S 1 , the underlying mechanisms associated with S 2 are more widely accepted. The aortic component (Ao2) is produced during the closure of the aortic valve while the pulmonary component (Pl2) results from the closure of the pulmonary valve. Each component usually lasts for less than 80 ms. During expiration the two components come closer together (less than 15 ms) while during inspiration, they are separated by 30-80 ms<ref type="bibr" target="#b59">[60]</ref>. The separation between the two components is mostly due to different intervals of ventricular systole for the left and the right side of the heart, which is modulated by respiration rhythm as a driving signal for cardiac cycle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head></head><label></label><figDesc>Figure 3.3 illustrates the PCG fast fourier transformation (FFT) over the acoustic oscillation spectrum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 3 . 3 :</head><label>33</label><figDesc>Figure 3.3: Fourier transform of PCG signal illustrates variation of amplitude along a wide spectrum of oscillation frequency.</figDesc><graphic coords="84,142.70,132.99,340.74,267.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 3 . 4 :</head><label>34</label><figDesc>Figure 3.4: Power spectrum of two different PCG signal illustrate different contents of frequency component.</figDesc><graphic coords="85,121.59,187.65,379.82,153.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head></head><label></label><figDesc>provision of diagnosis. Moving toward the goal of automatic diagnosis of heart diseases, computerbased heart sound analysis techniques will continue to evolve. Many advanced signal processing algorithms and data analysis models, for example wavelet transform, adaptive filtering, artificial neural network, and pattern recognition, have already provided new insight into the diagnostic value of heart sound. The exploration of further techniques in the coming years would hopefully help to realize the full potential of cardiac auscultation as a tool for the early detection of heart diseases. Fig.3.5 shows GUI of labVIEW programming platform for PCG signal acquisition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 3 . 5 :</head><label>35</label><figDesc>Figure 3.5: Graphical user interface for PCG signal acquisition and analysis based on labVIEW programming platform.</figDesc><graphic coords="86,127.49,246.25,371.20,205.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Figure 3 . 6 :</head><label>36</label><figDesc>Figure 3.6: Oscillometric blood pressure measurement procedure which integrate with the phonocardiography to optimize the non-invasive blood pressure measurement.</figDesc><graphic coords="88,143.38,134.82,338.18,195.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>Figure 3 . 7 :</head><label>37</label><figDesc>Figure 3.7: Phonocardiography signal processing used in many cardiovascular clinical application, where (A) is application of heart sound in performance test of left-ventricular assistive device (LVAD), (B) Use of PCG in the respiratory system synchronization test, (C) Application of PCG signal with ECGacquisition for a physiological system modeling and correlation. and (D) is the ?????.</figDesc><graphic coords="89,148.11,138.38,333.93,318.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head></head><label></label><figDesc>Due to the technique by which PCG is measured, studies have shown that time-related parameters derived from PCG are not affected by pre-ejection period (PEP) as conducted by Hasegawa et al. (1991) and Visser et al. (1993).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 4 . 1 :</head><label>41</label><figDesc>Figure 4.1: Phonocardiography wavelets transformation based on biorthogonal signal decomposition.</figDesc><graphic coords="93,134.16,134.16,357.78,229.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 4 . 2 :</head><label>42</label><figDesc>Figure 4.2: Fourier analysis of phonocardiography (above) the phase of PCG trace (below). The FFTamplitude of the same PCG signal.</figDesc><graphic coords="94,155.43,134.78,315.90,255.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head>Figure 4 . 3 :</head><label>43</label><figDesc>Figure 4.3: PCG signal wavelets analysis of different cardiac valvular disorder (right) normal cardiac murmurs, (middle) mitral regurgitation, (left) mitral stenotic PCG trace, and the corresponding wavelet derived spectrum for each cases.</figDesc><graphic coords="96,125.35,136.20,379.08,361.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head>.12) 4 . 2 . 3</head><label>423</label><figDesc>DEBAUCHIES (DB) WAVELET Another example of wavelets defined on the real line is Daubechies wavelets in which Figs.4.4 and 4.5 show Db-wavelet transformation of a different PCG signals. The Daubechies wavelets show a robust result in the analysis of linear time-varying biomedical signals, due to it ability to compensate for missed coefficient in the final decomposition paradigm. The φ D 3 is the Daubechies scaling function, and it is defined by the following relation:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><head>Figure 4 . 4 :</head><label>44</label><figDesc>Figure 4.4: Application of Db-Wavelet transformation on PCG signal for different clinical cases.</figDesc><graphic coords="98,156.32,135.33,319.84,260.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Figure 4 . 5 :</head><label>45</label><figDesc>Figure 4.5: Db-wavelet AS (aortic stenosis) phonocardiography signal decomposition with six-level denoising.</figDesc><graphic coords="98,135.57,433.76,354.60,198.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>Figure 4 . 6 :</head><label>46</label><figDesc>Figure 4.6: Decomposition of PCG signal based on wavelets approach.</figDesc><graphic coords="102,103.99,135.52,417.21,318.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head>Figure . 4</head><label>4</label><figDesc>.<ref type="bibr" target="#b6">7</ref> shows different wavelet transformation procedures such as Morlet, Meyer, Gaussian, and Mexican hat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_46"><head>Figure 4 . 7 :</head><label>47</label><figDesc>Figure 4.7: Wavelet transformation family (a) Morlet, (b) Meyer, (c) Gaussian, (d) Mexican hat.</figDesc><graphic coords="104,127.99,407.52,374.44,258.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_47"><head>Figure 4 . 8 :</head><label>48</label><figDesc>Figure 4.8: 3D phonocardiography signal decomposition based on DWT-method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_48"><head>Figure 4 . 9 :</head><label>49</label><figDesc>Figure 4.9: Phonocardiography adaptive wavelet pattern detection based on Least square optimization (LEO) algorithm, where (A) temporal representation of PCG-adaptive wavelet function; (B) is Dbwavelet function; (C) scaled coefficients of adaptive wavelet function; (D) the scale coefficients plot of Db-wavelet function.</figDesc><graphic coords="106,125.34,136.63,375.50,300.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_49"><head>Figure 4 . 10 :</head><label>410</label><figDesc>Figure 4.10: Shannon wavelet decomposition template used for optimization pattern detection of PCG signal.</figDesc><graphic coords="107,103.12,132.29,418.97,298.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_50"><head>Figure 4 . 11 :</head><label>411</label><figDesc>Figure 4.11: Block diagram of the PCG ARMAX system identification, the computational loop consist of clinical monitoring system (Ohmeda Medical. Inc. USA) which is connected to the analysis workstation of Windows-based platform. The main kernel consist of the (1) nonlinear weighting function, (2) ARMAX-identification</figDesc><graphic coords="108,146.97,137.18,333.31,285.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_51"><head>Figure 5 . 1 :</head><label>51</label><figDesc>Figure 5.1: Normal eight PCG signal traces with corresponding spectral distribution over frequency range and through time course of signal recording.</figDesc><graphic coords="110,158.43,342.65,309.30,218.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_52"><head>Figure 5 . 2 :</head><label>52</label><figDesc>Figure 5.2: Mitral-valve regurgitation PCG-signal trace and its related spectral distribution over frequency range and corresponding time course of recording.</figDesc><graphic coords="111,148.11,174.55,329.90,294.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_53"><head>Figure 5 . 3 :</head><label>53</label><figDesc>Figure 5.3: Phonocardiography energy detection flow diagram based on spectral estimation with higherorder clustering to identify the energy signature of the heart, in order to discriminate cardiac work during systolic-diastolic phase.</figDesc><graphic coords="112,147.33,269.35,334.05,321.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_54"><head>Figure 5 . 4 :</head><label>54</label><figDesc>Figure 5.4: DFT-based Fourier analysis system for continuous-time signals.</figDesc><graphic coords="115,144.94,448.12,334.82,177.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_55"><head>5. 2 . 95 Figure 5 . 5 :</head><label>29555</label><figDesc>Figure 5.5: Correlation 3D-contouring of PCG signal based on periodogram method</figDesc><graphic coords="119,99.94,133.60,426.25,300.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_56"><head>Figure 5 . 6 :</head><label>56</label><figDesc>Figure 5.6: Spectral representation of cardiac PCG signal with assigned to aortic stenosis.</figDesc><graphic coords="122,103.24,347.27,422.70,211.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_57"><head>Figure 5 . 7 :</head><label>57</label><figDesc>Figure 5.7: Schematics of phonocardiography simulation for adaptive FIR-model prediction process, where in the input PCG-signal x[n] to IIR-filtering; d[n] is the predicted signal, R xx ,r xd are the correlation matrix and covariance vector, respectively, the y[n] is the adaptive FIR-filtering system output; and k[n] is the background noise-source in the adaptive PCG-processing loop.</figDesc><graphic coords="124,105.85,138.34,415.23,260.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_58"><head>Figure 5 . 8 :</head><label>58</label><figDesc>Figure 5.8: Block diagram of phonocardiography identification based on adaptive ARMA modeling technique.The measured input signal represents phonocardiograph time-function, successively this signal interact with cardiac acoustic dynamics. The noise signal n(t) (disturbance), will be summed with physical variable, the two channel (input and output) are connected to the ARMA-identification model to extract pole and zero-coefficients for cardiac acoustic model.</figDesc><graphic coords="125,123.77,132.97,380.73,257.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_59"><head>Figure 5 . 9 :</head><label>59</label><figDesc>Figure 5.9: Embedded system component of digital stethoscope and ECG signal into one compact CDS-unit which will be used widely in health care facilities and clinical mobile system.</figDesc><graphic coords="129,106.87,138.31,415.48,300.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_60"><head>Figure 5 . 10 :</head><label>510</label><figDesc>Figure 5.10: Visual electronic stethoscope (VES) system with multi-parametric physiological signals (SpO2, ECG, and heart sounds); Ref: CMS-VE, China.</figDesc><graphic coords="130,167.47,137.10,291.24,270.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_61"><head>Figure 6 . 1 :</head><label>61</label><figDesc>Figure 6.1: Substantial PCG pattern recognition system elements and signal flow diagram, which represents the principal strategy for PCG signal classification.</figDesc><graphic coords="133,104.64,405.54,416.29,160.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_62"><head>2 .</head><label>2</label><figDesc>Compute the means of each of the clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_63"><head>3 .</head><label>3</label><figDesc>Reassign each object to the cluster with the closest mean μk.4. Return to step 2 until the means of the clusters do not change anymore.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_64"><head>Figure 6 . 3 :</head><label>63</label><figDesc>Figure 6.3: Sub-Euclidean K-mean classification result for seven input PCG signal ranging from aortic stenosis (AS), mitral regurgitation (MR), diastolic murmurs, and pulmonary valve stenosis (PS).</figDesc><graphic coords="136,143.74,342.66,338.64,268.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_65"><head>Figure 6 . 4 :</head><label>64</label><figDesc>Figure 6.4: Block diagram of principal component analysis (PCA) of phonocardiography signal. The signal flow diagram, including four cardia microphone acquisition, directed to ICU-bedside monitoring. By applied in line-signal filtering and noise-attenuation module, the vibration sources from the 4-auscultation site were localized. In addition, this technique can be used for diagnosis of a respiratory disease by using 'lung sound analysis module' and tracheal-microphone to classify and estimate bronchial and tracheal pathological cases. phonocardiography pattern classification was first used by Kuenter et al. (2002) where they combined methods for classification of high-dimension PCG data acquired from different patient groups for evaluating the performance of implanted heart valves.For a PCG-data matrix, X T P CG , with zero empirical mean (the empirical mean of the distribution has been subtracted from the data set in previous filtering stage), where each row represents a different repetition of the auscultation experiment, and each column gives the results from a</figDesc><graphic coords="139,148.11,213.51,331.49,273.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_66"><head>6. 6 . 117 Figure 6 . 5 :</head><label>611765</label><figDesc>Figure 6.5: PCA decomposition of PCG signal, where the above-left graph represents the extracted 7-PCG signal trace SIR index with the mean of 1.678 dB, and the above-right graph represents the energy level of the same PCG trace in the original mixing PCA-scheme, with a mean SIR value of 15.8068 dB. The bottom graph represents decomposed PCG trace with PCA-algorithm, according to Eq. 6.5.</figDesc><graphic coords="141,116.25,138.44,393.05,350.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_67"><head>Figure 6 . 6 :</head><label>66</label><figDesc>Figure 6.6: Block diagram of ICA-PCG signal classification and source localization, which use blind source separation (BSS).The internal stage between input PCG vectors X(t) and Z(t) consists of sub-band decomposition, normalization-mean data homogeneity (HNM), signal event decomposition, weighting coefficients setting, and programmable gain amplifier system at the output stage of ICA-BSS module.</figDesc><graphic coords="144,105.97,137.48,416.01,199.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_68"><head>Figure 6 . 7 :</head><label>67</label><figDesc>Figure 6.7: Fixed-point ICA PCG signal decomposition structure, which is used in localizing and classifying of the PCG signal vector [56].</figDesc><graphic coords="145,126.12,186.58,373.95,359.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_69"><head>Figure 6 . 8 :</head><label>68</label><figDesc>Figure 6.8: Performance results of independent component analysis (ICA-fixed point) of PCG signal, where (A) 3D performance index for signal classified according to input vectors; (B) Signal-inferenceratio (SIR) of PCG signals at -3dB attenuation diagram.</figDesc><graphic coords="147,104.74,138.39,417.09,312.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_70"><head>Figure 6 . 9 :</head><label>69</label><figDesc>Figure 6.9: A multilayer feed forward neural network with L-hidden layer that widely used in many signal processing and pattern classification application.</figDesc><graphic coords="149,106.87,135.45,412.45,215.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_71"><head>Figure 6 . 10 :</head><label>610</label><figDesc>Figure 6.10: The relationship between feature map ( ) and weight vector y i of winning neuron i.</figDesc><graphic coords="150,168.36,137.88,289.58,391.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_72"><head>Figure 6 . 11 :</head><label>611</label><figDesc>Figure 6.11: Simulink block diagram of PCG signal self-organizing mapping classification system, which uses adapted ANN-architecture for mapping different cardiac acoustic patterns. The bottom part shows the schematics for simulink realization of the SOM-network.</figDesc><graphic coords="151,101.45,248.42,423.24,269.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_73"><head>Figure 6 . 12 :</head><label>612</label><figDesc>Figure 6.12: Weights matrix for self-organizing mapping (SOM) which are used to classify PCG patterns.</figDesc><graphic coords="153,147.22,137.96,331.70,291.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_74"><head>Figure 6 . 13 :</head><label>613</label><figDesc>Figure 6.13: Four PCG signal pattern classification based on SOM-clustering technique, where these signal classifier using 34-layer SOM-neural network classifier system.</figDesc><graphic coords="154,148.11,204.77,329.90,298.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_75"><head>Figure 6 . 14 :</head><label>614</label><figDesc>Figure 6.14: Phonocardiography SOM classification weighting mapping indicated that a shift in the linear distribution of the weights could be useful in identifying PCG dynamics variation.</figDesc><graphic coords="155,127.49,138.35,371.20,210.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_76"><head>Figure 6 . 15 :</head><label>615</label><figDesc>Figure 6.15: Phonocardiography weights coefficient for a training classification applied to 6-PCG vectors, where (A) is the SOM weights spatial distribution, (B)is the covariance index for the 6-PCG signals.</figDesc><graphic coords="156,103.95,129.64,419.70,363.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_77"><head>Figure 6 . 16 :</head><label>616</label><figDesc>Figure 6.16: Classification scheme of phonocardiography signal illustrates five dominant heart sounds pattern.</figDesc><graphic coords="157,127.49,365.61,372.44,251.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_78"><head>Figure 6 . 17 :</head><label>617</label><figDesc>Figure 6.17: 3D representation of classified phonocardiography signals used K-mean neighborhood method: (a) normal heart sound; (b) aortic stenosis; (c) mitral valve regurgitation; (d) contouring plot of phonocardiography.</figDesc><graphic coords="160,127.49,210.74,371.20,301.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_79"><head>Figure 7 . 1 :</head><label>71</label><figDesc>Figure 7.1: Fetal phonocardiography tracing (above) in accompaniment with fECG tracing (below) and the noisy signal can be observed in this graphical trace (Ref: Fetal clinical monitoring, 2004).</figDesc><graphic coords="168,140.38,137.33,340.80,189.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_80"><head>Figure 7 . 2 :</head><label>72</label><figDesc>Figure 7.2: Figure schematics of fetal phonocardiography acquisition setup.The four locations of cardiac microphone to pick up phonocardiography traces of the fetus.</figDesc><graphic coords="169,166.82,135.96,293.16,286.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_81"><head>Figure 7 .</head><label>7</label><figDesc>3 displays different vital parameters with mitral stenosis ICP traces where the above</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_82"><head>Figure 7 . 3 :</head><label>73</label><figDesc>Figure 7.3: Double manometer study. Mitral stenosis (MS), sinus rhythm (SR). Top to bottom: intra cardiac phonocardiogram, left atrium, intra-cardiac phonocardiogram, left ventricle; left atrial pressure pulse; left ventricular pressure pulse; electrocardiogram, lead II. Time lines 40 ms. Paper speed 100 mm/s.(Ref:AHA 1976.)</figDesc><graphic coords="172,154.18,338.00,319.95,173.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_83"><head>Figure 7 . 4 :</head><label>74</label><figDesc>Figure 7.4: ICP-clinical instruments setup with four basic intra-cardiac inlets and the cardiac microphone unit that hinged with Swan-type catheter inserted through vascular route to record internal acoustic vibration of myocardium.</figDesc><graphic coords="174,122.24,137.69,377.11,218.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_84"><head>Figure 7 . 5 :</head><label>75</label><figDesc>Figure 7.5: Intra-arterial sound and instantaneous aortic velocity in a patient with a normal aortic valve and cardiac output (5.4 L/min), a patient with a normal valve and high cardiac output (12.9 L/min), a patient with aortic insufficiency, and a patient with aortic stenosis. The point velocities were redrawn on an identical scale to show clearly the relation between velocity, turbulence, and intra-arterial sound. It is apparent that as blood velocity and turbulence increased, arterial sound also increased from normal 100 P.D. (Reprint from Stein, 1978, [96].)</figDesc><graphic coords="175,124.77,132.89,380.28,290.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_85"><head>Figure 7 . 6 :</head><label>76</label><figDesc>Figure 7.6: Schematic of ICP signal acquisition and processing, where the input transducer is the intracardiac microphone, and low-pass filtering is used to remove parasitic ambient noise (from near lung activity and large vessels blood flow. The baseline matching to avoid any amplitude drift in the ICP signals is an FFT step performed before valvular component identification. The feature-extraction kernel used to separate S 1 , S 2 , S 3 , and S 4 ; the analysis results displayed on medical certified laptop platform.</figDesc><graphic coords="176,146.86,137.17,332.36,249.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_86"><head>Figure 7 . 7 :</head><label>77</label><figDesc>Figure 7.7: Adaptive noise cancellation method, for separation and suppression of lung sound from heart sound. The cancellation method depends on the adaptive IIR-filtering and parametric estimation algorithm to remove progressive overlapping source (e.g., lung sound) to take part in signal acquisition loop.</figDesc><graphic coords="177,147.73,395.04,336.38,149.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_87"><head>Figure 7 . 8 :</head><label>78</label><figDesc>Figure 7.8: Block diagram of adaptive filtering that is used to eliminate the parasitic noise and disturbances which affect and infer the PCG signal; the noise source here assigned to the lung sounds (LS) and other ambient noise sources originated nearby the cardiac microphone. The PCG signal is to be amplified in programmable gain amplifier (PGA) in order to equilibrate the intensity drift during PCG acquisition.</figDesc><graphic coords="178,148.11,227.51,329.92,158.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_88"><head>Figure 7 . 10 :</head><label>710</label><figDesc>Figure 7.10: PCG traces during atrial fibrillation state, which can be used to extract timing scheme for driving pacemaker stimulation rate. This technique may have a potential application in cardiac embedded pacing and monitoring.</figDesc><graphic coords="182,155.77,135.21,318.85,241.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_89"><head>Figure 7 . 11 :</head><label>711</label><figDesc>Figure 7.11: Schematic of the PCG-signal processing application in pacemaker driving system, where PCG signal can play a role as a trigger event for cardiac assist device (CAD), implantable cardiac pacemaker, and as navigator-guidance for intra-vascular catheterization.</figDesc><graphic coords="183,127.10,261.31,371.98,260.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_90"><head>Figure 8 . 1 :</head><label>81</label><figDesc>Figure 8.1: Block diagram of technical experimental setup for phonocardiography acoustics tomography imaging (PATI), which shows the configuration of cardiac microphones array on the subject chest with high precision acoustics and sound data acquisition platform (e.g., as the Data Translation DT-9837 DAQ-system for sound and vibration measurement), to enhance and accelerate acoustic image reconstruction rate.</figDesc><graphic coords="189,165.25,137.13,293.41,300.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_91"><head>Figure 8 . 2 :</head><label>82</label><figDesc>Figure 8.2: Schematic of the cardio-respiratory acoustic model that can be used for signal modeling and identification. This anatomical-based model can be used as calibration reference dynamics, for cardiography acoustic imaging. (A) 3D-reconstruction CT tomography image of the pulmonary alveoli and cardiac bed; (B) transverse cross-section showing the heart muscle (myocardium) and the two lobes of the lung; (C) equivalent cardio-respiratory acoustic model.</figDesc><graphic coords="190,163.93,263.29,294.47,264.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_92"><head>Figure 8 . 3 :</head><label>83</label><figDesc>Figure 8.3: Block diagram of adaptive acoustic image reconstruction system.</figDesc><graphic coords="193,157.67,253.75,310.81,211.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_93"><head>Figure 8 . 4 :</head><label>84</label><figDesc>Figure 8.4: Spatial mapping of the PCG acoustic imaging, which assigns the space deviation of PCG signal as a function of output voltage of cardiac microphone.</figDesc><graphic coords="195,140.49,260.32,346.42,263.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_94"><head>Figure 8 . 5 :</head><label>85</label><figDesc>Figure 8.5: Heart sound localization method, where the HSS represents the cardiac auscultation source.The dynamic properties of the heart acoustic vibration, shows a nonlinear behavior, and this is due to the propagation in a non-homogeneous medium through thoracic cavity. Additionally, the curvature of the microphone array is not symmetric due to the geometric parameters of the thorax.</figDesc><graphic coords="196,166.91,134.78,294.07,290.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_95"><head>Figure 8 . 6 :</head><label>86</label><figDesc>Figure 8.6: General cardiac acoustic imaging platform and its reconstructed acoustic mapping features acquired simultaneously with ECG gated signal. (A) is the geometrical representation of the cardiac microphone array; (B) is the AP projection chest radiography demonstrating the main anatomical parts involved in acoustics imaging; (C) is the spatial intensity mapping for x-positioned microphone and y-positioned microphone of dummy load model for thorax anatomy.</figDesc><graphic coords="199,142.44,138.41,340.84,304.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_96"><head>Figure 8 . 7 :</head><label>87</label><figDesc>Figure 8.7: The dynamic variation of the detectable acoustic waves in the dummy-phantom target for testing the performance of the microphone array detector in spatial domain as vertical positioned microphone y(m) and horizontal positioned x(m)(above)moving targets with 0.0023 m/s (below) image reconstruction.</figDesc><graphic coords="200,168.74,133.73,293.34,342.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="49,166.30,135.81,293.58,390.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="179,148.11,135.96,332.41,330.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 . 1 :</head><label>11</label><figDesc>Spatial characteristics of diagnosing valve disease from heart murmurs</figDesc><table><row><cell cols="2">Heart Sound occurs during</cell><cell>Associated with</cell></row><row><cell>S 1</cell><cell cols="2">isovolumetric contraction mitral and tricuspid valves closure</cell></row><row><cell>S 2</cell><cell>isovolumetric relaxation</cell><cell>aortic and pulmonary valves closure</cell></row><row><cell>S 3</cell><cell>early ventricular filling</cell><cell>normal in children; in adults,</cell></row><row><cell></cell><cell></cell><cell>associated with ventricular dilation</cell></row><row><cell></cell><cell></cell><cell>(e.g., ventricular systolic failure)</cell></row><row><cell>S 4</cell><cell>atrial contraction</cell><cell>associated with stiff, low compliant ventricle</cell></row><row><cell></cell><cell></cell><cell>(e.g., ventricular hypertrophy)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .2: Major</head><label>1</label><figDesc></figDesc><table><row><cell cols="5">heart valves pathological conditions and its related cardiac cycle</cell></row><row><cell>correlation occurrence</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pathology</cell><cell>Time</cell><cell>Side</cell><cell>Location</cell><cell>Position</cell></row><row><cell>Tricuspid stenosis (TS)</cell><cell cols="2">Diastolic Parasternal</cell><cell>3rd ICS</cell><cell>Supine</cell></row><row><cell>Tricuspid regurgitation (TR)</cell><cell>Systolic</cell><cell>Peristernal</cell><cell>3rd ICS</cell><cell>Supine</cell></row><row><cell>Pulmonary stenosis(PS)</cell><cell>Systolic</cell><cell>Right</cell><cell>Superior</cell><cell>Supine</cell></row><row><cell cols="2">Pulmonary regurgitation(PR) Diastolic</cell><cell>Right</cell><cell>Superior</cell><cell>Seated</cell></row><row><cell>Mitral stenosis(MS)</cell><cell>Diastolic</cell><cell>Left</cell><cell>Apex</cell><cell>Supine</cell></row><row><cell>Mitral regurgitation(MR)</cell><cell>Systolic</cell><cell>Left</cell><cell>Apex-Axilla</cell><cell>Supine</cell></row><row><cell>Aortic stenosis(AS)</cell><cell>Systolic</cell><cell>Parasternal</cell><cell>Superior</cell><cell>Supine</cell></row><row><cell>Aortic regurgitation(AR)</cell><cell cols="2">Diastolic Parasternal</cell><cell>Superior</cell><cell>Seated</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .3: List of main cardiac murmurs and their related hemody</head><label>1</label><figDesc></figDesc><table><row><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 . 1 :</head><label>41</label><figDesc>PCG signal analysis based on wavelets decomposition with the entropy for PCG intensity profile.</figDesc><table><row><cell cols="2">Energy Entropy Biased</cell><cell>S 1 -%</cell><cell>S 2 -%</cell><cell>Identified</cell><cell>p-</cell><cell>SIR Mean</cell></row><row><cell cols="4">(mW) ( P CG ) error predicted predicted</cell><cell>PCG%</cell><cell cols="2">value index value</cell></row><row><cell>203.66</cell><cell cols="2">1.293 0.0042 92.31%</cell><cell cols="4">92.61% 83.26± 0.13 0.0031 1.682 14.92</cell></row><row><cell>197.87</cell><cell cols="2">1.312 0.0023 91.62%</cell><cell cols="4">92.03% 95.51± 0.34 0.0028 1.732 16.38</cell></row><row><cell>193.42</cell><cell cols="2">1.352 0.0045 92.07%</cell><cell cols="4">92.12% 91.74± 0.32 0.0022 1.788 14.27</cell></row><row><cell>196.21</cell><cell cols="2">1.392 0.0051 90.36%</cell><cell cols="4">90.22% 93.90± 0.46 0.0034 1.892 15.29</cell></row><row><cell>191.93</cell><cell cols="2">1.421 0.0039 89.81%</cell><cell cols="4">90.94% 92.04± 0.32 0.0028 2.013 16.33</cell></row><row><cell>191.25</cell><cell cols="2">1.469 0.0036 91.02%</cell><cell cols="4">90.73% 93.09± 0.41 0.0032 1.703 16.51</cell></row><row><cell>190.01</cell><cell cols="2">1.532 0.0021 90.08%</cell><cell cols="4">90.01% 87.48± 0.29 0.0034 1.841 15.07</cell></row><row><cell>191.05</cell><cell cols="2">1.362 0.0028 89.05%</cell><cell cols="4">90.85% 88.87± 0.96 0.0022 2.451 14.86</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Adaptive system identification techniques have been applied to model and identify biomedical signals such as the ECG, and PCG. One objective of PCG signal analysis is to extract features of heart sound signal, which are useful for early detection of hemodynamics abnormalities.The modeling and simulation of PCG's tracing, which are recordings of heart sounds, have great interest for cardiologist.The autoregressive moving average (ARMAX) method, adaptive ARMAX modeling method, is used to estimate acoustic dynamics parameters of PCG signals.The analysis yields spectral features for use in classifying patient PCG's as normal or abnormal pattern to be assist in clinical diagnosis. Several diagnostic methods are available for detection of malfunctioning heart valves (mitral, aortic, and tricuspid), or for different gallop-disorders (diastolic and systolic gallop, atrial, and ventricular gallop).</figDesc><table><row><cell>5.3.1 PCG ARMA SPECTRAL ESTIMATION</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 . 1 :</head><label>61</label><figDesc>Comparison of different phonocardiography pattern classification methods, as performance index and residual error.</figDesc><table><row><cell>Clustering</cell><cell>p-value</cell><cell>SIR</cell><cell>PCG_mean</cell><cell>cluster</cell><cell>cluster</cell></row><row><cell>Method</cell><cell></cell><cell>index</cell><cell>value</cell><cell cols="2">identified non-defined</cell></row><row><cell>K-Mean</cell><cell>0.0123</cell><cell>1.682</cell><cell>0.842</cell><cell>11</cell><cell>4</cell></row><row><cell>ANN-RBN</cell><cell>0.0167</cell><cell>1.732</cell><cell>0.732</cell><cell>8</cell><cell>4</cell></row><row><cell>HOS-alg.</cell><cell>0.0189</cell><cell>1.788</cell><cell>0.931</cell><cell>9</cell><cell>3</cell></row><row><cell>Basic Aggl.</cell><cell>0.0154</cell><cell>1.892</cell><cell>0.963</cell><cell>10</cell><cell>4</cell></row><row><cell>Model based</cell><cell>0.1923</cell><cell>2.013</cell><cell>1.038</cell><cell>7</cell><cell>4</cell></row><row><cell cols="2">ICA-Fixed point 0.1037</cell><cell>1.893</cell><cell>1.082</cell><cell>12</cell><cell>3</cell></row><row><cell>ICA-JADE</cell><cell>0.182</cell><cell>0.1028</cell><cell>1.820</cell><cell>10</cell><cell>2</cell></row><row><cell>ICA-SONS</cell><cell>0.161</cell><cell>0.1043</cell><cell>1.710</cell><cell>11</cell><cell>3</cell></row><row><cell>PCA-cluster</cell><cell>0.1635</cell><cell>1.712</cell><cell>1.103</cell><cell>8</cell><cell>3</cell></row><row><cell>Fuzzy c-mean</cell><cell>0.1503</cell><cell>1.847</cell><cell>1.931</cell><cell>7</cell><cell>4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>d |p 1 -y| + φ(y, t)/ |p 1 -y| 2 , (8.1) D 2 (t -|p 2 -y| /c) = d |p 2 -y| + φ(y, t)/ |p 2 -y| 2 , (8.2) D cm (t -|p CM -y| /c) = d |p CM -y| + φ(y, t)/ |p 2 -y| 2 .(8.3)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 . 1 :</head><label>81</label><figDesc>Physiological parameters of cardiac acoustic imaging.</figDesc><table><row><cell>PCG</cell><cell>signal</cell><cell>maximum</cell><cell>minimum</cell><cell>attenuation</cell></row><row><cell cols="5">parameters bandwidth (Hz) amplitude(mV) amplitude(mV) coefficient(α)</cell></row><row><cell>S 1</cell><cell>209±1.25</cell><cell>344±1.93</cell><cell>275±1.2</cell><cell>0.238± 0.0043</cell></row><row><cell>S 2</cell><cell>245±2.03</cell><cell>302±2.04</cell><cell>207±1.4</cell><cell>0.167± 0.0021</cell></row><row><cell>S 3</cell><cell>312±1.69</cell><cell>278±2.07</cell><cell>240±1.75</cell><cell>0.382± 0.0038</cell></row><row><cell>S 4</cell><cell>135±1.48</cell><cell>290±2.19</cell><cell>178±1.29</cell><cell>0.246± 0.0031</cell></row><row><cell>S 1 -S 2</cell><cell>114±1.21</cell><cell>105±1.72</cell><cell>73±1.36</cell><cell>0.129± 0.0027</cell></row><row><cell>S 2 -S 3</cell><cell>89±1.94</cell><cell>78±2.16</cell><cell>47±1.81</cell><cell>0.203± 0.0030</cell></row><row><cell cols="4">cardiac acoustic mapping system was developed by Guardo et al. (1998)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Then, using the standard distance equation, one is able to construct a system of two equations, (8.6) and (8.7), and two unknowns. The coordinates of microphones 1, 2, and 3 are (x 1 , y 1 ), (x 2 , y 2 ), and (x 3 , y 3 ), respectively. The values of these variables are known. The coordinates of the source, (x s , y s ), are unknownδ mic1-mic2 = (x 1x s ) 2 + (y 1y s ) 2 -(x 2x s ) 2 + (y 2y s ) 2 (8.8) δ mic1-mic3 = (x 1x s ) 2 + (y 1y s )2 -(x 3x s ) 2 + (y 3y s ) 2 , (8.9)</figDesc><table><row><cell></cell><cell>.5</cell></row><row><cell>and equation below):</cell><cell></cell></row><row><cell>δ mic1-mic2 = (delay mic1-mic2 (v sound )/f s .</cell><cell>(8.6)</cell></row><row><cell>δ mic1-mic2 = (dist mic1-H SS -dist mic2-H SS ).</cell><cell>(8.7)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Varieties of patho-physiological case have distinct heart murmurs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The filtering method of PCG signal play vital role in spectral analysis of acoustic signals.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>where, as before, the signals are real valued, and p(k) is an unknown cross-correlation for lag (k). The reference signal v 1 (n-k) is processed by an adaptive filter to produce the output signal</p><p>where Ŵk (n) is the adjustable (real) tap weights of the adaptive filter. The filter output y(n) is subtracted from the primary signal d(n), serving as the "desired" response for the adaptive filter. The error signal is defined by: e(n) = d(n)y(n). <ref type="bibr">(7.6)</ref> Thus, substituting Equ. <ref type="bibr">(7.6)</ref> into Equ. (7.7), we get the following:</p><p>The error signal is, in turn, used to adjust the tap weights of the adaptive filter, and the control loop around the operations of filtering and subtraction is thereby closed. Note that the informationbearing signal s(n) is indeed part of the error signal e(n). The error signal e(n) constitutes the overall system output. From Equ. (7.7), the observer can see that the noise component (lung sound) in the system output is v 0 (n)-y(n). Now the adaptive filter attempts to minimize the mean-square value (i.e., average power) of the error signal e(n). The information-bearing signal s(n) is essentially unaffected by the adaptive noise canceler. Hence, minimizing the mean-square value of the error signal e(n) is equivalent to minimizing the mean-square value of the output noise v 0 (n)-y(n). With the signal s(n) remaining essentially constant, it follows that the minimization of the mean-square value of the error signal is indeed the same as the maximization of the output signal-to-noise ratio of the system.</p><p>The other method of PSG and PCG-signal separation is based on referential respiratory sound recording, based on synchronized expiration-inspiration phase cancellation. This technique, used 4 auscultation site with one tracheal sound track record and mapping the two-phase component into two time-varying functions with defined bandwidth (BW) f1 P SG f2 P SG which are temporally summed with sinc-based window.</p><p>Through the next step, to the noise filtering and PSG calibration for parameter identification of lung viscous properties, the resultant predictive parameters were fed to the ARMAX system identification module.The derived acoustic properties, together with air flow signal, were traced from the tracheal segment used in active separation of the heart sound from lung sound. The effective use of respiratory sound adaptive noise canceling, therefore, requires that positioning the cardiac microphone reference sensor in the noise field of the primary sensor with two specific objectives in mind. First, the information-bearing signal component of the primary sensor output is undetectable in the reference sensor output. Second, the PCG reference sensor output is highly correlated with the noise component of the primary sensor output. Moreover, the adaptation of the adjustable filter coefficients must be near the optimum level. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Luisada</surname></persName>
		</author>
		<title level="m">From Auscultation to Phonocardiography</title>
		<meeting><address><addrLine>Mosby, Saint Louis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Fundamentals of digital signal processing</title>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ludeman</forename><surname>Lonnie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Harper and Row Publishers, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Vinay Angle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">John</forename><surname>Proakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing Using Matlab V</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="1997">1997</date>
			<publisher>PSW publishing company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Analog and digital signal processing</title>
		<author>
			<persName><forename type="first">Ashok</forename><surname>Ambardar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>PSW publishing company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Real time signal processing: Implementation, Applications, and Experiments with TMS320C55X</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuo Sin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Bob</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>LTD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Advanced Signal Processing Handbook: Theory and Implementation of Radar, Sonar, and Medical Imaging Real-Time Systems</title>
		<author>
			<persName><forename type="first">Stergios</forename><surname>Stergiopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>CRC Press LLC</publisher>
			<pubPlace>Boca Raton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Digital signal processing for sonar</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Pridham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kay</surname></persName>
		</author>
		<idno type="DOI">10.1109/PROC.1981.12186</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1451" to="1506" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Windrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Stearns</surname></persName>
		</author>
		<title level="m">Adaptive Signal Processing</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sonar signal processing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Baggeroer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Digital Signal Processing</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Oppenheim</surname></persName>
		</editor>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Introduction to computer aided tomography</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Scudder</surname></persName>
		</author>
		<idno type="DOI">10.1109/PROC.1978.10990</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="628" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ultrasonic Diffraction Imagin</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nahamoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<idno>PTR-EE 82-80</idno>
		<imprint>
			<date type="published" when="1982-08">August 1982</date>
			<pubPlace>West Lafayette, IN</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical Engineering, Purdue University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Phase-aberration correction using signals from point reflectors and diffuse scatterers: basic principles</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Flax</surname></persName>
		</author>
		<author>
			<persName><surname>Mc</surname></persName>
		</author>
		<author>
			<persName><surname>Donnell</surname></persName>
		</author>
		<idno type="DOI">10.1109/58.9333</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ultrasonic, Ferroelectric Frequency Control</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="758" to="767" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A comparative evaluation of several algorithms for phase aberration correction</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Worrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Freiburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Trahey</surname></persName>
		</author>
		<idno type="DOI">10.1109/58.308498</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ultrasonic, Ferroelectrics Frequency Control</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="631" to="643" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<title level="m">Fundamentals of Digital Image Processing</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">K-space description for the imaging of dynamic objects</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Henkelman</surname></persName>
		</author>
		<idno type="DOI">10.1002/mrm.1910290324</idno>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="422" to="428" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effects of physiologic waveform Variability in triggered MR imaging: theoretical analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Lauzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Holdsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Rutt</surname></persName>
		</author>
		<idno type="DOI">10.1002/jmri.1880040618</idno>
	</analytic>
	<monogr>
		<title level="j">J. Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="853" to="867" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Correction of computed Tomography motion artifacts using pixel-specific back-projection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Godwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1109/42.500142</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="342" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Auscultation of the Heart and Phonocardiography</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leatham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Churchill Livingstone</publisher>
			<pubPlace>London, Edinburgh</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Corwin</surname></persName>
		</author>
		<title level="m">Handbook of Pathophysiology: Foundations of Health and Disease</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd Ed</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Guyton</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Hall</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Textbook of Medical Physiology</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Saunders W.B</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Poul-Erik</forename><surname>Paulev</surname></persName>
		</author>
		<title level="m">Textbook in Medical Physiology and Pathophysiology Essentials and clinical problems</title>
		<imprint>
			<publisher>Copenhagen Medical Publishers</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Auscultation of the Heart</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Michael</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Heart Sounds and Murmurs: A Practical Guide</title>
		<author>
			<persName><forename type="first">B</forename><surname>Erickson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Mosby-Year Book, Inc</publisher>
			<pubPlace>St. Louis</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Phonocardiogram signal analysis: techniques and performance comparison</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Obaidat</surname></persName>
		</author>
		<idno type="DOI">10.3109/03091909309006329</idno>
	</analytic>
	<monogr>
		<title level="j">MS Obaidat-Journal of medical engineering and technology</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="221" to="227" />
			<date type="published" when="1993-12-17">Nov-Dec 17. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Heart sound segmentation algorithm based on heart sound envelogram</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lukkarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hartimo</surname></persName>
		</author>
		<idno type="DOI">10.1109/CIC.1997.647841</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Cardiology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="105" to="108" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Principles of computerized tomography imaging</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Slaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Physics</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>IEEE Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doppler</forename><surname>Echocardiography</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Lea and Febiger Publisher</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
	<note>2ed</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">HRTF Measurements of a KEMAR Dummy-Head Microphone, MIT Media</title>
		<author>
			<persName><forename type="first">Bill</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-08">Aug, 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Mannheimer</surname></persName>
		</author>
		<title level="m">Standardization of phonocardiography, Proc. of Second European Congress of Cardiology</title>
		<imprint>
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The sounds and murmurs in contraction of the aorta: a study by auscultation and phonocardiography</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Rappaport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Sprague</surname></persName>
		</author>
		<idno type="DOI">10.1016/0002-8703(49)90793-0</idno>
	</analytic>
	<monogr>
		<title level="j">Am. Heart J</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
	<note>Jul.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Clinical significance of auscultation using electronic amplifiers</title>
		<author>
			<persName><forename type="first">K</forename><surname>Holldack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zeitschrift. Gesamte. Inn Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="606" to="608" />
			<date type="published" when="1973-10-15">Oct 15. 1973</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Investigation of an apparatus for calibrated phonocardiography according to the Mannheimer-Stordal system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ljunggren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Med Scand</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="388" to="393" />
			<date type="published" when="1949-06-30">Jun 30. 1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Standardization of phonocardiography: efforts in the Netherlands</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Bekkering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.1016/0002-8703(57)90162-X</idno>
	</analytic>
	<monogr>
		<title level="j">Am. Heart J</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="316" to="317" />
			<date type="published" when="1957-08">Aug. 1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Auscultation and phonocardiography: a personal view of the past 40 years</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leatham</surname></persName>
		</author>
		<idno type="DOI">10.1136/hrt.57.5.397</idno>
	</analytic>
	<monogr>
		<title level="j">Br. Heart J</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="397" to="403" />
			<date type="published" when="1987-05">May. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Luisada</surname></persName>
		</author>
		<title level="m">From Auscultation to Phonocardiography</title>
		<meeting><address><addrLine>Mosby, Saint Louis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Acoustic transmission characteristics of the thorax</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zalter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Luisada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Appl Physiol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="428" to="436" />
			<date type="published" when="1963-03">Mar. 1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Phonocardiographic Findings in Patients with Malfunctioning Artificial Valves</title>
		<author>
			<persName><forename type="first">O</forename><surname>Zoneraich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zoneraich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Non-Invasive Methods in Cardiology</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Zoneraich</surname></persName>
		</editor>
		<meeting><address><addrLine>Springfield, II</addrLine></address></meeting>
		<imprint>
			<publisher>Charles C Thomas</publisher>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">PC based phonocardiograph expert system</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Kahalekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Vaidya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shrawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings RC IEEE-EMBS and 14th BMESI</title>
		<meeting>RC IEEE-EMBS and 14th BMESI<address><addrLine>New Delhi, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="64" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Phonocardiography. I. General principles and problems of standardization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zalter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hodara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Luisada</surname></persName>
		</author>
		<idno type="DOI">10.1016/0002-9149(59)90188-2</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J Cardiol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
	<note>Jul</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A decision tree-based method for the differential diagnosis of aortic stenosis from mitral regurgitation using heart sounds</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stasis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Loukis</surname></persName>
		</author>
		<idno type="DOI">10.1186/1475-925X-3-21</idno>
	</analytic>
	<monogr>
		<title level="j">Biomedical Engineering Online</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">21</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Frequency spectrum of the aortic component of the second heart sound in patients with normal valves, aortic stenosis and aortic porcine xenografts</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Sabbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Lakier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldstein</surname></persName>
		</author>
		<idno type="DOI">10.1016/0002-9149(80)90604-9</idno>
	</analytic>
	<monogr>
		<title level="j">Amer. J. Cardiology</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="48" to="52" />
			<date type="published" when="1980-07">July 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Acoustic evaluation of prosthetic cardiac valve in the audio spectrum</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Audio Eng. Soc</title>
		<imprint>
			<biblScope unit="page" from="750" to="755" />
			<date type="published" when="1972-11">Nov. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Spectroanalytic evaluation of aortic prosthetic valves</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Najmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Linhart</surname></persName>
		</author>
		<idno type="DOI">10.1378/chest.66.1.44</idno>
	</analytic>
	<monogr>
		<title level="j">Chest</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="44" to="49" />
			<date type="published" when="1974-07">July 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The time-frequency representation of PCG, Industrial technology</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICIT.1994.467056</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference</title>
		<meeting>the IEEE International Conference<address><addrLine>Los Angeles, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="679" to="681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Sabbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Lakier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Magilligan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frequency of the first heart sound in the assessment of stiffening of mitral bioprosthetic valves</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="200" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Maximum entropy spectral analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Burg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">P37th S.E.G. Annual Meeting</title>
		<meeting><address><addrLine>Oklahoma City, OK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Speed of low-frequency sound through the lungs of normal men</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Kraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Physiol</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1862" to="1867" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Pole-zero modeling and classification of phonocardiograms</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Joo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-01">Jan. 1982</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Electrical Engineering and Computational Science, Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.Sc. thesis</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Rushmer</surname></persName>
		</author>
		<title level="m">Cardiovascular Dynamics, Sounders publisher</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Analysis and classification of physiological signals using wavelet transforms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Jacobson</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICECS.2003.1301934</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th IEEE International Conference on Electronics, Circuits and Systems</title>
		<meeting>the 10th IEEE International Conference on Electronics, Circuits and Systems</meeting>
		<imprint>
			<date type="published" when="2003-12">Dec, 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Acoustic imaging of the human chest</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kompis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Paskterkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wodicka</surname></persName>
		</author>
		<idno type="DOI">10.1378/chest.120.4.1309</idno>
	</analytic>
	<monogr>
		<title level="j">J. Chest</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1309" to="1321" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hilborn</surname></persName>
		</author>
		<title level="m">Chaos and Nonlinear Dynamics, 2nd edition</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">System identification-a survey</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Åström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Eykhoff</surname></persName>
		</author>
		<idno type="DOI">10.1016/0005-1098(71)90059-8</idno>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="123" to="162" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Soulie</surname></persName>
		</author>
		<title level="m">Intra-cardiac phonocardiography, III-World Congress of Cardiology</title>
		<meeting><address><addrLine>Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Willerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Kastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Dinsmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mundth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gerald Austen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sanders</surname></persName>
		</author>
		<idno type="DOI">10.1136/hrt.34.6.561</idno>
	</analytic>
	<monogr>
		<title level="m">Non-invasive assessment of prosthetic mitral paravalvular and intravalvular regurgitation</title>
		<imprint>
			<date type="published" when="1972">1972</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Self-organized formation of topologically correct feature maps</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00337288</idno>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="69" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Higher-Order Spectra analysis</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Nikias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Petropulu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>PTR Prentice Hall</publisher>
			<pubPlace>New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Method and Apparatus for Optimization of Cardiac Resynchronization Therapy Using Heart Sound</title>
		<author>
			<persName><forename type="first">Marina</forename><surname>Brockway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PU.S. Appl</title>
		<imprint>
			<biblScope unit="volume">498</biblScope>
			<biblScope unit="issue">10/865</biblScope>
			<biblScope unit="page">45</biblScope>
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Value of intra-cardiac phonocardiography in subaortic stenosis, (abstract) Chest</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Sabbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Anbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khaja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Folger</surname></persName>
		</author>
		<author>
			<persName><surname>Diagnostic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page">413</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Right-heart intra-cardiac phonocardiography in 80 subjects without organic heart disease: A study of the origin of innocent heart murmurs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wennevold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dan Med Bull</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">313</biblScope>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Common carotid artery stiffness and patterns of left ventricular hypertrophy in hypertensive patients</title>
		<author>
			<persName><forename type="first">P</forename><surname>Boutouyrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Girerd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benetos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">La</forename><surname>Colley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Abergel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Safar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hypertension</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="651" to="659" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">On the genesis of heart sounds</title>
		<author>
			<persName><forename type="first">E</forename><surname>Craige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="207" to="209" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Twentieth century pioneer in auscultation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leatham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Cardiology</title>
		<imprint>
			<biblScope unit="page" from="155" to="157" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Prognostic importance of elevated jugular venous pressure and a third heart sound in patients with heart failure</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Drasner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Rame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Dries</surname></persName>
		</author>
		<idno type="DOI">10.1056/NEJMoa010641</idno>
	</analytic>
	<monogr>
		<title level="j">N Engl J Med</title>
		<imprint>
			<biblScope unit="volume">345</biblScope>
			<biblScope unit="page" from="574" to="581" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The floppy, myxomatous mitral valve, mitral valve prolapse, and mitral regurgitation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Wooley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Kolibash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kilman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Sparks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Boudoulas</surname></persName>
		</author>
		<idno type="DOI">10.1016/0033-0620(91)90005-7</idno>
	</analytic>
	<monogr>
		<title level="j">Prog. Cardiovascular Disease</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="397" to="433" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Neural network based multi sensor heart sound analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Braschdorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dorsel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Most</surname></persName>
		</author>
		<idno type="DOI">10.1109/CIC.1990.144221</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Comput. Cardio</title>
		<meeting>Comput. Cardio</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="303" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Abbas</surname></persName>
		</author>
		<title level="m">Rasha Bassam, Adaptive ARMAX Cardiac Acoustic Identification, International Conference on Modeling, Simulation and Optimization ICMSAO 2009, Al Sharjah-UAE, an</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="209" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Sound and vibration analysis, theoretical basis for software development</title>
		<imprint>
			<publisher>User Guide(CHML) National Instruments</publisher>
		</imprint>
	</monogr>
	<note>www.ni.com</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The FFT in the study of the fourth heart sound</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Pinna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Piccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bartolozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fontana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Cardiology</title>
		<imprint>
			<biblScope unit="page" from="369" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Maximum entropy spectral analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Burg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 3 th S.E.G. Annual Meeting</title>
		<meeting><address><addrLine>Oklahoma City, OK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The wavelet transform and its application to phonocardiogram signal analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Khadra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matalgah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>El-Asir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mawagdeh</surname></persName>
		</author>
		<idno type="DOI">10.3109/14639239109025301</idno>
	</analytic>
	<monogr>
		<title level="j">Med. Inf. v</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="271" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Interactive processing method using Gabor wavelet and the wavelet transform for the analysis of phonocardiogram signals, Time-Frequency and Wavelets in Biomedical Signal Processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Matalgah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knopp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mawagdeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Engineering in Medicine and Biology Society</title>
		<imprint>
			<biblScope unit="page" from="271" to="304" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Classification of Carpentimer-Edwards bioprosthesis heart valves using an adaptive single layer perceptro</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Sava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T E</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Grant</surname></persName>
		</author>
		<idno type="DOI">10.1109/IEMBS.1995.575034</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of Engineering in Medicine and Biology Society</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="129" to="130" />
			<date type="published" when="1995">1995</date>
			<pubPlace>Montréal, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Neural network and conventional classifiers to distinguish between first and second heart sounds. Artificial Intelligence Methods for Biomedical Data Processing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Hebden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Torry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Colloquium</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="1996-04">April. 1996</date>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Automated noninvasive detection of coronary artery disease using wavelet-based neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Akay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Akay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Welkowitz</surname></persName>
		</author>
		<idno type="DOI">10.1109/IEMBS.1994.412126</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual International Conference of Engineering in Medicine and Biology Society</title>
		<meeting>the 16th Annual International Conference of Engineering in Medicine and Biology Society<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">N</forename><surname>Levanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mozeson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radar</forename><surname>Signals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiley</surname></persName>
		</author>
		<author>
			<persName><surname>Sons</surname></persName>
		</author>
		<idno type="DOI">10.1002/0471663085</idno>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Interscience Div.</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Phonocardiographic Signal Analysis Using a Modified Hidden Markov Model</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y A</forename><surname>Foo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Anantharaman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10439-006-9232-3</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Biomedical Eng</title>
		<imprint/>
	</monogr>
	<note>v35 i3. 367-374</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Computing Mel-frequency cepstral coefficients on the power spectrum</title>
		<author>
			<persName><forename type="first">S</forename><surname>Molau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schluter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2001.940770</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting><address><addrLine>Utah, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="73" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Neural network based multi-sensor heart sound analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Braschdorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dorsel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Most</surname></persName>
		</author>
		<idno type="DOI">10.1109/CIC.1990.144221</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Comput. Cardio</title>
		<imprint>
			<biblScope unit="page" from="303" to="306" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">A tutorial on Hidden Markov Models (HMM) and selected applications in speech recognition, Proceeding</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="257" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Training hidden Markov models with multiple observations-a combinatorial method</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parizeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Plamondon</surname></persName>
		</author>
		<idno type="DOI">10.1109/34.845379</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI. v</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="371" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Schafer</surname></persName>
		</author>
		<title level="m">Digital Processing of Speech Signals</title>
		<imprint>
			<date type="published" when="1978">1978</date>
		</imprint>
		<respStmt>
			<orgName>Georgia Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A New Algorithm for Joint Blind Signal Separation and Acoustic Echo Canceling</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Daniel Schobben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Piet Sommen</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISSPA.1999.815814</idno>
	</analytic>
	<monogr>
		<title level="m">F fth International Symposium on Signal Processing and its Applications, ISSPA&apos;99</title>
		<meeting><address><addrLine>Brisbane, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-08">August, 1999</date>
			<biblScope unit="page" from="22" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Classification of heart sounds using time-frequency method and artificial neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Collis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salmon</surname></persName>
		</author>
		<idno type="DOI">10.1109/IEMBS.2000.897889</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society</title>
		<meeting>the 22nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="988" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Principal Component Analysis</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Series in Statistics</title>
		<meeting><address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Digital signal processing of the phonocardiogram: Review of the most recent advances)</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Rangayyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Lehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pibarot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CRC Critical Reviews in Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="211" to="236" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>Phonocardiogram Signal Analysis: a Review</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A fuzzy relative of the ISODATA process and its use in detecting compact wellseparated clusters</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Dunn</surname></persName>
		</author>
		<idno type="DOI">10.1080/01969727308546046</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Cybernetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="32" to="57" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">RBApproximate data mining in very large relational data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">James</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Richard</forename><surname>Hathaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kotagiri</forename><surname>Ramamohanarao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ADC</title>
		<imprint>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Self-organized formation of topologically correct feature maps</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00337288</idno>
	</analytic>
	<monogr>
		<title level="j">Biological Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="69" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Self-organization: A derivation from first principles of a class of learning algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Luttrell</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.1989.118288</idno>
	</analytic>
	<monogr>
		<title level="m">IJCNN International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Clinical use of phonocardiography</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gmachl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiener klinische Wochenschrift</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">44</biblScope>
			<biblScope unit="page">836</biblScope>
			<date type="published" when="1950-11-03">Nov 3, 1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Ej</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oh</forename><surname>Gauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eh</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">An Intracardiac Manometer: Its Evaluation And Application</title>
		<imprint>
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
	<note>Circulation</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">A new method for producing, calibrating, and recording intracardiac sounds in man</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Feruglio</surname></persName>
		</author>
		<idno type="DOI">10.1016/0002-8703(63)90013-9</idno>
	</analytic>
	<monogr>
		<title level="j">Am Heart J</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="377" to="390" />
			<date type="published" when="1963-03">Mar. 1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Soulie</surname></persName>
		</author>
		<title level="m">Intra-cardiac phonocardiography, III World Congress of Cardiology</title>
		<meeting><address><addrLine>Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Adaptive noise cancelling: Principles and applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mccool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaunitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Hearn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Zeidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Goodlin</surname></persName>
		</author>
		<idno type="DOI">10.1109/PROC.1975.10036</idno>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>IEEE Proceeding</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Diagnostic: value of intra-cardiac phonocardiography in subaortic stenosis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Sabbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Anbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khaja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Folger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chest</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page">413</biblScope>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
	<note>abstract</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Detection of the first and second heart sound using probabilistic models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Gamero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Watrous</surname></persName>
		</author>
		<idno type="DOI">10.1109/IEMBS.2003.1280519</idno>
	</analytic>
	<monogr>
		<title level="m">Engineering in Medicine and Biology Society Proc. 5th Annual International Conference of the IEEE</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2877" to="2880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Method and apparatus for intracardiac phonography</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Gordienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I</forename><surname>Berseneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Masterkovana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Orin</surname></persName>
		</author>
		<author>
			<persName><surname>Silin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Prom SSSR</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="49" to="52" />
			<date type="published" when="1963-02">Feb. 1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Method and Apparatus for Optimization of Cardiac Resynchronization Therapy Using Heart Sound</title>
		<author>
			<persName><forename type="first">Marina</forename><surname>Brockway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PU.S. Appl</title>
		<imprint>
			<biblScope unit="volume">498</biblScope>
			<biblScope unit="issue">10-865</biblScope>
			<biblScope unit="page">45</biblScope>
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">A sub-band energy tracking algorithm for heart sound segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Haghighi-Mood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Torry</surname></persName>
		</author>
		<idno type="DOI">10.1109/CIC.1995.482711</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Cardiology</title>
		<imprint>
			<biblScope unit="page" from="22" to="50" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Rasha Bassam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rana</forename><surname>Kasim</surname></persName>
		</author>
		<title level="m">PCG spectral Estimation based on ARMAX technique, 4th Kuala Lumpur International Conference on Biomedical Engineering BIOMED 2008</title>
		<meeting><address><addrLine>Kuala Lumpur, Malaysia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Speed of low-frequency sound through the lungs of normal men</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Kraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal. Appl. Physiol</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1862" to="1867" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Development of a cardiac acoustic mapping system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cozic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><surname>Guardo</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02523210</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical and Biological Engineering and Computing</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Acoustic imaging of the human chest</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kompis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Paskterkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wodicka</surname></persName>
		</author>
		<idno type="DOI">10.1378/chest.120.4.1309</idno>
	</analytic>
	<monogr>
		<title level="j">J. Chest</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1309" to="1321" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Adaptive filters, Signal Processing Magazine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="386" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Beamforming: A versatile approach to spatial filtering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Veen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Buckley</surname></persName>
		</author>
		<idno type="DOI">10.1109/53.665</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE ASSP Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4" to="24" />
			<date type="published" when="1988-04">April 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hilborn</surname></persName>
		</author>
		<title level="m">Chaos and Nonlinear Dynamics, 2nd edition</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Beam steering with linear arrays</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">T</forename><surname>Von Ramm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBME.1983.325149</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Analysis and study of the variation of splitting In the second heart beat sound of the wavelet transform</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Debbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bereksi-Reguig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Engineering and Technology</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">On the genesis of heart sounds</title>
		<author>
			<persName><forename type="first">E</forename><surname>Craige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="207" to="209" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Twentieth century pioneer in auscultation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leatham</surname></persName>
		</author>
		<idno type="DOI">10.1002/clc.4960220223</idno>
	</analytic>
	<monogr>
		<title level="j">Clinical Cardiology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="155" to="157" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Common carotid artery stiffness and patterns of left ventricular hypertrophy in hypertensive patients</title>
		<author>
			<persName><forename type="first">P</forename><surname>Boutouyrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Girerd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benetos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lacolley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Abergel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Safar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hypertension</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="651" to="659" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Digital signal processing of the phonocardiogram: review of the most recent advancements</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pibarot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Crit. Rev. Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="163" to="219" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Multidimensional ultrasonic imaging for cardiology</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Kinter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Mcewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Greenleaf</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.9652</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1063" to="1073" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Hemodynamic determinants of the amplitude of the first heart sound</title>
		<author>
			<persName><surname>Sakamoto</surname></persName>
		</author>
		<author>
			<persName><surname>Kusukawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Dm Maccanon</surname></persName>
		</author>
		<author>
			<persName><surname>Luisada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation Research</title>
		<imprint>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">The floppy, myxomatous mitral valve, mitral valve prolapse, and mitral regurgitation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Wooley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Kolibash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kilman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Sparks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Boudoulas</surname></persName>
		</author>
		<idno type="DOI">10.1016/0033-0620(91)90005-7</idno>
	</analytic>
	<monogr>
		<title level="j">Prog. Cardiovascular Disease</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="397" to="433" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Rushmer</surname></persName>
		</author>
		<title level="m">Cardiovascular Dynamics, Sounders Publisher</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
