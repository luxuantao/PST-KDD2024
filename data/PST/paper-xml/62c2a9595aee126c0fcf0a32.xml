<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN</title>
				<funder>
					<orgName type="full">Alibaba Group through Alibaba Innovative Research Program</orgName>
				</funder>
				<funder ref="#_ug4asvN">
					<orgName type="full">Project of Youth Innovation Promotion Association CAS</orgName>
				</funder>
				<funder>
					<orgName type="full">China Scholarship Council</orgName>
				</funder>
				<funder ref="#_FCYhQkA #_JSG22a4 #_egUDZgm">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-06-30">30 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kuan</forename><surname>Li</surname></persName>
							<affiliation key="aff9">
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff9">
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Ao</surname></persName>
							<email>aoxiang@ict.ac.cn</email>
							<affiliation key="aff9">
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianfeng</forename><surname>Chi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jinghua</forename><surname>Feng</surname></persName>
							<email>jinghua.fengjh@alibaba-inc.com</email>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qing</forename><surname>He</surname></persName>
							<email>heqing@ict.ac.cn</email>
							<affiliation key="aff9">
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Chinese Academy of Sciences</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Chinese Academy of Sciences</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Chinese Academy of Sciences</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Institute of Computing Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Chinese Academy of Sciences</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">Institute of Intelligent Computing Technology</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="department">KDD &apos;22</orgName>
								<address>
									<addrLine>August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-30">30 Jun 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3539484</idno>
					<idno type="arXiv">arXiv:2207.00012v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph Neural Network</term>
					<term>Graph Adversarial Attack</term>
					<term>Structure Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Benefiting from the message passing mechanism, Graph Neural Networks (GNNs) have been successful on flourish tasks over graph data. However, recent studies have shown that attackers can catastrophically degrade the performance of GNNs by maliciously modifying the graph structure. A straightforward solution to remedy this issue is to model the edge weights by learning a metric function between pairwise representations of two end nodes, which attempts to assign low weights to adversarial edges. The existing methods use either raw features or representations learned by supervised GNNs to model the edge weights. However, both strategies are faced with some immediate problems: raw features cannot represent various properties of nodes (e.g., structure information), and representations learned by supervised GNN may suffer from the poor performance of the classifier on the poisoned graph. We need representations that carry both feature information and as mush correct structure information as possible and are insensitive to structural perturbations. To this end, we propose an unsupervised pipeline, named STABLE, to optimize the graph structure. Finally, we input the well-refined graph into a downstream classifier. For this part, we design an advanced GCN that significantly enhances the robustness of vanilla GCN [24]  without increasing the time complexity. Extensive experiments on four real-world graph benchmarks demonstrate that STABLE outperforms the state-of-the-art methods and successfully defends against various attacks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graphs are ubiquitous data structures that can represent various objects and their complex relations <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50]</ref>. As a powerful tool of learning representations from graphs, Graph Neural Networks (GNNs) burgeon widely explorations in recent years <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42]</ref> for numerous graph-based tasks, primarily focused on node representation learning <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43]</ref> and transductive node classification <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b34">35]</ref>. The key to the success of GNNs is the neural message passing mechanism, in which GNNs regard features and hidden representations as messages carried by nodes and propagate them through the edges. However, this mechanism also brings a security risk.</p><p>Recent studies have shown that GNNs are vulnerable to adversarial attacks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref>. In other words, by limitedly rewiring the graph structure or just perturbing a small part of the node features, attackers can easily fool the GNNs to misclassify nodes in the graph. The robustness of the model is essential for some security-critical domains. For instance, in fraudulent transaction detection, fraudsters can conceal themselves by deliberately dealing with common users. Thus, it is necessary to study the robustness of GNNs. Although attackers can modify the clean graph by perturbing node features or the graph structure, most of the existing adversarial attacks on graph data have concentrated on modifying graph structure <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b54">55]</ref>. Moreover, the structure perturbation is considered more effective <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b53">54]</ref> probably due to the message passing mechanism. Misleading messages will pass through a newly added edge, or correct messages cannot be propagated because an original edge is deleted. In this paper, our purpose is to defend against the non-targeted adversarial attack on graph data that attempts to reduce the overall performance of the GNN. Under this setting, the GNNs are supposed to be trained on a graph that the structure has already been perturbed. One representative perspective to defend against the attack is to refine the graph structure by reweighting the edges <ref type="bibr" target="#b51">[52]</ref>. Specifically, edge weights are derived from learning a metric function between pairwise representations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b44">45]</ref>. Intuitively, the weight of an edge could be represented as a distance measure between two end nodes, and defenders can further prune or add edges according to such distances.</p><p>Though extensive approaches have been proposed to model the pairwise weights, most research efforts are devoted to designing a novel metric function, while the rationality of the inputs of the function is inadequately discussed. In more detail, they usually utilize the original features or representations learned by the supervised GNNs to compute the weights.</p><p>However, optimizing graph structures based on either features or supervised signals might not be reliable. For example, GNN-Guard <ref type="bibr" target="#b44">[45]</ref> and Jaccard <ref type="bibr" target="#b39">[40]</ref> utilize cosine similarity of the initial features to model the edge weights, while GRCN <ref type="bibr" target="#b43">[44]</ref> uses the inner product of learned representations. The performance of these three models on Cora attacked by MetaAttack <ref type="bibr" target="#b54">[55]</ref> <ref type="foot" target="#foot_0">1</ref> is listed in Table <ref type="table" target="#tab_0">1</ref>. From the table, we first observe feature-based methods do not perform well under low perturbation rates, because features cannot carry structural information. Optimizing the structure based on such an insufficient property can lead to mistakenly deleting normal edges (the statistics of the removed edges is listed in Table <ref type="table" target="#tab_5">3</ref>). When the perturbation is low, the negative impact of such misdeletion is greater than the positive impact of deleting malicious edges.Thus, we want to refine the structure by learned representations which contain structural information. Second, we also see the representations learned by the supervised GNNs are not reliable under high perturbations (the results of GRCN). This is probably because attack methods are designed to degrade the accuracy of a surrogate GNN, so the quality of representations learned by the classifier co-vary with the task performance.</p><p>Based on the above analysis, we consider that the representations used for structure refining should be obtained in a different manner, and two factors in terms of learning representations in the adversarial scenario should be highlighted: 1) carrying feature information and in the meantime carrying as much correct structure information as possible and 2) insensitivity to structural perturbations.</p><p>To this end, we propose an approach named STABLE (STructure leArning GNN via more reliaBLe rEpresentations) in this paper, and it learns the representations used for structure refining by unsupervised learning. The unsupervised approach is relatively reliable because the objective is not directly attacked. Additionally, the unsupervised pipeline can be viewed as a kind of pretraining, and the learned representations may have been trained to be invariant to certain useful properties <ref type="bibr" target="#b38">[39]</ref> (i.e., the perturbed structure here). We design a contrastive method with a novel pre-process and recovery schema to obtain the representations. Different from the previous contrastive method <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b52">53]</ref>, we roughly refine the graph to remove the easily detectable adversarial edges and generate augmentation views by randomly recovering a small portion of removed edges. Pre-processing makes the underlying structural information obtained during the representation learning process relatively correct, and such an augmentation strategy can be viewed as injecting slight attack to the pre-processed graph. Then the representations learned on different augmentation views tend to be similar during the contrastive training. That is to say, we obtain representations insensitive to the various slight attacks. Such learned representations fulfill our requirements and can be utilized to perform graph structure refinement to derive an unpolluted graph.</p><p>In addition, any GNNs can be used for the downstream learning tasks after the structure is well-refined. For this part, many methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22]</ref> just use the vanilla GCN <ref type="bibr" target="#b23">[24]</ref>. By observing what makes edge insertion or deletion a strong adversarial change, we find that GCN falls victim to its renormalization trick. Hence we introduce an advanced message passing in the GCN module to further improve the robustness.</p><p>Our contributions can be summarized as follow:</p><p>(1) We propose a contrastive method with robustness-oriented augmentations to obtain the representations used for structure refining, which can effectively capture structural information of nodes and are insensitive to the perturbations. <ref type="bibr" target="#b1">(2)</ref> We further explore the reason for the lack of robustness of GCN and propose a more robust normalization trick. (3) Extensive experiments on four real-world datasets demonstrate that STABLE can defend against different types of adversarial attacks and outperform the state-of-the-art defense models. matrix of nodes. Let A ? {0, 1} ? ?? represent the adjacency matrix of G, in which A ? ? ? {0, 1} denotes the existence of the edge ? ? ? ? E that links node ? ? and ? ? . The first-order neighborhood of node ? ? is denoted as N ? , including node ? ? itself. We use N * ? to indicate ? ? 's neighborhood excluding itself. The transductive node classification task can be formulated as we now describe. Given a graph G and a subset V ? ? V of labeled nodes, with class labels from C = {? 1 , ? 2 , ..., ? ? }. Y ? and Y ? denote the ground-truth labels of labeled nodes and unlabeled nodes, respectively. The goal is to train a GNN ? ? to learn a function: V ? Y that maps the nodes to the label set so that ? ? can predict labels of unlabeled nodes. ? is the trainable parameters of GNN.</p><p>GNNs can be generally specified as ? ? (X, A) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b47">48]</ref>. Each layer can be divided into a message passing function (MSP) and an updating function (UPD). Given a node ? ? and its neighborhood N * ? , GNN first implements MSP to aggregate information from N * ? :</p><formula xml:id="formula_0">? ? ? = MSP({? ? -1 ? ; ? ? N * ? })</formula><p>, where ? ? -1 ? denotes the hidden representation in the previous layer, and ? 0 ? = ? ? . Then, GNN updates the representation by UPD: ? ? ? = UPD(? ? ? , ? ? -1 ? ), which is usually a sum or concat function. GNNs can be designed in an end-to-end fashion and can also serve as a representation learner for downstream tasks <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Gray-box Poisoning Attacks and Defence</head><p>In this paper, we explore the robustness of GNNs under non-targeted Gray-box poisoning attack. Gray-box <ref type="bibr" target="#b43">[44]</ref> means the attacker holds the same data information as the defender, and the defense model is unknown. Poisoning attack represents GNNs are trained on a graph that attackers maliciously modify, and the aim of it is to find an optimal perturbed A ? , which can be formulated as a bilevel optimization problem <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>:</p><formula xml:id="formula_1">argmin ? ? ??(?) L ??? (? ? * (A ? , X)) ?.? . ? * = argmin ? L ????? (? ? (A ? , X)).<label>(1)</label></formula><p>Here ?(A) is a set of adjacency matrix that fit the constraint:</p><formula xml:id="formula_2">?A ? -A ? 0 ?A ? 0</formula><p>? ?, L ??? is the attack loss function, and L ????? is the training loss of GNN. The ? * is the optimal parameter for ? ? on the perturbed graph. ? is the maximum perturbation rate. In the non-targeted attack setting, the attacker aims to degrade the overall performance of the classifier. Many efforts have been made to improve the robustness of GNNs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b48">49]</ref>. Among them, metric learning approach <ref type="bibr" target="#b51">[52]</ref> is a promising method <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b44">45]</ref>, which refines the graph structure by learning a pairwise metric function ? (?, ?):</p><formula xml:id="formula_3">S ? ? = ? (? ? , ? ? ),<label>(2)</label></formula><p>where ? ? is the raw feature or the learned embedding of node ? ? produced by GNN, and S ? ? denotes the learned edge weight between node ? ? and ? ? . ? (?, ?) can be a similarity metric or implemented in multilayer perceptions (MLPs). Further, the structure can be optimized according to the weights matrix S. For example, GN-NGuard <ref type="bibr" target="#b44">[45]</ref> utilizes cosine similarity to model the edge weights and then calculates edge pruning probability through a non-linear transformation. Moreover, GRCN <ref type="bibr" target="#b43">[44]</ref> and GAUGM <ref type="bibr" target="#b46">[47]</ref> directly compute the weights of the edges by the inner product of embeddings, and no additional parameters are needed:</p><formula xml:id="formula_4">S ? ? = ? (ZZ T ).<label>(3)</label></formula><p>Such methods aim to assign high weights to helpful edges and low weights to adversarial edges or even remove them. Here we want to define what is a helpful edge. Existing literature posits that strong homophily of the underlying graph is necessary for GNNs to achieve good performance on transductive node classification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b16">17]</ref>. Under the homophily assumption <ref type="bibr" target="#b30">[31]</ref>, the edge which links two similar nodes (e.g., same label) might help the nodes to be correctly classified. However, since only few labeled nodes are available, previous works utilize the raw features or the representations learned by the task-relevant GNNs to search for similar nodes. Different from the aforementioned defense methods, we leverage an unsupervised pipeline to calculate the weights matrix and refine the graph structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>In this section, we will present STABLE in a top-down fashion: starting with an elaboration of the overall framework, followed by the specific details of the structural optimization module, and concluding by an exposition of the advanced GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Overall Architecture</head><p>The illustration of the framework is shown in Fig. <ref type="figure" target="#fig_1">1</ref>. It consists of two major components, the structure learning network and the advanced GCN classifier. The structure learning network can be further divided into two parts, representation learning and graph refining. For the representation learning part, we design a novel contrastive learning method with a robustness-oriented graph data augmentation, which randomly recovers the roughly removed edges. Then the learned representations are utilized to revise the structure according to the homophily assumption <ref type="bibr" target="#b30">[31]</ref>. Finally, in the classification step, by observing what properties the nodes connected by the adversarial edges have, we carefully change the renormalization trick in GCN <ref type="bibr" target="#b23">[24]</ref> to improve the robustness. The overall training algorithm is shown in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Representation learning</head><p>According to <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b54">55]</ref>, most of the perturbations are edge insertions, which connect nodes with different labels. Thus a straightforward method to deal with the structural perturbation is to find the adversarial edges and remove them. Previous works utilize the raw features or the representations learned by the end-to-end GNNs to seek the potential perturbations. As we mentioned before, such approaches have flaws.</p><p>STABLE avoids the pitfalls by leveraging a task-irrelevant contrastive method with robustness-oriented augmentations to learn the representations. First, we roughly pre-process the perturbed graph based on a similarity measure, e.g., Jaccard similarity or cosine similarity. We quantify the score S ? ? between node ? ? and its neighbor ? ? as follows: </p><formula xml:id="formula_5">S ? ? = sim(? ? , ? ? ),<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Refining Prediction Representation Learning</head><p>Node Similarity where S is the score matrix, ? ? and ? ? are the feature vectors of ? ? and ? ? , respectively. Then we prune the edges whose scores are below a threshold ? 1 . The removed edge matrix and roughly preprocessed graph are denoted as E and G ? , where E ? ? = 1 denotes the edge between ? ? and ? ? is removed. Generating views is the key component of contrastive methods. Different views of a graph provide different contexts for each node, and we hope our views carry the context for enhancing the robustness of the representations. Previous works generate augmentations by randomly perturbing the structure <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b52">53]</ref> on the initial graph. Different from them, we generate ? graph views, denoted as G ? 1 to G ? ? , by randomly recovering a small portion of E on the pre-processed graph G ? . Formally, we first sample a random masking matrix P ? {0, 1} ? ?? , whose entry is drawn from a Bernoulli distribution P ? ? ? B (1 -?) if E ? ? = 1 and P ? ? = 0 otherwise. Here ? is a hyper-parameter that controls the recovery ratio. The adjacency matrix of the augmentation view can be computed as:</p><formula xml:id="formula_6">Encoder ?? ?? ?? ?? ?? ? ?? ?? ?? ?? ?? ?? ?? ? ? ?? ?? ?? ?? - ?? ?? ? ? ?? ?? ?? ? ?? ? ?? ??</formula><formula xml:id="formula_7">A ? 1 = A ? + E ? P,<label>(5)</label></formula><p>where A ? and A ? 1 denote the adjacency matrix of G ? and G ? 1 respectively, and ? is the Hadamard product. Other views can be obtained in the same way. The pre-process and the robustnessoriented augmentations are critical to the robustness, and we will elaborate on this point at the end of this subsection.</p><p>Our objective is to learn a one-layer GCN encoder ? ? parameterized by ? to maximize the mutual information between the local representation in G ? and the global representations in G ? . Here G ? denote arbitrary augmentation ?. The encoder follows the propagation rule:</p><formula xml:id="formula_8">? ? (X, A) = ? ( ?XW ? )<label>(6)</label></formula><p>where</p><formula xml:id="formula_9">? = (D + I ? ) -1 2 (A + I ? )(D + I ? ) -1 2</formula><p>is the renormalized adjacency matrix. we denote node representations in G ? and augmentation ? as H = ? ? (X, A ? ) and H ? = ? ? (X, A ? ? ). The global representation can be obtained via a readout function R. We leverage a global average pooling function:</p><formula xml:id="formula_10">? ? = ? 1 ? ? ?? ?=1 ? ?,? , (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>where ? is the logistic sigmoid nonlinearity, and ? ?,? is the representation of node ? ? in G ? ? . We employ a discriminator D ? to distinguish positive samples and negative samples, and the output D ? (?, ?) represents the probability score of the sample pair from the joint distribution. ? is the parameters of the discriminator. To generate negative samples, which means the pair sampled from the product of marginals, we randomly shuffle the nodes' features in G ? . We denote the shuffled graph and its representation as G ? and H = ? ? ( X, A ? ). To maximize the mutual information, we use a binary cross-entropy loss between the positive samples and negative samples, and the objective can be writen as:</p><formula xml:id="formula_12">L ? = - 1 2? ? ?? ?=1 1 ? ? ?? ?=1 logD ? (? ? , ? 1 ) ... + logD ? (? ? , ? ? )+ log 1 -D ? ( h? , ? 1 ) ... + log 1 -D ? ( h? , ? ? ) . (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>where ? ? and h? are the representations of node ? ? in G ? and G ? . Minimizing this objective function can effectively maximize the mutual information between the local representations in G ? and the global representations in the augmentations based on the Jensen-Shannon MI (mutual information) estimator <ref type="bibr" target="#b15">[16]</ref>.</p><p>To clarify why pre-processing and the designed augmentation method are crucial to robustness, we count the results of the preprocess and the recovery: Using Jaccard as the measure of the rough pre-process, 1, 705 edges are removed on Cora under 20% perturbation rate. Among them, 691 are adversarial edges, and 1014 are normal edges. 259 edges out of 1, 014 connect two nodes with different labels. More than half of the removals are helpful. Therefore, most of the edges in E can be regarded as adversarial edges so that the recovery can be viewed as injecting slight attacks on G ? . The degrees of perturbation can be ranked as</p><formula xml:id="formula_14">G ? G ? 1 ? G ? 2 ... ? G ? ? &gt; G ? .</formula><p>Recall that we need representations that carry as much correct structural information as possible and are insensitive to perturbations. We train our encoder on the three much cleaner graphs, so the representations are much better than those learned in the original graph. The process of maximizing mutual information makes the representations learned in G ? and in the views similar so that the representations will be insensitive to the recovery. In other words, they will be insensitive to perturbations. In short, the rough preprocess meets the former requirement, and the robustness-oriented augmentation meets the latter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Graph Refining</head><p>Once the high-quality representations are prepared, we can further refine the graph structure in this section. Existing literature posits that strong homophily of the underlying graph can help GNNs to achieve good performance on transductive node classification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b16">17]</ref>. Therefore, the goal of the refining is to reduce heterophilic edges (connecting two nodes in the different classes) and add homophilic edges (connecting two nodes in the same class). Under homophily assumption <ref type="bibr" target="#b30">[31]</ref>, similar nodes are more likely in the same class, so we use node similarity to search for potential homophilic edges and heterophilic edges.</p><p>We leverage the representations learned by the contrastive learning encoder to measure the nodes similarity:</p><formula xml:id="formula_15">M ? ? = sim(? ? , ? ? ), (<label>9</label></formula><formula xml:id="formula_16">)</formula><p>where M is the similarity score matrix, and M ? ? is the score of node ? ? and node ? ? . Here we utilize the cosine similarity. Then we remove all the edges that connect nodes with similarity scores below a threshold ? 2 . The above process can be formulated as:</p><formula xml:id="formula_17">A ? ? ? = 1 ? ? M ? ? &gt; ? 2 ??? A ? ? = 1 0 ?????????,<label>(10)</label></formula><p>where A ? is the adjacency matrix after pruning.</p><p>After pruning, we insert some helpful edges by building a top-? matrix T ? . For each node, we connect it to ? nodes that are most similar to it. Formally, T ? ? ? = 1, if ? ? is one of the ? nodes most similar to ? ? . Note that T ? is not a symmetric matrix because the similarity relation is not symmetric. For example, ? ? is the most similar node to ? ? but not vise versa. The pruning strategy cannot eliminate all the perturbations, and these insertions can effectively diminish the impact of the remaining harmful edges. From our empirical results, this is particularly effective when the perturbation rate is high. The optimal adjacency matrix can be formulated as:</p><formula xml:id="formula_18">A * = A ? + T ?<label>(11)</label></formula><p>The optimal graph is denoted as G * , and it is a directed graph due to the asymmetry of T.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Advanced GCN In the Adversarial Attack Scenario</head><p>After the graph is well-refined, any GNNs can be used for the downstream task. We find that only one modification to the renormalization trick in GCN is needed to enhance the robustness greatly. This improvement does not introduce additional learnable parameters and therefore does not reduce the efficiency of the GCN.</p><p>[55] studied the node degree distributions of the clean graph and the node degrees of the nodes that are picked for adversarial edges. Not surprisingly, the nodes selected by the adversarial edges are those with low degrees. The nodes with only a few neighbors are more vulnerable than high-degree nodes due to the message passing mechanism. However, the discussion about the picked nodes only exposes one-side property of the adversarial edges. We further define the degree of an edge as the sum of both connected nodes' degrees. The edge degree distribution is shown in Fig. <ref type="figure" target="#fig_3">2 (a)</ref>. It shows that adversarial edges tend to link two low-degree nodes, and nearly half of them are below 5 degrees.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Advanced GCN In the Adversarial Attack Scenario</head><p>After the graph is well refined, any GNNs can be used for the down- GCN assigns higher aggregation weights to low-degree neighbors, and the renormalization adjacency matrix is formulated as: ? = (D + I ? ) -1 2 (A + I ? )(D + I ? ) -1 2 . However, based on the above analysis, low-degree neighbors are more likely to be maliciously added neighbors. To give a specific example, here is node ? ? with only one neighbor in the clean graph, and the attacker link it to a low-degree node. In the aggregation step, only half of the messages are are correct. Even worse, the misleading message is assigned a higher weight because the added neighbor has a lower degree than the original neighbor.</p><p>Hence, a simple but effective way to improve the robustness of GCN is to assign lower weights to the low-degree neighbors. We propose our advanced GCN, which will implement the message passing as follow:</p><formula xml:id="formula_19">? ? ? = ReLU ?? ? ?N * ? (? ? ? ? ) ? ? ? ? -1 ? + ?? (? -1) ? W ? ? (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>where ? is the hyper-parameter that controls the weight design scheme, ? is the hyper-parameter that controls the weight of selfloop, ? is a normalization coefficient, and ReLU(?) = ??? (0, ?). ? 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>is the representation learned in Section 3.2. When ? is large, a node aggregate more from the high-degree nodes. ? is also designed for robustness. Once the neighbors are unreliable, nodes should refer more to themselves. High-degree nodes can be viewed as robust nodes, because a few perturbations can hardly cancel out the helpful information brought by their original neighbors. The learnable attack algorithms tend to bypass them. Thus, the message from these nodes are usually more reliable.</p><p>We show an example in Fig. <ref type="figure" target="#fig_3">2 (b</ref>). GCN * denotes the advanced GCN with ? = 0.6 and ? = 2. As the perturbation rate increases, the robustness improves more obviously. In fact, this normalization trick can merge with any GNNs.</p><p>We train an advanced GCN ? ? by minimizing the cross-entropy:</p><formula xml:id="formula_21">L ? = ?? ? ?V ? ? (? ? (H, A * ) ? , ? ? ) (<label>13</label></formula><formula xml:id="formula_22">)</formula><p>where ? is the cross entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we empirically analyze the robustness and effectiveness of STABLE against different types of adversarial attacks. Specifically, we aim to answer the following research questions: 4.1.2 Baselines. We compare STABLE with representative and state-of-the-art defence GNNs to verify the robustness. The baselines and SOTA approaches are GCN <ref type="bibr" target="#b23">[24]</ref>, RGCN <ref type="bibr" target="#b48">[49]</ref>, Jaccard <ref type="bibr" target="#b39">[40]</ref>,</p><formula xml:id="formula_23">? RQ1: Does STABLE</formula><p>GNNGuard <ref type="bibr" target="#b44">[45]</ref>, GRCN <ref type="bibr" target="#b43">[44]</ref>, ProGNN <ref type="bibr" target="#b21">[22]</ref>, SimpGCN <ref type="bibr" target="#b19">[20]</ref>, Elastic <ref type="bibr" target="#b27">[28]</ref>. We implement three non-targeted structural adversarial attack methods, i.e., MetaAttack <ref type="bibr" target="#b54">[55]</ref>, DICE <ref type="bibr" target="#b37">[38]</ref> and Random. We introduce all these defence methods and attack methods in the Appendix A.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Implementation Details.</head><p>The implementation details and parameter settings are introduced in Appendix A. <ref type="bibr" target="#b3">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Robustness Evaluation (RQ1)</head><p>To answer RQ1, we evaluate the performance of all methods attacked by different methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Against Mettack.</head><p>Table <ref type="table" target="#tab_4">2</ref> shows the performance on three datasets against MetaAttack <ref type="bibr" target="#b54">[55]</ref>, which is an effective attack method. The top two performance is highlighted in bold and underline. We set the perturbation rate from 0% to 20%. From this main experiment, we have the following observations:</p><p>? All the methods perform closely on clean graphs because most of them are designed for adversarial attacks, and the performance on clean graphs is their goal. Both GCN and RGCN perform poorly on graphs with perturbations, proving that GNNs are vulnerable without valid defenses. ? Jaccard, GNNGuard, GRCN, and ProGNN are all structure learning methods. Jaccard and GNNGuard seem insensitive to the perturbations, but there is a trade-off between the performance and the robustness. They prune the edges based on the features, but the raw features cannot sufficiently represent nodes' various properties. ProGNN and GRCN perform well when the perturbation rate is low, and the accuracy drops rapidly as the perturbation rate rises. GRCN suffers from poor end-to-end representations, and for ProGNN, we guess it is hard to optimize the structure on a heavily contaminated graph directly. Compared with them, STABLE leverages the task-irrelevant representations to optimize the graph structure, which leads to higher performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Result of Sturcture Learning (RQ2)</head><p>To validate the effectiveness of structure learning, we compare the results of structure optimization in STABLE and other metric learning methods. RGCN fails to refine the graph and makes the graph denser, so we exclude it. The statistics of the learned graphs are shown in Table <ref type="table" target="#tab_5">3</ref>. It shows the number of total removed edges, removed adversarial edges, and removed normal edges. Due to the limit of space, we only show results on Cora under MetaAttack.</p><p>To ensure a fair comparison, we tune the pruning thresholds in each method to close the number of total removed edges. It can be observed that STABLE achieves the highest pruning accuracy, indicating that STABLE revise the structure more precisely via more reliable representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parameter Analysis (RQ3)</head><p>From our experimental experience, we mainly tune ? and ? to achieve peak performance. Thus, we alter their values to see how they affect the robustness of STABLE. The sensitivity of other parameters are presented in Appendix A.6. As illustrated in Fig. <ref type="figure" target="#fig_2">4</ref>, we conduct experiments on Cora with the perturbation rate of 20% by  Moreover, to explore the relationship between these parameters and perturbation rates, we list the specific values which achieve the best performance on Cora in Table <ref type="table" target="#tab_6">4</ref>. Both ? and ? are directly proportional to the perturbation rate, which is consistent with our views. The more poisoned the graph is, the more helpful neighbors are needed, and the more trust in high-degree nodes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>In this section, we present the related literature on robust graph neural networks and graph contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Robust GNNs</head><p>Extensive studies have demonstrated that GNNs are highly fragile to adversarial attacks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref>. The attackers can greatly degrade the performance of GNNs by limitedly modifying the graph data, namely structure and features.</p><p>To strengthen the robustness of GNNs, multiple methods have been proposed in the literature, including structure learning <ref type="bibr" target="#b21">[22]</ref>, adversarial training <ref type="bibr" target="#b40">[41]</ref>, utilizing Gaussian distributions to represent nodes <ref type="bibr" target="#b48">[49]</ref>, designing a new message passing scheme driven by ? 1 -based graph smoothing <ref type="bibr" target="#b27">[28]</ref>, combining the kNN graph and the original graph <ref type="bibr" target="#b19">[20]</ref>, and excluding the low-rank singular components of the graph <ref type="bibr" target="#b7">[8]</ref>. <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b2">[3]</ref> study the robustness of GNNs from the breakdown point perspective and propose more robust aggregation approaches.</p><p>In the methods mentioned above, one representative type of approach is graph structure learning <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b51">52]</ref>, which aims to detect the potential adversarial edges and assign these edges lower weights or even remove them. ProGNN <ref type="bibr" target="#b21">[22]</ref> and GLNN <ref type="bibr" target="#b10">[11]</ref> tried to directly optimize the structure by treating it as a learnable parameter, and they introduced some regularizations like sparsity, feature smoothness, and low-rank into the objective. <ref type="bibr" target="#b39">[40]</ref> has found that attackers tend to connect two nodes with different features, so they invented Jaccard to prune the edges that link two dissimilar nodes. GNNGuard <ref type="bibr" target="#b44">[45]</ref> also modeled the edge weights by raw features. They further calculated the edge pruning probability through a non-linear transformation. GRCN <ref type="bibr" target="#b43">[44]</ref> and GAUGM <ref type="bibr" target="#b46">[47]</ref> directly computed the weights of the edges by the inner product of representations learned by the classifier, and no additional parameters were needed.</p><p>Different from the above-mentioned methods, we aim to leverage task-irrelevant representations, which represent rich properties of nodes and are insensitive to perturbations, to refine the graph structure. Then, we input the well-refined graph into a light robust classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Graph Contrastive Learning</head><p>To learn task-irrelevant representations, we consider using unsupervised methods, which are mainly divided into three categories: GAEs <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23]</ref>, random walk methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b32">33]</ref>, and contrastive methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b52">53]</ref>. Both GAEs and random walk methods are suffer from the proximity over-emphasizing <ref type="bibr" target="#b35">[36]</ref>, and the augmentation scheme in contrastive methods are naturally similar to adversarial attacks.</p><p>Graph contrastive methods are proved to be effective in node classification tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b52">53]</ref>. The first such method, DGI <ref type="bibr" target="#b35">[36]</ref>, transferred the mutual information maximization <ref type="bibr" target="#b15">[16]</ref> to the graph domain. Next, InfoGraph <ref type="bibr" target="#b33">[34]</ref> modified DGI's pipeline to make the global representation useful for graph classification tasks. Recently, GRACE <ref type="bibr" target="#b52">[53]</ref> and GraphCL <ref type="bibr" target="#b42">[43]</ref> adapted the data augmentation methods in vision <ref type="bibr" target="#b3">[4]</ref> to graphs and achieved state-of-the-art performance. Specifically, GraphCL generated views by various augmentations, such as node dropping, edge perturbation, attribute masking, and subgraph. However, these augmentations were not designed for adversarial attack scenarios. The edge perturbation method in GraphCL randomly added or deleted edges in the graph, and we empirically prove this random augmentation does not work in Appendix A.5.</p><p>Unlike GraphCL and GRACE randomly generated augmentations, STABLE generates robustness-oriented augmentations by a novel recovery scheme, which simulates attacks to make the representations insensitive to the perturbations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>To overcome the vulnerability of GNNs, we propose a novel defense model, STABLE, which successfully refines the graph structure via more reliable representations. Further, we design an advanced GCN as a downstream classifier to enhance the robustness of GCN. Our experiments demonstrate that STABLE consistently outperforms state-of-the-art baselines and can defend against different types of attacks. For future work, we aim to explore representation learning in adversarial attack scenarios. The effectiveness of STABLE proves that robust representation might be the key to GNN robustness. threshold are tuned from {0.01, 0.02, 0.03, 0.04, 0.05}. For GNNGuard, we follow the author's settings, which contains ? 0 = 0.5, ? = 2, ? 2 = 16 and ??????? = 0.5. For ProGNN and SimpGCN, following <ref type="bibr" target="#b19">[20]</ref>, we use the default hyper-parameter settings in the authors' implementation. For Elastic, the propagation step K is tuned from {3, 5, 10}, and the parameter ? 1 and ? 2 are tuned from {0, 3, 6, 9}.</p><p>For our work, ? 1 is Jaccard Similarity threshold in this work and tuned from{0.0, 0.01, 0.02, 0.03, 0.04, 0.05}, the recovery portion ? is fixed at 0.2, ? 2 is tuned from {0.1, 0.2, 0.3}, ? is tuned from {1, 3, 5, 7, 11, 13}, ? is tuned from -0.5 to 3, and ? is fixed at 2. We fix ? = 2 because we find that two augmentation views are good enough. The other parameters in ??? * follows the setting in <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Ablation Study (RQ4)</head><p>We conduct an ablation study to examine the contributions of different components in STABLE:</p><p>? STABLE-P: STABLE without rough pre-process.</p><p>? STABLE-A: STABLE without augmentations.</p><p>? STABLE-Ran: STABLE with random augmentations. We generate the views by randomly removing or adding edges. ? STABLE-K: We only prune edges in the refining phase.</p><p>? STABLE-GCN: Replace advanced GCN with GCN.  The accuracy on Cora and Citeseer under MetaAttack is illustrated in Fig. <ref type="figure" target="#fig_6">5</ref>. It is clearly observed that the STABLE-P perform worst, and it is in line with our point that G ? is much cleaner than G. STABLE-Ran and STABLE-A perform very closely, and the gap between them and STABLE widens as the perturbation rate increases. We can conclude that the robustness-oriented augmentation indeed works. It is worth noting that STABLE outperforms STABLE-K more significantly as the perturbation rate rising, as our expectation. We argue that adding helpful neighbors can diminish the impact of harmful edges, especially on heavily poisoned graphs.</p><p>To further verify the robustness of advanced GCN, we present the performance of SimpGCN* and Jaccard* in Table <ref type="table" target="#tab_7">6</ref>. Jaccard and SimpGCN both contain the vanilla GCN, so we can easily define two variants by replacing the GCN with the advanced GCN. As shown in Table <ref type="table" target="#tab_7">6</ref>, the variants of Jaccard and SimpGCN show more robust than the original models. The improvement of SimpGCN is more significant might because of the pruning strategy in Jaccard, which already removes some adversarial edges. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Sensitivity</head><p>We explore the sensitivity of ? 1 and ? 2 for STABLE. The performance change of STABLE is illustrate in Figure <ref type="figure" target="#fig_7">6</ref>. In fact, for Cora, we fixed ? 1 at 0.03 and ? 2 at 0.2 to achieve the best performance under different perturbation rate. For ? 1 , it is worth noting that, the performance on pre-processed graph is consistently higher than on the original graph(? 1 = 0). ? 2 = 0 implies that no edge is pruned in the refining step, and the performance is still competitive might due to the good representations and helpful edge insertions. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall framework. Dash lines mean recovered edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Left: The edge degree distribution of the clean graph and the distribution of the adversarial edges on Cora attacked by MetaAttack. Right: The mean accuracy under different perturbation rate on Cora. The data split follows 10%/ 10%/ 80/%(train/ val/test).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: (a): The edge degree distribution of the clean graph and the distribution of the adversarial edges on Cora attacked by MetaAttack. (b): The mean accuracy under different perturbation rates on Cora. The data split follows 10%/ 10%/ 80/%(train/ val/test).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Parameter sensitivity analysis on Cora.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparisons between STABLE and its variants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Parameter sensitivity analysis on Cora.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The mean accuracy under different perturbation rates by MetaAttack on the Cora dataset. Here the perturbation rate is the ratio of changed edges. The data split follows 10%/ 10%/ 80/%(train/ validation/ test).</figDesc><table><row><cell cols="4">Ptb Rate GCN GRCN GNNGuard Jaccard</cell></row><row><cell>0%</cell><cell>83.56 86.12</cell><cell>78.52</cell><cell>81.79</cell></row><row><cell>5%</cell><cell>76.36 80.78</cell><cell>77.96</cell><cell>80.23</cell></row><row><cell>10%</cell><cell>71.62 72.42</cell><cell>74.86</cell><cell>74.65</cell></row><row><cell>20%</cell><cell>60.31 65.43</cell><cell>72.03</cell><cell>73.11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Cora, Citeseer, and PubMed, and one blog graph, i.e., Polblogs. The statistics of these datasets are shown in Appendix A.2.</figDesc><table><row><cell>outperform the state-of-the-art defense</cell></row><row><cell>models under different types of adversarial attacks?</cell></row><row><cell>? RQ2: Is the structure learned by STABLE better than learned by other methods?</cell></row><row><cell>? RQ3: What is the performance with respect to different training parameters?</cell></row><row><cell>? RQ4: How do the key components benefit the robustness? (see Appendix A.5)</cell></row><row><cell>4.1 Experimental Settings</cell></row></table><note><p><p><p>4.1.1 Datasets. Following</p><ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b53">54]</ref></p>, we conduct our experiments on four benchmark datasets, including three citation graphs, i.e.,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>?</head><label></label><figDesc>SimPGCN and Elastic are two recent state-of-the-art robust methods. SimPGCN is shown robust on Cora and Citeseer because it can adaptively balance structure and feature information. It performs poorly on Polblogs due to the lack of feature information, which can also prove that the robustness of SimpGCN relies on the raw features. Hence, it might also face the same problem that the original features miss some valuable information.</figDesc><table><row><cell>Elastic benefits</cell></row><row><cell>from its ability to model local smoothing. Different from them, our</cell></row><row><cell>STABLE focus on refining the graph structure, and we just design</cell></row><row><cell>a variant of GCN as the classifier. STABLE outperforms these two</cell></row><row><cell>methods with 1%?8% improvement under low perturbation rate</cell></row><row><cell>and 7%?24% improvement under large perturbation rate.</cell></row><row><cell>? STABLE outperforms other methods under different perturbation</cell></row></table><note><p>rates. Note that on Polblogs, we randomly remove and add a small portion of edges to generate augmentations. As the perturbation rate increases, the performance drops slowly on all datasets, which demonstrates that STABLE is insensitive to the perturbations.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Classification accuracy(%) under different perturbation rates. The top two performance is highlighted in bold and underline. Other attacks. The performance under DICE and Random is presented in Fig.3. We only show the results on Cora and Citeseer due to the page limitation. RGCN and GRCN are not competitive, so they are not shown to keep the figure neat. Considering that DICE and Random are not as effective as MetaAttack, we set the perturbation rate higher. The figure shows that STABLE consistently outperforms all other baselines and successfully resists both attacks. Together with the observations from Section 4.2, we can conclude that STABLE outperforms these baselines and is able to defend against different types of attacks.</figDesc><table><row><cell cols="2">Dataset Ptb Rate</cell><cell>GCN</cell><cell>RGCN</cell><cell cols="3">Jaccard GNNGuard</cell><cell>GRCN</cell><cell>ProGNN SimPGCN</cell><cell>Elastic</cell><cell>STABLE</cell></row><row><cell></cell><cell>0%</cell><cell cols="7">83.56?0.25 83.85?0.32 81.79?0.37 78.52?0.46 86.12?0.41 84.55?0.30 83.77?0.57 84.76?0.53 85.58?0.56</cell></row><row><cell></cell><cell>5%</cell><cell cols="7">76.36?0.84 76.54?0.49 80.23?0.74 77.96?0.54 80.78?0.94 79.84?0.49 78.98?1.10 82.00?0.39 81.40?0.54</cell></row><row><cell>Cora</cell><cell>10%</cell><cell cols="7">71.62?1.22 72.11?0.99 74.65?1.48 74.86?0.54 72.43?0.78 74.22?0.31 75.07?2.09 76.18?0.46 80.49?0.61</cell></row><row><cell></cell><cell>15%</cell><cell cols="7">66.37?1.97 65.52?1.12 74.29?1.11 74.15?1.64 70.72?1.13 72.75?0.74 71.42?3.29 74.41?0.97 78.55?0.44</cell></row><row><cell></cell><cell>20%</cell><cell cols="7">60.31?1.98 63.23?0.93 73.11?0.88 72.03?1.11 65.34?1.24 64.40?0.59 68.90?3.22 69.64?0.62 77.80?1.10</cell></row><row><cell></cell><cell>0%</cell><cell cols="7">74.63?0.66 75.41?0.20 73.64?0.35 70.07?1.31 75.65?0.21 74.73?0.31 74.66?0.79 74.86?0.53 75.82?0.41</cell></row><row><cell></cell><cell>5%</cell><cell cols="7">71.13?0.55 72.33?0.47 71.15?0.83 69.43?1.46 74.47?0.38 72.88?0.32 73.54?0.92 73.28?0.59 74.08?0.58</cell></row><row><cell>Citeseer</cell><cell>10%</cell><cell cols="7">67.49?0.84 69.80?0.54 69.85?0.77 67.89?1.09 72.27?0.69 69.94?0.45 72.03?1.30 73.41?0.36 73.45?0.40</cell></row><row><cell></cell><cell>15%</cell><cell cols="7">61.59?1.46 62.58?0.69 67.50?0.78 69.14?0.84 67.48?0.42 62.61?0.64 69.82?1.67 67.51?0.45 73.15?0.53</cell></row><row><cell></cell><cell>20%</cell><cell cols="7">56.26?0.99 57.74?0.79 67.01?1.10 69.20?0.78 63.73?0.82 55.49?1.50 69.59?3.49 65.65?1.95 72.76?0.53</cell></row><row><cell></cell><cell>0%</cell><cell cols="3">95.04?0.11 95.38?0.14</cell><cell>/</cell><cell>/</cell><cell cols="2">94.89?0.24 95.93?0.17 94.86?0.46 95.57?0.26 95.95?0.27</cell></row><row><cell></cell><cell>5%</cell><cell cols="3">77.55?0.77 76.46?0.47</cell><cell>/</cell><cell>/</cell><cell cols="2">80.37?0.46 93.48?0.54 75.08?1.08 90.08?1.06 93.80?0.12</cell></row><row><cell>Polblogs</cell><cell>10%</cell><cell cols="3">70.40?1.13 70.35?0.40</cell><cell>/</cell><cell>/</cell><cell cols="2">69.72?1.36 85.81?1.00 68.36?1.88 84.05?1.94 92.46?0.77</cell></row><row><cell></cell><cell>15%</cell><cell cols="3">68.49?0.49 67.74?0.50</cell><cell>/</cell><cell>/</cell><cell cols="2">66.56?0.93 75.60?0.70 65.02?0.74 72.17?0.74 90.04?0.72</cell></row><row><cell></cell><cell>20%</cell><cell cols="3">68.47?0.54 67.31?0.24</cell><cell>/</cell><cell>/</cell><cell cols="2">68.20?0.71 73.66?0.64 64.78?1.33 71.76?0.92 88.46?0.33</cell></row><row><cell></cell><cell>0%</cell><cell cols="7">86.83?0.06 86.02?0.08 86.85?0.09 85.24?0.07 86.72?0.03 87.33?0.18 88.12?0.17 87.71?0.06 87.73? 0.11</cell></row><row><cell></cell><cell>5%</cell><cell cols="7">83.18?0.06 82.37?0.12 86.22?0.08 84.65?0.09 84.85?0.07 87.25?0.09 86.96?0.18 86.82?0.13 87.59?0.08</cell></row><row><cell>Pubmed</cell><cell>10%</cell><cell cols="7">81.24?0.17 80.12?0.12 85.64?0.08 84.51?0.06 81.77?0.13 87.25?0.09 86.41?0.34 86.78?0.11 87.46?0.12</cell></row><row><cell></cell><cell>15%</cell><cell cols="7">78.63?0.10 77.33?0.16 84.57?0.11 84.78?0.10 77.32?0.13 87.20?0.09 85.98?0.30 86.36?0.14 87.38?0.09</cell></row><row><cell></cell><cell>20%</cell><cell cols="7">77.08?0.2 74.96?0.23 83.67?0.08 84.25?0.07 69.89?0.21 87.09?0.10 85.62?0.40 86.04?0.17 87.24?0.08</cell></row><row><cell>$FFXUDF\</cell><cell>*&amp;1 -DFFDUG *11*XDUG</cell><cell></cell><cell>$FFXUDF\</cell><cell>*&amp;1 -DFFDUG *11*XDUG</cell><cell></cell><cell>$FFXUDF\</cell><cell>*&amp;1 -DFFDUG *11*XDUG</cell><cell>$FFXUDF\</cell><cell>*&amp;1 -DFFDUG *11*XDUG</cell></row><row><cell></cell><cell>3UR*11</cell><cell></cell><cell></cell><cell>3UR*11</cell><cell></cell><cell></cell><cell>3UR*11</cell><cell>3UR*11</cell></row><row><cell></cell><cell>6LP3*&amp;1</cell><cell></cell><cell></cell><cell>6LP3*&amp;1</cell><cell></cell><cell></cell><cell>6LP3*&amp;1</cell><cell>6LP3*&amp;1</cell></row><row><cell></cell><cell>(ODVWLF</cell><cell></cell><cell></cell><cell>(ODVWLF</cell><cell></cell><cell></cell><cell>(ODVWLF</cell><cell>(ODVWLF</cell></row><row><cell></cell><cell>67$%/(</cell><cell></cell><cell></cell><cell>67$%/(</cell><cell></cell><cell></cell><cell>67$%/(</cell><cell>67$%/(</cell></row><row><cell></cell><cell cols="2">3HUWXUEDWLRQ5DWH</cell><cell></cell><cell cols="2">3HUWXUEDWLRQ5DWH</cell><cell></cell><cell cols="2">3HUWXUEDWLRQ5DWH</cell><cell>3HUWXUEDWLRQ5DWH</cell></row><row><cell></cell><cell cols="2">(a) Cora DICE</cell><cell></cell><cell cols="2">(b) Citeseer DICE</cell><cell></cell><cell cols="2">(c) Cora Random</cell><cell>(d) Citeseer Random</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">Figure 3: Cora and Citeseer under DICE and Random</cell></row><row><cell cols="7">Especially STABLE has a huge improvement over other methods</cell><cell></cell></row><row><cell cols="3">on heavily contaminated graphs.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4.2.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>The statistics of the removed edges on the learned graph. It is worth noting that, regardless of the value of k, it is better to add than not to add. Another observation is that even ? = 5, which means nodes almost only aggregate messages from the neighbors with the highest degree, the result is still better than vanilla GCN, i.e., ? = -0.5.</figDesc><table><row><cell>Method</cell><cell cols="4">Total Adversarial Normal Accuracy(%)</cell></row><row><cell>Jaccard</cell><cell>1, 008</cell><cell>447</cell><cell>561</cell><cell>44.35</cell></row><row><cell cols="2">GNNGuard 1, 082</cell><cell>482</cell><cell>600</cell><cell>44.55</cell></row><row><cell>STABLE</cell><cell>1, 035</cell><cell>601</cell><cell>434</cell><cell>58.07</cell></row><row><cell>MetaAttack.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>The specific values of ? and ? which achieve the peak performance on Cora under different perturbation rate</figDesc><table><row><cell cols="2">Ptb Rate 0%</cell><cell cols="6">5% 10% 15% 20% 35% 50%</cell></row><row><cell>?</cell><cell>1</cell><cell>5</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>13</cell></row><row><cell>?</cell><cell cols="3">-0.5 -0.3 0.3</cell><cell>0.6</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Classification accuracy(%) on Cora under different perturbation rates. The asterisk indicates that the GCN part of this model is replaced with advanced GCN.</figDesc><table><row><cell cols="6">Datasets Ptb rate Jaccard Jaccard* SimpGCN SimpGCN*</cell></row><row><cell></cell><cell>0%</cell><cell>81.79</cell><cell>81.11</cell><cell>83.77</cell><cell>83.64</cell></row><row><cell></cell><cell>5%</cell><cell>80.23</cell><cell>80.57</cell><cell>78.98</cell><cell>80.45</cell></row><row><cell></cell><cell>10%</cell><cell>74.65</cell><cell>76.99</cell><cell>75.07</cell><cell>78.04</cell></row><row><cell>Cora</cell><cell>15%</cell><cell>74.29</cell><cell>76.32</cell><cell>71.42</cell><cell>75.31</cell></row><row><cell></cell><cell>20%</cell><cell>73.11</cell><cell>73.42</cell><cell>68.90</cell><cell>73.29</cell></row><row><cell></cell><cell>35%</cell><cell>66.11</cell><cell>68.79</cell><cell>64.87</cell><cell>71.15</cell></row><row><cell></cell><cell>50%</cell><cell>58.08</cell><cell>64.06</cell><cell>51.94</cell><cell>65.63</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>It is the state-of-the-art attack method that uses meta-gradients to maliciously modify the graph structure.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work is supported by <rs type="funder">Alibaba Group through Alibaba Innovative Research Program</rs>. This work is supported by the <rs type="funder">National Natural Science Foundation of China</rs> under Grant (No.<rs type="grantNumber">61976204</rs>, <rs type="grantNumber">U1811461</rs>, <rs type="grantNumber">U1836206</rs>). Xiang Ao is also supported by the <rs type="funder">Project of Youth Innovation Promotion Association CAS</rs>, <rs type="programName">Beijing Nova Program</rs> <rs type="grantNumber">Z201100006820062</rs>. <rs type="person">Yang Liu</rs> is also supported by <rs type="funder">China Scholarship Council</rs>. We would like to thank the anonymous reviewers for their valuable comments, and <rs type="person">Mengda Huang</rs>, <rs type="person">Linfeng Dong</rs>, <rs type="person">Zidi Qin</rs> for their insightful discussions.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_FCYhQkA">
					<idno type="grant-number">61976204</idno>
				</org>
				<org type="funding" xml:id="_JSG22a4">
					<idno type="grant-number">U1811461</idno>
				</org>
				<org type="funding" xml:id="_egUDZgm">
					<idno type="grant-number">U1836206</idno>
				</org>
				<org type="funding" xml:id="_ug4asvN">
					<idno type="grant-number">Z201100006820062</idno>
					<orgName type="program" subtype="full">Beijing Nova Program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX A.1 Algorithm</head><p>The overall training algorithm is shown in Algorithm 1. In line 2, we roughly pre-process G by removing some potential perturbations. From lines 3 to 10, we utilize a contrastive learning model with robustness-oriented augmentations to obtain the node representations. In lines 11 and 12, we refine the graph structure based on the representations learned before. from line 13 to 20, we train the classifier GCN * on ? * . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Datasets</head><p>Following <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b53">54]</ref>, we only consider the largest connected connected component (LCC). The statistics is listed in Tabel 5. There is no features available in Polblogs. Following <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b27">28]</ref> we set the feature matrix to be a ? ? ? identity matrix. The results of GNN-Guard and Jaccard on Polblogs are not available because the cosine similarity of the identity matrix is meaningless. For PubMed dataset, we use the attacked graphs provided provided by <ref type="bibr" target="#b20">[21]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Baselines</head><p>? GCN <ref type="bibr" target="#b23">[24]</ref>: GCN is a popular graph convolutional network based on spectral theory. ? RGCN <ref type="bibr" target="#b48">[49]</ref>: RGCN utilizes gaussian distributions to represent node and uses a variance-based attention mechanism to remedy the propagation of adversarial attacks. ? Jaccard <ref type="bibr" target="#b39">[40]</ref>: Since attacks tend to link nodes with different labels, Jaccard prune edges which connect two dissimilar nodes.</p><p>? GNNGuard <ref type="bibr" target="#b44">[45]</ref>: GNNGuard utilizes cosine similarity to model the edge weights and then calculates edge pruning probability through a non-linear transformation.</p><p>? GRCN <ref type="bibr" target="#b43">[44]</ref>: GRCN models edge weights by taking inner product of embeddings of two end nodes. ? ProGNN <ref type="bibr" target="#b21">[22]</ref>: ProGNN treats the adjacency matrix as learnable parameters and directly optimizes it with three regularizations, i.e., feature smoothness, low-rank and sparsity. ? SimpGCN <ref type="bibr" target="#b19">[20]</ref>: SimpGCN utilizes a ?NN graph to keep the nodes with similar features close in the representation space and a self-learning regularization to keep the nodes with dissimilar features remote.</p><p>? Elastic <ref type="bibr" target="#b27">[28]</ref>: Elastic introduces ? 1 -norm to graph signal estimator and proposes elastic message passing which is derived from one step optimization of such estimator. The local smoothness adaptivity enables the Elastic GNNs robust to structural attacks. ? MetaAttack <ref type="bibr" target="#b54">[55]</ref>: MetaAttack uses meta-gradients to solve the bilevel problem underlying poisoning attacks, essentially treating the graph as a hyperparameter to optimize. ? DICE <ref type="bibr" target="#b37">[38]</ref>: Disconnect Internally, connect externally.</p><p>? Random: Inject random structure noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Implementation Details</head><p>We use DeepRobust, an adversarial attack repository <ref type="bibr" target="#b25">[26]</ref>, to implement all the attack methods, RGCN, ProGNN, SimpGCN, and Jaccard. GNNGuard, Elastic, and GCN are implemented with the code provided by the authors.</p><p>For each graph, we randomly split the nodes into 10% for training, 10% for validation, and 80% for testing. Then we generate attacks on each graph according to the perturbation rate, and all the hyper-parameters in attack methods are the same with the authors' implementation. For all the defense models, we report the average accuracy and standard deviation of 10 runs.</p><p>All the hyper-parameters are tuned based on the loss and accuracy of the validation set. For RGCN, the hidden dimensions are tuned from {16, 32, 64, 128}. For Jaccard, the Jaccard Similarity</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixhop: Higher-order Graph Convolutional Architectures via Sparsified Neighborhood Mixing</title>
		<author>
			<persName><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazanin</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Ver Steeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Peter W Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<title level="m">Relational Inductive Biases, Deep Learning, and Graph Networks</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Understanding Structural Vulnerability in Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jintang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibiao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zibin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.06280</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Simple Framework for Contrastive Learning of Visual Representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Adaptive Universal Generalized Pagerank Graph Neural Network</title>
		<author>
			<persName><forename type="first">Eli</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olgica</forename><surname>Milenkovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adversarial Attack on Graph Structured Data</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1115" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">All You Need is Low (rank) Defending Against Adversarial Attacks on Graphs</title>
		<author>
			<persName><forename type="first">Negin</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saba</forename><forename type="middle">A</forename><surname>Al-Sayouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Darvishzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Bahare</forename><surname>Fatemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Layla</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyed</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazemi</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Single-Node Attack for Fooling Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Finkelshtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaim</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgenii</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.03574</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploring Structure-adaptive Graph Learning for Robust Semi-supervised Classification</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongming</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning Graph Representations With Embedding Propagation</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duran</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Reliable Graph Neural Networks via Robust Aggregation</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Z?gner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeruIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contrastive Multi-view Representation Learning on Graphs</title>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hosein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khasahmadi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. PMLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4116" to="4126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning Deep Representations by Mutual Information Estimation and Maximization</title>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Measuring and Improving The Use of Graph Information in Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaili</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard Tb</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Chang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">AUC-oriented Graph Neural Network for Fraud Detection</title>
		<author>
			<persName><forename type="first">Mengda</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghua</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Scaling Personalized Web Search</title>
		<author>
			<persName><forename type="first">Glen</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Node Similarity Preserving Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Derr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zitao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adversarial Attacks and Defenses on Graphs: A Review, A Tool and Empirical Studies</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charu</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD Explorations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Graph Structure Learning for Robust Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Xianfeng Tang, Suhang Wang, and Jiliang Tang</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Variational Graph Auto-Encoders</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS Workshop on Bayesian Deep Learning</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adaptive Graph Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Ruoyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feiyun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.06149</idno>
		<title level="m">Deeprobust: A Pytorch Library for Adversarial Attacks and Defenses</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Gated Graph Sequence Neural Networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Elastic Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6837" to="6849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Pick and Choose: A GNN-based Imbalanced Learning Approach for Fraud Detection</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zidi</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghua</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3168" to="3177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to Drop: Robust Graph Neural Network via Topological Denoising</title>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenchao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingchao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="779" to="787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Birds of a Feather: Homophily in Social Networks</title>
		<author>
			<persName><forename type="first">Lynn</forename><surname>Miller Mcpherson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Smith-Lovin</surname></persName>
		</author>
		<author>
			<persName><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of sociology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="415" to="444" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Graph Representation Learning via Graphical Mutual Information Maximization</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minnan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghua</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deepwalk: Online Learning of Social Representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Infograph: Unsupervised and Semi-supervised Graph-level Representation Learning via Mutual Information maximization</title>
		<author>
			<persName><forename type="first">Fan-Yun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Graph Attention Networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Hjelm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.10341</idno>
		<title level="m">Deep Graph Infomax</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Am-gcn: Adaptive Multi-channel Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meiqi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyu</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<idno>KDD. 1243-1253</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hiding Individuals and Communities in A Social Network</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Waniek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tomasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Talal</forename><surname>Wooldridge</surname></persName>
		</author>
		<author>
			<persName><surname>Rahwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="139" to="147" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Taylan Cemgil, et al. 2022. A Fine-grained Analysis on Distribution Shift</title>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Wiles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Stimberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ira</forename><surname>Sylvestre Alvise-Rebuffi</surname></persName>
		</author>
		<author>
			<persName><surname>Ktena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adversarial Examples on Graph Data: Deep Insights Into Attack and Defense</title>
		<author>
			<persName><forename type="first">Huijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Tyshetskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Docherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liming</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective</title>
		<author>
			<persName><forename type="first">Kaidi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongge</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsui-Wei</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyi</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">How Powerful Are Graph Neural Networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Yuning</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongduo</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Shen</surname></persName>
		</author>
		<title level="m">Graph Contrastive Learning With Augmentations</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Graph-revised Convolutional Network</title>
		<author>
			<persName><forename type="first">Donghan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruohong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="378" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">GNNGuard: Defending Graph Neural Networks Against Adversarial Attacks</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep learning on graphs: A survey</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Data Augmentation for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yozen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Woodford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Graph Neural Networks: A Review of Methods and Applications</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ganqu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengding</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="81" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Robust Graph Convolutional Networks Against Adversarial Attacks</title>
		<author>
			<persName><forename type="first">Dingyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1399" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Qing He, and Jianping Li. 2021. Intelligent financial fraud detection practices in post-pandemic era</title>
		<author>
			<persName><forename type="first">Xiaoqian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zidi</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanpeng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Innovation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">100176</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly Detection</title>
		<author>
			<persName><forename type="first">Yulin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuni</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifa</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiapu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingquan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03036</idno>
		<title level="m">Deep Graph Structure Learning for Robust Representations: A Survey</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep Graph Contrastive Representation Learning</title>
		<author>
			<persName><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2006.04131" />
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Graph Representation Learning and Beyond</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adversarial Attacks on Neural Networks for Graph Data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Z?gner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Adversarial Attacks on Graph Neural Networks via Meta Learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Z?gner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
