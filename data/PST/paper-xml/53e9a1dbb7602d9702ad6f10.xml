<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generalized Millman&apos;s formula and its application for estimation problems $</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-07-12">12 July 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vladimir</forename><surname>Shin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mechatronics</orgName>
								<orgName type="institution">Gwangju Institute of Science and Technology</orgName>
								<address>
									<addrLine>1 Oryong-Dong, Buk-Gu</addrLine>
									<postCode>500-712</postCode>
									<settlement>Gwangju</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Younghee</forename><surname>Lee</surname></persName>
							<email>yhlee@kyungnam.ac.kr</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics Education</orgName>
								<orgName type="institution">Kyungnam University</orgName>
								<address>
									<addrLine>449 Wolyoung-Dong, Happo-Gu</addrLine>
									<postCode>631-701</postCode>
									<settlement>Masan</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tae-Sun</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mechatronics</orgName>
								<orgName type="institution">Gwangju Institute of Science and Technology</orgName>
								<address>
									<addrLine>1 Oryong-Dong, Buk-Gu</addrLine>
									<postCode>500-712</postCode>
									<settlement>Gwangju</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generalized Millman&apos;s formula and its application for estimation problems $</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-07-12">12 July 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">3DE8712FAF86AD703D73C7BBF7C39FFB</idno>
					<idno type="DOI">10.1016/j.sigpro.2005.05.015</idno>
					<note type="submission">Received 11 March 2004; received in revised form 14 October 2004; accepted 15 May 2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Least-squares estimator</term>
					<term>Millman&apos;s formula</term>
					<term>Kalman filter</term>
					<term>Lainiotis-Kalman adaptive filter</term>
					<term>Suboptimal filtering</term>
					<term>Multisensor</term>
					<term>Data fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We derive an optimal combination of arbitrary number correlated estimates. In particular, for two estimates this combination represents the well-known Millman and Bar-Shalom-Campo formulae for uncorrelated and correlated estimation errors, respectively. This new result is applied to the various estimation problems as least-squares estimation, Kalman filtering, and adaptive filtering. The new approximate reduced-order estimators with parallel structure are presented. A practical implementation issue to consider these estimators is also addressed. Examples demonstrate the accuracy and efficiency of application of the generalized Millman's formula.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, there has been growing interest to fuse multisensory data to increase the accuracy of estimation parameters and system states. This interest is motivated by the availability of different types of sensor which uses various characteristics of the optical, infrared, and electromagnetic spectrums. In many situations system states or targets are measured by multisensors. The measurements used in the estimation process are assigned to a common target as a result of the association process. There is a problem of how to combine the estimates obtained from different types of sensors. The well-known Millman and Bar-Shalom-Campo formulae for two uncorrelated and correlated estimation errors, respectively, are widely used in the filtering and the smoothing problems <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>. But there is a need to generalize these formulae for the multisensor environment so that we can fuse more than two arbitrary dependent estimates.</p><p>The main purpose of this paper is a generalization of the Millman and Bar-Shalom-Campo formulae to arbitrary number of estimates, which we called generalized Millman's formula (GMF). The GMF represents optimal in mean-square sense linear combination of estimates with weighting coefficients depending on cross covariances between estimation errors. Furthermore the GMF has parallel structure and allows parallel processing of measurements.</p><p>A second purpose is to show how to apply the GMF in the several estimation problems such as least-squares (LS) estimation and state estimation in linear dynamic systems. It is shown that in the case of uncorrelated noises the estimator based on GMF is equivalent to the classical LS estimator. The obtained estimation algorithms reduce the computational burden and on-line computational requirements. This has been achieved via the use of a decomposition of the measurement vector into a set of subvectors of low dimension. The examples demonstrate the efficiency and high-accuracy of the proposed algorithms.</p><p>This paper is organized as follows. In Section 2, we derive the GMF and demonstrate the relationship between the GMF and the Millman and the Bar-Shalom-Campo formulae. In Section 3, it is shown that the GMF is equivalent to the batch LS estimator. In Sections 4 and 5, the new suboptimal and adaptive filters are derived by using the GMF and the decomposition of measurement vector. Finally, Section 6 is the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A general estimation model. The generalized Millman's formula</head><p>Suppose we have N local estimates of an unknown random vector</p><formula xml:id="formula_0">x 2 R n , x1 ; . . . ; xN ,<label>(1)</label></formula><p>where R n is an n-dimensional Euclidean space. The associated local error covariances are</p><formula xml:id="formula_1">P ij ¼ covf xi ; xj g; xi ¼ x À xi , i; j ¼ 1; . . . ; N.<label>ð2Þ</label></formula><p>It is desired to find the overall linear estimate of x, that is, the optimal estimate of the form</p><formula xml:id="formula_2">x ¼ X N i¼1 c i xi ; X N i¼1 c i ¼ I n ,<label>(3)</label></formula><p>where I n is the n Â n identity matrix, and c 1 ; . . . ; c N are n Â n constant weighting matrices determined from the mean-square criterion</p><formula xml:id="formula_3">Jðc 1 ; . . . ; c N Þ ¼ E xÀ X N i¼1 c i xi 2 0 @ 1 A ! min c i .<label>(4)</label></formula><p>The following linear equation for unknown weighting matrices c 1 ; . . . ; c N give a solution of this problem:</p><formula xml:id="formula_4">X NÀ1 i¼1 c i ðP ij À P iN Þ þ c N ðP Nj À P NN Þ ¼ 0, j ¼ 1; . . . ; N À 1, X N i¼1 c i ¼ I n .<label>ð5Þ</label></formula><p>The derivation of Eq. ( <ref type="formula" target="#formula_4">5</ref>) is given in Appendix A.</p><p>We call the formula (3) with the weighting matrices defined by <ref type="bibr" target="#b4">(5)</ref> as the generalized Millman's formula (GMF).</p><p>Remarks. (a) If local estimates x1 ; . . . ; xN in (1) are unbiased, then the overall estimate x ð3Þ is unbiased,</p><formula xml:id="formula_5">Eð xÞ ¼ X N i¼1 c i Eð xi Þ ¼ X N i¼1 c i " # EðxÞ ¼ EðxÞ.</formula><p>(b) The overall error covariance P ¼ covf xg; x ¼ x À x is given by</p><formula xml:id="formula_6">P ¼ E ðx À xÞðx À xÞ T Â Ã ¼ E X N i; j¼1 c i xi ðc j xj Þ T " # ¼ X N i;j¼1 c i P ij c T j ; P ij ¼ covf xi ; xj g.<label>ð6Þ</label></formula><p>(c) Usually in applications the local error covariances P ii ¼ covf xi ; xi g; i ¼ 1; . . . ; N are known. For instance, in linear estimation problems P ii is described by the Kalman filter equations or the LS one. However the cross-covariances P ij ¼ covf xi ; xj g; iaj, are usually unknown and it should be determined as in Section 4 or putted P ij ¼ 0 assuming that the local estimates are uncorrelated.</p><p>Example 1 (Optimal combination of two estimates). In the particular case at N ¼ 2 the GMF (3), <ref type="bibr" target="#b4">(5)</ref> gives the Bar-Shalom-Campo formula for the optimal combination of two correlated estimates <ref type="bibr" target="#b0">[1]</ref>,</p><formula xml:id="formula_7">x ¼ x1 þ ðP 11 À P 12 ÞðP 11 þ P 22 À P 12 À P 21 Þ À1 Âð x2 À x1 Þ ¼ ðP 22 À P 21 ÞðP 11 þ P 22 À P 12 À P 21 Þ À1 x1 þ ðP 11 À P 12 ÞðP 11 þ P 22 À P 12 À P 21 Þ À1 x2 .<label>ð7Þ</label></formula><p>If the two estimates x1 and x2 are uncorrelated, i.e., P 12 ¼ P 21 ¼ 0 in <ref type="bibr" target="#b6">(7)</ref>, then we have the Millman's formula <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>,</p><formula xml:id="formula_8">x ¼ P 22 ðP 11 þ P 22 Þ À1 x1 þ P 11 ðP 11 þ P 22 Þ À1 x2 . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>Example 2 (Fusion of the uncorrelated N-estimates). Suppose that the estimation errors x1 ; . . . ; xN are uncorrelated, i.e., P ij ¼ 0; iaj; then the linear system (5) has an explicit solution and the weighting matrices c 1 ; . . . ; c N in (3) take the form:</p><formula xml:id="formula_10">c i ¼ P ii X N j¼1 P À1 jj ! À1 ; i ¼ 1; . . . ; N.<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The optimal LS estimator</head><p>In the linear LS problem it is desired to estimate the vector x 2 R n , modeled as an unknown constant, from the linear measurements y 1 ; y 2 ; . . . ; y N ,</p><formula xml:id="formula_11">y i ¼ H i x þ w i ; y i 2 R m ; i ¼ 1; . . . ; N,<label>(10)</label></formula><p>such as to minimize the quadratic error weighted with the inverse of the positive definite matrix R N ,</p><formula xml:id="formula_12">J N ¼ ðy N À H N xÞ T ðR N Þ À1 ðy N À H N xÞ,<label>(11)</label></formula><p>where </p><formula xml:id="formula_13">y N ¼ y 1 . . . y N<label>2</label></formula><formula xml:id="formula_14">R N ¼ R 1 Á Á Á 0 . . . . . . . . . 0 Á Á Á R N 2 6 6 6 4 3 7 7 7 5 ¼ diag½R i .<label>ð12Þ</label></formula><p>The LS estimator that minimizes (11) is given by</p><formula xml:id="formula_15">x ¼ PðH N Þ T ðR N Þ À1 y N , P ¼ ðH N Þ T ðR N Þ À1 H N Â Ã À1 , P ¼ covð xÞ; x ¼ x À x<label>ð13Þ</label></formula><p>assuming the required inverse exists <ref type="bibr" target="#b3">[4]</ref>.</p><p>Using the blocked structure (12), the formulae (13) can be reconstructed as</p><formula xml:id="formula_16">x ¼ P X N i¼1 H T i R À1 i y i , P ¼ X N j¼1 H T j R À1 j H j ! À1 ¼ X N j¼1 P À1 jj ! À1 , P jj 9ðH T j R À1 j H j Þ À1 ; j ¼ 1; . . . ; N.<label>(14)</label></formula><p>To connect the LS estimator ( <ref type="formula" target="#formula_16">14</ref>) with the GMF (3), we first rewrite (14) as follows:</p><formula xml:id="formula_17">x ¼ X N j¼1 P À1 jj ! À1 X N i¼1 H T i R À1 i y i ¼ X N i¼1 X N j¼1 P À1 jj ! À1 ðP À1 ii P ii ÞH T i R À1 i y i or x ¼ X N i¼1 c i xi ; xi ¼ P ii H T i R À1 i y i , c i 9 P ii X N j¼1 P À1 jj ! À1 ; i ¼ 1; . . . ; N.<label>ð15Þ</label></formula><p>Comparing the above formula ( <ref type="formula" target="#formula_10">9</ref>) and ( <ref type="formula" target="#formula_17">15</ref>), the equivalence of the LS estimator (13) and GMF (3), (9) is established.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">State estimation in discrete-time linear systems</head><p>Consider a discrete-time linear dynamic system described by a difference equation with additive white Gaussian noise,</p><formula xml:id="formula_18">x kþ1 ¼ F k x k þ G k v k ; k ¼ 0; 1; . . . ,<label>(16)</label></formula><p>where x k 2 R n is the state vector, and fv k g is the sequence of zero-mean white Gaussian process noise,</p><formula xml:id="formula_19">v k 2 R r ; v k $Nð0; Q k Þ.</formula><p>Suppose that multiple sensor (measurement system) involves N sensors,</p><formula xml:id="formula_20">y ð1Þ k ¼ H ð1Þ k x k þ w ð1Þ k ; k ¼ 1; 2; . . . ; y ð1Þ k 2 R m 1 , . . . y ðNÞ k ¼ H ðNÞ k x k þ w ðNÞ k ; k ¼ 1; 2; . . . ; y ðNÞ k 2 R m N ,<label>ð17Þ</label></formula><p>with fw ð1Þ k g; . . . ; fw ðNÞ k g are the sequence of zeromean white Gaussian measurement noise, w ðiÞ k 2 R m i ; w ðiÞ k $Nð0; R ðiÞ k Þ; i ¼ 1; . . . ; N: The initial state is modeled as a Gaussian random vector with known mean and covariance, x 0 $Nðx 0 ; P 0 Þ. The N þ 1 noise sequences fv k g; fw ðiÞ k g; i ¼ 1; . . . ; N, and the initial state x 0 are mutually independent.</p><p>It is well known that the Kalman filter(KF) can be used to produce the optimal state estimate based on the results of overall measurements</p><formula xml:id="formula_21">Y k ¼ fy ð1Þ k . . . y ðNÞ k g; Y k 2 R m , m 1 þ Á Á Á þ m N ¼ m.<label>ð18Þ</label></formula><p>However, the computational cost and the numerical errors of the KF increase drastically with the state and measurement dimensions, for instance, in multisensor intelligent systems <ref type="bibr" target="#b4">[5]</ref>. Hence, the KF may be impractical to implement. In such cases, reduced-order suboptimal filters are preferable since there is no need to estimate those states by using overall measurements Y k simultaneously. In this paper, we show that the GMF may serve as an alternative to solve this problem. The derivation of new suboptimal reduced-order filter is based on the assumption that the overall measurement vector Y k consists of the combination of the different subvectors y ð1Þ k ; . . . ; y ðNÞ k , which can be processing separately. According to ( <ref type="formula" target="#formula_18">16</ref>) and (17), we have N unconnected dynamic subsystems ði ¼ 1; . . . ; NÞ with state vector x k 2 R n and measurement subvector y ðiÞ k 2 R m i :</p><formula xml:id="formula_22">x kþ1 ¼ F k x k þ G k v k , y ðiÞ k ¼ H ðiÞ k x k þ w ðiÞ k ,<label>ð19Þ</label></formula><p>where i (the number of subsystem) is fixed.</p><p>Next, let us denote the estimate of the state x k based on the measurement y ðiÞ k by xðiÞ kjk . To find xðiÞ kjk we apply the KF to the subsystem (19). We have </p><formula xml:id="formula_23">xðiÞ kjkÀ1 ¼ F kÀ1 xðiÞ kÀ1jkÀ1 ; xðiÞ 0j0 ¼ x 0 , xðiÞ kjk ¼ xðiÞ kjkÀ1 þ K ðiÞ k y ðiÞ k À H ðiÞ k xðiÞ kjkÀ1 h i , P ðiÞ kjkÀ1 ¼ F kÀ1 P ðiÞ kÀ1jkÀ1 F T kÀ1 þ G kÀ1 Q kÀ1 G T kÀ1 , P ðiÞ 0j0 ¼ P 0 , K<label>ðiÞ</label></formula><formula xml:id="formula_24">xGMF kjk ¼ X N i¼1 c ðiÞ k xðiÞ kjk ; X N i¼1 c ðiÞ k ¼ I n ,<label>(24)</label></formula><p>where the time-varying weighting matrices c ð1Þ k ; . . . ; c ðNÞ k determined by the Eqs. ( <ref type="formula" target="#formula_4">5</ref>):</p><formula xml:id="formula_25">X NÀ1 i¼1 c ðiÞ k P ðijÞ kjk À P ðiNÞ kjk þ c ðNÞ k P ðNjÞ kjk À P ðNNÞ kjk ¼ 0, j ¼ 1; . . . ; N À 1, X N i¼1 c ðiÞ k ¼ I n ,<label>ð25Þ</label></formula><p>where P ðiiÞ kjk 9P ðiÞ kjk is the covariance (23) determined by the KF (20), and P ðijÞ kjk ; iaj is cross-covariance, P ðijÞ kjk ¼ covf xðiÞ kjk ; xðjÞ kjk g, which satisfy the recursion</p><formula xml:id="formula_26">P ðijÞ kjk ¼ I n À K ðiÞ k H ðiÞ k h i Â F kÀ1 P ðijÞ kÀ1jkÀ1 F T kÀ1 þ G kÀ1 Q kÀ1 G T kÀ1 h i Â I n À K ðjÞ k H ðjÞ k h i T , P<label>ðijÞ</label></formula><formula xml:id="formula_27">0j0 ¼ P 0 ; iaj; i; j ¼ 1; . . . ; N,<label>(26)</label></formula><p>where the gain K ðiÞ k is determined by the KF (20). The derivation of the Eq. ( <ref type="formula" target="#formula_27">26</ref>) is given in Appendix B.</p><p>Thus, the KF (20), the GMF (24), (25) and the Eq. ( <ref type="formula" target="#formula_27">26</ref>) completely define the new suboptimal filter for estimate xGMF kjk of the state vector x k . Note, that the local estimates (22) are separated for different types of sensors. Therefore, the Kalman filters (20) can be implemented in parallel for various number of sensors i ¼ 1; . . . ; N.</p><p>Example 3 (Independent measurements of a scalar unknown). To estimate the value of a scalar unknown y from two types of measurements corrupted by additive white Gaussian noises, the system and measurement models are</p><formula xml:id="formula_28">x kþ1 ¼ x k ; x k ¼ y; k ¼ 0; 1; . . . , y ð1Þ k ¼ x k þ w ð1Þ k ; y ð2Þ k ¼ x k þ w ð2Þ k ,<label>ð27Þ</label></formula><p>where x k ; y ð1Þ k ; y ð2Þ k 2 R and w ðiÞ k $Nð0;</p><formula xml:id="formula_29">r i Þ; i ¼ 1; 2. Let x 0 $Nðy; s 2 y Þ.</formula><p>The KF gives the optimal mean-square estimate xKF kjk of an unknown y based on the overall measurements y ð1Þ k y ð2Þ k h i T . In this case it takes the form:</p><formula xml:id="formula_30">xKF kjk ¼ xKF kÀ1jkÀ1 þ K KF k y ð1Þ k À xKF kÀ1jkÀ1 y ð2Þ k À xKF kÀ1jkÀ1 2 4 3 5 , xKF 0j0 ¼ y, P KF kjkÀ1 ¼ P KF kÀ1jkÀ1 ; P KF 0j0 ¼ s 2 y , K KF k ¼ r 2 P KF kjkÀ1 r 1 r 2 þ ðr 1 þ r 2 ÞP KF kjkÀ1 r 1 P KF kjkÀ1 r 1 r 2 þ ðr 1 þ r 2 ÞP KF kjkÀ1 " # , P KF kjk ¼ r 1 r 2 P KF kjkÀ1 r 1 r 2 þ ðr 1 þ r 2 ÞP KF kjkÀ1 . (<label>28</label></formula><formula xml:id="formula_31">)</formula><p>Using the ''step-by-step'' induction, we obtain the exact formula for the mean-square error P KF kjk ,</p><formula xml:id="formula_32">P KF kjk 9Eðy À xKF kjk Þ 2 ¼ s 2 y 1 þ kr 12 s 2 y , r 12 ¼ r 1 þ r 2 r 1 r 2 .<label>ð29Þ</label></formula><p>Together with the optimal KF (28), we apply the suboptimal filter using the GMF (20), ( <ref type="formula" target="#formula_24">24</ref> </p><formula xml:id="formula_33">xð1Þ kjk ¼ xð1Þ kÀ1jkÀ1 þ K ð1Þ k y ð1Þ k À xð1Þ kÀ1jkÀ1 h i , xð1Þ 0j0 ¼ y, P<label>ð1Þ</label></formula><formula xml:id="formula_34">kjkÀ1 ¼ P<label>ð1Þ</label></formula><formula xml:id="formula_35">kÀ1jkÀ1 ; P ð1Þ 0j0 ¼ s 2 y , K<label>ð1Þ</label></formula><formula xml:id="formula_36">k ¼ P<label>ð1Þ</label></formula><formula xml:id="formula_37">kjkÀ1 r 1 þ P<label>ð1Þ</label></formula><formula xml:id="formula_38">kjkÀ1 ; P ð1Þ kjk ¼ 1 À K ð1Þ k h i P ð1Þ kjkÀ1<label>ð30Þ</label></formula><p>and</p><formula xml:id="formula_39">xð2Þ kjk ¼ xð2Þ kÀ1jkÀ1 þ K ð2Þ k y ð2Þ k À xð2Þ kÀ1jkÀ1 h i , xð2Þ 0j0 ¼ y, P<label>ð2Þ</label></formula><formula xml:id="formula_40">kjkÀ1 ¼ P<label>ð2Þ</label></formula><formula xml:id="formula_41">kÀ1jkÀ1 ; P ð2Þ 0j0 ¼ s 2 y , K<label>ð2Þ</label></formula><formula xml:id="formula_42">k ¼ P ð2Þ kjkÀ1 r 2 þ P<label>ð2Þ</label></formula><formula xml:id="formula_43">kjkÀ1 ; P ð2Þ kjk ¼ 1 À K ð2Þ k h i P ð2Þ kjkÀ1 .<label>ð31Þ</label></formula><p>The exact solution of the Eqs. ( <ref type="formula" target="#formula_38">30</ref>) and (31) take the form:</p><formula xml:id="formula_44">P ð1Þ kjk 9Eðy À xð1Þ kjk Þ 2 ¼ r 1 s 2 y r 1 þ ks 2 y , K<label>ð1Þ</label></formula><formula xml:id="formula_45">k ¼ s 2 y r 1 þ ks 2 y , P<label>ð2Þ</label></formula><formula xml:id="formula_46">kjk 9Eðy À xð2Þ kjk Þ 2 ¼ r 2 s 2 y r 2 þ ks 2 y , K<label>ð2Þ</label></formula><formula xml:id="formula_47">k ¼ s 2 y r 2 þ ks 2 y .<label>ð32Þ</label></formula><p>Next, using the scalar version of GMF (24) at N ¼ 2, and the formula <ref type="bibr" target="#b6">(7)</ref>, one can obtain the suboptimal estimate xGMF kjk of the unknown y as </p><formula xml:id="formula_48">xGMF kjk ¼ c ð1Þ k xð1Þ kjk þ c ð2Þ k xð2Þ kjk , c<label>ð1Þ</label></formula><p>where the error variances P ð1Þ kjk 9P ð11Þ kjk and P ð2Þ kjk 9 P ð22Þ kjk are determined by the formulae (32), and the cross-covariance P ð12Þ kjk , according to (26) is determined by the equation</p><formula xml:id="formula_50">P ð12Þ kjk ¼ 1 À K ð1Þ k h i 1 À K ð2Þ k h i P<label>ð12Þ</label></formula><formula xml:id="formula_51">kÀ1jkÀ1 , P<label>ð12Þ</label></formula><formula xml:id="formula_52">0j0 ¼ s 2 y .<label>ð34Þ</label></formula><p>Using (32), one can obtain the exact expressions for c ð1Þ k ; c ð2Þ k , and P ð12Þ kjk , respectively,</p><formula xml:id="formula_53">c ð1Þ k ¼ r 2 r 1 þ r 2 ; c ð2Þ k ¼ r 1 r 1 þ r 2 , P<label>ð12Þ</label></formula><formula xml:id="formula_54">kjk ¼ r 1 r 2 s 2 y ðr 1 þ ks 2 y Þðr 2 þ ks 2 y Þ .<label>ð35Þ</label></formula><p>At last, using (32) and ( <ref type="formula" target="#formula_54">35</ref>), one can has the error variance (6) of the suboptimal estimate xGMF kjk ,</p><formula xml:id="formula_55">P GMF kjk 9Eðy À xGMF kjk Þ 2 ¼ c<label>ð1Þ</label></formula><formula xml:id="formula_56">k h i 2 P ð1Þ kjk þ 2c ð1Þ k c ð2Þ k P ð12Þ kjk þ c<label>ð2Þ</label></formula><formula xml:id="formula_57">k h i 2 P ð2Þ kjk ¼ r 1 r 2 s 2 y ðr 1 þ r 2 Þ 2 r 2 r 1 þ ks 2 y þ 2r 1 r 2 ðr 1 þ ks 2 y Þðr 2 þ ks 2 y Þ þ r 1 r 2 þ ks 2 y ! .<label>ð36Þ</label></formula><p>Comparing the error variances ( <ref type="formula" target="#formula_32">29</ref>) and (36), we have</p><formula xml:id="formula_58">P GMF kjk À P KF kjk ¼ r 2 1 r 2 2 s 4 y ðr 1 þ r 2 Þ Â k ðr 1 þ ks 2 y Þðr 2 þ ks 2 y Þ½r 1 r 2 þ kðr 1 þ r 2 Þs 2 y<label>ð37Þ</label></formula><p>or</p><formula xml:id="formula_59">P GMF kjk À P KF kjk ¼ O 1 k 2 . (<label>38</label></formula><formula xml:id="formula_60">)</formula><p>The result show that the GMF yields suboptimal recursive filter with good accuracy and certain well-defined convergence properties. It can be used in multisensor environments to fuse local sensor's estimates to get more accurate estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Adaptive estimation in discrete-time linear systems</head><p>The purpose of this section is to present state estimation algorithm using the GMF that can ''adapt'' themselves to certain types of uncertainties considered as unknown parameters.</p><p>Consider the following discrete-time system with unknown parameters in measurement equation:</p><formula xml:id="formula_61">x kþ1 ¼ F k x k þ G k v k ; k ¼ 0; 1; . . . , y k ¼ H k ðyÞx k þ w k ; k ¼ 1; 2; . . . ,<label>ð39Þ</label></formula><p>where x k 2 R n is the state, y k 2 R m is the measurement, fv k g and fw k g are the zero-mean white Gaussian uncorrelated sequences, v k $Nð0; Q k Þ and w k $Nð0; R k ðyÞÞ. The initial state x 0 $Nðx 0 ; P 0 Þ is assumed to be uncorrelated with fv k g and fw k g. We assume that matrices H k ðyÞ and R k ðyÞ include the unknown parameter vector y 2 R p , which takes only a finite set of values y ¼ y 1 ; y 2 ; . . . ; y N .</p><p>This finite set might be the result of discretizing a continuous parameter space.</p><p>In adaptive filtering theory the state vector x k of this system can be estimated by using the Lainiotis-Kalman filter (LKF) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>:</p><formula xml:id="formula_63">xLKF kjk ¼ X N i¼1 pðy i jy k Þ xKF kjk ðy i Þ, P LKF kjk ¼ X N i¼1 pðy i jy k Þ P KF kjk ðy i Þ þ ð xKF kjk ðy i Þ À xLKF kjk Þ h Âð xKF kjk ðy i Þ À xLKF kjk Þ T i ,<label>ð41Þ</label></formula><p>where xKF kjk ðy i Þ and P KF kjk ðy i Þ are the state estimate and its covariance, respectively, given by the standard KF matched to the linear system (39) at fixed y i , and pðy i jy k Þ is a posteriori probability of y i given y k ¼ fy 1 ; . . . ; y k g, providing by Bayes's rule (see <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>). In addition, the LKF assumes that an a priori probability for y; pðyÞ, is available, i.e.,</p><formula xml:id="formula_64">pðyÞ ¼ pðy 1 Þ; . . . ; pðy N Þ; pðy 1 Þ þ Á Á Á þ pðy N Þ ¼ 1, pðy i ÞX0.<label>ð42Þ</label></formula><p>Here we show that the proposed GMF (3), ( <ref type="formula" target="#formula_4">5</ref>) may serve as an alternative to solve the adaptive filtering problem (39) without the additional assumption about a priori probability pðyÞ (42).</p><p>According to (39), we have N unconnected dynamic systems with known matrices</p><formula xml:id="formula_65">F k ; G k ; Q k ; H k ðy i Þ, and R k ðy i Þ, respectively: x kþ1 ¼ F k x k þ G k v k ; v k $Nð0; Q k Þ, y k ¼ H k ðy i Þx k þ w k ; w k $Nð0; R k ðy i ÞÞ,<label>ð43Þ</label></formula><p>where i is fixed and y i is the known value of the parameter y. Using the KF matched to (43) at fixed y i ði ¼ 1; . . . ; NÞ, we have N estimates</p><formula xml:id="formula_66">xð1Þ kjk 9 xkjk ðy 1 Þ; . . . ; xðNÞ kjk 9 xkjk ðy N Þ<label>(44)</label></formula><p>and associated error covariances</p><formula xml:id="formula_67">P ð1Þ kjk 9P kjk ðy 1 Þ; . . . ; P ðNÞ kjk 9P kjk ðy N Þ.<label>(45)</label></formula><p>Next, based on the GMF (24) and the notations (44), (45) the new adaptive filter can be determined by the following equations:</p><formula xml:id="formula_68">xGMF kjk ¼ X N i¼1 c ðiÞ k xkjk ðy i Þ; X N i¼1 c ðiÞ k ¼ I n ,<label>(46)</label></formula><p>where the weighting matrices c ð1Þ k ; . . . ; c ðNÞ k determined by the Eqs. ( <ref type="formula" target="#formula_25">25</ref>), (26).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Numerical example</head><p>Consider a scalar system described by</p><formula xml:id="formula_69">x kþ1 ¼ ax k þ v k , y k ¼ y i x k þ w k ; k ¼ 0; 1; . . . ; T,<label>ð47Þ</label></formula><p>where i ¼ 1; 2. This represents the model which takes two sensor modes with y 1 ¼ 1 and y 2 ¼ 0:1. The constants, the noise statistics and the initial state are subject to a ¼ 0:9, T ¼ 60, v k $Nð0; qÞ, q ¼ 0:1, w k $Nð0; rÞ, r ¼ 0:01 and x 0 $Nðx 0 ; P 0 Þ;</p><formula xml:id="formula_70">x 0 ¼ 1, P 0 ¼ 1.</formula><p>We describe here the results of simulations of two filters: the LKF (41) and the suboptimal adaptive filter (SAF) based on the GMF, which has proposed in Section 5.</p><p>The LKF for the model (47) takes the form <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>:</p><formula xml:id="formula_71">xLKF kjk ¼ cð1Þ k xkjk ðy 1 Þ þ cð2Þ k xkjk ðy 2 Þ, cðiÞ k ¼ pðy i jy k Þ; i ¼ 1; 2, pðy i jy k Þ ¼ L i ðy k Þ Á pðy i jy kÀ1 Þ P 2 s¼1 L s ðy k Þ Á pðy s jy kÀ1 Þ , pðy i jy 0 Þ ¼ pðy i Þ ¼ 0:5, L i ðy k Þ ¼ 1 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi P kjkÀ1 ðy i Þ p Â exp À ½y k À y i Á ða xkÀ1jkÀ1 ðy i ÞÞ 2 2P kjkÀ1 ðy i Þ &amp; ' , i ¼ 1; 2.<label>ð48Þ</label></formula><p>The SAF is of the form in Eq. ( <ref type="formula" target="#formula_7">7</ref>) Two cases were considered: in the first case, y 1 ¼ 1 is the true parameter value; for the second case, y 2 ¼ 0:1 is the true parameter value. The a prior probabilities were set to pðy 1 Þ ¼ pðy 2 Þ ¼ 0:5. All figures present the time histories of the filter characteristics for the first case. Such time histories is perfect analogy to the second case. The Monte-Carlo method for evaluating the a posteriori probabilities cðiÞ k ¼ pðy i jy k Þ, optimal xLKF kjk and suboptimal estimates xSAF kjk , and actual meansquare errors</p><formula xml:id="formula_72">xSAF kjk ¼ c ð1Þ k xkjk ðy 1 Þ þ c ð2Þ k xkjk ðy 2 Þ, c<label>ð1Þ</label></formula><formula xml:id="formula_73">P LKF k ¼ Eðx k À xLKF kjk Þ 2 ; P SAF k ¼ Eðx k À xSAF kjk Þ 2 was used.</formula><p>The number of samples was taken M ¼ 10 3 . In Fig. <ref type="figure">1</ref>, we show the a posteriori probabilities cðiÞ k ¼ pðy i jy k Þ and the corresponding weights c ðiÞ k . As we see the approximate weights c ðiÞ k offer a good alternative to the optimal weights cðiÞ k . The optimal xLKF kjk and the suboptimal estimates xSAF kjk are illustrated in Figs. 2. The mean-square errors for the LKF and the SAF are shown in Fig. <ref type="figure" target="#fig_1">3</ref>. According to Figs. <ref type="figure">2</ref> and<ref type="figure" target="#fig_1">3</ref>, it is possible to conclude that differences between the LKF and the SAF are negligible. This means that for our example the application of the SAF is a good one. Moreover, the simulation  results show that computation time for evaluation of xSAF kjk in 1.6 times is less than for xLKF kjk .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we have derived the GMF, which represents the optimal linear combination of arbitrary number correlated estimates. Each estimate is fused by the minimum mean-square error criterion. Using this formula, the equivalence of the LS estimator and the GMF is established. We have also derived the new suboptimal filtering and adaptive filtering algorithms for multisensor measurement systems. Theoretical and numerical results show good accuracy of the proposed suboptimal filters. These filters can be widely used in the different areas of applications: industrial, military, space, communication, target tracking, inertial navigation and others <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref> are mutually uncorrelated at iaj, the formula (B2) yields a linear recursive for P ðijÞ kjk . This completes the derivation of the Eq. ( <ref type="formula" target="#formula_27">26</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. The a posterior probabilities pðy i jy k Þ and weights C ðiÞ k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Mean-square errors using optimal filter P LKF k (solid line) and suboptimal filter P SAF k (dashed line).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>.</figDesc><table><row><cell>error xðiÞ kjk : xðiÞ kjk 9x k À xðiÞ kjk</cell><cell></cell><cell></cell><cell></cell><cell>Taking into account that the random vectors xðiÞ kÀ1jkÀ1 ; v kÀ1 ; w ðiÞ kÀ1 and w ðjÞ kÀ1</cell></row><row><cell cols="2">¼ F kÀ1 x kÀ1 þ G kÀ1 v kÀ1 À F kÀ1 Â y ðiÞ k À H ðiÞ k F kÀ1 kÀ1jkÀ1 xðiÞ h i</cell><cell cols="3">xðiÞ kÀ1jkÀ1 À K ðiÞ k</cell></row><row><cell cols="5">¼ F kÀ1 À K ðiÞ xðiÞ kÀ1jkÀ1 þ G kÀ1 v kÀ1 k H ðiÞ h k ðF kÀ1 x kÀ1 þ G kÀ1 v kÀ1 Þ þw ðiÞ k À H ðiÞ k F kÀ1 i xðiÞ kÀ1jkÀ1 ¼ I n À K ðiÞ k H ðiÞ k h i F kÀ1 xðiÞ kÀ1jkÀ1 þ I n À K ðiÞ k H ðiÞ k h i G kÀ1 v kÀ1 À K ðiÞ k w ðiÞ k .</cell><cell>ðB1Þ</cell></row><row><cell>Consequently, P ðijÞ kjk 9E xðiÞ h kjk x ðjÞ kjk ¼ E I n À K ðiÞ i k H ðiÞ k h þ I n À K ðiÞ k H ðiÞ k Â I n À K ðjÞ k H ðjÞ k h</cell><cell cols="2">F kÀ1 G kÀ1 v kÀ1 À K ðiÞ xðiÞ kÀ1jkÀ1 k w ðiÞ k F kÀ1 kÀ1jkÀ1 xðjÞ</cell><cell cols="2">i</cell></row><row><cell>þ I n À K ðjÞ k H ðjÞ k</cell><cell cols="3">G kÀ1 v kÀ1 À K ðjÞ k w ðjÞ k</cell><cell>i T</cell><cell>.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>ðB2Þ</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Vladimir Shin et al. / Signal Processing 86 (2006) 257-266</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A. Derivation of Eqs. <ref type="bibr" target="#b4">(5)</ref> In this Appendix, we give a brief derivation of the Eqs. <ref type="bibr" target="#b4">(5)</ref>. We seek the optimal weighting matrices c 1 ; . . . ; c N minimizing the mean-square error, i.e.,</p><p>Using ( <ref type="formula">6</ref>), (A1) can be rewritten as follows:</p><p>Next, use the formulae</p><p>Let us differentiate each summand of the function (A3) with respect to c 1 ; . . . ; c NÀ1 using (A4) and (A5), and then set the result to zero, i.e.,</p><p>we have the linear algebraic equations <ref type="bibr" target="#b4">(5)</ref> for the unknown weighting matrices c 1 ; . . . ; c N . This completes the derivation of the Eqs. ( <ref type="formula">5</ref>). First, we note that the KF equations ( <ref type="formula">19</ref>) and (20) yield the linear equation for the filtering</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The effect of the common process noise on the two-sensor fused-track covariance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bar-Shalom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Campo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerospace Electronic Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="803" to="805" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Applied Optimal Estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Optimal Estimation with an Introduction to Stochastic Control Theory</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Bar-Shalom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kirubarajan</surname></persName>
		</author>
		<title level="m">Estimation with Applications to Tracking and Navigation</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multisensor Integration and Fusion in Intelligent Systems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Kay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Man Cybernet</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="901" to="931" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Partitioned linear estimation algorithm: discrete case</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lainiotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Control</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="255" to="257" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Watanabe</surname></persName>
		</author>
		<title level="m">Adaptive Estimation and Control: Partitioning Approach</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
