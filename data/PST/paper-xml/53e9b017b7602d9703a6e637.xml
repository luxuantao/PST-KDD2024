<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning of Representations for Unsupervised and Transfer Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
							<email>yoshua.bengio@umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Université de Montréal. Montréal (QC)</orgName>
								<address>
									<postCode>H2C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Université de Montréal. Montréal (QC)</orgName>
								<address>
									<postCode>H2C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><surname>Dror</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Université de Montréal. Montréal (QC)</orgName>
								<address>
									<postCode>H2C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">V</forename><surname>Lemaire</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Université de Montréal. Montréal (QC)</orgName>
								<address>
									<postCode>H2C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><surname>Taylor</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Université de Montréal. Montréal (QC)</orgName>
								<address>
									<postCode>H2C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Silver</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. IRO</orgName>
								<orgName type="institution">Université de Montréal. Montréal (QC)</orgName>
								<address>
									<postCode>H2C 3J7</postCode>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Learning of Representations for Unsupervised and Transfer Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Learning</term>
					<term>unsupervised learning</term>
					<term>representation learning</term>
					<term>transfer learning</term>
					<term>multi-task learning</term>
					<term>self-taught learning</term>
					<term>domain adaptation</term>
					<term>neural networks</term>
					<term>Restricted Boltzmann Machines</term>
					<term>Auto-encoders</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning algorithms seek to exploit the unknown structure in the input distribution in order to discover good representations, often at multiple levels, with higher-level learned features defined in terms of lower-level features. The objective is to make these higherlevel representations more abstract, with their individual features more invariant to most of the variations that are typically present in the training distribution, while collectively preserving as much as possible of the information in the input. Ideally, we would like these representations to disentangle the unknown factors of variation that underlie the training distribution. Such unsupervised learning of representations can be exploited usefully under the hypothesis that the input distribution P (x) is structurally related to some task of interest, say predicting P (y|x). This paper focuses on the context of the Unsupervised and Transfer Learning Challenge, on why unsupervised pre-training of representations can be useful, and how it can be exploited in the transfer learning scenario, where we care about predictions on examples that are not from the same distribution as the training distribution.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Machine learning algorithms attempt to discover structure in data. In their simpler forms, that often means discovering a predictive relationship between variables. More generally, that means discovering where probability mass concentrates in the joint distribution of all the observations. Many researchers have found that the way in which data are represented can make a huge difference in the success of a learning algorithm.</p><p>Whereas many practitioners have relied solely on hand-crafting representations, thus exploiting human insights into the problem, there is also a long tradition of learning algorithms that attempt to discover good representations. Representation learning is the general context where this paper is situated. What can a good representation buy us? What is a good representation? What training principles might be used to discover good representations? Supervised machine learning tasks can be abstracted in terms of (X, Y ) pairs, where X is an input random variable and Y is a label that we wish to predict given X. This paper considers the use of representation learning in the case where labels for the task of interest are not available at the time of learning the representation. One wishes to learn the representation either in a purely unsupervised way, or using labels for other tasks. This c 2012 Y. Bengio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bengio</head><p>type of setup has been called self-taught learning <ref type="bibr" target="#b41">(Raina et al., 2007)</ref> but also falls in the areas of transfer learning, domain adaptation, and multi-task learning (where typically one also has labels for the task of interest) and is related to semi-supervised learning (where one has many unlabeled examples and a few labeled ones).</p><p>In order to address this challenge (and the Unsupervised and Transfer Learning Challenge<ref type="foot" target="#foot_0">1</ref> ), the algorithms described here exploit Deep Learning, i.e., learning multiple levels of representation. The intent is to discover more abstract features in the higher levels of the representation, which hopefully make it easier to separate from each other the various explanatory factors extent in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">The Context of The Unsupervised and Transfer Learning Challenge</head><p>The challenge was organized according to the following learning setup. The test <ref type="bibr">(and validation)</ref> sets have examples from classes not well represented in the training set. They have only a small number of unlabeled examples (4096) and very few labeled examples (1 to 64 per class) available to a Hebbian linear classifier (which discriminates according to the median between the centroids of two classes compared) applied separately to each class against the others. In the second phase of the competition, some labeled examples (from classes other than those in the test or validation sets) are available for the training set. Participants can use the training set (with some irrelevant labels, in the second phase) to construct a representation for test set examples. Typically this is achieved by learning a transformation of the raw input vectors into a new space, which hopefully captures the most important factors of variation present in the unknown generating distribution. That transformation can then be applied to test examples. The challenge server then trains the Hebbian linear classifier on top of that representation, on a small random subset of the test set, and evaluates generalization on the rest of the test set (many random subsets are computed to get an average score). The main difficulties are the following:</p><p>1. The input distribution is very different in the test (or validation) set, compared to the training set (for example, the set of classes to be discriminated in the test set may be absent or rare in the training set), making it unclear if anything can be transferred from the training to the test set.</p><p>2. Very few labels are available to the linear classifier on the test set, meaning that generalization of the classifier is inherently difficult and sensitive to the particulars of the representation chosen. This puts great pressure on the representation learning algorithm applied on the training set (unlabeled, in the experiments we performed) to discover really generic features likely to be of interest for many classification tasks on such data. Our intuition is that more abstract Deep Learning of Representations features are more likely to fit that stringent requirement, which motivates the use of Deep Learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Representations as Coordinate Systems</head><p>Representation learning is also intimately related to the research in manifold learning <ref type="bibr" target="#b23">(Hinton et al., 1997;</ref><ref type="bibr" target="#b51">Tenenbaum et al., 2000;</ref><ref type="bibr" target="#b49">Saul and Roweis, 2002;</ref><ref type="bibr" target="#b0">Belkin and Niyogi, 2003)</ref>. The objective of manifold learning algorithms is two-fold: identify low-dimensional regions of high-density (called manifold), and construct a coordinate system on these manifolds, i.e., a low-dimensional representation for input examples. Principal Components Analysis (PCA) is the linear ancestor of manifold learning algorithms: it provides a projection of each input vector to a low-dimensional coordinate vector, implicitly defining a low-dimensional hyperplane in input space near which density is hopefully concentrating. The extent of this mass concentration can be measured by the proportion of variance explained by principal eigenvectors of the data covariance matrix. Changes in the directions of the principal components are perfectly captured by the PCA, whereas changes in the orthogonal directions are completely lost. The proportion of the variance in the data captured by the PCA is a good measure of the effectiveness of a PCA dimensionality reduction (for a given choice of number of dimensions). The assumption is that directions where there is very little change in the data do not matter and can be considered noise, but this is not always true, especially when one wrongly assumes that the manifold is linear (e.g., with PCA). Non-linear manifold learning algorithms avoid the linear assumption but retain the notion of a drastic dimensionality reduction.</p><p>As we argue more at the end of this paper, although cutting the low-variance directions out (i.e., considering those directions as noise) is often very effective, it is not always clear what is signal and what is noise: although the extent of variability is a good hint, it is not perfect. As an example, consider images of faces, and two factors: person identity and pose. Most of the variation in pixel space can be explained by pose (especially the 2-D translation, scaling, and rotation), and two persons of the same sex, age, and hair type will be distinguishable only by looking at low variance components. That is why one often starts by preprocessing such images to align them as much as possible or focus only on images of faces in the same pose, e.g. frontal view.</p><p>It is a good thing to test, for one's data, if one can get better classification by simply removing the low-variance components, and in that case one should definitely do it<ref type="foot" target="#foot_1">2</ref> . However, we believe that a more encompassing and more conservative but more ambitious approach is to use a learning algorithm that separates the explanatory factors from each other as much as possible, and let a discriminant classifier pick out those that are relevant to a particular task.</p><p>In this context, overcomplete<ref type="foot" target="#foot_2">3</ref> sparse<ref type="foot" target="#foot_3">4</ref> representations have often <ref type="bibr" target="#b45">(Ranzato et al., 2007b</ref><ref type="bibr" target="#b46">(Ranzato et al., , 2008;;</ref><ref type="bibr" target="#b20">Goodfellow et al., 2009)</ref> been found to work better than dense undercomplete representations (such as produced by PCA). Consider a sparse overcomplete representation in the neighborhood of an input example x. Most local changes around x involve a continuous Bengio change of the "active" (non-zero) elements of the representation. Hence the set of active elements of the representation defines a local chart, a local coordinate system. Those charts are stitched together through the zero/non-zero transitions that occur when crossing some boundaries in input space. <ref type="bibr" target="#b20">Goodfellow et al. (2009)</ref> have found that sparse auto-encoders gave rise to more invariant representations (compared to non-sparse ones), in the sense that a subset of the representation elements (also called features) were more insensitive to input transformations such as translation or rotation of the camera. One advantage of such as an overcomplete representation is that it is not "cramped" in a small-dimensional space. The effective dimensionality (number of non-zeros) can vary depending on where we look. It is very plausible that in some regions of space it may be more appropriate to have more dimensions than in others.</p><p>Let h(x) denote the mapping from an input x to its representation h(x). Overcomplete representations which are not necessarily sparse but where h is non-linear are characterized at a particular input point x by a "soft" dimensionality and a "soft" subset of the representation coordinates that are active. The degree to which h i (x) is active basically depends on</p><formula xml:id="formula_0">∂h i (x) ∂x . When ∂h i (x)</formula><p>∂x is close to zero, coordinate i is inactive and unresponsive to changes in x, while the active coordinates encode (i.e., respond to) local changes around x. This is what happens with the Contracting Auto-encoder described a bit more in section 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Depth</head><p>Depth is a notion borrowed from complexity theory, and that is defined for circuits. A circuit is a directed acyclic graph where each node is associated with a computation. The results of the computation of a node are used as input by the successors of that node in the graph. In the circuit, input nodes have no predecessor and output nodes have no successor. The depth of a circuit is the longest path from an input to an output node. A long-standing question in complexity theory is the extent to which depth-limited circuits can efficiently represent functions that can otherwise be efficiently represented. A depth-2 circuit (with appropriate choice of computational elements, e.g. logic gates or formal neurons) can compute or approximate any function, but it may require an exponentially large number of nodes. This is a relevant question for machine learning, because many learning algorithms learn "shallow architectures" <ref type="bibr" target="#b4">(Bengio and LeCun, 2007)</ref>, typically of depth 1 (linear predictors) or 2 (most non-parametric predictors). If AI-tasks require deeper circuits (and human brains certainly appear deep), then we should find ways to incorporate depth into our learning algorithms. The consequences of using a too shallow predictor would be that it may not generalize well, unless given huge numbers of examples and capacity (i.e., computational resources and statistical resources).</p><p>The early results on the limitations of shallow circuits regard functions such as the parity function <ref type="bibr" target="#b55">(Yao, 1985)</ref>, showing that logic gates circuits of depth-2 require exponential size to implement d-bit parity where a deep circuit of depth O(log(d)) could implement it with O(d) nodes. <ref type="bibr" target="#b21">Håstad (1986)</ref> then showed that there are functions computable with a polynomial-size logic gate circuit of depth k that require exponential size when restricted to depth k − 1 <ref type="bibr" target="#b21">(Håstad, 1986)</ref>. Interestingly, a similar result was proven for the case of circuits made of linear threshold units (formal neurons) <ref type="bibr" target="#b22">(Håstad and Goldmann, 1991)</ref>, when trying to represent a particular family of functions. A more recent result brings an example of a very large class of functions that cannot be efficiently represented with a small-depth circuit <ref type="bibr" target="#b11">(Braverman, 2011)</ref>. It is particularly striking that the main theorem regards the representation of functions that capture dependencies in joint distributions. Basically, dependencies that involve more than r variables are difficult to capture by shallow circuits. An r-independent distribution is one that cannot be distinguished from the uniform distribution when looking only at r variables at a time. The proof of the main theorem (which concerns distribution over bit vectors) relies on the fact that order-r polynomials over the reals cannot capture r-independent distributions. The main result is that boundeddepth circuits cannot distinguish data from r-independent distributions from independent noisy bits. We have also recently shown <ref type="bibr" target="#b17">(Delalleau and Bengio, 2011)</ref> results for sum-product networks (where nodes either compute sums or products, over the reals). We found two families of polynomials that can be efficiently represented with deep circuits, but require exponential size with depth-2 circuits. Interestingly, sum-product networks were recently proposed to efficiently represent high-dimensional joint distributions <ref type="bibr" target="#b40">(Poon and Domingos, 2010)</ref>.</p><p>Besides the complexity-theory hints at their representational advantages, there are other motivations for studying learning algorithms which build a deep architecture. The earliest one is simply inspiration from brains. By putting together anatomical knowledge and measures of the time taken for signals to travel from the retina to the frontal cortex and then to motor neurons (about 100 to 200 ms), one can gather that at least 5 to 10 feedforward levels are involved for some of the simplest visual object recognition tasks. Slightly more complex vision tasks require iteration and feedback top-down signals, multiplying the overall depth by an extra factor of 2 to 4 (to about half a second).</p><p>Another motivation derives from what we know of cognition and abstractions: as argued in <ref type="bibr" target="#b1">Bengio (2009)</ref>, it is natural for humans to represent concepts at one level of abstraction as the composition of concepts at lower levels. Engineers often craft representations at multiple levels, with higher levels obtained by transformation of lower levels. Instead of a flat main program, software engineers structure their code to obtain plenty of re-use, with functions and modules re-using other functions and modules. This inspiration is directly linked to machine learning: deep architectures appear well suited to represent higher-level abstractions because they lend themselves to re-use and composition. For example, the low-level features of a deep network are composed to form higher-level features. And some of the features that are useful for one task may be useful for another, making Deep Learning particularly well suited for transfer learning and multi-task learning <ref type="bibr" target="#b13">(Caruana, 1995;</ref><ref type="bibr" target="#b14">Collobert and Weston, 2008)</ref>. Here one is exploiting the existence of underlying common explanatory factors that are useful for several tasks. This is also true of semi-supervised learning, which exploits connections between the input distribution P (X) and a target conditional distribution P (Y |X). In general these two distributions, seen as functions of x, may be unrelated to each other. But in the world around us, it is often the case that some of the factors that shape the distribution of input variables X are also predictive of the output variables Y . Deep Learning relies heavily on unsupervised or semi-supervised learning, and assumes that representations of X that are useful to capture P (X) are also in part useful to capture P (Y |X).</p><p>In the context of the Unsupervised and Transfer Learning Challenge, the assumption exploited by Deep Learning algorithms goes even further, and is related to the Self-Taught Learning setup <ref type="bibr" target="#b41">(Raina et al., 2007)</ref>. In the unsupervised representation-learning phase, one may have access to examples of only some of the classes, and the representation learned should be useful for other classes. One therefore assumes that some of the factors that explain P (X|Y ) for Y in the training classes, and that will be captured by the learned representation, will be useful to predict different classes, from the test set. In phase 1 of the competition, only X's from the training classes are observed, while in phase 2 some corresponding labels are observed as well, but no labeled examples from the test set are ever revealed. In our team (LISA), we only used the phase 2 training set labels to help perform model selection, since selecting and fine-tuning features based on their discriminatory ability on training classes greatly increased the risk of removing important information for test classes. See <ref type="bibr" target="#b35">Mesnil et al. (2011)</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Greedy Layer-Wise Learning of Representations</head><p>The following basic recipe was introduced in 2006 <ref type="bibr" target="#b26">(Hinton and Salakhutdinov, 2006;</ref><ref type="bibr">Hinton et al., 2006;</ref><ref type="bibr" target="#b42">Ranzato et al., 2007a;</ref><ref type="bibr">Bengio et al., 2007)</ref>:</p><p>1. Let h 0 (x) = x be the lowest-level representation of the data, given by the observed raw input x. From this point on, several variants have been explored in the literature. For supervised learning with fine-tuning, which is the most common variant <ref type="bibr">(Hinton et al., 2006;</ref><ref type="bibr" target="#b45">Ranzato et al., 2007b;</ref><ref type="bibr">Bengio et al., 2007)</ref>:</p><p>3. Initialize a supervised predictor whose first stage is the parametrized representation function h L (x), followed by a linear or non-linear predictor as the second stage (i.e., taking h L (x) as input).</p><p>4. Fine-tune the supervised predictor with respect to a supervised training criterion, based on a labeled training set of (x, y) pairs, and optimizing the parameters in both the representation stage and the predictor stage.</p><p>A supervised variant involves using all the levels of representation as input to the predictor, keeping the representation stage fixed, and optimizing only the predictor parameters <ref type="bibr">(Lee et al., 2009a,b)</ref>:</p><p>3. Train a supervised learner taking as input (h k (x), h k+1 (x), . . . , h L (x)) for some choice of 0 ≤ k ≤ L, using a labeled training set of (x, y) pairs.</p><p>A special case of the above is to have k = L, i.e., we keep only the top level as input to the classifier without supervised fine-tuning of the representation. Since labels for the test classes are not available (for fine-tuning) in the Unsupervised and Transfer Learning Challenge, the latter approach makes more sense, but in other settings (especially when the number of labeled examples is large) we have often found fine-tuning to be helpful <ref type="bibr" target="#b28">(Lamblin and Bengio, 2010)</ref>. Finally, there is a common unsupervised variant, e.g. for training deep auto-encoders (Hinton and <ref type="bibr" target="#b26">Salakhutdinov, 2006)</ref>  As detailed in <ref type="bibr" target="#b35">Mesnil et al. (2011)</ref>, it turned out for the challenge to always work better to have a low-dimensional h L (i.e. the input to the classifier), e.g., a handful of dimensions. This top-level representation was typically obtained by choosing PCA as the last stage of the hierarchy. In experiments with other kinds of data, with many more labeled examples, we had obtained better results with high-dimensional top-level representations (thousands of dimensions). We found higher dimensional top-level representations to be most hurtful for the cases where there are very few labeled examples. Note that the challenge criterion is an average over 1, 2, 4, 8, 16, 32 and 64 labeled examples per class. Because the cases with very few labeled examples were those on which there was most room for improvement (compared to other competitors), it makes sense that the low-dimensional solutions were the most successful.</p><p>Another remark is important here. On data sets with a larger labeled training set, we found that the supervised fine-tuning variant (where all the levels are finally tuned with respect to the supervised training criterion) can perform substantially better than without supervised fine-tuning <ref type="bibr" target="#b28">(Lamblin and Bengio, 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Transductive Specialization to Transfer Learning and Domain Adaptation</head><p>On the other hand, in the context of the challenge, there were no training labels for the task of interest, i.e., the classes of the test set, so it would not even have been possible to perform meaningful supervised fine-tuning. Worse than that in fact, the input distribution as well was very different between the training set and the test set. The large majority of examples from the training set were from classes other than those in the test set. This is a particularly extreme transfer learning or domain adaptation setup.</p><p>How could one hope to generalize in this context? If the training set input distribution had nothing to do with the test set input distribution, then even unsupervised representation-learning on the training set might not be helpful as a learned preprocessing for the test set. The only hope is that a representation-learning algorithm would discover features that capture the generic factors of variation present in all the classes, and that the classifier trained on the test set would then just need to pick up those factors relevant to the discrimination among test set classes. Unfortunately, because of the very small number of labeled examples available to the test set classifier, we found that we could not obtain good results (on the validation set) with high-dimensional representations. This implied that some selection of the relevant features had to be performed even before seeing any Bengio label from the test set. We believe that we achieved some of that by using a transductive strategy. The top levels(s) of the unsupervised feature-learning hierarchy were trained purely or mostly on the test set examples. Since the training set was much larger, we used it to extract a large set of general-purpose features that covered the variations across many classes. The unlabeled test set was then used transductively to select among the non-linear factors extracted from the training set those few factors varying most in the test set. Typically this was simply achieved by a simple PCA applied at the last level, trained only on test examples, and with very few leading eigenvectors selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A Zoo of Possible Layer-Wise Unsupervised Learning Algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">PCA, ICA, Normalization</head><p>Existing linear models such as PCA or ICA can be useful as one or more of the levels of a deep hierarchy. In fact, on several of the challenge data sets, we found that using a PCA as the first and the last level often worked very well. PCA preserves the global linear directions of maximum variance, and separates them into orthogonal components. The representation learned is the projection on the principal eigenvectors of the input covariance matrix. This corresponds to a coordinate system associated with a linear manifold spanned by these eigenvectors (centered at the center of mass of the data). For the first PCA layer, we typically kept a fairly large number of directions, so the main effect of that step is to smooth the input distribution by eliminating some of the variations involved in the least globally varying directions. Optionally, the PCA transformation can include a whitening step which means that the projections are normalized to variance 1 (by dividing each projection by the square root of the corresponding eigenvalue, i.e., component variance).</p><p>Whereas PCA can already perform a kind of normalization across examples (by subtracting the mean over examples and dividing by the standard deviation over examples, in the chosen directions), there is a complementary form of normalization which we have found useful. It is a simple variant of the contrast normalization commonly employed as an intermediate step in deep convolutional neural networks <ref type="bibr" target="#b29">(LeCun et al., 1989</ref><ref type="bibr" target="#b30">(LeCun et al., , 1998a))</ref>. The idea is to normalize across the elements of each input vector, by subtracting the mean and dividing by the standard deviation across elements of the input vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Auto-encoders</head><p>An auto-encoder defines a reconstruction r(x) = g(h(x)) of the input x from the composition of an encoder h(•) and a decoder g(•). In general both are parametrized and the most common parametrization corresponds to r(x) being the output of a one-hidden layer neural network (taking x as input) and h(x) being the non-linear output of the hidden layer. Training proceeds by minimizing the average of reconstruction errors, L(r(x), x). If the encoder and decoder are linear and L(r(x), x) = ||r(x) − x|| 2 is the square error, then h(x) learns to span the principal eigenvectors of the input, i.e., being equivalent (up to a rotation) to a PCA <ref type="bibr" target="#b10">(Bourlard and Kamp, 1988)</ref>. However, with a non-linear encoder, one obtains a representation that can be greedily stacked and often yields better representations with deeper encoders <ref type="bibr">(Bengio et al., 2007;</ref><ref type="bibr" target="#b20">Goodfellow et al., 2009)</ref>. A probabilistic interpretation of reconstruction error is simply as a particular form of energy function <ref type="bibr" target="#b46">(Ranzato et al., 2008)</ref> (the logarithm of an unnormalized probability density function). It means that examples with low reconstruction error have higher probability according to the model. A sparsity term in the energy function has been used to allow overcomplete representations <ref type="bibr" target="#b45">(Ranzato et al., 2007b</ref><ref type="bibr" target="#b46">(Ranzato et al., , 2008) )</ref> and shown to yield features that are (for some of them) more invariant to geometric transformations of images <ref type="bibr" target="#b20">(Goodfellow et al., 2009)</ref>. A successful alternative <ref type="bibr">(Bengio et al., 2007;</ref><ref type="bibr" target="#b54">Vincent et al., 2008)</ref> to the square reconstruction error in the case of inputs that are binary or in the (0,1) interval (like pixel intensities) is the sum of KL divergences between the binomial probability distributions associated with each input x i and with each reconstruction r i (x) (both seen as probabilities for a binary event).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">RBMs</head><p>As shown in <ref type="bibr" target="#b3">Bengio and Delalleau (2009)</ref>, the reconstruction error gradient for autoencoders can be seen as an approximation of the Contrastive Divergence <ref type="bibr" target="#b24">(Hinton, 1999</ref><ref type="bibr" target="#b25">(Hinton, , 2002) )</ref> update rule for Restricted Boltzmann Machines <ref type="bibr">(Hinton et al., 2006)</ref>. Boltzmann Machines are undirected graphical models, defined by an energy function which is related to the joint probability of inputs (visible) x and hidden (latent) variables h through P (x, h) = e −energy(x,h) /Z where the normalization constant Z is called the partition function, and the marginal probability of the observed data (which is what we want to maximize) is simply P (x) = h P (x, h) (summing or integrating over all possible configurations of h). A Boltzmann Machine is the equivalent for binary random variables of the multivariate Gaussian distribution for continuous random variables, in the sense that it is defined by an energy function that is a second-order polynomial in the random bit values. Both are particular kinds of Markov Random Fields (undirected graphical models), but the partition function of the Boltzmann Machine is intractable, which means that approximations of the log-likelihood gradient ∂ log P (x) ∂θ must be employed to train it (where θ is the set of parameters). Restricted Boltzmann Machines (RBMs) are Boltzmann Machines with a restriction in the connection pattern of the graphical model between variables, forming a bipartite graph with two groups of variables: the input (or visible) and latent (or hidden) variables. Whereas the original RBM employs binomial hidden and visible units, which worked well on data such as MNIST (where grey levels actually correspond to probabilities of turning on a pixel), the original extension of RBMs to continuous data (the Gaussian RBM) has not been as successful as more recent continuous-data RBMs such as the mcRBM <ref type="bibr">(Ranzato and Hinton, 2010)</ref>, the mPoT model <ref type="bibr">(Ranzato et al., 2010)</ref> and the spike-and-slab RBM <ref type="bibr" target="#b15">(Courville et al., 2011)</ref>, which was used in the challenge. The spike-and-slab RBM energy function allows hidden units to either push variance up or down in different directions, and it can be efficiently trained thanks to a 3-way block Gibbs sampling procedure.</p><p>RBMs are defined by their energy function, and when it is tractable (which is usually the case), their free energy function is:</p><formula xml:id="formula_1">FreeEnergy(x) = − log h e −energy(x,h) .</formula><p>The log-likelihood gradient can be defined in terms of the gradient of the free energy on observed (so-called positive) data samples x and on (so-called negative) model samples </p><formula xml:id="formula_2">− ∂ log P (x) ∂θ = ∂FreeEnergy(x) ∂θ − E[ ∂FreeEnergy(x) ∂θ ]</formula><p>where the expectation is over x ∼ P (x). When the free energy is tractable, the first term can be computed readily, whereas the second term involves sampling from the model. Various kinds of RBMs can be trained by approximate maximum likelihood stochastic gradient descent, often involving a Monte-Carlo Markov Chain to obtain those model samples. See <ref type="bibr" target="#b1">Bengio (2009)</ref> for a much more complete tutorial on this subject, along with <ref type="bibr">Hinton (2010)</ref> for tips and tricks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Denoising Auto-encoders</head><p>Denoising auto-encoders training is a simple variation on auto-encoder training: try to reconstruct the clean original input from an artificially and stochastically corrupted version of it, by minimizing the denoising reconstruction error. Denoising auto-encoders are simply trained by stochastic gradient descent, typically using mini-batches (of 20 to 200 examples) in order to take advantage of faster matrix-matrix operations on CPUs or GPUs. Denoising auto-encoders solve one of the thorny limitations of ordinary auto-encoders: the representation can be overcomplete without causing any problem of learning a trivial identity function. More hidden units just means that the model can more finely represent the input distribution. Denoising auto-encoders have recently been shown to be directly related to score matching <ref type="bibr" target="#b53">(Vincent, 2011)</ref>, an induction principle that can replace maximum likelihood when it is not tractable (and the inputs are continuous-valued). The score matching criterion is the squared norm of the difference between the model's score (gradient ∂ log P (x) ∂x of the log-likelihood with respect to the input x) and the score of the true data generating density (which is unknown, but from which we have samples). A simple way to understand the connection between denoising auto-encoders and score matching is the following.</p><p>Considering that reconstruction error is an energy function, the reconstruction from an auto-encoder normally goes from a lower-probability (higher energy) input configuration to a nearby higher-probability (lower energy) one, so the difference r(x) − x between reconstruction and input is the model's view of a direction of maximum increase in probability (i.e., the model's score). On the other hand, when one takes a training sample x and one randomly corrupts it into x, one typically obtains a lower probability neighbor, i.e., the vector x − x is nature's hint about a direction of rapid increase in probability (when starting at x). The squared difference of these two differences is just the denoising reconstruction error (r(x) − x) 2 , in the case of the squared error reconstruction loss.</p><p>In the challenge, we used <ref type="bibr" target="#b35">(Mesnil et al., 2011)</ref> particular denoising auto-encoders that are well suited for data with sparse high-dimensional inputs. Instead of the usual sigmoid or tanh non-linear hidden unit activations, these auto-encoders are based on rectifier units (max(x, 0) instead of tanh) with L1 penalty in the training criterion, which tends to make the hidden representation sparse. Stochastic rectifier units had been introduced in the context of RBMs earlier <ref type="bibr" target="#b37">(Nair and Hinton, 2010)</ref> and we have found them to be extremely useful for deterministic deep networks <ref type="bibr" target="#b18">(Glorot et al., 2011a)</ref> and denoising auto-encoders <ref type="bibr" target="#b19">(Glorot et al., 2011b)</ref>. A recent extension of denoising auto-encoders is particularly useful for two of the challenge data sets in which the input vectors are very large and sparse. It addresses a particularly troubling issue when training auto-encoders on large sparse vectors: whereas the encoder can take advantage of the numerous zeros in the input vector (it does not need to do any computation for them), the decoder needs to make reconstruction predictions and compute reconstruction error for all the inputs, including the zeros. With the sampled reconstruction algorithm <ref type="bibr" target="#b16">(Dauphin et al., 2011)</ref>, one only needs to compute reconstructions and reconstruction error for a small stochastically selected subset of the zeros, yielding very substantial speed-ups (20-fold in the experiments of <ref type="bibr" target="#b16">Dauphin et al. (2011)</ref>), the more so as the fraction of non-zeros decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Contractive Auto-encoders</head><p>Contractive auto-encoders <ref type="bibr" target="#b47">(Rifai et al., 2011)</ref> minimize a training criterion that is the sum of a reconstruction error and a "contraction penalty", which encourages the learnt representation h(x) to be as invariant as possible to the input x, while still allowing to distinguish the training examples from each other (i.e., to reconstruct them). As a consequence, the representation is faithful to changes in input space in the directions of the manifold near which examples concentrate, but it is highly contractive in the orthogonal directions. This is similar in spirit to a PCA (which only keeps the leading directions of variation and completely ignores the others), but is softer (no hard cutting at a particular dimension), is non-linear and can contract in different directions depending on where one looks in the input space (hence can capture non-linear manifolds). To prevent a trivial solution in which the encoder weights go to zero and the decoder weights to infinity, the contractive auto-encoder uses tied weights (the decoder weights are forced to be the transpose of the encoder weights). Because of the contractive criterion, what we find empirically is that for any particular input example, many of the hidden units saturate while a few remain sensitive to changes in the input (corresponding to changes in the directions of changes expected under the data distribution). That subset of active units changes as we move around in input space, and defines a kind of local chart, or local coordinate system, in the neighborhood of each input point. This can be visualized to some extent by looking at the singular values and singular vectors of the Jacobian matrix ∂h(x)  ∂x (containing the derivatives of each hidden unit output with respect to each input unit). Contrary to other auto-encoders, one tends to find only few dominant eigenvalues, and their number corresponds to a local rank or local dimension (which can change as we move in input space). This is unlike other dimensionality reduction algorithms in which the number of dimensions is fixed by hand (rather than learnt) and fixed across the input domain. In fact the learnt representation can be overcomplete (larger than the input): it is only in the sense of its Jacobian that it has an effective small dimensionality for any particular input point. The large number of hidden units can be exploited to model complicated non-linear manifolds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Tricks and Tips</head><p>A good starting point for tricks and tips relevant to training deep architectures, and in particular Restricted Boltzmann Machines (RBMs), is <ref type="bibr">Hinton (2010)</ref>. An older guide which is also useful to some extent is <ref type="bibr" target="#b38">Orr and Muller (1998)</ref>, and in particular <ref type="bibr" target="#b31">LeCun et al. (1998b)</ref>, since many of the ideas from neural networks training can be exploited here. A more recent guide for training the kinds of neural networks described here can be found in <ref type="bibr" target="#b2">Bengio (2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Monitoring Performance During Training</head><p>RBMs are tricky because although there are good estimators of the log-likelihood gradient, there are no known cheap ways of estimating the log-likelihood itself (Annealed Importance Sampling <ref type="bibr" target="#b36">(Murray and Salakhutdinov, 2009</ref>) is an expensive way of doing it). A poor man's option is to measure reconstruction error (as if the parameters were those of an auto-encoder), which works well for the beginning of training but does not help to choose a stopping point (e.g. to avoid overfitting). The practical solution is to save the model weights at different numbers of epochs (e.g., 5, 10, 20, 50) and plug the learned representation into a supervised classifier (for each of these training durations) in order to decide what training duration to select.</p><p>In the case of denoising auto-encoders, on the other hand, the denoising reconstruction error is a good measure of the model's progress (since it corresponds to the training criterion) and it can be used for early stopping. However, the best generative model or the one with the best denoising is not always the one that works best in terms of providing a good representation for a classifier. This is especially true in the transfer setting of the competition, where the training distribution is different from the test and validation distributions. In that case, the expensive solution of evaluating validation classification error at different training durations is the approach we have chosen. The training criterion of contractive auto-encoders can also be used as a good monitoring device (and its value on a validation set used to perform early stopping). Note that we did not really "stop" training, we only recorded representations at different points in the training trajectory and estimated Area under the Learning Curve (ALC<ref type="foot" target="#foot_4">5</ref> ) or other criteria associated with each. The advantage is that we do not need to retrain a separate model from scratch for each of the possible durations tested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Random Search and Greedy Layer-wise Strategy</head><p>Because one can have a different type of representation-learning model at each layer, and because each of these learning algorithms has several hyper-parameters, there is a huge number of possible configurations and choices one can make in exploring the kind of deep architectures that led to the winning entry of the challenge. There are two approaches that practitioners of machine learning typically employ to deal with hyper-parameters. One is manual trial and error, i.e., a human-guided search. The other is a grid search, i.e., choosing a set of values for each hyper-parameter and training and evaluating a model for each combination of values for all the hyper-parameters. Both work well when the number of hyper-parameters is small (e.g. 2 or 3) but break down when there are many more<ref type="foot" target="#foot_5">6</ref> . More systematic approaches are needed. An approach that we have found to scale better is based on random search and greedy exploration. The idea of random search <ref type="bibr">(Bergstra and</ref><ref type="bibr">Bengio, 2011, 2012)</ref> is simple and can advantageously replace grid search. Instead of forming a regular grid by choosing a small set of values for each hyper-parameter, one defines a distribution from which to sample values for each hyper-parameter, e.g., the log of the learning rate could be taken as uniform between log(0.1) and log(10 −6 ), or the log of the number of hidden units or principal components could be taken as uniform between log(2) and log(5000). The main advantage of random (or quasi-random) search over a grid is that when some hyper-parameters have little or no influence, random search does not waste any computation, whereas grid search will redo an exponential number of experiments (with respect to number of hyper-parameters) that are equivalent and do not bring any new information (because many of them have the same value for hyper-parameters that matter and different values for hyper-parameters that do not). Instead, with random search, every experiment is different, thus bringing more information. In addition, random search is convenient because even if some jobs are not finished, one can draw conclusions from the jobs that are finished. In fact, one can use the results on subsets of the experiments to establish confidence intervals (the experiments are now all iid), and draw a curve (with confidence interval) showing how performance improves as we do more exploration. Of course, it would be even better to perform a sequential optimization <ref type="bibr">(Bergstra et al., 2011)</ref> (such as Bayesian Optimization <ref type="bibr" target="#b12">(Brochu et al., 2009)</ref>) in order to take advantage of results of training experiments as they are obtained and sample in more promising regions of configuration space, but more research needs to be done towards this. On the other hand, random search is very easy and does not introduce hyper-hyper-parameters.</p><p>Another trick that we have used successfully in the past and in the challenge is the idea of a greedy search. Since the deep architecture is obtained by stacking layers and each layer comes with its own choices and hyper-parameters, the general strategy is the following. First optimize the choices for the first layer (e.g., try to find which single-layer learning algorithm and its hyper-parameters give best results according to some criterion such as validation set classification error or ALC). Then keep that best choice (or a few of the best choices found) and explore choices for the second layer, keeping only the best overall choice (or a few of the best choices found) among the 2-layer systems tested. This procedure can then be continued to add more layers, without the computational cost exploding with the number of layers (it just grows linearly).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Hyper-Parameters</head><p>The single most important hyper-parameter for most of the algorithms described here is the learning rate. A too small learning rate means slow convergence, or convergence to a poor performance given a finite budget of computation time. A too large learning rate gives poor results because the training criterion may increase or oscillate. The optimal learning rate for one data set and architecture may be too large or too small when changing one or the other, so it is worth optimizing the learning rate. Like most numerical hyper-parameters, the learning rates should be explored in the log-domain, and there is not much to be gained by refining it more than a factor of 2, whereas the dynamic range explored could be around 10 6 , learning rates are typically below 1. To efficiently search for a good learning rate, a greedy heuristic that we used is based on the following strategy. Start with a large learning rate and reduce it (by a factor 3) until training does not diverge. The largest learning rate which does not give divergent training (increasing training error) is usually a very good choice of learning rate.</p><p>For the challenge, another very sensitive hyper-parameter is the number of dimensions of the top-level representation fed to the classifier. It should probably be close to or related to the true number of classes (more classes would require more dimensions to be separated easily by a linear classifier).</p><p>Early stopping is another handy trick to speed-up model search, since it can be used to detect overfitting (even in the unsupervised learning sense) for a low computational cost.</p><p>After each training iteration one can compute an indicator of generalization error (either from the application of the unsupervised learning criterion on the validation set or even by training a linear classifier on a pseudo-validation set, as described below, sec. 4.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Visualization</head><p>Since the validation set ALC was an unreliable indicator of test set ALC, we used several strategies in the second phase of the competition to help guide the model selection. One of them is simply visualization of the representations as cloud points. One can visualize 3 dimensions at a time, either the leading 3 or a subset of the leading ones. To order and select dimensions we used PCA or t-SNE dimensionality reduction (van der Maaten and Hinton, 2008).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Simulating the Final Evaluation Scenario</head><p>Another strategy that often comes handy is to simulate (as much as possible) the final evaluation scenario, even in the absence of the test labels. In the case of the second phase of the competition, some of the training classes labels are available. Thus we could simulate the final evaluation scenario by choosing a subset of the training classes as "pseudo training set" and the rest as "pseudo test set", doing unsupervised training on the pseudo training set (or the union of pseudo training and pseudo test sets) and training the linear classifier using the pseudo test set. We then considered hyper-parameter settings that led not only to high accuracy in average across different choices of class subsets (for the pseudo train/test split), but also to high robustness (low variance) across these splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Examples in Transfer Learning</head><p>Deep Learning seems well suited to transfer learning because it focuses on learning representations and in particular "abstract" representations, representations that ideally disentangle the factors of variation present in the input.</p><p>This has been demonstrated already not only in this competition (see <ref type="bibr" target="#b35">Mesnil et al. (2011)</ref>) for more details), but also in several other instances. For example, in <ref type="bibr" target="#b8">Bengio et al. (2011)</ref>, it has been shown that a deep learner can take more advantage of out-ofdistribution training examples (whose distribution differs from the test distribution) than a shallow learner. Two settings were explored, with both results illustrated in Figure <ref type="figure" target="#fig_5">1</ref>  Another successful transfer example also using stacked denoising auto-encoders arises in the context of domain adaptation, i.e., where one trains an unsupervised representation based on examples from a set of domains but a classifier is then trained from few examples of only one domain. In that case, unlike in the challenge, the output variable always has the same semantics, but the input distribution (and to a lesser extent the relation between input and output) changes from domain to domain. <ref type="bibr" target="#b19">Glorot et al. (2011b)</ref> applied stacked denoising auto-encoders with sparse rectifiers (the same as used for the challenge) to domain adaptation in sentiment analysis (predicting whether a user liked a disliked a product based on a short review). Some of the results are summarized in Figure <ref type="figure" target="#fig_6">2</ref>, comparing transfer ratio, which indicates relative error when testing in-domain vs out-of-domain, i.e., how well transfer works (see <ref type="bibr" target="#b19">Glorot et al. (2011b)</ref> for more details). The stacked denoising autoencoders (SDA) are compared with the state of the art methods: SCL <ref type="bibr" target="#b9">(Blitzer et al., 2006)</ref> or Structural Correspondence Learning, MCT <ref type="bibr" target="#b34">(Li and Zong, 2008)</ref> or <ref type="bibr">Multi-label Consensus Training, SFA (Pan et al., 2010)</ref> or Spectral Feature Alignment, and T-SVM <ref type="bibr" target="#b50">(Sindhwani and Keerthi, 2006)</ref> or Transductive SVM. The SDA sh (Stacked Denoising Auto-encoder trained on all domains) clearly beats the state-of-the-art. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Moving Forward: Disentangling Factors of Variation</head><p>In spite of all the nice results described here, and in spite of winning the final evaluation of the challenge, it is clear to the author that research in Deep Learning of representations is only in its infancy, and that much more should be done to improve the learning algorithms.</p><p>In particular, it is the author's belief that these algorithms would be much more useful in transfer learning if they could better disentangle the underlying factors of variation. In a sense it is obvious that if we had algorithms that could do that really well, than most learning tasks (supervised learning, transfer learning, reinforcement learning, etc.) would become much easier, and the effect would be most felt when only very few labeled examples for the final task of interest are present. The question is whether we can actually improve in this direction, and the hypothesis we propose is that by explicitly designing the models and training criterion towards that objective, there is much to be gained. Ultimately, one can view the problem of learning from very few labeled examples of the task of interest almost as a an inference problem ("given that I define a new class based on this particular example, what is the probability that this other example also belongs to it?"), where the parameters of the model (i.e., the representation) have already been established through prior training on many more related examples (labeled or not) which help to capture the underlying factors of variation, some of which are relevant in the target task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3.</head><label></label><figDesc>No labels for the classes of interest (of the test set) are available at all when learning the representation. The labels from the training set might in fact mislead a representationlearning algorithm, because the directions of discrimination which are useful among the training set classes could be useless to discriminate among the test set classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>2. For = 1 to L Train an unsupervised learning model taking as observed data the training examples h −1 (x) represented at level − 1, and after training, producing representations h (x) = R (h −1 (x)) at the next level.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>or a Deep Boltzmann Machine (Salakhutdinov and Hinton, 2009): 3. Initialize an unsupervised model of x based on the parameters of all the stages. 4. Fine-tune the unsupervised model with respect to a global (all-levels) training criterion, based on the training set of examples x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Bengiox</head><label></label><figDesc>∼ P (x):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>. In the first one (left hand side of figure), training examples (character images) are distorted by adding all kinds of noises and random transformations (coherent with character images), but the target distribution contains clean examples. Training on the distorted examples was found to help the deep learners (SDA{1,2}) more than the shallow ones (MLP{1,2}), when the goal is to test on the clean examples. In the second setting (right hand side of figure),i.e., the multi-task setting, training is on all 62 classes available, but the target distribution of interest is a restriction to a subset of the classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relative improvement in character classification error rate due to out-ofdistribution examples. Left: Improvement (or loss, when negative) induced by out-of-distribution examples (perturbed data). Right: Improvement (or loss, when negative) induced by multi-task learning (training on all character classes and testing only on either digits, upper case, or lower-case). The deep learner (stacked denoising auto-encoder) benefits more from out-of-distribution examples, compared to a shallow MLP. {SDA,MLP}1 and {SDA,MLP}2 are respectively trained on different types of distortions. The NIST set includes all 62 character classes while NIST digits include only the 10 digits. Reproduced from Bengio et al. (2011).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Transfer ratios on the Amazon benchmark. Both SDA-based systems outperforms the rest, and SDA sh (unsupervised training on all domains) is best. Reproduced from Glorot et al. (2011b).</figDesc><graphic url="image-1.png" coords="16,122.40,90.86,367.20,291.64" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">. http://www.causality.inf.ethz.ch/unsupervised-learning.php</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">. and in fact, removing some of the low-variance directions with a preliminary PCA has worked well in the challenge.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">. overcomplete representation: with more dimensions than the raw input</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">. sparse representation: with many zeros or near-zeros</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">. The ALC is the sum of the accuracy measure for different number of labeled training examples. The accuracy measure used here is the AUC or Area Under the Curve. See http://www.causality.inf. ethz.ch/ul_data/DatasetsUTLChallenge.pdf</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">. Experts can handle many hyper-parameters, but results become less reproducible and algorithms less accessible to non-experts.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The author wants to thank NSERC, the Canada Research Chairs, mPrime, Compute Canada and FQRNT for their support, and the other authors of the companion paper <ref type="bibr" target="#b35">(Mesnil et al., 2011)</ref> for their contributions to many of the results and ideas illustrated here.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using manifold structure for partially labeled classification</title>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 15 (NIPS&apos;02)</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Learning deep architectures for AI. Foundations and Trends in Machine Learning</title>
				<imprint>
			<publisher>Now Publishers</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Practical recommendations for gradient-based training of deep architectures</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
				<editor>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Justifying and generalizing contrastive divergence</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Delalleau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1601" to="1621" />
			<date type="published" when="2009-06">June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scaling learning algorithms towards AI</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Large Scale Kernel Machines</title>
				<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Decoste</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 19 (NIPS&apos;06)</title>
				<editor>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Platt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Hoffman</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep learners benefit more from out-of-distribution examples</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Bergeron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Boulanger-Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youssouf</forename><surname>Chherawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myriam</forename><surname>Côté</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Eustache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Pannetier Lebeuf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salah</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Savard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Sicard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR W&amp;CP: Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2011)</title>
				<meeting><address><addrLine>Fort Lauderdale, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04">April 2011</date>
		</imprint>
	</monogr>
	<note>James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization, 2011. The Learning Workshop</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Algorithms for hyperparameter optimization</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémy</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Kégl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;2011</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP &apos;06</title>
				<meeting>of EMNLP &apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Auto-association by multilayer perceptrons and singular value decomposition</title>
		<author>
			<persName><forename type="first">Hervé</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Poly-logarithmic independence fools bounded-depth boolean circuits</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Braverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="108" to="115" />
			<date type="published" when="2011-04">April 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brochu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><forename type="middle">M</forename><surname>Cora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
		<idno>TR-2009-23</idno>
		<imprint>
			<date type="published" when="2009-11">November 2009</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of British Columbia</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning many related tasks at the same time with backpropagation</title>
		<author>
			<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 7 (NIPS&apos;94)</title>
				<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Leen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-fifth International Conference on Machine Learning (ICML&apos;08)</title>
				<editor>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sam</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</editor>
		<meeting>the Twenty-fifth International Conference on Machine Learning (ICML&apos;08)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised models of images by spike-and-slab RBMs</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</title>
				<meeting>the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sampled reconstruction for large-scale learning of embeddings</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</title>
				<meeting>the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Shallow vs. deep sum-product networks</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Delalleau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 24 (NIPS&apos;11)</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoire</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR W&amp;CP: Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2011)</title>
				<imprint>
			<date type="published" when="2011-04">April 2011a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoire</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</title>
				<meeting>the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Measuring invariances in deep networks</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 22 (NIPS&apos;09)</title>
				<editor>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christopher</forename><surname>Williams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="646" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Almost optimal lower bounds for small depth circuits</title>
		<author>
			<persName><forename type="first">Johan</forename><surname>Håstad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th annual ACM Symposium on Theory of Computing</title>
				<meeting>the 18th annual ACM Symposium on Theory of Computing<address><addrLine>Berkeley, California</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="6" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the power of small-depth threshold circuits</title>
		<author>
			<persName><forename type="first">Johan</forename><surname>Håstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikael</forename><surname>Goldmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Complexity</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="113" to="129" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modelling the manifolds of images of handwritten digits</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Revow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Products of experts</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Artificial Neural Networks (ICANN)</title>
				<meeting>the Ninth International Conference on Artificial Neural Networks (ICANN)<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>IEE</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A practical guide to training restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>UTML TR 2010-003</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2010. July 2006</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Reducing the dimensionality of data with neural networks</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Important gains from supervised fine-tuning of deep architectures on large labeled sets</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS*2010 Deep Learning and Unsupervised Feature Learning Workshop</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donnie</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998-11">November 1998a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genevieve</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks, Tricks of the Trade</title>
		<title level="s">Lecture Notes in Computer Science LNCS</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1998">1998b</date>
			<biblScope unit="volume">1524</biblScope>
		</imprint>
	</monogr>
	<note>Efficient backprop</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-sixth International Conference on Machine Learning (ICML&apos;09)</title>
				<editor>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Littman</surname></persName>
		</editor>
		<meeting>the Twenty-sixth International Conference on Machine Learning (ICML&apos;09)<address><addrLine>Montreal (Qc), Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for audio classification using convolutional deep belief networks</title>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Largman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 22 (NIPS&apos;09)</title>
				<editor>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christopher</forename><surname>Williams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2009">2009b</date>
			<biblScope unit="page" from="1096" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-domain adaptation for sentiment classification: Using multiple classifier combining methods</title>
		<author>
			<persName><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NLP-KE &apos;08</title>
				<meeting>of NLP-KE &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unsupervised and transfer learning challenge: a deep learning approach</title>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salah</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erick</forename><surname>Lavoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR W&amp; CP: Proceedings of the Unsupervised and Transfer Learning challenge and workshop</title>
				<editor>
			<persName><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Dror</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Lemaire</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Taylor</surname></persName>
		</editor>
		<editor>
			<persName><surname>Silver</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evaluating probabilities under high-dimensional latent variable models</title>
		<author>
			<persName><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 21 (NIPS&apos;08)</title>
				<editor>
			<persName><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML &apos;10</title>
				<meeting>of ICML &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<author>
			<persName><forename type="first">Genevieve</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: tricks of the trade</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag Inc</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1524</biblScope>
		</imprint>
	</monogr>
	<note>ISBN 3-540-65311-2 (paperback</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cross-domain sentiment classification via spectral feature alignment</title>
		<author>
			<persName><forename type="first">Xiaochuan</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Tao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW &apos;10</title>
				<meeting>of WWW &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Sum-product networks: A new deep architecture</title>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2010 Workshop on Deep Learning and Unsupervised Feature Learning</title>
				<meeting><address><addrLine>Whistler, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Self-taught learning: transfer learning from unlabeled data</title>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-fourth International Conference on Machine Learning (ICML&apos;07)</title>
				<editor>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</editor>
		<meeting>the Twenty-fourth International Conference on Machine Learning (ICML&apos;07)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="759" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient learning of sparse representations with an energy-based model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Poultney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;06</title>
				<imprint>
			<date type="published" when="2007">2007a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generating more realistic images using gated MRF&apos;s</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 23 (NIPS&apos;10)</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Culotta</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2002" to="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Modeling pixel means and covariances using factorized third-order Boltzmann machines</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2551" to="2558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Efficient learning of sparse representations with an energy-based model</title>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Poultney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 19 (NIPS&apos;06)</title>
				<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hoffman</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007">2007b</date>
			<biblScope unit="page" from="1137" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sparse feature learning for deep belief networks</title>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20 (NIPS&apos;07)</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1185" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Contracting auto-encoders: Explicit invariance during feature extraction</title>
		<author>
			<persName><forename type="first">Salah</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</title>
				<meeting>the Twenty-eight International Conference on Machine Learning (ICML&apos;11)</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep Boltzmann machines</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Twelfth International Conference on Artificial Intelligence and Statistics (AIS-TATS&apos;09)</title>
				<meeting>The Twelfth International Conference on Artificial Intelligence and Statistics (AIS-TATS&apos;09)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="448" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Think globally, fit locally: unsupervised learning of low dimensional manifolds</title>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="119" to="155" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Large scale semi-supervised linear svms</title>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Sathiya</forename><surname>Keerthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR &apos;06</title>
				<meeting>of SIGIR &apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vin</forename><surname>De Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000-12">December 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11">November 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International Conference on Machine Learning (ICML 2008)</title>
				<editor>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sam</forename><surname>Roweis</surname></persName>
		</editor>
		<meeting>the 25th Annual International Conference on Machine Learning (ICML 2008)</meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Separating the polynomial-time hierarchy by oracles</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual IEEE Symposium on Foundations of Computer Science</title>
				<meeting>the 26th Annual IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
