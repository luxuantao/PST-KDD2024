<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A New Case for the TAGE Branch Predictor *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
							<email>andre.seznec@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">INRIA/IRISA Campus de Beaulieu</orgName>
								<address>
									<postCode>35042</postCode>
									<settlement>Rennes Cedex</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A New Case for the TAGE Branch Predictor *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The TAGE predictor is often considered as state-of-the-art in conditional branch predictors proposed by academy. In this paper, we first present directions to reduce the hardware implementation cost of TAGE. Second we show how to further reduce the misprediction rate of TAGE through augmenting it with small side predictors.</p><p>On a hardware implementation of a conditional branch predictor, the predictor tables are updated at retire time. A retired branch normally induces three accesses to the branch predictor tables : read at prediction time, read at retire time and write for the update. We show that in practice, the TAGE predictor accuracy would not be significantly impaired by avoiding a systematic second read of the prediction tables at retire time for correct prediction. Combined with the elimination of silent updates, this significantly reduces the number of accesses to the predictor. Furthermore, we present a technique allowing to implement the TAGE predictor tables as bank-interleaved structures using single-port memory components. This significantly reduces the silicon footprint of the predictor as well as its energy consumption without significantly impairing its accuracy.</p><p>In the last few years, progress in branch prediction accuracy has relied on associating a main state-of-the-art single scheme branch predictor with specialized side predictors. As a second contribution of the paper, we develop this side predictor approach for TAGE. At the recent 3rd Championship Branch Prediction,it was shown that the TAGE predictor can be augmented with several side predictors, each one addressing a category of predictions that is not optimally addressed by TAGE. The Immediate Update Mimicker tracks the inflight already executed but not retired branches and</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>From 1990 to 2000, there has been a very active research in branch prediction <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b2">3]</ref> resulting in the design of complex branch predictors <ref type="bibr" target="#b21">[22]</ref>. After 2001, the research on branch prediction was essentially conducted by a small community that participated to the Championship Branch Prediction (CBP) in 2004 and 2006 <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18]</ref>. However, tremendous progress were made during this period: the research of neural inspired predictors led by Jimenez <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b0">1]</ref>, the introduction of GEometric History Length predictors by Seznec <ref type="bibr" target="#b20">[21]</ref> and the introduction of the TAGE predictor by Seznec and Michaud <ref type="bibr" target="#b25">[26]</ref>. In practice, on the traces distributed for the first two CBPs, more accuracy progress was achieved between 2001 and 2006 than between 1993 and 2001 after the introduction of gshare by McFarling in 1993 <ref type="bibr" target="#b15">[16]</ref>.</p><p>Since 2006, TAGE has been often considered as state-of-theart in terms of branch prediction accuracy <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>. In this paper, we reenforce the case for the TAGE predictor in two directions. First we show that the TAGE predictor requires less accesses to the predictor tables than other branch predictors thus potentially enabling simpler (or more cost effective) implementation. Second, building on the side predictors recently presented at the 3rd Championship Branch Prediction <ref type="bibr" target="#b23">[24]</ref> for the TAGE predictor, we show that TAGE can be combined with a small local history predictor to obtain even higher accuracy at the same storage budget, thus achieving state-of-art prediction accuracy. Combining these two approaches, we present a cost-effective predictor that achieves state-of-the-art prediction accuracy.</p><p>In a processor, the hardware predictor tables are updated at retire time to avoid pollution by the wrong path; this delayed update induces extra mispredictions compared with oracle update at fetch time. Previous studies were generally showing that the accuracy loss due to this delayed update on global history predictors is relatively marginal <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21]</ref>. However these studies are assuming that the predictor tables are read a second time and the prediction recomputed at retire time. Each branch on the correct path potentially leads to 3 accesses of the predictor tables, read at prediction time, read at retire time and write at retire time. Such a high number of accesses potentially leads to a very costly branch prediction structure (multiported and/or very complex bank-interleaved structure). As a first contribution of the paper, we show that on the TAGE predictor and contrary to other predictors, the read at retire time can be avoided with limited accuracy loss. Combined with the elimination of silent updates (more than 90 % in average), this significantly reduces the number of accesses to the predictor. Moreover, we present a bank-interleaving technique that allows to use single-ported memory components to build the TAGE predictor tables. Combining these two techniques allows significant silicon area savings and significant reduction of the energy consumption on the predictor.</p><p>Since 2006, the trend for further prediction accuracy improvement is to associate side predictors targeting special categories of branches with a state-of-the-art main predictor (TAGE, <ref type="bibr" target="#b25">[26]</ref>, OGEHL <ref type="bibr" target="#b20">[21]</ref>, Piecewise Linear <ref type="bibr" target="#b10">[11]</ref>, FTL <ref type="bibr" target="#b7">[8]</ref>), e.g. a loop predictor with the TAGE predictor in L-TAGE <ref type="bibr" target="#b25">[26]</ref> or the address-branch correlator in <ref type="bibr" target="#b4">[5]</ref>.</p><p>In this paper, we illustrate this approach for the TAGE predictor with the ISL-TAGE predictor, that was presented at the 3rd Championship Branch Prediction <ref type="bibr" target="#b23">[24]</ref>.</p><p>For the TAGE predictor, in order to limit the mispredictions due to delayed updates, we introduce the Immediate Update Mimicker, IUM, (Section 5.1) that aims at limiting these extra mispredictions through predicting branches with inflight non-retired occurrences: if the prediction for branch B is provided by the same predictor table and the same table entry that already provided the prediction for an already executed but not yet retired branch B' the we use the execution outcome of branch B' as a prediction for branch B rather than the output of the predictor. The IUM is shown to allow to recover almost all the mispredictions due to delayed updates. While TAGE is generally very efficient at predicting periodic regular behavior even when the period spans over hundreds or thousands of branches, it fails to predict loop exits if the control flow path inside the loop body is irregular. A loop predictor <ref type="bibr" target="#b5">[6]</ref> can more efficiently track loops with constant numbers of iterations and therefore predict the exit of these loops with a very high accuracy (Section 5.2). On some applications, there exist branches (generally only a few) that are not strongly correlated with the branch history or path, but exhibit a statistical bias towards taken or not-taken. On these branches, the TAGE predictor generally performs worse than simpler solutions that capture statistical bias by using wide counters. The Statistical Corrector predictor (Section 5.3) is introduced to capture these branches and to predict them with an accuracy close to their statistical bias at a reasonable cost. The ISL-TAGE predictor combines TAGE with the IUM, the loop predictor and the Statistical Corrector Predictor.</p><p>In some applications, there remains some branches that are intrinsically better predicted through the use of local history than through the use of a global history. In the ISL-TAGE predictor proposal , the Statistical Corrector Predictor is indexed using the same global history as TAGE. We show that replacing the global history by the local history offers the opportunity to smoothly combine the TAGE predictor with local prediction. Associated with TAGE, a Statistical Corrector predictor based on local history (LSC for short) essentially captures these branches. It also captures most of the branches that the loop predictor is correctly predicting and most of the branches that the initial Statistical Corrector predictor based on global history is correcting. At similar storage budget, the TAGE-LSC (+ IUM) predictor outperforms the ISL-TAGE predictor <ref type="bibr" target="#b23">[24]</ref> 1 using a smaller number of components and a smaller number of tagged tables, and without using any unrealistic tricks.</p><p>The remainder of the paper is organized as follows. Section 2 presents the experimental framework used in this paper. Section 3 recalls the main characteristics of the TAGE predictor used as the main predictor in this paper and presents its main qualities and its base performance. Section 4 analyzes the number of predictor table accesses on a real hardware processor and shows that the TAGE predictor exhibits marginal accuracy loss when the prediction is not reread at retire time, therefore potentially allowing simpler hardware implementation. Moreover we show that the TAGE predictor can be designed with single-port bank-interleaved memory components instead of 3-ported memory components. Section 5 presents the ISL-TAGE predictors. Section 5.1 introduces the Immediate Update Mimicker, IUM that recovers most of the mispredictions due to delayed update of the TAGE branch predictor tables. Section 5.2 describes the loop predictor and its benefit as a side predictor. Section 5.3 presents the Statistical Corrector predictor, that tracks branches that are not strongly correlated with the branch history path but are statistically biased. In Section 6, we show how the Statistical Corrector predictor can be leveraged to use local history in a side predictor for TAGE. We show that TAGE-LSC can achieve state-of-the-art prediction accuracy levels for the prediction storage budgets (128K-512Kbits) that are currently considered for implementation. In Section 7 presents a cost-effective implementation of the TAGE-LSC predictor using single-port memory components and avoiding predictor read at retire time can be avoided for correct prediction. Section 8 concludes this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Experimental Framework</head><p>In order to allow reproducibility of the experiments reported in this paper, the evaluation framework used is the one provided for 1 winner of the 3rd Championship Branch Prediction the 3rd Championship Branch Prediction, http://www.jilp.org/jwac-2/framework.html. The simulation is trace driven, but includes features to model a simple out-of-order execution core with a realistic memory hierarchy. It allows to delay branch prediction table updates till the retire stage in the pipeline. The benchmark set features 40 traces, approximately 50 million micro-ops long classified into 5 categories: CLIENT, INT (Integer), MM (Multimedia), SERVER and WS (Workstation). It is noticeable that some of these traces exhibit very large footprints (several tens of thousands of static branches), they also include both user and system activity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Performance Metric</head><p>In order to remain consistent with the 3rd CBP, we will use the metric Misprediction Penalty per Kilo Instructions (MPPKI) proposed for the 3rd CBP. In practice, for the predictors considered in this paper, this metric is globally proportional to the misprediction number despite that the average misprediction penalty varies among the benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Benchmark Set Characteristics</head><p>Based on a first analysis of the benchmark set after running a base 512Kbits L-TAGE predictor, the benchmark set can be divided in two major sets with very different misprediction rates.</p><p>A set of high misprediction rate benchmarks includes CLIENT02, INT01, INT02, MM05, MM07, WS03 and WS04. These 7 benchmarks represent approximately 3/4 th of the mispredictions of the 40 benchmarks. All these benchmarks exhibit more than 500,000 mispredictions (i.e more than 10 mispredictions per kilomicrooperations) for the reference predictor (see next section) considered in this study. Among this class, CLIENT02 is the only benchmark amenable to a low misprediction rate by simply increasing the size of the predictor to unrealistic storage budget (256 Mbits).</p><p>The set of the 33 medium and low misprediction rates benchmarks represent only 1/4th of the mispredictions and none of them exhibit more than 170,000 mispredictions on our reference predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Background on the TAGE Predictor</head><p>The TAGE predictor was introduced in <ref type="bibr" target="#b25">[26]</ref> and is the core predictor of the L-TAGE predictor that won the second Championship Branch Prediction in 2006 <ref type="bibr" target="#b22">[23]</ref>. Figure <ref type="figure">1</ref> illustrates a TAGE predictor. The TAGE predictor features a base predictor T0 in charge of providing a basic prediction and a set of (partially) tagged predictor components Ti. The base predictor can be a simple PC-indexed 2-bit counter bimodal table. The tagged predictor components Ti, 1 ≤ i ≤ M are indexed using different global history lengths that form a geometric series, i.e, L(i) = (int)(α i−1 * L(1) + 0.5) as introduced for the OGEHL predictor <ref type="bibr" target="#b20">[21]</ref>. On a TAGE predictor, most of the storage is used in tables indexed with (relatively) short histories, but the predictor is able to capture correlation with very old branches (up to 2000 branches in our experiments in this paper).</p><p>An entry of a tagged component of the TAGE predictor consists in a 3-bit prediction counter ctr whose sign provides the prediction, a (partial) tag and a useful bit u to guide replacement policy (Figure <ref type="figure">2</ref> ). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A few definitions and notations.</head><p>The provider component is the matching component with the longest history. The alternate prediction altpred is the prediction that would have occurred if there had been a miss on the provider component. If there is no hit on a tagged component then altpred is the default prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Prediction Computation</head><p>At prediction time, the base predictor and the tagged components are accessed simultaneously. The base predictor provides a default prediction. The tagged components provide a prediction only on a tag match.</p><p>In the general case, the overall prediction is provided by the hitting tagged predictor component that uses the longest history, or in case of no matching tagged predictor component, the default prediction is used. It was remarked that when the provider component is a tagged component and the prediction is weak, the confidence in the prediction is quite low ( often less than 60%). In this situation, the alternate prediction is often more accurate than the provider component prediction. This property was found to be essentially temporal on the whole application. Dynamically monitoring it through a single 4-bit counter USE_ALT_ON_NA was found to allow to (slightly) improve prediction accuracy <ref type="bibr" target="#b25">[26]</ref>. The prediction computation algorithm is as follows:</p><p>1. Find the matching component with the longest history 2. if (the prediction counter is not weak or USE_ALT_ON_NA is negative) then the prediction counter sign provides the prediction else the prediction is the alternate prediction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predictor Update</head><p>In all cases, the prediction counter of the provider component is updated. The useful bit u is set if the prediction was correct and the alternate prediction altpred was incorrect. New tagged entries are allocated only on mispredictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Allocating tagged entries on mispredictions</head><p>In previous studies on the TAGE predictor, it was argued to allocate at most one entry to limit the footprint of the application on the predictor. In practice, the footprint limitation holds only on demanding applications and for small predictors (e.g. 64 Kbits) or predictors with a small number of tables. For large TAGE predictors (in the 256Kbits-512Kbits range), we discovered that allocating several (in practice up to 3 or 4) entries in different tables enables a very short warming or transition phase in the predictor. It also allows us to use a very simple and effective way of managing the useful bits on the predictor (see below in Section 3.2.2).</p><p>If the provider component Ti is not the component using the longest history (i.e., i ≤ M ), then up to four entries on a predictor component Tk with i &lt; k ≤ M are allocated on non-consecutive tables. The entries are chosen among the useless entries, i.e., with a null u bit. An allocated entry is initialized with the prediction counter set to weak correct. Bit u is initialized to 0 (i.e., not useful).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Managing the u bit</head><p>The useful bit u is used for locking entries in the predictor. The u bit of a provider component is set whenever the prediction was correct and the alternate prediction altpred was incorrect. In order to avoid the useful bits to stay forever set, the following resetting policy is implemented. The number of successes and failures on entries allocations is monitored; this monitoring is performed through a single 8-bit counter (u=1, increment, u=0, decrement). This counter saturates when more failures than successes are encountered on allocations. At that time we reset all the u bits of the predictor. Typically, such a global reset occurs when one out of two entries on the used portion of the predictor has been set to useful.</p><p>This simple policy was found to be more efficient than the previously proposed management using 2-bit useful counters for the TAGE predictor <ref type="bibr">[26][23]</ref>; it also uses a single u bit per tagged TAGE entry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementation Tradeoffs</head><p>Various parameters can be tuned on the TAGE predictor in order to get prediction accuracy.</p><p>Depending on the storage budget one will use small or large number of tables. It was shown in <ref type="bibr" target="#b22">[23]</ref> that for small budgets (e.g. 32K-64Kbits) using 5 to 8 tables is good tradeoff and that for large budgets (e.g. 256Kbits-512Kbits) using 12-15 tables is a better tradeoff.</p><p>Most of the storage budget in the TAGE predictor is dedicated to the partial tags. Using a large tag width leads to waste part of the storage while using a small tag width leads to false tag match detections. We found that , for a 13 tables TAGE predictor using 12-bit tag is good tradeoff. However Experiments showed that one can use wider tag for long histories for a better tradeoff. Previous experiments <ref type="bibr" target="#b25">[26]</ref> have shown that the TAGE predictor performs efficiently on a wide spectrum of history lengths with maximum history lengths ranging from a 100 to more than 1,000 history bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The Reference TAGE Predictor</head><p>This study targets the 64Kbytes storage budget that was allowed for the 3rd Championship Branch Prediction. Therefore the reference TAGE predictor that will be used in this study has been dimensioned to fit in that storage budget. It features a 13component, and uses the <ref type="bibr" target="#b5">(6,</ref><ref type="bibr">2000)</ref> geometric history length with the following table sizes for a total of 65,408 bytes of storage:</p><p>• Bimodal table: 32K prediction bits + 8K hysteresis bits • Tag width for table Ti: max (6+i, 15) bits <ref type="table">T1, 2Kentries, Tables 2-7</ref>, 4Kentries, Tables <ref type="table">8-9</ref>, 2Kentries and Tables <ref type="table">10-12</ref>, 1K entries</p><formula xml:id="formula_0">• Table</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Delayed Update Issue on Conditional Branch Predictor</head><p>On a real hardware processor, the predictor tables are updated at retire time to avoid pollution of the predictor by wrong path branches. A single predictor table entry may provide several mispredictions in a row due to this late update. While this phenomenon has been recognized by the microarchitecture research community, it has been considered to be relatively marginal on global history predictors featuring long history <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21]</ref>. However these studies were assuming that the predictor tables were reread and the prediction recomputed at retire time: each branch on the correct path potentially leads to 3 accesses of the predictor tables, read at prediction time, read at retire time and write at retire time.</p><p>At a first glance, the second read at retire time appears useless since one could use the values read at prediction time. However the simple example of a loop execution and a bimodal 2-bit counter predictor illustrated on Figure <ref type="figure" target="#fig_1">3</ref> shows that this second read might be really needed. On the example the first 6 iterations are mispredicted: till retiring the first iteration, i.e. for iterations 2 and 3, the value read on the predictor is C=0, i.e. strongly not-taken, then till retiring iteration 4, i.e. iterations 4, 5 and 6, the value read on the predictor is C=1, i.e weakly taken; the bimodal predictor predicts correctly at iteration 7 instead of of iteration 3 when immediately updated or iteration 5 if the predictor was reread at update time.</p><p>Three predictor accesses per branch would normally necessitate the use of 3-port predictor tables in order to issue and to commit one branch per cycle. Unfortunately 3-port memory component occupy much more area and dissipates much more energy than single ported memory component. Simple experiments run on CACTI 6.5 <ref type="bibr" target="#b18">[19]</ref> showed that, for the range of memory array sizes used in branch predictors (1Kbytes to 64Kbytes) and for equal capacity the area of a 3-port memory array is 3-4 times larger than a single-ported memory array, while the energy dissipated per access is about 25-30 % higher.</p><p>To the best of our knowledge, no constructor has ever disclosed how these potential 3 accesses per branch on the predictor are handled in the hardware implementation of the predictor when one want to sustain one branch prediction per cycle. Since 3-port predictor tables are not hardware cost-effective, alternative techniques are needed.</p><p>In the remainder of the section, we present realistic techniques to reduce the number of accesses on the branch predictor, particularly for the TAGE predictor. Such techniques can be leveraged in real designs to build predictors using dual-ported or single-ported </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reducing the Number of Accesses on the Branch Predictor</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Eliminating silent updates</head><p>The first obvious technique to reduce the number of accesses on the branch predictor is to avoid the silent updates of the predictor. On update, in many cases the table entries are overwritten with the exact same value they were previously holding. Eliminating this silent update is a simple technique that holds for all branch predictors and that should be very effective. This technique was already mentioned by Baniasadi and Moshovos in the context of energy saving <ref type="bibr" target="#b1">[2]</ref>.</p><p>We confirmed this assumption by simulations of 3 very different predictors: our reference TAGE predictor, a simple 512 Kbits gshare <ref type="bibr" target="#b15">[16]</ref> predictor as a representative of first generation predictor and a 520 Kbits GEHL predictor <ref type="bibr" target="#b20">[21]</ref> as a representative of neural inspired predictors 2 . A GEHL predictor featuring 13 tables, 5 bit entries and 8K entries per table using <ref type="bibr" target="#b5">(6,</ref><ref type="bibr">2000)</ref> history length , i.e. a total of 520 Kbits was considered 3 .</p><p>In practice, on the benchmark set, TAGE encounters an average of 2.17 effective writes per misprediction or 9.06 writes per 100 retired conditional branches. GEHL, by construction of its update policy, encounters slightly less than 2 effective writes per misprediction (1.94) or 9.10 writes per 100 retired branches. Gshare encounters in average 1.54 writes per misprediction or 9.61 writes per 100 retired branches.</p><p>2 by neural inspired, we mean that prediction is computed through a tree of adders and that the predictor update is threshold based as described in the initial perceptron predictor study <ref type="bibr" target="#b12">[13]</ref> 3 The GEHL configuration was not optimized. The purpose of this experiment is not here to compare accuracies of GEHL and TAGE, but to illustrate the issues of delayed update and multiple accesses to the predictor tables on different predictors</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Eliminating the read at retire time ?</head><p>One would like to avoid the read of the predictor tables at retire time if possible. However there might be performance loss. We have conducted experiments to evaluate three possible scenarii on the 3 branch predictors used above and compared their performance with the oracle update at fetch time scenario [I] as a reference. The three possible scenarii are:</p><p>1.</p><p>[A]: reread the prediction tables at retire time before (potential) update.</p><p>2.</p><p>[B]:only read prediction at fetch time, propagate all the informations with the branches in the pipeline, and write the update at retire time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Summary on Number of Predictor Accesses per Branch</head><p>Compared with predictors using wide counters or predictors using a single predictor table, TAGE suffers only a marginal accuracy impact when the predictor table is read only once at pre-diction time particularly if it is read at retire time on mispredictions. The performances losses on Scenario [C] on GEHL predictors and gshare will push designers to reject this scenario and therefore to perform systematically two reads on the predictor tables per branch.</p><p>On the other hand, the validity of Scenario [C] for TAGE opens the possibility to implement the TAGE predictor with bank-interleaved tables built with single-ported memory banks (e.g. 4-way interleaved) since each (retired) branch generates in average only 1.13 accesses (1 read at prediction time, 0.04 read in average at retire time, and 0.09 write in average at retire time) to the predictor tables. Such a solution can leverage the proposition for the EV8 branch predictor <ref type="bibr" target="#b21">[22]</ref> to guarantee that two or even three consecutive branch predictions will access different banks in each table as shown below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Towards 4-way Interleaved single-ported Predictor Tables for TAGE</head><p>In this section, we assume that each of the tables in the TAGE predictor is 4-way interleaved. We assume that a single branch (either direct or indirect) is predicted per cycle. In order to guarantee a smooth repartition of the accesses among the banks, one can guarantee that the predicted branch will not access any of the banks that were accessed by the two previous predictions as follows:</p><p>Let X,Y and Z be the PCs of the three successive branches, we compute b(Z), the number of the bank accessed for the prediction of Z as follows: We assume that prediction has priority over update and that write at retire time has priority over read at retire time. Our algorithm guarantees that for every bank of any of the predictor tables, for every 3 cycles interval, 2 cycles are free for performing the updates.</p><p>Since for scenario [C], reads at retire time and effective write updates are rare, no huge buffering is needed. In practice, reading the predictor, computing the update and updating the predictor necessitates a few cycles: the read at retire time can be delayed by one cycle (conflict with a prediction) and the update by up to two cycles (conflict with prediction or/and an older update).</p><p>Simulations of bank-interleaving for scenario [C] leads to 627 MMPKI, i.e., very close to the 625 MPPKI achieved without bankinterleaving, but using 3-port memory arrays. Evaluations using CACTI 6.5 <ref type="bibr" target="#b18">[19]</ref> report a 3.3x decrease of the silicon area occupied by the memory arrays and a 2x decrease of the energy dissipated in the memory arrays per predictor access when assuming bankinterleaving instead of 3-port memory array.</p><p>Note that this bank-interleaving technique can be applied for most global history predictors also resulting in marginal accuracy losses. On local history predictors, the bank-interleaving technique can also be applied on the predictor tables but results in more substantial prediction accuracy loss since several entries correspond to the same (history,branch) pair, thus inducing more aliasing conflicts, and necessitating a longer training.</p><p>In the remainder of the paper apart Section 7, we will consider that predictors are implemented using 3-port memory arrays. Moreover apart Section 5.1 and Section 7, we will consider that the predictor is systematically reread at retire time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The ISL-TAGE predictor</head><p>In this section, we detail the side predictors that were proposed for TAGE at the 3rd Championship on Branch Prediction <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Immediate Update Mimicker</head><p>In the previous section, we have pointed out that the impact of delayed update on the TAGE predictor is much lower than on other predictors including the neural-inspired predictors, particularly when one try to only read at prediction time and write at retire time. In order to further limit the impact of the use of the delayed update, an add-on to TAGE can be implemented, the Immediate Update Mimicker, IUM.</p><p>On a misprediction, the global history can be repaired immediately and when a block is fetched on the correct path, the speculative branch history is correct. In practice, repairing the global history is straightforward if one uses a circular buffer to implement the global history. We leverage the same idea with IUM predictor (Figure <ref type="figure" target="#fig_5">4</ref>).</p><p>When fetching a conditional branch, IUM records the prediction, the identity of the entry E in the TAGE predictor (number of the table and its index) that provides the prediction. At branch resolution on a misprediction, the IUM is repaired through reinitializing its head pointer to the associated IUM entry and updating this entry with the correct direction.</p><p>When fetching on the correct path, the associated IUM entry associated with an inflight branch B features the matching predictor entry E that provided the TAGE prediction and the effective outcome of branch B (corrected in case of a misprediction on B). In case of a new hit on entry E in the predictor before the retirement of branch B, the (TAGE predictor + IUM) can respond with the direction provided by the IUM rather than with the TAGE prediction (on which entry E has not been updated).</p><p>IUM can be implemented in hardware through a fully-associative table with one entry per inflight branch. It allows to recover about 3/4th of the mispredictions due to late update of the TAGE predictor tables if all predictions are recomputed are retire time (Scenario Without the IUM, the gap between immediate update and realistic update is very dependent on the benchmarks. For some benchmarks, particularly on the set of high misprediction rate benchmarks and for scenarii [A] and [C] the difference between immediate update and realistic update is marginal (&lt; 1% of the mispredictions), while on other benchmarks (e.g. CLIENT04, CLIENT06) it represents more than 10 % of the mispredictions. For all the benchmarks, the IUM reduces this gap to less 1% for Scenario [A] or 2% for Scenario [C] . For Scenario [B], CLIENT02, a high misprediction rate benchmark, is a specific outlier with an accuracy loss of 9 % without the IUM. With the IUM, it reaches an acceptable 5 % accuracy loss. Note that for implementing Scenario [B] or [C] in a real hardware predictor, one will have to propagate information read on the predictor at prediction time up to retire The IUM entry can be augmented with a few fields to propagate these information.</p><p>For the sake of simplicity and since the accuracy difference between Scenario [A] and Scenario [C] is very limited, we will use Scenario [A] in the remainder of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The Loop Predictor</head><p>Loops with constant number of iterations are branches that are highly predictable when one only considers the local history. The TAGE predictor is generally able to predict these loops with very high accuracy when the control flow inside the loop is regular. However when the control flow in the loop body is erratic, the TAGE predictor may fail to correctly predict the exit of the loop <ref type="bibr" target="#b5">[6]</ref>.</p><p>A loop predictor can simply identify regular loops with constant number of iterations. The loop predictor will provide the global prediction when it identifies the branch as a loop with a constant iteration number and when this identificatiion has reached a high confidence, i.e. when the loop has been executed several times with the same number of iterations. In practice, reaching a high confidence level after 7 executions of the overall loop appears as a good tradeoff.</p><p>A loop predictor with a limited number of entries and high associativity is sufficient. In the experiments we report below, a 4way skewed associative 64-entry loop predictor is assumed. Each entry in the loop predictor table consists of a past iteration count on 10 bits, a retire iteration count on 10 bits each , a partial tag on 10 bits, a confidence counter on 3 bits, an age counter on 3 bits and 1 direction bit i.e. 37 bits per entry. Replacement policy is based on the age. An entry can be replaced only if its age counter is null. On allocation, age is first set to 7. Age is decremented whenever the entry was a possible replacement target and incremented when the entry is used and has provided a valid prediction and the prediction would have been incorrect otherwise. Age is reset to zero whenever the branch is determined as not being a regular loop.</p><p>The overall hardware complexity of the loop predictor is not in the loop predictor table itself but in the speculative management of the iteration numbers. Figure <ref type="figure" target="#fig_6">5</ref> illustrates here a possible implementation of such a speculative management, a Speculative Loop Iteration Manager, SLIM. The SLIM records a new entry for each branch recognized as a loop. The entry features the PC of the branch and the (speculative) iteration number that has been reached. At prediction time, the loop predictor is checked. On a hit with high confidence, the (non-speculative) number of the current iteration and the number of iterations in the loop are read on the predictor. The SLIM is read in parallel. If the branch also hits in the SLIM then the most recent hitting entry provides the speculative iteration number. The speculative iteration number is incremented and checked against the predicted number of iterations of the loop, branch outcome is predicted accordingly. On a misprediction, the SLIM entries after the misprediction are cleared. On a loop retirement, the associated SLIM entry is cleared.</p><p>Associating the loop predictor on top of the base TAGE+IUM predictor allows to reach 593 MPPKI, i.e. approximately a 3 % reduction of the performance loss due to imperfect prediction by the TAGE+IUM predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The Statistical Corrector Predictor</head><p>The TAGE predictor is very efficient at predicting very correlated branches even if the correlation is with very remote branches, e.g. on a 1000 bits branch history. However, TAGE fails at predicting statistically biased branches e.g. branches that are not correlated with the control flow path, but have only some statistical bias towards a direction. On some of these branches, the TAGE predictor performs even worse than a simple PC-indexed table of wide counters (e.g. 5 bit counters).</p><p>In order to better predict this class of statistically biased branches, the Statistical Corrector predictor is introduced <ref type="bibr" target="#b23">[24]</ref>. The correc-tion aims at detecting the unlikely predictions and to revert them: the prediction and the (address, history) pair is presented to Statistical Corrector predictor which decides whether or not inverting the prediction (similar to the Agree predictor <ref type="bibr" target="#b26">[27]</ref>). Since in most cases the prediction provided by the TAGE predictor is correct, the Statistical Corrector predictor agrees most of the time with the TAGE predictor. Therefore a relatively small Statistical Corrector predictor performs close to an unlimited size Statistical Corrector predictor.</p><p>A quite efficient implementation of the Statistical Corrector predictor was derived from the GEHL predictor <ref type="bibr" target="#b20">[21]</ref>. It features 4 logical tables indexed with the 4 shortest history lengths (0, 6, 10, 17) as the main TAGE predictor and the prediction (Taken/Not taken) flowing out from the TAGE predictor. The tables are 1K 6-bit entries, i.e., a total of 24 Kbits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main (TAGE +IUM) Predictor</head><p>Stat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corr . ain</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6. The Statistical Corrector predictor</head><p>The prediction is computed as the sign of the sum of the (centered) predictions read on the Statistical Corrector table plus eight times the (centered) output of the hitting bank in TAGE. By centered predictions, we mean 2*ctr+1. Incorporating the prediction counter value from TAGE allows to take into account the confidence in the TAGE prediction <ref type="bibr" target="#b24">[25]</ref>. The TAGE prediction is reverted if the Statistical Corrector predictor disagrees and the absolute value of the sum is above a dynamic threshold. The dynamic threshold is adjusted at run-time in order to ensure that the use of the Statistical Corrector predictor is beneficial. The technique used to adapt the threshold is similar to the technique proposed for dynamically adapting the update threshold of the GEHL predictor <ref type="bibr" target="#b20">[21]</ref>.</p><p>When adding the Statistical Corrector predictor on top of the TAGE + IUM + loop predictor, a performance of 580 MPPKI is reached, i.e. approximately a 2 % reduction of the performance loss due to imperfect TAGE+IUM+loop predictor. Unrealistic tricks were used in <ref type="bibr" target="#b23">[24]</ref> to bring the performance to 568 MPPKI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">The ISL-TAGE Predictor Performance</head><p>Using side predictors of relatively small size, the ISL-TAGE predictor reduces the misprediction rate of the 512Kbits TAGE predictor by 6 % which is approximately the misprediction re-duction that would be obtained by scaling the TAGE predictor to 2Mbits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">TAGE-LSC: Adapting the Statistical Corrector Predictor to Local History</head><p>In many applications, there exist branches whose behaviors are only correlated with their own local history (loops, but also periodic behavior). Most of these behaviors are captured by the global history predictors, but some are not. Hybrid predictors combining local history and global history were introduced <ref type="bibr" target="#b15">[16]</ref> for capturing the best of global correlation and local correlation. However metapredictors were shown to be poorly efficient and new solutions combining local history and global history were proposed for neural based predictors <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b7">8]</ref>. Up to now, there has not been any elegant proposal to combine the global history TAGE predictor with some efficient local history predictor. The approach used for the Statistical Corrector Predictor can be adapted to offer such a solution as illustrated in Figure <ref type="figure">7</ref>. The structure of the Speculative Local History Manager is very similar to the Immediate Update Mimicker (one entry per inflight branch, associative search on inflight branches, . . . ). Therefore these two structures could be combined in a real hardware processor We found that using 5 tables featuring 1K 6-bit entries and history lengths (0,4, 10, 17, 31) on the LGEHL predictor and a small 32-entry direct-mapped local history table is sufficient to capture most of the local correlation that a 512 Kbits TAGE predictor does not capture on our benchmark set. In most cases, the LSC prediction just agrees with the TAGE prediction, but when it disagrees and above the threshold, it provides the correct prediction in more than 70 % of the cases.</p><p>The very small size of the required local history table can be explained by the observation that for most benchmarks a very small number of static branches (generally less than 10) represent the majority of the dynamic mispredictions on the TAGE predictor.</p><p>On top of the (TAGE + IUM + loop predictor + Statistical Corrector predictor), the LSC predictor allows to reach 555 MPPKI, thus nearly reducing misprediction rate by more than 4%. In practice, using the LSC predictor alone on top the TAGE+IUM predictor allows to reach 559 MPPKI, i.e. it captures most of the mispredictions that are captured the loop predictor and the Statistical Corrector predictor. A 30 Kbits LSC predictor reduces the performance loss due to imperfect prediction of the TAGE+IUM predictor by more than 8 %.</p><p>In order to get fair comparison with the ISL-TAGE <ref type="bibr" target="#b23">[24]</ref>, we adjusted the size of the TAGE-LSC predictor to 512 Kbits by simply reducing the size of Table <ref type="table">T7</ref> to 2K entries (thus saving 34K storage bits) in the reference predictor. We obtain 562 MMPKI against 581 MPPKI for a 512 Kbits ISL-TAGE predictor with similar structure (same TAGE predictor, 5 tables GEHL-like predictor for Statistical Corrector Predictor and loop predictor) and 568 MPPKI for the ISL-TAGE predictor presented at the 3rd CBP (16-component TAGE+ IUM+ Statistical Corrector predictor + loop predictor + costly tricks such as sharing/interleaving TAGE tagged tables, sharing/interleaving Statistical Corrector predictor tables and extensive search for the best set of history lengths).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance Evaluation of the TAGE-LSC Predictor</head><p>Many parameters can be varied in the TAGE-LSC (storage size, number of tables and history lengths).</p><p>As its parents TAGE and GEHL predictors, the TAGE-LSC predictor is very robust to the choice of the history lengths, for instance on a 512Kbits TAGE-LSC predictor, using a (3,300) history series lead to 575 MPPKI, the (4,1000) history series lead to 563 MPPKI, and the (8,5000) history series leads to 563 MPPKI.</p><p>Decreasing the number of the TAGE predictor tables has not a large impact. A 9-component TAGE-LSC predictor using (6,1000) history series achieves 566 MPPKI and a 6-component TAGE-LSC predictor using (6,500) history series achieves 583 MPPKI.</p><p>On Figure <ref type="figure" target="#fig_8">9</ref>, we illustrate the respective performance for TAGE predictors and TAGE+LSC predictors for size ranging from 128 Kbits to 32 Mbits. The simulations were run just by scaling the sizes of all the components by a power of two, no attempt to optimize other parameters was done. For both predictors, the performance reaches a plateau around 16-32Mbits. In fact for 39 out of the 40 benchmarks, it reaches the plateau well before 16-32 Mbits, but for CLIENT02 the misprediction rate suddenly falls at 2Mbits-8Mbits budget: most of the mispredictions are due to only 2 branches that have repetitive behaviors but with thousands of different patterns. The TAGE-LSC predictor exhibits more potential than the TAGE predictor. In the range of size of interest for hardware implementation, 128Kbits -512Kbits, the TAGE-LSC predictor performs consistently as a 4-8 larger TAGE predictor. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Comparisons with Alternative Branch Predictors</head><p>At the 3rd ChampionShip Branch Prediction, the FTL++ predictor <ref type="bibr" target="#b6">[7]</ref> and the OH-SNAP <ref type="bibr" target="#b13">[14]</ref> were respectively ranked 2nd and 3rd with respectively 581 MPPKI and 598 MPPKI. The configurations presented at the Championship have some features that are not realistically implementable. However both these predictors capture some correlations that are not captured by TAGE-LSC.</p><p>Both FTL++ and OH-SNAP are based on neural based techniques, respectively GEHL combined with LGEHL for FTL++ and piecewise linear <ref type="bibr" target="#b10">[11]</ref> combined with dynamic weight adaptation <ref type="bibr" target="#b0">[1]</ref> for OH-SNAP.</p><p>Both these predictors are significantly outperformed on the 33 most predictable benchmarks by both ISL-TAGE and TAGE-LSC: respectively 196 MPPKI for ISL-TAGE, 198 MPPKI for TAGE-LSC, 232 MPPKI for FTL++ and 254 MPPKI for OH-SNAP.</p><p>On the other hand, both FTL++ and OH-SNAP slightly outperform ISL-TAGE and TAGE-LSC on the 7 most unpredictable benchmarks as illustrated by Figure <ref type="figure" target="#fig_10">10</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Towards Cost-effective TAGE-LSC Predictor</head><p>In Section 4, we have shown that, at a marginal accuracy loss the TAGE predictor can be implemented using 4-way bank-interleaved single port memory components and that the predictor read at retire time can be avoided on correct predictions also at a marginal accuracy loss.</p><p>However the TAGE-LSC predictor features local history components which accuracy could be impaired when applying these optimizations. Therefore we run experiments with the TAGE-LSC predictor to assess the accuracy loss due applying the same complexity reduction to the local history components on the complete TAGE-LSC predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Bank interleaving</head><p>Using the bank-interleaving technique described in Section 4.3 on local history components can have two conjugated impacts on the prediction accuracy. First more entries are needed for mapping a single branch (up to four times), second more entries have to be trained, thus leading to more start-up mispredictions.</p><p>Using bank-interleaving on the 512 Kbits TAGE-LSC considered in the previous section revealed to be quite efficient even for the local history components apart for a single application trace CLIENT02. Doubling the number of entries in the local components was found to restored the accuracy on CLIENT02. In our experiments, we were able to define a 512 Kbits TAGE-LSC predictor using 4-way interleaved single-ported tables and achieving 569 MPPKI, i.e. an accuracy loss of 3 MPPKI due to interleaving on the local components (training impact), 2 MPPKI due to interleaving on the TAGE components and 2 MPPKI due to size reduction of some tables of TAGE to fit the 512 Kbits storage budget.</p><p>Evaluations with CACTI6.5 <ref type="bibr" target="#b18">[19]</ref> indicate that this interleaving allows to reduce the silicon area by approximately a factor 3.3 and to approximately halve the power consumption per predictor read access.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Eliminating the Read at Retire Time on Correct Predictions</head><p>In Section 4, we have shown that the second read at retire time can be avoided on the TAGE predictor when prediction is correct with limited impact on the predictor accuracy.</p><p>On top of the 4-way interleaved TAGE-LSC predictor considered above, applying this optimization on both the TAGE components and the LSC components does not degrade too much the accuracy, since 575 MPPKI is achieved. This accuracy loss is very limited (2 MPPKI) if the optimization is applied only applied only to the TAGE components. Eliminating the second read for correct predictions on the local history components has a slightly higher accuracy impact (4 MPPKI). Since silent updates represent the vast majority of updates and can be eliminated, the elimination of the read at retire time on correct prediction allows to nearly halves the energy consumption of the predictor on correct predictions.</p><p>On the other hand, completely eliminating the second read (Scenario [B] in Section 4) has as a much higher impact accuracy impact (599 MPPKI) and therefore is not recommended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>The TAGE predictor has often been considered as state-of-theart in conditional branch prediction in terms of prediction accuracy <ref type="bibr" target="#b0">[1]</ref>. Asserting confidence to predictions by TAGE has recently been shown to be simple and storage free <ref type="bibr" target="#b24">[25]</ref>. In this paper, we have further made the case for considering the TAGE predictor in real hardware processors through two directions: 1) reduction of its implementation cost and its energy consumption 2) improvement of its prediction accuracy.</p><p>On a processor, a prediction on a correct branch generates 3 predictor table accesses, read at prediction time, second read at retire time and write update at retire time. This normally leads to the use of multiport memory components for the branch predictor. We have shown that, on a real hardware implementation, the TAGE accuracy would not be significantly impaired by avoiding a systematic second read of the prediction tables at retire time for correct prediction. Combined with the elimination of silent updates, this leads to only 1.13 predictor tables accesses in average per retired branch. Furthermore, we have shown that it is possible to implement the TAGE predictor tables as bank-interleaved structures single-port banks, thus significantly reducing the silicon footprint of the predictor as well as its energy consumption.</p><p>We have also shown that to further improve TAGE predictor accuracy, TAGE can be augmented with (small) side predictors, each targeting a set of branches that are difficult to predict with TAGE. We have presented the Immediate Update Mimicker that tracks the inflight already executed but not retired branches and uses their result for correcting the predictions. The IUM allows to recover most of the mispredictions due to delayed updates. As already proposed for the L-TAGE <ref type="bibr" target="#b22">[23]</ref>, TAGE can be augmented with a loop predictor to correctly predict loops with constant iteration numbers. TAGE is very efficient at predicting the behavior of branches that are completely correlated with the path history even when this path is thousands of branches long. But TAGE fails at capturing branches that are not strongly biased but that are only statistically biased. To capture these statistical biases, we have introduced the Statistical Corrector Predictor. Relying on the use of wide counters, the Statistical Corrector predictor tracks these statistically correlated branches. These 3 side predictors were presented at the 3rd Championship Branch Prediction for the ISL-TAGE predictor <ref type="bibr" target="#b23">[24]</ref>. We have further extended this approach showing that the Statistical Corrector Predictor can be used to leverage local history to further improve the potential of the TAGE predictor. Furthermore,the LSC, Statistical Corrector predictor based on local history, dwarfs the benefits of the loop predictor and the global history Statistical Corrector and therefore makes a good case for the use of a TAGE-LSC predictor which combines a main TAGE predictor with IUM and a small LSC, Local history Statistical Corrector predictor.</p><p>Finally we have shown that the TAGE-LSC predictor is amenable to a cost-effective implementation at a marginal accuracy loss through exploiting bank-interleaved structures and avoiding the second read at retire time on correct predictions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Figure 1. The TAGE predictor synopsis: a base predictor is backed with several tagged predictor components indexed with increasing history lengths</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Example of a loop execution assuming a bimodal table with null prediction counter at the first iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 .</head><label>3</label><figDesc>[C]: reread the predictions at retire time for mispredicted branches only. Scenario [A] potentially leads to 3 accesses per branch prediction and systematically generates 2 reads for each retired branch. Scenario [B] generates at most one read and one write. Scenario [C] generates 2 read accesses only on mispredicted branches. Scenarii [B] and [C] necessitate that the values read on the predictor are propagated with the branch instruction in the pipeline and used at retire time.In practice for the first generation predictors such as gshare using a single table of prediction counters, the accuracy loss encountered in Scenario [B] is dramatic. On the 512 Kbits gshare, we respectively obtained[I] 944 MPPKI, [A] 970 MPPKI , [B] 1292 MPPKI , [C] 1011 MPPKI. Scenario [B]where the predictor table is only read at fetch time can not be considered as a solution for a real hardware implementation. Even Scenario [C] , rereading the predictor at retire time for mispredicted branches, leads to a quite significant accuracy loss.On predictors derived from neural-inspired predictors (perceptron, piecewise linear, OGEHL), the same phenomenon occurs as illustrated on the 520 Kbits GEHL predictor. The different scenarii lead to the following results : [I] 664 MPPKI , [A] 685 MPPKI , [B] 801 MPPKI, [C] 744 MPPKI. While the 3.5 % extra penalty due to delayed update is acceptable in Scenario [A] , the losses due to the use of old counter values on correct predictions (Scenarii [B] and [C]) are very large and cannot be considered for effective implementation. On the GEHL predictor, 13 counters are involved in a prediction. In particular when the same branch has several inflight occurrences, the prediction counters associated with the short histories are not correctly incremented or decremented.For the TAGE predictor, the accuracy loss phenomenon is much less pronounced: [I] 609 MPPKI, [A] 617MPPKI, [B] 640 MPPKI, [C] 625 MPPKI. On TAGE, on correct predictions, only one or two TAGE entries are involved in a prediction and its update. On a correct prediction, in Scenarii [B] and [C] , the update will use old prediction counter values only if the provider component and entry was updated by an already inflight branch at prediction time. Moreover, at the difference of the neural inspired predictors, the amplitude of the prediction counters is limited.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>if (Z is unconditional) b(Z) = -1 ; /*i.e. no access*/ else {b(Z) = Z &amp; 3; while ((b(Z) == b(X)) || (b(Z) == b(Y)) b(Z) = (b(Z) +1) &amp; 3;}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>[A], 611 MPPKI vs Scenario [I] 609 MPPKI). For Scenario [B], prediction tables are read only at fetch time, half of the mispredictions due to delayed updates are recovered (624 MPPKI) while for Scenario [C] where prediction tables are reread only on mispredictions, the accuracy loss is limited (614 MPPKI).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The Immediate Update Mimicker: when the prediction is provided by the same entry and the same component as an already executed inflight branch, use the outcome of the branch instead of the TAGE prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The loop predictor and the Speculative Loop Iteration Management: use of the non-speculative iteration number or of the iteration number of the most recent inflight iteration.</figDesc><graphic url="image-75.png" coords="7,389.09,189.14,91.22,52.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>6. 1 Figure 7 .Figure 8 .</head><label>178</label><figDesc>Figure 7. The TAGE-LSC predictor combines a TAGE predictor and a Local history Statistical Corrector Predictor</figDesc><graphic url="image-164.png" coords="8,331.67,471.80,58.82,51.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. TAGE vs.TAGE-LSC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>: respectively 2311 MPPKI for ISL-TAGE, 2287 MPPKI for TAGE-LSC, 2222 MPPKI for FTL++ and 2227 MPPKI for OH-SNAP. Understanding the intrinsic auto-and inter-correlation properties that are better captured by FTL++ and/or OH-SNAP than TAGE-LSC might lead to further progress in branch prediction research.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Prediction accuracy on the 7 less predictable benchmarks</figDesc></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* This work was partially supported by the European Research Council Advanced Grant DAL No 267175</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Low-power, high-performance analog neural branch prediction</title>
		<author>
			<persName><forename type="first">Renée</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Amant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="447" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sepas: a highly accurate energy-efficient branch predictor</title>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Baniasadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISLPED</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="38" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The YAGS branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual International Symposium on Microarchitecture</title>
				<meeting>the 31st Annual International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1998-12">Dec 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using hybrid branch predictors to improve branch prediction accuracy in the presence of context switches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Evers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International Symposium on Computer Architecture</title>
				<meeting>the 23rd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Address-branch correlation: A novel locality for long-latency hard-to-predict branches</title>
		<author>
			<persName><forename type="first">Hongliang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiyang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="74" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive information processing: An effective way to improve perceptron predictors</title>
		<author>
			<persName><forename type="first">Hongliang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiyang</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="http://www.jilp.org/vol7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction Level Parallelism</title>
		<imprint>
			<date type="published" when="2005-04">April 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Revisiting local history for improving fused two-level branch predictor</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kuroyanagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hiraki</surname></persName>
		</author>
		<ptr target="http://www.jilp.org/jwac-2/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Championship on Branch Prediction</title>
				<meeting>the 3rd Championship on Branch Prediction</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fused two-level branch prediction with ahead calculation</title>
		<author>
			<persName><forename type="first">Yasuo</forename><surname>Ishii</surname></persName>
		</author>
		<ptr target="http://wwwjilp.org/vol9" />
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction Level Parallelism</title>
		<imprint>
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast path-based neural branch prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jimenez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 36th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2003-12">dec 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reconsidering complex branch predictors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Symposium on High Perform ance Computer Architecture</title>
				<meeting>the 9th International Symposium on High Perform ance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Piecewise linear branch prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual International Symposium on Computer Architecture</title>
				<meeting>the 32nd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2005-06">june 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The impact of delay on the design of branch predictors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual International Symposium on Microarchitecture</title>
				<meeting>the 33rd Annual International Symposium on Microarchitecture<address><addrLine>Monterey, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-12">December 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic branch prediction with perceptrons</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Symposium on High Perform ance Computer Architecture</title>
				<meeting>the Seventh International Symposium on High Perform ance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Oh-snap: Optimized hybrid scaled neural analog predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><surname>Jiménez</surname></persName>
		</author>
		<ptr target="http://www.jilp.org/jwac-2/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Championship on Branch Prediction</title>
				<meeting>the 3rd Championship on Branch Prediction</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting conditional branches with fusion-based hybrid predictors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Henry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Conference on Parallel Architectures and Compilation Techniques</title>
				<meeting>the 11th Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Combining branch predictors. TN 36, DEC WRL</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcfarling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Trading conflict and capacity aliasing in conditional branch predictors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Uhlig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture (ISCA-97)</title>
				<meeting>the 24th Annual International Symposium on Computer Architecture (ISCA-97)</meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A PPM-like, tag-based predictor</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Michaud</surname></persName>
		</author>
		<ptr target="http://www.jilp.org/vol7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction Level Parallelism</title>
		<imprint>
			<date type="published" when="2005-04">April 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Cacti 6.0: A tool to model large caches</title>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Muralimanohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<idno>hpl-2009-85</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>HP Laboratories</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Research report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving the accuracy of dynamic branch prediction using branch correlation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Rahmeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the 5th International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Analysis of the O-GEHL branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual International Symposium on Computer Architecture</title>
				<meeting>the 32nd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2005-06">june 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Design tradeoffs for the ev8 branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sazeidès</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Computer Architecture</title>
				<meeting>the 29th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The L-TAGE branch predictor</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
		<ptr target="http://wwwjilp.org/vol9" />
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction Level Parallelism</title>
		<imprint>
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A 64 kbytes ISL-TAGE branch predictor</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Championship Branch Prediction</title>
				<meeting>the 3rd Championship Branch Prediction</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Storage Free Confidence Estimation for the TAGE branch predictor</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE Symposium on High-Performance Computer Architecture (HPCA 2011)</title>
				<meeting>the 17th IEEE Symposium on High-Performance Computer Architecture (HPCA 2011)</meeting>
		<imprint>
			<date type="published" when="2011-02">Feb 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A case for (partially)-tagged geometric history length predictors</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Michaud</surname></persName>
		</author>
		<ptr target="http://www.jilp.org/vol8" />
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction Level Parallelism</title>
		<imprint>
			<date type="published" when="2006-04">April 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The agree predictor: A mechanism for reducing negative branch history interference</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sprangle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Chappell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alsup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24 th Annual International Symposium on Computer Architecture</title>
				<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Two-level adaptive branch prediction</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Symposium on Microarchitecture</title>
				<meeting>the 24th International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1991-11">Nov. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
