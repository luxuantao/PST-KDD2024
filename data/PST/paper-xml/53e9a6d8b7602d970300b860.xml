<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Analysis on delay-dependent stability for neural networks with time-varying delays</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-10-24">24 October 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Kwon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering</orgName>
								<orgName type="institution">Chungbuk National University</orgName>
								<address>
									<addrLine>52 Naesudong-ro, Heungduk-gu</addrLine>
									<postCode>361-763</postCode>
									<settlement>Cheongju</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ju</forename><forename type="middle">H</forename><surname>Park</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Yeungnam University</orgName>
								<address>
									<addrLine>214-1 Dae-Dong</addrLine>
									<postCode>712-749</postCode>
									<settlement>Kyongsan</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Electronic Engineering</orgName>
								<orgName type="institution">Daegu University</orgName>
								<address>
									<postCode>712-714</postCode>
									<settlement>Gyungsan</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Cha</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">Chungbuk National University</orgName>
								<address>
									<addrLine>52 Naesudong-ro, Heungduk-gu</addrLine>
									<postCode>361-763</postCode>
									<settlement>Cheongju</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Analysis on delay-dependent stability for neural networks with time-varying delays</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-10-24">24 October 2012</date>
						</imprint>
					</monogr>
					<idno type="MD5">706F6E39A611396AC4C166B46F8CF5A9</idno>
					<idno type="DOI">10.1016/j.neucom.2012.09.012</idno>
					<note type="submission">Received 4 May 2012 Received in revised form 22 August 2012 Accepted 14 September 2012 Communicated by S. Arik</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Neural networks Time-varying delays Stability Lyapunov method</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper considers the problem of delay-dependent stability criteria for neural networks with timevarying delays. First, by constructing a newly augmented Lyapunov-Krasovskii functional, a less conservative stability criterion is established in terms of linear matrix inequalities (LMIs). Second, by proposing a novel activation function condition which has not been considered, a further improved result is proposed. Finally, two numerical examples utilized in other literature are given to show the improvements over the existing ones and the effectiveness of the proposed idea.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the past few decades, neural networks have been widely applied to various fields such as load frequency control in power systems <ref type="bibr" target="#b0">[1]</ref>, pattern recognition <ref type="bibr" target="#b1">[2]</ref>, finance <ref type="bibr" target="#b2">[3]</ref>, associative memories <ref type="bibr" target="#b3">[4]</ref>, mechanics of structures and materials <ref type="bibr" target="#b4">[5]</ref>, smart antenna arrays <ref type="bibr" target="#b5">[6]</ref>, and other scientific areas <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>. Therefore, neural networks play important roles in many practical systems. Since the key feature of these applications with neural networks is that the equilibrium points of the designed network are stable, stability analysis of neural network is a prerequisite and an important work. In the implementation of neural networks, time delays naturally occur due to the finite switching speed of amplifies and may cause some sophisticated dynamical behaviors such as instability or oscillation of neural networks <ref type="bibr" target="#b12">[13]</ref>. Therefore, delay-dependent stability analysis of neural networks with time-delays has been extensively investigated <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref> since it is well known that delay-dependent stability criteria are generally less conservative than delay-independent ones when the sizes of time-delays are small.</p><p>The main aim of delay-dependent stability analysis is to get maximum delay bounds such that the designed networks are asymptotically stable for any delay less than maximum delay bounds. For the case of time-varying delays, maximum delay bounds for guaranteeing the asymptotic stability of the networks in <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref> were investigated for different upper bounds of derivative of time-varying delays. Thus, how to construct Lyapunov-Krasovskii functional and estimate an upper bound of timederivative of it play key roles to increase delay bounds. Recently, since a delay-partitioning idea was firstly proposed in <ref type="bibr" target="#b30">[31]</ref>, it is well recognized that the delay-partitioning approach can reduce the conservatism of stability criteria. One of the main advantages of this method can obtain more tighter upper bounds obtained by calculating the time-derivative of Lyapunov-Krasovskii functional, which leads to less conservative results. However, when the number of delay-partitioning number increases, the matrix formulation becomes more complex and the computational burden and time-consumption grow bigger.</p><p>In this regard, many researchers <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref> have been studied the delay-partitioning method for delay-dependent stability criteria of neural networks with time-delays. In <ref type="bibr" target="#b23">[24]</ref>, by utilizing different free-weighting matrices in two delay subintervals, a piecewise delay method which is the same concept of two delaypartitioning approaches was proposed for the stability analysis of delayed neural networks. Xiao and Zhang <ref type="bibr" target="#b26">[27]</ref> also studied the stability analysis for uncertain delayed neural networks by taking delay-partitioning number as two. Recently, in <ref type="bibr" target="#b27">[28]</ref>, the weighting-delay-based stability criteria for neural networks with time-varying delay were investigated by proposing the idea of dividing the delay interval by the weighted parameters. Very recently, new delay-derivative-dependent stability criteria for neural networks with unbounded distributed delay and discrete time-varying delays were presented in <ref type="bibr" target="#b28">[29]</ref> by introducing an improved delay-partitioning technique and general convex combination. Further improved versions of the method <ref type="bibr" target="#b28">[29]</ref> were introduced in <ref type="bibr" target="#b29">[30]</ref>. However, in spite of such extensive researches mentioned above, there are still rooms for further improvements of the stability criteria.</p><p>In this paper, the problem of delay-dependent stability analysis for neural networks with time-varying delays is investigated. Unlike the method of <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>, no delay-partitioning methods are utilized. Instead, by taking more information about states and activation functions as augmented vectors, an augmented Lyapunov-Krasovskii's functional is proposed. Then, inspired by the work of <ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>, a sufficient condition such that the considered neural networks are asymptotically stable is derived in terms of linear matrix inequalities (LMIs) which will be presented in Theorem 1. And, with the same Lyapunov-Krasovskii's functional considered, a new activation function condition which has not been considered yet in other literature is proposed and utilized in Theorem 2 to reduce the conservatism of stability criterion. Through two numerical examples utilized in other literature, it will be shown that the proposed stability criteria can provide larger delay bounds than the results of <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref> in spite of not employing delay-partitioning approaches.</p><p>Notation: Throughout this paper, R n denotes n-dimensional Euclidean space and R nÂm is the set of all n Â m real matrices. For symmetric matrices X and Y, the notation X 4 Y (respectively, X Z Y) means that the matrix XÀY is positive definite (respectively, nonnegative). diagfÁ Á Ág denotes the block diagonal matrix.</p><p>% represents the elements below the main diagonal of a symmetric matrix. The subscript 'T' denotes the transpose of the matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem statement</head><p>Consider the following neural networks with time-varying delays:</p><formula xml:id="formula_0">_ yðtÞ ¼ ÀAyðtÞþW 0 gðyðtÞÞ þW 1 gðyðtÀhðtÞÞÞ þb,<label>ð1Þ</label></formula><p>where yðtÞ ¼ ½y  The delay, h(t), is a time-varying continuous function satisfying</p><formula xml:id="formula_1">A R n , A ¼ diagfa i g A R nÂn is a positive diagonal matrix, W 0 ¼ ðw 0 ij Þ nÂn A R nÂn and W 1 ¼ ðw 1 ij Þ nÂn A R</formula><formula xml:id="formula_2">0 r hðtÞ r h U , À1 o _ hðtÞ r h D ,<label>ð2Þ</label></formula><p>where h U 40 and h D are known constant scalar values. The activation functions, g i ðy i ðtÞÞ, i ¼ 1, . . . ,n, are assumed to be bounded and hold the following condition:</p><formula xml:id="formula_3">k À i r g i ðuÞÀg i ðvÞ uÀv r k þ i , u, v A R, u a v, i ¼ 1, . . . ,n,<label>ð3Þ</label></formula><p>where k þ i and k À i are constants. For simplicity, in stability analysis of the neural networks (1), the equilibrium point y n ¼ ½y n 1 , . . . ,y n n T whose uniqueness has been reported in <ref type="bibr" target="#b7">[8]</ref> is shifted to the origin by utilizing the transformation xðÁÞ ¼ yðÁÞÀy n , which leads the system (1) to the following form:</p><formula xml:id="formula_4">_ xðtÞ ¼ ÀAxðtÞþW 0 f ðxðtÞÞ þW 1 f ðxðtÀhðtÞÞÞ<label>ð4Þ</label></formula><p>where xðtÞ ¼ ½x 1 ðtÞ, . . . ,x n ðtÞ T A R n is the state vector of the transformed system, f ðxðtÞÞ ¼ ½f 1 ðx 1 ðtÞÞ, . . . ,f n ðx n ðtÞÞ T and f j ðx j ðtÞÞ ¼ g j ðx j ðtÞþy n j ÞÀg j ðy n j Þ with f j ð0Þ ¼ 0ðj ¼ 1, . . . ,nÞ. It should be noted that the activation functions f i ðÁÞ ði ¼ 1, . . . ,nÞ satisfy the following condition <ref type="bibr" target="#b8">[9]</ref>:</p><formula xml:id="formula_5">k À i r f i ðuÞÀf i ðvÞ uÀv rk þ i , u, v A R, u av, i ¼ 1, . . . ,n:<label>ð5Þ</label></formula><p>If v ¼0 in ( <ref type="formula" target="#formula_5">5</ref>), then we have</p><formula xml:id="formula_6">k À i r f i ðuÞ u rk þ i 8 u a0, i ¼ 1, . . . ,n,<label>ð6Þ</label></formula><p>which is equivalent to</p><formula xml:id="formula_7">½f i ðuÞÀk À i u½f i ðuÞÀk þ i u r 0, i ¼ 1, . . . ,n:<label>ð7Þ</label></formula><p>The objective of this paper is to investigate the delay dependent stability analysis of system (4) which will be conducted in Section 3. Before deriving our main results, we state the following lemmas.</p><p>Lemma 1. For any constant positive-definite matrix M A R nÂn and arb, the following inequalities hold:</p><formula xml:id="formula_8">ðaÀbÞ Z a b _ x T ðsÞM _ xðsÞ dsZ Z a b _ xðsÞ ds T M Z a b _ xðsÞ ds ,<label>ð8Þ</label></formula><formula xml:id="formula_9">ðaÀbÞ 2 2 Z a b Z a s _ x T ðuÞM _ xðuÞ du ds Z Z a b Z a s _ xðuÞ du ds T M Z a b Z a s _ xðuÞu ds :<label>ð9Þ</label></formula><p>Proof. According to Jensen's inequality in <ref type="bibr" target="#b34">[35]</ref>, one can obtain <ref type="bibr" target="#b7">(8)</ref>. Moreover, the following inequality holds:</p><formula xml:id="formula_10">ðaÀsÞ Z a s _ x T ðuÞM _ xðuÞ du Z Z a s _ xðuÞ du T M Z a s _ xðuÞ du :<label>ð10Þ</label></formula><p>By Schur Complements <ref type="bibr" target="#b35">[36]</ref>, Eq. ( <ref type="formula" target="#formula_10">10</ref>) is equivalent to the following:</p><formula xml:id="formula_11">R a s _ x T ðuÞM _ xðuÞ du R a s _ x T ðuÞ du R a s _ xðuÞ du ðaÀsÞM À1 2 4 3 5 Z 0:<label>ð11Þ</label></formula><formula xml:id="formula_12">Integration of (11) from b to a yields R a b R a s _ x T ðuÞM _ xðuÞ du ds R a b R a s _ x T ðuÞ du ds R a b R a s _ xðuÞ du ds R a b ðaÀsÞM À1 ds 2 4 3 5 Z0:<label>ð12Þ</label></formula><p>Therefore, the inequality ( <ref type="formula" target="#formula_12">12</ref>) is equivalent to the inequality (9) according to Schur Complements. This completes the proof. &amp; Lemma 2 (Skelton et al. <ref type="bibr" target="#b36">[37]</ref>). Let zAR n , F ¼ F T A R nÂn , and B A R mÂn such that rankðBÞ on. Then, the following statements are equivalent:</p><p>(1) z T Fzo0, Bz ¼ 0, za0, (2) ðB ? Þ T FB ? o0, where B ? is a right orthogonal complement of B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Main results</head><p>In this section, by use of augmented Lyapunov-Krasovskii functionals, new delay-dependent stability criteria for systems (4) will be proposed. For the sake of simplicity of matrix representation, e i ði ¼ 1, . . . ,12Þ A R 12nÂn are defined as block entry matrices. (For example, e T 3 ¼ ½0, 0, I, 0, 0, 0, 0, 0, 0, 0, 0, 0).</p><p>The notations for some matrices are defined as </p><formula xml:id="formula_13">zðtÞ ¼ x T ðtÞ, x T ðtÀhðtÞÞ, x T ðtÀh U Þ, _ x T ðtÞ, _ x T ðtÀh U Þ, Z t</formula><formula xml:id="formula_14">C ¼ h U e 1 Q 4 e T 1 þh U e 4 Q 5 e T 4 þe 1 P 1 e T 1 þe 2 ðÀP 1 þ P 2 Þe T 2 Àe 3 P 2 e T 3 , Y ¼ À2e 1 K m H 1 K p e T 1 þe 1 ðK m þ K p ÞH 1 e T 8 þe 8 H 1 ðK m þK p Þe T 1 À2e 8 H 1 e T 8 À2e 2 K m H 2 K p e T 2 þ e 2 ðK m þ K p ÞH 2 e T 9 þ e 9 H 2 ðK m þ K p Þe T 2 À2e 9 H 2 e T 9 À2e 3 K m H 3 K p e T 3 þ e 3 ðK m þK p ÞH 3 e T 10 þ e 10 H 3 ðK m þ K p Þe T 3 À2e 10 H 3 e T 10 , S 1 ¼ FþXþCþYþP 1 RP T 2 þ P 2 RP T 1 þP 3 N P T 3 ÀP 4 N P T 4 þ P 5 QP T 5 Àð1Àh D ÞP 6 QP T 6 þh 2 U P 3 GP T 3 ÀP 7 G S % G " # P T 7 :<label>ð13Þ</label></formula><p>Now, we have following theorem.</p><p>Theorem 1. For given scalars h U 4 0 and h D , diagonal matrices</p><formula xml:id="formula_15">K p ¼ diagfk þ 1 , . . . ,k þ n g and K m ¼ diagfk À 1 , . . . ,k</formula><p>À n g, the system (4) is asymptotically stable for 0 r hðtÞ r h U and _ hðtÞ rh D if there exist positive diagonal matrices L ¼ diagfl 1 , . . . ,l n g, D ¼ diagfd 1 , . . . ,d n g,</p><formula xml:id="formula_16">H i ¼ diagfh i1 , . . . ,h in g ði ¼ 1,2,3Þ, positive definite matrices R ¼ ½R ij 4Â4 A R 4nÂ4n , N ¼ ½N ij 3Â3 A R 3nÂ3n , Q ¼ ½Q ij 2Â2 A R 2nÂ2n , G ¼ ½G ij 3Â3 A R 3nÂ3n , Q i ði ¼ 3,4</formula><p>,5Þ, any symmetric matrices P i ði ¼ 1,2Þ, and any matrix S ¼ ½S ij 3Â3 A R 3nÂ3n , satisfying the following LMIs:</p><formula xml:id="formula_17">ðG ? Þ T fS 1 gG ? o0,<label>ð14Þ</label></formula><formula xml:id="formula_18">G S % G " # 40,<label>ð15Þ</label></formula><formula xml:id="formula_19">Q 4 P 1 % Q 5 " # 40,<label>ð16Þ</label></formula><formula xml:id="formula_20">Q 4 P 2 % Q 5 " # 40,<label>ð17Þ</label></formula><p>where S 1 and G are defined in <ref type="bibr" target="#b12">(13)</ref>, and G ? is the right orthogonal complement of G.</p><p>Proof. For positive diagonal matrices L, D and positive definite matrices R, N , Q, G, Q i ði ¼ 3,4,5Þ, let us consider the following Lyapunov-Krasovskii's functional candidate ,</p><formula xml:id="formula_21">V ¼ P 6 i ¼ 1 V i , where V 1 ¼ xðtÞ xðtÀh U Þ R t</formula><formula xml:id="formula_22">V 2 ¼ Z t tÀh U</formula><p>a T ðsÞN aðsÞ dsþ 2</p><formula xml:id="formula_23">X n i ¼ 1 l i Z x i<label>ðtÞ</label></formula><formula xml:id="formula_24">0 ðf i ðsÞÀk À i sÞ ds þd i Z x i<label>ðtÞ</label></formula><formula xml:id="formula_25">0 ðk þ i sÀf i ðsÞÞ ds , V 3 ¼ Z t tÀhðtÞ bðsÞ T QbðsÞ ds, V 4 ¼ h U Z t tÀh U Z t s a T ðuÞGaðuÞ du ds, V 5 ¼ ðh 2 U =2Þ Z t tÀhU Z t s Z t u _ x T ðvÞQ 3 _ xðvÞ dv du ds, V 6 ¼ Z t tÀhU Z t s x T ðuÞQ 4 xðuÞ du ds þ Z t tÀhU Z t s _ x T ðuÞQ 5 _ xðuÞ du ds:<label>ð18Þ</label></formula><p>The time-derivative of V 1 is calculated as </p><formula xml:id="formula_26">_ V 1 ¼ 2 xðtÞ xðtÀh U Þ R t</formula><formula xml:id="formula_27">¼ z T ðtÞ ðP 1 RP T 2 þ P 2 RP T 1 ÞzðtÞ:<label>ð19Þ</label></formula><p>By calculation of _ V 2 , we have</p><formula xml:id="formula_28">_ V 2 ¼ a T ðtÞN aðtÞÀa T ðtÀh U ÞN aðtÀh U Þþ2 f ðxðtÞÞÀK m xðtÞ Â Ã T L _ xðtÞ þ2½K p xðtÞÀf ðxðtÞÞ T D _ xðtÞ ¼ z T ðtÞðP 3 N P T 3 ÀP 4 N P T 4 þFÞzðtÞ:<label>ð20Þ</label></formula><p>With the condition _ hðtÞ r h D , an upper bound of V 3 is obtained as</p><formula xml:id="formula_29">_ V 3 r z T ðtÞ½P 5 QP T 5 Àð1Àh D ÞP 6 QP T 6 zðtÞ:<label>ð21Þ</label></formula><p>By use of Lemma 1 and Theorem 1 in <ref type="bibr" target="#b32">[33]</ref>, an estimation of _ V 4 is </p><formula xml:id="formula_30">_ V 4 ¼ h 2 U a T ðtÞGaðtÞÀh U Z t</formula><p>For the detailed proof of Eq. ( <ref type="formula" target="#formula_31">22</ref>), see <ref type="bibr" target="#b37">[38]</ref>. By Lemma 1, _ V 5 is bounded as</p><formula xml:id="formula_32">_ V 5 ¼ ðh 2 U =2Þ 2 _ x T ðtÞQ 3 _ xðtÞÀðh 2 U =2Þ Z t tÀhU Z t s _ x T ðuÞQ 3 _ xðuÞ du ds r ðh 2 U =2Þ 2 _ x T ðtÞQ 3 _ xðtÞÀ Z t tÀhU Z t s _ xðuÞ du ds T Q 3 Â Z t tÀhU Z t s _ xðuÞ du ds ¼ z T ðtÞXzðtÞ:<label>ð23Þ</label></formula><formula xml:id="formula_33">Calculation of _ V 6 leads to _ V 6 ¼ h U x T ðtÞQ 4 xðtÞÀ Z t tÀhU x T ðsÞQ 4 xðsÞ ds þh U _ x T ðtÞQ 5 _ xðtÞÀ Z t tÀhU _ x T ðsÞQ 5 _ xðsÞ ds:<label>ð24Þ</label></formula><p>Inspired by the work of <ref type="bibr" target="#b33">[34]</ref>, the following two zero equalities with any symmetric matrices P 1 and P 2 are considered:</p><formula xml:id="formula_34">0 ¼ x T ðtÞP 1 xðtÞÀx T ðtÀhðtÞÞP 1 xðtÀhðtÞÞÀ2 Z t tÀhðtÞ x T ðsÞP 1 _ xðsÞ ds, 0 ¼ x T ðtÀhðtÞÞP 2 xðtÀhðtÞÞÀx T ðtÀh U ÞP 2 xðtÀh U Þ À2 Z tÀhðtÞ tÀhU x T ðsÞP 2 _ xðsÞ ds:<label>ð25Þ</label></formula><p>With the above two zero equalities, an upper bound of _ V 6 is </p><formula xml:id="formula_35">_ V 6 rz T<label>ðtÞCzðtÞ</label></formula><formula xml:id="formula_36">0 r À2 X n i ¼ 1 h 1i ½f i ðx i ðtÞÞÀk À i x i ðtÞ½f i ðx i ðtÞÞÀk þ i x i ðtÞ À2 X n i ¼ 1 h 2i ½f i ðx i ðtÀhðtÞÞÞÀk À i x i ðtÀhðtÞÞ½f i ðx i ðtÀhðtÞÞÞ Àk þ i x i ðtÀhðtÞÞ À2 X n i ¼ 1 h 3i ½f i ðx i ðtÀh U ÞÞÀk À i x i ðtÀh U Þ½f i ðx i ðtÀh U ÞÞÀk þ i x i ðtÀh U Þ ¼ z T ðtÞYzðtÞ:<label>ð27Þ</label></formula><p>From Eqs. ( <ref type="formula" target="#formula_25">18</ref>)-( <ref type="formula" target="#formula_36">27</ref>) and by application of S-procedure <ref type="bibr" target="#b35">[36]</ref>, if Eqs. ( <ref type="formula" target="#formula_19">16</ref>) and ( <ref type="formula" target="#formula_20">17</ref>) hold, then an upper bound of _ V is</p><formula xml:id="formula_37">_ V r z T ðtÞS 1 zðtÞ,<label>ð28Þ</label></formula><p>where S 1 are defined in <ref type="bibr" target="#b12">(13)</ref>. By Lemma 2, z T ðtÞS 1 zðtÞo0 with 0 ¼ GzðtÞ is equivalent to ðG ? Þ T S 1 G ? o 0. Therefore, if LMIs ( <ref type="formula" target="#formula_17">14</ref>)-( <ref type="formula" target="#formula_20">17</ref>) hold, then the neural networks ( <ref type="formula" target="#formula_4">4</ref>) is asymptotically stable. This completes the proof. &amp; Remark 1. In Theorem 1, the augmented vector zðtÞ has integrating terms of activation function f ðxðtÞÞ which are R t tÀhðtÞ f ðxðsÞÞ ds and R tÀhðtÞ tÀhU f ðxðsÞÞ ds. By these terms, more past history of f ðxðtÞÞ can be utilized, which may lead less conservative results.</p><p>Remark 2. Recently, the reciprocally convex optimization technique to reduce the conservatism of stability criteria for systems with time-varying delays was proposed in <ref type="bibr" target="#b32">[33]</ref>. Motivated by this work, the proposed method of <ref type="bibr" target="#b32">[33]</ref> was utilized in Eq. ( <ref type="formula" target="#formula_31">22</ref>). However, an augmented vector with R t tÀhðtÞ xðsÞ ds, R tÀhðtÞ tÀhU xðsÞ ds, R t tÀhðtÞ f ðxðsÞÞ ds, R tÀhðtÞ tÀhU f ðxðsÞÞ ds was used, which is different from the method of <ref type="bibr" target="#b32">[33]</ref>.</p><p>Next, based on the results of Theorem 1, a further improved stability criterion for system (1) will be introduced as Theorem 2 by utilizing new activation condition which has not been proposed yet.</p><p>Theorem 2. For given scalars h U 4 0 and h D , diagonal matrices</p><formula xml:id="formula_38">K p ¼ diagfk þ 1 , . . . ,k þ n g and K m ¼ diagfk À 1 , . . . ,k</formula><p>À n g, the system (4) is asymptotically stable for 0 r hðtÞ r h U and _ hðtÞ rh D if there exist</p><formula xml:id="formula_39">positive diagonal matrices L ¼ diagfl 1 , . . . ,l n g, D ¼ diagfd 1 , . . . ,d n g, H i ¼ diagfh i1 , . . . ,h in g ði ¼ 1, . . . ,5Þ, positive definite matrices R ¼ ½R ij 4Â4 A R 4nÂ4n , N ¼ ½N ij 3Â3 A R 3nÂ3n , Q ¼ ½Q ij 2Â2 A R 2nÂ2n , G ¼ ½G ij 3Â3 A R 3nÂ3n , Q i ði ¼ 3,4</formula><p>,5Þ, any symmetric matrices P i ði ¼ 1,2Þ, and any matrix S ¼ ½S ij 3Â3 A R 3nÂ3n , satisfying the following LMIs:</p><formula xml:id="formula_40">ðG ? Þ T fS 1 þ OgG ? o 0,<label>ð29Þ</label></formula><formula xml:id="formula_41">G S % G " # 4 0,<label>ð30Þ</label></formula><formula xml:id="formula_42">Q 4 P 1 % Q 5 " # 4 0,<label>ð31Þ</label></formula><formula xml:id="formula_43">Q 4 P 2 % Q 5 " # 4 0,<label>ð32Þ</label></formula><p>where S 1 , G are defined in (13), G ? is the right orthogonal complement of G, and O is defined as </p><formula xml:id="formula_44">O ¼</formula><p>Proof. From ( <ref type="formula" target="#formula_5">5</ref>), the following conditions hold:</p><formula xml:id="formula_46">k À i r f i ðx i ðtÞÞÀf i ðx i ðtÀhðtÞÞÞ x i ðtÞÀx i ðtÀhðtÞÞ r k þ i , k À i r f i ðx i ðtÀhðtÞÞÞÀf j ðx i ðtÀh U ÞÞ x i ðtÀhðtÞÞÀx i ðtÀh U Þ rk þ i , i ¼ 1, . . . ,n:<label>ð34Þ</label></formula><p>For i ¼ 1, . . . ,n, the above two conditions are equivalent to</p><formula xml:id="formula_47">½f i ðx i ðtÞÞÀf i ðx i ðtÀhðtÞÞÀk À i ðx i ðtÞÀx i ðtÀhðtÞÞÞ Â½f i ðx i ðtÞÞÀf i ðx i ðtÀhðtÞÞÞÀk þ i ðx i ðtÞÀx i ðtÀhðtÞÞÞ r0,<label>ð35Þ</label></formula><formula xml:id="formula_48">½f i ðx i ðtÀhðtÞÞÞÀf i ðx i ðtÀh U ÞÞÀk À i ðx i ðtÀhðtÞÞÀx i ðtÀh U ÞÞ Â½f i ðx i ðtÀhðtÞÞÞÀf i ðx i ðtÀh U ÞÞÀk þ i ðx i ðtÀhðtÞÞÀx i ðtÀh U ÞÞ r0:<label>ð36Þ</label></formula><p>Therefore, for any positive diagonal matrices H 4 ¼ diagfh 4i , . . . ,h 4n g and H 5 ¼ diagfh 5i , . . . ,h 5n g, the following inequality holds 0 r À2</p><formula xml:id="formula_49">X n i ¼ 1 fh 4i ½f i ðx i ðtÞÞÀf i ðx i ðtÀhðtÞÞÞÀk À i ðx i ðtÞÀx i ðtÀhðtÞÞÞ Â½f i ðx i ðtÞÞÀf i ðx i ðtÀhðtÞÞÞÀk þ i ðx i ðtÞÀx i ðtÀhðtÞÞÞg À2 X n i ¼ 1 fh 5i ½f i ðx i ðtÀhðtÞÞÞÀf i ðx i ðtÀh U ÞÞÀk À i ðx i ðtÀhðtÞÞÀx i ðtÀh U ÞÞ Â½f i ðx i ðtÀhðtÞÞÞÀf i ðx i ðtÀh U ÞÞÀk þ i ðx i ðtÀhðtÞÞÀx i ðtÀh U ÞÞg ¼ z T ðtÞOzðtÞ:<label>ð37Þ</label></formula><p>By the consideration of Eq. ( <ref type="formula" target="#formula_49">37</ref>) and the same Lyapunov-Krasovskii's functional <ref type="bibr" target="#b17">(18)</ref>, the other procedure is straightforward from the proof of Theorem 1, so we omit it. &amp; Remark 3. In many works <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>, the condition of ( <ref type="formula" target="#formula_6">6</ref>) was utilized to reduce the conservatism of stability criteria. However, the condition of Eq. ( <ref type="formula" target="#formula_49">37</ref>) in Theorem 2 is proposed for the first time in this work. Through two numerical examples in checking the conservatism of delay-dependent stability criteria for system (4), it will be shown that the newly proposed activation condition significantly improves the feasible region of stability criteria by comparing maximum delay bounds which are one of important index for checking the conservatism of stability criteria.</p><p>Remark 4. When the information of an upper bound of _ hðtÞ is unknown or larger than one, Theorems 1 and 2 also provide delay-dependent stability criteria for (4) by letting Q ¼ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Numerical examples</head><p>In this section, two numerical examples which utilized in other works to check the conservatism of stability criteria are utilized to show the improvements on the feasible regions of the proposed stability criteria. To do this, MATLAB, YALMIP 3.0 and SeDuMi 1.3 are used to solve LMI problems.</p><p>Example 1. Consider the neural networks (4) with the parameters</p><formula xml:id="formula_50">A ¼ 2 0 0 2 ! , W 0 ¼ 1 1 À1 À1 ! , W 1 ¼ 0:88 1 1 1 ! , K p ¼ diagf0:4,0:8g, K m ¼ diagf0,0g:<label>ð38Þ</label></formula><p>For this system, by dividing delay interval into two and employing different free-weighting matrices at each interval, improved maximum delay bounds were obtained in <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref> when h D is 0.8, 0.9, and unknown (or larger than one). In <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, delay-partitioning techniques when delay-partitioning number is two were applied to obtain maximum delay bounds for the above system. By application of Theorems 1 and 2, our delay bounds are obtained and the detail comparison of our results with existing ones <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref> is given in Table <ref type="table" target="#tab_7">1</ref>. From Table <ref type="table" target="#tab_7">1</ref>, one can see that Theorem 1 enhances the feasible region of stability criteria in spite of not utilizing the delaypartitioning technique. Furthermore, Theorem 2 provides larger delay bounds than that of Theorem 1, which shows the effectiveness of the proposed idea in Theorem 2 to reduce the conservatism of stability criteria. To confirm the obtained result, h U ¼2.8222 for unknown h D , a simulation result when xð0Þ ¼ ½1,À1 T , f ðxðtÞÞ ¼ ½0:4 tanhðx 1 ðtÞÞ,0:8 tanhðx 2 ðtÞÞ T , and hðtÞ ¼ 2:82229sinðtÞ9 is shown in Fig. <ref type="figure" target="#fig_2">1</ref>. From Fig. <ref type="figure" target="#fig_2">1</ref>, one can see that the state responses converge to zero as time gets larger. </p><formula xml:id="formula_51">K m ¼ diagf0, 0, 0, 0g:<label>ð39Þ</label></formula><p>Table <ref type="table" target="#tab_8">2</ref> gives the comparison results on the maximum delay bound allowed via the methods in recent works and our new study. From Table <ref type="table" target="#tab_8">2</ref>, it can be seen that Theorem 2 gives larger delay bounds than very recent results in <ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref>. To confirm the obtained result, h U ¼2.6575 for unknown h D , a simulation result when xð0Þ ¼ ½1,0:75,À0:75,À1 T , f ðxðtÞÞ ¼ ½0:1137 tanhðx 1 ðtÞÞ, 0:1279 tanhðx 2 ðtÞÞ, 0:7994 tanhðx 3 ðtÞÞ, 0:2368 tanhðx 4 ðtÞÞ T , and hðtÞ ¼ 2:65759sinðtÞ9 is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. From Fig. <ref type="figure" target="#fig_1">2</ref>, one can see that the state responses also converge to zero as time gets larger.    x(t)</p><p>x 1 (t) x 2 (t) x 3 (t) x 4 (t) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, two delay-dependent stability criteria for neural networks with time-varying delays have been proposed by the use of the Lyapunov method and the LMI framework. In Theorem 1, by construction of the augmented Lyapunov-Krasovskii functional, the improved delay-dependent stability criterion has been proposed without use of delay-partitioning techniques. And, with new inequalities of activation functions, the further improved stability criterion was proposed in Theorem 2. Through two numerical examples, the improvement of the proposed stability criteria has been successfully verified.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>nÂn are the interconnection matrices representing the weight coefficients of the neurons, and b ¼ ½b 1 ,b 2 , . . . ,b n T A R n represents a constant input vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Example 2 .</head><label>2</label><figDesc>Consider the neural networks (40:4852 À0:3351 0:2336 À1:6033 0:5988 À0:3224 1:2352 0:3394 À0:0860 À0:3824 À0:5785 À0:1311 0:3253 À0:9534 À0:5015 diagf0:1137, 0:1279, 0:7994, 0:2368g,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. State responses of system considered in Example 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. State responses of system considered in Example 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1 ðtÞ, . . . ,y n ðtÞ T A R n is the neuron state vector, n denotes the number of neurons in a neural network, gðyðtÞÞ ¼ ½g 1 ðy 1 ðtÞÞ, . . . ,g n ðy n ðtÞÞ T A R n means the neuron activation function, gðyðtÀhðtÞÞÞ ¼ ½g 1 ðy 1 ðtÀhðtÞÞÞ, . . . ,g n ðy n ðtÀhðtÞÞÞ T</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>P 1 ¼ ½e 1 , e 3 , e 6 þe 7 , e 11 þ e 12 , P 2 ¼ e 4 , e 5 , e 1 Àe 3 , e 8 Àe 10 ¼ ½e 1 , e 4 , e 8 , P 4 ¼ ½e 3 , e 5 , e 10 , P 5 ¼ ½e 1 , e 8 , P 6 ¼ ½e 2 , e 9 , P 7 ¼ ½e 6 , e 1 Àe 2 , e 11 , e 7 , e 2 Àe 3 e 12 , G ¼ ½ÀA, 0, 0, ÀI, 0, 0, 0, W 0 , W 1 , 0, 0, 0, F ¼ e 8 Le T 4 þe 4 Le T 8 Àe 1 K m Le T 4 Àe 4 LK m e T 1 þe 1 K p De T 4 þe 4 DK p e T 1 Àe 8 De T 4 Àe 4 De T U =2Þ 2 e 4 Q 3 e T 4 Àðh U e 1 Àe 6 Àe 7 ÞQ 3 ðh U e 1 Àe 6 Àe 7 Þ T ,</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x T ðsÞ ds,</cell></row><row><cell cols="2">Z tÀhðtÞ</cell><cell cols="2">x T ðsÞ ds, f</cell><cell cols="3">T ðxðtÞÞ, f</cell><cell>T ðxðtÀhðtÞÞÞ, f</cell><cell>tÀhðtÞ T ðxðtÀh U ÞÞ,</cell></row><row><cell>tÀhU Z t</cell><cell>f</cell><cell cols="2">T ðxðsÞÞ ds,</cell><cell cols="2">Z tÀhðtÞ</cell><cell cols="2">f</cell><cell># T T ðxðsÞÞ ds</cell><cell>,</cell></row><row><cell>tÀhðtÞ</cell><cell></cell><cell></cell><cell></cell><cell>tÀhU</cell><cell></cell><cell></cell></row><row><cell cols="3">aðtÞ ¼ x T ðtÞ, _ x T ðtÞ, f h</cell><cell cols="2">T ðxðtÞÞ i T</cell><cell cols="3">, bðtÞ ¼ x T ðtÞ, f T ðxðtÞÞ h i T</cell><cell>,</cell></row><row><cell>Â</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ã</cell><cell>,</cell></row><row><cell cols="6">P 3 8 ,</cell><cell></cell></row><row><cell>X ¼ ðh 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>From<ref type="bibr" target="#b6">(7)</ref>, for any positive diagonal matrices H 1 ¼ diagfh 11 , . . . , h 1n g, H 2 ¼ diagfh 21 , . . . ,h 2n g, and H 3 ¼ diagfh 31 , . . . ,h 3n g, the following inequality holds:</figDesc><table><row><cell>À</cell><cell>Z t tÀhðtÞ</cell><cell cols="2">"</cell><cell cols="2">xðsÞ _ xðsÞ</cell><cell cols="2"># T Q 4 P 1 % Q 5 "</cell><cell cols="2"># "</cell><cell>xðsÞ _ xðsÞ</cell><cell># ds</cell></row><row><cell>À</cell><cell cols="2">Z tÀhðtÞ tÀhU</cell><cell cols="2">"</cell><cell cols="2">xðsÞ _ xðsÞ</cell><cell cols="2"># T Q 4 P 2 % Q 5 "</cell><cell cols="2"># "</cell><cell>xðsÞ _ xðsÞ</cell><cell>#</cell><cell>ds:</cell><cell>ð26Þ</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>À½e 8 Àe 9 Àðe 1 Àe 2 ÞK m H 4 ½e 8 Àe 9 Àðe 1 Àe 2 ÞK p T À½e 8 Àe 9 Àðe 1 Àe 2 ÞK p H 4 ½e 8 Àe 9 Àðe 1 Àe 2 ÞK m T À½e 9 Àe 10 Àðe 2 Àe 3 ÞK m H 5 ½e 9 Àe 10 Àðe 2 Àe 3 ÞK p T À½e 9 Àe 10 Àðe 2 Àe 3 ÞðK p H 5 ½e 9 Àe 10 Àðe 2 Àe 3 ÞK m T :</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 1</head><label>1</label><figDesc>Delay bounds h U with different h D (Example 1).</figDesc><table><row><cell>h D</cell><cell>0.8</cell><cell>0.9</cell><cell>Unknown (or h D Z 1)</cell></row><row><cell>[24] (m¼ 2) a</cell><cell>2.8634</cell><cell>1.9508</cell><cell>1.7809</cell></row><row><cell>[26] (m¼ 2) a</cell><cell>2.8854</cell><cell>1.9631</cell><cell>1.7810</cell></row><row><cell>[29] (m¼ 2) a</cell><cell>3.1150</cell><cell>2.1153</cell><cell>1.3189</cell></row><row><cell>[30] (m¼ 2) a</cell><cell>3.2113</cell><cell>2.2172</cell><cell>1.3718</cell></row><row><cell>Theorem 1</cell><cell>3.7174</cell><cell>2.6871</cell><cell>2.2975</cell></row><row><cell>Theorem 2</cell><cell>3.7174</cell><cell>2.8339</cell><cell>2.8222</cell></row></table><note><p>a m is a delay-partitioning number.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 2</head><label>2</label><figDesc>Delay bounds h U with different h D (Example 2).</figDesc><table><row><cell>h D</cell><cell>0.1</cell><cell>0.5</cell><cell>0.9</cell><cell>Unknown (or h D Z 1)</cell></row><row><cell>[28] ðr ¼ 0:6Þ</cell><cell>3.3574</cell><cell>2.5915</cell><cell>2.1306</cell><cell>2.0779</cell></row><row><cell>[27] (m¼ 2) a</cell><cell>3.5546</cell><cell>2.6438</cell><cell>2.1349</cell><cell>-</cell></row><row><cell>[26] (m¼ 2) a</cell><cell>3.7525</cell><cell>2.7353</cell><cell>2.2760</cell><cell>2.1326</cell></row><row><cell>Theorem 1</cell><cell>3.7024</cell><cell>2.8589</cell><cell>2.3473</cell><cell>2.2106</cell></row><row><cell>Theorem 2</cell><cell>3.7857</cell><cell>3.0546</cell><cell>2.6703</cell><cell>2.6575</cell></row></table><note><p>a m is a delay-partitioning number.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>O.M. Kwon et al. / Neurocomputing 103 (2013) 114-120</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Associate in ERC-ARC, POSTECH. In March 2000, he joined Yeungnam University, Kyongsan, Republic of Korea, where he is currently a Full Professor. From December 2006 to December 2007, he was a Visiting Professor in the Department of Mechanical Engineering, Georgia Institute of Technology. His research interests include robust control and filtering, neural networks, complex networks, and chaotic systems. He has published a number of papers in these areas. He serves as an Editor of International Journal of Control, Automation and Systems. He is also an Associate Editor/Editorial Board member for several O.M. Kwon et al. / Neurocomputing 103 (2013) 114-120</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education, Science and Technology (2012-0000479), and by a grant of the Korea Healthcare Technology R&amp;D Project, Ministry of Health &amp; Welfare, Republic of Korea (A100054).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Application of neural networks to loadfrequency control in power systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Beaufay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Abdel-Magrid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="183" to="194" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Common optimization of adaptive preprocessing units and a neural network during the learning period. Application in EEG pattern recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Galicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Witte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Örschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Griessbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1153" to="1163" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural network applications in finance: a review and analysis of literature</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Selvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Manage</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="129" to="139" />
			<date type="published" when="1990">1990-1996. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis and optimal design of continuous neural networks with applications to associate memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhengjiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Baozong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="259" to="271" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural networks in mechanics of structures and materials-new results and prospects of applications</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Waszczyszyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ziemian ´ski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Struct</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2261" to="2276" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural network applications in smart antenna arrays: a review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Shrivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Electron. Commun. (AE Ü)</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="903" to="912" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Global stability of a class of neural networks with timevarying delay</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ensari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. II</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="126" to="130" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Novel global robust stability criteria for interval neural networks with multiple time-varying delays</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W C</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. A</title>
		<imprint>
			<biblScope unit="volume">342</biblScope>
			<biblScope unit="page" from="322" to="330" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Global exponential stability of generalized recurrent neural networks with discrete and distributed delays</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="667" to="675" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exponential synchronization of stochastic Cohen-Grossberg neural networks with mixed time-varying delays and reaction-diffusion via periodically intermittent control</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="12" to="21" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Robust stability analysis of a class OF neural networks with discrete time delays</title>
		<author>
			<persName><forename type="first">O</forename><surname>Faydasicok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A new set of sufficient conditions based on coupling parameters for synchronization of Hopfield like Chaotic Neural Networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Menhaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control Automat. Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="104" to="111" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Chaotic simulated annealing by a neural network with a variable delay: design and application</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1557" to="1565" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exponential synchronization for arrays of coupled neural networks with time-delay couplings</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control Automat. Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="187" to="196" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Delay-dependent robust stability criteria for delay neural networks with linear fractional uncertainties</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control Automat. Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="281" to="287" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Further results on delay-dependent stability criteria of neural networks with time-varying delays</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="726" to="730" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust stability analysis of generalized neural networks with multiple discrete delays and multiple distributed delays</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1789" to="1796" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Delay-dependent stability analysis for continuoustime BAM neural networks with Markovian jumping parameters</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="315" to="321" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stochastic exponential stability of the delayed reaction-diffusion recurrent neural networks with Markovian jumping parameters</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. A</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="page" from="3201" to="3209" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improved delay-dependent exponential stability criteria for discrete-time recurrent neural networks with time-varying delays</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="321" to="330" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Passivity analysis of neural networks with timevarying delays</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. II</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="325" to="329" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stability of stochastic Markovian jump neural networks with mode-dependent delays</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="2157" to="2163" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On robust stability for uncertain neural networks with interval time-varying delays</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Control Theory Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="625" to="634" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">New stability criteria of neural networks with interval time-varying delays: a piecewise delay method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<biblScope unit="page" from="249" to="259" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">New Lyapunov-Krasovskii functionals for global asymptotic stability of delayed neural networks</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">L</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="533" to="539" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improved delay-dependent stability criterion for neural networks with time-varying delays</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. A</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<biblScope unit="page" from="529" to="535" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">New globally asymptotic stability criteria for delayed neural networks</title>
		<author>
			<persName><forename type="first">S.-P</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. II</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="659" to="663" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Novel weighting-delay-based stability criteria for recurrent neural networks with time-varying delay</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="91" to="106" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Delay-derivative-dependent stability for delayed neural networks with unbounded distributed delay</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1365" to="1371" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stability analysis on delayed neural networks based on an improved delay-partitioning approach</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="page" from="3086" to="3095" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A further refinement of discretized Lyapunov functional method for the stability of time-delay systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="967" to="976" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An augmented model for robust stability analysis of time-varying delay systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ariba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gouaisbaut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1616" to="1626" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reciprocally convex approach to stability of systems with time-varying delays</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="235" to="238" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust H1 stabilisation of networked control systems with packet analyser</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Control Theory Appl</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1828" to="1837" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An integral inequality in the stability problem of time-delay systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Decision Control</title>
		<meeting>the IEEE Conference on Decision Control<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-12">December 2000</date>
			<biblScope unit="page" from="2805" to="2810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Feron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Balakrishnan</surname></persName>
		</author>
		<title level="m">Linear Matrix Inequalities in Systems and Control Theory</title>
		<meeting><address><addrLine>SIAM, Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">A Unified Algebraic Approach to Linear Control Design</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Skelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Iwasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Grigoradis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Taylor and Francis</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">New results on exponential passivity of neural networks with time-varying delays</title>
		<author>
			<persName><forename type="first">Z.-G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ju</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nonlinear Anal. Real World Appl</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1593" to="1599" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">His research interests include time-delay systems, cellular neural networks, robust control and filtering, large-scale systems, secure communication through synchronization between two chaotic systems, complex dynamical networks, multi-agent systems, and so on. He has presented a number of papers in these areas. He is a member of KIEE, ICROS, and IEEK. He joined as an Editorial Member of KIEE and also severed as an Editorial Member in Nonlinear Analysis: Hybrid Systems from 2011</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ju H. Park received the B.S. and M.S. degrees in Electronics Engineering from</title>
		<meeting><address><addrLine>Daegu; Daegu; Pohang</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-02">February 2004 to January 2006. 1997. May 1997 to February 2000</date>
		</imprint>
		<respStmt>
			<orgName>S degree in Electronic Engineering from Kyungbuk National University ; Chungbuk National University ; Kyungpook National University</orgName>
		</respStmt>
	</monogr>
	<note>Republic of Korea. he was a Research</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
