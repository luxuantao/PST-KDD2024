<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DC programming and DCA: thirty years of developments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hoai</forename><forename type="middle">An</forename><surname>Le Thi</surname></persName>
							<email>hoai-an.le-thi@univ-lorraine.fr</email>
							<idno type="ORCID">0000-0002-2239-2100</idno>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory of Theoretical and Applied Computer Science (LITA)</orgName>
								<orgName type="institution">University of Lorraine</orgName>
								<address>
									<addrLine>3, rue Augustin Fresnel</addrLine>
									<postCode>57 073</postCode>
									<settlement>Metz Technopole</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><forename type="middle">Pham</forename><surname>Dinh</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratory of Mathematics</orgName>
								<orgName type="institution">National Institute for Applied Sciences -Rouen</orgName>
								<address>
									<postCode>76801</postCode>
									<settlement>Saint-Étienne-du-Rouvray Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DC programming and DCA: thirty years of developments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7D4751B448BCAFBA85D550330E12DC20</idno>
					<idno type="DOI">10.1007/s10107-018-1235-y</idno>
					<note type="submission">Received: 21 December 2016 / Accepted: 9 January 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>DC programming</term>
					<term>DCA</term>
					<term>Theory</term>
					<term>Algorithms</term>
					<term>Applications Mathematics Subject Classification 90C26</term>
					<term>90C90</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The year 2015 marks the 30th birthday of DC (Difference of Convex functions) programming and DCA (DC Algorithms) which constitute the backbone of nonconvex programming and global optimization. In this article we offer a short survey on thirty years of developments of these theoretical and algorithmic tools. The survey is comprised of three parts. In the first part we present a brief history of the field, while in the second we summarize the state-of-the-art results and recent advances. We focus on main theoretical results and DCA solvers for important classes of difficult nonconvex optimization problems, and then give an overview of real-world applications whose solution methods are based on DCA. The third part is devoted to new trends and important open issues, as well as suggestions for future developments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nonconvex (differentiable/nondifferentiable) programming and global optimization have known, during the past three decades, dramatic developments around the world.</p><p>The absence of convexity creates a source of difficulties of all kinds, in particular the distinction between the local and global minima, the non-existence of verifiable characterizations of global solutions, etc, that causes all the computational complexity while passing from convex to nonconvex programming. Finding a global solution of a nonconvex program, especially in the large-scale setting, is the quest for the holy grail for optimizers.</p><p>Over the last three decades, a variety of nonconvex optimization techniques have been recently developed by researchers. Generally speaking, there are two different but complementary approaches in nonconvex programming: global approaches such as cutting plane, branch and bound, branch and cut can guarantee the globality of the solutions but they are very expensive, especially for the large-scale setting; and local approaches, on the contrary, are much faster but computed local solutions can not be proven, in general, to be global ones. Many current approaches are not generally effective in large-scale problems from real-world applications. Finding efficient algorithms that realize a compromise between the quality and the scalability to tackle large-scale problems is a great challenge of nonconvex programming.</p><p>Roughly speaking, the nonconvex and nondifferentiable optimization problems encountered in the literature of mathematical programming as well as real-world applications can be divided into the following three classes (A) sup{ f (x) : x ∈ C}, where f and C are convex, (B) inf{g(x)h(x) : x ∈ R n }, where g, h are convex, (C) inf{g(x)h(x) : x ∈ C, f 1 (x)f 2 (x) ≤ 0}, where g, h, f 1 , f 2 and C are convex.</p><p>It is clear that <ref type="bibr" target="#b81">[82,</ref><ref type="bibr" target="#b224">223]</ref> Problem (A) is a special case of Problem (B) with g = χ C , the indicator function of C and h = f , while the latter can be equivalently transformed into the form of (A) by introducing an additional scalar variable. As for Problem (C), it can be equivalently reformulated in the form of (B) via exact penalty relative to the constraint f 1 (x)f 2 (x) ≤ 0. Problem (B), called a DC (Difference of Convex functions) program, thus plays a central role in nonconvex programming. Its particular structure has been permitting a good deal of development both in qualitative and quantitative studies.</p><p>Denoted by DC(X ) the set of DC functions on X := R n and by Γ o (X ) the set (convex cone) of all proper lower semi-continuous convex functions on X . Let O be an open set in X. Thanks to the richness of DC(X ) (see the properties (i)-(iv) below, which were mentioned in <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b224">223]</ref>), DC programs cover most of all nonconvex "realistic" optimization problems.</p><p>(i) DC(O) is the space containing the class of lower-C 2 functions on O ( f is said to be lower-C 2 on O if f is locally a supremum of a family of C 2 (O) (functions twice continuously differentiable on O). In particular, DC(O) contains the space C 1,1 (O) of functions whose gradient is locally Lipschitzian on O. (ii) DC(X ) is the space generated by the convex cone Γ o (X ): DC(X ) = Γ o (X ) -Γ o (X ). (iii) DC(X ) is closed under all the operations usually considered in optimization.</p><p>In particular, a linear combination of f i ∈ DC(X ) belongs to DC(X ), a finite supremum of DC functions is DC, etc. Moreover, an important result in <ref type="bibr" target="#b51">[52]</ref> permits to identify DC functions in numerous situations, simply by using a local analysis of convexity (remember that a function f : S → R defined on an open convex set S ⊂ R n is locally DC if for all x ∈ S there is a convex neighborhood U of x and a pair of convex functions g, h on U such that f U = g Uh U , f U being the restriction of f to U ). (iv) A locally DC function on a convex set S is DC on S.</p><p>The relation in (ii) marks the passage from convex optimization to nonconvex optimization and also indicates that DC(X ) constitutes a minimal realistic extension of Γ o (X ).</p><p>DC programming and DCA (DC Algorithms) constitute the backbone of nonconvex programming and global optimization. DCA was first introduced especially for the standard DC program (B) by Pham Dinh Tao in 1985 as a natural and logical extension of his previous works on convex maximization since 1974 and further focused for the general DC program of the form (C). Crucial developments and improvements for DC programming and DCA from both theoretical and computational aspects have been completed since 1994 throughout the joint works of the authors of this paper and their coworkers to become now classic and increasingly popular. As a continuous approach, DC programming and DCA were successfully applied to combinatorial optimization as well as many classes of hard nonconvex programs (see Sect. 3.2). These theoretical and algorithmic tools have been enriched from both a theoretical and an algorithmic point of view, thanks to a lot of their applications, by researchers and practitioners in the world, to model and solve nonconvex programs from many fields of Applied Sciences (refer to Sect. <ref type="bibr">3.4)</ref>.</p><p>The year 2015 marks the 30th birthday of DC programming and DCA. On this occasion, it is timely to offer here a short survey on thirty years of developments of this field.</p><p>For beginning, let us introduce briefly DC programming and DCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Outline of DC programming and DCA</head><p>Let X be the Euclidean space R n equipped with the canonical inner product ., . and its Euclidean norm . . The dual space of X , denoted by Y , can be identified with X itself. DC Programming and DCA address the problem of minimizing a function f which is a difference of convex functions on the whole space X . Generally speaking, a so-called standard DC program takes the form α = inf{ f (x) := g(x)h(x) : x ∈ X } (P dc ), with g, h ∈ Γ 0 (X ). Such a function f is called a DC function, and gh, a DC decomposition of f , while the convex functions g and h are DC components of f. When at least one of the functions g and h is polyhedral convex, (P dc ) is called a Polyhedral DC program. Polyhedral DC programming, which was a founding element of DC programming and DCA, has interesting properties on local optimality conditions and the finite convergence of DCA.</p><p>DC duality associates a primal DC program with its dual, which is also a DC program too:</p><formula xml:id="formula_0">α = inf{h * (y) -g * (y) : y ∈ Y } (D dc )</formula><p>where ϕ * defined by ϕ * (y) := sup{ x, y -ϕ(x) : x ∈ X }, ∀y ∈ Y is the conjugate of ϕ. There is so a perfect symmetry between (P dc ) and its dual (D dc ): the dual of (D dc ) is exactly (P dc ).</p><p>Let us introduce the following usual notations. The effective domain of ϕ ∈ Γ 0 (X ) is dom ϕ := {x ∈ X : g(x) &lt; +∞} and the finiteness α implies dom g ⊂ dom h and so dom f = dom g.</p><p>For ε &gt; 0 and x ∈ dom ϕ, the ε-subdifferential of ϕ at x, denoted by ∂ϕ ε (x), is defined by</p><formula xml:id="formula_1">∂ϕ ε (x) := {y ∈ Y : ϕ(u) ≥ ϕ(x) + x -u, y -ε ∀u ∈ X },<label>(1)</label></formula><p>while ∂ϕ stands for the usual (or exact) subdifferential of ϕ at x (i.e. ε = 0 in (1)). DC programming investigates the structure of DC(X ), DC duality and local and global optimality conditions for DC programs. The complexity of DC programs clearly lies in the distinction between local and global solutions and, consequently, the lack of verifiable global optimality conditions. Necessary local optimality conditions for the primal DC program (P dc ) were developed as follows (by symmetry those relating to dual DC program (D dc ) are trivially deduced).</p><p>Critical and strongly critical points A point x * is a critical point of (P dc ) (or of f = gh) if ∂g(x * ) ∩ ∂h(x * ) = ∅, or equivalently 0 ∈ ∂g(x * ) -∂h(x * ), while it is called strongly critical point of (P dc ) (or of f = gh) if ∅ = ∂h(x * ) ⊂ ∂g(x * ).</p><p>The notion of DC criticality is close to Clarke stationarity/Fréchet critical point in the sense that the Clarke/Fréchet subdifferential ∂ C f /∂ F f of f = gh verifies ∂ C f (x) ⊂ [∂g(x) -∂h(x)], ∂ F f (x) ⊂ [∂g(x) -∂h(x)] with equality under technical assumptions. Hence Clarke stationarity of x * , i.e., 0 ∈ ∂ C f (x * ) or its Fréchet stationarity, say 0 ∈ ∂ F f (x * ) implies DC criticality of x * . We have an equivalence between these notions if the related equality holds in the corresponding inclusion.</p><p>DC strong criticality and d(directional)-stationarity for DC programs DC criticality and strong criticality depend on DC decompositions g -h of DC objective function f = gh. And, since a DC function has infinitely many DC decompositions, the following question is well-founded: is there a stationarity notion for DC programs that is defined from the function f itself without going through a DC decomposition of f ? And in case of a positive answer, what is its relation with the notions of criticality exclusively specific to DC programming and DCA. This question was studied in our earlier works in 1985 and 1987 (see <ref type="bibr" target="#b233">[232,</ref><ref type="bibr" target="#b234">233]</ref> and references quoted therein).</p><p>Very recently, in <ref type="bibr" target="#b0">[1]</ref> the authors studied the d-stationarity and optimality in DC programming, they advised researchers to be careful of DC criticality notions. We fully agree with their consideration, since a thorough mastery of these theoretical and algorithmic tools would undoubtedly permit to discover the hidden faces of DC programming and DCA. Needless to say, the commonly used stationarity remains the d-stationarity related to the DC objective function f .</p><p>For the sake of completeness, let us recall and complete the major results concerning these different criticalities. They rely on the main results in convex analysis <ref type="bibr" target="#b248">[247]</ref> related to the subdifferential and the directional derivative of a convex function and the support function of a convex set in X . Let ϕ : X → R∪{+∞} be a proper function on X and x ∈ dom ϕ. The directional derivative ϕ (x; .) of ϕ at x is defined by</p><formula xml:id="formula_2">ϕ (x; u) := lim t↓0 ϕ(x + tu) -ϕ(x) t .</formula><p>If ϕ is convex, it becomes</p><formula xml:id="formula_3">ϕ (x; u) := inf t&gt;0 ϕ(x + tu) -ϕ(x) t .</formula><p>The d-stationarity of a proper function ϕ : X → R ∪ {+∞}. A vector x ∈ dom ϕ is d-stationary of ϕ if ϕ (x; u) ≥ 0 for every u ∈ X . The following result points out the key relations between d-stationarity and strong criticality.</p><p>Theorem 1 Let f := gh be the DC objective function of the primal DC program (P dc ) with g, h ∈ Γ 0 (X ) and its optimal value α being finite (implying dom f ⊂ dom g ⊂ dom h). Then the following properties hold:</p><p>(i) f (x; u) = g (x; u)h (x; u) for all u ∈ X. (ii) The vector x ∈ X is d-stationary of f (or for (P dc ) if and only if g (x; u) ≥ h (x; u) for all u ∈ X. Hence for x ∈ dom g, if both equalities g (x; u) = χ * ∂g(x) (u) and h (x; u) = χ * ∂h(x) (u) hold for all u ∈ X, then there is identity between the d-stationarity of x and the strong criticality of x. (iii) If x ∈ ri (dom g) ∩ ri (dom h) then d-stationarity of x is equivalent to strong criticality of x. (iv) If x ∈ ri (dom g) then d-stationarity of x implies strong criticality of x. (v) If x ∈ ri (dom h) then strong criticality of x implies d-stationarity of x. (vi) If the affine hulls of dom g and of dom h are identical then ri (dom g) ⊂ ri (dom h) and, for x ∈ ri (dom g), d-stationarity of x is equivalent to its strong criticality.</p><p>Proof The proof of this Theorem can be easily deduced from the specific structure of DC function and the main results concerning the subdifferential and the directional derivative of the convex function. It is omitted here. One observes that strong criticality is generally equivalent to directional stationarity. This justifies the well-foundedness of DC programming and DCA.</p><p>Philosophy of DCA DCA is based on local optimality conditions and duality in DC programming. The main idea of DCA is quite simple: at each iteration k, DCA approximates the second DC component h(x) by its affine minorization h k (x) := h(x k ) + xx k , y k , with y k ∈ ∂h(x k ), and minimizes the resulting convex function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic DCA scheme</head><p>Initialization: Let x 0 ∈ dom ∂h, k = 0.</p><p>For k = 0, 1, . . . until convergence of {x k }:</p><formula xml:id="formula_4">k1: Calculate y k ∈ ∂h(x k ); k2: Calculate x k+1 ∈ argmin{g(x) -h k (x) : x ∈ R n } (P k ).</formula><p>As the optimal solutions set of (P k ) is nothing else than ∂g * (y k ) (dually, ∂h(x k ) is the optimal solutions set of the problem</p><formula xml:id="formula_5">min{h * (y) -g * (y k-1 ) -y -y k-1 , x k : y ∈ R n } (D k )),</formula><p>this DCA scheme can be expressed in another form:</p><formula xml:id="formula_6">For k = 0, 1, . . . , set y k ∈ ∂h(x k ); x k+1 ∈ ∂g * (y k ).</formula><p>DCA performs so a double linearization with the help of the subgradient of h and g * , and DCA can also be viewed as an iterative primal-dual subgradient method.</p><p>Convergence properties of the DCA and its theoretical basis are described in <ref type="bibr" target="#b131">[130,</ref><ref type="bibr" target="#b224">223]</ref>. However, it is worthwhile to mention the following properties:</p><p>(i) DCA is a descent method without line search (the sequence {g(x k )h(x k )} is decreasing) but with global convergence (i.e. it converges from an arbitrary starting point). (ii) If g(x k+1 )h(x k+1 ) = g(x k )h(x k ), then x k is a critical point of gh. In this case, DCA terminates at kth iteration. (iii) If the optimal value α of problem (P dc ) is finite and the infinite sequence {x k } is bounded, then every limit point x * of this sequence is a critical point of gh. (iv) DCA has a linear convergence for general DC programs. In DC programming with subanalytic data, the whole sequence {x k } generated by DCA converges and DCA's rate convergence is stated. (v) In polyhedral DC programs, the sequence {x k } contains finitely many elements and DCA converges to a critical point x * after a finite number of iterations. Especially, if h is polyhedral convex and h is differentiable at x * , then x * is a local minimizer of (P dc ). (vi) This very simple DCA scheme hides the extrapolating character of DCA. Indeed, we show that, at the limit, the primal (dual)  <ref type="bibr" target="#b83">[84,</ref><ref type="bibr" target="#b122">121,</ref><ref type="bibr" target="#b123">122,</ref><ref type="bibr" target="#b167">166,</ref><ref type="bibr" target="#b225">224]</ref>.</p><p>The basic DCA above described, also named the simplified DCA in <ref type="bibr" target="#b224">[223]</ref> (or standard DCA), computes critical points of f = gh while the complete DCA provides strongly critical points of f = gh (see <ref type="bibr" target="#b224">[223]</ref> for its description and its convergence).</p><p>Approximate DCA The basic DCA scheme requires the computations of y k ∈ ∂h(x k ); x k+1 ∈ ∂g * (y k ). However, these computations are not necessarily exact, say, we can use an approximate DCA scheme of the form</p><formula xml:id="formula_7">y k ∈ ∂ ε k h(x k ); x k+1 ∈ ∂ ε k g * (y k ).</formula><p>It has been proved in <ref type="bibr" target="#b296">[295]</ref> that the approximate DCA still converges to a critical point as ε k ↓ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DCA with successive DC decomposition</head><p>In the basic DCA scheme, the DC decomposition f = gh is fixed before starting DCA and the majorization f k of f at iteration k is defined by f k (x) := g(x)h k (x). It is obviously that, closer f k to f , faster DCA converges, and better DCA could be. Hence, to increase the speed of convergence of DCA, one can modify iteratively DC decompositions of f , hoping to get more suitable f k . More precisely, at each iteration k one considers the so-called "successive DC decomposition" of f , namely f (x) := g k (x)h k (x), and takes</p><formula xml:id="formula_8">f k (x) := g k (x) -h k k (x). The sequence { f (x k )} is still decreasing, since we have always f (x k ) = f k (x k ) ≥ f k (x k+1 ) ≥ f (x k+1</formula><p>). This update DC decompositions procedure can be used as long as the sequence { f (x k )} is quickly decreasing. Once the value f (x k ) is slowly improved, one fixes the DC decomposition and applies the basic DCA until its convergence. The above convergence properties of DCA is then guaranteed.</p><p>General DCA Recently, a natural extension of DC programming and DCA for modeling and solving general DC programs with DC constraints (the problem (C) above) was developed in <ref type="bibr" target="#b90">[91]</ref>. Two resulting approaches consist in reformulating those programs as standard DC programs in order to use standard DCAs for their solutions.</p><p>DC programming and DCA can be viewed as an elegant extension of convex analysis/convex programming, sufficiently broad to cover most real-world nonconvex programs, but not too large in order to be able to use the powerful arsenal of modern convex analysis/convex programming (DCA works on convex functions g and h and their conjugate but not on the DC function f itself). This philosophy leads to the nice and simple concept of approximating a nonconvex (DC) program by a sequence of convex ones for the construction of DCA. DCA's distinctive feature relies upon the fact that DCA deals with the convex DC components g and h but not with the DC function f itself. The most important among the key properties of DCA is the flexibility: there are as many DCA as there are DC decompositions. Since a DC function f has infinitely many DC decompositions which have crucial impacts on the qualities (speed of convergence, robustness, efficiency, globality of computed solutions,...) of DCA, one can explore and exploit the effects of DC decomposition to design efficient DCA schemes. This flexibility implies another key property of DCA: with appropriate DC decompositions and suitably equivalent DC reformulations, DCA makes it possible to recover all (resp. most) standard methods in convex (resp. nonconvex) programming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Links between DCA and standard convex/nonconvex programming approaches</head><p>In this subsection we first discuss about DCA versus the Majorization-Minimization (MM) and the Successive Convex Approximation (SCA) approaches. We show furthermore that several convex/nonconvex programming approaches are special versions of DCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1">DCA versus the MM and SCA approaches</head><p>To our knowledge, the general principle behind the MM method was first introduced by the numerical analysts Ortega and Rheinboldt <ref type="bibr" target="#b207">[206]</ref> in their studies related to line search methods in one dimensional setting, followed by the work of de Leeuw <ref type="bibr" target="#b169">[168]</ref> for multidimensional scaling problems (MDS). But the acronym MM appeared for the first time in the work of Hunter and Lange <ref type="bibr" target="#b59">[60]</ref>. It is worth noting that in <ref type="bibr" target="#b169">[168]</ref>, de Leeuw formulated the metric MDS problem as the maximization of a ratio of two gauges and then applied the convex maximization algorithm early proposed in <ref type="bibr" target="#b216">[215,</ref><ref type="bibr" target="#b217">216]</ref>. Later, de Leeuw's algorithm was interpreted in <ref type="bibr" target="#b59">[60]</ref> as an MM based method. Like DCA, the MM is not an algorithm but a philosophy, because it gives a way to construct algorithms. More precisely, for solving the minimization problem</p><formula xml:id="formula_9">min{ f (x) : x ∈ X ⊂ R n }, the idea of the MM is to construct a majorization function θ over X × X such that f (x) ≤ θ(x, y), ∀x, y ∈ X and f (x) = θ(x, x), ∀x ∈ X</formula><p>and then update x at each iteration k by x k+1 ∈ arg min{θ(x, x k ) : x ∈ X }.</p><p>Basically, any surrogate defined above can be used to majorize the objective function f , but usually the following four typical approaches have been used in the literature: Jensen's inequality, Convexity inequality, Cauchy-Schwartz inequality, Inequality of arithmetic and geometric means. In general, these approaches are based on the convexity and the differentiability of the surrogate function θ. When θ is convex, the MM is also known in the literature, more recently, under the name SCA, even if the term "approximation" is used instead to "majorization".</p><p>Without going into details, it is worth mentioning the main differences and advantages of DCA compared to MM method.</p><p>(i) Whilst MM proposes a general idea to majorize the objective function f , how to construct such a majorization for a given function f still is a very hard question. Meanwhile DCA gives the simplest and the most closed convex surrogate function of f (see the property vi) of Basic DCA scheme). So, the major benefit of DCA versus MM is that the DC structure offers an effective and suitable convex surrogate. (ii) DCA works on DC components g and h which are convex, but not the function f itself. While the MM method majorizes iteratively the whole objective function f , DCA approximates only one part of f , say it majorizes the concave part -h and keeps the convex part g of f . Hence it is more likely that the majorization g(x)h k (x) in DCA is better than θ(x, x k ) in MM, especially as we have the flexibility of DCA related to the freedom of the choice of g and h. For example, comparing with the first order Taylor approximation (Böning and Lindsay 1988) of f , one usual way to construct the surrogate function in MM method, DCA gives a better approximation. In addition, working with the convex functions g and h (in the context of DCA) by taking advantage of the powerful convex analysis tools is by far easier and more attractive than working with nonconvex functions f (in the context of MM). Moreover, with useful convex analysis tools, working with convex functions g and h (in DCA's framework) is easier and more attractive than working with nonconvex functions f (in the context of MM). (iii) One of the key criteria in judging majorizing functions in the MM (as well as DCA)</p><p>is their ease in solving subproblems. For this purpose, the usual surrogate functions θ of MM based methods are smooth, so these methods turn a nonsmooth problem into a smooth problem. Whereas, DCA works, in the same way, on nonsmooth and smooth optimization problems by using subgradient of convex functions. Again, this is a considerable benefit of DCA in nonsmooth optimization. (iv) Thanks to its attractive features, namely, working on convex functions g and h and then fundamental convex analysis tools such as conjugacy, subdifferential, criticality, d-stationarity, strong convexity, etc, can be used properply, and the flexibility of DC decompositions, DCA enjoys, in several classes of problems, deeper and more interesting convergence properties, for example-the finite convergence for polyhedral DC programs, the convergence of the series x k+1x k 2 while g or h is strongly convex (we can always get this strong convexity via regularization techniques <ref type="bibr" target="#b131">[130,</ref><ref type="bibr" target="#b224">223]</ref>).</p><p>Related works using the MM/SCA principle in the literature lead to the following observations: numerical methods proposed in these works for a concrete problem resort finally, directly or not, to DCA. Even if the DC structure of the problem under consideration is hidden, with the usual choices of the surrogate functions, the MM/SCA methods result to DCA versions. In other words, the nonconvex functions which can use these surrogates are in fact DC, and the proposed MM methods are nothing else but DCA versions. This justifies once again the above classification of realistic nonconvex problems (they contain the three classes of DC programs). From numerical point of view, highlighting first the DC structure of the problem and then investigating directly DCA seem to be simpler, and more effective/efficient than MM, since one can exploit the effect of DC decomposition to design other DCA schemes. Hence, an important question is how to recognize a DC function.</p><p>On the other hand, the following questions deserve deeper reflections if one would like to move beyond DC programming and DCA with the help of MM approaches:</p><p>-Show DC programs such that there is an MM version which is not DCA. In this case compare this MM to DCA from both algorithmic and computational point of views. -Find out classes of nonsmooth nonconvex programs which are not DC but can be solved by MM.</p><p>At last, let us consider the commonly used convex surrogate functions in the literature which are linear upper bounds, quadratic upper bounds and proximal upper bounds. We will show that, in these cases, the resulting SCA based algorithms are DCA versions. To simplify the presentation, we consider the following optimization problem (in the literature, the objective function can be the sum of f and a convex function g, then one uses the SCA principle for f and keeps g):</p><formula xml:id="formula_10">min{ f (x) : x ∈ X } (2)</formula><p>where X is a convex set in R n . The idea of SCA is to iteratively approximate f (x) by convex surrogate functions θ(x, x k ). More precisely, at each iteration k, SCA computes</p><formula xml:id="formula_11">x k+1 ∈ arg min{θ(x, x k ) : x ∈ X }.<label>(3)</label></formula><p>Commonly used convex majorization in SCA and link with DCA (i) Linear upper bounds of concave functions. When f (x) is concave differentiable the following affine function is often used to majorize f :</p><formula xml:id="formula_12">θ(x, x k ) = f (x k ) + ∇ f (x k ), x -x k , (<label>4</label></formula><formula xml:id="formula_13">)</formula><p>and the SCA iteration becomes</p><formula xml:id="formula_14">x k+1 ∈ arg min{ f (x k ) + ∇ f (x k ), x -x k : x ∈ X }. (<label>5</label></formula><formula xml:id="formula_15">)</formula><p>This algorithm is also known in the literature under the name "Successive Linear Approximation". It is clear that f is a DC function with the following natural DC decomposition: f (x) = g(x)h(x) with g(x) = 0, h(x) =f (x) and the corre-</p><formula xml:id="formula_16">sponding DC program is min{g(x) -h(x) : x ∈ X }.<label>(6)</label></formula><p>Then DCA applied on (6) consists of computing, at each iteration k,</p><formula xml:id="formula_17">y k = -∇ f (x k ), x k+1 ∈ arg min{-y k , x : x ∈ X } = arg min ∇ f (x k ), x : x ∈ X</formula><p>which is nothing else than the SCA iteration (5) after removing the constant terms. Note that when f is nonsmooth we can replace ∇ f (x k ) by a subgradient of f at x k .</p><p>(ii) Quadratic upper bounds of smooth functions. When f is twice differentiable, the following upper bound is usual:</p><formula xml:id="formula_18">θ(x, x k ) = f (x k ) + ∇ f (x k ), x -x k + 1 2 (x -x k ) T H (x -x k ), (<label>7</label></formula><formula xml:id="formula_19">)</formula><p>where H is a positive semidefinite matrix such that H -∇ 2 f (x) is also positive semidefinite. Let g and h be the function defined by g(x)</p><formula xml:id="formula_20">= 1 2 x T H x, h(x) = 1 2 x T H x -f (x).</formula><p>Hence f can be expressed as f (x) = g(x)h(x), say f is DC since the two components g and h are convex. Applying DCA on (3) with this DC decomposition amounts to computing, at each iteration k,</p><formula xml:id="formula_21">y k = H x k -∇ f (x k ), x k+1 ∈ arg min 1 2 x, H x -H x k -∇ f (x k ), x : x ∈ X (8)</formula><p>which is exactly the SCA iteration (3), <ref type="bibr" target="#b6">(7)</ref> after removing the constant terms. Note that <ref type="bibr" target="#b6">(7)</ref> is also referred as the proximal gradient approximation when H = ρ I , where I denotes the identity matrix. (iii) Proximal upper bounds of convex functions. To get the strong convexity of f , the proximal upper bound of f , say θ(x, x k ) = f (x) + ρ 2 xx k 2 is often used that leads to the well-known proximal point algorithm in convex programming. We will see below that this algorithm is a version of DCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2">The CCCP is an instance of DCA in smooth optimization</head><p>The concave-convex procedure (CCCP) was first proposed in 2003 <ref type="bibr" target="#b330">[329]</ref> for constructing discrete time dynamical systems that can be guaranteed to decrease almost any global optimization/energy function. Under the assumptions that the objective function f is twice differentiable (and then it can be rewritten as the sum of a convex part f vex (x) and a concave part f cav (x)) and that the feasible set is defined by linear constraints, each iteration of the CCCP procedure approximates the concave part by its tangent and minimizes the resulting convex function:</p><formula xml:id="formula_22">x k+1 ∈ arg min f vex (x) + x, f cav (x k ) : x ∈ C .</formula><p>Obviously, CCCP is nothing else than DCA for smooth optimization. It is observed that many researchers/practitioners are aware of this fact, but still continue to call CCCP applied to nonsmooth DC programs!!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.3">The EM algorithm for exponential families is a version of DCA</head><p>The EM (Expectation-Maximization) algorithm was explained and given its name in 1977 in a classic paper by Arthur Dempster et al. <ref type="bibr" target="#b32">[33]</ref> where they pointed out that the method had been "proposed many times in special circumstances" by earlier authors. People recognize that EM is an MM type algorithm in which the surrogate function is constructed by Jensen's inequality. Consider now the case where the likelihood function is an exponential family:</p><formula xml:id="formula_23">P(x, v, w|Θ) = (1/Z (x|Θ)) exp D i=1 Θ i m i (x, v, w)</formula><p>, where x is a vector observation, v is a visible state, w is a hidden variable, m i (x, v, w) is some real or binary function, and <ref type="figure">,</ref><ref type="figure">v,</ref><ref type="figure">w</ref>) is the normalization term. If we have a data set X then the log-likelihood of the data is given as L (Θ) = x∈X log w P(x, v, w|Θ). For finding Θ, one maximizes the log-likelihood function max{L (Θ)}.</p><formula xml:id="formula_24">Z (x|Θ) = v,w exp D i=1 Θ i m i (x</formula><p>(</p><p>EM for solving (9) consists of the following steps:</p><p>-E-step: Determine the lower bound</p><formula xml:id="formula_26">Q(Θ, Θ k ) of L (Θ) by Q(Θ, Θ k ) =</formula><p>x w P(w|x, v; Θ k ) log P(x, v, w|Θ)</p><formula xml:id="formula_27">- x w P(w|x, v; Θ k ) log P(w|x, v; Θ k ), (<label>10</label></formula><formula xml:id="formula_28">)</formula><p>where</p><formula xml:id="formula_29">P(w|x, v; Θ k ) = exp D i=1 Θ k i m i (x, v, w) / w exp D i=1 Θ k i m i (x, v, w ) . -M-step: Compute Θ k+1 by maximizing Q(Θ, Θ k ).</formula><p>The reader can verify that this EM algorithm is exactly DCA applied on the problem (9) (in its equivalent form min{-L (Θ)}), with the following DC decomposition of the negative log-likelihood -L (Θ) = gh:</p><formula xml:id="formula_30">g(Θ) = x∈X log v,w exp D i=1 Θ i m i (x, v, w) , h(Θ) = x∈X log w exp D i=1 Θ i m i (x, v, w) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.4">DCA for convex programming</head><p>Consider the convex program α = min{ f (x) : x ∈ C} <ref type="bibr" target="#b10">(11)</ref> where f and C are convex. First, taking the DC decomposition f (x) = g(x)h(x) with g = f and h = 0 and applying DCA on the resulting DC program we obtain the following DCA iteration:</p><formula xml:id="formula_31">y k = 0, x k+1 ∈ arg min{ f (x) : x ∈ C}.</formula><p>Hence DCA performs exactly one iteration that consists of solving <ref type="bibr" target="#b10">(11)</ref>. It turns out that this DCA corresponds to any standard convex solver used for solving <ref type="bibr" target="#b10">(11)</ref>. Now, consider other DC decompositions f (x) = g(x)-h(x) (one say f a false DC function). DCA applied on the resulting DC programs can be different from standard convex algorithms for solving <ref type="bibr" target="#b10">(11)</ref>, but it gives also a global solution to <ref type="bibr" target="#b10">(11)</ref>. Moreover, thanks to the effect of DC decomposition, it can be happened that the corresponding DCA schemes are better than standard convex algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.5">Proximal point algorithm for convex programming is a DCA version</head><p>Let f ∈ Γ o (X ) and C be a nonempty closed convex set in X . Consider the following convex program</p><formula xml:id="formula_32">α = inf{ f (x) : x ∈ C} ⇔ α = inf{χ C (x) + f (x) : x ∈ X }. (<label>12</label></formula><formula xml:id="formula_33">)</formula><p>For any λ &gt; 0, the function</p><formula xml:id="formula_34">g(x) := χ C (x) + 1 2 λ x 2 + f (x), h(x) := 1 2 λ x 2</formula><p>are convex, and then gh is a DC decomposition of χ C + f . DCA applied on <ref type="bibr" target="#b11">(12)</ref> with this DC decomposition corresponds to</p><formula xml:id="formula_35">y k = λx k , x k+1 ∈ arg min f (x) + 1 2 λ x 2 -x, λx k or x k+1 = I + 1 λ ∂ f -1</formula><p>x k which is nothing else but the proximal point algorithm for convex program <ref type="bibr" target="#b11">(12)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.6">Goldstein-Levitin-Polyak projection algorithm is a DCA version</head><p>Now let λ be a positive number such that the function h(x) := 1 2 λ x 2f (x) is convex, and let g(x) := χ C (x) + 1 2 λ x 2 . Hence gh is a DC decomposition of χ C + f and applying DCA on <ref type="bibr" target="#b11">(12)</ref> with this DC decomposition we have</p><formula xml:id="formula_36">y k = λx k -η k , η k ∈ ∂ f (x k ); x k+1 = P C x k - 1 λ η k , (<label>13</label></formula><formula xml:id="formula_37">)</formula><p>where P C denotes the orthogonal projection mapping. One recognizes in <ref type="bibr" target="#b12">(13)</ref> the Goldstein-Levitin-Polyak projection algorithm <ref type="bibr" target="#b239">[238]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.7">Iterative shrinkage-thresholding algorithm ISTA is a DCA version</head><p>ISTA was first introduced in <ref type="bibr" target="#b21">[22]</ref> and later developed in <ref type="bibr" target="#b31">[32]</ref> and <ref type="bibr" target="#b12">[13]</ref>. The most general case was considered in <ref type="bibr" target="#b12">[13]</ref>:</p><formula xml:id="formula_38">min x { f (x) = g 1 (x) + g 2 (x)}, (<label>14</label></formula><formula xml:id="formula_39">)</formula><p>where g 1 , g 2 are convex and g 2 is differentiable with L-Lipschitz gradient. ISTA proposed in <ref type="bibr" target="#b12">[13]</ref> iteratively computed</p><formula xml:id="formula_40">x k+1 = arg min x g 1 (x) + L 2 x -x k - 1 L ∇g 2 (x k ) 2 . (<label>15</label></formula><formula xml:id="formula_41">)</formula><p>ISTA can be interpreted as a DCA scheme by using the following DC decomposition:</p><formula xml:id="formula_42">f (x) = g(x) -h(x), where g(x) = g 1 (x) + L 2 x 2 , h(x) = L 2 x 2 -g 2 (x). (<label>16</label></formula><formula xml:id="formula_43">)</formula><p>Similarly, the ISTA with backtracking step-size (when the Lipschitz constant L is not always known or computable) is a version of DCA with successive DC decomposition. We just saw that several standard convex/nonconvex approaches are DCA versions. Meanwhile, the power and creative freedom offered by DC programming and DCA, in particular the flexibility in the choice of DC decomposition allow to design other versions of DCA, which are more efficient than the standard methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Milestone</head><p>We state below the most significant steps in the development of DC programming and DCA.</p><p>• 1974: before DC programming and DCA, convex maximization The works of Pham Dinh Tao on the computation of bound-norms of matrices (i.e., maximizing a semi-norm over the unit ball of a norm) during the period <ref type="bibr">1974-1985 ([215-219]</ref> and references therein) paved the way for the introduction of DC programming and DCA. • 1985: the birth of DC programming and DCA The previous works on convex maximization are extended in a natural and logical way to the DC programming. DC programming and DCA were introduced in 1985 by Pham Dinh Tao <ref type="bibr" target="#b233">[232]</ref> in the preliminary state. From 1994, these tools were extensively developed throughout various joint works of Le Thi Hoai An and Pham Dinh Tao, and they are increasingly popularized since 2002. • 1994: DCA for solving the trust region subproblem Since its birth, DCA has been developed in some works but significant results have not had time to emerge during the period 1986-1992. The first important results have occurred in the thesis work of <ref type="bibr">Le Thi Hoai An 1992</ref><ref type="bibr">-1994 [82]</ref>. Among them the most interesting one concerns DCA for solving the trust region subproblem (i.e., the ball constrained quadratic programming problem) which plays a key role in the so-called trust region method for nonlinear optimization. The proposed DCA is a very simple, fast and scalable algorithm, which is hard to escape a global minimum. It has attracted attention of the community of nonlinear optimization and has been known to be one of the best algorithms for this problem. This work was published firstly in a short version in <ref type="bibr" target="#b223">[222]</ref> and then its complete version in <ref type="bibr" target="#b225">[224]</ref> marks a crucial step in the developments of DCA, it was a prelude to the development and the popularization of DCA. Several DCA based algorithms in both local and global approaches for linear or convex quadratic constrained nonconvex quadratic programming problems have been motivated by/based on this work. • 1996: DCA for optimizing over the efficient set In <ref type="bibr" target="#b146">[145]</ref>, DCA was investigated, for the first time, for minimizing a convex or concave or quadratic function f over the efficient set of a multiple objective program. The original problem were reformulated as a DC program with the help of a penalty function, and the exact penalty was proved when f is concave. This paper constitutes the starting point to a more general result on exact penalty in DC programming in 1999 and motivated the use of DCA for other classes of difficult nonconvex programs. Later developments of DCA for optimizing over the efficient set were done in <ref type="bibr" target="#b149">[148,</ref><ref type="bibr" target="#b151">150]</ref>. • 1997: DCA for nonconvex quadratic programs We developed in <ref type="bibr" target="#b122">[121]</ref> several DCA versions corresponding to different DC decompositions and studied local optimality conditions and convergence properties of the resulting DCAs. The combined DCA-BB (Branch and Bound) algorithm using DC relaxation for a quadratic function has seen the day in <ref type="bibr" target="#b122">[121]</ref>. Afterward, specific DCA and the combined DCA-BB for bound constrained quadratic programs have been proposed in <ref type="bibr" target="#b123">[122]</ref>. These works established the foundations to later developments of DCA on linear/quadratic integer programming. The year 1997 was also marked by the seminal paper "DC programming and DCA: Theory, Algorithm, Applications" which was devoted to a thorough study and the state-of-the-art of DC programming and DCA <ref type="bibr" target="#b224">[223]</ref>. • 1998: introduction of Ellipsoidal bisection in BB algorithms for nonconvex quadratic programs Motivated by the efficiency of DCA for ball constrained quadratic programs, we introduced in <ref type="bibr" target="#b147">[146]</ref>, for the first time in global optimization, the ellipsoidal bisection technique in a BB scheme for nonconvex quadratic programs. This technique enjoys a double advantage: we do not require that the polytope K is given explicitly by a system of linear inequalities and/or equalities, and the inexpensive ellipsoidal constrained quadratic programs are the main subproblems in the BB scheme.</p><p>• 1999: exact penalty in concave minimization and DC reformulations of several classes of difficult nonconvex programs It has been proved in <ref type="bibr" target="#b148">[147]</ref> that the exact penalty holds for the problem of minimizing a concave function under a nonempty bounded polyhedral convex set with an additional concave constraint. This result permits to recast several classes of difficult nonconvex programs including linear/quadratic integer programming, complementarity problems, bilevel programming, multiple objective programming and optimization over the efficient set into suitable DC programs and open the door to an effective investigation of DCA for solving them. This work is followed by a series of papers which were devoted to the development of efficient DCAs for these classes of difficult problems in nonconvex programming and combinatorial optimization (see Sect. 3.2). • Since 1999: first applications of DCA for solving real-world nonconvex optimization problems The first application of DCA for real-world problems was the molecular conformation, one of the fundamental problems in computational biology <ref type="bibr" target="#b84">[85,</ref><ref type="bibr" target="#b124">123,</ref><ref type="bibr" target="#b129">128,</ref><ref type="bibr" target="#b130">129]</ref>. The effectiveness of DCA was proved from this first issue. Since then, DCA was successfully investigated for signal restoration <ref type="bibr" target="#b126">[125]</ref>, data analysis (the Multidimensional Scaling Problem <ref type="bibr" target="#b127">[126]</ref>) and network optimization <ref type="bibr" target="#b128">[127,</ref><ref type="bibr" target="#b181">180]</ref>. • 2001: solving combinatorial optimization problems by DCA The first application of DCA in combinatorial optimization deals with linear constrained quadratic zero-one programming, it was published in <ref type="bibr" target="#b125">[124]</ref>. Thanks to the exact penalty results, the linear constrained quadratic zero-one programming problem can be equivalently reformulated as the concave quadratic program for which DCA has been shown to be efficient. Here we proved an important property of DCA: DCA works on a continuous domain but, with a suitable penalty parameter, it gives an integer solution. This impressive nice result is the key to success of DCA for integer programming. This work attracted attention of the combinatorial optimization community and instigated the use of DCA in various application areas. • Since 2002: DCA was increasingly popularized, especially in machine learning and data mining The research on applications of DCA for real-world problems is very active and increasingly popular since 2002. A variety of machine learning methods based on DCA were developed by researchers who have demonstrated the effectiveness and the scalability of DCA. Since then, DC Programming and DCA have been successfully applied by many researchers and practitioners in the world to a lot of nonconvex programs in various fields of applied sciences (for which these approaches are robust, reliable and more efficient than existing methods). An incomplete list of works using DCA is given in <ref type="bibr" target="#b167">[166]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• 2005: exact penalty in DC programming, and DCA for sparse optimization</head><p>The previous results concerning exact penalty in concave programming developed in <ref type="bibr" target="#b148">[147]</ref> were extended in <ref type="bibr" target="#b142">[141,</ref><ref type="bibr" target="#b144">143]</ref> to establish some exact penalty properties in DC programming. These works allow to reformulate several classes of combinatorial optimization with DC objective functions and nonconvex programs as DC programs. At the same time, the first work on DCA in sparse optimization (which refers to a nonconvex optimization problem involving the zero-norm in the objective function or constraints) was appeared in <ref type="bibr" target="#b190">[189]</ref> for feature selection in SVM (Support Vector Machine). Since then, DCA is widely developed to sparse optimization and its applications for variable selection in classification, compressed sensing and finance via two approaches: DC approximation (see <ref type="bibr" target="#b145">[144]</ref> and references therein) and DC reformulation via exact penalty <ref type="bibr" target="#b98">[99]</ref>. These two DC approaches cover all existing algorithms in nonconvex approaches for sparse optimization. The year 2005 was also marked by the state-of-the-art paper <ref type="bibr" target="#b131">[130]</ref> which completes and extends the seminal work on DC programming and DCA in <ref type="bibr" target="#b224">[223]</ref>. • 2013: DCA for general DC programs and recent advances Hitherto DCA is investigated for standard DC programs (minimizing a DC function over a convex set). However, numerous real-world problems deal with DC constraints. In <ref type="bibr" target="#b90">[91]</ref>, we present a natural extension of DC programming and DCA for modeling and solving general DC programs with DC constraints. Two resulting approaches consist in reformulating those programs as standard DC programs in order to use standard DCAs for their solutions. Some other hot topics like convergence rate of DCA for DC programs with subanalytic data, exact penalty and error bounds in DC programming whose mixed integer DC programming were presented in <ref type="bibr" target="#b92">[93,</ref><ref type="bibr" target="#b226">225]</ref>. In particular, the convergence study of the whole standard DCA sequence is a difficult problem. Actually, and only for standard DC programs with subanalytic data, one should use the sophisticated nonsmooth version of the Lojasiewicz inequality to demonstrate, for the first time, this convergence result with rate depending on the Lojasiewicz exponent of the objective function.</p><p>• Today … DC programming and DCA were the subject of several hundred articles in the high ranked scientific journals and the high-level international conferences, as well as various international research projects, and were the methodological basis of more than 50 PhD theses. About 100 invited symposia/sessions dedicated to DC programming and DCA were presented in many international conferences. The ever-growing number of works using DC programming and DCA proves their power and their key role in nonconvex programming/global optimization and many areas of applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DC Programming and DCA: the state-of-the-art</head><p>We will summarize the key results which constitute the state-of-the-art of DC Programming and DCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Main theoretical results</head><p>DC functions have many important properties that were derived from 1950s in <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b51">[52]</ref>. However, it was necessary to wait until the mid-80s when the class of DC functions was introduced in optimization, to the appearance of DC programming.</p><p>The general theoretical results about DC Programming and DCA were developed in <ref type="bibr" target="#b224">[223]</ref> where we have established the DC duality, local optimality conditions, the transportation of local/global solutions via the DC duality, regularization techniques, the convergence properties of DCA, and special properties (on the local optimality conditions, the finite convergence of DCA) for the special class of DC programs (when either g or h is polyhedral convex) called polyhedral DC programs.</p><p>Later, the computational efficiency of DCA suggested to us a deeper and more complete study on DC programming in <ref type="bibr" target="#b131">[130]</ref>, using polyhedral DC programs. The DC duality is investigated in an easier way, which is more convenient to the study of optimality conditions. New practical results on local optimality are presented. We emphasize regularization techniques in DC programming in order to construct suitable equivalent DC programs to nondifferentiable nonconvex optimization problems and new significant questions which have to be answered. A deeper insight into DCA was introduced which really sheds new light on DCA and could partly explain its efficiency.</p><p>The stability of Lagrangian duality and the optimality global of the minimization of a nonconvex quadratic function on Euclidean balls and spheres have been studied in <ref type="bibr" target="#b222">[221]</ref>. It is worth to note that these problems are among a very few nonconvex optimization problems where the stability of Lagrangian duality holds, i.e., there is no duality gap.</p><p>The exact penalty in concave minimization over a bounded polyhedral convex set with an additional reverse convex constraint was developed in <ref type="bibr" target="#b148">[147]</ref>. Both theoretical and practical studies of this class of nonconvex programs are more convenient and easier when the reverse convex constraint is penalized. We have proved that if the concave function defining the reverse convex constraint is nonnegative over the bounded polyhedral convex set, then the exact penalty and the stability of the Lagrangian duality hold. Consequently, equivalent DC programs are formulated. We showed that this result can be applied to concave minimization over the pareto set, bilevel linear program, linear program with mixed linear complementarity constraint, and mixed zero-one concave minimization programming. These results allowed building a first bridge between DC programming and operations research, founded on which DCA based algorithms were developed for the above mentioned classes of problems in later works. More recently, we obtain interesting results on exact penalty with/without error bounds in DC programming with nonconvex constraint sets in <ref type="bibr" target="#b142">[141,</ref><ref type="bibr" target="#b144">143]</ref>. These recent results permit to recast various classes of difficult nonconvex programs into suitable DC programs to be tackled by the efficient DCA and combined DCA-global algorithms. Following these results we were able to solve many difficult combinatorial optimization problems (minimizing a DC function under linear/convex quadratic constraints and mixed 0-1 variables) by DC programming and DCA (see, for example, <ref type="bibr" target="#b108">[109,</ref><ref type="bibr" target="#b159">[158]</ref><ref type="bibr" target="#b160">[159]</ref><ref type="bibr" target="#b161">[160]</ref>), and numerous other works.</p><p>Recently, motivated by the richness of DC functions and of DC programs in many applications, some academic works on DC programming were developed. For instance, the authors of <ref type="bibr" target="#b11">[12]</ref> gave a survey on many existing properties of DC functions, while those of <ref type="bibr" target="#b209">[208]</ref> used the notion of B-stationary point of nonsmooth DC Programs and studied its relation with the DC criticality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DCA solvers for important classes of difficult nonconvex programs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">The trust region subproblems</head><p>The trust region subproblem (TRSP) is the minimization of a quadratic function over an Euclidean ball. It has crucial importance in numerical analysis and nonlinear optimization, and enjoys distinctive features: (i) It is the basic subproblem for the Trust-Region Method (consisting of solving a sequence of (TRSP)) which can be considered as an improved Newton type method and is recognized to be among the most robust, stable and efficient methods in nonlinear programming (see <ref type="bibr" target="#b30">[31]</ref> where a chapter is devoted to DC programming and DCA for solving (TRSP)). (ii) TRSP is one of rare nonconvex programs which possess verifiable global optimality conditions (quite close to KKT conditions). TRSP has only one local-nonglobal solution. (iii) The set of KKT points for TRSP is contained in at most 2m + 2 disjunctive subsets where the objective function has the same value and m is the number of the distinct negative eigenvalues of the symmetric matrix defining the quadratic function of TRSP. These properties should promote inexpensive local descent methods which can perform finitely many restartings to converge to global solutions of TRSP. In <ref type="bibr" target="#b223">[222,</ref><ref type="bibr" target="#b225">224]</ref>, we investigated DCA to solve TRSP. Thanks to the particular structure of the trust-region subproblem, the DCA is very simple: it consists of computing, at each iteration, the projection of a point on an Euclidean ball, which is explicit and requires only matrix-vector products. In practice, DCA converges to the global solution of TRSP. The inexpensive implicitly restarted Lanczos method of Sorensen is used to check the optimality of solutions provided by the DCA. When a nonglobal solution is found, a simple numerical procedure is introduced both to find a feasible point having a smaller objective value and to restart the DCA at this point. It is shown that in the nonconvex case, the DCA converges to the global solution of TRSP, using only matrix-vector products and requiring at most 2m + 2 restarts. Numerical simulations establish the robustness and efficiency of the DCA compared to standard related methods, especially for large-scale problems. This paper provides positive answers concerning (TRSP) in an efficient and elegant way. It is very much appreciated by the international optimization community and popularizes DC programming and DCA. It is also worth noting that TRSP plays an important role in BB algorithms using ellipsoidal outer approximation techniques for lower bounding and this method has been applied successfully in many global algorithms (see <ref type="bibr" target="#b83">[84,</ref><ref type="bibr" target="#b123">122,</ref><ref type="bibr" target="#b147">146]</ref>). Later, a careful study on the behavior of DCA sequences for TRSP was presented in <ref type="bibr" target="#b154">[153,</ref><ref type="bibr" target="#b291">290,</ref><ref type="bibr" target="#b292">291]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Ellipsoidal constrained quadratic programming problems</head><p>Ellipsoidal constrained quadratic programming problems (EQP) consist of minimizing a quadratic function subject to finitely many strictly convex quadratic constraints. It can be formulated as follows</p><formula xml:id="formula_44">min f (x) := 1 2 x T Qx + q T x : 1 2 x T A i x + (b i ) T x -r i ≤ 0, i = 1, . . . , m<label>(17)</label></formula><p>with Q being an (n × n) symmetric matrix, A i being (n × n) symmetric positive definite matrices for all i ∈ {1, . . . , m}, r i being positive numbers and x, q, b i ∈ R n . This problem arises in the context of structural optimization, particularly truss topology design problems. A special case of ( <ref type="formula" target="#formula_44">17</ref>) is the quadratic programming with two convex quadratic constraints (m = 2) which is the subproblem of many trust region algorithms for constrained optimization. Interesting applications of these algorithms are numerical solutions of parameter identification problems formulated as nonlinear least squares problems (see e.g. <ref type="bibr" target="#b52">[53]</ref> and reference therein).</p><p>In <ref type="bibr" target="#b83">[84]</ref>, we developed two approaches to solve the general problem ( <ref type="formula" target="#formula_44">17</ref>): DCA and a combined DCA-BB method. With a suitable DC decomposition, the DCA requires the computing of the orthogonal projection of a point onto the intersection of finitely many ellipsoids as the main subproblem. For this subproblem we investigated the decomposition proximal point algorithm that leads to computing the projection of a point onto a ball. Thus, the decomposition proximal point method requires only matrixvector products, and thereby seems to be efficient in large-scale setting. For the BB algorithm, always motivated by the fact that the TRSP can be efficiently solved by the DCA with restarting procedure, we used it as main subproblems in lower bounding. For this purpose, we used the Lagrangian duality for bounding and the ellipsoidal bisection for branching. Thus, in both local and global approaches suitable techniques based on an efficient algorithm for ball constrained quadratic programs was investigated. It is the key to success of the proposed algorithms for EQP. Numerical results in <ref type="bibr" target="#b83">[84]</ref> showed that DCA, with a starting point provided by bounding procedure, provided an ε-optimal solution to (17) with ε &lt; 0.05 (in 49/50 problems). By the way, the combined DCA-BB algorithm converges rapidly to a solution of <ref type="bibr" target="#b16">(17)</ref>. Note, however, that algorithm BB without DCA cannot provide an ε -solution in a reasonable time after (2500 BB iterations) when n ≥ 15, since the upper bound is improved slowly during the branching and bounding procedure. This shows that DCA plays a key role in the combined BB-DCA algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Nonconvex quadratic programs</head><p>Nonconvex quadratic programs (NQP) which consist of minimizing a quadratic function over a bounded polyhedral convex set play a crucial role in nonconvex programming from both a theoretical and an algorithmic point of view. It is a fundamental model in nonlinear programming and is known to be NP-hard except some special cases. Surprisingly enough, the problem of locally solving nonconvex quadratic programs remains NP-hard <ref type="bibr" target="#b295">[294]</ref>.</p><p>DCA was intensively investigated in our various works for NQP in the general case <ref type="bibr" target="#b122">[121,</ref><ref type="bibr" target="#b147">146,</ref><ref type="bibr" target="#b227">226]</ref> and the special case of box constrained NQP <ref type="bibr" target="#b123">[122]</ref>. We proposed three approaches: DCA schemes for finding local minimizers, the combined DCA-interior point method for large-scale problems, and the combined DCA-BB algorithms for finding global minimizers. A quadratic function is an attractive example of a DC function having various DC decompositions which enjoy great effects on resulting DCA schemes. We developed in <ref type="bibr" target="#b122">[121]</ref> suitable DC decompositions and corresponding DCA for the general case of NQP. DCA then consists in the solution of a sequence of convex quadratic programs (or linear programs when the quadratic function is concave). For globally solving NQP, we developed a combined DCA-BB algorithm using DC relaxation technique (i.e. the lower bound of a DC function f = gh is defined by the sum of g and the convex envelope of (-h) which is easily computed if h is separable in its variables) for lower bounding while upper bounds are objective values at solutions computed by DCA. This work is the basis of several methods developed in our works on different classes of quadratic programming problems. It is followed by a series of papers which are interested in combining DCA with other BB techniques for globally solving nonconvex quadratic programming using ellipsoidal bounding and branching techniques in <ref type="bibr" target="#b123">[122,</ref><ref type="bibr" target="#b147">146]</ref>, while a continuous approach based on DC Programming and DCA is investigated in <ref type="bibr" target="#b125">[124,</ref><ref type="bibr" target="#b230">229]</ref> for mixed 0-1 quadratic programming. Note that each iteration of ellipsoidal BB requires globally solving a TRSP that can be done very efficiently by DCA. It was proved in <ref type="bibr" target="#b122">[121]</ref> (Proposition 1) that when the quadratic function is concave, DCA gives almost always a local minimizer to NQP. Numerical experiments in <ref type="bibr" target="#b122">[121,</ref><ref type="bibr" target="#b123">122,</ref><ref type="bibr" target="#b147">146]</ref> show that DCAs converge very rapidly (when n ≤ 500, the maximal number of iterations is 3). Moreover, they provide a global solution if the initial point x 0 is near enough to a global one. Hence, the combined DCA-BB is interesting and so very recommended for problems with small and medium sizes.</p><p>For solving large-scale problems, a crucial issue from <ref type="bibr" target="#b122">[121]</ref> is how to efficiently solve large-scale convex quadratic programs because (even if DCA requires solutions of a few convex quadratic programs) solving these large-scale problems are expensive with other existing algorithms. We have recourse to (polynomial-time) interior point methods for solving convex quadratic programs. In <ref type="bibr" target="#b227">[226]</ref>, we provided a new regularization technique based on DC programming and DCA to handle indefinite Hessians in a primal-dual interior point framework for nonconvex quadratic programming problems. The new regularization leads automatically to a strongly factorizable quasidefinite matrix in the Newton system. Numerical results for large-scale problems (up to 400, 000 dimensions) showed the robustness and the efficiency of our approach compared with the powerful software LOQO <ref type="bibr" target="#b293">[292]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Binary linear/quadratic programs</head><p>DCA was investigated the first time in <ref type="bibr" target="#b125">[124]</ref> for the linearly constrained quadratic programming with binary variables (we call BQP in short)</p><formula xml:id="formula_45">α = min f (x) := 1 2 x, Qx + q, x : Ax ≤ b, x ∈ {0, 1} n , (BQP)</formula><p>where</p><formula xml:id="formula_46">Q is an (n × n) symmetric matrix, q, x ∈ R n , A is an (m × n) matrix and b ∈ R m . Note that binary linear program is a special case of BQP when Q = 0.</formula><p>In <ref type="bibr" target="#b125">[124]</ref> the (continuous) DC formulation of BQP was obtained by the following way. First, (BQP) was transformed equivalently in the form</p><formula xml:id="formula_47">α = min f (x) := 1 2 x, (Q -λI )x + q + λ 2 e, x : x ∈ K , p(x) ≤ 0 ,</formula><p>where λ ≥ 0 is such that the matrix Q -λI is negative semidefinite, p is a concave function with nonnegative values on</p><formula xml:id="formula_48">K := {x ∈ [0, 1] n : Ax ≤ b}, defined by p(x) = (1/2)[e T x -x T x]</formula><p>, and e denotes the vector of ones in R n . Then, from the results on exact penalty in concave minimization <ref type="bibr" target="#b148">[147]</ref>, it follows that there exists t o ≥ 0 such that for all t &gt; t o (BQP) is equivalent to the (strictly) concave quadratic minimization program: The second advantage makes our method efficient to find an integer ε-solution of (CCQP) in the large-scale setting as we show hereafter. These DCA and BB-DCA have been used for solving several problems in divers domains of application including scheduling <ref type="bibr" target="#b114">[114,</ref><ref type="bibr" target="#b162">161,</ref><ref type="bibr" target="#b193">192]</ref>, supply chain <ref type="bibr" target="#b120">[119,</ref><ref type="bibr" target="#b201">200]</ref>, transport <ref type="bibr" target="#b187">[186]</ref>, network optimization <ref type="bibr" target="#b116">[116,</ref><ref type="bibr" target="#b117">117,</ref><ref type="bibr" target="#b251">250,</ref><ref type="bibr" target="#b267">266,</ref><ref type="bibr" target="#b270">269,</ref><ref type="bibr" target="#b271">270]</ref>, cryptography <ref type="bibr" target="#b99">[100]</ref>, finance <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b105">106,</ref><ref type="bibr" target="#b159">158]</ref> where the number of integer variables goes up to 1,700,000 <ref type="bibr" target="#b267">[266]</ref>, and the above advantages of DCA have been confirmed by numerous numerical results comparing with CPLEX solver <ref type="bibr" target="#b60">[61]</ref>. It turns out in these experiments that (i) DCA always provides an integer solution and it converges after a few number of iterations (about 4); (ii) For the problems that CPLEX can (globally) solve, the gap between DCA and CPLEX is very small: to cite a few, ε = 1.6.10 -2 in <ref type="bibr" target="#b270">[269]</ref>, ε = 5.7.10 -3 in <ref type="bibr" target="#b117">[117]</ref>, ε = 6.7.10 -4 in <ref type="bibr" target="#b159">[158]</ref>, ε = 0 in <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b267">266,</ref><ref type="bibr" target="#b271">270]</ref>. In other cases, the gap between DCA and the first lower bound (given by the BB algorithm or simply by solving the first linear relaxation problem) varies between 1.5 and 10% <ref type="bibr" target="#b114">[114,</ref><ref type="bibr" target="#b120">119,</ref><ref type="bibr" target="#b201">200]</ref> (note however that, there is nothing to say that the solution given by DCA is not global in these cases); Moreover, in most cases, DCA is much faster than CPLEX, the ratio of gain goes up to 1278 times (for the minimum M-dominating set problem <ref type="bibr" target="#b251">[250]</ref> with 5, 000 integer variables); (iii) Thanks to the efficiency of DCA, the combined BB-DCA is faster than the BB and, more importantly, it can handle problems with larger dimension for which the BB cannot.</p><formula xml:id="formula_49">min 1 2 x, (Q -λI )x + q + λ 2 e, x : x ∈ K , (CCQP) with λ = λ + t.</formula><p>Besides the combined BB-DCA, another global approach, called DCA-CUT (introduced first in <ref type="bibr" target="#b200">[199]</ref> which uses the solution of DCA to construct the cutting plane), was successfully developed to solve several real-world problems (see for example <ref type="bibr" target="#b186">[185,</ref><ref type="bibr" target="#b267">266]</ref>). In particular, for the Single Straddle Carrier Routing Problem in Port Container Terminals <ref type="bibr" target="#b187">[186]</ref>, DCA-CUT gives the exact optimal solution in a very short time (less than 25 seconds) for the problems up to 4, 900 integer variables while the running time of CPLEX is up to 177 times more.</p><p>Later, in <ref type="bibr" target="#b230">[229]</ref> the SDP relaxation was investigated in the combined DCA-BB method. This technique seems to be efficient for finding a good starting point of DCA. In all cases, DCA gave a very good binary solution, most of them are -optimal solutions of BQP (with ≤ 1% or even exact optimal ones) since the number of restarting DCA is surprisingly small and equal to 1 in most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Nonlinear bilevel programming problems</head><p>In <ref type="bibr" target="#b152">[151]</ref>, the authors considered a class of nonlinear bilevel programs in which the objective function in the first level is a DC function, and the second level is a quadratic program. DCA and the combined DCA-BB were investigated for solving the relaxed problem obtained from the original one by replacing the solution set of the quadratic program in the second level by its KKT point set. The last problem is described by</p><formula xml:id="formula_50">min {F(x, y) : (x, y) ∈ K , y ∈ K T (x)} (BDCQP)</formula><p>where</p><formula xml:id="formula_51">F : R n 1 × R n 2 → R is a DC function, K ⊂ R n 1 × R n 2 is a polyhedral convex set and K T (x)</formula><p>is the set of all KKT points of the quadratic programming problem min 1  2 y, Px + y, Qy + q, y : Dx + E y + b ≤ 0 with P, Q, D and E being matrices of dimensions (n 2 × n 1 ), (n 2 × n 2 ), ( p × n 1 ) and ( p × n 2 ), respectively, Q is symmetric and q ∈ R n 2 , b ∈ R p . The KKT point set K T (x) of each given x was expressed as</p><formula xml:id="formula_52">K T (x) = {(y, λ) : Px + Qy + q + E T λ = 0, Dx + E y + b ≤ 0, λ T (Dx + E y + b) = 0, λ ≥ 0}</formula><p>and the resulting nonconvex program was reformulated as a DC program (minimizing a DC function over a polyhedral convex set) by using exact penalty technique in DC programming <ref type="bibr" target="#b142">[141,</ref><ref type="bibr" target="#b144">143]</ref>. The penalty function was defined by θ(x, y, λ) := p i=1 min{λ i , -(Dx + E y + b) i } and the linear complementarity constraint was replaced by θ(x, y, λ) ≤ 0, λ ∞ ≤ c. Suitable DC decompositions were investigated in order to get appropriate DCA and BB algorithms for the penalized problem. The very original DCA's feasibility (i.e., the sequence of points generated by DCA, applied to the penalized equivalent DC program, is contained in the feasible set of the original problem (BDCQP)) was pointed out as well as the strategy of restarting DCA with better feasible solutions given by the BB. Numerical simulations showed the effectiveness and efficiency of DCA and its combination with the BB in order to reach global solutions of (BDCQP).</p><p>One drawback of this approach resides in the fact that the nonconvex multiplier variables λ must be added to the equivalent DC program, and so increases the complexity of the problem. In <ref type="bibr" target="#b153">[152]</ref>, a new exact penalty function was proposed for solving a class of bilevel programming problems where the upper (resp. lower) objective function is quadratic (resp. linear). It permits to reformulate the equivalent DC program in the same space of the linear bilevel program. The resulting DCA scheme is quite simple: it consists of solving one linear program and one convex quadratic program at each iteration. Moreover, DCA enjoys interesting convergence properties: after a finite number of iterations it converges, in general, to a local solution. To check the globality of solutions computed by DCA a combined BB-DCA algorithm was developed. The results on random data with large dimensions show that DCA provides good approximated optimal solutions (the gap between the objective value of DCA and the lowed bound given by BB scheme is about 8% for randomly generated data), and the combined BB-DCA is efficient. An interesting real-world application in portfolio selection was considered for which DCA gives in all test problems (real data) an ε-optimal solution with ε &lt; 2%. Note that these approaches can also be applied for the case where the upper objective function is DC because that the exact penalty holds in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.6">Bilevel multiple objective programming problems</head><p>DCA and the combined DCA-BB were developed in <ref type="bibr" target="#b146">[145,</ref><ref type="bibr" target="#b149">148,</ref><ref type="bibr" target="#b151">150]</ref> for a widely studied class of the so-called Bilevel Multiple Objective Programming (BMOP) in which the upper objective is a real valued function while the lower level problem is a multiple objective linear program:</p><formula xml:id="formula_53">min {F(x) : x ∈ E(K )} (B M O P),</formula><p>where C is an (r × n) matrix, E(K ) is the solution set (called the efficient set) of the problem max{C x : x ∈ K } and K is a bounded polyhedral convex set in R n . This class of problems has many applications in multiple objective decision making <ref type="bibr" target="#b329">[328]</ref> and was intensively studied in the literature. Most of the existing algorithms deal with the case where F is a linear function. Numerical solutions by global approaches are still difficult when r ≥ 4. So, it is interesting to investigate local approaches and combine these two approaches for solving efficiently large-scale problems.</p><p>Two DC formulations of (BMOP) were proposed, one in the decision space R n <ref type="bibr" target="#b146">[145,</ref><ref type="bibr" target="#b151">150]</ref>, and another in the criteria space R r (when F is concave, <ref type="bibr" target="#b149">[148]</ref>). The key idea is to introduce suitable penalty functions for representing the efficient (or more generally, the weakly efficient) sets and then use exact penalty techniques in DC programming. DCA was then investigated for solving resulting DC programs. Unlike existing approaches, DCA can solve these problems with a large number of criteria. For globalizing DCA, several combined DCA-BB algorithms were proposed in <ref type="bibr" target="#b146">[145,</ref><ref type="bibr" target="#b151">150]</ref> where the branching procedure was efficiently proceeded in the criteria space via simplicial subdivision while bounding procedures were suitably developed for each case, when F is a convex/concave/quadratic function <ref type="bibr" target="#b146">[145]</ref> and when F is linear <ref type="bibr" target="#b151">[150]</ref>. The numerical results in <ref type="bibr" target="#b146">[145,</ref><ref type="bibr" target="#b151">150]</ref> showed that DCA is reliable in finding a good efficient point and/or a global minimizer to problem (BMOP), although, in general, the starting point of DCA is not in E(K ). More precisely DCA found an εoptimal solution with ε &lt; 1 in 85% cases (128/150 problems), and a global minimizer in 76% cases (114/150 problems). In particular, when r ≥ 5, DCA gave the global solutions in 43 out of the 50 cases. Hence it is interesting to use DCA while computing upper bounds in BB methods. As for the BB scheme, it is useful to get the initial point and to prove the globality of DCA. By the way, the combined DCA-BB can solve problems of larger dimension.</p><p>In <ref type="bibr" target="#b149">[148]</ref>, a BB method using simplicial subdivision and two tight affine minorants for bounding was proposed for the case where F is a linear function. This algorithm works very well when p ≤ 4. Nevertheless, as in any global method for optimizing over the efficient and/or weakly efficient sets, it is very difficult to solve the problem when p ≥ 5. DCA and the combined DCA-BB are really required to handle large-scale problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.7">Linear complementarity problems</head><p>The simplest and most widely studied complementarity problem is the Linear Complementarity Problem (LCP), which is one of the fundamental problems of mathematical programming. It consists of finding a vector x ∈ R n \ {0} such that</p><formula xml:id="formula_54">Ax + b, x = 0, Ax + b ≥ 0, x ≥ 0,</formula><p>for a given real (n ×n) matrix A and a vector b ∈ R n . The LCP is known to be NP-hard, even if the underlying symmetric matrix has only one negative eigenvalue. Although the LCP is not explicitly an optimization problem, there exist in the literature various optimization models and methods for solving it. In general, the resulting optimization problem of LCP is nonconvex, and thus solving such a problem by global approaches is very difficult in the large-scale setting.</p><p>DC programming and DCA were carefully investigated in <ref type="bibr" target="#b82">[83,</ref><ref type="bibr" target="#b133">132]</ref> for LCP (a follow-up to <ref type="bibr" target="#b133">[132]</ref> is done recently in <ref type="bibr" target="#b61">[62]</ref>). When A is symmetric, solving the LCP is equivalent to finding a KKT point of the quadratic program min f (x) := 1 2</p><p>x, Ax + b, x : x ≥ 0 which can be done by a very inexpensive DCA scheme. If A is asymmetric, the LCP becomes much more difficult than the symmetric case. We proposed four optimization formulations to LCP including a linear constrained quadratic program, a concave minimization problem with separate variables: a simple constrained (nonnegativity of variables) quadratic program, and a bilinear program: whose the optimal value is equal to zero when the LCP has a solution. This property is interesting for using local approaches and iterative algorithms such as DCA: the known optimal value can be used as a stopping rule for iterative algorithms and for checking the globality of the obtained solution. These four optimization problems are all DC programs with quite simple structure which are quite suitable for applying DCA. Basing on appropriate DC decomposition for each of four proposed optimization models we developed simple DCA schemes which consist of solving successive linear programs, or successive convex quadratic programs, or quite simply the projection of points on R 2n (or on R n + in the symmetric case). Numerical experiments on several test problems given in <ref type="bibr" target="#b40">[41]</ref> and some previous works (see <ref type="bibr" target="#b133">[132]</ref>) proved the efficiency and the rapidity as well as the scalability of the proposed approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.8">Eigenvalue complementarity problems</head><p>For given matrices A ∈ R n×n and B ∈ S ++ n , where S ++ n denotes the set of all (n × n) symmetric positive definite matrices, the so-called Eigenvalue Complementarity Problem (EiCP) consists of finding λ ∈ R (Complementary Eigenvalue) and x ∈ R n \ {0} (Complementary Eigenvector) such that w = (λB -A)x, w ≥ 0, x ≥ 0, w T x = 0.</p><p>The EiCP is an extension of the classical eigenvalue problem that has been widely studied <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b241">240]</ref>. Solving the EiCP is in general an NP-hard problem since determining the feasibility of EiCP is already proved to be an NP-complete problem <ref type="bibr" target="#b63">[64]</ref>.</p><p>DC programming and DCA were investigated for both Symmetric Eigenvalue Complementarity problem SEiP <ref type="bibr" target="#b106">[107]</ref> (EiCP when A and B are both symmetric matrices), and Asymmetric Eigenvalue Complementarity Problem AEiCP <ref type="bibr" target="#b204">[203]</ref> (EiCP when A is an asymmetric matrix and B is a positive definite matrix). Among several equivalent formulations of SEiCP in the literature, the three most interesting formulations for the use of DCA were considered in <ref type="bibr" target="#b106">[107]</ref>: solving SEiCP amounts to finding a KKT point of these optimization problems. Thus, applying DCA on these problems one gets solutions to SEiCP (this result is no longer valid when the matrix A is asymmetric). Three DCA schemes were developed for minimizing the generalized Rayleigh quotient on the standard n -1 simplex, minimizing a difference of logarithmic functions on the standard n -1 simplex, and minimizing a quadratic function with one quadratic constraint and simple constraints. The nice effect of DC decompositions was well exploited, especially in the two DCA schemes whose main work per iteration relies on the computation of a projection of a point onto the standard n -1 simplex. Computational experiments showed that DCA is quite efficient and in most of the cases DCA outperforms Spectral Projected Gradient Algorithm (SPGA) <ref type="bibr" target="#b64">[65]</ref>, one among the best existing algorithms for EiCP.</p><p>As for AEiCP, similar to the LCP, there are nonlinear programming (NLP) formulations having interesting properties which are suitable to the use of DCA <ref type="bibr" target="#b204">[203]</ref>: if their optimal value is equal to zero, then their optimal solutions correspond to solutions of the AEiCP. Three NLP formulations were introduced, they were reformulated as DC programs by penalizing nonlinear constraints (including complementarity constraints). Two DCA schemes were proposed for two resulting DC programs, one is minimizing a sum of a convex quadratic function and three nonconvex polynomial functions over a polytope, the other is minimizing a sum of a convex quadratic function, a nonconvex polynomial function and a nonconvex fractional function over a polytope. Two initialization strategies for DCA using SDP (Semi Definite Programming) and convex quadratic programming were investigated. Some numerical simulations for randomly generated problems and real-world problems showed a good performance of DCA. DCA almost always yields a global optimal solution with zero optimal value of NLP formulations (solution of EiCP) within a short computational time and is especially efficient for relatively large-scale problems. These remarkable results outperformed the Enumerative method, Branch-and-bound method, and BARON/GAMS presented in <ref type="bibr" target="#b64">[65]</ref>.</p><p>Another class of complementarity problems is the Quadratic Eigenvalue Complementarity Problem (QEiCP) which consists of finding a real number λ and a vector x ∈ R n \{0} such that w = λ 2 Ax + λBx + C x, x T w = 0, x ≥ 0, w ≥ 0, where A, B, C ∈ R n×n are given matrices. The problem QEiCP and its applications were first introduced in <ref type="bibr" target="#b258">[257]</ref>. At the time being, a few algorithms are available in the literature.</p><p>DCA was developed in <ref type="bibr" target="#b203">[202]</ref> for QEiCP where the authors reformulated QEiCP as minimizing a nonconvex polynomial function subject to linear constraints. DCA applied on QEiCP requires solving a convex quadratic program over a polyhedral convex set at each iteration which can be efficiently solved by many quadratic programming solvers such as CPLEX of IBM <ref type="bibr" target="#b60">[61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.9">Sparse optimization</head><p>Sparse optimization or optimization involving the zero norm has many applications in various domains, and draws increased attention from many researchers in recent years. The 0 -norm on R n , denoted . 0 , is defined by x 0 := |{i = 1, . . . , n : x i = 0}|, where |S| is the cardinality of the set S. Formally, a sparse optimization problem takes the form</p><formula xml:id="formula_55">inf f (x, y) + λ x 0 : (x, y) ∈ K ⊂ R n ×R m , (<label>18</label></formula><formula xml:id="formula_56">)</formula><p>where the function f corresponds to a given criterion and λ is a positive number that makes the trade-off between the criterion f and the sparsity of x, or inf{ f (x, y) :</p><formula xml:id="formula_57">(x, y) ∈ K , x 0 ≤ k}. (<label>19</label></formula><formula xml:id="formula_58">)</formula><p>During the last two decades, research is very active in models and methods optimization involving the zero-norm. Works can be divided into three categories according to the way to treat the zero-norm: convex approximation, nonconvex approximation, and nonconvex exact reformulation. Nonconvex approximation approaches were extensively developed to solve <ref type="bibr" target="#b17">(18)</ref>, most of them were in the context of machine learning and image analysis (feature selection in classification, sparse regressions, and compressed sensing, see Sect. 3.4.2 (j) below). A variety of sparsity-inducing penalty functions were proposed to approximate the 0 term (see the related references in <ref type="bibr" target="#b145">[144]</ref>). Using these approximations, several algorithms have been developed for resulting optimization problems. In the recent seminal paper <ref type="bibr" target="#b145">[144]</ref>, nonconvex approximation approaches for sparse optimization were studied with a unifying point of view in DC programming framework. Considering a common DC approximation of the zero-norm including all standard sparse inducing penalty functions, the authors studied the consistency between global minimums (resp. local minimums) of approximate and original problems and showed that, in several cases, some global minimizers (resp. local minimizers) of the approximate problem are also those of the original problem. Based on exact penalty techniques in DC programming, stronger results for some particular approximations were proved, namely, the approximate problem, with suitable parameters, is equivalent to the original problem. The efficiency of several sparse inducing penalty functions was fully analyzed. Four DCA schemes were developed that cover all standard algorithms in nonconvex sparse approximation approaches as special versions. They can be viewed as, an 1 -perturbed algorithm/reweighted-1 algorithm. This paper offered a unifying nonconvex approximation approach, with solid theoretical tools as well as efficient algorithms based on DC programming and DCA, to tackle the zero-norm and sparse optimization. As an application, the proposed methods were implemented for the feature selection in SVM problem and performed empirical comparative numerical experiments on the proposed algorithms with various approximation functions.</p><p>There are few works in nonconvex exact reformulation approaches which consist of reformulating equivalently a sparse optimization problem as a continuous nonconvex program. Besides the linear program with equilibrium constraints (LPEC) formulation for <ref type="bibr" target="#b17">(18)</ref> when f is linear <ref type="bibr" target="#b182">[181]</ref>, works in these approaches deal with DC programming and DCA. They were developed in <ref type="bibr" target="#b105">[106]</ref> (for Portfolio selection problem with cardinality constraint), <ref type="bibr" target="#b281">[280]</ref> (for the general classes ( <ref type="formula" target="#formula_55">18</ref>) and ( <ref type="formula" target="#formula_57">19</ref>)), <ref type="bibr" target="#b282">[281]</ref> (for Sparse Eigenvalue problem of the form max{x T Ax : x T x = 1, x 0 ≤ k}), and in <ref type="bibr" target="#b98">[99]</ref> for <ref type="bibr" target="#b17">(18)</ref> and application to feature selection in SVM. The key idea is using the penalty techniques related to the 0 -norm to reformulate ( <ref type="formula" target="#formula_55">18</ref>) and ( <ref type="formula" target="#formula_57">19</ref>) as DC programs, that can be treated by DC programming and DCA. We suppose that K is bounded in the variable x, i.e., K <ref type="formula" target="#formula_55">18</ref>) and ( <ref type="formula" target="#formula_57">19</ref>) can be reformulated as</p><formula xml:id="formula_59">⊂ n i=1 [a i , b i ] × R m where a i , b i ∈ R such that a i ≤ 0 &lt; b i for i = 1, . . . , n. Then (</formula><formula xml:id="formula_60">α := inf{ f (x, y) + λe T u : (x, y) ∈ K , u ∈ {0, 1} n , |x i | ≤ c i u i , i = 1, . . . , n},<label>(20)</label></formula><p>where c i := max{|x i | :</p><formula xml:id="formula_61">x i ∈ [a i , b i ]} = max{|a i | , |b i |} for i = 1, . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, n, and</head><formula xml:id="formula_62">α := inf{ f (x, y) : (x, y) ∈ K , u ∈ {0, 1} n , |x i | ≤ c i u i , i = 1, . . . , n, e T u ≤ k },<label>(21)</label></formula><p>respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.10">Optimizing radial basis functions and global derivative-free optimization</head><p>In recent years, the derivative-free global optimization methods based on RBFs (Radial Basis Functions) have been proposed by several authors. The main idea is that, in each iteration of direct search, an RBF model with as many points as possible is constructed and then it is minimized in the intersection of the feasible set with a trust region whose radius is proportional to the direct-search step size. In this framework, the authors of <ref type="bibr" target="#b164">[163]</ref> addressed the global optimization of functions subject to bound and linear constraints and investigated two DCA schemes for the resulting subproblems which consist of the minimization of the RBF models subject to simple bounds on the variables. The best proposed DCA was compared to the MATLAB fmincon solver and proved to be competitive (in the sense that DCA obtains similar objective function values using fewer objective function evaluations). Extensive numerical results were reported, they confirmed the utility of the RBF in driving the overall direct-search algorithm for a better objective function value using fewer objective function evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.11">Nonlinear optimization with convex constraints</head><p>In <ref type="bibr" target="#b93">[94]</ref> the authors proposed a DC trust-region algorithm to solve a class of nonlinear optimization problems where the constrained set C is closed and convex (and, from a practical point of view, where projecting onto the feasible region is computationally affordable). Here DCA was investigated for solving the resulting trust-region subproblems which consist of minimizing quadratic models on the intersection of the feasible set C with a trust region (especially, when C is defined by bounds on the variables these subproblems become box constrained quadratic programs for which DCA is explicit and very inexpensive). The overall approach was shown to be globally convergent to first-order critical points (when the second-order information used in the quadratic model DC decompositions is exact). The remarkable point is that the theory only requires one DCA iteration on the trust-region subproblem to ensure global convergence, which amounts to only one projection onto the feasible region (we recall that the computation of the generalized Cauchy point may take more than one projection). The numerical efficiency and robustness of the proposed new scheme when applied to bound-constrained problems were measured by comparing its performance against some of the current state-of-the-art nonlinear programming solvers on a vast collection of test problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Related DCA based algorithms</head><p>Besides the above mentioned DCA solvers, during the last decade, the DCA principle has been used under different guises in several works. To a complete survey, it would be useful to discuss about these related approaches which include various DCA versions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">SCA based methods</head><p>(a) Single block SCA <ref type="bibr" target="#b243">[242]</ref>. The considered optimization problem is</p><formula xml:id="formula_63">min{ f 0 (x) + g 0 (x) : f j (x) + g j (x) ≤ 0, j = 1, . . . ., m}<label>(22)</label></formula><p>where f j is smooth (possibly nonconvex) and g j is convex (possibly nonsmooth). SCA <ref type="bibr" target="#b243">[242]</ref> iteratively approximates f j (x), j = 0, . . . , m by convex surrogate functions θ j (x, x k ), j = 0, . . . , m which satisfies the following assumptions: (i) θ j (y, y) = f j (y); (ii) θ j (x, y) ≥ f j (x); (iii) ∇θ j (., y)(y) = ∇ f j (y); (iv) θ j (x, y) is continuous in (x, y).</p><p>The practical useful approximations are linear approximation, convex quadratic approximation, proximal approximation, and by a similar way showed in Sect. 1 we can see that the resulting SCA algorithms are in fact general DCA schemes (DCA applied on general DC programs of the type C).</p><p>(b) Parallel SCA for nonsmooth nonconvex optimization <ref type="bibr" target="#b245">[244]</ref>. The considered optimization problem is</p><formula xml:id="formula_64">min f (x) + n i=1 g i (x i ) : x = (x 1 , . . . , x n ) ∈ X 1 × . . . × X n , (<label>23</label></formula><formula xml:id="formula_65">)</formula><p>where X i is a closed convex set, f (x) is a smooth function (possibly nonconvex), g(x) = n i=1 g i (x i ) is a separable convex function (possibly nonsmooth). At each iteration k, parallel SCA chooses a subset s k ⊂ {1, . . . , n} and approximates f with respect to x i , i ∈ s k by strongly convex function θ i (x i , x k ) satisfying the above assumptions (i)-(iv). The subset s k can be chosen by the randomized or cyclic variable selection rules. We observe that parallel SCA is a block version of SCA. Two commonly used strongly convex approximations are the convex quadratic upper bound and the proximal upper bound. In these cases parallel SCA can be considered as a block version of DCA. In application, the authors considered the lasso problem and used the proximal upper bound.</p><p>(c) Jacobi SCA Algorithm <ref type="bibr" target="#b257">[256]</ref>. Consider the optimization problem min</p><formula xml:id="formula_66">⎧ ⎨ ⎩ V (x) = N j=1 f j (x) : x = (x 1 , . . . , x n ) ∈ X 1 × . . . × X n ⎫ ⎬ ⎭ , (<label>24</label></formula><formula xml:id="formula_67">)</formula><p>where X i and f j satisfy the following conditions: (i) X i is closed and convex;</p><p>(ii)</p><formula xml:id="formula_68">f j (x) is continuously differentiable on X = X 1 × . . . × X n ; (iii) ∇ x i f j (x)</formula><p>is Lipschitz continuous on X ; (iv) V (x) is coercive with respect to X . Jacobi SCA is a distributed version of SCA. Denote x -i = (x j ) j =i and C i ⊂ {j : f j (., x -i ) is convex on X i , for all x -i }. At each iteration k, for all i = 1, . . . , n, the exact Jacobi SCA Algorithm approximates V (x) with respect to x i by a convex surrogate function θ C i (x i , x k ) and computes</p><formula xml:id="formula_69">xC i (x k , τ i ) = arg min θ C i (x i , x k ) : x i ∈ X i , (<label>25</label></formula><formula xml:id="formula_70">)</formula><p>where θ C i (x i , x k ) is the convex quadratic approximation given by</p><formula xml:id="formula_71">θ C i (x i , x k ) = j∈C i f j (x i , x k -i ) + j∈C -i ∇ x i f j (x k ) T (x i -x k i ) + τ i 2 (x i -x k i ) T H i (x k )(x i -x k i ), (<label>26</label></formula><formula xml:id="formula_72">)</formula><p>with C -i and H i (x k ) being, respectively, the complement of C i in {1, ..., N } and a uniformly positive definite matrix, and τ i &gt; 0. And the next feasible vector x k+1 is computed by</p><formula xml:id="formula_73">x k+1 = x k + γ k ( xC (x k , τ ) -x k ), (<label>27</label></formula><formula xml:id="formula_74">)</formula><p>where</p><formula xml:id="formula_75">xC (x k , τ ) = xC i (x k , τ i ) n i=1</formula><p>. We observe that if j∈C i f j (x i , x -i ) only depends on x i , i.e., j∈C i f j (x i , x -i ) = fi (x i ) and γ k = 1, Jacobi SCA can be interpreted as a DCA scheme with successive DC decomposition. In <ref type="bibr" target="#b257">[256]</ref>, the authors have also proposed an inexact Jacobi SCA Algorithm replacing xC i (x k , τ i ) by its approximation z k i within the accuracy k i . (d) NOVA: iNner cOnVer Approximation algorithm <ref type="bibr" target="#b255">[254,</ref><ref type="bibr" target="#b256">255]</ref>. Consider the constrained optimization problem:</p><formula xml:id="formula_76">min{U (x) : g j (x) ≤ 0, j = 1, . . . , m, x ∈ K },<label>(28)</label></formula><p>where U (x) is a Lipschitz continuous gradient function, g j (x) is continuously differentiable and K is closed convex. The idea of NOVA is to iteratively approximate U (x) by a strongly convex function Ũ (x, x k ) satisfying Assumption (i)-(iv) in (b) (do not require global upper-bound property) and g j (x) by convex functions g j (x, x k ) satisfying Assumption (i)-(iv) in (a). More precisely, at each iteration k, NOVA computes</p><formula xml:id="formula_77">xk+1 ∈ arg min{ Ũ (x, x k ) : g j (x, x k ) ≤ 0, j = 1, . . . , m, x ∈ K }<label>(29)</label></formula><p>and then sets</p><formula xml:id="formula_78">x k+1 = x k + γ k ( xk+1 -x k ).</formula><p>In practice, the strongly convex approximations Ũ (x, x k ) of U (x) are commonly chosen to be the convex quadratic/proximal approximations and the convex approximations g j (x, x k ) of g j (x) are also the convex linear/quadratic/proximal approximations. In such cases, NOVA with γ k = 1 can be interpreted as a general DCA scheme (i.e. DCA for general DC programs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">(B)SUM: (Block) successive upper-bound minimization</head><p>(a) SUM: Successive upper-bound minimization <ref type="bibr" target="#b244">[243]</ref>. Consider the optimization problem</p><formula xml:id="formula_79">min{ f (x) : x ∈ X }, (<label>30</label></formula><formula xml:id="formula_80">)</formula><p>where f is continuous and X is a closed convex set. SUM <ref type="bibr" target="#b244">[243]</ref> is similar to SCA, but SUM does not require the convexity of θ(x, x k ). Instead, it must satisfy the following conditions:</p><formula xml:id="formula_81">(i) θ(y, y) = f (y) ∀y ∈ X ; (ii) θ(x, y) ≥ f (x) ∀x, y ∈ X ; (iii) θ (x, y; d) = f (y; d) ∀d with y + d ∈ X ; (iv) θ(x, y) is continuous in (x, y);</formula><p>where f (y; d) is the directional derivative of f at point y in direction d. Even if SUM does not require the convexity of θ , in practice, commonly used approximations in SUM based algorithms are convex, more precisely linear/quadratic or proximal upper bounds. Hence, as mentioned in Sect. 1, the resulting SUM algorithms is a DCA version. <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b243">242,</ref><ref type="bibr" target="#b244">243]</ref>. BSUM addresses the optimization problem of the form</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) BSUM: Block successive upper-bound minimization</head><formula xml:id="formula_82">min{ f (x) : x = (x 1 , . . . , x n ) ∈ X 1 × . . . × X n }. (<label>31</label></formula><formula xml:id="formula_83">)</formula><p>BSUM is a block version of SUM. More precisely, at each iteration k, BSUM chooses the block i = (k mod n) + 1, and solves the following problem</p><formula xml:id="formula_84">x k i ∈ arg min{θ i (x i , x k-1 ) : x i ∈ X i },<label>(32)</label></formula><p>where</p><formula xml:id="formula_85">θ i (x i , x k-1</formula><p>) is an approximation of f (x) which satisfies the following assumptions (i)</p><formula xml:id="formula_86">θ i (y i , y) = f (y) ∀y ∈ X ; (ii) θ i (x i , y) ≥ f (y 1 , . . . , y i-1 , x i , y i+1 , . . . , y n ) ∀x i ∈ X i , y ∈ X ; (iii) θ i (x i , y; d) = f (y; d) ∀d = (0, . . . , d i , . . . , 0) with y i + d i ∈ X i ; (iv) θ i (x i , y) is continuous in (x i , y) for all i.</formula><p>In <ref type="bibr" target="#b244">[243]</ref>, the authors provided convergence properties of BSUM by assuming that the subproblem (32) has a unique solution for all x k-1 . Observe that BSUM is a block version of SUM and with the above usual majorization BSUM is a block version of DCA. Note that, there is no SUM/BSUM scheme implemented in case of the subproblems are nonconvex. The reason seems to be natural, as globally solving the sequence of nonconvex subproblems is still difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Proximal point algorithms [265]</head><p>[265] proposed a proximal point algorithm (PPA) for DC programs</p><formula xml:id="formula_87">min x { f (x) = g(x) -h(x)}, (<label>33</label></formula><formula xml:id="formula_88">)</formula><p>where g, h are proper, convex, and lower semi-continuous. PPA iteratively computes w k ∈ ∂h(x k ) and</p><formula xml:id="formula_89">x k+1 = arg min x g(x) + 1 2c k x -x k -c k w k 2 . (<label>34</label></formula><formula xml:id="formula_90">)</formula><p>It is easy to verify that PPA is nothing else but DCA applied on <ref type="bibr" target="#b32">(33)</ref> with the following successive DC decomposition</p><formula xml:id="formula_91">f (x) = g k (x) -h k (x), g k (x) = g(x) + 1 2c k x 2 , h k (x) = h(x) + 1 2c k x 2 . (<label>35</label></formula><formula xml:id="formula_92">)</formula><p>Note that in the convex case (h = 0), PPA reduces to classical PPA proposed in <ref type="bibr" target="#b183">[182,</ref><ref type="bibr" target="#b249">248]</ref>. In <ref type="bibr" target="#b65">[66]</ref>, the convexity of g is replaced by the convexity of g(x) + 1 2c k x 2 . Hence PPA of <ref type="bibr" target="#b65">[66]</ref> is actually a version of DCA with successive DC decomposition. <ref type="bibr" target="#b9">[10]</ref> did not require the convexity on g but assumed that x k+1 can be computed. PPA in <ref type="bibr" target="#b9">[10]</ref> can be regarded as a DCA-type algorithm (say, approximating h by an affine function and then solving the resulting problem).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">The FBSA and GIST algorithms</head><p>In <ref type="bibr" target="#b10">[11]</ref>, the authors proposed the FBSA (Forward-Backward Splitting Algorithm) for solving the next problem:</p><formula xml:id="formula_93">min x { f (x) = g 1 (x) + g 2 (x)}, (<label>36</label></formula><formula xml:id="formula_94">)</formula><p>where g 1 is a proper lower semicontinuous function and g 2 is a C 1 function with L-Lipschitz gradient. FBSA iteratively computes</p><formula xml:id="formula_95">x k+1 ∈ arg min x g 2 (x k ) + ∇g 2 (x k ), x -x k + t k 2 x -x k 2 + g 1 (x) . (<label>37</label></formula><formula xml:id="formula_96">)</formula><p>Suppose that we can determine a number t k such that</p><formula xml:id="formula_97">g k (x) = g 1 (x) + t k 2 x 2 and h k (x) = t k 2 x 2 -g 2 (x) are convex functions.</formula><p>Then f is a DC function and ( <ref type="formula" target="#formula_95">37</ref>) is nothing else but DCA applied on <ref type="bibr" target="#b35">(36)</ref> with the successive DC decomposition f = g kh k . For any real number t k , FBSA is a DCA-type algorithm with successive DC decomposition.</p><p>Note that if g 1 is a DC function, FBSA reduces to the GIST (General Iterative Shrinkage and Thresholding) algorithm proposed in <ref type="bibr" target="#b46">[47]</ref>. <ref type="bibr" target="#b29">[30]</ref> considered a special case where both g 1 and g 2 are convex. On the other hand, Fixed Point Iteration Algorithm <ref type="bibr" target="#b50">[51]</ref> is a forward-backward splitting algorithm with constant step-size for solving the problem min x x 1 + f (x), where f is differentiable and convex. Hence, Fixed Point Iteration Algorithm is actually a DCA scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5">DC proximal Newton algorithm (DC-PN)</head><p>In <ref type="bibr" target="#b242">[241]</ref>, the authors proposed a so-called DC-PN algorithm for the following problem:</p><formula xml:id="formula_98">inf{F(x) := f (x) + h(x) : x ∈ R n },<label>(38)</label></formula><p>where f and h are DC functions</p><formula xml:id="formula_99">f = f 1 -f 2 , h = h 1 -h 2 , with f 1 , f 2 , h 1 , h 2 being real-valued convex funtions on R n , f twice diffenrentiable and f 1 differentiable with gradient Lipschitz of rank L. DC-PN consists of computing z k f 2 = ∇ f 2 (x k ), z k h 2 ∈ ∂h 2 (x k</formula><p>) and solving the following convex problem only one step by proximal Newton to update x k+1</p><formula xml:id="formula_100">min x f 1 (x) + h 1 (x) -z k f 2 + z k h 2 , x .</formula><p>More precisely, DC-PN requires to compute</p><formula xml:id="formula_101">xk ∈ arg min h 1 (x) + 1 2 x T H k x + ∇ f 2 (x k ) -z k f 2 -z k h 2 -H k x k , x , (<label>39</label></formula><formula xml:id="formula_102">)</formula><p>and find step size t k via line search and update</p><formula xml:id="formula_103">x k+1 = x k + t k x k , where x k = xk -x k .</formula><p>If one takes t k = 1, then x k+1 = xk and it is no difficult to verify that DC-PN is actually a DCA with the successive DC decomposition F(x) = g k (x)h k (x), where g k (x) and h k (x) are convex functions given by</p><formula xml:id="formula_104">g k (x) = h 1 (x) + 1 2 x T H k x, h k (x) = 1 2 x T H k x -f 1 (x) + f 2 (x) + h 2 (x).</formula><p>Note that if f 2 = h 2 = 0, DC-PN reduces to proximal Newton-type methods in convex optimization <ref type="bibr" target="#b168">[167]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.6">Stochastic gradient descent (SGD)</head><p>The idea of stochastic approximation method is introduced by <ref type="bibr" target="#b247">[246]</ref> and developed in <ref type="bibr" target="#b16">[17]</ref>. More precisely, <ref type="bibr" target="#b16">[17]</ref> have developed the stochastic gradient algorithm for minimizing the expected risk function min</p><formula xml:id="formula_105">x∈R d f (x) = E ξ f (ξ, x) , (<label>40</label></formula><formula xml:id="formula_106">)</formula><p>where f (ξ, x) is a differentiable, convex function. The expected risk function cannot be minimized directly because the grand truth distribution is unknown. However, it is possible to compute an approximation by using n realizations ξ 1 , ..., ξ n of ξ with n being large enough. The approximation problem of ( <ref type="formula" target="#formula_105">40</ref>) is min</p><formula xml:id="formula_107">x∈R d f (x) = 1 n n i=1 f (ξ i , x) . (<label>41</label></formula><formula xml:id="formula_108">)</formula><p>At each iteration k, SGD randomly chooses a realization ξ i k and computes x k+1 by the following rule</p><formula xml:id="formula_109">x k+1 = x k -α k ∇ f (ξ i k , x k ), (<label>42</label></formula><formula xml:id="formula_110">)</formula><p>where α k is the learning rate. SGD can be interpreted as a stochastic version of DCA developed in <ref type="bibr" target="#b236">[235]</ref>. Indeed, the problem (41) can be expressed as a DC program min</p><formula xml:id="formula_111">x∈R d { f (x) = g(x) -h(x)}, (<label>43</label></formula><formula xml:id="formula_112">)</formula><p>where g(x) and h(x) are given by</p><formula xml:id="formula_113">g(x) = ρ 2 x 2 , h(x) = 1 n n i=1 ρ 2 x 2 -f (ξ i , x) := 1 n n i=1 h i (x),</formula><p>with ρ &gt; 0 such that ρ 2 x 2f (ξ i , x) is convex. At each iteration k, stochastic DCA consists of randomly choosing ξ i k and computing a stochastic approximation</p><formula xml:id="formula_114">y i k of ∇h(x k ) by y i k = ∇h i k (x k ) = ρx k -∇ f (ξ i k , x k</formula><p>), and then computing x k+1 by</p><formula xml:id="formula_115">x k+1 ∈ arg min g(x) -y i k , x ⇔ x k+1 = x k - 1 ρ ∇ f (ξ i k , x k ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">DCA solvers for real-world applications</head><p>DCA was successfully applied to many large-scale DC optimization problems and proved to be more robust and efficient than related standard methods, thanks to the flexibility and the nice effect of DC decompositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Computational biology</head><p>DC programming and DCA were extensively developed for several challenging classes of problems in computational biology-Multiple Sequence Alignment, Molecular conformation, Protein fold recognition, and Phylogenetic tree reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Multiple sequence alignment (MSA)</head><p>It is well-known that the MSA problem can be transformed into the NP-complete Maximum Weight Trace problem (MWT in short), as a natural formulation of merging partial alignments to form multiple alignments. Le Thi et al. <ref type="bibr" target="#b140">[139]</ref> proposed a constraint generation method based on DCA to the MSA using the 0-1 linear formulation of the MWT. This method solves, at each iteration, one 0-1 linear program for which DCA is used. Numerical simulation experiments showed the superiority of this approach compared to some standard methods. In <ref type="bibr" target="#b5">[6]</ref>, two new formulations were proposed for the MSA: a new 0-1 quadratic programming formulation whose the number of variables and constraints are much smaller than that of the MWT, and a compact linear 0-1 formulation of the MWT. The authors proposed to use DCA for these new formulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) Molecular conformation</head><p>These last years there has been a very active research in the molecular conformation, one of major subjects of computational biology. When the molecular conformation is determined by distances between pairs of atoms in the molecule, the molecular conformation is tackled by solving the distance geometry problem which has many applications in various domains. DC programming and DCA were extensively studied for solving both exact distance geometry problem (finding n points x 1 , . . . , x n ∈ R p such that x ix j = δ i j , (i, j) ∈ S , where S is a subset of the point pairs, δ i j with (i, j) ∈ S is the given distance between x i and x j ) in <ref type="bibr" target="#b129">[128]</ref> and general distance geometry problem (finding x 1 , . . . , x n ∈ R p such that l i j ≤ x ix j ≤ u i j , (i, j) ∈ S , where l i j and u i j are lower and upper bounds of the distance between x i and x j , respectively) in <ref type="bibr" target="#b84">[85,</ref><ref type="bibr" target="#b124">123,</ref><ref type="bibr" target="#b130">129,</ref><ref type="bibr" target="#b136">135]</ref>, and testing on real datasets of molecular conformation. It has been shown in these works that the DCA can be well exploited to obtain efficient algorithms for both exact and general large-scale distance geometry problems. Key issues of DCA were carefully studied and several techniques were proposed to exploit the nice effect of DC decompositions (the Lagrangian duality without gap relative to DC programming, the regularization techniques) and of starting points (using the shortest paths between all pairs of atoms to generate the complete dissimilarity matrix and the spanning trees procedure and the smoothing technique). Many numerical simulations of the molecular optimization problems with up to 12,567 variables (4189 atoms) reported in <ref type="bibr" target="#b84">[85,</ref><ref type="bibr" target="#b124">123,</ref><ref type="bibr" target="#b129">128]</ref> proved the practical usefulness of the nonstandard nonsmooth reformulations, the globality of found solutions, and the robustness and efficiency of DCAs. Note that, so far the optimization existing methods consider the problem of medium-sized molecules (777 atoms) only.</p><p>Molecular conformation can also be done by minimizing an energy function whose global minimizer corresponds to the molecular structure. In this context, the Lennard-Jones and Morse potential energies are mostly used. DCAs were carefully studied for minimizing the Lennard-Jones potential energy <ref type="bibr" target="#b134">[133]</ref> and the Morse potential energy <ref type="bibr" target="#b135">[134]</ref>. They are very difficult and challenging global optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(c) Phylogenetic tree reconstruction</head><p>In <ref type="bibr" target="#b34">[35]</ref> the authors proved that the phylogenetic tree reconstruction, a fundamental task in evolutionary biology, is a DC program and proposed a cutting plane method for computing the branch lengths x of the tree. This algorithm works on small datasets (5 sequences). In <ref type="bibr" target="#b86">[87]</ref>, a DCA scheme was developed which works well on large size datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(d) Protein fold recognition</head><p>Enhanced protein fold recognition through a novel data integration approach was proposed in <ref type="bibr" target="#b326">[325]</ref>.</p><p>For a complete review on DC programming and DCA for computational biology (resp. distance geometry problems) the reader is referred to <ref type="bibr" target="#b87">[88]</ref> (resp. <ref type="bibr" target="#b136">[135]</ref>).</p><p>One can have another insight of the applications of DCA in Biology through machine learning techniques. In this framework DCA was investigated to gene selection in cancer classification <ref type="bibr" target="#b121">[120]</ref>, network-based penalized regression with application to genomic data <ref type="bibr" target="#b67">[68]</ref>, to name a few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Machine learning and data mining</head><p>Machine Learning and Data Mining (MLDM in short) represent a mine of optimization problems that are almost all DC programs for which appropriate solution methods should use DC programming and DCA. During the last decade DC programming and DCA have been successfully applied to modeling and solving many problems in MLDM. As mentioned above, the three methods Expectation-Maximization (EM) <ref type="bibr" target="#b32">[33]</ref>, Successive Linear Approximation (SLA) <ref type="bibr" target="#b19">[20]</ref> and Convex-Concave Procedure (CCCP) <ref type="bibr" target="#b330">[329]</ref>, better known, in a certain period, to data miners-not aware of the state-of-the-art in optimization-are particular cases of DCA. In addition, these three methods, without proof of convergence, relate only to differentiable functions. Since then, the paternity has been acknowledged by leading experts in the field in their publications. We give below a brief overview of the problems in MLDM which were solved by DCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Clustering</head><p>Clustering is a fundamental problem in unsupervised learning and has many applications in various domains. DCA is extensively investigated in various works for all matters of clustering: hard/fuzzy/weighted/block/hierarchical clustering. The first work <ref type="bibr" target="#b88">[89]</ref> was devoted to hard (partitional) clustering via the most popular formulation, the so-called minimum sum-of-squares clustering (MSSC) of the form</p><formula xml:id="formula_116">min n k=1 min i=1,...,c x k -v i 2 2 : v i ∈ R d , i = 1, . . . , c .</formula><p>A very simple and inexpensive DCA scheme where all computations are explicit was proposed in <ref type="bibr" target="#b88">[89]</ref>. This work is the basis of several DCAs developed for clustering data streams <ref type="bibr" target="#b274">[273]</ref><ref type="bibr" target="#b275">[274]</ref><ref type="bibr" target="#b276">[275]</ref>, clustering massive data sets <ref type="bibr" target="#b274">[273,</ref><ref type="bibr" target="#b277">276]</ref>. In <ref type="bibr" target="#b97">[98]</ref>, a Gaussian kernel version of the MSSC problem was considered for which an efficient DCA scheme was investigated. This algorithm outperforms the DCA for the MSSC in several numerical test problems. An alternative mixed integer formulation of the MSSC problem was considered in <ref type="bibr" target="#b97">[98]</ref>, where it is reformulated as a DC program via new results on exact penalty technique in DC programming <ref type="bibr" target="#b144">[143]</ref>. Fuzzy clustering via the Fuzzy c-Means (FCM) model was studied in <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b96">97]</ref> with three DC formulations and corresponding DCA schemes. Different variants of weighted clustering were considered in <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b102">103,</ref><ref type="bibr" target="#b196">195,</ref><ref type="bibr" target="#b274">273]</ref> for which DCA were efficiently investigated. DC Programming and DCA have also succeeded in multilevel hierarchical clustering and its applications in multicast <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b143">142]</ref>, block clustering <ref type="bibr" target="#b77">[78]</ref>.</p><p>A common advantage of DCAs for the above mentioned clustering problems (except for the mixed 0-1 formulation of the MSSC) is that, with suitable DC decompositions, they are all simple and inexpensive, they require only matrix-vector products. The numerical results demonstrated that the proposed algorithms are more efficient and more robust than related existing algorithms. DC Programming and DCA have also been successful in <ref type="bibr" target="#b208">[207]</ref> for clustering with unknown number of clusters via sparse optimization formulations (for which DCA was applied to the approximation problems), and for maximum margin clustering in <ref type="bibr" target="#b302">[301,</ref><ref type="bibr" target="#b331">330]</ref> where the problem was formulated as a general DC program (including DC constraints).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) Modularity maximization and communities detection</head><p>The modularity maximization, one of the most used methods for detecting communities in a network, can be formulated as a 0-1 indefinite quadratic program. Interestingly, in <ref type="bibr" target="#b111">[112]</ref> the authors showed that this hard discrete optimization problem is equivalent to the minimization of a concave quadratic function over a product of simplices. A fast and scalable DCA scheme was developed for the last problem, it requires only matrix-vector product at each iteration. Numerical experiments in <ref type="bibr" target="#b111">[112]</ref> indicated that DCA can handle large size networks having up to <ref type="bibr">4,194,304 nodes and 30,359,198</ref> edges and outperforms reference algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(c) Self-organizing maps (SOM)</head><p>In <ref type="bibr" target="#b109">[110]</ref> DC programming and DCA were developed for the popular Batch SOM model which is a nonsmooth, nonconvex program. With an elegant matrix formulation and a natural DC decomposition, the resulting DCA requires only sums and scalar multiplications of vectors which are simple and very inexpensive. A training version for DCA with an efficient cooling schedule is investigated. This approach is fast and scalable and is promising for large-scale setting, it outperforms the standard Batch SOM method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(d) Nonnegative matrix factorization (NMF) and dictionary learning</head><p>The NMF problem (which consists of approximating a given nonnegative matrix A ∈ R m×n by the product of two low-rank nonnegative matrices U ∈ R m×r and V ∈ R n×r ) has many applications such as text mining, image processing, spectral data analysis, etc. In <ref type="bibr" target="#b166">[165]</ref>, the NMF problem and several NMF variants were considered. Two DCAs were developed. The first combined the alternating framework and DCA while the second applied directly DCA to the whole NMF problem. The efficiency of the proposed approaches was empirically demonstrated on both real-world and synthetic datasets. It turns out that DCAs compete favorably with the five state-of-the-art algorithms. In <ref type="bibr" target="#b214">[213,</ref><ref type="bibr" target="#b294">293]</ref> the authors highlighted other two DC reformulations of the NMF problem and proposed to use DCA for solving them. A more difficult NMF variant which requires U to be 0-1 matrix and V to have stochastic columns was considered in <ref type="bibr" target="#b261">[260]</ref>, where the authors used a penalty technique in DC programming to tackle the 0-1 constraint. A related problem to the NMF is the dictionary learning. DCA-based methods were developed in <ref type="bibr" target="#b296">[295,</ref><ref type="bibr" target="#b298">297]</ref> with encouraging results in image denoising application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(e) One-class Support Vector Machine (OC-SVM) and Anomaly detection</head><p>One of the most successful approach for anomaly/novelty/outliers detection is the OC-SVM which tries to separate the high density regions by a hyperplane. In <ref type="bibr" target="#b262">[261]</ref> the authors extended the OC-SVM approach to thresholded estimates of likelihood ratios and reformulated it as a DC program by changing variables, and proposed a DCA scheme which guaranteed the globality of solutions. Another extension of the OC-SVM including latent dependency was proposed in <ref type="bibr" target="#b45">[46]</ref> for which DCA was developed. <ref type="bibr" target="#b33">[34]</ref> followed the idea of the support vector data description (SVDD) but employed the 0 -norm to measure the classification error. The logarithmic approximation of 0norm was used and DCA was efficiently investigated for the resulting problem. Also based on the SVDD, <ref type="bibr" target="#b299">[298]</ref> used the ramp loss for measuring errors and developed a DCA based algorithm for solving the resulting problem.</p><p>(f) Robust support vector machines Despite its wide success, the classical SVM is sensitive to the presence of outliers and yields poor generalization performance due to the unboundedness of the hinge loss function. To overcome these drawbacks, many works proposed to replace an unbounded loss by a bounded DC ramp loss and apply DCA for the resulting problem. Various ramp losses were proposed for robust SVM in <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b41">42]</ref>, <ref type="bibr" target="#b260">[259]</ref> (ψ-learning loss), <ref type="bibr" target="#b315">[314]</ref> (the truncated hinge loss), for robust multiclass SVM in <ref type="bibr" target="#b174">[173,</ref><ref type="bibr" target="#b175">174,</ref><ref type="bibr" target="#b315">314]</ref>, and for some variants of robust SVM including the ramp loss linear programming SVM <ref type="bibr" target="#b58">[59]</ref>, the ramp loss least squares SVM <ref type="bibr" target="#b172">[171]</ref>, the ramp loss nonparallel SVM <ref type="bibr" target="#b173">[172]</ref>, the robust support vector regression <ref type="bibr" target="#b306">[305,</ref><ref type="bibr" target="#b307">306,</ref><ref type="bibr" target="#b337">336]</ref> and the outcome weighted learning <ref type="bibr" target="#b24">[25]</ref>. DCAs were successfully investigated for the resulting problems in these works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(g) Spherical separation</head><p>Another group of binary classification methods is based on spherical separator where we separate two set of points by mean of a hypersphere. Several DCA-based algorithms have been proposed for this problem in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> and <ref type="bibr" target="#b100">[101]</ref>. It turns out that the DCA corresponding to the projection DC decomposition proposed in <ref type="bibr" target="#b100">[101]</ref> is the most computationally efficient.</p><p>(h) Other problems of supervised learning and weakly supervised learning DC programming and DCA were successfully applied in some other classes of problems in supervised learning, weakly supervised learning including leveraging the margin built on boosting techniques <ref type="bibr" target="#b68">[69]</ref>, kernel selection <ref type="bibr" target="#b4">[5]</ref>, training of nonpositivesemidefinite kernels <ref type="bibr" target="#b1">[2]</ref>, multiple objective classification <ref type="bibr" target="#b332">[331]</ref>, learning structural SVMs with latent variables <ref type="bibr" target="#b328">[327]</ref>, tuning regularization parameter in the multiclass probabilistic kernel discriminant analysis <ref type="bibr" target="#b334">[333]</ref>, learning the model parameters of log-linear mixture models <ref type="bibr" target="#b290">[289]</ref>, supervised dictionary learning for soft-thresholding classifier <ref type="bibr" target="#b38">[39]</ref>, multi-instance learning <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b69">70]</ref>, and multi-instance multi-label learning <ref type="bibr" target="#b340">[339]</ref>. Experiments in the aforementioned works also indicate that DCA-approaches have state-of-the-art performance.</p><p>(i) Semi-supervised classification DC programming and DCA were investigated to the so-called transductive support vector machine (TSVM) in <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b304">303]</ref> where a penalty term was added into the conventional SVM formulation and the resulting DCA consists of solving a sequence of SVM problems. Another DC formulation and the corresponding DCA were proposed in <ref type="bibr" target="#b320">[319]</ref> for semi-supervised support vector machines (S3VMs). DC programming and DCA were also investigated to various variants of the TSVM in <ref type="bibr" target="#b283">[282,</ref><ref type="bibr" target="#b303">302,</ref><ref type="bibr" target="#b305">304,</ref><ref type="bibr" target="#b320">319]</ref>, and to semi-supervised spherical separation in <ref type="bibr" target="#b6">[7]</ref>.</p><p>(j) Learning with sparsity Naturally, sparsity is modeled using 0 -norm that leads to considering a sparse optimization problem. As mentioned above, all standard algorithms in nonconex approximation approaches and nonconvex exact reformulation approaches are DCAs.</p><p>Variable (feature) selection in classification is one of major topics and the most widely studied in learning with sparsity. For feature selection in SVM, various works used DC approximations of the 0 -norm and investigated DCA via the exponential approximation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b95">96,</ref><ref type="bibr" target="#b190">189,</ref><ref type="bibr" target="#b205">204]</ref>, the p -norm <ref type="bibr" target="#b48">[49]</ref>, the smoothly clipped absolute deviation (SCAD) <ref type="bibr" target="#b121">[120,</ref><ref type="bibr" target="#b333">332]</ref>, the capped-1 <ref type="bibr" target="#b205">[204]</ref>, the logarithm function <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b311">310]</ref>, the minimax concave penalty (MCP) <ref type="bibr" target="#b72">[73]</ref>. The most complete work in DC approximation approaches including all standard algorithms was given in <ref type="bibr" target="#b145">[144]</ref>. Novel approaches were investigated in <ref type="bibr" target="#b98">[99,</ref><ref type="bibr" target="#b150">149]</ref> including the 2 -0 regularization and the combined convex (with the help of its biconjugate function) and DC approximation approaches <ref type="bibr" target="#b150">[149]</ref>, and the exact penalty approach <ref type="bibr" target="#b98">[99]</ref>. The DC approximation approach is also applied for variable selection in multi-class SVM <ref type="bibr" target="#b110">[111,</ref><ref type="bibr" target="#b192">191]</ref>, semi-supervised SVM <ref type="bibr" target="#b75">[76]</ref>, linear discriminant analysis <ref type="bibr" target="#b155">[154,</ref><ref type="bibr" target="#b157">156]</ref>, minimax probability machine <ref type="bibr" target="#b318">[317]</ref>, and extreme learning machine <ref type="bibr" target="#b321">[320]</ref>.</p><p>Group variable selection is an extension of variable selection and arises in several real-world applications with the presence of highly correlated features. When the feature groups are pre-specified, group variable selection can be formulated in the same manner as for individual variable selection. <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b156">155,</ref><ref type="bibr" target="#b317">316]</ref> are recent works using the DC approximation approach for group variable selection with feature groups pre-specified while <ref type="bibr" target="#b259">[258,</ref><ref type="bibr" target="#b322">321,</ref><ref type="bibr" target="#b341">340]</ref> deal with DCA based methods for simultaneous feature grouping and selection.</p><p>Sparse regression and compressed sensing DCA based methods were developed to sparse logistic regression <ref type="bibr" target="#b319">[318]</ref>, sparse linear regression <ref type="bibr" target="#b308">[307]</ref>, sparse quantile regression <ref type="bibr" target="#b263">[262,</ref><ref type="bibr" target="#b316">315]</ref>, and to compressed sensing which refers to techniques for efficiently acquiring and reconstructing signals via the resolution of underdetermined linear systems. Compressed sensing concerns sparse signal representation, sparse signal recovery and sparse dictionary learning which can be formulated as a sparse optimization problem. DC approximation approach and DCA were widely used for solving this problem in the context of compressed sensing in <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b118">118,</ref><ref type="bibr" target="#b197">196]</ref> (using usual sparse inducing functions) and in <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b177">176,</ref><ref type="bibr" target="#b178">177,</ref><ref type="bibr" target="#b324">323]</ref> via new regularizations using the ratios or the difference of 1 and 2 norms.</p><p>It has been pointed out in <ref type="bibr" target="#b145">[144]</ref> that popular algorithms for sparse regression and compressed sensing, including Focal Underdetermined System Solver (FOCUSS) <ref type="bibr" target="#b47">[48]</ref>, Local Quadratic Approximation (LQA) <ref type="bibr" target="#b36">[37]</ref>, Adaptive Lasso <ref type="bibr" target="#b343">[342]</ref>, reweighted 1 <ref type="bibr" target="#b20">[21]</ref>, Iteratively Reweighted Least Squares (IRLS) <ref type="bibr" target="#b22">[23]</ref>, Local Linear Approximation (LLA) <ref type="bibr" target="#b344">[343]</ref>, are particular cases of DCA.</p><p>Sparse eigenvalue problem Generally speaking, this problem aims to find an eigenvector x of an (n × n) symmetric matrix A such that x 0 ≤ k, where k ∈ N, 1 ≤ k &lt; n. DC approximation approaches and DCA were investigated for the case where A 0 (resp. A is indefinite) in <ref type="bibr" target="#b264">[263]</ref> (resp. in <ref type="bibr" target="#b284">[283]</ref>) while DCA based on the exact penalty technique was developed in <ref type="bibr" target="#b282">[281]</ref>.</p><p>Low-rank matrix estimation Low-rank matrix estimation is the central part of some important problems such as matrix completion <ref type="bibr" target="#b43">[44]</ref> and robust principal component analysis <ref type="bibr" target="#b265">[264]</ref>. Since the rank of a matrix X is equal to the 0 -norm of its vector of singular values x σ , low-rank matrix estimation problem can be addressed similarly as for the minimization problem involving the 0 -norm. DCA based methods were developed in <ref type="bibr" target="#b265">[264]</ref> via the capped-1 and in <ref type="bibr" target="#b43">[44]</ref> via the p -norm (0 &lt; p &lt; 1) and the logarithm approximations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sparse covariance matrix estimation</head><p>In <ref type="bibr" target="#b15">[16]</ref>, using the lasso penalty on the entries of the covariance matrix, the authors proposed a DCA based method for estimating a sparse covariance matrix on the basis of sample vectors drawn from a multivariate normal distribution. A more efficient DCA based algorithm with a more suitable DC decomposition was developed in <ref type="bibr" target="#b237">[236]</ref> for the same problem. The problem of estimating sparse precision matrices from data with missing values was studied in <ref type="bibr" target="#b279">[278]</ref> where the authors used the lasso penalty and developed DCA for the corresponding maximum likelihood problem. Experiments show that the DCA is superior to the Expectation Maximization algorithm in terms of convergence speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(k) Learning under uncertain data</head><p>Data uncertainty is common in real-world applications due to various reasons and must be handled carefully. Recently, the idea of using robust optimization <ref type="bibr" target="#b13">[14]</ref>, a novel and useful approach to deal with uncertain data, has attracted more interest from researchers. Robust optimization models result in solving a min-max optimiza-tion problem which is often nonconvex and then difficult to solve. Based on robust optimization models, DC programming and DCA were recently developed to Feature selection for linear SVMs under uncertain data in <ref type="bibr" target="#b165">[164]</ref> and for Robust clustering uncertain data in <ref type="bibr" target="#b296">[295,</ref><ref type="bibr" target="#b297">296]</ref>. These works showed that DC programming and DCA are very powerful tools to address learning problems under uncertain data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Image analysis (a) Image segmentation</head><p>Clustering is a useful technique for image segmentation, which is the process of partitioning an image into non-overlapped and consistent regions. Works in <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b102">103,</ref><ref type="bibr" target="#b196">195,</ref><ref type="bibr" target="#b199">198]</ref> have demonstrated the efficiency of DCA-based clustering algorithms for image segmentation problem with applications in noisy image segmentation, automated cell counting and edge detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) Signal and Image restoration</head><p>Signal/Image restoration has a wide range of applications in image processing, since degradation is inevitable in the process of image acquisition. In <ref type="bibr" target="#b126">[125,</ref><ref type="bibr" target="#b252">251]</ref>, the authors have successfully investigated DCA for restoring signal and image affected by additive noise. A variety of works using DCA-based compressed sensing techniques have been proposed for image denoising <ref type="bibr" target="#b178">[177,</ref><ref type="bibr" target="#b180">179,</ref><ref type="bibr" target="#b296">295,</ref><ref type="bibr" target="#b298">297]</ref>, image deblurring <ref type="bibr" target="#b180">[179]</ref>, the narrowband farfield direction-of-arrival (DOA) estimation problem <ref type="bibr" target="#b47">[48]</ref>, recovery of electroencephalography (EEG)/magnetoencephalography (MEG) signals in neuroimaging <ref type="bibr" target="#b47">[48]</ref>, differential optical absorption spectroscopy analysis <ref type="bibr" target="#b178">[177]</ref>, over-Sampled DCT <ref type="bibr" target="#b178">[177]</ref>, and MRI reconstruction <ref type="bibr" target="#b180">[179,</ref><ref type="bibr" target="#b324">323]</ref>. DC programming and DCA were also employed for super-resolution of point sources <ref type="bibr" target="#b179">[178]</ref>, and multiplicative noise removal <ref type="bibr" target="#b171">[170]</ref>.</p><p>(c) Discrete tomography Discrete tomography concerns the problem of reconstruction of discrete-valued functions from a limited number of projections. Various mathematical formulations of this problem were proposed in several works <ref type="bibr" target="#b199">[198,</ref><ref type="bibr" target="#b253">252,</ref><ref type="bibr" target="#b254">253,</ref><ref type="bibr" target="#b310">309,</ref><ref type="bibr" target="#b342">341]</ref>. They are all binary quadratic programs for which DC programming and DCA were investigated via exact penalty techniques. Experimental results in these works demonstrated that DCA-based approaches are scalable and have excellent performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4">Communication system and network optimization</head><p>Optimization plays a key role in communication systems (CS) since most of the issues of this domain are related to optimization problems. Nonconvex optimization becomes an indispensable and powerful tool for the analysis and design of CS since the last decade. As an innovative approach to nonconvex programming, DC programming and DCA are increasingly used by researchers/practitioners in this field. A careful review on DC programming and DCA in CS can be found in <ref type="bibr" target="#b138">[137]</ref>. Here, due to the page limit, we only provide an (incomplete) list of problems in CS and network optimization solved by DCA. In terms of optimization, they can be partitioned into four classes of DC programs.</p><p>(a) Standard DC programs Capacity and flow assignment problems <ref type="bibr" target="#b181">[180]</ref>; multicommodity network optimization problems with step increasing cost functions <ref type="bibr" target="#b128">[127]</ref>; resource allocation in wireless networks <ref type="bibr" target="#b300">[299]</ref>; power control problems in wireless networks <ref type="bibr" target="#b158">[157]</ref>; spectrum management problem <ref type="bibr" target="#b267">[266]</ref>; SINR (signal-to-interference-plus-noise ratio) maximize multicasting in cognitive radio <ref type="bibr" target="#b235">[234]</ref>; network utility maximization problem <ref type="bibr" target="#b137">[136]</ref>; weighted sum-rate maximization in a MIMO (multiple-input multiple-output) interference network <ref type="bibr" target="#b327">[326]</ref>; power allocation in OFDM (Orthogonal Frequency Division Multiplexing) based NOMA (Non Orthogonal Multiple Access) systems <ref type="bibr" target="#b211">[210]</ref>; enhanced multi-input multi-output multi-eavesdropper (MIMOME) wiretap channel via adopting full-duplex MIMO radios <ref type="bibr" target="#b339">[338]</ref>; joint beamforming optimization and power control for full-duplex MIMO two-way relay channel <ref type="bibr" target="#b335">[334]</ref>; resource allocation problem in cooperative physical layer security <ref type="bibr" target="#b287">[286]</ref>; mode switching for energyefficient device-to-device communications in cellular networks <ref type="bibr" target="#b39">[40]</ref>; energy efficient secure communication over decode-and-forward relay channels <ref type="bibr" target="#b301">[300]</ref>; improving physical layer secrecy using full-duplex jamming receivers <ref type="bibr" target="#b336">[335]</ref>; physical layer security (secrecy rate maximization) via cooperative jamming <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b288">287]</ref>; secrecy rate maximization with uncoordinated cooperative jamming by single-antenna helpers under secrecy outage probability constraint <ref type="bibr" target="#b185">[184]</ref>; physical layer security via relay beamforming strategies <ref type="bibr" target="#b289">[288]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) General DC programs</head><p>Joint base-station association, channel assignment, beamforming and power control in heterogeneous networks <ref type="bibr" target="#b70">[71]</ref>; joint optimization of source power allocation and distributed relay beamforming in multiuser peer-to-peer relay networks <ref type="bibr" target="#b25">[26]</ref>; time-difference-of-arrival (TDOA) based positioning problem <ref type="bibr" target="#b44">[45]</ref>; rank-two beamforming and power allocation in multicasting relay networks <ref type="bibr" target="#b250">[249]</ref>; multihop backhaul compression for the uplink of cloud radio access networks <ref type="bibr" target="#b213">[212]</ref>; optimal fronthaul quantization for cloud radio positioning <ref type="bibr" target="#b62">[63]</ref>.</p><p>(c) Mixed 0-1 Linear/Quadratic programs Cross-layer optimization in multi-hop time division multiple access networks <ref type="bibr" target="#b116">[116,</ref><ref type="bibr" target="#b117">117]</ref>; the quality of service (QoS) routing problems <ref type="bibr" target="#b270">[269,</ref><ref type="bibr" target="#b271">270,</ref><ref type="bibr" target="#b273">272]</ref>; partitioninghub location-routing problem <ref type="bibr" target="#b272">[271]</ref>; the minimum m-dominating set problem <ref type="bibr" target="#b251">[250]</ref>; resource allocation optimization in orthogonal frequency-division multiple access (OFDMA)/time-division duplexing (TDD) wireless networks <ref type="bibr" target="#b202">[201]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(d) Mixed 0-1 DC programs</head><p>Joint optimization of cooperative beamforming and relay assignment in multi-user wireless relay networks <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.5">Security (a) Cryptography</head><p>For building high-quality S-boxes which are a key component of modern cryptosystems, the authors of <ref type="bibr" target="#b76">[77]</ref> studied the construction of highly nonlinear balanced Boolean functions and proposed a deterministic optimization model which is the min-imization of a polyhedral convex function on a convex polytope with 0-1 variables. Several DCA based algorithms were developed for this large-scale problem (2 n variables, where n is the size of the Boolean function): DCA, the combined DCA -Genetic Algorithm <ref type="bibr" target="#b76">[77]</ref>, the combined DCA and Simulated Annealing Algorithm <ref type="bibr" target="#b18">[19]</ref>. Numerical simulations proved that DCA is a promising approach for this problem. Moreover the combined approaches improve the efficiency of DCA and outperform other standard approaches.</p><p>For authentification and identification schemes in cryptanalysis, the two very hard problems called Perceptron Problem (PP) and Permuted Perceptron Problem (PPP) were studied in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b99">100,</ref><ref type="bibr" target="#b141">140]</ref>. DCAs have been shown to be efficient and outperform standard methods, in particular in terms of scalability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) Network security</head><p>In the field of network security, the Intrusion Detection Systems (IDSs) always require more research to improve system performance. Multi-Class Support Vector Machine (MSVM) has been widely used for network intrusion detection to perform the multiclass classification of intrusions. In <ref type="bibr" target="#b73">[74]</ref>, DCA was investigated to IDSs via the two models of MSVM. Computational results on a benchmark data for IDSs show the efficiency of DCA on both models, in particular the alternative model with the ∞ -norm.</p><p>In another direction of network security, several recent promising works concern physical layer security, for instance secrecy rate maximization while transmission of information (see the applications of DCA in communication system and network optimization).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.6">Portfolio optimization</head><p>The selection of investment funds to build optimal portfolios is expressed in mathematical language as an optimization problem. The aim is to find the optimal portfolio minimizing the risk for an expected level of performance or maximizing return for an authorized level of risk. The famous model of risk minimization introduced by Markovitch in 1952 is a convex quadratic program. Since it does not completely reflect the actual situations, it was generalized by several researchers by adding new types of constraints. The new models are combinatorial optimization problems and/or nonconvex in continuous variables for which DC programming and DCA were extensively developed in several works. On the other hand DCA was also investigated to models based on "Value-at-Risk". We show below an (incomplete) list of problems in portfolio optimization successfully solved by DCA and combined DCA-BB methods, they can be partitioned into five classes of DC programs. The numerical results in these works demonstrate the effectiveness, scalabillity and superiority of DCA compared to existing methods.</p><p>(a) Standard DC Portfolio optimization under step increasing transaction costs <ref type="bibr" target="#b104">[105]</ref>; Portfolio decision with higher moments <ref type="bibr" target="#b231">[230]</ref>; minimizing the transaction costs of portfolio selection <ref type="bibr" target="#b215">[214]</ref>; constructing optimal sparse portfolios using regularization methods <ref type="bibr" target="#b37">[38]</ref>.</p><p>(b) General DC Globally solving the Value-at-Risk <ref type="bibr" target="#b229">[228]</ref>; Value-at-Risk constrained optimization <ref type="bibr" target="#b191">[190,</ref><ref type="bibr" target="#b312">311]</ref>.</p><p>(c) Linearly/quadratically constrained quadratic programming with mixed 0-1 variables Portfolio selection under downside risk measures and cardinality constraints <ref type="bibr" target="#b105">[106]</ref>; robust investment strategies with discrete asset choice constraints <ref type="bibr" target="#b49">[50]</ref>; continuous min max problem for single period portfolio selection with discrete constraints <ref type="bibr" target="#b159">[158]</ref>.</p><p>(d) DC programs with mixed 0-1 variables/integer variables Long-short portfolio optimization under cardinality constraints <ref type="bibr" target="#b103">[104]</ref>; minimizing the transaction costs of portfolio selection <ref type="bibr" target="#b232">[231]</ref>; discrete portfolio optimization under concave transaction costs <ref type="bibr" target="#b228">[227]</ref>.</p><p>(e) Bilevel programming problems portfolio selection <ref type="bibr" target="#b153">[152]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.7">Transportation</head><p>Several large-scale problems in the area of transportation were modeled as 0-1 (or mixed 0-1) linear programming problems and successfully solved by DCA and combined DCA-global methods (BB, DCA-CUT which is a new cut based on a solution given by DCA). They include the multimodal transport problem <ref type="bibr" target="#b107">[108]</ref>; the car pooling problem <ref type="bibr" target="#b267">[266,</ref><ref type="bibr" target="#b268">267]</ref>; the scheduling of lifting vehicle in an automated port container terminal <ref type="bibr" target="#b80">[81]</ref>; the single straddle carrier routing problem in port container terminals <ref type="bibr" target="#b187">[186,</ref><ref type="bibr" target="#b189">188]</ref>; the two-dimensional packing problem <ref type="bibr" target="#b188">[187]</ref> and the orienteering problem <ref type="bibr" target="#b269">[268]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.8">Task allocation, resource allocation, localization problems</head><p>The sensor network localization with uncertainties in anchor positions and the optimization of traffic signals in networks considering rerouting were formulated as a standard DC program and solved by DCA in <ref type="bibr" target="#b314">[313]</ref> and <ref type="bibr" target="#b286">[285]</ref>, respectively. The two much more difficult problems, namely Nonlinear UAV task assignment problem under uncertainty and Planning a multisensor multizone search for a target were studied in <ref type="bibr" target="#b112">[113]</ref> and <ref type="bibr" target="#b108">[109]</ref> respectively. They were formulated as a 0-1 or mixed 0-1 DC program and efficiently solved by DCA via exact penalty techniques in DC programming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.9">Production, operation management</head><p>The earliness tardiness scheduling problems <ref type="bibr" target="#b114">[114,</ref><ref type="bibr" target="#b115">115]</ref> and the minimization of preventive maintenance cost with unequal release dates and tardiness penalties, under real-time and resource constraints <ref type="bibr" target="#b162">[161,</ref><ref type="bibr" target="#b285">284]</ref> were formulated as mixed 0-1 linear programs and favorably solved by DCA. A more difficult problem, namely optimizing a multi-stage production/inventory system, was studied in <ref type="bibr" target="#b161">[160]</ref>. It was formulated as a mixed integer linear program for which DCA and the combined DCA-BB were developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.10">Supply chain management</head><p>Similar to the area of transportation, several large-scale problems in Supply chain management were modeled as 0-1 (or mixed 0-1) linear programming problems and successfully solved by DCA and combined DCA-global methods including the strategic capacity planning in supply chain the strategic supply chain design problem from qualified partner set <ref type="bibr" target="#b120">[119]</ref>; the single-vehicle cyclic inventory routing problem <ref type="bibr" target="#b338">[337]</ref>, and the logistics network design and planning problem <ref type="bibr" target="#b280">[279]</ref>. DC programming and DCA via exact penalty techniques were also extensively investigated for the concave cost supply problem <ref type="bibr" target="#b132">[131]</ref>, the inventory routing problem in supply chain <ref type="bibr" target="#b194">[193]</ref> and the multi-period problem of fair transfer prices and inventory holding policies in two-enterprise supply chains <ref type="bibr" target="#b160">[159]</ref>. They were formulated as mixed 0-1 DC programs for which the proposed DCA schemes were shown to be efficient, fast and scalable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Exact penalty techniques in DC programming</head><p>Continuing the work in <ref type="bibr" target="#b142">[141,</ref><ref type="bibr" target="#b144">143]</ref>, very recently we are interested in exact penalty techniques with DC programming which leverage the DC structure of nonconvex constraints. In <ref type="bibr" target="#b91">[92]</ref>, we consider the error bounds for inequality systems and the exact penalization for constrained optimization problems. We firstly investigate the relationships between the errors bounds and the exact penalization. Secondly, we establish the new errors bounds for inequality systems of concave functions and of nonconvex quadratic functions over polyhedral convex sets. These established results serve as theoretical tools for penalization methods in nonconvex programming, especially in DC programming. For general DC programs discussed below, these techniques allow to reformulate equivalently them as standard DC programs. For instance, minimizing a DC function under a polyhedral convex set with additional nonconvex quadratic constraints, which is a hard and important problem having many applications. A deeper research direction being in progress (see <ref type="bibr" target="#b226">[225]</ref>) is to consider the error bound for systems of finitely many DC inequalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Exact penalty in mixed Integer DC programming</head><p>In <ref type="bibr" target="#b226">[225]</ref> we considered the class of (NP-hard) mixed integer DC programs (44) below and proposed five DC penalty functions with explicit DC decompositions.</p><formula xml:id="formula_117">α := inf{ f (x, y) = g(x, y) -h(x, y) : (x, y) ∈ K , x ∈ [l, u] ∩ Z n }<label>(44)</label></formula><p>where</p><formula xml:id="formula_118">K := {(x, y) ∈ R n+ p : C(x, y) := Ax + By ≤ b} with C ∈ R m×(n+ p) , A ∈ R m×n , B ∈ R m× p , [l, u] := n i=1 [l i , u i ] ⊂ R n , with l i , u i ∈ Z, l i &lt; u i for i = 1, . . . , n.</formula><p>The readers are referred to <ref type="bibr" target="#b226">[225]</ref> for more details. This challenging class of nonconvex programs encompasses most combinatorial optimization problems, in particular usual mixed integer linear/quadratic programming problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Convergence of DCA with subanalytic data</head><p>The general convergence of DCA above mentioned says that every convergent subsequence of the sequence {x k } (resp. {y k }) converges to a generalized KKT point of (P dc ) (resp. (D dc )). From a theoretical point of view, convergence rate analysis of DCA is an open key issue. Some elegant results on the convergence of the whole sequences {x k } and {y k } as well as their convergence rate, in case the objective functions and the constraints are subanalytic, have been recently presented in <ref type="bibr" target="#b226">[225]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">New generations of algorithms in the DC programming framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">General DCA</head><p>A general DC program takes the form</p><formula xml:id="formula_119">inf{g 0 (x) -h 0 (x) : x ∈ C, g i (x) -h i (x) ≤ 0, i = 1., , , m}, (P dcg )</formula><p>where C is a nonempty closed convex set in R n , g i , h i ∈ Γ 0 (R n ), i = 0, . . . , m, and its feasible set E = {x ∈ C : f i (x) ≤ 0, i = 1, . . . , m} is assumed to be nonempty. This class of nonconvex programs is the most general in DC programming and, a fortiori, more difficult to treat than that standard DC programs (P dc ) because of the nonconvexity of the constraints. It is not new and has been addressed in <ref type="bibr" target="#b224">[223]</ref>. Its renewed interests are due to the fact that this class appears, increasingly, in many models of nonconvex variational approaches. In <ref type="bibr" target="#b226">[225]</ref>, we presented two approaches for modeling and solving (P dcg ) which are the natural extension of the standard DCA. These two approaches consist of reformulation of those programs as standard DC programs. The first one is based on penalty techniques in DC programming while the second linearizes concave functions in DC constraints to build convex inner approximations of the feasible set. Both designed algorithms can be viewed as a sequence of standard DCAs with updated penalty (resp. relaxation) parameters, which marks the passage from standard DCAs to general DCAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">DCA for mixed integer DC programming</head><p>The recent results on exact penalty in mixed integer DC programming can be exploited to solve many classes of mixed integer DC programming problems by DCA, see e.g. <ref type="bibr" target="#b228">[227]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">DCA collaborative</head><p>Exploiting the nice effect of DC decompositions of the same DC function as well as the nice effect of various equivalent DC formulations of the same problem are challenging issues in DC programming and DCA. An innovative technique named DCA collaborative has been recently developed in <ref type="bibr" target="#b85">[86]</ref> that consists of designing collaborative DCA schemes for the same DC program. The main idea is to exploit the efficiency of DCA applied on each DC decomposition/DC formulation at each running cycle of DCA to get the best current solution and then restart each DCA scheme from this solution. Various versions of the collaborative algorithm can be investigated for several applications. For instance DCA for clustering proposed in <ref type="bibr" target="#b85">[86]</ref> has been shown to be more efficient than other DCA based algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">DCA for new practical problems</head><p>Today, the number of works applying DCA for new practical problems in various areas is growing constantly. To name a few, reinforcement learning <ref type="bibr" target="#b238">[237]</ref>, Markov Decision Process <ref type="bibr" target="#b55">[56]</ref>, extreme learning <ref type="bibr" target="#b321">[320]</ref>, face recognition based on Haar features <ref type="bibr" target="#b309">[308]</ref>, sparse and low-rank recovery under simplex constraints <ref type="bibr" target="#b170">[169]</ref>, linear feature transform and enhancement of classification on deep neural network <ref type="bibr" target="#b325">[324]</ref>, penalized regression-based clustering <ref type="bibr" target="#b313">[312]</ref>, optimisation over the non-dominated set of a multiobjective optimisation problem <ref type="bibr" target="#b176">[175]</ref>, continuous equilibrium network design problem via mathematical programming with complementarity constraints (MPCC) <ref type="bibr" target="#b198">[197]</ref>, finding a Nash equilibrium in polymatrix game of three players (hexamatrix game) <ref type="bibr" target="#b206">[205]</ref>, absolute fused lasso and its application to Genome-Wide association studies <ref type="bibr" target="#b323">[322]</ref>, full-rate general rank beamforming in single-group multicasting networks using non-orthogonal STBC <ref type="bibr" target="#b278">[277]</ref>, power allocation in multicasting relay network <ref type="bibr" target="#b163">[162]</ref>, secure cooperative communications under secrecy outage constraint <ref type="bibr" target="#b240">[239]</ref>, solving Brugnano-Casulli piecewise linear systems <ref type="bibr" target="#b221">[220]</ref>, relaxed Mumford-Shah image segmentation <ref type="bibr" target="#b212">[211]</ref>, etc. And among numerous works in DC programming framework appear during the last year, we can cite a few, e.g. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b110">111,</ref><ref type="bibr" target="#b139">138,</ref><ref type="bibr" target="#b158">157,</ref><ref type="bibr" target="#b184">183,</ref><ref type="bibr" target="#b195">194,</ref><ref type="bibr" target="#b209">208,</ref><ref type="bibr" target="#b210">209,</ref><ref type="bibr" target="#b237">236,</ref><ref type="bibr" target="#b246">245]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">New trends and open issues</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">DCA for Semi Infinite Programming (SIP)</head><p>SIP refers to optimization problems having infinitely many constraints. In recent years several methods have been developed for convex SIP (i.e., when the objective function f is convex). Traditionally, they can be classified into three categories: the exchange methods, discretization methods and methods based on local reduction. All the methods are in nonconvex programming framework (that consider a sequence of finitely many constrained optimization problems), because checking the feasibility of a solution to SIP amounts to globally solving a nonconvex program. When f is nonconvex the corresponding SIP is much more difficult and solving nonconvex SIP is a challenge of the optimization community. DCA can be investigated to DC SIP problems, say SIP with the DC objective function f = gh. Our methodology can be based on two approaches: (i) if g is a convex function in variable x then one can use the idea of traditional methods for (SIP) in which standard DCA schemes should be iter-atively applied; (ii) if g is a DC function of the variable x then one can use the idea of traditional methods for (SIP) in which general DCA schemes should be iteratively applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Online DCA and application in online learning</head><p>In recent years, due to technological advances, in several practical optimization problems, input data can be collected and processed in real time and decision making has to be "online". We are then faced with the so-called Online optimization problem. The scientific challenge is that how well can an online algorithm perform. A key tool in Online optimization is Online convex optimization which aims to solve a convex problem for each online round. For this purpose, either the considered loss function should be convex, or it should be approximated by a convex function. However, there are many online optimization problems where the loss functions are nonconvex, nonsmooth, for instance online classification problems. Today, the major challenge in Online optimization is online algorithm performing on nonconvex loss functions. Developing Online DCA could be a good direction for this challenge. The first work in this framework is recently given in <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b89">90]</ref>. Similar ideas can be extended for several classes of Online learning problems. Another interesting direction could be the development of online DCA for stochastic optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Stochastic DCA and application in stochastic learning</head><p>In recent years, Stochastic optimization, which refers to methods for optimizing an objective function when randomness is present, has become essential tools for science, engineering, business, computer science, and statistics, in particular for big data. The research study on the stochastic schemes based on DCA is just the beginning of the ongoing works <ref type="bibr" target="#b101">[102,</ref><ref type="bibr" target="#b236">235]</ref>. In these works, we introduce stochastic DCA for minimizing a large sum of nonconvex functions, a problem of utmost importance in machine learning. With appropriate DC components, we present two special versions of the stochastic DCA: stochastic proximal DCA and stochastic proximal Newton DCA. We also show that stochastic gradient descent algorithm <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b247">246]</ref> and the stochastic proximal descent algorithm <ref type="bibr" target="#b14">[15]</ref> are special versions of stochastic DCA (see <ref type="bibr" target="#b101">[102,</ref><ref type="bibr" target="#b236">235]</ref>). As an application, we apply the proposed algorithm to a log-linear model incorporating latent variables. The parameter estimation of this model often results in an optimization problem involving a rational function of mixtures of exponential terms. It is a nonconvex and large-scale problem which is very hard to solve. The stochastic DCA can also be developed for solving other stochastic learning models, especially, sparse SVM, sparse logistic regression, sparse matrix factorization, group variable selection in latent log-linear model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Open issues</head><p>It would be wrong to think that using DCA for efficiently solving a practical problem is a simple procedure. Indeed, the general DCA scheme is rather a philosophy than an algorithm. There is not only one DCA but infinitely many DCAs for a considered problem. Despite the bright successes obtained by researchers and practitioners in the use of DC programming and DCA for modeling and solving nonconvex and global optimization problems, their works have not exploited the full power and creative freedom offered by these tools: their proposed DCAs, although more efficient than existing methods, but can be further improved to better handle largescale problems. The design of an efficient DCA for a real-world problem is an art which should be based on theoretical tools and on its special structure. Key issues that should be studied while developing DCA for a DC program are the following. (c) Scalability: the complexity of DCA depends mainly on the solution methods for convex subproblems. Therefore, designing fast and scalable convex solvers for convex subproblems is an important issue of DCA.</p><p>In addition, other open issues could be composite functions techniques in DC programming and DCA, and algorithms for computing sharp stationary solutions for DC functions whose the second DC component is not differentiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have given a short survey (with an incomplete list of references) on the thirty years of developments of DC Programming and DCA which have wonderful scientific impacts on many fields of applied sciences. Due to the page limit, we just gave a very brief outline on the philosophy and key properties of DCA and on its historic, for a complete study of DC programming and DCA the reader is referred to the two papers <ref type="bibr" target="#b131">[130,</ref><ref type="bibr" target="#b224">223]</ref>. And recent advances in this field can be found in <ref type="bibr" target="#b226">[225]</ref>. Among the stateof-the-art results, we focus on the presentation of DCA solvers for important classes of difficult nonconvex programs and for real-world applications. The reader can see that, DCA solvers are available for a large class of problems (one can say most of the problems) appeared in optimization (continuous or discrete) and operational research. Hence the list of references we offered could be useful for them in the study/use of solution methods for their problems. On another hand, the list of DCA solvers available to solving real-world problems, classified area by area, would allow readers to find the material of most interest to them in their specific applications. The list of references showed that many classes of problems in various domains of applications can be solved by DCA. In addition, the analysis on the related works in nonconvex programming framework provided the reader a unified DC programming and DCA point of view on the solution methods for realistic convex/nonconvex programs.</p><p>It is certain that developments of nonconvex programming and global optimization via DC Programming and DCA for modeling and solving real-world nonconvex optimization problems (in many branches of applied sciences) will intensify yet in the years to come and for long, because Nonconvex Programming and Global Optimization are endless.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1</head><label>1</label><figDesc>Recent advanced theoretical tools for DC programming and DCA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Efficiency (the convergence speed and the quality of computed solutions): (i) Finding an appropriate DC decomposition. From the theoretical point of view, the question of "good" DC decompositions is still open. This depends strongly on the very specific structure of the problem being considered, hence the crucial role of reformulation techniques to obtain suitable models. The ideal is to obtain explicit DCA, which corresponds to the explicit computation of a solution of the resulting convex program at each iteration. What is not always possible, especially for nondifferentiable DC programs, and the development of efficient convex optimization methods should be considered, especially in high dimension. (ii) Strategy of computing "good" starting points. This can be done by combining with other approaches-heuristic or local search methods, solutions of convex relaxation problems in global methods. The last way consists in finding a convex minorant of the objective function and solving the resulting convex program whose solution is used to initialize DCA. This strategy must be developed in depth and in a specific way, in light of recent advances in DC programming. (iii) Using Nesterov smoothing techniques applied to generated convex subprograms for accelerating DCAs. (iv) Using Proximal approaches techniques for both regularization, decomposition and improving DCA's convergence speed. (v) Using Armijo type linesearch (standard DCA's stepsize being equal to 1) for DC objective functions in DCAs in order to boost them. (vi) Estimating DCA's convergence rate for special classes of DC programs. (b) Globality: Globalizing DCA by DCA multi-start, combined DCA-Branch and Bound/Branch and Cut methods, finding convex minorants of DC functions for computing lower bounds of optimal values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>are also primal and dual optimal solutions respectively. This property, due to the characterization of proper lower semi-continuous convex functions mentioned above (being supremums of a family of affine functions defined by range (∂h)), makes convex approximations in DCA the most closed to the DC component h on X, and needless to say, enhances considerably DCA with respect to other Successive Convex Approximation approaches. These original and distinctive features explain in part the effective convergence of suitably customized DCA, with a reasonable choice of a starting point, towards global optimal solutions of DC programs. In practice, DCA quite often converges to global optimal solutions. The globality of DCA may be assessed either when the optimal values are known a priori, or through global optimization techniques (in small dimension of course) the most popular among them remain Branch-and-Bound (BB) or Cutting Plane Techniques</figDesc><table /><note><p>solution x * (resp. y * ) computed by DCA is also a global solution of the DC program obtained from (P dc ) (resp. (D dc )) by replacing the function h (resp. g * ) with the supremum sup k≥1 h k (resp. sup k≥1 (g * ) k ) of all the affine minorizations h k (resp. (g * ) k ) of h (resp. g * ) generated by DCA. These DC programs are closer to (P dc ) and (D dc ) than (P k ) and (D k ) respectively, because the function sup k≥1 h k (resp. sup k≥1 (g * ) k ) better approximates the function h (resp. g * ) than h k (resp. (g * ) k ). Moreover if sup k≥1 h k (resp. sup k≥1 (g * ) k ) coincides with h (resp. g * ) at an optimal solution of (P dc ) (resp. (D dc )), then x * and y *</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Its solution set is so contained in the vertex set of K . DCA developed previously for NQP can be then applied to (CCQP). With a suitable DC decomposition for the concave quadratic minimization, DCA enjoys several advantages: (i) DCA only requires solving one linear program at each iteration; (ii) If x r ∈ {0, 1} n , then x k ∈ {0, 1} n for all k ≥ r ; (iii) DCA has finite convergence. Exploiting these advantages of DCA we proposed the combined DCA-BB for BQP in which DC relaxation was used for lower bounding and DCA was applied to (CCQP) to get a good feasible (integer) solution.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors are grateful to Dr. Vo Xuan Thanh for sending us some references on DCA solvers for real-world applications, and the two anonymous reviewers as well as Professor Jong-Shi Pang for their constructive comments that greatly improved the manuscript, in particular one of reviewers for providing us some references on related DCA methods in Sect. 3.3.   </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Difference-of-convex learning: directional stationarity, optimality, and sparsity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1637" to="1665" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combining DC algorithms (DCAs) and decomposition techniques for the training of nonpositive-semidefinite kernels</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Akoa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1854" to="1872" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On functions representable as a difference of convex functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alexandroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Doklady Akad. Nauk SSSR (N.S.)</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="360" to="376" />
			<date type="published" when="1950">2012. 1950</date>
		</imprint>
	</monogr>
	<note>Mathetical. Izv.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new decomposition method for multiuser dc-programming and its applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alvarado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scutari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2984" to="2998" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A DC-programming algorithm for kernel selection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2006</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">New formulations of the multiple sequence alignment problem</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Arthanari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="40" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semisupervised spherical separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Astorino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fuduli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Model</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="6351" to="6358" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">DC models for spherical separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Astorino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fuduli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gaudioso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="657" to="669" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Margin maximization in spherical separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Astorino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fuduli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gaudioso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="322" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the convergence of the proximal algorithm for nonsmooth functions involving analytic features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Attouch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="16" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward-backward splitting, and regularized Gauss-Seidel methods</title>
		<author>
			<persName><forename type="first">H</forename><surname>Attouch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bolte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Svaiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="129" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On difference convexity of locally lipschitz functions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bačák</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Borwein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8-9</biblScope>
			<biblScope unit="page" from="961" to="978" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkage-thresholding algorithm for linear inverse problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust Optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>El Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Princeton Series in Applied Mathematics</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Princeton University Press</publisher>
			<pubPlace>Princeton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incremental proximal methods for large scale convex optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="195" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sparse estimation of a covariance matrix</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="807" to="820" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On-line learning in neural networks. Chap</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">On-line Learning and Stochastic Approximations</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="9" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Techniques d&apos;optimisation déterministe et stochastique pour la résolution de problèmes difficiles en cryptologie</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouallagui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>INSA de Rouen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Design of highly nonlinear balanced boolean functions using an hybridation of DCA and simulated annealing algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouallagui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modelling, Computation and Optimization in Information Systems and Management Sciences</title>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="579" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Feature selection via concave minimization and support vector machines</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Mangasarian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998. 1998</date>
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Enhancing sparsity by reweighted-l 1 minimization</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Fourier Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="877" to="905" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nonlinear wavelet image processing: variational problems, compression, and noise removal through wavelet shrinkage</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A D</forename><surname>Vore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Lucier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="319" to="335" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Iteratively reweighted algorithms for compressive sensing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="3869" to="3872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Joint optimization of cooperative beamforming and relay assignment in multi-user wireless relay networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Wirel. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5481" to="5495" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Personalized dose finding using outcome weighted learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Kosorok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">516</biblScope>
			<biblScope unit="page" from="1509" to="1521" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint optimization of source power allocation and distributed relay beamforming in multiuser peer-to-peer relay networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pesavento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2962" to="2973" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A regularization framework for multiple-instance learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2006</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Large scale transductive SVMs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1687" to="1712" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trading convexity for scalability</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2006</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="201" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Signal recovery by proximal forward-backward splitting</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Wajs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1168" to="1200" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trust Region Methods</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An iterative thresholding algorithm for linear inverse problems with a sparsity constraint</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Defrise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>De Mol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1413" to="1457" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B Methodol</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust outlier detection with L0-SVDD</title>
		<author>
			<persName><forename type="first">M</forename><surname>El Azami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lartizien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning</title>
		<imprint>
			<publisher>ESANN</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="389" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Phylogenetic analysis via DC programming</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Nayakkankuppam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A method for finding structured sparse solutions to nonnegative least squares problems with applications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2010" to="2046" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Variable selection via nonconcave penalized likelihood and its oracle properties</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">456</biblScope>
			<biblScope unit="page" from="1348" to="1360" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Constructing optimal sparse portfolios using regularization methods</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fastrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paterlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Winker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CMS</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="417" to="434" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dictionary learning for fast classification based on softthresholding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="306" to="321" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Mode switching for energy-efficient deviceto-device communications in cellular networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan-Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Wirel. Commun</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6993" to="7003" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Handbook of test problems in local and global optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Floudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Pardalos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Adjiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Gümüs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Harding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Klepeis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Schweiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Nonconvex Optimization and Its Applications</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="1999">1999</date>
			<publisher>Springer</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Batch and online learning algorithms for nonconvex Neyman-Pearson classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gasso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pappaioannou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spivak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Recovering sparse signals with a certain family of nonconvex penalties and DC programming</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gasso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4686" to="4698" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A non-convex algorithm framework based on DC programming and DCA for matrix completion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Algorithms</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="903" to="921" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A concave-convex procedure for TDOA based positioning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Gholami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gezici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Strom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Lett</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="765" to="768" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Hidden Markov anomaly detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Göernitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>W&amp;CP</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1833" to="1842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A general iterative shrinkage and thresholding algorithm for non-convex regularized optimization problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on International Conference on Machine Learning, ICML&apos;13</title>
		<meeting>the 30th International Conference on International Conference on Machine Learning, ICML&apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sparse signal reconstructions from limited data using FOCUSS: a reweighted minimum norm algorithm</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Gorodnitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="600" to="616" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Sparse high-dimensional fractional-norm support vector machine via DC programming</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="136" to="148" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Robust investment strategies with discrete asset choice constraints using DC programming and DCA</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gülpinar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moeini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="62" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fixed-point continuation for 1 -minimization: methodology and convergence</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Hale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1107" to="1130" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On functions representable as a difference of convex functions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hartman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac. J. Math</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="707" to="713" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">On the solution of a two ball trust region subproblem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Heinkenschloss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="249" to="276" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">From Convex Optimization to Nonconvex Optimization. Part I Necessary and Sufficient Conditions for Global Optimality</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Hiriart-Urruty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="219" to="239" />
			<pubPlace>Boston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Advanced machine learning techniques based on DC programming and DCA</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Ho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Solving an infinite-horizon discounted Markov decision process by DC programming and DCA</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering: ICCSAMA 2016, Proceedings, Part I</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Van Do</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="43" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Online DC optimization for online binary linear classification</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Bui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems: ACIIDS 2016, Proceedings, Part II</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Trawiński</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Hong</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="661" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A unified algorithmic framework for blockstructured optimization involving big data: with applications in machine learning and signal processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="77" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Ramp loss linear programming support vector machine</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Suykens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2185" to="2211" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Rejoinder to discussion of optimization transfer using surrogate objective functions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ibm: Cplex</forename><surname>Optimizer</surname></persName>
		</author>
		<ptr target="https://www.ibm.com/analytics/data-science/prescriptive-analytics/cplex-optimizer" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A study of the difference-of-convex approach for solving linear programs with complementarity constraints</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jara-Moroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waechter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program. Ser. B</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Optimal fronthaul quantization for cloud radio positioning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Simeone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haimovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Veh. Technol</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2763" to="2768" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The eigenvalue complementarity problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Júdice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Sherali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="156" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">On the asymmetric eigenvalue complementarity problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Júdice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Sherali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="549" to="568" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Proximal point methods and nonconvex optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tichatschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="389" to="406" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A DC optimization-based clustering technique for edge detection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Khalaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Astorino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>D'alessandro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gaudioso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Lett</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="627" to="640" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Network-based penalized regression with application to genomic data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="582" to="593" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Leveraging the margin more carefully</title>
		<author>
			<persName><forename type="first">N</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first international conference on Machine learning ICML 2004</title>
		<meeting>the twenty-first international conference on Machine learning ICML 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">63</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Ellipsoidal multiple instance learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Krummenacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2013</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="73" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Joint base-station association, channel assignment, beamforming and power control in heterogeneous networks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Speidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Droste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 75th Vehicular Technology Conference (VTC Spring)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A doubly sparse approach for group variable selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Inst. Stat. Math</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="997" to="1025" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Nonconvex regularizations for feature selection in ranking with sparse SVM</title>
		<author>
			<persName><forename type="first">L</forename><surname>Laporte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Déjean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1118" to="1130" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Network intrusion detection based on multi-class support vector machine</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zidna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Collective Intelligence. Technologies and Applications: ICCCI 2012, Proceedings, Part I</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Hoang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Jedrzejowicz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="536" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Modélisation et optimisation non convexe basées sur la programmation DC et DCA pour la résolution de certaines classes des problémes en fouille de données et cryptologie</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Université Paul Verlaine-Metz</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Sparse semi-supervised support vector machines by DC programming and DCA</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page" from="62" to="76" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A combined DCA: GA for constructing highly nonlinear balanced boolean functions in cryptography</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bouvry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="613" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Block clustering based on Difference of Convex functions (DC) programming and DC algorithms</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Huynh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2776" to="2807" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Image segmentation via feature weighted fuzzy clustering by a DCA based algorithm</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">479</biblScope>
			<biblScope unit="page" from="53" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">DC programming and DCA for solving minimum sum-of-squares clustering using weighted dissimilarity measures</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">XIII</biblScope>
			<biblScope unit="page" from="113" to="131" />
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">DCA for solving the scheduling of lifting vehicle in an automated port container terminal</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yassine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moussi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Manag. Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="286" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Analyse numérique des algorithmes de l&apos;optimisation DC. Approches locale et globale. Codes et simulations numériques en grande dimension</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>Université de Rouen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Applications. Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Contribution à l&apos;optimisation non convexe et l&apos;optimisation globale: : Théorie. Algorithmes et Applications</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Habilitation à Diriger des Recherches, National Institute for Applied Sciences</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Rouen</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">An efficient algorithm for globally minimizing a quadratic function under convex quadratic constraints</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="401" to="426" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Solving large scale molecular distance geometry problems by a smoothing technique via the Gaussian transform and D.C. programming</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="375" to="397" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">DCA collaborative for clustering</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Phylogenetic tree reconstruction by a DCA based algorithm</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>LITA, University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">DC programming and DCA for challenging problems in bioinformatics and computational biology</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automata, Universality, Computation, Emergence, Complexity and Computation</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Adamatzky</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="383" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A new efficient algorithm based on DC programming and DCA for clustering</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Belghiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="593" to="608" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Online learning based on Online DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Submitted</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">DC programming and DCA for general DC programs</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Van Do</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="15" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Error bounds via exact penalization with applications to concave and quadratic systems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="228" to="250" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Convergence analysis of DCA with subanalytic data</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Globally convergent DC trust-region methods</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I F</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="225" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Noisy image segmentation by a robust clustering algorithm based on DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Industrial Conference on Advances in Data Mining, ICDM&apos;08</title>
		<meeting>the 8th Industrial Conference on Advances in Data Mining, ICDM&apos;08</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="72" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">A DC programming approach for feature selection in support vector machines learning</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Data Anal. Classif</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="278" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Fuzzy clustering based on nonconvex optimisation approaches using difference of convex (DC) functions algorithms</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Data Anal. Classif</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="104" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">New and efficient DCA based algorithms for minimum sum-of-squares clustering</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="388" to="401" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Feature selection in machine learning: an exact penalty approach using a difference of convex function algorithm</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="163" to="186" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Solving the perceptron problem by deterministic optimization approach based on DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bouvry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INDIN</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<publisher>IEEE</publisher>
			<pubPlace>Cardiff</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Binary classification via spherical separator by DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1393" to="1407" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Stochastic DCA for the large-sum of non-convex functions problem and its application to group variable selection in classification</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08">2017. August 2017. 2017</date>
			<biblScope unit="page" from="3394" to="3403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A novel approach to automated cell counting based on a difference of convex functions algorithm (DCA)</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">:</forename><forename type="middle">M T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Collective Intelligence. Technologies and Applications</title>
		<imprint>
			<biblScope unit="volume">8083</biblScope>
			<biblScope unit="page" from="336" to="345" />
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Long-short portfolio optimization under cardinality constraints by difference of convex functions algorithm</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Moeini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">161</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="199" to="224" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">DC programming approach for portfolio optimization under step increasing transaction costs</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Moeini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="289" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Portfolio selection under downside risk measures and cardinality constraints based on DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Moeini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Manag. Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="459" to="475" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">A DC programming approach for solving the symmetric eigenvalue complementarity problem</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Moeini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joaquim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1097" to="1117" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Solving a multimodal transport problem by DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Ndiaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Research, Innovation and Vision for the Future</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">A DC programming approach for planning a multisensor multizone search for a target</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="231" to="239" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Self-organizing maps by difference of convex functions optimization</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Disc</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="1336" to="1365" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">DCA based algorithms for feature selection in multi-class support vector machine</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">249</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="273" to="300" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">A DC programming approach for finding communities in networks</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2827" to="2854" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">A robust approach for nonlinear UAV task assignment problem under uncertainty</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Computational Collective Intelligence II</title>
		<imprint>
			<biblScope unit="volume">6450</biblScope>
			<biblScope unit="page" from="147" to="159" />
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Solving the earliness tardiness scheduling problem by DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Balk</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="271" to="288" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">A time-indexed formulation of earliness tardiness scheduling via DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Multiconference on Computer Science and Information Technology IMCSIT</title>
		<imprint>
			<biblScope unit="issue">09</biblScope>
			<biblScope unit="page" from="779" to="784" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Energy minimization-based cross-layer design in wireless networks</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 High Performance Computing &amp; Simulation Conference (HPCS 2008)</title>
		<meeting>the 2008 High Performance Computing &amp; Simulation Conference (HPCS 2008)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="283" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">DC programming and DCA based cross-layer optimization in multi-hop TDMA networks. Intelligent Information and Database Systems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="volume">7803</biblScope>
			<biblScope unit="page" from="398" to="408" />
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Sparse signal recovery by difference of convex functions algorithms</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">:</forename><forename type="middle">H M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems</title>
		<imprint>
			<biblScope unit="volume">7803</biblScope>
			<biblScope unit="page" from="387" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">A continuous DC programming approach to the strategic supply chain design problem from qualified partner set</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1001" to="1012" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification using DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Ouchani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Front. Comput. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="612" to="620" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Solving a class of linearly constrained indefinite quadratic problems by D.C. algorithms</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="285" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">A branch-and-bound method via D.C. optimization algorithm and ellipsoidal technique for box constrained nonconvex quadratic programming problems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="206" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">D.C. programming approach for large-scale molecular optimization via the general distance geometry problem</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimization in Computational Chemistry and Molecular Biology: Local and Global Approaches</title>
		<title level="s">Nonconvex Optimization and Its Applications</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Floudas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Pardalos</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="301" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">A continuous approach for globally solving linearly constrained quadratic zero-one programming problems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="93" to="120" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">D.C. optimization approaches via Markov models for restoration of signal (1-D) and (2-D)</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Convex Analysis and Global Optimization</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Hadjisavvas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Pardalos</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="303" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">D.C. programming approach to the multidimensional scaling problem</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Local to Global Optimization</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Migdalas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Pardalos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Värbrand</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="231" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">D.C. programming approach for multicommodity network optimization problems with step increasing cost functions</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="205" to="232" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Large scale molecular optimization from distance matrices by a D.C. optimization approach</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="114" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">A new algorithm for solving large scale molecular distance geometry problems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optimization</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Di Pillo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Murli</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="285" to="302" />
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>High Performance Algorithms and Software for Nonlinear Optimization</note>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">The DC (difference of convex functions) programming and DCA revisited with DC models of real world nonconvex optimization problems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="23" to="48" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">A continuous approach for the concave cost supply problem via DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Appl. Math</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="325" to="338" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">On solving linear complemetarity problems by DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="507" to="524" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">A two phases DCA based algorithm for solving the Lennard-Jones problem</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>LITA, University of Metz</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Minimizing the morse potential energy function by a DC programming approach</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>LITA, University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">DC programming approaches for distance geometry problems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distance Geometry: Theory, Methods, and Applications</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Mucherino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lavor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Liberti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Maculan</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="225" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Network utility maximisation: A DC programming approach for Sigmoidal utility function</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Advanced Technologies for Communications (ATC&apos;13)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="50" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">DC programming in communication systems: challenging problems and methods</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vietnam J. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="28" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Difference of convex functions algorithms (DCA) for image restoration via a Markov random field model</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Eng</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="873" to="906" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">DCA based algorithms for multiple sequence alignment (MSA). Cent</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Belghiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="501" to="524" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Cryptanalysis of an identification scheme based on the perceptron problem using a hybridization of deterministic optimization and genetic algorithm</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bouallagui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 International Conference on Security &amp; Management</title>
		<meeting>the 2009 International Conference on Security &amp; Management<address><addrLine>SAM</addrLine></address></meeting>
		<imprint>
			<publisher>CSREA Press</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="117" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Exact penalty techniques in DC programming</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Rouen</pubPlace>
		</imprint>
		<respStmt>
			<orgName>National Institute for Applied Sciences</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Optimization based DC programming and DCA for hierarchical clustering</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1067" to="1085" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Exact penalty and error bounds in DC programming</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="509" to="535" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">DC approximation approaches for sparse optimization</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">244</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="46" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Numerical solution for optimization over the efficient set by D.C. optimization algorithm</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Muu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">A combined D.C. optimization-ellipsoidal branch-andbound algorithm for solving nonconvex quadratic programming problems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Muu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comb. Optim</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="28" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Exact penalty in DC programming</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Muu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vietnam J. Math</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="169" to="179" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Simplicially constrained D.C. optimization over the efficient and weakly efficient sets</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Muu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="503" to="521" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Efficient approaches for 2 -0 regularization and applications to feature selection in SVM</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="549" to="565" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Combination between global and local methods for solving an optimization problem over the efficient set</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thoai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="258" to="270" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">D.C. optimization techniques for solving a class of nonlinear bilevel programs</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thoai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Nguyen Canh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="337" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">A DC programming approach for a class of bilevel programming problems and its application in portfolio selection</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NACO Numer. Algebra Control Optim</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="167" to="185" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Behavior of DCA sequences for solving the trust-region subproblem</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="317" to="329" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">DC programming and DCA for sparse optimal scoring problem</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page" from="170" to="181" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">Efficient nonconvex group variable selection and application to group sparse optimal scoring</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Submitted</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">DC programming and DCA for sparse Fisher linear discriminant analysis</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2809" to="2822" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">An efficient DCA based algorithm for power control in large scale wireless networks</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="page" from="215" to="226" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Solving continuous min max problem for single period portfolio selection with discrete constraints by DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1025" to="1038" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">New and efficient algorithms for transfer prices and inventory holding policies in two-enterprise supply chains</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="24" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Optimizing a multi-stage production/inventory system by DC programming based approaches</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="441" to="468" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">A difference of convex functions algorithm for optimal scheduling and real-time assignment of preventive maintenance jobs on parallel processors</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">D</forename><surname>Adjallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Ind. Manag. Optim</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="243" to="258" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">DC programming and DCA for transmit beamforming and power allocation in multicasting relay network</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gély</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering: ICCSAMA 2016, Proceedings, Part I</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Van Do</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="29" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Optimizing radial basis functions by D.C. programming and its use in direct search for global derivative-free optimization</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Vaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I F</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOP</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="190" to="214" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Feature selection for linear SVMs under uncertain data: robust optimization based on difference of convex functions algorithms</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="36" to="50" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Efficient nonegative matrix factorization by DC programming and DCA</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1163" to="1216" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<author>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename></persName>
		</author>
		<ptr target="http://www.lita.univ-lorraine.fr/~lethi/index.php/en/research/dc-programming-and-dca.html(Homepage" />
		<title level="m">DC Programming and DCA</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Proximal newton-type methods for minimizing composite functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1420" to="1443" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Applications of convex analysis to multidimensional scaling</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Leeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Developments in Statistics</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Barra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Brodeau</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Romier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Van Cutsem</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North Holland</publisher>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="133" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title level="m" type="main">Methods for sparse and low-rank recovery under simplex constraints</title>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rangapuram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Slawski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.00507</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Variational multiplicative noise removal by DC programming</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1200" to="1216" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Ramp loss least squares support vector machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="61" to="68" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Ramp loss nonparallel support vector machine for pattern classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Based Syst</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="224" to="233" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Multicategory ψ-learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="500" to="509" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Multicategory ψ-learning and support vector machine: computational tools</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Doss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="219" to="236" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<monogr>
		<title level="m" type="main">Non-dominated set of a multi-objective optimisation problem</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Lancaster University</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Computational aspects of constrained L1-L2 minimization for compressive sensing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modelling, Computation and Optimization in Information Systems and Management Sciences</title>
		<editor>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="169" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Computing sparse representation in a highly coherent dictionary based on difference of L1 and L2</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="196" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Point source super-resolution via non-convex l 1 based methods</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1082" to="1100" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">A weighted difference of anisotropic and isotropic total variation model for image processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1798" to="1823" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Separable convexification and DCA techniques for capacity and flow assignment problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Phong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P L</forename><surname>Luna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RAIRO Oper. Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="269" to="281" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Machine learning via polyhedral concave minimization</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Mangasarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applied Mathematics and Parallel Computing-Festschrift for Klaus Ritter</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Fischer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Riedmueller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Schaeffler</surname></persName>
		</editor>
		<meeting><address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Physica-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="175" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Brève communication. régularisation d&apos;inéquations variationnelles par approximations successives</title>
		<author>
			<persName><forename type="first">B</forename><surname>Martinet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESAIM: Mathematical Modelling and Numerical Analysis -Modélisation Mathématique et Analyse Numérique 4(R3)</title>
		<imprint>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="154" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Large-scale nonconvex stochastic optimization by doubly stochastic successive convex approximation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mokhtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scutari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4701" to="4705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Secrecy rate maximization with uncoordinated cooperative jamming by single-antenna helpers under secrecy outage probability constraint</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Lett</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2174" to="2177" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ndiaye</surname></persName>
		</author>
		<title level="m">Simulation et optimisation DC dans les réseaux de transport combinés : codes à usage industriel</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>INSA de Rouen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Single straddle carrier routing problem in port container terminals: Mathematical model and solving approaches</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ndiaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Intell. Inf. Database Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="532" to="554" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">DC programming and DCA for large-scale two-dimensional packing problems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ndiaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems</title>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7197</biblScope>
			<biblScope unit="page" from="321" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Single straddle carrier routing problem in port container terminals: Mathematical model and solving approaches</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ndiaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modelling, Computation and Optimization in Information Systems and Management Sciences</title>
		<editor>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Bouvry</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Pham Dinh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="21" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Combined SVM-based feature selection and classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Steidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="129" to="150" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<monogr>
		<title level="m" type="main">The DC programming and the cross-entropy method for some classes of problems in finance, assignment and search theory</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>INSA de Rouen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b192">
	<monogr>
		<title level="m" type="main">La programmation DC et DCA pour certaines classes de problèmes en apprentissage et fouille de données</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b193">
	<monogr>
		<title level="m" type="main">Approches locales et globales basées sur la programmation DC et DCA pour des problèmes combinatoires en variables mixtes 0-1 : applications à la planification opérationnelle</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Université Paul Verlaine-Metz</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Solving an inventory routing problem in supply chain by DC programming and DCA</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems</title>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">6592</biblScope>
			<biblScope unit="page" from="432" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Convergence analysis of a proximal point algorithm for minimizing differences of functions</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="129" to="147" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B T</forename><surname>Nguyen</surname></persName>
		</author>
		<title level="m">La programmation DC et DCA en analyse d&apos;image : acquisition comprimée, segmentation et restauration</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">DC approximation approach for 0 -minimization in compressed sensing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering</title>
		<editor>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Van Do</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">A DC programming approach to the continuous equilibrium network design problem</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering: ICCSAMA 2016, Proceedings, Part I</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Van Do</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<title level="m" type="main">Techniques d&apos;optimisation en traitement d&apos;image et vision par ordinateur et en transport logistique</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Université Paul Verlaine-Metz</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b200">
	<monogr>
		<title level="m" type="main">Méthodes exactes pour l&apos;optimisation DC polyédrale en variables mixtes 0-1 basées sur DCA et des nouvelles coupes</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>INSA de Rouen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">A branch and bound algorithm based on DC programming and DCA for strategic capacity planning in supply chain design for a new market opportunity</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen Canh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research Proceedings. Operations Research Proceedings</title>
		<imprint>
			<biblScope unit="page" from="515" to="520" />
			<date type="published" when="2006">2006. 2007</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">DC programming and DCA approach for resource allocation optimization in OFDMA/TDD wireless networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen Canh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering</title>
		<editor>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Van Do</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">Solving the quadratic eigenvalue complementarity problem by DC programming</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Júdice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modelling, Computation and Optimization in Information Systems and Management Sciences</title>
		<editor>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="203" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Efficient DC programming approaches for asymmetric eigenvalue complementarity problem</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Judice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="812" to="829" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Learning sparse classifiers with difference of convex functions algorithms</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="830" to="854" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title level="m" type="main">On a local search for hexamatrix games</title>
		<author>
			<persName><forename type="first">A</forename><surname>Orlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strekalovsky</surname></persName>
		</author>
		<editor>A. Kononov, I. Bykadorov, O. Khamisov, I. Davydov, P. Kononova</editor>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="477" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<title level="m" type="main">Iterative Solutions of Nonlinear Equations in Several Variables</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rheinboldt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>Academic</publisher>
			<biblScope unit="page" from="253" to="255" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Cluster analysis: unsupervised learning via supervised learning with a non-convex penalty</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1865" to="1889" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Computing B-stationary points of nonsmooth DC programs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alvarado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="118" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Decomposition methods for computing directional stationary solutions of a class of non-smooth non-convex optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Power allocation in OFDM based NOMA systems: a DC programming approach</title>
		<author>
			<persName><forename type="first">P</forename><surname>Parida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Globecom Workshops (GC Wkshps)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1026" to="1031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
		<title level="m" type="main">A weighted difference of anisotropic and isotropic total variation for relaxed Mumford-Shah image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<publisher>IEEE ICIP</publisher>
			<biblScope unit="page" from="4314" to="4318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Multihop backhaul compression for the uplink of cloud radio access networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Simeone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shamai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Veh. Technol</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3185" to="3199" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<monogr>
		<title level="m" type="main">Programmation DC et DCA pour l&apos;optimisation non convexe/optimisation globale en variables mixtes entières : Codes et Applications</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>INSA de Rouen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">A DC programming framework for portfolio selection by minimizing the transaction costs</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">479</biblScope>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Elements homoduaux d&apos;une matrice A relatifs à un couple de normes (φ, ψ)</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Séminaire d&apos;Analyse Numérique</title>
		<meeting><address><addrLine>Grenoble</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
	<note>Applications au calcul de s φψ (a)</note>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Calcul du maximum d&apos;une forme quadratique définie positive sur la boule unité de la norme du maximum</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Séminaire d&apos;Analyse Numérique</title>
		<meeting><address><addrLine>Grenoble</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Contribution à la théorie de normes et ses applications à l&apos;analyse numérique. Université Joseph Fourier</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">&apos;etat es science</title>
		<meeting><address><addrLine>Grenoble</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
	<note type="report_type">Thèse de doctorat d</note>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Algorithmes de calcul du maximum des formes quadratiques sur la boule unité de la norme du maximum</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="401" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Convergence of a subgradient method for computing the bound norm of matrices</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="163" to="182" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">DC programming and DCA for solving Brugnano-Casulli piecewise linear systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="196" to="204" />
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>Supplement C</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Lagrangian stability and global optimality in nonconvex quadratic minimization over Euclidiean balls and spheres</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Convex Anal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="263" to="276" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Difference of convex function optimization algorithms (DCA) for globally minimizing nonconvex quadratic forms on Euclidean balls and spheres</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res. Lett</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="207" to="216" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">Convex analysis approach to D.C. programming: theory, algorithm and applications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Math. Vietnam</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="289" to="355" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">D.C. optimization algorithms for solving the trust region subproblem</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="476" to="505" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Recent advances in DC programming and DCA</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Computational Intelligence XIII</title>
		<imprint>
			<biblScope unit="volume">8342</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Combining DCA and interior point techniques for large-scale nonconvex quadratic programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Akoa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="609" to="629" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">DC programming approaches for discrete portfolio optimization under concave transaction costs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Lett</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">DC programming and DCA for globally solving the value-at-risk</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen Canh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Manag. Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="477" to="501" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">An efficient combination of DCA and B&amp;B using DC/SDP relaxation for globally solving binary quadratic programs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen Canh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="595" to="632" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">An efficient DC programming approach for portfolio decision with higher moments</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="525" to="554" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">DC programming and DCA for portfolio optimization with linear and fixed transaction costs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8398</biblScope>
			<biblScope unit="page" from="392" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Algorithms for solving a class of nonconvex optimization problems. Methods of subgradients</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Souad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fermat Days 85: Mathematics for Optimization, North-Holland Mathematics Studies</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Hiriart-Urruty</surname></persName>
		</editor>
		<meeting><address><addrLine>North-Holland; Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="249" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">Duality in D.C. (difference of convex functions) optimization. Subgradient methods</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Souad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trends in Mathematical Optimization</title>
		<title level="s">International Series of Numerical Mathematics</title>
		<meeting><address><addrLine>Basel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="276" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">D.C. iterations for SINR maximin multicasting in cognitive radio</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Kha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Signal Processing and Communication Systems (ICSPCS 2012)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<monogr>
		<title level="m" type="main">DCA based algorithms for learning with sparsity in high dimensional setting and stochastical learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Phan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">Sparse covariance matrix estimation by DCA-based algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3040" to="3077" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">Difference of convex functions programming for reinforcement learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pietquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Red Hook</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2519" to="2527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<monogr>
		<title level="m" type="main">Introduction to Optimization</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Optimization Software. Inc. Publication Division</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">Secure cooperative communications under secrecy outage constraint: a DC programming approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Poulakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vassaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Panagopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wirel. Commun. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="332" to="335" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<analytic>
		<title level="a" type="main">The symmetric eigenvalue complementarity problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Queiroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Júdice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Humes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Comput</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">248</biblScope>
			<biblScope unit="page" from="1849" to="1863" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<analytic>
		<title level="a" type="main">DC proximal newton for nonconvex optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gasso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="636" to="647" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<monogr>
		<title level="m" type="main">Successive convex approximation: analysis and applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>University of Minnesota</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">A unified convergence analysis of block successive minimization methods for nonsmooth optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1126" to="1153" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<analytic>
		<title level="a" type="main">Parallel successive convex approximation for nonsmooth nonconvex optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Red Hook</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<analytic>
		<title level="a" type="main">A stochastic successive minimization method for nonsmooth nonconvex optimization with applications to transceiver design in wireless communication networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="515" to="545" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<title level="a" type="main">A stochastic approximation method</title>
		<author>
			<persName><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Monro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Stat</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="407" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<meeting><address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b249">
	<analytic>
		<title level="a" type="main">Monotone operators and the proximal point algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Control Optim</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="877" to="898" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b250">
	<analytic>
		<title level="a" type="main">Rank-two beamforming and power allocation in multicasting relay networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pesavento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Signal Process</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3435" to="3447" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b251">
	<analytic>
		<title level="a" type="main">Solving the minimum m-dominating set problem by a continuous optimization approach based on DC programming and DCA</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bouvry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comb. Optim</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="397" to="412" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b252">
	<analytic>
		<title level="a" type="main">Signal and image approximation with level-set constraints</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="160" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">Discrete tomography by convex-concave regularization and D.C. programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schüle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Appl. Math</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="229" to="243" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">Adaptive reconstruction of discrete-valued objects from few projections</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schüle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Electron. Notes Discrete Math</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="365" to="384" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<analytic>
		<title level="a" type="main">Parallel and distributed methods for constrained nonconvex optimization-part I: theory</title>
		<author>
			<persName><forename type="first">G</forename><surname>Scutari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lampariello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1929" to="1944" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b256">
	<analytic>
		<title level="a" type="main">Parallel and distributed methods for constrained nonconvex optimization-part II: applications in communications and machine learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Scutari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lampariello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sardellitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1945" to="1960" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">Decomposition by partial linearization: parallel optimization of multi-agent systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Scutari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Palomar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="641" to="656" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<analytic>
		<title level="a" type="main">Quadratic eigenvalue problems under conic constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Anal. A</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="700" to="721" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">Simultaneous supervised clustering and feature selection over a graph</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="899" to="914" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<analytic>
		<title level="a" type="main">On ψ learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="724" to="734" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b261">
	<analytic>
		<title level="a" type="main">Matrix factorization with binary components</title>
		<author>
			<persName><forename type="first">M</forename><surname>Slawski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lutsik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Red Hook</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3210" to="3218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b262">
	<analytic>
		<title level="a" type="main">Relative novelty detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Teo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the 12th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="536" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b263">
	<analytic>
		<title level="a" type="main">Robust check loss-based variable selection of high-dimensional single-index varying-coefficient model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Nonlinear Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="109" to="128" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title level="a" type="main">Sparse eigen methods by D.C. programming</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R G</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;07</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="831" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">Robust principal component analysis via capped norms</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD, KDD&apos;13</title>
		<meeting>the 19th ACM SIGKDD, KDD&apos;13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="311" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<analytic>
		<title level="a" type="main">Proximal point algorithm for minimization of DC function</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Sampaio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Candido</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Math</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="451" to="462" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b267">
	<monogr>
		<title level="m" type="main">Programmation DC et DCA pour la résolution de certaines classes des problèmes dans les systèmes de transport et de communication</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>INSA -Rouen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b268">
	<analytic>
		<title level="a" type="main">Solving car pooling problem using DCA</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Arnould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khadraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Global Information Infrastructure Symposium (GIIS 2011)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b269">
	<analytic>
		<title level="a" type="main">Solving relaxation orienteering problem using DCA-CUT</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modelling, Computation and Optimization in Information Systems and Management Sciences</title>
		<editor>
			<persName><forename type="first">Le</forename><surname>Thi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham Dinh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<analytic>
		<title level="a" type="main">Solving multicast QoS routing problem in the context V2I communication services using DCA</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khadraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACIS 9th International Conference on Computer and Information Science (ICIS)</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="471" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<analytic>
		<title level="a" type="main">Solving QoS routing problems by DCA</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khadraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems</title>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">5991</biblScope>
			<biblScope unit="page" from="460" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b272">
	<analytic>
		<title level="a" type="main">Solving partitioning-hub location-routing problem using DCA</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khadraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Ind. Manag. Optim</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="102" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b273">
	<analytic>
		<title level="a" type="main">Solving many to many multicast QoS routing problem using DCA and proximal decomposition technique</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khadraoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computing, Networking and Communications</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="809" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<monogr>
		<title level="m" type="main">Techniques d&apos;optimisation non convexe basée sur la programmation DC et DCA et méthodes évolutives pour la classification non supervisée</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">Clustering data stream by a sub-window approach using DCA</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boudjeloud-Assala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Data Mining in Pattern Recognition</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Perner</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="279" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b276">
	<analytic>
		<title level="a" type="main">Clustering data streams over sliding windows by DCA</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boudjeloud-Assala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Computational Methods for Knowledge Engineering</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Van Do</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Le Thi</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="65" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<analytic>
		<title level="a" type="main">An efficient clustering method for massive dataset based on DC programming and DCA approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boudjeloud-Assala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICONIP 2013, Part II</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hirose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Hou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kil</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8227</biblScope>
			<biblScope unit="page" from="538" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b278">
	<monogr>
		<title level="m" type="main">Full-rate general rank beamforming in single-group multicasting networks using non-orthogonal STBC</title>
		<author>
			<persName><forename type="first">D</forename><surname>Taleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pesavento</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2365" to="2369" />
		</imprint>
	</monogr>
	<note>24th EUSIPCO</note>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">Inverse covariance estimation from data with missing values using the concave-convex procedure</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Akametalu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Tomlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bayen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">53rd IEEE Conference on Decision and Control</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="5736" to="5742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">A DC programming heuristic applied to the logistics network design problem</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Thanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bostel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Péton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Prod. Econ</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="105" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<analytic>
		<title level="a" type="main">DC programming approach for a class of nonconvex programs involving 0 norm. Modelling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computation and Optimization in Information Systems and Management Sciences</title>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="348" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b282">
	<analytic>
		<title level="a" type="main">A DC programming approach for sparse eigenvalue problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ICML-10</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Fürnkranz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</editor>
		<meeting>ICML-10</meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1063" to="1070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b283">
	<analytic>
		<title level="a" type="main">A multiple kernel framework for inductive semi-supervised SVM learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gasso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="46" to="58" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b284">
	<analytic>
		<title level="a" type="main">Finding musically meaningful words by sparse CCA</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Turnbull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Barrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R G</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS Workshop on Music, the Brain and Cognition</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b285">
	<analytic>
		<title level="a" type="main">DCA for minimizing the cost and tardiness of preventive maintenance tasks under real-time allocation constraint</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Adjallah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Le</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Swiatek</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">5991</biblScope>
			<biblScope unit="page" from="410" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b286">
	<analytic>
		<title level="a" type="main">A new approach for optimizing traffic signals in networks considering rerouting</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modelling, Computation and Optimization in Information Systems and Management Sciences, Advances in Intelligent Systems and Computing</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b287">
	<analytic>
		<title level="a" type="main">DC programming and DCA for a novel resource allocation problem in emerging area of cooperative physical layer security</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced Computational Methods for Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page" from="57" to="68" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Advances in Intelligent Systems and Computing</note>
</biblStruct>

<biblStruct xml:id="b288">
	<analytic>
		<title level="a" type="main">DC programming and DCA for enhancing physical layer security via cooperative jamming</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="235" to="244" />
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>Supplement C</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b289">
	<analytic>
		<title level="a" type="main">DC programming and DCA for enhancing physical layer security via relay beamforming strategies</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gély</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACIIDS 2016, Part II</title>
		<title level="s">LNAI</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Trawiński</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Hong</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9622</biblScope>
			<biblScope unit="page" from="640" to="650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b290">
	<analytic>
		<title level="a" type="main">A difference of convex functions approach to large-scale log-linear model estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tsiligkaridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marcheret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio Speech</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2255" to="2266" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b291">
	<analytic>
		<title level="a" type="main">Convergence rate of the Pham Dinh-Le Thi algorithm for the trust-region subproblem</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Tuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="904" to="915" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b292">
	<analytic>
		<title level="a" type="main">Convergence of Pham Dinh-Le Thi&apos;s algorithm for the trust-region subproblem</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="337" to="347" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b293">
	<analytic>
		<title level="a" type="main">LOQO: an interior point code for quadratic programming</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Vanderbei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="451" to="484" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b294">
	<analytic>
		<title level="a" type="main">Non-negative matrix factorization, convexity and isometry</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vasiloglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 SIAM ICDM</title>
		<meeting>the 2009 SIAM ICDM</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="673" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b295">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Vavasis</surname></persName>
		</author>
		<title level="m">Nonlinear Optimization: Complexity Issues</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b296">
	<monogr>
		<title level="m" type="main">Learning with sparsity and uncertainty by difference of convex functions optimization</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>University of Lorraine</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b297">
	<analytic>
		<title level="a" type="main">Robust optimization for clustering</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Part II</title>
		<meeting><address><addrLine>Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">9622</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b298">
	<analytic>
		<title level="a" type="main">DC programming and DCA for dictionary learning</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Collective Intelligence</title>
		<imprint>
			<biblScope unit="volume">9329</biblScope>
			<biblScope unit="page" from="295" to="304" />
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct xml:id="b299">
	<analytic>
		<title level="a" type="main">Ramp loss support vector data description</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Le Thi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham Dinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Asian Conference on Intelligent Information and Database Systems</title>
		<meeting>9th Asian Conference on Intelligent Information and Database Systems<address><addrLine>Kanazawa; Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-03-05">2017. 3-5 April 2017. 2017. 2017</date>
		</imprint>
	</monogr>
	<note>Lecture Note in Computer Science. to appear</note>
</biblStruct>

<biblStruct xml:id="b300">
	<analytic>
		<title level="a" type="main">DC programming approach for resource allocation in wireless networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vucic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Symposium on Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (WiOpt 2010)</title>
		<meeting>the 8th International Symposium on Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (WiOpt 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="380" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b301">
	<analytic>
		<title level="a" type="main">Energy efficient secure communication over decode-and-forward relay channels</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="892" to="905" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b302">
	<analytic>
		<title level="a" type="main">Linear time maximum margin clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="319" to="332" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b303">
	<analytic>
		<title level="a" type="main">Large margin semi-supervised learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1867" to="1891" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b304">
	<analytic>
		<title level="a" type="main">On transductive support vector machines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Prediction and Discovery</title>
		<title level="s">Contemporary Mathematics</title>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">443</biblScope>
			<biblScope unit="page" from="7" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b305">
	<analytic>
		<title level="a" type="main">On efficient large margin semisupervised learning: method and theory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="719" to="742" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b306">
	<analytic>
		<title level="a" type="main">Training robust support vector regression via D.C. program</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inf. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2385" to="2394" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b307">
	<analytic>
		<title level="a" type="main">Robust support vector regression with generalized loss function and applications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Process. Lett</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="106" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b308">
	<analytic>
		<title level="a" type="main">Calibrating nonconvex penalized regression in ultra-high dimension</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2505" to="2536" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b309">
	<analytic>
		<title level="a" type="main">An effective l 0 -svm classifier for face recognition based on haar features</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Nat. Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b310">
	<analytic>
		<title level="a" type="main">Prior learning and convex-concave regularization of binary tomography</title>
		<author>
			<persName><forename type="first">S</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schüle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Electron. Notes Discrete Math</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="313" to="327" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b311">
	<analytic>
		<title level="a" type="main">Use of the zero-norm with linear models and kernel methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tipping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1439" to="1461" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b312">
	<analytic>
		<title level="a" type="main">Value-at-risk optimization using the difference of convex algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wozabal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OR Spectrum</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="861" to="883" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b313">
	<analytic>
		<title level="a" type="main">A new algorithm and theory for penalized regression-based clustering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b314">
	<analytic>
		<title level="a" type="main">A DC Programming approach for sensor network localization with uncertainties in anchor positions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Ind. Manag. Optim</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="817" to="826" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b315">
	<analytic>
		<title level="a" type="main">Robust truncated hinge loss support vector machines</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">479</biblScope>
			<biblScope unit="page" from="974" to="983" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b316">
	<analytic>
		<title level="a" type="main">Variable selection in quantile regression</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat Sin</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="801" to="817" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b317">
	<analytic>
		<title level="a" type="main">Efficient nonconvex sparse group feature selection via continuous and discrete optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">224</biblScope>
			<biblScope unit="page" from="28" to="50" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b318">
	<analytic>
		<title level="a" type="main">A DC programming approach for feature selection in the minimax probability machine</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="24" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b319">
	<analytic>
		<title level="a" type="main">A sparse logistic regression framework by difference of convex functions programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="254" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b320">
	<analytic>
		<title level="a" type="main">A class of semi-supervised support vector machines by DC programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Data Anal. Classif</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="433" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b321">
	<analytic>
		<title level="a" type="main">A sparse extreme learning machine framework by continuous optimization algorithms and its application in pattern recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Appl. Artif. Int</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="176" to="189" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b322">
	<monogr>
		<title level="m" type="main">Feature grouping and selection over an undirected graph</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>ACM SIGKDD</publisher>
			<biblScope unit="page" from="922" to="930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b323">
	<analytic>
		<title level="a" type="main">Absolute fused lasso and its application to genome-wide association studies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1955" to="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b324">
	<analytic>
		<title level="a" type="main">Minimization of 1-2 for compressed sensing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="536" to="563" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b325">
	<monogr>
		<title level="m" type="main">Linear feature transform and enhancement of classification on deep neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Submitted</note>
</biblStruct>

<biblStruct xml:id="b326">
	<analytic>
		<title level="a" type="main">Enhanced protein fold recognition through a novel data integration approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b327">
	<monogr>
		<title level="m" type="main">Convex-concave procedure for weighted sum-rate maximization in a MIMO interference network</title>
		<author>
			<persName><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lijun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<publisher>IEEE GLOBECOM</publisher>
			<biblScope unit="page" from="4060" to="4065" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b328">
	<analytic>
		<title level="a" type="main">Learning structural SVMs with latent variables</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;09</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1169" to="1176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b329">
	<analytic>
		<title level="a" type="main">Multiple-Criteria Decision Making: Concepts, Techniques, and Extensions</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Concepts and Methods in Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="1985">1985</date>
			<publisher>Springer</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b330">
	<analytic>
		<title level="a" type="main">The concave-convex procedure</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="915" to="936" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b331">
	<analytic>
		<title level="a" type="main">Maximum margin clustering made practical</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="596" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b332">
	<analytic>
		<title level="a" type="main">Select objective functions for multiple criteria programming classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Intelligence and Intelligent Agent Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="420" to="423" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
	<note>WI-IAT&apos;08</note>
</biblStruct>

<biblStruct xml:id="b333">
	<analytic>
		<title level="a" type="main">Variable selection for support vector machines in moderately high dimensions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="76" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b334">
	<analytic>
		<title level="a" type="main">Multiclass probabilistic kernel discriminant analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Joint Conference on Artifical Intelligence, IJCAI&apos;09</title>
		<meeting>the 21st International Joint Conference on Artifical Intelligence, IJCAI&apos;09</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1363" to="1368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b335">
	<analytic>
		<title level="a" type="main">Joint beamforming optimization and power control for full-duplex MIMO two-way relay channel</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="555" to="566" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b336">
	<analytic>
		<title level="a" type="main">Improving physical layer secrecy using full-duplex jamming receivers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Krikidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Petropulu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="4962" to="4974" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b337">
	<analytic>
		<title level="a" type="main">Training robust support vector regression with smooth non-convex loss function</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1039" to="1058" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b338">
	<analytic>
		<title level="a" type="main">Combining DC-programming and steepest-descent to solve the singlevehicle inventory routing problem</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Aghezzaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Ind. Eng</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="321" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b339">
	<analytic>
		<title level="a" type="main">Enhanced MIMOME wiretap channel via adopting full-duplex MIMO radios</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Communications Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="3320" to="3325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b340">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2291" to="2320" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b341">
	<analytic>
		<title level="a" type="main">Simultaneous grouping pursuit and feature selection over an undirected graph</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">502</biblScope>
			<biblScope unit="page" from="713" to="725" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b342">
	<analytic>
		<title level="a" type="main">Discrete tomography by continuous multilabeling subject to projection constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th German Conference on Pattern Recognition</title>
		<meeting>the 38th German Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b343">
	<analytic>
		<title level="a" type="main">The adaptive lasso and its oracle properties</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="issue">476</biblScope>
			<biblScope unit="page" from="1418" to="1429" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b344">
	<analytic>
		<title level="a" type="main">One-step sparse estimates in nonconcave penalized likelihood models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1509" to="1533" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
