<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fairness in the First Stage of Two-Stage Recommender Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fairness in the First Stage of Two-Stage Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many large-scale recommender systems consist of two stages, where the first stage focuses on efficiently generating a small subset of promising candidates from a huge pool of items for the secondstage model to curate final recommendations from. In this paper, we investigate how to ensure group fairness to the items in this two-stage paradigm. In particular, we find that existing first-stage recommenders might select an irrecoverably unfair set of candidates such that there is no hope for the second-stage recommender to deliver fair recommendations. To this end, we propose two thresholdpolicy selection rules that, given any relevance model of queries and items and a point-wise lower confidence bound on the expected number of relevant items for each policy, find near-optimal sets of candidates that contain enough relevant items in expectation from each group of items. To instantiate the rules, we demonstrate how to derive such confidence bounds from potentially partial and biased user feedback data, which are abundant in many large-scale recommender systems. In addition, we provide both finite-sample and asymptotic analysis of how close the two threshold selection rules are to the optimal thresholds. Beyond this theoretical analysis, we show empirically that these two rules can consistently select enough relevant items from each group while minimizing the size of the candidate sets for a wide range of settings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Two-stage pipelines <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77]</ref> are ubiquitous in large-scale recommender systems. Their key advantage lies in their efficiency and scalability, making it possible to curate personalized recommendations from billions of items within milliseconds <ref type="bibr" target="#b44">[45]</ref>. The first stage focuses on efficiently generating a small set of candidates that contains enough relevant items. To achieve the necessary efficiency, models used in the first stage may be less accurate and biased. The second stage only considers the candidates selected in the first stage for generating the final recommendations. It can thus be more resource intensive, which allows second-stage models to be more accurate and less biased.</p><p>While much prior work has focused on improving the efficiency and overall effectiveness of two-stage pipelines <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b44">45]</ref>, less attention has been given to the fairness aspects of this twostage paradigm. We therefore investigate methods for ensuring fair allocation of exposure to the items and their providers in twostage pipelines, for which there are ample ethical <ref type="bibr" target="#b39">[40]</ref>, economical (e.g., provider retention, super-star economics <ref type="bibr" target="#b46">[47]</ref>), and legal (e.g., anti-trust law <ref type="bibr" target="#b56">[57]</ref>) reasons. We specifically investigate how the first stage impacts the fairness of the recommendations, making our work complementary to the existing body of work on fairness and diversity of the second stage in bandits <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b63">64]</ref> and rankings <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b74">75]</ref>. These second-stage methods do not apply to the first stage, since their computation overhead is at least linear in the number of items and would thus lead to unacceptable latency if they are used in the first stage <ref type="foot" target="#foot_0">1</ref> .</p><p>We consider a group-based notion of fairness to the items. Since the second-stage recommender makes the final recommendations from the candidate set produced by the first stage, a key requirement for the first stage is to select enough relevant items from each group of items to avoid generating an irrecoverably unfair set of candidates. For example, consider an e-commerce recommender system, where we aim to ensure both small businesses and large businesses receive an equitable amount of exposure to the users. Without a fairness-aware candidate generation policy in the first stage, it might happen that the group of items belonging to small businesses are disproportionately selected less in the first stage, which might be due to biased relevance estimation towards the items from small businesses. In this case, there is little hope for the second-stage recommendation policy to ensure fairness, since <ref type="bibr" target="#b0">(1)</ref> there might not be enough relevant items from small businesses for the second-stage recommendations to be fair; <ref type="bibr" target="#b1">(2)</ref> second-stage recommendation policies typically only ensure fairness proportional to the items selected in the first stage, where small businesses are already unfairly represented. These fairness issues can appear in almost any two-stage recommender system where we need to consider fair allocation of exposure to the items, including those in hiring, online streaming, and social media.</p><p>In this paper, we study how to ensure fairness with distributionfree and finite-sample guarantees in the first stage of two-stage recommender systems, while retaining the efficiency of existing first-stage recommender systems. In particular, limited by the latency requirements and motivated by the Rooney rule <ref type="bibr" target="#b12">[13]</ref>, we focus on constructing threshold-based first-stage candidate generation policies that can provably select the smallest sets of candidates that contain a desired expected number of relevant items from each group, given any-possibly biased-relevance model. These guarantees make our approach different from existing works that rely on reducing the bias of relevance estimation in recommendation policies to improve fairness <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b71">72]</ref>. While these are certainly useful for the first stage, they do not provide finite-sample and distribution-free guarantees on the fairness and quality of the items selected in the first stage.</p><p>Contributions. We formalize fairness objectives for the first stage of recommender pipelines and propose two threshold selection rules-which we call the union rule and the monotone rulemotivated by distribution-free uncertainty quantification methods. We show that, given any relevance model of queries and items, they can provably select a desired number of relevant items in expectation from each group with high probability, while minimizing the candidate-set size in the first stage. This result holds even if the relevance model is biased against some groups. We also provide both finite-sample and asymptotic analysis on how close the thresholds selected by the two rules are to the optimal ones. The threshold selection rules and the near-optimality analysis rely on lower and upper confidence bounds on the expected number of relevant items from each group for candidate generation policies. Thus, we derive such confidence bounds from potentially biased and partial user feedback data (e.g., user clicks), which are abundant in many recommender systems. From these bounds, we show that the two threshold selection rules approach the optimal thresholds asymptotically. In addition, We also discuss how the proposed first-stage recommendation policy design can shift the cost of inaccurate relevance estimation and lack of data from the disadvantaged groups<ref type="foot" target="#foot_1">2</ref> to the latency of the second-stage recommender, which provides economic incentives for the decision makers to construct more accurate relevance models and to collect more data for every group of items.</p><p>Finally, we corroborate the theoretical analysis of the two proposed selection rules with an empirical evaluation on the Microsoft Learning to Rank datasets <ref type="bibr" target="#b50">[51]</ref> against several baselines. The results show that only the two proposed selection rules can consistently select enough relevant items from each group across different amounts of user feedback data and accuracies of the relevance model. With a decent amount of data, the two proposed selection rules achieve the smallest candidate-set size among the methods that can select enough relevant items. We also conduct ablation studies to test their robustness to the parameters in the selection rules. To facilitate research in this area, we will release the code for the the empirical evaluation with the final version of the paper. We have submitted an anonymous version of the code with the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FURTHER RELATED WORK</head><p>Our proposed threshold selection rules are inspired by distributionfree uncertainty quantification methods <ref type="bibr" target="#b24">[25]</ref>, including calibration <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b49">50]</ref> and conformal prediction <ref type="bibr" target="#b62">[63]</ref>. The goal of distributionfree uncertainty quantification is to provide point estimates with finite-sample distribution-free error guarantees (calibration) or confidence intervals (conformal prediction) of some target parameters of interest. In this context, the most relevant work is arguably by Bates et al. <ref type="bibr" target="#b2">[3]</ref>, where they provide a strategy to control the risk of prediction sets from a pool of candidates. Our proposed monotone threshold selection rule borrows similar ideas from their strategy. The strategy relies on a point-wise lower confidence bound on the risk, which they derive from full-information data. In contrast, we derive the confidence bounds using partial and biased user feedback, which we can typically have easy access to in recommender systems. In addition, we also provide both finite-sample and asymptotic near-optimality analysis of the two proposed threshold selection rules.</p><p>The confidence bounds we derive are built upon literature on off-policy evaluation in recommender systems <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b59">60]</ref>. Many works have proposed estimators to estimate the expected utility of a contextual bandit <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b68">69]</ref> or a ranking policy <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b70">71]</ref> from biased and partial user feedback. Some works have derived finite-sample confidence bounds on the estimation error in contextual bandits <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b42">43]</ref>. We use similar techniques to derive confidence bounds around the clipped inverse propensity weighted estimator <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b32">33]</ref> for the ranking setting.</p><p>Threshold selection rules have also been applied to screening processes <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b65">66]</ref>. However, these works assume that the candidates are independent and identically distributed (i.i.d.). In contrast, we consider recommendation scenarios where the relevances of the items are dependent given a recommendation request. Thus these approaches do not apply here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FAIRNESS IN THE FIRST STAGE</head><p>We consider recommendation problems with 𝑛 items<ref type="foot" target="#foot_2">3</ref> 𝒅 = 𝑑 𝑗 𝑗 ∈ [𝑛] , where each item 𝑑 𝑗 belongs to the item space D, i.e., 𝑑 𝑗 ∈ D for all 𝑗 ∈ [𝑛]. We want to select enough relevant items from several (possibly overlapping) groups G of items. We assume the group information is known for every item 𝑑 𝑗 and can be included in the feature representation of the item. We model the distribution of requests coming into the recommender system using a distribution 𝑃 𝑄,𝑹 over queries and relevance vectors. For each recommendation request, the query 𝑞 ∈ Q and the relevance vector 𝒓 = 𝑟 𝑗 𝑗 ∈ [𝑛] of the items are independently drawn from 𝑞, 𝒓 ∼ 𝑃 𝑄,𝑹 , where 𝑟 𝑗 ∈ {0, 1} is the relevance of item 𝑑 𝑗 to the recommendation request. The first-stage recommender relies on an expected-relevance estimation model<ref type="foot" target="#foot_3">4</ref> 𝑓 : Q × D → [0, 1], which maps a query 𝑞 and an item 𝑑 𝑗 to an estimate 𝑓 𝑞, 𝑑 𝑗 of the expected relevance <ref type="foot" target="#foot_4">5</ref>  and 𝑠 𝑗 ∈ {0, 1} represents whether the item 𝑑 𝑗 is selected (𝑠 𝑗 = 1) or not selected (𝑠 𝑗 = 0).</p><p>Ideally, we would like a policy 𝜋 𝑓 that selects only items that are relevant to the recommendation request from each group. Unfortunately, as long as there is no deterministic mapping between the query 𝑞 and the relevance vector 𝒓, such perfect candidate generation policy does not exist in general. What is worse, to satisfy the latency requirements, recommender systems require that 𝑓 be computed efficiently, often at the expense of accuracy and unbiasedness. So instead, we focus on constructing a policy 𝜋 𝑓 that creates sets of items that are near-optimal in terms of the candidate-set size, while provably containing enough relevant items in expectation for each group of items, without making assumptions on the distribution 𝑃 𝑄,𝑹 nor the accuracy/bias of the relevance model 𝑓 .</p><p>In particular, given any relevance model 𝑓 , we consider groupaware threshold policies that select 𝑡 𝑔 ∈ [𝑡 max 𝑔 ] top-scored (predicted by the relevance model 𝑓 ) items from each group 𝑔. 𝑡 max 𝑔 is the largest candidate-set size the decision makers consider for a group 𝑔, which conveys the decision makers' belief that there must be enough relevant items from group 𝑔, had they selected 𝑡 max 𝑔 top-scored items from 𝑔. Formally, let 𝒕 = 𝑡 𝑔 𝑔 ∈ G , a threshold policy 𝜋 𝑓 𝒕 selects an item if it is among the 𝑡 𝑔 top-scored items from a group 𝑔, i.e.,</p><formula xml:id="formula_0">𝑠 𝑗 = 1 if ∃𝑔 ∈ G s.t. 𝑗 ∈ 𝜎 𝑓 𝑞,𝑔 ( 𝑗 ′ ) : 𝑗 ′ ∈ 𝑡 𝑔 0 otherwise,<label>(1)</label></formula><p>where 𝜎 𝑓 𝑞,𝑔 is a ranking of the items in the group 𝑔 by their estimated relevance to the query 𝑞 predicted by 𝑓 , which returns the index 𝜎 𝑓 𝑞,𝑔 ( 𝑗) of the item that is ranked at position 𝑗 from group 𝑔 . We assume that 𝜎 𝑓 𝑞,𝑔 is deterministic without loss of generality. We aim to select a threshold vector 𝒕 ∈ 𝑔 ∈ G 𝑡 max 𝑔 such that the expected number of relevant items from each group 𝑔 ∈ G is greater than a target 𝑈 ★ 𝑔 ∈ R specified by the decision makers, i.e.,</p><formula xml:id="formula_1">𝑈 𝑔 𝑡 𝑔 𝑈 𝑔 𝜋 𝑓 𝒕 = E 𝑞,𝒓 ∼𝑃 𝑄,𝑹       ∑︁ 𝑗 ∈[𝑡 𝑔 ] 𝑟 𝜎 𝑓 𝑞,𝑔 ( 𝑗)       ≥ 𝑈 ★ 𝑔 ,<label>(2)</label></formula><p>while minimizing the candidate-set size 𝑡 𝑔 of each group 𝑔. Note that when the groups are disjoint, minimizing the candidate-set size of each group is equivalent to minimizing the candidate-set size of the whole first-stage recommender. Throughout the paper, we make the following assumptions.</p><p>Assumption 3.1.</p><formula xml:id="formula_2">𝑈 𝑔 𝑡 max 𝑔 ≥ 𝑈 ★ 𝑔 &gt; 0 ∀𝑔 ∈ G.</formula><p>The target expected numbers of relevant items 𝑈 ★ 𝑔 𝑔 ∈ G reflect the decision makers' belief that they can build a fair second-stage recommender system given 𝑈 ★ 𝑔 relevant items from each group 𝑔.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">FAIR AND NEAR-OPTIMAL THRESHOLD SELECTION RULES</head><p>In this section, we first introduce two threshold selection rules that can provably select enough relevant items in expectation from each group with high probability, while achieving near-optimal candidate-set sizes. Both rules rely on a point-wise lower confidence bound on the expected number of relevant items for each threshold policy and each group, and their near-optimality gaps further depend on a point-wise upper confidence bound on that quantity. Thus, we derive such lower and upper confidence bounds from some user feedback data (e.g., user clicks), which might be partial and biased. From these bounds, we instantiate concrete threshold selection algorithms, provide asymptotic analysis on how close the proposed threshold selection rules are to the optimal, and discuss how these two rules can incentivize the decision makers to improve the accuracy of the relevance model and collect more data for the disadvantaged groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Threshold Selection Rules</head><p>For now, lets assume that we have access to a point-wise lower confidence bound Û − 𝑔 (𝑡, 𝛼) on the expected number of relevant items 𝑈 𝑔 (𝑡) such that for any group 𝑔 ∈ G, threshold<ref type="foot" target="#foot_5">6</ref> 𝑡 ∈ 0 :</p><formula xml:id="formula_3">𝑡 max 𝑔 − 1 ,</formula><p>and 𝛼 ∈ (0, 1),</p><formula xml:id="formula_4">Pr 𝑈 𝑔 (𝑡) ≥ Û − 𝑔 (𝑡, 𝛼) ≥ 1 − 𝛼 .</formula><p>We will derive one such bound using user feedback data in Section 4.3. Given this bound, we propose two threshold selection rules which can ensure that the expected number of relevant items is above the target level 𝑈 ★ 𝑔 with high probability, while achieving near-optimal expected candidate-set size for a group 𝑔.</p><p>The first rule we propose is called the union threshold selection rule. Given any success probability 1 − 𝛼 ∈ (0, 1), it selects the smallest threshold tunion 𝑔 for a group 𝑔 such that the lower confidence bound on the expected number of relevant items with failure probability 𝛼 𝑡 max 𝑔 −1 is greater than the target, i.e.,</p><formula xml:id="formula_5">tunion 𝑔 min          𝑡 ∈ 𝑡 max 𝑔 − 1 : Û − 𝑔 𝑡, 𝛼 𝑡 max 𝑔 − 1 ≥ 𝑈 ★ 𝑔          ,<label>(3)</label></formula><p>where we define the minimum over the empty set for a group 𝑔 to be 𝑡 max 𝑔 , i.e., we set the threshold to be 𝑡 max 𝑔 if none of the lower bounds exceeds the target. We show that the union threshold selection rule can select enough relevant items for a group 𝑔 with high probability in the following theorem, with a proof that applies the union bound over the lower confidence bounds for each threshold, as reflected in our naming of the rule. Proof. For a group 𝑔, applying the union bound to the lower confidence bounds for each threshold, and by Assumption 3.1, we have that with probability at least 1 − 𝛼,</p><formula xml:id="formula_6">𝑈 𝑔 (𝑡) ≥ Û − 𝑔 𝑡, 𝛼 𝑡 max 𝑔 − 1 ∀𝑡 ∈ 𝑡 max 𝑔 .</formula><p>When the above event holds,</p><formula xml:id="formula_7">𝑈 𝑔 tunion 𝑔 ≥ Û − 𝑔 tunion 𝑔 , 𝛼 𝑡 max 𝑔 − 1 ≥ 𝑈 ★ 𝑔 ,</formula><p>where the second inequality is by the definition of tunion</p><formula xml:id="formula_8">𝑔 . ■</formula><p>The second selection rule is called the monotone threshold selection rule. Given any success probability 1 − 𝛼 ∈ (0, 1), it selects the smallest threshold tmono 𝑔 for a group 𝑔 such that the lower confidence bound with failure probability 𝛼 for every threshold larger than or equal to tmono 𝑔 is greater than the target 𝑈 ★ 𝑔 , i.e.,</p><formula xml:id="formula_9">tmono 𝑔 min 𝑡 ∈ 𝑡 max 𝑔 − 1 : Û − 𝑔 𝑡 ′ , 𝛼 ≥𝑈 ★ 𝑔 , ∀𝑡 ≤ 𝑡 ′ &lt;𝑡 max 𝑔 .<label>(4)</label></formula><p>Compared to tunion 𝑔 , tmono 𝑔 allows for a larger failure probability in the confidence lower bounds for each threshold, but requires that the lower bounds be greater than the target for all the thresholds  larger than the selected one, in addition to the selected one. It can also ensure selecting enough relevant items with high probability for any group as shown in the following theorem, where the proof leverages the fact that 𝑈 𝑔 is monotonically increasing, as reflected in our naming of the rule. Theorem 4.2. Under Assumption 3.1, for any group 𝑔 ∈ G and 𝛼 ∈ (0, 1), with probability at least 1 − 𝛼,</p><formula xml:id="formula_10">𝑈 𝑔 tmono 𝑔 ≥ 𝑈 ★ 𝑔 .</formula><p>Proof. The proof of the theorem is inspired by that of Theorem 1 in <ref type="bibr" target="#b2">[3]</ref>.</p><p>For any group 𝑔, let 𝑡 ★ 𝑔 be the smallest threshold such that the expected number of relevant items from group 𝑔 using the threshold policy is larger than or equal to 𝑈 ★ 𝑔 , i.e.,</p><formula xml:id="formula_11">𝑡 ★ 𝑔 min 𝑡 ∈ 𝑡 max 𝑔 : 𝑈 𝑔 (𝑡) ≥ 𝑈 ★ 𝑔 .<label>(5)</label></formula><p>By Assumption 3.1, we know that the set on the right of Eq. </p><formula xml:id="formula_12">Û − 𝑔 𝑡 ★ 𝑔 − 1, 𝛼 ≥ 𝑈 ★ 𝑔 &gt; 𝑈 𝑔 𝑡 ★ 𝑔 − 1 .</formula><p>By the lower confidence bound, we know that this happens with probability at most 𝛼, which concludes the proof. ■</p><p>We summarize the fair first-stage threshold-policy selection algorithm in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Finite-Sample Near-Optimality Gaps</head><p>So far, we have shown that both threshold selection rules ensure that the expected number of relevant items is large enough with high probability from each group. Now we characterize how far the expected number of relevant items selected by each threshold policy deviates from the target 𝑈 ★ 𝑔 for each group 𝑔. The finite-sample near-optimality gaps we prove depend also on a point-wise upper confidence bound Û + 𝑔 (𝑡, 𝛼) on the expected number of relevant items 𝑈 𝑔 (𝑡) such that for any group 𝑔 ∈ G, threshold 𝑡 ∈ 𝑡 max 𝑔 − 1 , and 𝛼 ∈ (0, 1),</p><formula xml:id="formula_13">Pr 𝑈 𝑔 (𝑡) ≤ Û + 𝑔 (𝑡, 𝛼) ≥ 1 − 𝛼 .<label>(6)</label></formula><p>We will show how to derive one such bound for data that takes the form of partial-information user feedback in Section 4.3.</p><p>For the union threshold selection rule tunion 𝑔 , we have the following proposition that bounds how much more relevant items it selects than the target 𝑈 ★ 𝑔 .</p><p>Proposition 4.3. Under Assumption 3.1, for any group 𝑔 ∈ G and 𝛼 ∈ (0, 1), with probability at least 1 − 𝛼,</p><formula xml:id="formula_14">𝑈 𝑔 tunion 𝑔 − 𝑈 ★ 𝑔 &lt; Û + 𝑔 tunion 𝑔 , 𝛼 𝑡 max 𝑔 − 1 − Û − 𝑔 tunion 𝑔 − 1, 𝛼 𝑡 max 𝑔 − 1 .</formula><p>Proof. By applying the union bound over the upper confidence bounds for all the thresholds for a group 𝑔 and by Assumption 3.1, we have that with probability at least 1 − 𝛼,</p><formula xml:id="formula_15">𝑈 𝑔 (𝑡) ≤ Û + 𝑔 𝑡, 𝛼 𝑡 max 𝑔 − 1 ∀𝑡 ∈ 𝑡 max 𝑔 ,</formula><p>and thus</p><formula xml:id="formula_16">𝑈 𝑔 tunion 𝑔 ≤ Û + 𝑔 tunion 𝑔 , 𝛼 𝑡 max 𝑔 − 1 = Û − 𝑔 tunion 𝑔 − 1, 𝛼 𝑡 max 𝑔 − 1 + Û + 𝑔 tunion 𝑔 , 𝛼 𝑡 max 𝑔 − 1 − Û − 𝑔 tunion 𝑔 − 1, 𝛼 𝑡 max 𝑔 − 1 &lt; 𝑈 ★ 𝑔 + Û + 𝑔 tunion 𝑔 , 𝛼 𝑡 max 𝑔 − 1 − Û − 𝑔 tunion 𝑔 − 1, 𝛼 𝑡 max 𝑔 − 1 ,</formula><p>where the last inequality is by the definition of tunion The proof of proposition 4.4 is almost the same as that of Proposition 4.3, and therefore we omit it. We can see that both threshold selection rules rely on the lower confidence bounds, and their optimality gaps depend further on the upper confidence bounds on the expected number of relevant items for threshold policies. To instantiate the two rules and their finite-sample near-optimality gaps, we introduce how to derive such bounds using user feedback data in the next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Confidence Bounds from User Feedback</head><p>In many recommender systems, we have access to an abundance of user feedback (e.g., user clicks, dwell times) that can help reveal the relevance of the items to the queries. However, these data are partial (we only observe a user's feedback for a subset of the items) and biased (by the presentation of the policy that logged the data). Thus, we derive confidence bounds that are robust to these properties 7 .</p><p>More formally, we use a sample of logged user feedback for 𝑚 recommendation served by a deployed logging policy 𝜋 0 . For each recommendation request 𝑖, we merely assume that the query and the relevance vector are independently sampled from the query and relevance-vector distribution 𝑞 𝑖 , 𝒓 𝑖 ∼ 𝑃 𝑄,𝑹 . Instead of directly observing the relevance vector 𝒓 𝑖 , we observe some user feedback (e.g., user clicks)</p><formula xml:id="formula_17">𝒄 𝑖 = 𝑐 𝑗 𝑖 𝑗 ∈ [𝑛]</formula><p>that is typically biased by the recommendation that 𝜋 0 made (e.g., position in ranking). To model this presentation bias, we follow the standard approach <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b67">68]</ref> where the user feedback for an item 𝑑 𝑗 is decomposed as the product of the user observation and the relevance 𝑐 𝑶 | 𝑄,𝑹 . We call the conditional probability that the user observes an item under the logging policy 𝜋 0 the propensity, and denote it as</p><formula xml:id="formula_18">𝑝 𝑗 𝑖 Pr 𝑂 𝑗 𝑖 = 1 | 𝑄 = 𝑞 𝑖 , 𝑹 = 𝒓 𝑖 ; 𝜋 0 .</formula><p>In the case of one-item recommendation, this can be interpreted as the probability that the logging policy 𝜋 0 recommends the item. Since we control the logging policy, this propensity is known by design. In the case of ranking, the propensities typically need to be estimated. There are many existing works on estimating the propensities <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b67">68]</ref> by making assumptions on how the users interact with the ranked items (e.g., position-based click models <ref type="bibr" target="#b0">[1]</ref> where the propensity only depends on the rank of the item, and cascade click model <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b61">62]</ref> where it further depends on the relevances of the items in a particular way). Thus we assume we know the (estimated) propensities, and the batch of logged user feedback for constructing the confidence bounds is</p><formula xml:id="formula_19">S CB = {𝑞 𝑖 , 𝒄 𝑖 , 𝒑 𝑖 } 𝑖 ∈ [𝑚] , where 𝒑 𝑖 = 𝑝 𝑗 𝑖 𝑗 ∈ [𝑛]</formula><p>and 𝑚 &gt; 1. Throughout the paper, we assume that the propensities are positive, as formally described below, which can be achieved by carefully designing the logging policy. Assumption 4.5. There exists 𝛾 &gt; 0 such that</p><formula xml:id="formula_20">𝑝 𝜎 𝑓 𝑞,𝑔 ( 𝑗) &gt; 𝛾 ∀𝑔 ∈ G, 𝑞 ∈ Q, 𝑗 ∈ 𝑡 max 𝑔 .</formula><p>The confidence bounds we derive using S CB are based on the clipped inverse propensity weighted (CIPW) estimator <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33]</ref> adapted to this ranking setting. The following CIPW estimator estimates the expected number of relevant items 𝑈 𝑔 (𝑡 𝑔 ) of threshold policies (recall that we use capital letters to denote random variables) 7 The full-information setting is a special case of this partial-information setting where the users observe every item.  Due to space limit, the proofs of these two and the rest of propositions are in the supplementary material. Note that both bounds apply to any group of items including the group of all items 𝒅. Though we apply them for fair first-stage threshold-policy design and characterizing the finite-sample near-optimality gaps, we believe that they might be of independent interests in other contexts.</p><formula xml:id="formula_21">Û CIPW 𝑔,𝜆 𝑡 𝑔 1 𝑚 ∑︁ 𝑖 ∈ [𝑚] ∑︁ 𝑗 ∈[𝑡 𝑔 ] min 𝜆, 1 𝑝 𝜎 𝑓 𝑄 𝑖 ,𝑔 ( 𝑗) 𝑖 𝐶 𝜎 𝑓 𝑄 𝑖 ,𝑔 ( 𝑗) 𝑖 ,<label>(7)</label></formula><p>With these bounds, we can instantiate Algorithm 1 and the finitesample near-optimality gaps. We can see that these two selection rules can ensure enough relevant items from each group regardless of the accuracy of the relevance model nor the amount of user feedback data across groups. However, the candidate-set sizes of the groups are determined by those factors. In particular, we need to include more items from a group if the relevance model is less accurate and/or we have less data for the group. This shifts the costs of inaccurate relevance estimation and/or lack of data for the items from disadvantaged groups to the latency of the secondstage recommender, and thus provides economic incentives for the decision makers to build accurate relevance models and collect enough data for every group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Asymptotic Near-Optimality Analysis</head><p>From these upper and lower confidence bounds, we can now analyze how close the selected thresholds are to the optimal thresholds 𝑡 ★ 𝑔 as defined in Eq. 5 asymptotically. In the following propositions, we show that the expected number of relevant items using the selected policies will converge to the target asymptotically, and the selected thresholds will also converge to the optimal thresholds asymptotically, under mild assumptions. </p><formula xml:id="formula_22">𝑈 𝑔 t𝑔 − 1 &lt; 𝑈 ★ 𝑔 + 𝛿.</formula><p>Proposition 4.9. Under the conditions in Proposition 4.8 and further assume that 𝑈 𝑔 is strictly increasing, we have that for any group 𝑔 ∈ G, 𝛼 ∈ (0, 1), it holds almost surely that there exists 𝑐 &gt; 0 such that for any 𝑚 &gt; 𝑐,</p><formula xml:id="formula_23">𝑡 ★ 𝑔 ≤ t𝑔 ≤ 𝑡 ★ 𝑔 + 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EMPIRICAL EVALUATION</head><p>In this section, we compare the union tunion 𝑔 and the monotone tmono 𝑔 threshold selection rules with several competitive baselines on first-stage recommendation scenarios simulated from the Microsoft Learning-to-Rank WEB30K dataset <ref type="bibr" target="#b50">[51]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setup</head><p>The dataset consists of 30, 000 queries, along with the relevances and the features of the items per query. We divide the items into two categories-"old and estabilished" and "new and undiscovered"by their "url click count" feature given in the dataset. The feature represents "the click count of a url aggregated from user browsing data in a period". We set the items with zero click count as the disadvantaged group disadv and the other items as the advantaged group adv. We binarize the relevance by assigning relevance 1 to items with an original label of 2, 3, or 4, and 0 to the others. The average numbers of relevant items per query from each group are AR adv = 6.16 and AR disadv = 13.99.</p><p>For each experiment, we randomly split the data into 1% for training a logistic regression model as the relevance model 𝑓 , 69% for simulating the user feedback, and 30% for testing different firststage candidate generation policies. To simulate user feedback, we follow prior works <ref type="bibr" target="#b35">[36]</ref> to assume that users follow a positionbased click model <ref type="bibr" target="#b15">[16]</ref>. More specifically, for each recommendation request 𝑖, we randomly sample a query from the 69% data, create a ranking for the top 𝑡 max Unless specified explicitly, we set the size of the user feedback 𝑚 = 100, 000, the clipping parameter 𝜆 = 100, and the largest number of items we consider from both groups to be the same 𝑡 max adv = 𝑡 max disadv = 50, the success probability 1 − 𝛼 = 0.9 by default. We set the target expected numbers of relevant items 𝑈 ★ adv and 𝑈 ★ disadv to satisfy the equal opportunity constraint <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b65">66]</ref>, i.e., 𝑈 ★ adv /AR adv = 𝑈 ★ disadv /AR disadv , subject to 𝑈 ★ disadv + 𝑈 ★ adv = 5. Baselines. We compare tmono 𝑔 (CIPW-LB-mono) and tunion 𝑔 (CIPW-LB-union) with several baselines. The Uncalibrated Individual baseline selects top-ranked items from each group until the sum of the scores predicted by 𝑓 exceed the target. The Uncalibrated Marginal baseline selects the smallest threshold for each group using the simulated user data such that the average sum of scores is greater than the target. The Platt Individual, Platt Marginal, Platt PG Individual, and Platt PG Marginal baselines are the same as the uncalibrated ones, except that they apply Platt scaling <ref type="bibr" target="#b49">[50]</ref> to the relevance model using user feedback data through inverse propensity weighting <ref type="bibr" target="#b43">[44]</ref>, where "PG" implies that we calibrate the relevance model per group. The IPW baseline selects the smallest threshold such that the inverse propensity weighted (IPW) estimator on the expected number of relevant items of the threshold policy is greater than the target for each group.</p><p>Metrics. To compare different first-stage candidate generation policies, we run experiments 50 times for each setting. For each run, we estimate whether each candidate generation policy selects</p><formula xml:id="formula_24">enough relevant items ER 𝑔 I Ê 𝑗 ∈ [𝑛]:𝑑 𝑗 ∈𝑔 𝑠 𝑗 𝑟 𝑗 ≥ 𝑈 ★ 𝑔 and</formula><p>the candidate-set size CSS 𝑔 = Ê𝑔 𝑗 ∈ [𝑛]:𝑑 𝑗 ∈𝑔 𝑠 𝑗 for both 𝑔 = adv and 𝑔 = disadv on the 30% full-information test data. We then compare different polices in terms of the percentage of times they ensure enough relevant items (along with standard errors) and the average candidate-set size (along with standard deviations) for both groups across the 50 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">How do different methods scale with the size of user feedback data?</head><p>Figure <ref type="figure" target="#fig_6">1</ref> compares different candidate generation policies with respect to the percentage of times they selects enough relevant items ((a) and (b)), and the average candidate-set sizes ((c) and (d)) for both the advantaged groups ((a) and (c)) and the disadvantaged group ((b) and (d)). We can see that the Uncalibrated baselines do not guarantee selecting enough relevant items in general. The IPW baseline selects enough relevant items for most of the instances, and achieves smaller or comparable candidate-set sizes as the two proposed rules. Part of the reason is that we consider discrete threshold policies, and the expected number of relevant items of the optimal threshold 𝑈 𝑔 𝑡 ★ 𝑔 is typically larger than the target 𝑈 ★ 𝑔 . As long as the IPW estimator does not overestimate the expected number of relevant items more than the difference 𝑈 𝑔 𝑡 ★ 𝑔 − 𝑈 ★ 𝑔 , it will select enough relevant items. However, as we can see, it fails to select enough relevant items more often on the disadvantaged group, especially when the size of the user feedback data is small. This is because the variance of the CIPW estimator is larger for the disadvantaged group due to a larger threshold and smaller propensities. This phenomena is more obvious when the relevance model is less accurate for the disadvantaged group as shown in the next subsection. Among the methods that always select enough  relevant items, the two proposed threshold selection rules have the smallest candidate-set sizes when the amount of data is large. As we have less and less data, the two proposed rules select more and more items to account for the increasing uncertainty due to the lack of data. Comparing the two proposed rules, the monotone selection rule consistently outperforms the union selection rule in terms of the candidate-set size across data sizes, partly because it allows for a larger failure probability in the lower confidence bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">How does the accuracy of the relevance model affect different groups of items?</head><p>To simulate scenarios where the relevance model 𝑓 might be less accurate for the disadvantaged group, we vary the accuracy of 𝑓 for the disadvantaged group by replacing its prediction for items in the disadvantaged group with some noise 𝛽 sampled from 𝛽 ∼ Beta(1, 10), with probability 𝜖 disadv , i.e., 𝑓 disadv = (1 − 𝜂) 𝑓 + 𝜂𝛽, where 𝜂 ∼ Bernoulli (𝜖 disadv ). Figure <ref type="figure" target="#fig_11">2</ref> compares different candidate generation policies when we vary the relevance noise ratio 𝜖 disadv to the disadvantaged group. We can see that, as the relevance model becomes less accurate for the disadvantaged group (𝜖 disadv becomes larger), only the two proposed threshold selection rules always select enough relevant items for the disadvantaged group. In particular, IPW fails to select enough relevant items substantially more often for the disadvantaged group than for the advantaged group, since it does not account for the uncertainty in the estimation process. This highlights the benefits of distribution-free and finite-sample guarantees the proposed union and monotone threshold selection rules enjoy. The two rules achieve this by selecting more items from the disadvantaged group to account for the increasing uncertainty due to less accurate relevance model for the disadvantaged group. Again, the monotone threshold selection rule consistently outperforms the union threshold selection rule in terms of the candidate-set size across different relevance noise ratios to the disadvantaged group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">How robust are the two proposed rules to</head><p>the clipping parameter 𝜆?</p><p>Figure <ref type="figure" target="#fig_12">3</ref> shows the performance of the two proposed threshold selection rules with varying clipping parameter 𝜆. We can see that the two proposed rules can select enough relevant items across different values in the clipping parameter 𝜆, which confirms their distribution-free and finite-sample guarantees. The candidate-set sizes for both groups exhibit a bowel shape, which is consistent with our theory of finite-sample near-optimality gaps, that the optimal 𝜆 lies in the middle where there is a favorable bias and variance trade-off in the CIPW estimator.  5.5 Are the two proposed rules robust to the largest considered threshold 𝑡 max 𝑔 ?</p><p>We compare the performance of the two proposed threshold selection rules when we use different largest considered threshold 𝑡 max 𝑔 in Figure <ref type="figure">4</ref>. Unsurprisingly, the two proposed selection rules still select enough relevant items across different values of 𝑡 max 𝑔 , as predicted by the distribution-free and finite-sample guarantees. In terms of the candidate-set size, there is a slight increase for the union threshold selection rule as the largest considered threshold increases. This is expected since it uses smaller and smaller failure probabilities in the lower confidence bounds. For the monotone threshold selection rule, the candidate-set size does not change with the maximum considered threshold, partly because the failure probability it uses in the lower confidence bounds does not change. This also shows that the lower confidence bounds used in the monotone selection rule are still not too loose even when the thresholds are large, since the threshold 𝑡 is in the log terms in the bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we initiated the study of fairness in the first stage of two-stage recommender systems. In particular, we proposed two threshold-policy selection rules that can select fair first-stage policies using abundantly available user-feedback data even if the relevance model used in the first stage is biased and has disparate accuracy across groups. We show that the two selection rules can provably select enough relevant items in expectation from each group with high probability, achieve near-optimal candidate-set sizes, and retain the efficiency of most existing first-stage recommender systems. Both the theoretical analysis and the empirical evaluation confirm that the two proposed selection rules are robust to the amount of user feedback data, the accuracy of the relevance model, and the parameters inside the two rules.</p><p>A PROOF OF <ref type="bibr">PROPOSITION 4.6</ref> Proof. We can decompose the difference between 𝑈 𝑔 (𝑡) and its CIPW estimate as the bias and the concentration terms as follows .</p><p>For the bias term, we have</p><formula xml:id="formula_25">𝑈 𝑔 (𝑡) − 𝑈 CIPW 𝑔,𝜆 (𝑡) = E 𝑞,𝒓 ∼𝑃 𝑄,𝑹       ∑︁ 𝑗 ∈ [𝑡 ] 𝑟 𝜎 𝑓 𝑞,𝑔 ( 𝑗) − min 𝜆𝑝 𝜎 𝑓 𝑞,𝑔 ( 𝑗) , 1 𝑟 𝜎 𝑓 𝑞,𝑔 ( 𝑗)       ≥ 0.</formula><p>Combing the two inequalities, we conclude the proof. ■ B PROOF OF PROPOSITION 4.7</p><p>Proof. We decompose the difference between 𝑈 𝑔 (𝑡) and its CIPW estimate as the bias and the concentration terms slightly different from the proof of Proposition 4. .</p><p>For the first concentration term, we can apply Hoeffding's inequality <ref type="bibr" target="#b28">[29]</ref> over the randomness in the queries. We can get that, with probability at least 1 − 𝛼/2, 𝑈 𝑔 (𝑡) − Proof. We still only prove the proposition for tmono </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 4 . 1 .</head><label>41</label><figDesc>Under Assumption 3.1, for any group 𝑔 ∈ G and 𝛼 ∈ (0, 1), with probability at least 1 − 𝛼, 𝑈 𝑔 tunion 𝑔 ≥ 𝑈 ★ 𝑔 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 2 : 3 :</head><label>123</label><figDesc>Fair First-Stage Threshold-Policy Selection 1: input: G, 𝑈 ★ Compute the lower confidence bounds for each group 𝑔 ∈ G and each threshold 𝑡 ∈ 𝑡 max 𝑔 − 1 : Û − 𝑔 (𝑡, 𝛼) for tmono 𝑔 or Û − 𝑔 𝑡, 𝛼 𝑡 max 𝑔 −1 for tunion 𝑔 . Compute t𝑔 for each group 𝑔 ∈ G : t𝑔 = tmono 𝑔 by Eq 4 or t𝑔 = tunion 𝑔 by Eq 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>4: return 𝜋 𝑓 t , where t = t𝑔 𝑔 ∈ G .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>We can similarly derive the finite-sample near-optimality gap for tmono 𝑔 as shown in the following proposition. Proposition 4.4. Under Assumption 3.1, for any group 𝑔 and 𝛼 ∈ (0, 1), with probability at least 1 − 𝛼,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fairness</head><label></label><figDesc>in the First Stage of Two-Stage Recommender Systems</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>𝑜𝑗 𝑖 ∈ {0, 1} denotes whether the user observes the item. The user observation vector 𝒐 ∈ {0, 1} 𝑛 is generated from 𝑃 𝜋 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1 𝑚</head><label>1</label><figDesc>with a clipping parameter 𝜆-the maximum inverse propensity weight-to balance the bias and variance of the estimator. The following propositions provide empirical upper and lower confidence bounds on the expected number of relevant items 𝑈 𝑔 𝑡 𝑔 around its CIPW estimate Û CIPW 𝑔,𝜆 𝑡 𝑔 . Proposition 4.6. Under Assumption 4.5, for any 𝜆 &gt; 0, 𝑔 ∈ G, 𝑡 ∈ 𝑡 max 𝑔 − 1 , and 𝛼 ∈ (0, 1), with probability at least 1 − 𝛼, we have that 𝑈 𝑔 (𝑡) ≥ Û CIPW 𝑔,𝜆 (𝑡) − √︂ 2𝑉 𝑚 (𝒁 𝑔,𝑡 ) ln(2/𝛼) 𝑔 ( 𝑗) 𝑖 𝐶 𝜎 𝑓 𝑄 𝑖 ,𝑔 ( 𝑗) 𝑖 be the CIPW estimate of recommendation request 𝑖, and 𝑉 𝑚 𝒁 𝑔,𝑡 =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Proposition 4 . 7 .</head><label>47</label><figDesc>Under Assumption 4.5, for any 𝜆 &gt; 0, 𝑔 ∈ G, 𝑡 ∈ 𝑡 max 𝑔 − 1 , and 𝛼 ∈ (0, 1), with probability at least 1 − 𝛼, we have that 𝑈 𝑔 (𝑡) ≤ Û CIPW 𝑔,𝜆 (𝑡) + √︂ 2𝑉 𝑚 (𝒁 𝑔,𝑡 ) ln(4/𝛼) 𝑔 ( 𝑗) 𝑖 Û + (𝑡, 𝛼).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Proposition 4 . 8 .</head><label>48</label><figDesc>Let t𝑔 be either tunion 𝑔 or tmono 𝑔 , and 𝜆 = √ 𝑚. Under Assumption 3.1 and 4.5, for any group 𝑔 ∈ G and any 𝛼 ∈ (0, 1), it holds almost surely (with probability 1) that for any 𝛿 &gt; 0, there exists 𝑐 &gt; 0 such that for any 𝑚 &gt; 𝑐, 𝑈 ★ 𝑔 − 𝛿 &lt; 𝑈 𝑔 t𝑔 &lt; 1 + 𝑈 ★ 𝑔 + 𝛿, and even stronger than the second inequality above,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>𝑔</head><label></label><figDesc>items from each group by the relevance model 𝑓 , simulate the user observation 𝑜 𝑗 𝑖 ∼ Bernoulli 𝑝 𝑗 𝑖 with the propensity set as one over the rank of the item 𝑝 𝑗 𝑖 = 1 𝑟𝑎𝑛𝑘 ( 𝑗 | 𝜋 0 ) for each item 𝑗, and the simulated user feedback is 𝑐 𝑗 𝑖 = 𝑜 𝑗 𝑖 𝑟 𝑗 𝑖 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison of different first-stage candidate generation policies when we vary the amount 𝑚 of user feedback data.The left two plots show the empirical probability, along with standard error bars, that each policy selects enough relevant items for the advantaged group ER adv and the disadvantaged group ER disadv across 50 runs. The right two plots show the empirical average, along with one standard deviation as shaded regions, of the expected candidate-set size for the advantaged group CSS adv and the disadvantaged group CSS disadv across 50 runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of different first-stage candidate generation policies when we vary the accuracy of the relevance model to the disadvantaged group by changing the relevance noise ratio 𝜖 disadv to the disadvantaged group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Analysis of the two proposed threshold selection rules when we vary the clipping parameter 𝜆.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>6 ,.</head><label>6</label><figDesc>𝑈 𝑔 (𝑡) − Û CIPW 𝑔,𝜆 (𝑡) = 1 𝑚 ∑︁ 𝑖 ∈ [𝑚] 𝑈 𝑔 (𝑡 | 𝑄 𝑖 ) − E Û CIPW 𝑔,𝜆 (𝑡) | 𝑸 Bias Term + 𝑈 𝑔 (𝑡) − 1 𝑚 ∑︁ 𝑖 ∈ [𝑚] 𝑈 𝑔 (𝑡 | 𝑄 𝑖 ) First Concentration Term + E Û CIPW 𝑔,𝜆 (𝑡) | 𝑸 − Û CIPW 𝑔,𝜆(𝑡)Second Concentration Term.where𝑸 = (𝑄 𝑖 ) 𝑖 ∈ [𝑚] , E [• | 𝑸] or E [• | 𝑄 𝑖 ]denote taking expectation over all the randomness in • except that in 𝑸 or 𝑄 𝑖 , and𝑈 𝑔 (𝑡 | 𝑄 𝑖 )For the second concentration term, we can similarly apply the empirical Bernstein bound (Theorem 4 in<ref type="bibr" target="#b45">[46]</ref>) to the i.i.d. random variables𝑍 𝑔,𝑡 𝑖 𝑖 ∈ [𝑚]over the randomness in the rewards and the user observations to get that with probability at least 1 − 𝛼/2,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>1 .− 1 −𝑔− 1 ,</head><label>111</label><figDesc>𝑚 ∑︁ 𝑖 ∈ [𝑚] 𝑈 𝑔 (𝑡 | 𝑄 𝑖 ) ≤ 𝑡 √︂ ln(2/𝛼) 2𝑚.For the bias term, we upper bound it as follows 1 𝑚 ∑︁ 𝑖 ∈ [𝑚] 𝑈 𝑔 (𝑡 | 𝑄 𝑖 ) − E Û CIPW Combining the three inequalities by applying the union bound concludes the proof. ■ C PROOF OF PROPOSITION 4.8 Proof. We only prove the proposition for tmono 𝑔 , since the proof for tunion 𝑔 is almost the same. Since 𝑝 𝑗 𝑖 ≥ 𝛾 &gt; 0, we have lim 𝑚→+∞ 𝜆 = lim 𝑚→+∞ √ 𝑚 &gt; 1 𝛾 ≥ 1 𝑝 𝑗 𝑖 . Thus the CIPW estimator becomes the vanilla inverse propensity weighted estimator [30] asymptotically, which is unbiased. As a result, lim 𝑚→+∞ Û CIPW 𝑔,𝜆 (𝑡) = 𝑈 𝑔 (𝑡) ∀𝑡 ∈ 𝑡 max 𝑔 holds almost surely by the strong law of large numbers. On the other hand, 𝑝 𝑗 𝑖 ≥ 𝛾 &gt; 0 also implies that 𝑍 𝑔,𝑡 𝑖 ≤ 𝑡 𝛾 . Thus the sample variance can be bounded by 𝑉 𝑚 𝒁 𝑔,𝑡 ≤ 𝑡 2 𝛾 2 . Therefore, it holds almost surely that lim terms in the differences are sub-constant in 𝑚. By the definition of limit at infinity, it holds almost surely that, for any 𝛿 &gt; 0, there exists 𝑐 &gt; 0 such that for any 𝑚 &gt; 𝑐, 𝑈 𝑔 tmono 𝑔 + 𝛿 &gt; Û − 𝑔 tmono 𝑔 , 𝛼 ≥ 𝑈 ★ 𝑔 , and 𝑈 𝑔 tmono 𝑔 𝛿 &lt; Û − 𝑔 tmono 𝛼 &lt; 𝑈 ★ 𝑔 . From the above, we can get 𝑈 𝑔 tmono 𝑔 ≤ 1 + 𝑈 𝑔 tmono 𝑔 − 1 &lt; 1 + 𝑈 ★ 𝑔 + 𝛿. ■ D PROOF OF PROPOSITION 4.9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>E 𝑅 𝑗 | 𝑄 = 𝑞 .</figDesc><table><row><cell cols="3">Given a fixed first-stage relevance model 𝑓 , a first-stage candidate</cell></row><row><cell cols="3">generation policy 𝜋 𝑓 : Q × D 𝑛 → {0, 1} 𝑛 maps a query 𝑞 and</cell></row><row><cell cols="2">the items 𝑑 𝑗</cell><cell>𝑗 ∈ [𝑛] to the selection decisions 𝒔 = 𝜋 (𝑞, 𝒅), where</cell></row><row><cell>𝒔 = 𝑠 𝑗</cell><cell>𝑗 ∈ [𝑛]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>𝑈 𝑔 (𝑡) − Û CIPW 𝑔,𝜆 (𝑡) = 𝑈 𝑔 (𝑡) − 𝑈 CIPW Lets first look at the concentration term. Since for all 𝑖 ∈ [𝑚] and 𝑗 ∈ 𝑡 maxApplying the empirical Bernstein bound (Theorem 4 in<ref type="bibr" target="#b45">[46]</ref>) to the i.i.d. random variables 𝒁 𝑔,𝑡 , we have that for any 𝛼 ∈ (0, 1), with probability at least 1 − 𝛼,</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>𝑔,𝜆</cell><cell>(𝑡)</cell><cell>+ 𝑈 CIPW 𝑔,𝜆</cell><cell>(𝑡) − Û CIPW 𝑔,𝜆</cell><cell>(𝑡)</cell><cell>,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Bias</cell><cell></cell><cell>Concentration</cell></row><row><cell>where</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>𝑈 CIPW 𝑔,𝜆</cell><cell>(𝑡)</cell><cell cols="2">E 𝑞,𝒓 ∼𝑃 𝑄,𝑹 ,𝒐∼𝑃</cell><cell cols="2">𝜋 0 𝑶 | 𝑞,𝒓</cell><cell cols="5">𝑧 𝑔,𝑡 = E 𝑞,𝒓 ∼𝑃 𝑄,𝑹</cell><cell>     </cell><cell>∑︁ 𝑗 ∈ [𝑡 ]</cell><cell>min 𝜆𝑝 𝜎 𝑓 𝑞,𝑔 ( 𝑗) , 1 𝑟 𝜎 𝑓 𝑞,𝑔 ( 𝑗)</cell><cell>     </cell><cell>.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>𝑔</cell><cell cols="2">− 1 , 0 ≤ min 𝜆,</cell><cell>𝑝</cell><cell>1 𝑄 𝑖 ,𝑔 𝜎 𝑖 𝑓</cell><cell>( 𝑗 )</cell><cell>≤ 𝜆, and 𝐶</cell><cell>𝜎 𝑄 𝑖 ,𝑔 ( 𝑗) 𝑓 𝑖</cell><cell>∈ {0, 1}, we have</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0 ≤ 𝑍</cell><cell cols="4">𝑔,𝑡 𝑖 ≤ 𝑡𝜆 ∀𝑖 ∈ [𝑚].</cell></row><row><cell></cell><cell></cell><cell>𝑈 CIPW 𝑔,𝜆</cell><cell cols="2">(𝑡) − Û CIPW 𝑔,𝜆</cell><cell cols="3">(𝑡) ≥ − √︂</cell><cell cols="3">2𝑉 𝑚 (𝒁 𝑔,𝑡 ) ln(2/𝛼) 𝑚</cell><cell>−</cell><cell>7𝑡𝜆 ln(2/𝛼) 3(𝑚 − 1)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Let 𝛿 = min 𝑈 ★ 𝑔 − 𝑈 𝑔 𝑡 ★ 𝑔 − 1 , 𝑈 𝑔 𝑡 ★ 𝑔 + 1 − 𝑈 ★ 𝑔 .Since 𝑈 𝑔 is strictly increasing, we know that 𝛿 &gt; 0. From the proof of Proposition 4.8, we know that it holds almost surely that there exists 𝑐 &gt; 0 such that for any𝑚 &gt; 𝑐, 𝑈 ★ 𝑔 − 𝛿 ≥ 𝑈 𝑔 𝑡 ★ 𝑔 − 1 , 𝑈 ★ 𝑔 + 𝛿 ≤ 𝑈 𝑔 𝑡 ★𝑔 + 1 , and thus tmono</figDesc><table><row><cell></cell><cell>𝑈 𝑔</cell><cell>tmono</cell></row><row><cell>and thus tmono 𝑔</cell><cell>≥ 𝑡 ★ 𝑔 ; and</cell><cell></cell></row><row><cell></cell><cell>𝑈 𝑔</cell><cell>tmono</cell></row><row><cell>𝑔</cell><cell>≤ 𝑡 ★ 𝑔 + 1.</cell><cell>■</cell></row></table><note>𝑔 , since the proof for tunion 𝑔 is almost the same. 𝑔 &gt; 𝑔 − 1 &lt;</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The first-stage recommenders typically employ approximate algorithms to retrieve approximately top-scored items with sub-linear (in the number of items) time complexity, e.g., locality-sensitive hashing<ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b73">74]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Disadvantaged groups in this paper refer to groups of items for which the relevance estimation is inaccurate/biased, and/or we lack user feedback data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">We use[•]  to denote the set {1, 2, . . . , •}.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">We call it the relevance model interchangeably.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">We use capital letters to denote random variables and lower case letters to denote realizations of random variables.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">We use [0 : •] to denote the set {0, 1, . . . , •}.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6">Fairness in the First Stage of Two-Stage Recommender Systems</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by NSF Awards IIS-1901168 and IIS-2008139. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Estimating position bias without intrusive interventions</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unbiased learning to rank with unbiased propensity estimation</title>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keping</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Distribution-free, risk-controlling prediction sets</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Angelopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihua</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<publisher>JACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fairness in recommendation ranking through pairwise comparisons</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tulsee</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Heldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Equity of attention: Amortizing individual fairness in rankings</title>
		<author>
			<persName><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">CaS-MoS: A framework for learning candidate selection models over structured queries and documents</title>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Borisyuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnaram</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joaquin</forename><surname>Quiñonero-Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><forename type="middle">X</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elon</forename><surname>Portugaly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising</title>
				<editor>
			<persName><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Snelson</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Balanced neighborhoods for multi-sided fairness in recommendation</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasim</forename><surname>Sonboli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aldo</forename><surname>Ordonez-Gauger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In FAccT</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ranking with Fairness Constraints</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Elisa</forename><surname>Celis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damian</forename><surname>Straszak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisheeth</forename><forename type="middle">K</forename><surname>Vishnoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICALP</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimating clickthrough bias in the cascade model</title>
		<author>
			<persName><forename type="first">Praveen</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Top-k off-policy correction for a REINFORCE recommender system</title>
		<author>
			<persName><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francois</forename><surname>Belletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fair contextual multi-armed bandits: Theory and experiments</title>
		<author>
			<persName><forename type="first">Yifang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Cuellar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haipeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jignesh</forename><surname>Modi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Heramb Nemlekar, and Stefanos Nikolaidis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Tackling unconscious bias in hiring practices: The plight of the Rooney rule</title>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">W</forename><surname>Collins</surname></persName>
			<affiliation>
				<orgName type="collaboration">NYUL Rev.</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithmic decision making and the cost of fairness</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Corbett-Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Feller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharad</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aziz</forename><surname>Huq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An experimental comparison of click position-bias models</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onno</forename><surname>Zoeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Ramsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The well-calibrated Bayesian</title>
		<author>
			<persName><forename type="first">Dawid</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASA</title>
		<imprint>
			<date type="published" when="1982">1982. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluating stochastic rankings with expected exposure</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Michael D Ekstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Twosided fairness in rankings via Lorenz dominance</title>
		<author>
			<persName><forename type="first">Virginie</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Corbett-Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamal</forename><surname>Atif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Doubly Robust Policy Evaluation and Learning</title>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dudík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pixie: A system for recommending 3+ billion items to 200+ million users in real-time</title>
		<author>
			<persName><forename type="first">Chantat</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><forename type="middle">Zitao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sugnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Intervention harvesting for context-dependent examination-bias estimation</title>
		<author>
			<persName><forename type="first">Zhichong</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fairnessaware ranking in search &amp; recommendation systems with application to linkedin talent search</title>
		<author>
			<persName><forename type="first">Cem</forename><surname>Sahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Geyik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnaram</forename><surname>Ambler</surname></persName>
		</author>
		<author>
			<persName><surname>Kenthapadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Online learning with an unknown fairness metric</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Gillen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Distributionfree binary classification: prediction sets, confidence intervals and calibration</title>
		<author>
			<persName><forename type="first">Chirag</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandr</forename><surname>Podkopaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaditya</forename><surname>Ramdas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Equality of opportunity in supervised learning</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nati</forename><surname>Srebro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Practical lessons from predicting clicks on ads at facebook</title>
		<author>
			<persName><forename type="first">Xinran</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ou</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Atallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Bowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Eighth International Workshop on Data Mining for Online Advertising</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fairness of Exposure in Light of Incomplete Exposure Estimation</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Heuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fatemeh</forename><surname>Sarvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Probability Inequalities for Sums of Bounded Random Variables</title>
		<author>
			<persName><forename type="first">Wassily</forename><surname>Hoeffding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASA</title>
		<imprint>
			<date type="published" when="1963">1963. 1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A generalization of sampling without replacement from a finite universe</title>
		<author>
			<persName><forename type="first">G</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donovan</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASA</title>
		<imprint>
			<date type="published" when="1952">1952. 1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">On component interactions in two-stage recommender systems</title>
		<author>
			<persName><forename type="first">Jiri</forename><surname>Hron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Krauth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Kilbertus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbors: towards removing the curse of dimensionality</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
				<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Truncated importance sampling</title>
		<author>
			<persName><surname>Edward L Ionides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Top-K Contextual Bandits with Equity of Exposure</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Jeunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Goethals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>Recommendations as treatments. AI Magazine</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unbiased learning-to-rank with biased feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fairness in learning: Classic and contextual bandits</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><forename type="middle">H</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Balanced policy evaluation and learning</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Kallus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Candidate generation with binary codes for large-scale top-n recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unequal representation and gender stereotypes in image search results for occupations</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">A</forename><surname>Munson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HCI</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Introducing the Expohedron for Efficient Pareto-optimal Fairness-Utility Amortizations in Repeated Rankings</title>
		<author>
			<persName><forename type="first">Till</forename><surname>Kletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Michel</forename><surname>Renders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Loiseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Determinantal Point Processes for Machine Learning</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Confident off-policy evaluation and selection through self-normalized importance weighting</title>
		<author>
			<persName><forename type="first">Ilja</forename><surname>Kuzborskij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Vernade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andras</forename><surname>Gyorgy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Csaba</forename><surname>Szepesvári</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Obtaining Calibrated Probabilities with Personalized Ranking Models</title>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Off-policy learning in two-stage recommender systems</title>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Empirical Bernstein Bounds and Sample-Variance Penalization</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Towards a fair marketplace: Counterfactual evaluation of the trade-off between relevance, fairness &amp; satisfaction in recommendation systems</title>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugues</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Doubly-Robust Estimation for Unbiased Learningto-Rank from Position-Biased Click Feedback</title>
		<author>
			<persName><forename type="first">Harrie</forename><surname>Oosterhuis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.17118</idno>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Achieving Fairness in the Stochastic Multi-Armed Bandit Problem</title>
		<author>
			<persName><forename type="first">Vishakha</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ganesh</forename><surname>Ghalme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yadati</forename><surname>Narahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName><forename type="first">John</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
				<imprint>
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Introducing LETOR 4.0 Datasets</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning diverse rankings with multi-armed bandits</title>
		<author>
			<persName><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fighting fire with fire: Using antidote data to improve polarization and fairness of recommender systems</title>
		<author>
			<persName><forename type="first">Bashir</forename><surname>Rastegarpanah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Crovella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Reliable Decisions with Threshold Calibration</title>
		<author>
			<persName><forename type="first">Roshni</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alyssa</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Recommendations as treatments: Debiasing learning and evaluation</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Group fairness in Bandits with Biased Feedback</title>
		<author>
			<persName><forename type="first">Candice</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">P</forename><surname>Dickerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAMAS</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Google fined record $2.7 billion in EU antitrust ruling</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New York Times</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Fairness of exposure in rankings</title>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Cab: Continuous adaptive blending for policy evaluation and learning</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Santacatterina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Batch learning from logged bandit feedback through counterfactual risk minimization</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">The self-normalized estimator for counterfactual learning</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Cascade model-based propensity estimation for counterfactual learning to rank</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Vardasbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Markov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Algorithmic learning in a random world</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Gammerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Shafer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Fairness of exposure in stochastic bandits</title>
		<author>
			<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">User Fairness, Item Fairness, and Diversity for Rankings in Two-Sided Markets</title>
		<author>
			<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In ICTIR</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Improving Screening Processes via Calibrated Subset Selection</title>
		<author>
			<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><forename type="middle">Gomez</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Learning to rank with selection bias in personal search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Position bias estimation for unbiased learning to rank in personal search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Golbandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Optimal and adaptive off-policy evaluation in contextual bandits</title>
		<author>
			<persName><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dudık</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Tfrom: A two-sided fairness-aware recommendation model for both customers and providers</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guandong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yudong</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Beyond parity: Fairness objectives for collaborative filtering</title>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Sampling-bias-corrected neural modeling for large corpus item recommendations</title>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">Zhiyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Heldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditee</forename><surname>Kumthekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Fa* ir: A fair top-k ranking algorithm</title>
		<author>
			<persName><forename type="first">Meike</forename><surname>Zehlike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hajian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Megahed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Recommending what video to watch next: a multitask ranking system</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aniruddh</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shawn</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditee</forename><surname>Kumthekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maheswaran</forename><surname>Sathiamoorthy</surname></persName>
		</author>
		<editor>Xinyang Yi, and Ed Chi</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Learning tree-based deep model for recommender systems</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengye</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guozheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
