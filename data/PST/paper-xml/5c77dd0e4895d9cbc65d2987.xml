<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Named-Entity Recognition: Generating Gazetteers and Resolving Ambiguity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">David</forename><surname>Nadeau</surname></persName>
							<email>david.nadeau@nrc-cnrc.gc.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Information Technology National Research Council</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Information Technology and Engineering</orgName>
								<orgName type="institution">University of Ottawa</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
							<email>peter.turney@nrc-cnrc.gc.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Information Technology National Research Council</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stan</forename><surname>Matwin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Information Technology and Engineering</orgName>
								<orgName type="institution">University of Ottawa</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute for Computer Science</orgName>
								<orgName type="institution">Polish Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Named-Entity Recognition: Generating Gazetteers and Resolving Ambiguity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AF8EE6F5F53F893741836AF99EA154D2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a named-entity recognition (NER) system that addresses two major limitations frequently discussed in the field. First, the system requires no human intervention such as manually labeling training data or creating gazetteers. Second, the system can handle more than the three classical named-entity types (person, location, and organization). We describe the system's architecture and compare its performance with a supervised system. We experimentally evaluate the system on a standard corpus, with the three classical named-entity types, and also on a new corpus, with a new named-entity type (car brands).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper builds on past work in unsupervised named-entity recognition (NER) by Collins and Singer <ref type="bibr" target="#b2">[3]</ref> and Etzioni et al. <ref type="bibr" target="#b3">[4]</ref>. Our goal is to create a system that can recognize named-entities in a given document without prior training (supervised learning) or manually constructed gazetteers. (We use the term gazetteer interchangeably with the term named-entity list.)</p><p>Collins and Singer's <ref type="bibr" target="#b2">[3]</ref> system exploits a large corpus to create a generic list of proper names (named-entities of arbitrary and unknown types). Proper names are collected by looking for syntactic patterns with precise properties. For instance, a proper name is a sequence of consecutive words, within a noun phrase, that are tagged as NNP or NNPS by a part-of-speech tagger and in which the last word is identified as the head of the noun phrase. Like Collins and Singer, we use a large corpus to create lists of named-entities, but we present a technique that can exploit diverse types of text, including text without proper grammatical sentences, such as tables and lists (marked up with HTML).</p><p>Etzioni et al. <ref type="bibr" target="#b3">[4]</ref> refer to their algorithm as a named-entity extraction system. It is not intended for named-entity recognition. In other words, it is used to create large lists of named-entities, but it is not designed for resolving ambiguity in a given document. The distinction between these tasks is important. It might seem that having a list of entities in hand makes NER trivial. One can extract city names from a given document by merely searching in the document for each city name in a city list. However, this strategy often fails because of ambiguity. For example, consider the words "It" (a city in Mississippi State and a pronoun) and "Jobs" (a person's surname and a common noun). The task addressed by Etzioni et al. could be called automatic gazetteer generation. Without ambiguity resolution, their system cannot perform robust, accurate NER. This claim is supported by the experiments we present in Section 3.</p><p>In this paper, we propose a named-entity recognition system that combines namedentity extraction (inspired by Etzioni et al. <ref type="bibr" target="#b3">[4]</ref>) with a simple form of named-entity disambiguation. We use some simple yet highly effective heuristics, based on the work of Mikheev <ref type="bibr" target="#b8">[9]</ref>, Petasis et al. <ref type="bibr" target="#b12">[13]</ref>, and Palmer and Day <ref type="bibr" target="#b11">[12]</ref>, to perform named-entity disambiguation. We compare the performance of our unsupervised system with that of a basic supervised system, using the MUC 7 NER corpus <ref type="bibr" target="#b0">[1]</ref>. We also show that our technique is general enough to be applied to other named-entity types, such as car brands, or bridge names. To support this claim, we include an experiment with car brands.</p><p>The paper is divided as follows. First, we present the system architecture in Section 2. Then, we compare its performance with a supervised baseline system on the MUC 7 NER corpus in Section 3. Next, we show that the system can handle other type of entities, in addition to the classic three (person, location, and organization), in Section 4. We discuss the degree of supervision in Section 5. We conclude in Section 6 by arguing that our system advances the state-of-the-art of NER by avoiding the need for supervision and by handling novel types of named-entities. The system's source code is available under the GPL license at http://balie.sourceforge.net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Unsupervised Named-Entity Recognition System</head><p>The system is made of two modules. The first one is used to create large gazetteers of entities, such as a list of cities. The second module uses simple heuristics to identify and classify entities in the context of a given document (i.e., entity disambiguation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Generating Gazetteers</head><p>The task of automatically generating lists of entities has been investigated by several researchers. In Hearst <ref type="bibr" target="#b5">[6]</ref>, lexical patterns are studied that can be used to identify nouns from the same semantic class. For instance, a noun phrase that follows the pattern "the city of" is usually a city. In Riloff and Jones <ref type="bibr" target="#b13">[14]</ref>, a small set of lexical patterns and a small set of entities are grown using mutual bootstrapping. Finally, Lin and Pantel <ref type="bibr" target="#b6">[7]</ref> show how to create large clusters of semantically related words using an unsupervised technique. Their idea is based on examining words with similar syntactic dependency relationships. They show they can induce semantic classes such as car brands, drugs, and provinces. However, their technique does not discover the labels of the semantic classes, which is a common limitation of clustering techniques.</p><p>The algorithm of Etzioni et al. <ref type="bibr" target="#b3">[4]</ref> outperforms all previous methods for the task of creating a large list for a given type of entity or semantic class; the task of automatic gazetteer generation. Nadeau <ref type="bibr" target="#b10">[11]</ref> shows that it is possible to create accurate lists of cities and car brands in an unsupervised manner, limiting the supervision to a seed of four examples. In the remainder of this section, we summarize how to generate a list of thousands of cities from a seed of a few examples, in two steps (repeated if necessary).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Retrieve Pages with Seed</head><p>The first step is information retrieval from the Web. A query is created by conjoining a seed of k manually generated entities (e.g., "Montreal" AND "Boston" AND "Paris" AND "Mexico City"). In our experience, when k is set to 4 (as suggested by Etzioni et al. <ref type="bibr" target="#b3">[4]</ref>) and the seed entities are common city names, the query typically retrieves Web pages that contain many names of cities, in addition to the seed names. The basic idea of the algorithm is to extract these additional city names from each retrieved Web page.</p><p>The same strategy can be applied to person names, company names, car brands, and many other types of entities. Although it is outside of the scope of this paper, we should mention that we successfully applied this technique to more than 50 named-entity types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Apply Web Page Wrapper</head><p>A Web page wrapper is a rule-based system that identifies the location of specific types of information within a Web page. For example, a wrapper for identifying the location of news headers on the Web site radio-canada.ca might contain the rule, "A header is an HTML node of type &lt;a&gt;, with text length between 10 and 30 characters, in a table of depth 5 and with at least 3 other nodes in the page that satisfy the same rule."</p><p>The gazetteer generation algorithm proceeds by learning rules that identify the locations of positive examples. For each page found in 2.1.1, a Web page wrapper is trained on the k positive examples that are known to appear in the page, but only if they are strictly contained in an HTML node (e.g., &lt;td&gt; Boston &lt;/td&gt;) or surrounded by a small amount of text inside an HTML node (e.g., &lt;td&gt; Boston hotel &lt;/td&gt;). The remaining HTML nodes in the page are treated as if they were negative examples, but we only include in the negative set the nodes with the same HTML tags as the positive examples <ref type="bibr" target="#b10">[11]</ref>. For instance, if the k positive nodes are tagged as bold (i.e., "&lt;b&gt;"), then the negative examples will be restricted to the remaining bold text in the Web page. The Web page wrapper we used is similar to Cohen and Fan's <ref type="bibr" target="#b1">[2]</ref> wrapper, in terms of the learning algorithm and the feature vector.</p><p>As described above, Web page wrapping is a classification problem. A supervised learning algorithm is used to classify unknown entities in the current Web page. In this application, the training set and the testing set are the same. The learning algorithm is trained on the given Web page and then the learned model is applied to reclassify the text in the same Web page. The idea is to learn rules, during training, that identify the locations of the known entities (the seed entities) and can be applied, during testing, to identify entities appearing in similar contexts, which may be further positive examples.</p><p>Two main problems make this task difficult. First, there is noise in the class labels in the training data, because everything except the seed words are initially labeled as negative. If the page contains more than k entities of the desired type, the very nodes we want to extract were labeled as negative. The second problem is the class imbalance in the data. Along with the k positive examples, there are usually hundreds or thousands of negative examples. These two problems are handled by noise filtering and cost-sensitive classification, respectively.</p><p>At this point, our technique goes beyond the system of Etzioni et al. <ref type="bibr" target="#b3">[4]</ref>, which uses a simple Web page wrapper, consisting of hand-crafted rules. To handle the problem of noise in the class labels, we use a filtering approach inspired by Zhu et al. <ref type="bibr" target="#b15">[16]</ref>. The noise filtering strategy is to simply remove any instance similar to a positive instance. We say that two nodes are similar when their feature vectors are identical, except for the text length feature. (Refer to Cohen and Fan <ref type="bibr" target="#b1">[2]</ref> for a description of the Web page wrapper's features.) Using this filter, an average of 42% of the examples that are initially labeled as negative are removed from the training set. These examples are left in the (unlabeled) testing set. When the trained model is later applied to the testing set, some of the removed examples may be classified as positive and some may be classified as negative.</p><p>To handle the class imbalance problem, we use a cost-sensitive supervised learning system. Using the original unbalanced dataset, the wrapper is almost incapable of extracting new entities. It mainly guesses the majority class (negative) and only extracts the initial seed from Web pages. To discourage the learning algorithm from using the trivial solution of always guessing the majority class, a high cost is assigned to misclassification errors in which a positive example is classified as negative. This costsensitive approach over-samples the positive examples to rebalance the dataset. This rebalancing must be done for each individual Web page, to take into account the imbalance ratio of each wrapper. Rebalancing is performed automatically, by randomly choosing HTML nodes to add to the dataset, up to the desired ratio of positive to negative examples.</p><p>Past research suggests that supervised learning algorithms work best when the ratio is near 1:1 <ref type="bibr" target="#b7">[8]</ref>. We hypothesized that the wrapper would work best when we rebalanced the dataset by duplicating positive instances until the ratio reached 1:1. To verify this hypothesis, we studied the behavior of the wrapper with different ratios on a set of 40 Web pages. As expected, we found that the wrapper performance is optimal when the ratio is 1:1. We therefore use this ratio in the experiments in Sections 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Repeat</head><p>The two steps above (2.2.1, 2.2.2) are repeated as needed. Each iteration brings new entities that are added to the final gazetteer. At each iteration, k new randomly chosen entities are used to refresh the seed for the system. Entities are chosen from the gazetteer under construction. Preference is given to seed entities that are less likely to be noise, such as those appearing in multiple Web pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Resolving Ambiguity</head><p>The list lookup strategy is the method of performing NER by scanning through a given input document, looking for terms that match a list entry. The list lookup strategy suffers from three main problems: (1) entity-noun ambiguity errors, (2) entity boundary detection errors, and (3) entity-entity ambiguity errors. Due to these three problems, the gazetteer generating module presented in Section 2.1 is not adequate, by itself, for reliable namedentity recognition. We found heuristics in the literature to tackle each of these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Entity-Noun Ambiguity</head><p>Entity-noun ambiguity occurs when an entity is the homograph of a noun. The plural word "jobs" and the surname "Jobs" is an example of this problem. To avoid this problem, Mikheev <ref type="bibr" target="#b8">[9]</ref> proposes the following heuristic: In a given document, assume that a word or phrase with initial capitals (e.g., "Jobs") is a named-entity, unless (1) it sometimes appears in the document without initial capitals (e.g., "jobs"), ( <ref type="formula">2</ref>) it only appears at the start of a sentence or at the start of a quotation (e.g., "Jobs that pay well are often boring."), or (3) it only appears inside a sentence in which all words with more than three characters start with a capital letter (e.g., a title or section heading).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Entity Boundary Detection</head><p>A common problem with the list lookup strategy is errors in recognizing where a namedentity begins and ends in a document (e.g., finding only "Boston" in "Boston White Sox"). This can happen when a named-entity is composed of two or more words (e.g., "Jean Smith") that are each listed separately (e.g., "Jean" as a first name and "Smith" as a last name). It can also happen when an entity is surrounded by unknown capitalized words (e.g., "New York Times" as an organization followed by "News Service" as an unlisted string). Palmer and Day <ref type="bibr" target="#b11">[12]</ref> propose the longest match strategy for these cases. Accordingly, we merge all consecutive entities of the same type and every entity with any adjacent capitalized words. We did not, however, merge consecutive entities of different types, since we would not have known the resulting type.</p><p>The rule above is general enough to be applied independently of the entity type. We found that other merging rules could improve the precision of our system, such as "create a new entity of type organization by merging a location followed by an organization". However, we avoided rules like this, because we believe that this type of manual rule engineering results in brittle, fragile systems that do not generalize well to new data. Our goal is to make a robust, portable, general-purpose NER system, with minimal embedded domain knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Entity-Entity Ambiguity</head><p>Entity-entity ambiguity occurs when the string standing for a named-entity belongs to more than one type. For instance, if a document contains the named-entity "France", it could be either the name of a person or the name of a country. For this problem, Petasis et al. <ref type="bibr" target="#b12">[13]</ref>, among others, propose that at least one occurrence of the named-entity should appear in a context where the correct type is clearly evident. For example, in the context "Dr. France", it is clear that "France" is the name of a person.</p><p>We could have used cues, such as professional titles (e.g., farmer), organizational designators (e.g., Corp.), personal prefixes (e.g., Mr.) and personal suffixes (e.g., Jr.), but as discussed in the preceding section, we avoided this kind of manual rule engineering. and the strings i s and j s share at least one word with more than three characters; returns false otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm:</head><p>Let {} = A . For each instance of a named-entity e in document D :</p><p>If there is exactly one alias set i a with a member j e such that a , consisting of } {e , and add q a to A .</p><p>set is unambiguous, it can be used to resolve the whole set. For instance, "Atlantic ocean" is clearly a location but "Atlantic" can be either a location or an organization. If both belong to the same alias set, then we assume that the whole set is of type location. A second way to use the alias resolution is to include unknown words in the model. Unknown words are typically introduced by the heuristic in Section 2.2.2. If an entity (e.g., "Steve Hill") is formed from a known entity (e.g., "Steve") and an unknown word (e.g., "Hill"), we allow occurrences of this unknown word to be added in the alias group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation with the MUC-7 Enamex Corpus</head><p>In the Message Understanding Conferences (MUC), the Named-Entity Recognition (NER) track focuses on the three classical types of named-entities: person, location, and organization. These three types of named-entities are collectively called Enamex. In this section, we compare the performance of our system with a baseline supervised system, using the Enamex corpus from MUC-7. For this experiment, a portion of the corpus is given to the supervised system in order to train it. Our unsupervised system simply ignores this portion of corpus. The same baseline experiment was conducted on MUC-6 and MUC-7 by Palmer and Day <ref type="bibr" target="#b11">[12]</ref> and Mikheev et al. <ref type="bibr" target="#b9">[10]</ref> respectively. Their systems work as follows. A training corpus is read and the tagged entities are extracted and listed. Given a testing corpus, the lists are used in a simple lookup strategy, so that any string that matches a list entry is classified accordingly.</p><p>Table <ref type="table" target="#tab_1">1</ref> presents the results of Mikheev on MUC-7 (in the "Learned lists" columns). There is also a comparison with a system that uses hand-made lists of common entities (in the "Common lists" columns). The "Combined lists" columns are based on a combination of both approaches. These results are from Mikheev's published experiments <ref type="bibr" target="#b9">[10]</ref>.</p><p>In Table <ref type="table" target="#tab_1">1</ref>, "re" is the recall, "pr" is the precision, and "f" is the f-measure (the harmonic mean of precision and recall), expressed as percentages. For the purpose of comparison, we ran our system on MUC-7 using gazetteers that we generated as described in Section 2.1. We generated gazetteers for some of the subtypes of named-entities given by Sekine <ref type="bibr" target="#b14">[15]</ref>. The generated gazetteers are described in Table <ref type="table" target="#tab_2">2</ref>. We also used a special list of the months of the year, because we noticed they were an abnormally important source of noise on the development (dry run) set. <ref type="foot" target="#foot_0">1</ref> Many months are also valid as personal first names. List size depends on the performance of the Web page wrapper at extracting entities. Nadeau <ref type="bibr" target="#b10">[11]</ref> showed that lists have a precision of at least 90%. We did not restrict the web mining to a specific geographic region and we did not enforce strict conditions for the list elements. As a result, the "state / province" list contains elements from around the world (not only Canada and the U.S.) and the "first name" list contains a multitude of compound first names, although our algorithm is designed to capture them by merging sequences of first names, as explained in Section 2.2.2.</p><p>Table <ref type="table" target="#tab_3">3</ref> shows the result of a pure list lookup strategy, based on our generated gazetteers (in the "Generated lists" columns). For comparison, Table <ref type="table" target="#tab_3">3</ref> also shows the best supervised results from Table <ref type="table" target="#tab_1">1</ref> (in the "Mikheev combined lists" columns). The results we report in Tables <ref type="table" target="#tab_1">1,</ref><ref type="table" target="#tab_3">3</ref>, 4, and 5 are all based on the held-out formal corpus of MUC-7. We believe the comparison in Table <ref type="table" target="#tab_3">3</ref> gives a good sense of the characteristics of both approaches. The supervised approach is quite precise but its recall is lower, since it cannot handle rare entities. The unsupervised approach benefits from large gazetteers, which enable higher recall at the cost of lower precision.</p><p>The case of locations is interesting. There is evidence that there is a substantial vocabulary transfer between the training data and the testing data, which allows the supervised method to have an excellent recall on the unseen texts. Mikheev's lists get a high recall with a list of only 770 locations. The supervised method benefits from highly repetitive location names in the MUC corpus.</p><p>These results are slightly misleading. The MUC scoring software that produces these measures allows partial matching. That means, if a system tags the expression "Virgin Atlantic" when the official annotated key is "Virgin Atlantic Group", it will be credited with a success. In Table <ref type="table" target="#tab_4">4</ref>, we provide another view of the system's performance, which may be less misleading. Table <ref type="table" target="#tab_4">4</ref> gives, for our system, the precision and recall of all entity types at the level of text; that is, the performance on finding exact string matches. The next step in our evaluation consists in adding the heuristics presented in Sections 2.2.1 to 2.2.3. These heuristics are designed to be unsupervised; that is, they require no training (unlike n-gram contexts, for example) and they are not deduced from our domain knowledge about a specific entity type. Table <ref type="table" target="#tab_5">5</ref> shows the contribution of each heuristic. The "Generated lists" columns are copied from Tables <ref type="table" target="#tab_3">3</ref> and<ref type="table" target="#tab_4">4</ref>, to show the performance of the list lookup strategy without disambiguation (i.e., Section 2.1 without Section 2.2). The contribution of each heuristic (H1, H2, H3) is additive. H1 (Section 2.2.1) procures a dramatic improvement in precision with negligible loss of recall. The main source of ambiguity is entity-noun homographs such as "jobs", "gates", and "bush". Heuristic H2 (Section 2.2.2) gives small gains in precision and recall of individual entity types (the first three rows in Table <ref type="table" target="#tab_5">5</ref>). As explained, these scores are misleading because they count partial matches and thus these scores are not sensitive to the boundary detection errors that are corrected by H2. However, the performance of text matching is greatly improved (last row in Table <ref type="table" target="#tab_5">5</ref>). We noticed that most corrected boundaries are attributable to person entities composed of a known first name and an unlisted capitalized string standing, presumably, for the surname.</p><p>H3 (Section 2.2.3) mainly increases precision and recall for named-entities of the person type, due to the the alias resolution algorithm. An occurence of a full person name is usually unambiguous and thus can help with annotating isolated surnames, which are often either ambiguous (confused with organization names) or simply unlisted strings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation with Car Brands</head><p>There are many more types of named-entities than the three classical types in Enamex. Sekine et al. <ref type="bibr" target="#b14">[15]</ref> propose a hierarchy of 200 types of named-entities. Evans <ref type="bibr" target="#b4">[5]</ref> proposes a framework to handle such wide variety. His approach is based on lexical patterns, inspired by Hearst <ref type="bibr" target="#b5">[6]</ref>. He paired this technique with a heuristic for handling ambiguity in capitalized words. Our system is similar, but it is based on a method proven to give better recall at finding entities <ref type="bibr" target="#b3">[4]</ref>.</p><p>In this section, we show how the system performs on the task of recognizing car brands. Intuitively, it seems that this type is easier to handle than a type such as persons that has an almost infinite extension. However, recognizing car brands poses many difficulties. Car brands can be confused with common nouns (e.g., Focus, Rendez-Vous, Matrix, Aviator) and with company names (e.g., "Ford" versus "Ford Motor Company"). Another difficulty is the fact that new car brands are created every year, so keeping a gazetteer of car brands up-to-date is challenging.</p><p>We created a small pilot corpus composed of news specifically about cars from some popular news feeds (CanWest, National Post, and The Associated Press). We use eight documents, for a total of 5,570 words and 196 occurrences of car brands.</p><p>The Web-page wrapper technique was used to generate a list of 5,701 car brands and the heuristics of sections 2.2.1 to 2.2.3 were applied without any modifications. Table <ref type="table" target="#tab_6">6</ref> reports the results. The performance on this task is comparable to the Enamex task. Without ambiguity resolution (in the "Generated list" columns), the precision is low, typically under 50%. This is the impact of frequent and ambiguous words like "will" (Toyota Will) and noise in our list (e.g., new, car, fuel). The ambiguity resolution algorithms (in the "H1, H2, and H3" columns) raise the precision above 80%. The remaining recall errors are due to rare car brands (e.g., "BMW X5 4.8is" or "Ford Edge"). The remaining precision errors are due to organization-car ambiguity (e.g., "National" as in "National Post" versus "Chevrolet National") and noise in the list (e.g., Other, SUV). We believe that the good performance of gazetteer generation combined with ambiguity resolution on an entirely new domain emphasizes their domain-independent character and shows the strength of the unsupervised approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Supervised versus Unsupervised</head><p>We describe our system as unsupervised, but the distinction between supervised and unsupervised systems is not always clear. In some systems that are apparently unsupervised, it could be argued that the human labour of generating labeled training data has merely been shifted to embedding clever rules and heuristics in the system.</p><p>In our gazetteer generator (Section 2.1), the supervision is limited to a seed of four entities per list Less than four examples results in lower precision and more than four examples results in lower recall <ref type="bibr" target="#b3">[4]</ref>. In our ambiguity resolver (Section 2.2), we attempt to minimize the use of domain knowledge of specific entity types. Our system exploits human-generated HTML markup in Web pages to generate gazetteers. However, because Web pages are available in such a quantity and because the creation of Web pages is now intrinsic to the workflow of most organization and individuals, we believe this annotated data comes at a negligible cost. For these reasons, we believe it is reasonable to describe our system as unsupervised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we presented a named-entity recognition system that advances the state-ofthe-art of NER by avoiding the need for supervision and by handling novel types of named-entities. In a comparison on the MUC corpus, our system outperforms a baseline supervised system but it is still not competitive with more complex supervised systems. There are (fortunately) many ways to improve our model. One interesting way would be to generate gazetteers for a multitude of named-entity types (e.g., all 200 of Sekine's types) and use list intersection as an indicator of ambiguity. This idea would not resolve the ambiguity itself but would clearly identify where to invest further efforts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Simple alias resolution algorithmInstead, we applied a simple alias resolution algorithm, presented in Figure1. When an ambiguous entity is found, its aliases are used in two ways. First, if a member of an alias</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Results of a supervised system on MUC-7</figDesc><table><row><cell></cell><cell cols="3">Learned lists</cell><cell cols="3">Common lists</cell><cell cols="3">Combined lists</cell></row><row><cell></cell><cell>re</cell><cell>Pr</cell><cell>f</cell><cell>re</cell><cell>pr</cell><cell>f</cell><cell>re</cell><cell>pr</cell><cell>f</cell></row><row><cell cols="2">organization 49</cell><cell>75</cell><cell>59</cell><cell>3</cell><cell>51</cell><cell>6</cell><cell>50</cell><cell>72</cell><cell>59</cell></row><row><cell>person</cell><cell>26</cell><cell>92</cell><cell>41</cell><cell>31</cell><cell>81</cell><cell>45</cell><cell>47</cell><cell>85</cell><cell>61</cell></row><row><cell>location</cell><cell>76</cell><cell>93</cell><cell>84</cell><cell>74</cell><cell>94</cell><cell>83</cell><cell>86</cell><cell>90</cell><cell>88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Type and size of gazetteers built using Web page wrapper</figDesc><table><row><cell>Gazetteer</cell><cell>Size</cell></row><row><cell>Location: city</cell><cell>14,977</cell></row><row><cell>Location: state / province</cell><cell>1,587</cell></row><row><cell>Location: continent / country / island</cell><cell>781</cell></row><row><cell>Location: waterform</cell><cell>541</cell></row><row><cell>Location: astral body</cell><cell>85</cell></row><row><cell>Organization: private companies</cell><cell>20,498</cell></row><row><cell>Organization: public services</cell><cell>364</cell></row><row><cell>Organization: schools</cell><cell>3,387</cell></row><row><cell>Person: first names</cell><cell>35,102</cell></row><row><cell>Person: last names</cell><cell>3,175</cell></row><row><cell>Person: full names</cell><cell>3,791</cell></row><row><cell>Counter-examples: months</cell><cell>12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Supervised list creation vs. unsupervised list creation techniques</figDesc><table><row><cell></cell><cell cols="3">Mikheev combined lists</cell><cell></cell><cell>Generated lists</cell><cell></cell></row><row><cell></cell><cell>Re</cell><cell>pr</cell><cell>f</cell><cell>re</cell><cell>pr</cell><cell>f</cell></row><row><cell>organization</cell><cell>50</cell><cell>72</cell><cell>59</cell><cell>70</cell><cell>52</cell><cell>60</cell></row><row><cell>person</cell><cell>47</cell><cell>85</cell><cell>61</cell><cell>59</cell><cell>20</cell><cell>30</cell></row><row><cell>location</cell><cell>86</cell><cell>90</cell><cell>88</cell><cell>83</cell><cell>31</cell><cell>45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Generated list performance on text matching</figDesc><table><row><cell></cell><cell></cell><cell>Generated lists</cell><cell></cell></row><row><cell></cell><cell>re</cell><cell>pr</cell><cell>f</cell></row><row><cell>text</cell><cell>61</cell><cell>29</cell><cell>39</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Performance of heuristics to resolve named-entity ambiguity</figDesc><table><row><cell></cell><cell></cell><cell cols="3">H1 (Entity-noun</cell><cell cols="2">H1 + H2 (Entity</cell><cell cols="3">H1 + H2 + H3</cell></row><row><cell cols="2">Generated lists</cell><cell cols="2">ambiguity)</cell><cell></cell><cell>boundary)</cell><cell></cell><cell cols="3">(Entity-entity</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ambiguity)</cell><cell></cell></row><row><cell>re pr</cell><cell>f</cell><cell>re</cell><cell>pr</cell><cell>f</cell><cell>re pr</cell><cell>f</cell><cell>re</cell><cell>pr</cell><cell>f</cell></row><row><cell cols="2">org. 70 52 60</cell><cell>69</cell><cell>73</cell><cell>71</cell><cell cols="2">69 74 71</cell><cell>71</cell><cell>75</cell><cell>73</cell></row><row><cell cols="2">per. 59 20 30</cell><cell>58</cell><cell>53</cell><cell>55</cell><cell cols="2">66 63 64</cell><cell>83</cell><cell>71</cell><cell>77</cell></row><row><cell cols="2">loc. 83 31 45</cell><cell>82</cell><cell>69</cell><cell>75</cell><cell cols="2">81 77 79</cell><cell>80</cell><cell>77</cell><cell>78</cell></row><row><cell cols="2">text 61 29 39</cell><cell>61</cell><cell>57</cell><cell>59</cell><cell cols="2">72 72 72</cell><cell>74</cell><cell>72</cell><cell>73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>System performance for car brand recognition</figDesc><table><row><cell></cell><cell cols="2">Generated list</cell><cell></cell><cell></cell><cell>H1, H2 and H3</cell><cell></cell></row><row><cell></cell><cell>Re</cell><cell>pr</cell><cell>f</cell><cell>re</cell><cell>pr</cell><cell>f</cell></row><row><cell>cars</cell><cell>86</cell><cell>42</cell><cell>56</cell><cell>85</cell><cell>88</cell><cell>86</cell></row><row><cell>text</cell><cell>71</cell><cell>34</cell><cell>46</cell><cell>79</cell><cell>83</cell><cell>81</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>It can be argued that the month list is a form of manual rule engineering, contrary to the principles discussed in Section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2.2.2. We decided to use it because most of the noise was clearly corpusdependent, since each article contains a date header. For results without the month list, subtract 5% from the precision for the person type.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Caroline Barrière, who provided us with helpful comments on an earlier version of this work. Support of the Natural Sciences and Engineering Research Council and of the Communications and Information Technology division of the Ontario Centres of Excellence is gratefully acknowledged.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MUC-7 Named Entity Task Definition, version 3.5</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chinchor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Seventh Message Understanding Conference</title>
		<meeting>of the Seventh Message Understanding Conference</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning Page-Independent Heuristics for Extracting Data from Web Page</title>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International World Wide Web Conference</title>
		<meeting>of the International World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised Models for Named Entity Classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<meeting>of the Joint SIGDAT Conference on Empirical Methods in Natural Language essing and Very Large Corpora</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised Named-Entity Extraction from the Web: An Experimental Study</title>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-M</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="91" to="134" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Framework for Named Entity Recognition in the Open Domain</title>
		<author>
			<persName><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Recent Advances in Natural Language Processing</title>
		<meeting>Recent Advances in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic Acquisition of Hyponyms from Large Text Corpora</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Computational Linguistics</title>
		<meeting>of International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Induction of Semantic Classes from Natural Language Text</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>of ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Data Mining for Direct Marketing: Problems and Solutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Knowledge-free Method for Capitalized Word Disambiguation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mikheev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference of</title>
		<meeting>Conference of</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Named Entity Recognition without Gazetteers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mikheev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference of European Chapter</title>
		<meeting>Conference of European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Création de surcouche de documents hypertextes et traitement du langage naturel</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nadeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. Computational Linguistics in the North-East</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Statistical Profile of the Named Entity Task</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Day</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL Conference for Applied Natural Language Processing</title>
		<meeting>ACL Conference for Applied Natural Language essing</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using Machine Learning to Maintain Rule-based Named-Entity Recognition and Classification Systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Petasis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vichot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wolinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karkaletsis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Spyropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference of</title>
		<meeting>Conference of</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning Dictionaries for Information Extraction using Multilevel Bootstrapping</title>
		<author>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of National Conference on Artificial Intelligence</title>
		<meeting>of National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Extended Named Entity Hierarchy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nobata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Language Resource and Evaluation Conference</title>
		<meeting>of the Language Resource and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Eliminating Class Noise in Large Data-Sets</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning</title>
		<meeting>of the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
