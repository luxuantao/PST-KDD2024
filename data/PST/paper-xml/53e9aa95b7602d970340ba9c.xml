<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Hardware Gaussian Noise Generator Using the Wallace Method</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Dong-U</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Wayne</forename><surname>Luk</surname></persName>
							<email>w.luk@imperial.ac.uk</email>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">John</forename><forename type="middle">D</forename><surname>Villasenor</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Guanglie</forename><surname>Zhang</surname></persName>
							<email>glzhang@cse.cuhk.edu.hk</email>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Philip</forename><forename type="middle">H W</forename><surname>Leong</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">partment</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<postCode>90024</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>2SW 2BT</postCode>
									<settlement>London</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Electrical Engineering Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90024</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Sci-ence and Engineering</orgName>
								<orgName type="institution">Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Hardware Gaussian Noise Generator Using the Wallace Method</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">808CF0EE5C45C88136984B876D994F45</idno>
					<idno type="DOI">10.1109/TVLSI.2005.853615</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Channel coding</term>
					<term>communication channels</term>
					<term>field-programmable gate arrays (FPGAs)</term>
					<term>Gaussian noise</term>
					<term>highperformance</term>
					<term>Monte Carlo methods</term>
					<term>reconfigurable-computing</term>
					<term>technology-mapping</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a hardware Gaussian noise generator based on the Wallace method used for a hardware simulation system. Our noise generator accurately models a true Gaussian probability density function even at high values. We evaluate its properties using: 1) several different statistical tests, including the chi-square test and the Anderson-Darling test and 2) an application for decoding of low-density parity-check (LDPC) codes. Our design is implemented on a Xilinx Virtex-II XC2V4000-6 field-programmable gate array (FPGA) at 155 MHz; it takes up 3% of the device and produces 155 million samples per second, which is three times faster than a 2.6-GHz Pentium-IV PC. Another implementation on a Xilinx Spartan-III XC3S200E-5 FPGA at 106 MHz is two times faster than the software version. Further improvement in performance can be obtained by concurrent execution: 20 parallel instances of the noise generator on an XC2V4000-6 FPGA at 115 MHz can run 51 times faster than software on a 2.6-GHz Pentium-IV PC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE AVAILABILITY of high quality Gaussian random numbers is critical to many simulation, graphics and Monte Carlo applications. Currently, the majority of such simulations are performed using systems based on microprocessors, digital signal processors, or other software-programmable devices. In these systems, the trigonometric, exponential, and other functions involved in many of the methods for obtaining Gaussian random variables can be performed using software libraries <ref type="bibr" target="#b0">[1]</ref>. As a result, not much research has been reported concerning efficient hardware methods for implementation of Gaussian noise generators. However, well-optimized hardware implementations can often operate one or more orders of magnitude faster than similarly optimized software implementations. Recent advances in field-programmable gate array (FPGA) technology have substantially improved performance and cost effectiveness of hardware implementations, and they provide a strong motivation for us to reexamine the issue of Gaussian noise generation in hardware.</p><p>The work described here is originally motivated by ongoing advances in communications relating to channel codes <ref type="bibr" target="#b1">[2]</ref>, and in particular by the development of new generations of channel codes that operate on very long (thousands to tens of thousands of bits each) blocks of data. For these codes, it is often desirable to perform simulations of extremely large numbers of blocks in order to assess the bit-error rate (BER) performance at rates as low as 10 .</p><p>There are many other applications in which very large simulations using Gaussian noise are valuable as well. These include financial modeling <ref type="bibr" target="#b2">[3]</ref>, simulation of economic systems <ref type="bibr" target="#b3">[4]</ref>, and molecular dynamics simulations <ref type="bibr" target="#b4">[5]</ref>. For all of these applications, hardware-based simulation offers the potential to speed up simulation by several orders of magnitude, but is feasible only if suitably fast and high-quality noise generators can be implemented. In principle, one could generate the noise samples on a PC and transfer them to the hardware device performing the simulation. However in such approaches, generation of the noise samples is often the performance bottleneck. Hence, it is desirable to have a hardware noise generator. On-chip noise generation is significantly faster and does not suffer from transfer overheads.</p><p>In addition, since deviation from an ideal Gaussian probability density function (pdf) can degrade simulation results, very large simulations have stringent requirements on the quality of the pdf in the tails. Samples that lie at large multiples of (standard deviation) away from the mean are rare, but they are also exactly the noise realizations that are most likely to induce events of high interest in understanding the behavior of the overall system. To accurately obtain good characteristics in the tails requires the combination of: 1) an underlying method that creates high values with the proper frequency and 2) a hardware implementation of the method that preserves the requisite precision at all stages to ensure that high behavior is not compromised.</p><p>The principal contribution of this paper is a hardware Gaussian noise generator based on the Wallace method <ref type="bibr" target="#b5">[6]</ref> that offers quality suitable for simulations involving very large numbers of noise samples. The noise generator occupies approximately 3% of the resources of a Xilinx Virtex-II XC2V4000-6 FPGA device, while producing over 155 million samples per second. The key contributions of our work include:</p><p>• a hardware architecture for the Wallace method;</p><p>• exploration of hardware implementations of the proposed architecture targeting both advanced high-speed FPGAs and low-cost FPGAs; • evaluation of the proposed approach using several different statistical tests, including the chi-square test and the Anderson-Darling (A-D) test, as well as through application to a large communications simulation involving low-density parity-check (LDPC) channel codes <ref type="bibr" target="#b6">[7]</ref>. The rest of this paper is organized as follows. Section II covers background material and previous work. Section III provides an overview of the Wallace method. Section IV describes our Wallace architecture, and discusses how each of its steps can be handled in a hardware implementation. Section V describes technology-specific implementation of the hardware architecture. Section VI discusses evaluation and results, and Section VII offers conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>Most methods for generating random Gaussian variables are based on transformations or operations on uniform random variables. Widely used methods include various rejection-acceptance methods <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>, the use of the central limit theorem <ref type="bibr" target="#b10">[11]</ref>, the inversion method <ref type="bibr" target="#b11">[12]</ref> and the Box-Muller method <ref type="bibr" target="#b12">[13]</ref>. While there are many software implementations of these methods, there is little previous work on digital hardware Gaussian noise generation.</p><p>The rejection-acceptance methods are popular in software approaches. However, they contain conditional loops such that the output rates are not constant, which is undesirable in a hardware simulation environment. While in principle the central limit theorem can be used to produce Gaussian samples if a suitable number of samples are involved, in practice an impractically large number of samples would be required to achieve an accurate representation of the ideal Gaussian pdf.</p><p>The Box-Muller method, either alone or in combination with the central limit theorem, has been the focus of most efforts in hardware implementation. For example, Boutillon et al. <ref type="bibr" target="#b13">[14]</ref> present a hardware Gaussian noise generator based on the Box-Muller algorithm in conjunction with the central limit theorem. Their design occupies 437 logic cells on an Altera Flex 10K100EQC240-1 FPGA, and outputs 24.5 million noise samples per second at a clock speed of 98 MHz. Recently, the "Additive White Gaussian Noise (AWGN) Core 1.0" <ref type="bibr" target="#b14">[15]</ref> has been released by Xilinx, which is based on the Boutillion et al. architecture.</p><p>Chen et al. <ref type="bibr" target="#b15">[16]</ref> use a cummulative distribution function (cdf) conversion table to transform uniform random variables to Gaussian random variables. They have implemented the Gaussian noise generator as part of a readback-signal generator on a Xilinx Virtex-E XCV1000E FPGA at 70 MHz. The method they employ is basically the inversion method <ref type="bibr" target="#b11">[12]</ref> implemented with a look-up table. However, the number of table entries are insufficient. To produce high quality noise samples with their direct table look-up approach, one would lead to an impractically large table.</p><p>Fan et al. <ref type="bibr" target="#b16">[17]</ref> present a hardware Gaussian noise generator based on the polar method <ref type="bibr" target="#b10">[11]</ref> in conjunction with the central limit theorem. Their design is implemented on an Altera Mercury EP1M120F484C7 FPGA; it takes up 336 logic elements and has a clock speed of 73 MHz generating a sample every clock. The polar method is a variant of the Box-Muller method and is a class of the rejection-acceptance methods, hence the output rate is not constant. In order to overcome this problem, they employ a first-in first-out (FIFO) buffer with the read speed set to half of the write speed.</p><p>The drawback of the hardware designs mentioned above are revealed by statistical tests applied to evaluate the noise samples produced. The authors carry out relative error comparisons between the ideal Gaussian pdf and the obtained pdf for a small number of samples and limited maximum value. Such tests are not enough to ensure the quality of the noise samples; one should thoroughly apply well known goodness-of-fit tests such as the chi-square test and the A-D test over large numbers of samples. Designs which fail such statistical tests are inadequate for high quality hardware communications simulations such as LDPC codes. This issue is discussed in more detail in Section VI.</p><p>In <ref type="bibr" target="#b17">[18]</ref>, we present a hardware Gaussian noise generator based on the Box-Muller method and central limit theorem. The idea is similar to <ref type="bibr" target="#b13">[14]</ref>, but we employ more sophisticated approximation techniques for the mathematical functions of the Box-Muller method, resulting in significantly more statistically accurate noise samples. The design occupies 2514 slices, two block RAMs and eight MULT18X18s ( <ref type="formula">18</ref>18 embedded multiplier blocks) on a Xilinx Virtex-II XC2V4000-6 FPGA. It operates at 133 MHz generating a noise sample every clock and passes the statistical tests widely used for testing normality discussed in Section VI.</p><p>All of the methods described above produce normal variables by performing operations on uniform variables. In contrast, Wallace proposes an algorithm using an evolving pool of normal variables to generate additional normal variables <ref type="bibr" target="#b5">[6]</ref>. The approach draws its inspiration from uniform random number generators that generate one or more new uniform variables from a set of previously generated uniform variables. Given a set of normally distributed random variables, a new set of normally distributed random variables can be generated by applying a linear transformation. Brent <ref type="bibr" target="#b18">[19]</ref> has implemented a fast vectorized Gaussian random number generator using the Wallace method on the Fujitsu VP2200 and VPP300 vector processors. In <ref type="bibr" target="#b19">[20]</ref>, Brent and Rüb outline possible problems associated with the Wallace method and discuss ways of avoiding them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. WALLACE METHOD</head><p>Wallace proposes a fast algorithm for generating normally distributed pseudorandom numbers which generates the target distributions directly using their maximal-entropy properties <ref type="bibr" target="#b5">[6]</ref>. This algorithm is particularly suitable for high throughput hardware implementation since no transcendental functions such as , or are required. An overview of the Wallace method is described in Fig. <ref type="figure" target="#fig_0">1</ref>. It takes a pool of normally distributed random numbers from the normal distribution. These values are normalized so that their average squared value is one. In transformation steps, numbers are treated as a vector , and transformed into new numbers from the components of the vector where is an orthogonal matrix. If the original values are normally distributed, then so are the new values. Furthermore, this transformation preserves the sum of squares.</p><p>The process of generating a new pool of normally distributed random numbers is called a "pass." After a pass, a pool of new Gaussian random numbers is formed. As there are variables in the data pool, transformation steps are performed during each pass. A -vector is multiplied with the orthogonal matrix in performing a transformation step.</p><p>As stated by Wallace, it is desirable that any value in the pool should eventually contribute to every value in the pools formed after several passes. In Wallace's original method, the old pool is treated as an -by-array stored in row-major order, and the new pass is treated as an -by-array stored in column major order. Hence, each pass effectively transposes the values in the pool. If is odd, the transposition is sufficient to ensure eventual mixing of the values. However if is even, transposition alone is not sufficient. We describe in Section IV how we overcome this problem to reduce correlation even further.</p><p>The initial values in the pool are normalized so that their average squared value is one. Because is orthogonal, the subsequent passes do not alter the sum of the squares. This would be a defect, since if are independent samples from the normal distribution, we would expect to have a chi-squared distribution . In order to overcome this defect, a variate from the previous pool is used to approximate a random sample from the distribution. A scaling factor is introduced to ensure that the sum of the squares of the values in the pool is , the random sample.</p><p>One concern of the Wallace method is the issue of correlations given the use of previous outputs to generate new outputs. This can be problematic in the case of realizations with large absolute values lying in the tails of the Gaussian, since each value contributes values in the subsequent block, values in the next block, and so on with diminishing influence. With proper choice of parameters such as pool size and transformation size, the effect of these correlations can be minimized for a given set of requirements with respect to number of noise samples, tail accuracy, and noise quality. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. ARCHITECTURE</head><p>This section provides an overview of the hardware design for the Wallace method, which involves a four-stage hardware architecture shown in Fig. <ref type="figure" target="#fig_1">2</ref>. The implementation of this architecture in FPGA technology will be presented in Section V. In Fig. <ref type="figure" target="#fig_1">2</ref>, the select signals for the multiplexors and the clock enable signals for the registers are omitted for simplicity.</p><p>In our design illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, we choose and resulting in a pool size of 1024. Although one can choose any and , in this work, we follow Wallace's original description. On-chip, true dual read/write port synchronous RAM is used to implement the pool. The dual-port RAM allows two values to be read and written simultaneously, improving the memory bandwidth.</p><p>As all the variables from the pool are used to generate the new pseudo random numbers, the indexes should cover all the numbers in the pool and at the same time reduce the correlations between them. The addresses which index the pool are started from a random origin "start," stepped by a random odd "stride" and XOR is performed with a random "mask." The combination of these three operations is critical to achieve good mixing between the Gaussian samples in the pool. Our tests show that if one of them is not performed, it causes degradation in the overall Gaussian noise quality.</p><p>In order to achieve better mixing of the Gaussian random number generator, more pass types can be used during a pass by introducing different orthogonal matrices. As in Wallace's original implementation, two orthogonal matrices and are chosen for our design During a pass, is used for first half and is used for the second half of the pass. As the elements of the matrices and are only 1 or 1, only simple integer addition and shift operations are required. The Gaussian random variables in the pool are held as 24 bit two's complement integers. For the given set of four values , , , to be transformed, and with our choice of and , the new values , , , can be calculated from the old ones as follows:</p><p>(1) <ref type="bibr" target="#b1">(2)</ref> where . Note that the operations above are performing the actual transformations, hence there is no need to store and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. First Stage</head><p>This stage involves generation of the uniformly distributed realizations start, stride and mask. While traditional linear feedback shift registers (LFSRs) <ref type="bibr" target="#b20">[21]</ref> are sufficient as a uniform random number generator (URNG), Tausworthe URNGs <ref type="bibr" target="#b21">[22]</ref> offer better randomness with modest hardware cost. The Tausworthe URNG we employ follows the algorithm presented in <ref type="bibr" target="#b21">[22]</ref>. It combines three LFSR based random number generators to obtain improved statistical properties, generates a 32-bit uniform random number per clock, and has a period of around 2 . Since we use a pool size of 1024, 10 bits are needed for the three variables. Since stride needs to be odd at all times, we concatenate a one after the least significant bit. Hence, for each pass, altogether 29 bits are used for start, stride, and mask. The remaining three bits are left unused. The multiplication by two is implemented simply by a left shift, and the multiplication by three is implemented by a left shift followed by an addition. This addressing scheme ensures that the correlations between variables are kept at a minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Third Stage</head><p>This stage involves the most interesting challenge: efficiently performing the actual transformation. This stage contains the "Pool RAM" which holds the pool of 1024 Gaussian random variables. Dual-port RAM is used to implement the pool. Since each variable in the pool is 24 bits, the total size of the pool is bits. The "init Pool ROM" and the counter are used to initialize the pool with the original pool contents when the reset signal is set. This ROM is single-ported and has the same size as the pool. The contents of this ROM are generated in software using the Box-Muller method, and the variables are normalized so that their sum of squares is equal to one.</p><p>Fig. <ref type="figure" target="#fig_2">3</ref> shows how we perform the transformation steps described in (1) and ( <ref type="formula">2</ref>). The timing diagram of this circuit and the "Pool RAM" is illustrated in Fig. <ref type="figure">4</ref>. We can see that the dual-port RAM is fully utilized. is calculated in three steps In principle, we could share a single adder in conjunction with multiplexors to perform all the operations of the transformation circuit. However, high-speed adders are efficiently implemented on FPGAs by fast-carry chains. In fact, both a two-input 24-bit multiplexor and a 24-bit adder occupy 14 slices (user-configurable elements on the FPGA) in a Xilinx Virtex-II FPGA. In addition the use of multiplexors would increase the delay significantly. For these reasons, we decide to use separate adders/subractors for each operation. For other devices such as Application-Specific Integrated Circuits (ASICs), it can be more efficient to adopt the former approach involving The critical path of the entire Wallace design is from to which is just a multiplexor followed by a subtractor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. The Fourth Stage</head><p>This stage performs the sum of squares correction described in Section III. It follows the approach used by Wallace in the FastNorm implementations <ref type="bibr" target="#b22">[23]</ref>.</p><p>A random sample with an approximate distribution can be obtained as <ref type="bibr" target="#b9">(10)</ref> where has unit normal distribution, and for large . Hence, can be computed as <ref type="bibr" target="#b10">(11)</ref> where</p><p>. We set and .</p><p>The noise sample , generated from the transformation circuit of Stage 3, is multiplied by to correct the sum of the squares and hence the final noise sample. is obtained by <ref type="bibr" target="#b11">(12)</ref> Since and are constants, they are precalculated in software and stored as constants in the hardware design.</p><p>Before a pass, is assigned with a variable from a previous pass, and is updated. For the very first pass when the reset signal is set, is initialized to where is the sum of squares of the initial pool. Note that we are using a pool size of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. IMPLEMENTATION</head><p>This section presents implementations of the four-stage architecture using FPGA technology.</p><p>The Tausworthe URNG in Stage 1 can be implemented in configurable hardware using a small amount of resources. Recent FPGAs have a large number of user-configurable elements: for instance, the Xilinx Virtex-II XC2V4000-6 device has 23 040 user-configurable elements known as slices. We use the primitive pentanomial over with a random initial state. This takes up just 77 slices. Xilinx Virtex-II devices have embedded memory elements and multipliers, which are known as block RAMs and MULT18X18s. Each block RAM can hold 18 kb of data and each MULT18X18 can implement a 18 bit 18 bit multiplication. If the data or the multiplication are larger than 18 kb or 18 bit 18 bit, the Xilinx tools will use multiple block RAMs and MULT18X18s to implement them. The Xilinx Virtex-II XC2V4000-6 device has 120 block RAMs and 120 MULT18X18s in total. The "init Pool ROM" is implemented using single-port block RAM, while the "Pool RAM" is implemented using dual-port block RAM. Since, we use a pool of 1024 and use 24 bits for each noise samples, the size of "init Pool ROM" and "Pool RAM" are both 24 576 bits, occupying two block RAMs each. The constant coefficient multiplier in Stage 4 uses two block RAMs to implement part of the multiplication. The 24 bit 24 bit multiplier in Stage 4 occupies four MULT18X18s.</p><p>Several FPGA implementations have been developed, using Xilinx System Generator 6.3 <ref type="bibr" target="#b23">[24]</ref>. All designs are heavily pipelined to maximize throughput. Synplicity Synplify Pro 7.7 is used for synthesis. For place-and-route, Xilinx ISE 6.3 is used with the maximum effort level and the clock constraints are carefully tuned to give the fastest clock frequency. We have mapped and tested the Wallace design onto a hardware platform with a Xilinx Virtex-II XC2V4000-6 FPGA. The design occupies 770 slices, six block RAMs, and four MULT18X18s, which takes up around 3% of the device. The pipelined design operates at 155 MHz, and hence our design produces 155 million Gaussian noise samples per second. The resource usage of each of the four stages is shown in Table <ref type="table" target="#tab_0">I</ref>.</p><p>The latency of our design is 1138 clock cycles ( 7 s at 155 MHz); 1024 cycles are used to initialize the "Pool RAM" with the initial pool of Gaussian random samples. The other 114 cycles are needed to fill up the pipelines of the design. Although the latency is very large, it is not important since we only care about the throughput in a hardware-based simulation.</p><p>From a hardware designer's point of view, it is interesting to explore the tradeoffs between using different types of hardware resources. For instance, a table can be implemented using block RAM or distributed RAM using slices. Table <ref type="table" target="#tab_0">II</ref> shows our noise generator implemented using different FPGA resources. We observe that the design using slices only is more than four times the number of slices and has significantly lower clock speed than our original design. Also, the area and speed penalty of using slices to implement tables instead of block RAMs is especially high. Hence, in our opinion, dedicated FPGA resources such as block RAMs and MULT18X18s should be used wherever applicable.</p><p>We have also implemented our design on a low-cost Xilinx Spartan-III XC3S200E-5 FPGA, utilizing the slices, block RAMs, and MULT18X18s available on the chip. The design runs at 106 MHz and takes up the same amount of resources as the Virtex-II design above, which requires around half of the resources in the device.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EVALUATION AND RESULTS</head><p>This section describes the statistical tests that we use to analyze the properties of the generated Gaussian noise.</p><p>To ensure the randomness of the uniform random numbers start, stride and mask, we have tested the Tausworthe URNG with the Diehard tests <ref type="bibr" target="#b24">[25]</ref>. The Tausworthe URNG pass all the tests indicating that the uniform random samples generated are indeed uniformly randomly distributed.</p><p>We use two well-known goodness-of-fit tests to check the normality of the random variables: the chi-square test and the A-D test <ref type="bibr" target="#b25">[26]</ref>. The test involves quantizing the axis into bins, determining the actual and expected number of samples appearing in each bin, and using the results to derive a single number that serves as an overall quality metric. This test is essentially a comparison between an experimentally determined histogram and the ideal pdf. In contrast to the test which deals with quantized aspects of a design, the A-D test deals with continuous properties. It is modified from the Kolmogorov-Smirnov (K-S) test <ref type="bibr" target="#b10">[11]</ref> to give more weight to the tails than the K-S test does. The K-S test is distribution free in the sense that the critical values do not depend on the specific distribution being tested. The A-D test makes use of the specific distribution (normal in our case) in calculating critical values.</p><p>The probability that the deviation of the observed from the expected is due to chance alone can be obtained from a -value <ref type="bibr" target="#b25">[26]</ref> based on the above tests. A sample set with a small -value means that it is less likely to follow the target distribution. The general convention is to reject the null hypothesis-that the samples are normally distributed-if the -value is less than 0.05.</p><p>Our hardware Wallace implementation passes the statistical tests even with extremely large numbers of samples. We have run a simulation of 10 samples to calculate the -values for the and A-D test. For the test, we use 100 bins for the axis over the range . The -values for the and A-D tests are found to be 0.5385 and 0.7372 respectively, which are well above 0.05, indicating that the generated noise samples are indeed normally distributed. To test the noise quality in the high regions, we run a simulation of 10 samples over the range and with 100 bins. This is equivalent to a simulation size of over 10 samples. The -values for the and A-D tests are found to be 0.6839 and 0.7662, showing that the noise quality even in the high regions is high.</p><p>If is a pair of random numbers with Gaussian distributions, then should be uniform over . Six million Gaussian variables, randomly picked from a population of 10 samples generated from our design are transformed using this identity, resulting in three million uniform random variables. These uniform variables are tested with the Diehard tests <ref type="bibr" target="#b24">[25]</ref> for uniformity. They pass all tests indicating that the transformed numbers are indeed uniformly distributed. Fig. <ref type="figure" target="#fig_4">5</ref> shows the pdf obtained from our Gaussian noise generator for a population of four million samples. The samples pass both the We compare our design with two other designs: "White Gaussian Noise Generator" block available in Xilinx System Generator 6.3 <ref type="bibr" target="#b23">[24]</ref> and the design presented in <ref type="bibr" target="#b17">[18]</ref>. The "White Gaussian Noise Generator" block is based on the "Additive White Gaussian Noise (AWGN) Core 1.0" from Xilinx <ref type="bibr" target="#b14">[15]</ref>. The Xilinx core follows the architecture presented by Boutillon et al. in <ref type="bibr" target="#b13">[14]</ref>, which uses the Box-Muller method in conjunction with the central limit theorem. The block is slightly slower and larger than the core, since it is less optimized. The design in <ref type="bibr" target="#b17">[18]</ref> is also based on the Box-Muller method and central limit theorem, but we employ more sophisticated approximation techniques for the mathematical functions in the Box-Muller method, resulting in significantly more statistically accurate noise samples. We test the noise samples generated from the Xilinx block with the and the A-D test. We find that the samples fail the tests after just 160 000 samples. We also tested the Boutillon et al. <ref type="bibr" target="#b13">[14]</ref> design with the test, and found that it fails after just 20 000 samples. This is primary due to the limited resolution problem of their nonuniform direct look-up table approach. We suspect that the tables would have to be impractically large to generate high quality noise samples with this approach.</p><p>Table <ref type="table" target="#tab_1">III</ref> compares the Xilinx block, our Box-Muller design in <ref type="bibr" target="#b17">[18]</ref>, and our Wallace design. We can see that the Xilinx block uses less resources and is slightly faster than our Wallace design, but as mentioned above the block fails the statistical tests after a small number of samples. Both of our Box-Muller and Wallace designs pass the statistical tests, even with very large numbers of samples. However, our Wallace design is around three times smaller and slightly faster.</p><p>Fig. <ref type="figure" target="#fig_5">6</ref> shows the variation of the value with sample size for the Xilinx block, and various Wallace implementations at different data path and noise sample bit-widths. The dotted horizontal line is the 0.05 confidence level ( -value), i.e., values below this line pass the test. We observe that the Xilinx block fails after a small number of samples. For the Wallace implementations, we observe that with increasing precision more samples are required to fail the test. This is due to a combination of two factors: 1) insufficient precision in the Wallace arithmetic leading to low quality noise samples and 2) because of finite precision of the noise samples, some bins of the test will be more biased than others, this effect is reduced with increasing noise precision.  In Fig. <ref type="figure" target="#fig_6">7</ref> we plot the Wallace bitwidth versus the number of samples without failure. With the axis in logarithmic scale, we can see a linear behavior. The dotted line shows the trend at higher bit-widths. For instance, if 32 bit Wallace is used, up to around 10 samples would pass the test. Increasing the Wallace bit-width would require more block RAMs for the pool, and larger multipliers for the sum-of-squares correction, and more slices for the larger adders and multiplexors. , respectively. Thus, the lack of noise of sufficient quality can lead to an overly optimistic (and incorrect) conclusions regarding the behavior of the code.</p><p>The performance of the noise generator can be improved by concurrent execution. We have experimented with placing mul-  tiple instances of our noise generator in an FPGA, and discovered that there is a reduction in clock speed due to increased routing congestion. We are able to fit up to 20 instances on the XC2V4000-6 FPGA running at 115 MHz, the number of block RAMs available on the device being the limit. Of course using a larger device such as the Virtex-4 XC4VFX140 FPGA, we are able to fit even more instances. Note that it is perfectly valid to use multiple instances of the noise generator, as long as the Tausworthe URNGs and pool RAMs are initialized with different random seeds and noise samples. Our hardware implementations have been compared to several software implementations based on the Wallace, Ziggurat <ref type="bibr" target="#b9">[10]</ref>, polar and Box-Muller method <ref type="bibr" target="#b10">[11]</ref>, which are known to be the fastest methods for generating Gaussian noise for instruction processors. For the Wallace and Ziggurat methods, FastNorm2<ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b22">[23]</ref> and rnorrexp <ref type="bibr" target="#b9">[10]</ref>, which are publicly available, are used. In order to make a fair comparison, we use the same uniform number generator for all implementations. The mixed multiplicative congruential (Lehmer) generator <ref type="bibr" target="#b27">[28]</ref> used in the Fast-Norm2 implementation is chosen. Software implementations are run on an Intel Pentium-IV 2.6-GHz PC is equipped with 1-GB DDR-SDRAM. They are written in ANSI C and compiled with the GNU gcc 3.2.2 compiler with -O3 optimization, generating double precision floating-point numbers. Note that all software implementations pass the and A-D tests. The results are shown in Table <ref type="table" target="#tab_2">IV</ref>. It can be seen that our hardware designs are faster than software implementations by 2-609 times, depending on the device used and the resource utilization. Looking at the PC results, we can see that the Wallace method performs significantly better than other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>We have presented a hardware Gaussian noise generator using the Wallace method to support simulations which involve very large numbers of samples.</p><p>Our noise generator architecture contains four stages. It takes up approximately 3% of a Xilinx Virtex-II XC2V4000-6 FPGA and half of a Xilinx Spartan-III XC3S200E-5, and can produce 155 million samples per second. Further improvement in performance can be obtained by concurrent execution: 20 parallel instances of the noise generator on an XC2V4000-6 FPGA at 115 MHz can run 51 times faster than software on a 2.6-GHz Pentium-IV PC. The quality of the noise samples is confirmed by two statistical tests: the test and the A-D test, and also by applications involving LDPC decoding. We are currently exploring methods for characterizing and optimizing Gaussian noise generators, such that the most appropriate noise generator can be selected for a given application.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the Wallace method.</figDesc><graphic coords="3,38.52,65.94,250.00,78.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of our Gaussian noise generator architecture based on the Wallace method. The triangle in Stage 4 is a constant coefficient multiplier.</figDesc><graphic coords="3,301.14,65.58,251.00,483.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Transformation circuit of Stage 3. The square boxes are registers. The select signals for the multiplexors and the clock enable signals for the registers are omitted for simplicity.</figDesc><graphic coords="4,305.16,65.90,246.00,229.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 7 )Fig. 4 .</head><label>74</label><figDesc>Fig. 4. Detailed timing diagram of the transformation circuit and the dual-port "Pool RAM." A z indicates the address of the data z and WE is the write enable signal of the "Pool RAM." All ports and registers of the transformation circuit and ports of the dual-port RAM are shown. We observe that the dual-port RAM is fully utilized.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The pdf of the generated noise from our design for a population of four million samples. The p-values of the and A-D tests are 0.7303 and 0.8763, respectively.</figDesc><graphic coords="7,40.68,65.90,245.00,187.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Variation of the value with sample size for the Xilinx block and various Wallace implementations at different precisions.</figDesc><graphic coords="8,39.84,65.42,250.00,124.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Wallace bitwidth versus number of samples without failure.We see a linear behavior with the y axis in logarithmic scale.</figDesc><graphic coords="8,40.26,239.00,249.00,163.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8</head><label>8</label><figDesc>shows BER performance simulation results for a 972 1944 irregular LDPC code from [27]. Results show our Wallace noise generator, standard Box-Muller, and Box-Muller with the noise saturated at and . The Box-Muller implementations are written in software using double-precision floating point arithmetic. Two observations can be made from this figure. First, there are no distinguishable differences between our Wallace implementation and the software Box-Muller. Second, limiting the noise power to a certain multiple results in inaccurate simulation results, particularly in regions of lower BER. For instance at dB, our Wallace gives a BER of 10 , standard Box-Muller gives 10 , whereas Box-Muller saturated at and give 10 and 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. BER performance simulation results for a 972 2 1944 irregular LDPC code. The Box-Muller implementations are written in software using double-precision floating point arithmetic.</figDesc><graphic coords="8,302.64,65.46,252.00,174.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,115.14,65.82,360.00,429.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I RESOURCE</head><label>I</label><figDesc>UTILIZATION FOR THE FOUR STAGES OF THE NOISE GENERATOR ON A XILINX VIRTEX-II XC2V4000-6 FPGA TABLE II HARDWARE IMPLEMENTATION RESULTS OF THE NOISE GENERATOR USING DIFFERENT TYPES OF FPGA RESOURCES ON A XILINX VIRTEX-II XC2V4000-6 FPGA</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE III COMPARISONS</head><label>III</label><figDesc>OF DIFFERENT HARDWARE GAUSSIAN NOISE GENERATORS IMPLEMENTED ON XILINX VIRTEX-II XC2V4000-6 FPGAS. ALL DESIGNS GENERATE A NOISE SAMPLE EVERY CLOCKand the A-D test resulting in a smooth bell-shaped Gaussian distribution.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV PERFORMANCE</head><label>IV</label><figDesc>COMPARISON: TIME FOR PRODUCING ONE BILLION GAUSSIAN NOISE SAMPLES. THE XC2V4000-6 FPGA BELONGS TO THE XILINX VIRTEX-II FAMILY, WHILE THE XC3S200E-5 FPGA BELONGS TO THE XILINX SPARTAN-III FAMILY</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In FastNorm2, the pool is updated periodically, whereas in our hardware implementation it is not.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank R. P. Brent, A. Abdul Gaffar, A. C. H. Ng, R. C. C. Cheung, E. Vallés, and the reviewers for their assistance.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Manuscript received August 20, 2004; revised March 23, 2005. This work was supported in part by Xilinx Inc., by the U.K. Engineering and Physical Sciences Research Council under Grants GR/N 66599 and GR/R 31409, by the U.S. Office of Naval Research, and by the Research Grants Council of the Hong Kong Special Administrative Region, China, under Project CUHK4333/02E. D. Lee was with the</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Flannery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Vetterling</surname></persName>
		</author>
		<title level="m">Numerical Recipes in C</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Implementation of near Shannon limit error-correcting codes using reconfigurable hardware</title>
		<author>
			<persName><forename type="first">B</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schmit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. Field-Programmable Custom Computing Machines</title>
		<meeting>IEEE Symp. Field-Programmable Custom Computing Machines</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The market model of interest rate dynamics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ga ¸tarek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Musiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Finance</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="155" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gaussian estimation of mixed-order continuous-time dynamic models with unobservable stochastic trends from mixed stock and flow data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bergstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometric Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="505" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Langevin dynamics simulations of macromolecules on parallel computers</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lenhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rüb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Macromolecular Theory Simul</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="507" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast pseudorandom generators for normal and exponential variates</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="127" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Low-density parity-check codes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gallager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="21" to="28" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An alias method for sampling from the normal distribution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Dieter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="159" to="170" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A fast normal random number generator</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="449" to="453" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Ziggurat method for generating random variables</title>
		<author>
			<persName><forename type="first">G</forename><surname>Marsaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Statist. Softw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Seminumerical Algorithms, 3rd ed, ser. The Art of Computer Programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Knuth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Addison-Wesley</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Continuous random variate generation by fast numerical inversion</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hörmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leydold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Modeling and Computer Simulation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="347" to="362" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A note on the generation of random normal deviates</title>
		<author>
			<persName><forename type="first">G</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="610" to="611" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Design of high speed AWGN communication channel emulator</title>
		<author>
			<persName><forename type="first">E</forename><surname>Boutillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Danger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gazel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analog Integr. Circuits Signal Process</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="142" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Additive white Gaussian noise (AWGN) Core v1.0. Xilinx Inc</title>
		<ptr target="http://www.xilinx.com" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reconfigurable readback-signal generator based on a field-programmable gate array</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bazargan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Magn</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1744" to="1750" />
			<date type="published" when="2004-03">Mar. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A versatile high speed bit error rate testing scheme</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zilic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Quality Electronic Design</title>
		<meeting>IEEE Int. Symp. Quality Electronic Design</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="395" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Gaussian noise generator for hardware-based simulations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Villasenor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1523" to="1534" />
			<date type="published" when="2004-12">Dec. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A fast vectorised implementation of Wallace&apos;s normal random number generator</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brent</surname></persName>
		</author>
		<idno>TR-CS-97-07</idno>
	</analytic>
	<monogr>
		<title level="j">ANU Computer Sci</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>The Australian National University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On Wallace&apos;s method for the generation of normal variates</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rüb</surname></persName>
		</author>
		<idno>MPI-I-98-1-020</idno>
	</analytic>
	<monogr>
		<title level="j">MPI Informatik Res. Rep</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Max-Planck-Institut für Informatik</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Design techniques of FPGA based random number generator</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Military and Aerospace Applications of Programmable Devices and Technology Conf</title>
		<meeting><address><addrLine>Laurel, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Maximally equidistributed combined Tausworthe generators</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Ecuyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Comput</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">213</biblScope>
			<biblScope unit="page" from="203" to="213" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">MDMC software-Random number generators</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wallace</surname></persName>
		</author>
		<ptr target="http://www.datamining.monash.edu.au/software/random" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Xilinx System Generator User Guide v6.3. Xilinx Inc</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Diehard: A battery of tests of randomness</title>
		<author>
			<persName><forename type="first">G</forename><surname>Marsaglia</surname></persName>
		</author>
		<ptr target="http://stat.fsu.edu/~geo/diehard.html" />
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Agostino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stephens</surname></persName>
		</author>
		<title level="m">Goodness-of-Fit Techniques</title>
		<imprint>
			<publisher>Marcel Dekker Inc</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multiple rate low-density parity-check codes with constant block length</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vila Casado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Asilomar Conf. Signals, Systems and Computers</title>
		<meeting>IEEE Asilomar Conf. Signals, Systems and Computers</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="2010" to="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A long-period pseudo-random generator</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno>TR89/123</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>Monash Univ., Australia</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">He is a Member of Academic Staff in the Department of Computing, Imperial College of Science, Technology, and Medicine, London, U.K., and leads the Custom Computing Group there. His research interests include theory and practice of customizing hardware and software for specific application domains, such as graphics and image processing, multimedia, and communications. Much of his current work involves high-level compilation techniques and tools for parallel computers and embedded systems</title>
		<author>
			<persName><forename type="first">Dong-U</forename><surname>Lee ; London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">S&apos;01-M&apos;05) received the B.Eng. degree in information systems engineering and the Ph.D. degree in computing, both from Imperial College</title>
		<meeting><address><addrLine>Oxford, U.K</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001. 2004</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Los Angeles (UCLA)</orgName>
		</respStmt>
	</monogr>
	<note>where he is developing hardware implementations of communication algorithms for deep-space communications with the Jet Propulsion Laboratory, NASA. He visited UCLA in 2002 and 2003 as a Visiting Scholar, where he developed hardware designs for LDPC codes. His research interests include reconfigurable computing, computer arithmetic, communications and video image processing. particularly those containing reconfigurable devices such as field-programmable gate arrays</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
