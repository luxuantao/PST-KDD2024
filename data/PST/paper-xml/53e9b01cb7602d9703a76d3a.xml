<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Spelling Correction for Query Completion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Huizhong</forename><surname>Duan</surname></persName>
							<email>duan9@illinois.edu</email>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Hsu</surname></persName>
							<email>paulhsu@microsoft.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana</orgName>
								<address>
									<addrLine>Champaign 201 N Goodwin Ave Urbana</addrLine>
									<postCode>61801</postCode>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<postCode>98052</postCode>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Online Spelling Correction for Query Completion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DB0F5FCD7324D59F7B99F4F66004FB8C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [INFORMATION STORAGE AND RETRIEVAL]: Information Search and Retrieval -query formulation; H.4.m [Information Systems and Applications]: Miscellaneous Algorithms</term>
					<term>Performance</term>
					<term>Experimentation Spelling correction</term>
					<term>query completion</term>
					<term>transformation model</term>
					<term>A* search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we study the problem of online spelling correction for query completions. Misspelling is a common phenomenon among search engines queries. In order to help users effectively express their information needs, mechanisms for automatically correcting misspelled queries are required. Online spelling correction aims to provide spell corrected completion suggestions as a query is incrementally entered. As latency is crucial to the utility of the suggestions, such an algorithm needs to be not only accurate, but also efficient.</p><p>To tackle this problem, we propose and study a generative model for input queries, based on a noisy channel transformation of the intended queries. Utilizing spelling correction pairs, we train a Markov n-gram transformation model that captures user spelling behavior in an unsupervised fashion. To find the top spellcorrected completion suggestions in real-time, we adapt the A* search algorithm with various pruning heuristics to dynamically expand the search space efficiently. Evaluation of the proposed methods demonstrates a substantial increase in the effectiveness of online spelling correction over existing techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Misspelling is a common phenomenon in search engine queries. According to Cucerzan and Brill <ref type="bibr" target="#b7">[9]</ref>, more than 10% of search engines queries are misspelled. This is even more severe for tail queries, of which more than 20% are misspelled <ref type="bibr" target="#b3">[5]</ref>. Misspellings occur for a variety of reasons. When typing quickly, users may add or drop letters unintentionally. Accidentally hitting an adjacent key on the keyboard, also known as the fat-finger syndrome <ref type="bibr">[1]</ref>, is also common, especially on mobile devices with small virtual keyboards. In addition to typographical errors, some errors result from the challenge of spelling itself. With inconsistent spelling rules <ref type="bibr">[2]</ref>, ambiguous word breaking boundaries, and constant introduction of new words, spelling presents a formidable challenge to foreign and native speakers alike. Table <ref type="table" target="#tab_0">1</ref>  To assist users in expressing their information needs, it is important for search engines to automatically generate corrections for misspelled queries. Two such mechanisms are in common use.</p><p>The first corrects a query after it is submitted to the search engine.</p><p>For confident corrections, the search engine can search the corrected query directly. As the entire query string is given, we refer to such an approach as offline spelling correction. The second technique provides corrections to the query completion suggestions as the query is being entered. Specifically, the search engine responds to each keystroke with a list of query suggestions that best correct and complete the partial query. Compared with offline spelling correction, this task not only needs to address incomplete queries, but also requires lower latency to be effective. We refer to this task as online spelling correction.</p><p>Online correction has many merits that cannot be achieved by offline correction. First, it keeps users informed of potential errors as they type. Thus, spelling errors and the resulting ambiguities can be eliminated even before issuing the query. Second, it helps users express their information needs. As the quality and quantity of suggestions from current search engines degrade dramatically with misspelled partial queries, the ability to suggest popular completions from corrected partial queries can improve the effectiveness of the suggestions. Third, it saves users effort in inputting queries. With more comprehensive suggestions that correct potential errors, users are more likely to find the target query in the suggestion list. Selecting a corrected suggestion reduces not only the number of keystrokes required to input a query, but often also the additional click on the search result page to confirm the correction.</p><p>It is worth noting that although many search engines today apply online corrections to query completion suggestions, their abilities are fairly limited. For instance, neither of the two major US search engines, Google and Bing, suggests any completion for "importamt" and "miunderstand" at the time of this submission, which are only one letter away from "important" and "misunderstand", respectively.</p><p>In this paper, we model search queries with a generative model, where the intended query is transformed through a noisy channel into a potentially misspelled query. The distribution from which the target query is selected is estimated from the search engine query log based on frequency. Thus, we are more likely to suggest more popular queries. For the noisy channel, which describes the distribution of spelling errors, we follow the joint-sequence modeling framework <ref type="bibr" target="#b2">[4]</ref> to define the probability of transforming the original query into the observed character sequence. Specifically, we treat the desired and realized queries as a sequence of substring transformation units, or transfemes for convenience. Thus, we can decompose the probability of the overall transformation sequence as a product of the transfeme probabilities, each conditioned on the previous transfemes. By applying the Markov assumption and experimenting with the length of the transfeme units, we can build transformation models of varying complexities. Figure <ref type="figure">1</ref> shows an example segmentation of the input and output queries into a sequence of transfemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: Example segmentation into transfemes</head><p>To estimate the conditional probabilities of the transfemes, we train a smoothed transfeme n-gram language model from a set of correction query pairs. As the query pairs are not co-segmented in the training data, we apply the expectation-maximization (EM) algorithm to segment the data with the objective of maximizing the model probability. Since different users misspell at different rates, we further propose a mixture model to address the problem of overly-aggressive corrections.</p><p>As suggestion latency is crucial to the usefulness of query suggestions from potentially misspelled partial queries, we further explore efficient data structures and algorithms to dynamically search for the top query completions under the proposed transformation model. In particular, we apply the A* search algorithm against a trie built from the query log, where each node is further annotated with the best score of all descendent queries. We also experiment with different pruning heuristics to reduce search latency. As all query pairs have a non-zero transformation probability under this model, we further investigate probability thresholding techniques to reduce irrelevant suggestions.</p><p>The rest of the paper is organized as follows. After surveying the related work in Section 2, we introduce the generative model for online correction in Section 3. Next, we present the proposed transformation model and search algorithm in Sections 4 and 5.</p><p>We follow up with experiment results in Section 6 before concluding in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Research on spelling correction has a long history <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b11">13,</ref><ref type="bibr" target="#b13">15]</ref>. Edit distance, initially proposed by Damerau <ref type="bibr" target="#b8">[10]</ref> and Levenshtein <ref type="bibr" target="#b11">[13]</ref>, has been widely used in generic spelling correction. More recent work on offline spelling correction tends to focus on search engine queries <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b7">9,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b14">16]</ref>. Cucerzan and Brill <ref type="bibr" target="#b7">[9]</ref> studied spelling correction as an iterative process to exploit the information in query logs. Li et al. <ref type="bibr" target="#b12">[14]</ref> explored distributional similarity of query terms to estimate the error model. Chen et al. <ref type="bibr" target="#b5">[7]</ref> leveraged web search results to improve the performance of spelling correction on rare queries. Sun et al. <ref type="bibr" target="#b14">[16]</ref> explored clickthrough data to identify user correction pairs, and applied them to build a phrase-based error model. Gao et al. <ref type="bibr" target="#b10">[12]</ref> proposed the use of a general ranker as a generalization of the traditional noisy channel model in spelling correction, and implemented it with a distributed infrastructure to incorporate large scale data. As offline spelling correction is just a special case of online spelling correction, we consider the performance of both conditions when evaluating our system.</p><p>One of the earliest forms of auto-completion is the tab completion feature found in many command prompts. It is later extended by Darragh et al. <ref type="bibr" target="#b9">[11]</ref> to support the prediction of general text.</p><p>Recently, Chaudhuri and Kaushik <ref type="bibr" target="#b4">[6]</ref> proposed a technique to further extended auto-completion to tolerate errors. Particularly, they made use of a simple edit distance model and performed a fuzzy search over database records to find completions. To the best of our knowledge, this is the only prior work that addresses the problem of online spelling correction. Unfortunately, with a predetermined cap on edit distance and linear lookup time with increasing data size, the algorithm is not sufficiently robust and scalable for online spelling correction for query completion.</p><p>Our approach to spelling correction is largely inspired by previous work in grapheme to phoneme transformation. Chen <ref type="bibr">[8]</ref> studied conditional and joint maximum entropy models for grapheme to phoneme conversion. Taylor <ref type="bibr" target="#b15">[17]</ref> used a hidden Markov model, where the graphemes are observations of the hidden phoneme states. Bisani and Ney <ref type="bibr" target="#b2">[4]</ref> proposed a joint-sequence model for modeling grapheme to phoneme transformation, where graphemes and phonemes are viewed as a joint sequence generated with a Markov model. In this work, we adapt the joint sequence modeling of Bisani and Ney to model the transformation from the intended query to the observed sequence. However, whereas grapheme to phoneme conversions are strongly constrained by pronunciation rules, typographical errors do not impose any constraint on possible transformations, increasing the difficulty in model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ONLINE SPELLING CORRECTION</head><p>In offline spelling correction, we want to find the correctly spelled query ̂ with the highest probability of yielding the potentially misspelled input query . By applying Bayes' rule, we can alternatively express the task as:</p><formula xml:id="formula_0">̂ ( | ) ( | ) ( )<label>(1)</label></formula><p>In this noisy channel model formulation, ( ) is a query language model that describes the prior probability of as the intended user query. ( | ) ( ) is the transformation model that represents the probability of observing the query when the original user intent is to enter the query .</p><p>For online spelling correction, we are given only the prefix ̅ of the potentially misspelled input query . Thus, the objective is to find the correctly spelled query ̂ that maximizes the probability of yielding any query that extends the given partial query ̅. More formally, we want to find:</p><formula xml:id="formula_1">̂ ̅ ( | ) ̅ ( | ) ( )<label>(2)</label></formula><p>WWW 2011 -Session: Query Analysis March 28-April 1, 2011, Hyderabad, India where ̅ denotes that ̅ is a prefix of . In this formulation, we can view offline spelling correction as just a constrained special case of the more generic online spelling correction.</p><p>In this work, as search engines typically only suggest previously seen queries as completions, we model the query prior ( ) using the maximum likelihood estimation of the distribution of queries from the query log. Consequently, this model can only correct misspelled query prefixes to previously observed queries. In future work, we plan to extend this approach to the use of an ngram language model for the query prior ( ) to allow corrections to previously unseen queries.</p><p>To simplify the transformation model, we segment the conversion from to as a sequence of substring transformation units, or transfemes. For example, the transformation can be segmented into the transfeme sequence: , , , , . By describing the sequence with a transfeme n-gram language model, we can decompose the transformation model into a set of conditional transfeme probabilities. This allows us to not only train the model from segmented correction pairs, but also generalize the model to previously unseen transformations.</p><p>Factoring the solution into the query language model and transfeme transformation model enables the two models to be updated independently. As the query language model needs to reflect the constantly changing trends across topics, the query histogram and corresponding trie data structure can be updated frequently with low cost. On the other hand, the transformation model describes the user spelling behavior when entering queries. As this behavior does not change rapidly, we do not need to retrain the model as often. Instead, as the pattern of spelling errors depends heavily on the keyboard layout (English vs. French), keyboard size (standard vs. thumb-sized), and interface (physical buttons vs. virtual keyboard), we can build a separate transformation model for each text entry environment.</p><p>As we can see from Equation (2), by relaxing to be any query that extends the partial query ̅ , online spelling correction significantly increases the theoretical search space. However, with appropriate data structures and algorithms, we can actually perform this search faster than offline spelling correction, as we demonstrate in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">TRANSFORMATION MODEL</head><p>The transformation model presented in this work, including the EM training, pruning, and smoothing algorithms, largely mirrors the joint sequence model for grapheme to phoneme conversion in speech recognition, as described in Bisani and Ney <ref type="bibr" target="#b2">[4]</ref>. In the following sections, we define the transformation model as applied to spelling correction, summarize the EM training algorithm, and present additional considerations specific to spelling correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Definition</head><p>We decompose a transformation from the intended query to the observed query as a sequence of substring transformation units. As this model is inspired by joint sequence modeling in grapheme to phoneme conversion <ref type="bibr" target="#b2">[4]</ref>, we name such substring transformation units transfemes. For example, the transformation can be segmented into the transfeme sequence * +, where only the last transfeme, , involves a correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given a sequence of transfemes</head><p>, we can expand the probability of the sequence using the chain rule. As there are multiple ways to segment a transformation in general, we further model the transformation probability ( ) as the sum of all possible segmentations. Formally,</p><formula xml:id="formula_2">( ) ∑ ( ) ( ) ∑ ∏ ( | ) , - ( )<label>(3)</label></formula><p>where ( ) is the set of all possible joint segmentations of and . Further applying the Markov assumption that a transfeme only depends on the previous transfemes, similar to an ngram language model, we obtain:</p><formula xml:id="formula_3">( ) ∑ ∏ ( | ) , - ( )<label>(4)</label></formula><p>We define the length of a transfeme , as:</p><formula xml:id="formula_4">| | *| | | |+<label>(5)</label></formula><p>In general, a transfeme can be arbitrarily long. To constrain the complexity of the transformation model, we limit the maximum length of a transfeme to . With both n-gram approximation and transfeme length constraint, we obtain the final model with parameters and :</p><formula xml:id="formula_5">( ) ∑ ∏ ( | ) , - ( ) | | (6)</formula><p>In the special case of and , the transformation model degenerates to a model similar to weighted edit distance. With , we assume that the transfemes are generated independently of one another. As each transfeme contains substrings of at most one letter, we can model the standard Levenshtein edit operations <ref type="bibr" target="#b11">[13]</ref>: insertions , deletions , and substitutions</p><p>, where denotes the empty string. However, unlike many edit distance models, the weights in the transformation model represent normalized probabilities estimated from data, not just arbitrary score penalties. Thus, the transformation model not only captures the underlying patterns of spelling errors, but also allows us to compare the probabilities of different completion suggestions in a mathematically principled way. Figure <ref type="figure">2</ref> contains an example of such a transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: Example transformation with</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>With</head><p>, transpositions are penalized twice, even though it occurs as easily as other edit operations. Similarly, phonetic spelling errors, such as , often involve multiple characters. Modeling these transfemes as single character edit operations not only over-penalizes the transformation, but also pollutes the model as it increases the probabilities of edit operations, such as , that would otherwise have very low probabilities. By increasing , we increase the allowable length of the transfemes. Thus, the model is able to capture more meaningful transformation units and reduce probability contamination that result from decomposing intuitively atomic substring transformations. Figure <ref type="figure" target="#fig_0">3</ref> compares an example transformation with and . Instead of increasing , we can also improve the modeling of errors spanning multiple characters by increasing , the number of transfemes the model probabilities are conditioned on. Consider the example from Figure <ref type="figure" target="#fig_0">3 with</ref> . When , no context is considered in the generation of each transfeme. When , the probability of each transfeme is dependent on its previous transfeme. As a result, we are able to capture the fact that has a much higher probability when following the transfeme . As a more interesting example, is often misspelled as . A unigram model (</p><p>) is not able to express such an error. A bigram model ( ) captures this pattern by assigning higher probability to the transfeme when following . A trigram model ( ) can further identify exceptions to this pattern when preceded by a , as is more common than . As and capture similar behavior in our transformation model, we study the effect of different combinations of and in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Estimation</head><p>To learn the patterns of user spelling errors, we use a parallel corpus of input and output query pairs, where the input represents the intended query with correct spelling and the output corresponds to the potentially misspelled transformation of the input. If such data is pre-segmented into transfemes, we can derive the transformation model directly using maximum likelihood estimation (MLE). However, such labeled training data is generally too costly to obtain in large scale. Thus, we devise an expectation-maximization (EM) algorithm to estimate the parameters in the transformation model from partially observed data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given a set of observed training pairs</head><p>* +, where , we can write the log likelihood of the training data as:</p><formula xml:id="formula_6">( ) ∑ ( | ) ∑ ∑ ( | ) ( )<label>(7)</label></formula><p>where * ( | )+ is the set of model parameters. , the joint segmentation of each training pair into a sequence of transfemes, is the unobserved variable. By applying the EM algorithm <ref type="bibr" target="#b1">[3]</ref>, we can iteratively find the parameter set that maximizes the log likelihood.</p><p>For and , where each transfeme of length up to 1 is generated independently, we derive the following update formulas:</p><formula xml:id="formula_7">( ) ∏ ( ) , -<label>(8)</label></formula><formula xml:id="formula_8">( ) ∑ ∑ ( ) ∑ ( ) ( ) ( ) ( )<label>(9)</label></formula><formula xml:id="formula_9">( ) ( ) ∑ ( )<label>(10)</label></formula><p>where ( ) is the count of transfeme in the segmentation sequence , ( ) is the expected partial count of the transfeme with respect to the transformation model , and is the updated model. (</p><p>), also known as the evidence for , can be computed efficiently using a forward-backward algorithm <ref type="bibr" target="#b2">[4]</ref>.</p><p>We can extend the EM training algorithm to higher order transformation models (</p><p>), where the probability of each transfeme now depends on the previous transfemes. Other than having to take into account the transfeme history context when accumulating the partial counts, the general EM procedure is essentially the same. Specifically, we have:</p><formula xml:id="formula_10">( ) ∏ ( | ) , -<label>(11)</label></formula><formula xml:id="formula_11">( ) ∑ ∑ ( ) ∑ ( ) ( ) ( ) ( )<label>(12)</label></formula><formula xml:id="formula_12">( | ) ( ) ∑ ( )<label>(13)</label></formula><p>where is a transfeme sequence representing the history context, and ( ) is the occurrence count of transfeme following the context in the segmentation sequence . Though more complicated, (</p><p>), the evidence for in the context of , can still be computed efficiently using the forward-backward algorithm.</p><p>As the number of model parameters increases with , we initialize the model parameters using the converged values from the lower order model to achieve faster convergence. Specifically,</p><formula xml:id="formula_13">( | ) ( | )<label>(14)</label></formula><p>where is a sequence of transfemes representing the context, and is without the oldest context transfeme.</p><p>Extending the training procedure to further complicates the forward-backward computation. But the general form of the EM algorithm remains the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Pruning</head><p>One challenge with a direct implementation of the above algorithms is that as we increase the model parameters and , the number of potential parameters in the transformation model increases exponentially. Assuming an alphabet size of 50, a model contains ( ) parameters, as each component in can take on any of the 50 symbols or . But a model may contain up to ( ) parameters! Although most parameters are never observed in the data, model pruning techniques are still beneficial to reduce the overall search space, during both training and decoding, and to reduce overfitting, as infrequent transfeme n-grams are likely to be noise.</p><p>In this work, we employ two pruning strategies in each iteration of the training algorithm. First, we remove transfeme n-grams with expected partial counts below a threshold . Second, we trim out transfeme n-grams with estimated conditional probabilities below a threshold . The thresholds and are tuned against a held-out development set. By filtering out transfemes with low confidence, we significantly reduce the number of active parameters in the model and speed up the running time of training and decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Model Smoothing</head><p>As with any maximum likelihood estimation techniques, the EM algorithm has a tendency to overfit the training data when the number of model parameters is large, for example when . The standard technique in n-gram language modeling to address this problem is to apply smoothing when computing the conditional probabilities. In our work, we study two smoothing techniques: Jelinek-Mercer (JM) and absolute discounting (AD).</p><p>In JM smoothing, the probability of a transfeme is given by the linear interpolation of its maximum likelihood estimation at order (using partial counts) and its smoothed probability from a lower order distribution:</p><formula xml:id="formula_14">( | ) ( ) ( ) ∑ ( ) ( | )<label>(15)</label></formula><p>where ( ) is the linear interpolation parameter. Note that ( | ) and ( | ) are probabilities from different distributions within the same model. That is, in computing thegram model, we also compute the partial counts and probabilities for all lower-order -grams, where .</p><p>AD smoothing operates by discounting the partial counts of the transfemes. The removed probability mass is then redistributed to the lower order model:</p><formula xml:id="formula_15">( | ) ( ( ) ) ∑ ( ) ( ) ( | )<label>(16)</label></formula><p>where is the discount and ( ) is computed such that ∑ ( | ) . Note that the partial ( ) can be arbitrarily small, it is not possible to choose a value of such that ( ) will always be larger than . Consequently, we will trim the model if ( ) . For both smoothing techniques, all parameters are tuned on a held-out development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Mixture Models</head><p>When training from a dataset consisting of only query correction pairs, the resulting model is likely to over-correct. To address this issue, we prepare another dataset of correctly spelled query pairs and propose two ways of using the two datasets for training.</p><p>The first approach simply concatenates the two datasets together when estimating the transformation model. We refer to this method as data mixture. The second technique trains two transformation models from the two datasets individually. It is easy to see that the model trained from correctly spelled queries will only assign non-zero probabilities to transfemes with identical input and output, as all the transformation pairs are identical. We linearly interpolate the two models as the final model:</p><formula xml:id="formula_16">( ) ( ) ( ) ( )<label>(17)</label></formula><p>We label this approach as model mixture, where we can view each transfeme as probabilistically generated from one of the two distributions, according to the interpolation factor . As with all other modeling parameters, is tuned on a held-out development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussions</head><p>Observant readers may have noticed that the transformation model estimates the joint probability of the input and output substrings in a transfeme. As the transformation probability is later multiplied with the query language model in the generative formulation for online and offline spelling corrections, we are essentially double counting the input query probability. A solution to this problem is to normalize the transformation model for each input substring after training, so as to obtain a conditional model. Although this solution is theoretically sound, initial experiments have failed to improve the performance. As is common in speech recognition, where a "fudge factor" is introduced to balance the language model score against the acoustic model, we reformulate the optimization as:</p><formula xml:id="formula_17">̂ ( | ) ( ) ( ) ( )<label>(18)</label></formula><p>where ( ) is still the transformation model probability, and is the fudge factor controlling the additional probability mass of the query language model. Empirically, this approach turns out to be very effective in our experiments, although it lacks a theoretical foundation. We plan to continue exploring this issue in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SEARCH</head><p>With a query language model and a transformation model, we are able to compute the probability of any query given an input query . However, our task is to find the input query ̂ with highest probability efficiently, so as to enable offline spelling correction. More generally for online spelling correction, we want to find the top completions of an observed query prefix ̅. To achieve this, we propose to apply the A* search algorithm against a trie representing the query language model. Below we first introduce the modified trie data structure that we use to store the queries and their probabilities. We then present the A* search algorithm, followed by discussions on the pruning and thresholding techniques necessary to improve the efficiency and quality of the suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Trie</head><p>As the search algorithm starts from the beginning of a query and incrementally traverses potential corrections one letter at a time, we use a prefix tree (trie) to represent all queries in the query log. Figure <ref type="figure" target="#fig_1">4b</ref> shows a trie built over the set of strings in Figure <ref type="figure" target="#fig_1">4a</ref>. To avoid ambiguity, we end each string with an implicit character. Thus in the trie, all leaf nodes are associated with a complete query. Internal nodes do not represent complete strings. For each node in the trie, we store the largest probability among all queries represented by its descendant leaf nodes. As this represents the largest value among all queries starting with the prefix associated with the node, we can apply it an admissible heuristic function for A* search. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">A* Search</head><p>We use the A* search algorithm to find the top corrected query completions for the prefix ̅ , given the query trie and transformation model . We represent each intermediate search path as a quadruplet &lt;Pos, Node, Hist, Prob&gt;, corresponding to the current position in the query prefix ̅, the current node in trie , the transformation history so far, and the probability of this search path, respectively. The full algorithm is presented Figure <ref type="figure" target="#fig_2">5</ref>.</p><p>Input: Query trie , transformation model , integer , query prefix ̅ Output: Top completion suggestions of ̅  The algorithm works by maintaining a priority queue of intermediate search paths, ranked by decreasing probabilities. We initialize the queue with the initial path &lt;0, T.Root, [], 1&gt; (line C). While there is still a path on the queue, we dequeue it and check if there are still characters unaccounted for in the input prefix ̅ (lines F). If so, we iterate over all transfeme expansions that transform substrings starting from the current node in the trie to substrings yet unaccounted for in the query prefix (line G). For each transfeme expansion, we add a corresponding path to the trie (line L). The probability of the path is updated to include adjustments to the heuristic future score and the probability of the transfeme given the previous history (line K).</p><formula xml:id="formula_18">A B C D E F G H I J K L M N O P Q R S T U V W X Y List l = new</formula><p>As we expand the search path, we will eventually reach a point where all the characters in the input query have been consumed. The first path in the search that meets this criterion represents a partial correction to the partial input query ̅. At this point, the search transitions from correcting potential errors in the partial input to extending the partial correction to complete queries. In this scenario (line M), if the path is associated with a leaf node in the trie (line N), indicating that we have reached the end of a complete query, we add the corresponding query to the suggestion list (line O) and return if we have sufficient suggestions (line P). Otherwise, we iterate over all transfemes that extend from the current node (line S) and add them to the priority queue (line X). As the transformation score is not affected by extensions to the partial query, we only update the score to reflect the changes in the heuristic future score (line W). When we run out of search paths to expand, we return the current list of correction completions (line Y).</p><p>The heuristic future score we use in the A* algorithm, as applied in line K and W, is the probability value stored with each node in the trie. As this value represents the largest probability among all queries reachable from this path, it is an admissible heuristic that guarantees that the algorithm will indeed find the top suggestions.</p><p>One problem with this heuristic function is that it does not penalize the untransformed part of the input query. Therefore, we can design a better heuristic by taking into consideration the upper bound of the transformation probability ( ). Formally,</p><formula xml:id="formula_19">( ) ( ) ( , | |-| )<label>(19)</label></formula><p>where , | |-is the substring of from position π.Pos to | |. For each query, we pre-compute the second maximization in the equation for all positions of using dynamic programming.</p><p>The A* search algorithm can also be configured to perform exact match for offline spelling correction by simply substituting the probabilities in line W with line K. In effect, we continue to penalize transformations involving additional unmatched letters even after finding a prefix match.</p><p>It is worth noting that a search path can theoretically grow to infinite length, as is allowed to appear as either the source or target of a transfeme. In practice, this does not happen as the probability of such transformation sequences will be very low and will not be further expanded in the search algorithm.</p><p>A translation model with larger parameter ( bounds the length of transfemes) significantly increases the number of potential search paths. As we need to consider all possible transfemes with length less or equal to when expanding each path, models with larger are less efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Pruning</head><p>To further improve the efficiency of A* search, we need to limit the search space and prune unpromising paths early. In practice, carefully designed beam pruning methods can usually achieve significant improvement in efficiency without causing much loss in accuracy. In our work, we employ two pruning techniques: absolute pruning and relative pruning. For absolute pruning, we limit the number of paths to be explored at each position in the target query . As mentioned earlier, the complexity of our search algorithm is theoretically unbounded due to transfemes. However, by applying absolute pruning, we can bound the complexity of the algorithm by (| | ), where is the number of paths allowed at each position in .</p><p>With relative pruning, we only explore the paths that have probabilities higher than a certain percentage of the maximum probability at each position. The threshold values are carefully designed to achieve the best efficiency without causing a significant drop in accuracy. In practice we find relative pruning to be generally more effective for pruning unpromising paths. In our system, we make use of both absolute pruning and relative pruning to improve search efficiency and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Thresholding</head><p>From the perspective of user interface, it is not always a good idea to show a predefined number of suggestions for every query. Showing more suggestions incurs a cost, as users spend more time looking at them instead of completing their task. Moreover, showing irrelevant suggestions risks annoying users. Therefore, we need to make a binary decision for each suggestion on whether it should be shown to the user. Ideally, we want to measure the distance between the target query and the suggested correction . The larger the distance, the more risk we take to include it in the suggestions. One way to approximate the distance is to compute the log of the inverse transformation probability, averaged over the number of characters in the query:</p><formula xml:id="formula_20">( ) | | ( )<label>(20)</label></formula><p>This risk function is not very effective in practice, as the input query usually consists of several words, of which only one is misspelled. It is unintuitive to average the risk over all letters in the query. Instead, we can first segment into words and measure the risk at the word level. Specifically, we measure the risk of each word separately using the above formula and define the final risk function as the fraction of words in having a risk value above a given threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENT 6.1 Datasets</head><p>Our primary focus in this work is to build a transformation model that is able to capture all the misspelling behaviors of users. To obtain such behaviors, we make use of the click logs of search engine recourse links. Recourse links are provided when the offline correction mechanisms of search engines detect a potential misspelling. For example, in Google (Figure <ref type="figure">6a</ref>), a recourse link is shown in the sentence "Did you mean: important". When the user clicks on this link, it indicates that the user agrees with the correction. Therefore, the search engine will use the suggested query to rerun the search. Similarly recourse links are provided in Bing as well (Figure <ref type="figure">6b</ref>). By recording such clicks, we accumulate a set of high quality corrections that represent real user spelling behaviors.</p><p>It is worth noting that although the recourse links are provided by an offline spelling correction system, it does not mean that our ability will be limited to that of the offline system. First, our model captures the underlying patterns of spelling corrections instead of memorizing corrections at the word or query level. For instance, in the example from Figure <ref type="figure">6</ref>, a possible pattern is that im tends to be misspelled as in. Second, our logs consist of recourse link clicks from multiple sites. As the spellers of different search engines behave differently, we can learn from a diverse set of correction pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6. Examples of recourse links</head><p>There are also other ways to obtain records of spelling corrections. For example, by analyzing the webpage metadata for near-miss spellings, such those between title and anchor text, we can extract possible spelling corrections. Similarly, such corrections can also be obtained using click-through data from the query log, where a query-document mismatch would indicate a spelling error. In our work, we view the extraction of correction records as a logical step that precedes transformation modeling. Our model can be easily extended to incorporate all sources of spelling correction pairs.</p><p>Our dataset for training the transformation model contains 1.4 million recourse link clicks. The statistics of the training data are shown in Table <ref type="table" target="#tab_2">2</ref>. Around 80% of all queries and 70% of all unique queries are correctly spelled. 1/10 of the training data is held out for parameter tuning. The query log we use for estimating the query popularity model consists of 21 million unique queries. Our test set is a human annotated set which contains 9,959 unique queries. Table <ref type="table">3</ref> provides the statistics of the test data. The distribution over correctly spelled and misspelled queries is similar to that of the training data. 1/10 of the test data is also held out for tuning additional parameters, e.g. the coefficient for the mixture model. The remainder of the test queries is referred to as "all queries" in our evaluation results. The subset of misspelled queries within all queries is referred to as "misspelled queries".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3. Statistics of the test data</head><p>Correctly Spelled Misspelled Total Unique 7585 (76%) 2374 (24%) 9959</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation Metrics</head><p>We evaluate our methods with the following metrics: R@N: Recall@N is the number of correct suggestions in the top ranked N suggestions generated by the system divided by the total number of suggestions in the ground truth. Since in our ground truth, each query has exactly one correction, the total number of suggestions is the same as the number of queries. Intuitively, Recall@N indicates the percentage of queries that the system can correct within the top N suggestions. Therefore, it is a very natural measurement for performance of correction. We take R@1 as our primary evaluation metric in experiment. Recall@N on all queries is also referred to as accuracy in other works <ref type="bibr" target="#b10">[12]</ref>.</p><p>P@N: Precision@N is the number of correct suggestions in the top ranked N suggestions generated by the system divided by the smaller value of N or the total number of suggestions generated by the system. Precision reveals the quality of suggestions generated by the system. Penalty is given to generating more incorrect suggestions. Note that this definition is different from another widely used definition of P@N, where the denominator is fixed to be N. Our definition can be interpreted as the precision of a system that limits its number of outputs to N at most. It is also worth noting that while the micro average and macro average for recall are the same, it is not the case for precision. For precision, we take the micro average because for queries where the system provides no suggestion, precision is not well defined.</p><p>R@N and P@N are metrics for measuring offline spelling correction. We use these metrics to evaluate our system in the exact match mode. Next, we introduce two metrics for measuring the performance of online spelling correction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MKS:</head><p>Minimal Keystrokes measures the minimal number of key presses the user has to make in order to issue the target search query. This metric simulates the scenario of users entering queries to search engines. Suppose the user's query is inportan and the correct query is important. The user types in each letter in inportan sequentially. In the case that no suggestion is available, the user types in all the letters in inportan and presses the Enter key. Then the user can click on the recourse link provided by the offline speller. Therefore, the total number of keystrokes the user makes is the length of inportan, plus 1 for the Enter key, and 1 for the recourse link click. When suggestions are provided while the user is typing, she can use arrow keys to select a query from the suggestion list. For example, after typing in inpo, the user sees that important appears at the fifth position in the suggestion list. Thus, she can select the query by pressing the Down Arrow key 5 times, followed by the Enter key. In this case, the number of keystrokes is the number of letters the user enters (4) plus the number of arrow keys the user hits (5), plus 1 for the Enter key. If the user continues typing the rest of the query, she may see important increase to rank one for the input inpor. In this case, the number of keystrokes is 5+1+1=7, which is the minimal number of keystrokes (MKS). A good correction mechanism should have low MKS. In our experiments, we consider superstrings of the target query as positive matches, too. That is, in the case that "important people" is suggested instead of "important", we still treat it as a match.</p><p>PMKS: PMKS refers to penalized MKS, which adds a penalty to MKS for each suggestion generated by the system, as it takes effort for users to examine them for correctness. In this work we heuristically assign 0.1 keystrokes as the penalty for showing each suggestion. Thus, reading each query suggestion costs one tenth the effort of pressing a key. The essential idea of minimizing effort in MKS and PMKS is of independent research interest and could be applied to a wide range of research studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Experimental Results</head><p>In this subsection, we study the performance of our proposed system. We conduct all experiments on both the all queries and misspelled queries test sets to demonstrate the overall performance as well as the ability to handle misspelled queries.</p><p>We first compare our system with existing baselines in Table <ref type="table" target="#tab_3">4</ref>.</p><p>The first baseline we include is the edit distance model used by Chaudhuri and Kaushik <ref type="bibr" target="#b4">[6]</ref>. To the best of our knowledge, this is the only existing research study on online spelling correction. Our system outperforms the edit distance model in terms of all evaluation metrics. Significance test (t-test) shows that the improvement of our system is significant (p-value &lt; 0.05) for all measurements except R@10. This indicates that most misspellings are not very severe; therefore the edit distance model is able to rank the best correction among the top 10 suggestions. However, the edit distance model is not able to further distinguish corrections within the same edit distance. We further observe that although we see a big gap in R@1 for misspelled queries, the overall performance difference for all queries is less than that of the misspelled queries. This is expected as the edit distance model will always rank identical transformation on top (if it exists in the query log).</p><p>We also include Google's online query spelling suggestions 1 as a baseline. As it is unclear how Google's online spelling suggestion can be configured to run in exact match mode, we only measure 1 Based on results collected on August 4, 2010.</p><p>its performance with respect to the online correction metric, i.e. MKS. Not surprisingly, Google outperforms the simple editdistance model. On average users save 0.38 keystrokes per query using Google's spelling suggestions over that of the edit distance model. For misspelled queries, nearly 1 keystroke is saved. Yet, our system further outperforms Google's suggestion system on MKS with a statistically significant 1.1 and 1.5 keystrokes savings on all queries and misspelled queries, respectively. It is worth noting that a larger search space (query log in our case) may result in worse performance. Since the size of Google's search space is unknown, we cannot jump to the conclusion that our system outperforms Google's spelling suggestion system. We also see in this experiment that the MKS metric is fairly consistent with Recall. Higher recall values always correspond to lower MKS. This validates the use of MKS as a performance metric.</p><p>To further understand how the proposed method works, we study the performance of the transformation model with different configurations of and . Figure <ref type="figure" target="#fig_4">7</ref> shows the effect of the transfeme Markov order at and . As we increase from 1 to 2, we see a consistent increase in performance; but from 2 to 3, the performance decreased instead. This is contradictory with our intuition that higher order models result in better performance. We believe that this is because higher order models are more likely to suffer from data sparseness. Thus, with more training data, we may find higher order models to further improve the performance over . We also observe that for a fixed , increasing actually decreases the performance. We hypothesize that this may be due to overfitting, as increasing significantly increases the number of model parameters. As larger also significantly increases the cost of search, it is impractical for realtime scenarios. Under the current setting, our best result is achieved with</p><p>. Thus for all subsequent experiments, we fix the configuration to .</p><p>To confirm the effect of smoothing, we experiment with two smoothing methods and compare their performance. In Figure 8 we see that absolute discounting (AD) outperforms Jelinek-Mercer (JM) smoothing over every evaluation metric for both the all queries and misspelled queries test sets. This is in line with previous language modeling research that found discounting based smoothing to outperform simple interpolation techniques. This experiment confirms our hypothesis that employing proper smoothing methods substantially increases the performance of the transformation model.</p><p>We present the effectiveness of our proposed methods for avoiding over correction in Table <ref type="table">5</ref>. As we can see, the nonmixture model, which is trained with misspelled queries only, performs well for misspelled queries. However, the overall performance is not good because it tends to alter queries that are already correctly spelled. Both the data mixture and model mixture approaches improve the overall performance by reducing such overcorrections. For the all queries set, they perform equally well. For misspelled queries, model mixture performs just as well as the non-mixture model. However the performance of the data mixture approach drops significantly. From an application perspective, it is the misspelled queries for which users need suggestions the most. Users are able to enter queries that they can spell no matter what our system suggests. In this sense, the model mixture approach is more preferable than the data mixture approach. Moreover, by estimating the two models separately, the model mixture approach can be updated more easily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5. Performance study on overcorrection</head><p>All Queries Misspelled Queries R@1 R@10 MKS R@1 R@ In Table <ref type="table" target="#tab_7">8</ref>, we study the effect of the proposed thresholding method for pruning irrelevant suggestions. As we can see, with suggestion pruning, the performance of online spelling correction substantially increases for both the all queries and misspelled queries sets in terms of P@1, P@10 and PMKS. This verifies the effectiveness of our proposed thresholding method. But in terms of R@1, R@10 and MKS, the performance actually decreased. The reason behind this pattern is that the first set of metrics (P@1, P@10 and PMKS) assigns penalty for showing irrelevant suggestions, while the second set of metrics does not. In fact, any pruning of suggestions can only decrease the recall, as some correct suggestions may be pruned by mistake. From our perspective, showing too many irrelevant corrections has a strong negative effect on the query completion user experience, increasing the risk of losing users. Given that the recall did not significantly decrease, we prune suggestions using risk thresholding in the implementation of our system.</p><p>Finally, we address the efficiency of our approach. From our experiments, we observe that although a better heuristic function can reduce the running time of the search algorithm, beam pruning is still required to achieve practical performance. In Figure <ref type="figure" target="#fig_6">9</ref> we plot the performance and running times for different relative beam pruning thresholds. Based on our experiments on an unoptimized implementation, we observe that as we relax the pruning threshold, the running time increases exponentially.</p><p>However, the increase in R@1 is slow and ceases beyond a relative threshold of . In Table <ref type="table" target="#tab_5">6</ref> we list some example correction pairs identified by our system. None of these input queries are in the training corpus. As we can see, our method is capable of capturing various kinds of spelling errors for multiple word phrases. By updating the query language model frequently, we can keep our online spelling correction system up-to-date with the latest query language.   ) is much smaller than ( ). But with , ( | ) is significantly larger than ( | ). This is desirable as is a more common mistake (e.g. "haul" vs "hual") than .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>This paper addresses the problem of online spelling correction for search queries by adopting a generative model for query correction. We first propose a transfeme based transformation model that is capable of capturing users' spelling behavior. We estimate the transformation model using clicks on search engine recourse links, which represent user confirmed query misspellings. Next, we study various techniques to optimize the effectiveness of the transformation model.</p><p>To efficiently retrieve the query corrections with the highest probability according to the generative model, we propose the use of an algorithm based on A* search. The A* search algorithm is configured to deal with partial queries, so that online search is possible. We study different pruning and thresholding methods to improve the efficiency of the A* search.</p><p>Finally, we propose two evaluation metrics for online spelling correction, minimal keystrokes and penalized minimal keystrokes, based on the idea of minimal effort cost for users. We conduct extensive experiments and conclude that the proposed method is both effective and efficient for the task of online spelling correction.</p><p>For future work, we plan to explore the use of other sources of spelling correction pairs to more robustly estimate the transformation models. For example, we will consider the use of webpage metadata, including title and anchor texts, to extract correction pairs. We also plan to extend our model by incorporating a large scale language model <ref type="bibr" target="#b16">[18]</ref> so that we can suggest query corrections that have never been seen before. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparing transformations with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Trie with highest probabilities</figDesc><graphic coords="5,356.75,563.50,162.30,137.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A* search algorithm for online spelling correction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Performance with varying and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Performance of transformation models with different smoothing methods</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: R@1/Running time vs. pruning threshold</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Types of misspellings</head><label>1</label><figDesc>summarizes different types of misspellings and provides examples of each.</figDesc><table><row><cell>Cause</cell><cell>Misspelling</cell><cell>Correction</cell></row><row><cell>Typing quickly</cell><cell>exxit</cell><cell>exit</cell></row><row><cell></cell><cell>mispell</cell><cell>misspell</cell></row><row><cell>Keyboard adjacency</cell><cell>importamt</cell><cell>important</cell></row><row><cell>Inconsistent rules</cell><cell>concieve</cell><cell>conceive</cell></row><row><cell></cell><cell>conceirge</cell><cell>concierge</cell></row><row><cell>Ambiguous word breaking</cell><cell>silver light</cell><cell>silverlight</cell></row><row><cell>New words</cell><cell>kinnect</cell><cell>kinect</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 . Statistics of training data</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell>Correctly Spelled</cell><cell>Misspelled</cell><cell>Total</cell></row><row><cell>Unique</cell><cell>101,640 (70%)</cell><cell>44,226 (30%)</cell><cell>145,866</cell></row><row><cell>Total</cell><cell>1,126,524 (80%)</cell><cell>283,854 (20%)</cell><cell>1,410,378</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 . Comparison of performance with baseline systems</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>All Queries</cell><cell></cell><cell cols="3">Misspelled Queries</cell></row><row><cell></cell><cell cols="3">R@1 R@10 MKS</cell><cell cols="3">R@1 R@10 MKS</cell></row><row><cell cols="2">EditDist 0.899</cell><cell>0.973</cell><cell cols="2">13.39 0.579</cell><cell>0.887</cell><cell>14.53</cell></row><row><cell>Google</cell><cell>N/A</cell><cell>N/A</cell><cell>13.01</cell><cell>N/A</cell><cell>N/A</cell><cell>13.49</cell></row><row><cell cols="2">Proposed 0.918</cell><cell>0.976</cell><cell cols="2">11.86 0.677</cell><cell>0.900</cell><cell>11.96</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 . Examples suggestions</head><label>6</label><figDesc></figDesc><table><row><cell>Input Query</cell><cell>Top Suggestion</cell></row><row><cell>milk shak</cell><cell>milkshake recipes</cell></row><row><cell>hwo to tain ur dra</cell><cell>how to train your dragon</cell></row><row><cell>alice on wander land</cell><cell>alice in wonderland</cell></row><row><cell>mision inpos</cell><cell>mission impossible</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 . Examples of transfeme probabilities</head><label>7</label><figDesc>To further understand the internal mechanism of our model, we list some transfeme probabilities in Table7. Clearly, for ,</figDesc><table><row><cell>(</cell><cell>)</cell><cell>0.0001</cell><cell>(</cell><cell>|</cell><cell>)</cell><cell>0.0006</cell></row><row><cell>(</cell><cell>)</cell><cell>0.0002</cell><cell>(</cell><cell>|</cell><cell>)</cell><cell>0.2</cell></row><row><cell>(</cell><cell>)</cell><cell>0.002</cell><cell>(</cell><cell>|</cell><cell>)</cell><cell>0.007</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 . Effect of Pruning</head><label>8</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">all queries</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">misspelled queries</cell><cell></cell><cell></cell></row><row><cell></cell><cell>R@1</cell><cell>R@10</cell><cell>P@1</cell><cell>P@10</cell><cell>MKS</cell><cell>PMKS</cell><cell>R@1</cell><cell>R@10</cell><cell>P@1</cell><cell>P@10</cell><cell>MKS</cell><cell>PMKS</cell></row><row><cell>w/ pruning</cell><cell>0.916</cell><cell>0.969</cell><cell>0.927</cell><cell>0.304</cell><cell>11.87</cell><cell>19.42</cell><cell>0.669</cell><cell>0.875</cell><cell>0.704</cell><cell>0.241</cell><cell>12.00</cell><cell>19.21</cell></row><row><cell>w/o pruning</cell><cell>0.918</cell><cell>0.976</cell><cell>0.920</cell><cell>0.262</cell><cell>11.86</cell><cell>19.60</cell><cell>0.677</cell><cell>0.900</cell><cell>0.685</cell><cell>0.204</cell><cell>11.96</cell><cell>19.56</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>March 28-April 1, 2011, Hyderabad, India</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A gentle tutorial on the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<idno>ICSI-TR-97-021. 1997</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint-sequence models for graphemeto-phoneme conversion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bisani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Online expansion of rare queries for sponsored search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ciccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Josifovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Extending auto-completion to tolerate errors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaushik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving query spelling correction using web search results</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Conditional and joint models for grapheme-tophoneme conversion</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurospeech</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spelling correction as an iterative process that exploits the collective knowledge of web users</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cucerzan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A technique for computer detection and correction of spelling errors</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Damerau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication of ACM</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The reactive keyboard: a predictive typing aid</title>
		<author>
			<persName><forename type="first">J</forename><surname>Darragh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A large scale ranker-based system for search query spelling correction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Micol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploring distributional similarity based models for query spelling correction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A contextual postprocessing system for error correction using binary ngrams</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Rieseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning phrasebased spelling error models from clickthrough data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Micol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Quirk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hidden Markov models for grapheme to phoneme conversion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurospeech</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-style language model for web scale information retrieval</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
