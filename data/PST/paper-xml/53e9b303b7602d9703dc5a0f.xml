<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Bayesian Networks to Analyze Expression Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nir</forename><surname>Friedman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michal</forename><surname>Linial</surname></persName>
							<email>michall@leonardo.ls.huji.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Life Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Iftach</forename><surname>Nachman</surname></persName>
							<email>iftach@cs.huji.ac.il</email>
							<affiliation key="aff2">
								<orgName type="department">Center for Neural Computation &amp; School of Computer Science and Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dana</forename><surname>Pe'er</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Hebrew University Jerusalem</orgName>
								<address>
									<postCode>91904</postCode>
									<country key="IL">ISRAEL</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Bayesian Networks to Analyze Expression Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">216264F0F363EC84FE21F5E65F306933</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>DNA hybridization arrays simultaneously measure the expression level for thousands of genes. These measurements provide a "snapshot" of transcription levels within the cell. A major challenge in computational biology is to uncover, from such measurements, gene/protein interactions and key biological features of cellular systems.</p><p>In this paper, we propose a new framework for discovering interactions between genes based on multiple expression measurements. This framework builds on the use of Bayesian networks for representing statistical dependencies. A Bayesian network is a graph-based model of joint multi-variate probability distributions that captures properties of conditional independence between variables. Such models are attractive for their ability to describe complex stochastic processes, and for providing clear methodologies for learning from (noisy) observations. We start by showing how Bayesian networks can describe interactions between genes. We then present an efficient algorithm capable of learning such networks and a statistical method to assess our confidence in their features. Finally, we apply this method to the S. cerevisiae cell-cycle measurements of Spellman et al. [35]   to uncover biological features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A central goal of molecular biology is to understand the regulation of protein synthesis and its reactions to external and internal signals. All the cells in an organism carry the same genomic data, but their protein makeup can be drastically different both temporally and spatially, due to regulation. Protein synthesis is regulated by many mechanisms at its different levels. These include mechanisms for controlling transcription initiation, RNA splicing, mRNA transport, translation initiation, post-translational modifications, and degradation of mRNA/protein. One of the main junctions at which regulation occurs is mRNA transcription. A major role in</p><p>We are therefore able to focus on interactions whose signal in the data is strong.</p><p>Bayesian networks are a promising tool for analyzing gene expression patterns. First, they are particularly useful for describing processes composed of locally interacting components; that is, the value of each component directly depends on the values of a relatively small number of components. Second, statistical foundations for learning Bayesian networks from observations, and computational algorithms to do so are well understood and have been used successfully in many applications. Finally, Bayesian networks provide models of causal influence: Although Bayesian networks are mathematically defined strictly in terms of probabilities and conditional independence statements, a connection can be made between this characterization and the notion of direct causal influence. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>The remainder of this paper is organized as follows. In Section 2, we review key concepts of Bayesian networks, learning them from observations, and using them to infer causality. In Section 3, we describe how Bayesian networks can be applied to model interactions among genes and discuss the technical issues that are posed by this type of data. In Section 4, we apply our approach to the gene-expression data of Spellman et al. <ref type="bibr" target="#b34">[35]</ref>, analyzing the statistical significance of the results and their biological plausibility. Finally, in Section 5, we conclude with a discussion of related approaches and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bayesian Networks 2.1 Representing Distributions with Bayesian Networks</head><p>Consider a finite set X = fX1;:::;Xng of random variables where each variable Xi may take on a value xi from the domain Val(Xi). In this paper, we focus on finite domains, though much of the following holds for infinite domains, such as continuous valued random variables. We use capital letters, such as X; Y; Z, for variable names and lowercase letters x; y; z to denote specific values taken by those variables. Sets of variables are denoted by boldface capital letters X;Y ; Z, and assignments of values to the variables in these sets are denoted by boldface lowercase letters x; y; z. We denote I(X; Y j Z) to mean X is independent of Y conditioned on Z.</p><p>A Bayesian network is a representation of a joint probability distribution. This representation consists of two components. The first component, G, is a directed acyclic graph whose vertices correspond to the random variables X1; : : : ; Xn. The second component describes a conditional distribution for each variable, given its parents in G. Together, these two components specify a unique distribution on X1; : : : ; Xn.</p><p>The graph G represents conditional independence assumptions that allow the joint distribution to be decomposed, economizing on the number of parameters. The graph G encodes the Markov Assumption:</p><p>(*) Each variable Xi is independent of its non-descendants, given its parents in G.</p><p>By applying the chain rule of probabilities and properties of conditional independencies, any joint distribution that satisfies (*) can be decomposed in the product form P(X1; : : :</p><formula xml:id="formula_0">; Xn) = n Y i=1 P(XijPa(Xi));</formula><p>where Pa(Xi) is the set of parents of Xi in G. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of a graph G, lists the Markov independencies it encodes, and the product form they imply.</p><p>To specify a joint distribution, we also need to specify the conditional probabilities that appear in the product form. This is the second component of the network representation. This component describes distributions P(xijpa(Xi)) for each possible value xi of Xi, and pa(Xi) of Pa(Xi). In the case of finite valued variables, we can represent these conditional distributions as tables. Generally, Bayesian networks are flexible and can accommodate many forms of conditional distribution, including various continuous models.</p><p>Given a Bayesian network, we might want to answer many types of questions that involve the joint probability (e.g., what is the probability of X = x given observation of some of the other variables?) or independencies in the domain (e.g., are X and Y independent once we observe Z?). The literature contains a suite of algorithms that can answer such queries (e.g., see <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b30">31]</ref>), exploiting the explicit representation of structure in order to answer queries efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Equivalence Classes of Bayesian Networks</head><p>A Bayesian network structure G implies a set of independence assumptions in addition to (*). Let Ind(G) be the set of independence statements (of the form X is independent of Y given Z) that hold in all distributions satisfying these Markov assumptions. These can be derived as consequences of (*).</p><p>More than one graph can imply exactly the same set of independencies. For example, consider graphs over two variables X and Y . The graphs X ! Y and X Y both imply the same set of independencies (i.e., Ind(G) = ;). We say that two graphs G and G 0 are equivalent if Ind(G) = Ind(G 0 ).</p><p>This notion of equivalence is crucial, since when we examine observations from a distribution, we cannot distinguish between equivalent graphs. Results of <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b31">32]</ref> show that we can characterize equivalence classes of graphs using a simple representation. In particular, these results establish that equivalent graphs have the same underlying undirected graph but might disagree on the direction of some of the arcs. Theorem 2.1 <ref type="bibr" target="#b31">[32]</ref> Two graphs are equivalent if and only if their DAGs have the same underlying undirected graph and the same vstructures (i.e. converging directed edges into the same node, such as a ! b c).</p><p>Moreover, an equivalence class of network structures can be uniquely represented by a partially directed graph (PDAG), where a directed edge X ! Y denotes that all members of the equivalence class contain the arc X ! Y ; an undirected edge X-Y denotes that some members of the class contain the arc X ! Y , while others contain the arc Y ! X. Given a directed graph G, the PDAG representation of its equivalence class can be constructed efficiently <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning Bayesian Networks</head><p>The problem of learning a Bayesian network can be stated as follows. Given a training set D = fx 1 ; : : : ; x N g of independent in- stances of X, find a network B = hG; i that best matches D.</p><p>(More precisely, we search for an equivalence class of networks that best matches D.) The common approach to this problem is to introduce a statistically motivated scoring function that evaluates each network with respect to the training data, and to search for the optimal network according to this score.</p><p>A commonly used scoring function is the Bayesian score (see <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21]</ref>  The network structure also implies that the joint distribution has the product form P(A; B; C; D;E) = P(A)P(BjA;E)P(CjB)P(DjA)P(E)</p><p>where C is a constant independent of G and</p><formula xml:id="formula_1">P(D j G) = Z P(D j G; )P( j G)d</formula><p>is the marginal likelihood which averages the probability of the data over all possible parameter assignments to G. The particular choice of priors P(G) and P( j G) for each G determines the exact Bayesian score. Under mild assumptions on the prior probabilities, this scoring metric is asymptotically consistent: Given a sufficiently large number of samples, graph structures that exactly capture all dependencies in the distribution, will receive, with high probability, a higher score than all other graphs <ref type="bibr" target="#b18">[19]</ref>. This means, that given a sufficiently large number of instances in large data sets, learning procedures can pinpoint the exact network structure up to the correct equivalence class. Heckerman et al. <ref type="bibr" target="#b20">[21]</ref> present a family of priors, called BDe priors, that satisfy two important requirements: First, these priors are structure equivalent, i.e., if G and G 0 are equivalent structures they are guaranteed to have the same score. Second, the priors are decomposable. That is, the score can be rewritten as the sum S BDe (G : D) = X i ScoreContribution BDe (Xi; Pa(Xi) : D);</p><p>where the contribution of every variable Xi to the total network score depends only on its own value and the values of its parents in G. These two properties are satisfied for BDe priors when all instances x `in D are complete-that is, they assign values to all the variables in X.</p><p>Once the prior is specified (we use an un-informative prior in our experiments) and the data is given, learning amounts to finding the structure G that maximizes the score. This problem is known to be NP-hard <ref type="bibr" target="#b7">[8]</ref>, thus we resort to heuristic search. The decomposition of the score is crucial for this optimization problem. A local search procedure that changes one arc at each move can efficiently evaluate the gains made by adding, removing or reversing a single arc. An example of such a procedure is a greedy hill-climbing algorithm that at each step performs the local change that results in the maximal gain, until it reaches a local maximum. Although this procedure does not necessarily find a global maximum, it does perform well in practice. Examples of other search methods that advance using one-arc changes include beam-search, stochastic hill-climbing, and simulated annealing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Learning Causal Patterns</head><p>A Bayesian network is a model of dependencies between multiple measurements. We are also interested in modeling the process that generated these dependencies. Thus, we need to model the flow of causality in the system of interest (e.g., gene transcription). A causal network is a model of such causal processes. A causal network is similar to a Bayesian network (i.e., a DAG where each node represents a random variable along with a local probability model for each node), the difference being it interprets the parents of a variable as its immediate causes.</p><p>We can relate causal networks and Bayesian networks, by assuming the Causal Markov Assumption: given the values of a variable's immediate causes, it is independent of its earlier causes. When the casual Markov assumption holds, the causal network satisfies the Markov independencies of the corresponding Bayesian network, thus allowing us to treat causal networks as Bayesian networks. For example, this assumption is a natural one in models of genetic pedigrees: once we know the genetic makeup of the individual's parents the genetic makeup of her ancestors are not informative about her own genetic makeup.</p><p>The main difference between causal and Bayesian networks, is that a causal network models not only the distribution of the observations, but also the effects of interventions. If X causes Y , then manipulating the value of X (i.e., setting it to another value in such a way that the manipulation itself does not affect the other variables), affects the value of Y . On the other hand, if Y is a cause of X, then manipulating X will not affect Y . Thus, although the Bayesian networks X ! Y and X Y are equivalent, as causal networks they are not.</p><p>When can we learn a causal network from observations? This issue received a thorough treatment in the literature <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36]</ref>. From observations alone, we cannot distinguish between causal networks that specify the same independence assumptions, i.e., belong to the same equivalence class. When learning an equivalence class (PDAG) from the data, we can conclude that the true causal network is possibly any one of the networks in this class. If a directed arc X ! Y is in the PDAG, then all the networks in the equivalence class agree that X is an immediate cause of Y . Thus, we infer the causal direction of the interaction between X and Y .</p><p>We stress that we can infer such causal relations without any experimental intervention (e.g. knockout and over-expressions) among our samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Applying Bayesian Networks to Expression Data</head><p>In this section we describe our approach to analyzing gene expression data using Bayesian network learning techniques. We model the expression level of each gene as a random variable. In addition, other attributes that affect the system can be modeled as random variables. These can include a variety of attributes of the sample, such as experimental conditions, temporal indicators (i.e., the time/stage that the sample was taken from), background variables (e.g., which clinical procedure was used to get a biopsy sample), and exogenous cellular conditions.</p><p>By learning a Bayesian network based on the statistical dependencies between these variables, we can answer a wide range of queries about the system. For example, does the expression level of a particular gene depend on the experimental condition? Is this dependence direct, or indirect? If it is indirect, which genes mediate the dependency? We now describe how one can learn such a model from the gene expression data. Many important issues arise when learning in this domain. These involve statistical aspects of interpreting the results, algorithmic complexity issues in learning from the data, and preprocessing the data.</p><p>Most of the difficulties in learning from expression data revolve around the following central point: Contrary to previous applications of learning Bayesian networks, expression data involves transcript levels of thousands of genes while current data sets contain at most a few dozen samples. This raises problems in computational complexity and the statistical significance of the resulting networks. On the positive side, genetic regulation networks are sparse, i.e., given a gene, it is assumed that no more than a few dozen genes directly affect its transcription. Bayesian networks are especially suited for learning in such sparse domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Representing Partial Models</head><p>When learning models with many variables, small data sets are not sufficiently informative to significantly determine that a single model is the "right" one. Instead, many different networks should be considered as reasonable explanation of the given the data. From a Bayesian perspective, we say that the posterior probability over models is not dominated by a single model (or equivalence class of models). <ref type="foot" target="#foot_0">1</ref> Our approach is to analyze this set of plausible (i.e., high-scoring) networks. Although this set can be very large, we might attempt to characterize features that are common to most of these networks, and focus on learning them.</p><p>Before we examine the issue of inferring such features, we briefly discuss two classes of features involving pairs of variables. While at this point we handle only pairwise features, it is clear that this analysis is not restricted to them, and in the future we are planning on examining more complex features.</p><p>The first type of features is Markov relations: Is Y in the Markov blanket of X? The Markov blanket of X is the minimal set of variables that shield X from the rest of the variables in the model. More precisely, X given its Markov blanket is independent from the remaining variables in the network. It is easy to check that this relation is symmetric: Y is in X's Markov blanket if and only if there is either an edge between them, or both are parents of another variable <ref type="bibr" target="#b30">[31]</ref>. In the context of gene expression analysis, a Markov relation indicates that the two genes are related in some joint biological interaction or process. Note, two variables in a Markov relation are directly linked in the sense that no variable in the model mediates the dependence between them. It remains possible that an unobserved variable (e.g., protein activation) is an intermediate in their interaction.</p><p>The second type of features is order relations: Is X an ancestor of Y in all the networks of a given equivalence class? That is, does the given PDAG contain a path from X to Y in which all the edges are directed? This type of feature does not involve only a close neighborhood, but rather captures a global property. Recall that under the assumptions of Section 2.4, learning that X is an ancestor of Y would imply that X is a cause of Y . However, these assumptions do not necessarily hold in the context of expression data. Thus, we view such a relation as an indication, rather than evidence, that X might be a causal ancestor of Y .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Estimating Statistical Con dence in Features</head><p>We now face the following problem: To what extent do the data support a given feature? More precisely, we want to estimate a measure of confidence in the features of the learned networks, where "confidence" approximates the likelihood that a given feature is actually true (i.e. is based on a genuine correlation and causation).</p><p>An effective, and relatively simple, approach for estimating confidence is the bootstrap method <ref type="bibr" target="#b13">[14]</ref>. The main idea behind to other models that are learned from gene expression data, such as clustering models.</p><p>the bootstrap is simple. We generate "perturbed" versions of our original data set, and learn from them. In this way we collect many networks, all of which are fairly reasonable models of the data. These networks show how small perturbations to the data can effect many of the features.</p><p>In our context, we use the bootstrap as follows:</p><p>For i = 1 : : : m (in our experiments, we set m = 200).</p><p>-Re-sample with replacement, N instances from D. Denote by Di the resulting dataset. -Apply the learning procedure on Di to induce a network structure Ĝi.</p><p>For each feature f of interest calculate</p><formula xml:id="formula_2">conf(f ) = 1 m m X i=1 f( Ĝi)</formula><p>where f(G) is 1 if f is a feature in G, and 0 otherwise.</p><p>We refer the reader to <ref type="bibr" target="#b15">[16]</ref> for more details, as well as large-scale simulation experiments with this method. These simulation experiments show that features induced with high confidence are rarely false positives, even in cases where the data sets are small compared to the system being learned. This bootstrap procedure appears especially robust for the Markov and order features described in section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">E cient Learning Algorithms</head><p>In section 2.3, we formulated learning Bayesian network structure as an optimization problem in the space of directed acyclic graphs. The number of such graphs is super-exponential in the number of variables. As we consider hundreds &amp; thousands of variables, we must deal with an extremely large search space. Therefore, we need to use (and develop) efficient search algorithms.</p><p>To facilitate efficient learning, we need to be able to focus the attention of the search procedure on relevant regions of the search space, giving rise to the Sparse Candidate algorithm <ref type="bibr" target="#b17">[18]</ref>. The main idea of this technique is that we can identify a relatively small number of candidate parents for each gene based on simple local statistics (such as correlation). We then restrict our search to networks in which only the candidate parents of a variable can be its parents, resulting in a much smaller search space in which we can hope to find a good structure quickly.</p><p>A possible pitfall of this approach is that early choices can result in an overly restricted search space. To avoid this problem, we devised an iterative algorithm that adapts the candidate sets during search. At each iteration n, for each variable Xi, the algorithms chooses the set C n i = fY1;:::;Ykg of variables which are the most promising candidate parents for Xi. We then search for Bn, an optimal network in which Pa Gn (Xi) C n i . The network found is then used to guide the selection of better candidate sets for the next iteration. We ensure that Bn monotonically improves in each iteration by requiring Pa G n?1 (Xi) C n i . The algorithm contin- ues until there is no change in the candidate sets.</p><p>We briefly outline our method for choosing C n i . We assign each Xj some score of relevance to Xi, choosing variables with the highest score. A natural score that measures the dependence between two variables is their mutual information denoted I(X;Y ). The following is an example that arises with such a score: Consider the network in Figure <ref type="figure" target="#fig_0">1</ref>. If I(B; D) &gt; I(B; E), for k = 2, E will be left out of C n B . Since A mediates the dependence between B and D, the network learned in this iteration will contain only A as B's parent. We can use this conditional independence to improve This graph shows a "local map" for the gene SVS1. The width (and color) of edges corresponds to the computed confidence level. An edge is directed if there is a sufficiently high confidence in the order between the pair genes connected by the edge. This local map shows that CLN2 seperates SVS1 from several other genes. Although there is a strong connection between CLN2 to all these genes, there are no other edges connecting them. This indicates that, with high confidence, these genes are conditionally independent given the expression level of CLN2. our candidate sets. A better score is the conditional mutual information, I(Xi; XjjPa G n?1 (Xi)). The score we actually use is an estimator of the conditional mutual information in the underlying distribution, that takes into account also the number of parameters needed to learn Xi's conditional probability.</p><p>We refer the reader to <ref type="bibr" target="#b17">[18]</ref> for more details on the algorithm and its complexity, as well as empirical results comparing its performance to traditional search techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discretization</head><p>In order to specify a Bayesian network model, we still need to define the local probability model for each variable. At the current stage, we choose to focus on the qualitative aspects of the data, and so we discretize gene expression values into three categories: ?1;0; and 1, depending whether the expression rate is significantly lower than, similar to, or greater than the respective control. The control expression level of a gene can be either determined experimentally (as in the methods of <ref type="bibr" target="#b11">[12]</ref>), or it can be set as the average expression level of the gene across experiments. The meaning of "significantly" is defined by setting a threshold to the ratio between measured expression and control. In our experiments we choose a threshold value of 0:5 in logarithmic (base 2) scale.</p><p>It is clear that by discretizing the measured expression levels we are loosing information. An alternative to discretization is using (semi)parametric density models for representing conditional probabilities in the networks we learn (e.g. <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30]</ref>). However, a bad choice of the parametric family can strongly bias the learning algorithm. We believe that discretization provides a reasonably unbiased approach for dealing with this type of data. We are currently exploring the appropriateness of several density models for this type of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Application to Cell Cycle Expression Patterns</head><p>We applied our approach to the data of Spellman et al. <ref type="bibr" target="#b34">[35]</ref>, containing 76 gene expression measurements of the mRNA levels of 6177 S. cerevisiae ORFs. These experiments measure six time series under different cell cycle synchronization methods. Spellman et al. <ref type="bibr" target="#b34">[35]</ref> identified 800 genes whose expression varied over the different cell-cycle stages. Of these, 250 clustered into 8 distinct clusters based on the similarity of expression profiles. We learned networks whose variables were the expression level of each of these 800 genes. Some of the robustness analysis was performed only on the set of 250 genes that appear in the 8 major clusters.</p><p>In learning from this data, we treat each measurement as a sample from a distribution, and do not take into account the temporal aspect of the measurement. Since it is clear that the cell cycle process is of temporal nature, we compensate by introducing additional variable denoting the cell cycle phase. This variable is forced to be a root in all the networks learned. Its presence allows to model dependency of expression levels on current cell cycle. <ref type="foot" target="#foot_1">2</ref>We used the Sparse Candidate algorithm with a 200-fold bootstrap in the learning process. The learned features show that we can recover intricate structure even from such small data sets. It is important to note that our learning algorithm uses no prior biological knowledge nor constraints. All learned networks and relations are based solely on the information conveyed in the measurements themselves. These results are available at our WWW site: http://www.cs.huji.ac.il/labs/compbio/expression. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Robustness Analysis</head><p>We performed a number of tests to analyze the statistical significance and robustness of our procedure. We carried most of these tests on the smaller 250 gene data set for computational reasons.</p><p>To test the credibility of our confidence assessment, we created a random data set by randomly permuting the order of the experiments independently for each gene. Thus for each gene the order was random, but the composition of the series remained unchanged. In such a data set, genes are independent of each other, and thus we do not expect to find "real" features. As expected, both order and Markov relations in the random data set have significantly lower confidence. We compare the distribution of confidence estimates between the original data set and the randomized set in Figure <ref type="figure" target="#fig_3">3</ref>. Clearly, the distribution of confidence estimates in the original data set have a longer and heavier tail in the high confidence region. The runs on the random data sets do not learn almost anything with a confidence level above 0.8, which leads us to believe that most features that are learned in the original data set with such confidence levels originate in true signals in the data. Also, the confidence distribution for the real dataset is concentrated closer to zero than the random distribution. This suggests that the networks learned from the real data are sparser.</p><p>Since the analysis was not performed on the whole S. cerevisiae genome, we also tested the robustness of our analysis to the addition of more genes, comparing the confidence of the learned features between the 250 and 800 gene datasets. Figure <ref type="figure" target="#fig_4">4</ref> compares feature confidence in the analysis of the two datasets. As we can see, there is a strong correlation between confidence levels of the features between the two data sets.</p><p>A crucial choice in our procedure is the threshold level used for discretization of the expression levels. the high confidence features to the choice of this threshold. This was tested by repeating the experiments using different threshold levels. Again, the graphs show a definite linear tendency in the confidence estimates of features between the different discretization thresholds. Obviously, this linear correlation gets weaker for larger threshold differences. We also note that order relations are much more robust to changes in the threshold than the Markov relations.</p><p>A valid criticism of our discretization method is that it penalizes genes whose natural range of variation is small: since we use a fixed threshold, we would not detect changes in such genes. A possible way to avoid this problem is to normalize the expression of genes in the data. That is, we rescale the expression level of each gene, so that the relative expression all genes have the same mean and variance. We note that analysis methods that use pearson correlation to compare genes, such as <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15]</ref>, are implicitly performing such a normalization. 3 When we discretize a normalized dataset, we are essentially rescaling the discretization factor differently for each gene, depending on its variance in the data. We tried this approach with several discretization levels, and got results comparable to our original discretization method. The 20 top Markov relations highlighted by this method were a bit different, but interesting and biologically sensible in their own right. The order relations were again more robust to the change of methods and discretization thresholds. A possible reason is that order relations depend on the network structure in a global manner, and thus can remain intact even after many local changes to the structure. The Markov relation, being a local one, is more easily disrupted. Since the graphs learned are extremely sparse, each discretization method "highlights" different signals in the data, which are reflected in the Markov relations learned.</p><p>In summary, although many of the results we report below (es- 3 An undesired effect of such a normalization is the amplification of measurement noise. If a gene has fixed expression levels across samples, we expect the variance in measured expression levels to be noise either in the experimental conditions or the measurements . When we normalize the expression levels of genes, we loose the distinction between such noise and true (i.e., significant) changes in expression levels.</p><p>In our experiments, we can safely assume this effect will not be too grave, since we only focus on genes that display significant changes across experiments. pecially order relations) are stable across the different experiments discussed in the previous paragraph, it is clear that our analysis is sensitive to the discretization method. In all the different discretization methods we tried, our analysis found interesting relationships in the data. Thus, the challange is to find alternative methods that can recover all these relationships in one analysis. We are currently working on learning with (semi)parametric density models that would circumvent the need for discretization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Order relations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Biological Analysis</head><p>We believe that the results of this analysis can be indicative of biological phenomena in the data. This is confirmed by our ability to predict sensible relations between genes of known function. We now examine several consequences that we have learned from the data. We consider, in turn, the order relations and Markov relations found by our analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Order Relations</head><p>The most striking feature of the high confidence order relations, is the existence of dominant genes. Out of all 800 genes only few seem to dominate the order (i.e., appear before many genes). The intuition is that these genes are indicative of potential causal sources of the cell-cycle process. Let Co(X;Y ) denote the confidence in X being ancestor of Y . We define the dominance score of X as P Y;Co(X;Y )&gt;t Co(X; Y ) k ; using the constant k for rewarding high confidence features and the threshold t to discard low confidence ones. These dominant genes are extremely robust to parameter selection for both t, k and the discretization cutoff of section 3.4. A list of the highest scoring dominating genes appears in table <ref type="table" target="#tab_0">1</ref>.</p><p>Inspection of the list of dominant genes reveals quite a few interesting features. Among the dominant genes are those directly involved in cell-cycle control and initiation. For example, CLN1, CLN2 and CDC5, whose functional relation has been established <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13]</ref>. Other genes, like MCD1 and RFA2, were found to be essential <ref type="bibr" target="#b19">[20]</ref>. These are clearly key genes in basic cell functions, involved in chromosome dynamics and stability (MCD1) and in nucleotide excision repair (RFA2). Most of the dominant genes encode nuclear proteins, and some of the unknown genes are also potentially nuclear: (e.g., YLR183C contains a forkhead-associated domain which is found almost entirely among nuclear proteins). Some of them are components of pre-replication complexes. Others (like RFA2,POL30 and MSH6) are involved in DNA repair. It is known that DNA repair is a prerequisite for transcription, and DNA areas which are more active in transcription, are also repaired more frequently <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>A few non nuclear dominant genes are localized in the cytoplasm membrane (SRO4 and RSR1). These are involved in the budding and sporulation process which have an important role in the cell-cycle. RSR1 belongs to the ras family of proteins, which are known as initiators of signal transduction cascades in the cell.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Markov Relations</head><p>Inspection of the top Markov relations reveals that most are functionaly related. A list of the top scoring relations can be found in table 2. Among these, all involving two known genes make sense biologically. When one of the ORFs is unknown careful searches using Psi-Blast <ref type="bibr" target="#b2">[3]</ref>, Pfam <ref type="bibr" target="#b33">[34]</ref> and Protomap <ref type="bibr" target="#b39">[40]</ref> can reveal firm homologies to proteins functionally related to the other gene in the pair. (e.g. YHR143W, which is paired to the endochitinase CTS1, is related to EGT2 -a cell wall maintence protein). Several of the unknown pairs are physically adjacent on the chromosome, and thus presumably regulated by the same mechanism (see <ref type="bibr" target="#b4">[5]</ref>), although special care should be taken for pairs whose chromosomal location overlap on complementary strands, since in these cases we might see an artifact resulting from cross-hybridization. Such analysis raises the number of biologically sensible pairs to 19/20.</p><p>There are some interesting Markov relations found that are beyond the limitations of clustering techniques. One such regulatory link is FAR1-ASH1: both proteins are known to participate in a mating type switch. The correlation of their expression patterns is low and <ref type="bibr" target="#b34">[35]</ref> cluster them into different clusters. Among the high confidence markov relations, one can also find examples of conditional indpendence, i.e., a group of highly correlated genes whose correlation can be explained within our network stucture. One such example involves the genes: CLN2,RNR3,SVS1,SRO4 and RAD41, their expression is correlated, in <ref type="bibr" target="#b34">[35]</ref> all appear in the same cluster. In our network CLN2 is with high confidence a parent of each of the other 4 genes, while no links are found between them. This suits biological knowledge: CLN2 is a central and early cell cycle control, while there is no clear biological relationship between the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discusion and Future Work</head><p>In this paper we presented a new approach for analyzing gene expression data that builds on the theory and algorithms for learning Bayesian networks. We described how to apply these techniques to gene expression data. The approach builds on two techniques that were motivated by the challanges posed by this domain: a novel search algorithm <ref type="bibr" target="#b17">[18]</ref> and an approach for estimating statistical confidence <ref type="bibr" target="#b15">[16]</ref>. We applied our methods to real expression data of Spellman et al. <ref type="bibr" target="#b34">[35]</ref>. Although, we did not use any prior knowledge, we managed to extract many biologically plausible conclusions from this analysis.</p><p>Our approach is quite different than the clustering approach used by <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35]</ref>, in that it attempts to learn a much richer structure from the data. Our methods are capable of discovering causal relationships, interactions between genes other than positive correlation, and finer intra-cluster structure. We are currently developing hybrid approaches that combine our methods with clustering algorithms to learn models over "clustered" genes.</p><p>The biological motivation of our approach is similar to work on inducing genetic networks from data <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b37">38]</ref>. There are two key differences: First, the models we learn have probablistic semantics. This better fits the stochastic nature of both the biological processes and noisy experimentation. Second, our focus is on extracting features that are pronounced in the data, in contrast to current genetic network approaches that attempt to find a single model that explains the data. We are currently working on improving methods for expression analysis by expanding the framework described in this work. Promising directions for such extentions are: (a) Developing the theory for learning local probability models that are capable of dealing with the continuous nature of the data; (b) Improving the theory and algorithms for estimating confidence levels; (c) Incorporating biological knowledge (such as possible regulatory regions) as prior knowledge to the analysis; (d) Improving our search heuristics; (e) Applying Dynamic Bayesian Networks ( <ref type="bibr" target="#b16">[17]</ref>) to temporal expression data.</p><p>Finally, one of the most exciting longer term prospects of this line of research is discovering causal patterns from gene expression data. We plan to build on and extend the theory for learning causal relations from data and apply it to gene expression. The theory of causal networks allows learning both from observational data and interventional data, where the experiment intervenes with some causal mechanisms of the observed system. In gene expression context, we can model knockout/overexpressed mutants as such interventions. Thus, we can design methods that deal with mixed forms of data in a principled manner (See <ref type="bibr" target="#b8">[9]</ref> for a recent work in this direction). In addition, this theory can provide tools for experimental design, that is, understanding which interventions are deemed most informative to determining the causal structure in the underlying system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>for complete description): S(G : D) = log P(G j D) = log P(D j G) + log P(G) + C An example of a simple Bayesian network structure. This network structure implies several conditional independence statements: I(A; E), I(B;D j A; E), I(C; A; D;E j B), I(D; B; C; E j A), and I(E; A; D).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of the graphical display of Markov features.This graph shows a "local map" for the gene SVS1. The width (and color) of edges corresponds to the computed confidence level. An edge is directed if there is a sufficiently high confidence in the order between the pair genes connected by the edge. This local map shows that CLN2 seperates SVS1 from several other genes. Although there is a strong connection between CLN2 to all these genes, there are no other edges connecting them. This indicates that, with high confidence, these genes are conditionally independent given the expression level of CLN2.</figDesc><graphic coords="5,66.53,54.41,213.03,213.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 2 illustrates the graphical display of results of this analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Histograms of confidence levels for the cell cycle data set, and the randomized data set. The histograms on the left are of order relations, and the ones on the right are of Markov relations. The histograms on the top row show the distribution of confidence levels in the interval 0; 1]. The histograms on the bottom row show the tails of these distributions for high-confidence features. These histograms are all based on the 250 genes data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison between significance levels with different number of genes in the analysis. Each relation is shown as a point, with the x-coordinate being its confidence in the the 250 genes data set and the y-coordinate the confidence in the 800 genes data set. The left figure shows order relation features, and the right figure shows Markov relation features; .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>List of dominant genes in the ordering relations (top 14 out of 30)</figDesc><table><row><cell cols="4">Gene/ORF Dominance # of descendent genes</cell><cell></cell></row><row><cell></cell><cell>Score</cell><cell>&gt; :8</cell><cell>&gt; :7</cell><cell>notes</cell></row><row><cell>YLR183C</cell><cell>551</cell><cell>609</cell><cell>708</cell><cell>Contains forkheaded assosiated domain, thus possibly nuclear</cell></row><row><cell>MCD1</cell><cell>550</cell><cell>599</cell><cell>710</cell><cell>Mitotic Chromosome Determinant,null mutant is inviable</cell></row><row><cell>CLN2</cell><cell>497</cell><cell>495</cell><cell>654</cell><cell>Role in cell cycle START, null mutant exhibits G1 arrest</cell></row><row><cell>SRO4</cell><cell>463</cell><cell>405</cell><cell>639</cell><cell>Involved in cellular polarization during budding</cell></row><row><cell>RFA2</cell><cell>456</cell><cell>429</cell><cell>617</cell><cell>Involved in nucleotide excision repair, null mutant is inviable</cell></row><row><cell>YOL007C</cell><cell>444</cell><cell>367</cell><cell>624</cell><cell></cell></row><row><cell>YOX1</cell><cell>400</cell><cell>243</cell><cell>556</cell><cell>Homeodomain protein</cell></row><row><cell>GAT3</cell><cell>398</cell><cell>309</cell><cell>531</cell><cell>Putative GATA zinc finger transcription factor related to polII</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>transcription</cell></row><row><cell>POL30</cell><cell>376</cell><cell>173</cell><cell>520</cell><cell>Required for DNA replication and repair, null mutant is inviable</cell></row><row><cell>RSR1</cell><cell>352</cell><cell>140</cell><cell>461</cell><cell>GTP-binding protein of the ras family involved in bud site selection</cell></row><row><cell>CLN1</cell><cell>324</cell><cell>74</cell><cell>404</cell><cell>Role in cell cycle START, null mutant exhibits G1 arrest</cell></row><row><cell>YBR089W</cell><cell>298</cell><cell>29</cell><cell>333</cell><cell></cell></row><row><cell>MSH6</cell><cell>284</cell><cell>7</cell><cell>325</cell><cell>Required for mismatch repair in mitosis and meiosis</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>List of top Markov relations</figDesc><table><row><cell cols="2">Confidence Gene 1</cell><cell>Gene 2</cell><cell>notes</cell></row><row><cell>1.0</cell><cell cols="3">YKL163W-PIR3 YKL164C-PIR1 Close locality on chromosome</cell></row><row><cell>0.985</cell><cell>PRY2</cell><cell>YKR012C</cell><cell>Close locality on chromosome</cell></row><row><cell>0.985</cell><cell>MCD1</cell><cell>MSH6</cell><cell>Both bind to DNA during mitosis</cell></row><row><cell>0.98</cell><cell>PHO11</cell><cell>PHO12</cell><cell>Both nearly identical acid phosphatases</cell></row><row><cell>0.975</cell><cell>HHT1</cell><cell>HTB1</cell><cell>Both are Histones</cell></row><row><cell>0.97</cell><cell>HTB2</cell><cell>HTA1</cell><cell>Both are Histones</cell></row><row><cell>0.94</cell><cell>YNL057W</cell><cell>YNL058C</cell><cell>Close locality on chromosome</cell></row><row><cell>0.94</cell><cell>YHR143W</cell><cell>CTS1</cell><cell>Homolog to EGT2 cell wall control, both involved in Cytokinesis</cell></row><row><cell>0.92</cell><cell>YOR263C</cell><cell>YOR264W</cell><cell>Close locality on chromosome</cell></row><row><cell>0.91</cell><cell>YGR086</cell><cell>SIC1</cell><cell>Homolog to mammalian nuclear ran protein, both involved in nuclear function</cell></row><row><cell>0.9</cell><cell>FAR1</cell><cell>ASH1</cell><cell>Both part of a mating type switch, expression uncorelated</cell></row><row><cell>0.89</cell><cell>CLN2</cell><cell>SVS1</cell><cell>Function of SVS1 unknown</cell></row><row><cell>0.88</cell><cell>YDR033W</cell><cell>NCE2</cell><cell>Homolog to transmembrame proteins suggest both involved in protein secretion</cell></row><row><cell>0.86</cell><cell>STE2</cell><cell>MFA2</cell><cell>A mating factor and receptor</cell></row><row><cell>0.85</cell><cell>HHF1</cell><cell>HHF2</cell><cell>Both are Histones</cell></row><row><cell>0.85</cell><cell>MET10</cell><cell>ECM17</cell><cell>Both are sulfite reductases</cell></row><row><cell>0.85</cell><cell>CDC9</cell><cell>RAD27</cell><cell>Both participate in Okazaki fragment processing</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This observation is not unique to Bayesian network models. It equally well applies</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We note that we can learn temporal models using a Bayesian network that includes gene expression values in two (or more) consecutive time points<ref type="bibr" target="#b16">[17]</ref>. This raises the number of variables in the model. We are currently perusing this issue.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors are grateful to Gill Bejerano, Hadar Benyaminy, David Engelberg, Moises Goldszmidt, Daphne Koller, Matan Ninio, Itzik Pe'er, and Gavin Sherlock for comments on drafts of this paper and useful discussions relating to this work. We also thank Matan Ninio for help in running and analyzing the robustness experiments. This work was supported through the generosity of the Michael Sacher Trust.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Indentification of gene regulatory networks by strategic gene disruptions and gene over-expressions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Akutsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kuhara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Maruyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Minyano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>Ninth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<publisher>ACM-SIAM</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays</title>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Barkai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Notterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ybarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="6745" to="6750" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gapped blast and psi-blast: a new generation of protein database search programs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Altschul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Clustering gene expression patterns</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-Dor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yakhini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Biology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="281" to="297" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Gene clusters and polycistronic transcription in eukaryotes</title>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioessays</title>
		<imprint>
			<biblScope unit="page" from="480" to="487" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Identifying gene regulatory networks from experimental data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Filkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3&apos;rd Annual International Conference on Computational Molecular Biology (RECOMB)</title>
		<meeting>3&apos;rd Annual International Conference on Computational Molecular Biology (RECOMB)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A transformational characterization of equivalent Bayesian network structures</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eleventh Conference on Uncertainty in Artificial Intelligence (UAI &apos;95)</title>
		<meeting>Eleventh Conference on Uncertainty in Artificial Intelligence (UAI &apos;95)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="87" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks is NPcomplete</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning from Data: Artificial Intelligence and Statistics V</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-J</forename><surname>Lenz</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Causal discovery from a mixture of experimental and observational data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</title>
		<meeting>Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="116" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Bayesian method for the induction of probabilistic networks from data</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Herskovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="309" to="347" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Yeast G1 cyclins CLN1 and CLN2 and a GAP-like protein have a role in bud formation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cvrckova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nasmyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMBO J</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="5277" to="5286" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploring the metabolic and genetic control of gene expression on a genomic scale</title>
		<author>
			<persName><forename type="first">J</forename><surname>Derisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">282</biblScope>
			<biblScope unit="page" from="699" to="705" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An impaired RNA polymerase II activity in saccharomyces cerevisiae causes cell-cycle inhibition at START</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Drebot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Friesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol Gen Genet</title>
		<imprint>
			<biblScope unit="volume">241</biblScope>
			<biblScope unit="page" from="327" to="334" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">An Introduction to the Bootstrap</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cluster analysis and display of genome-wide expression patterns</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Spellman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Botstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="14863" to="14868" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data analysis with Bayesian networks: A bootstrap approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldszmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</title>
		<meeting>Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning the structure of dynamic probabilistic networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;98)</title>
		<meeting>Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;98)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="139" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning Bayesian network structure from massive datasets: The &quot;sparse candidate&quot; algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pe'er</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</title>
		<meeting>Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the sample complexity of learning Bayesian networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yakhini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Twelfth Conference on Uncertainty in Artificial Intelligence (UAI &apos;96)</title>
		<meeting>Twelfth Conference on Uncertainty in Artificial Intelligence (UAI &apos;96)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="274" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A direct link between sister chromatid cohesion and chromosome condensation revealed through the analysis of MCD1 in s. cerevisiae</title>
		<author>
			<persName><forename type="first">V</forename><surname>Guacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koshland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strunnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="57" />
			<date type="published" when="1997-10">October 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks: The combination of knowledge and statistical data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="197" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A Bayesian approach to causal discovery</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cooper</surname></persName>
		</author>
		<idno>MSR-TR-97-05</idno>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discovering structure in continuous variables using Bayesian networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 8 (NIPS &apos;96)</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The transcriptional program in the response of human fibroblasts to serum</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Trent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Staudt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Boguski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lashkari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shalon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Botstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="page" from="83" to="87" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">An introduction to Bayesian Networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>University College London Press</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A general algorithm for approxiamte inference and its application to hybrid Bayes nets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Angelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</title>
		<meeting>Fifthteenth Conference on Uncertainty in Artificial Intelligence (UAI &apos;99)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="324" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">DNA expression monitoring by hybridization of high density oligonucleotide arrays</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Follettie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Chee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Want</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Horton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1675" to="1680" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">DNA repair, DNA replication, and UV mutagenesis</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Mcgregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Investig Dermatol Symp Proc</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cluster analysis and data visualization for large scale gene expression data</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Michaels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Askenazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fuhrman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Somogyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pac. Symp. Biocomputing</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="42" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Inference and learning in hybrid Bayesian networks</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno>CSD-98-990</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>U.C. Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Probabilistic Reasoning in Intelligent Systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Morgan Kaufmann</title>
		<meeting><address><addrLine>San Francisco, Calif</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A theory of inferred causation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Knowledge Representation and Reasoning: Proc. Second International Conference (KR &apos;91)</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="441" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The gene expression matrix: Towards the extraction of genetic network architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fuhrman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Askenazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wuensche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Second World Congress of Nonlinear Analysts (WCNA)</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pfam: multiple sequence alignments and hmmprofiles of protein domains</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Sonnhammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Eddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Birney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bateman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Durbin</surname></persName>
		</author>
		<ptr target="http://pfam.wustl.edu/" />
	</analytic>
	<monogr>
		<title level="j">Nucl. Acids Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="320" to="322" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Comprehensive identification of cell cycle-regulated genes of the yeast sacccharomyces cerevisiae by microarray hybridization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Spellman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sherlock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Anders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Botstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Futcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular Biology of the Cell</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="3273" to="3297" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Causation, prediction, and search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Effect of DNA lesions on transcription elongation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tornaletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Hanawalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochimie</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="139" to="146" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Modeling regulatory networks with weight matrices</title>
		<author>
			<persName><forename type="first">D</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Workman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stormo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pac. Symp. Biocomputing</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="112" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Large-scale temporal gene expression mapping of central nervous system development</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Furhmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Micheals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Somogyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="334" to="339" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Protomap -automated classification of all protein sequences: a hierarchy of protein families, and local maps of the protein space</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Linial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Linial</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Genetics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="360" to="378" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
