<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ANTIDOTE: Understanding and Defending against Poisoning of Anomaly Detectors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Benjamin</forename><forename type="middle">I P</forename><surname>Rubinstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Blaine</forename><surname>Nelson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ling</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Intel Labs Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Intel Labs Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shing-Hon</forename><surname>Lau</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Satish</forename><surname>Rao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nina</forename><surname>Taft</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Intel Labs Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tygar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ANTIDOTE: Understanding and Defending against Poisoning of Anomaly Detectors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BB7690F58899F3EC222E5308EA4B6FBE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C.2.0 [Computer-Communication Networks]: General-Security and Protection</term>
					<term>C.4 [Performance of Systems]: Modeling Techniques</term>
					<term>I.2.6 [Artificial Intelligence]: Learning</term>
					<term>K.6.5 [Management of Computing and Information Systems]: Security and Protection Measurement, Performance, Security Network Traffic Analysis, Principal Components Analysis, Adversarial Learning, Robust Statistics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Statistical machine learning techniques have recently garnered increased popularity as a means to improve network design and security. For intrusion detection, such methods build a model for normal behavior from training data and detect attacks as deviations from that model. This process invites adversaries to manipulate the training data so that the learned model fails to detect subsequent attacks.</p><p>We evaluate poisoning techniques and develop a defense, in the context of a particular anomaly detector-namely the PCA-subspace method for detecting anomalies in backbone networks. For three poisoning schemes, we show how attackers can substantially increase their chance of successfully evading detection by only adding moderate amounts of poisoned data. Moreover such poisoning throws off the balance between false positives and false negatives thereby dramatically reducing the efficacy of the detector.</p><p>To combat these poisoning activities, we propose an antidote based on techniques from robust statistics and present a new robust PCA-based detector. Poisoning has little effect on the robust model, whereas it significantly distorts the model produced by the original PCA method. Our technique substantially reduces the effectiveness of poisoning for a variety of scenarios and indeed maintains a significantly better balance between false positives and false negatives than the original method when under attack.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Statistical machine learning (SML) techniques are increasingly being used as tools for analyzing and improving network design and performance. They have been applied to a variety of problems such as enterprise network fault diagnosis <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref>, email spam filtering <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b26">27]</ref>, worm detection <ref type="bibr" target="#b24">[25]</ref>, and intrusion detection <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33]</ref>, as well as many others. These solutions draw upon a variety of techniques from the SML domain including Singular Value Decomposition, clustering, Bayesian inference, spectral analysis, maximum-margin classification, etc. In many scenarios, these approaches have been demonstrated to perform well. Many of these SML techniques include a learning phase during which a model is trained using collected data. Such techniques have a serious vulnerability, namely they are susceptible to adversaries who purposefully inject malicious data during the phases of data-collection and modelbuilding. The intent of such poisoning is to direct an SML algorithm to learn the wrong model; if adversaries influence detectors to learn the wrong underlying model or normality, then such detectors are unable to properly identify abnormal activities. Poisoning is particularly incentivized when SML techniques are used as defenses against cybercrime threats.</p><p>Other than a few efforts <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref>, this type of vulnerability has not been extensively explored by those who apply SML techniques to networking and systems problems. Applied machine learning researchers have started to address these problems by focusing on adversarial training of specific algorithms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b21">22]</ref>. The learning theory community has focused on online learning <ref type="bibr" target="#b3">[4]</ref>, where data is selected by an adversary with complete knowledge of the learner, and has developed efficient algorithms with strong guarantees. However, the simplifying assumption of all data being produced by an omniscient adversary does not hold for many practical threat models. Given the increasing popularity of applying SML techniques to networking problems, we believe exploring adversarial learning with realistic threat models is important and timely.</p><p>In this paper we study both poisoning strategies and defenses in the context of a particular anomaly detector, namely the PCA-subspace method <ref type="bibr" target="#b15">[16]</ref>, based on Principal Component Analysis (PCA). This technique has received a large amount of attention, leading to extensions <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>, and inspiring related research <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33]</ref>. We consider an adversary who knows that an ISP is using a PCA-based anomaly detector. The adversary's aim is to evade future detection by poisoning the training data so that the detector learns a distorted set of principal components. Because PCA solely focuses on link traffic covariance, we explore poisoning schemes that add chaff (additional traffic) into the network to increase the variance of network traffic. The end goal of the attacker is to increase the false negative rate of a detector, which corresponds to his evasion success rate. In our abstract <ref type="bibr" target="#b28">[29]</ref>, we illustrated that simple poisoning strategies can improve an adversary's ability to evade detection. Our first contribution in this paper is a detailed analysis of how adversaries subvert the learning process. We explore a range of poisoning strategies in which the attacker's knowledge about the network traffic state is varied, and in which the attacker's time horizon (length of poisoning episode) is varied. (We use the words 'attackers' and 'adversaries' interchangeably.) Through theoretical analysis of global poisoning tactics, we uncover some simple and effective poisoning strategies for the adversary. In order to gain insights as to why these attacks work, we illustrate their impact on the normal model built by the PCA detector.</p><p>Because the networks that SML techniques are used in are non-stationary, the baseline models must be periodically retrained to capture evolving trends in the underlying data. In previous usage scenarios <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b29">30]</ref>, the PCA detector is retrained regularly (e.g., weekly), meaning that attackers could poison PCA slowly over long periods of time; thus poisoning PCA in a more stealthy fashion. By perturbing the principal components gradually, the attacker decreases the chance that the poisoning activity itself is detected. We design such a poisoning scheme, called a Boiling Frog scheme, and demonstrate that it can boost the false negative rate as high as the non-stealthy strategies, with far less chaff, albeit over a longer period of time.</p><p>Our second contribution is to design a robust defense against this type of poisoning. It is known that PCA can be strongly affected by outliers <ref type="bibr" target="#b27">[28]</ref>. However, instead of finding the principal components along directions that maximize variance, robust statistics suggests components that maximize more robust measures of dispersion. It is well known that the median is a more robust measure of location than the mean, in that it is far less sensitive to the influence of outliers. This concept can be extended to robust alternatives to variance such as the Median Absolute Deviation (MAD). Over the past two decades a number of robust PCA algorithms have been developed that maximize MAD instead of variance. Recently the PCA-GRID algorithm was proposed as an efficient method for maximizing MAD without under-estimating variance (a flaw identified in previous solutions) <ref type="bibr" target="#b5">[6]</ref>. We adapt PCA-GRID for anomaly detection by combining the method with a new robust cutoff threshold. Instead of modeling the squared prediction error as Gaussian (as in the original PCA method), we model the error using a Laplace distribution. The new threshold was motivated from observations of the residual that show longer tails than exhibited by Gaussian distributions. We call our method that combines PCA-GRID with a Laplace cutoff threshold, antidote. The key intuition behind this method is to reduce the effect of outliers and help reject poisonous training data.</p><p>Our third contribution is to carry out extensive evaluations of both antidote and the original PCA method, in a variety of poisoning situations, and to assess their performance via multiple metrics. To do this, we used traffic matrix data from the Abilene network since many other studies of traffic matrix estimation and anomaly detection have used this data. We show that the original PCA method can be easily compromised by any of our poisoning schemes, with only small amounts of chaff. For moderate amounts of chaff, the PCA detector starts to approach the performance of a random detector. However, antidote is dramatically more robust. It outperforms PCA in that i) it more effectively limits the adversary's ability to increase his evasion success; ii) it can reject a larger portion of contaminated training data; and iii) it provides robust protection across nearly all origin-destination flows through a network. The gains of antidote for these performance measures are large, especially as the amount of poisoning increases. Most importantly, we demonstrate that antidote incurs insignificant shifts in its false negative and false positive performance, compared to PCA, when no poisoning events happen; however when poisoning does occur, the gains of antidote over PCA are enormous with respect to both of these traditional performance measures. The PCA method was not designed to be robust. Our results indicate that it is possible to take such useful techniques and bolster their performance under difficult circumstances.</p><p>Our study sheds light on the general problem of poisoning SML techniques, in terms of the types of poisoning schemes that can be construed, their impact on detection, and strategies for defense. Related Work. Several earlier studies examined attacks on specific learning systems for related applications. In <ref type="bibr" target="#b25">[26]</ref>, the authors describe red herring attacks that weaken polymorphic worm detection systems by poisoning the training data used to build signature-based classifiers. In red herring attacks, the adversary forces the learner to make false negative predictions by including spurious features in positive training examples. Subsequent malicious instances evade detection by excluding these features, now included as conjuncts in the conjunction learned by Polygraph. Venkataraman et al. <ref type="bibr" target="#b30">[31]</ref> present lower bounds for learning worm signatures based on red herring attacks and reductions to classic results from Query Learning. While the red herring attacks exploit the Polygraph conjunction learner's tendency to overfit, our poisoning attacks exploit PCA's singular focus on link traffic covariance.</p><p>Attacks that increase false negative rates by manipulating the test data have also been explored. The polymorphic blending attacks of Fogla and Lee <ref type="bibr" target="#b9">[10]</ref> encrypt malicious traffic so that the traffic is indistinguishable from innocuous traffic to an intrusion detection system. By contrast our variance injection attacks add small amounts of chaff to largely innocuous training traffic to make the traffic appear more like future DoS attacks to be launched post-poisoning. In the email spam filtering domain, Wittel and Wu <ref type="bibr" target="#b31">[32]</ref> and Lowd and Meek <ref type="bibr" target="#b21">[22]</ref> add good words-tokens the filter associates with non-spam messages-so spam messages can evade detection.</p><p>Ringberg et al. <ref type="bibr" target="#b27">[28]</ref> performed a study of the sensitivities of the PCA method that illustrates how the PCA method can be sensitive to the number of principal components used to describe the normal subspace. This parameter can limit PCA's effectiveness if not properly configured. They also show that routing outages can pollute the normal subspace; a kind of perturbation to the subspace that is not adversarial. Our work differs in two key ways. First we demonstrate a different type of sensitivity, namely that of data poisoning. This adversarial perturbation can be stealthy and subtle, and is more challenging to circumvent than observable routing outages. Second, <ref type="bibr" target="#b27">[28]</ref> focuses on showing the variability in PCA's performance to certain sensitivities, and not on defenses. In our work, we propose a robust defense against a malicious adversary and demonstrate its effectiveness. It is conceivable that the technique we propose could help limit PCA's sensitivity to routing outages, although such a study is beyond the scope of this paper. A recent study <ref type="bibr" target="#b2">[3]</ref> showed that the sensitivities observed in <ref type="bibr" target="#b27">[28]</ref> come from PCA's inability to capture temporal correlations. They propose to replace PCA by a Karhunen-Loeve expansion. Our study indicates that it would be important to examine, in future work, the data poisoning robustness of this proposal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head><p>To uncover anomalies, many network anomography detection techniques mine the network-wide traffic matrix, which describes the traffic volume between all pairs of Points-of-Presence (PoP) in a backbone network and contains the collected traffic volume time series for each origin-destination (OD) flow. In this section, we define traffic matrices, present our notation, and summarize the PCA anomaly detection method of Lakhina et al. <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Traffic Matrices and Volume Anomalies</head><p>Network link traffic represents the superposition of OD flows. We consider a network with N links and F OD flows and measure traffic on this network over T time intervals. The relationship between link traffic and OD flow traffic is concisely captured in the routing matrix A. This matrix is an N × F matrix such that Aij = 1 if OD flow j passes over link i, and is zero otherwise. If X is the T × F traffic matrix (TM) containing the time-series of all OD flows, and if Y is the T × N link TM containing the time-series of all links, then Y = XA . We denote the t th row of Y as y(t) = Yt,• (the vector of N link traffic measurements at time t), and the original traffic along a source link, S by yS(t). We denote column f of routing matrix A by A f .</p><p>We consider the problem of detecting OD flow volume anomalies across a top-tier network by observing link traffic volumes. Anomalous flow volumes are unusual traffic load levels in a network caused by anomalies such as Denial of Service (DoS) attacks, Distributed DoS attacks, flash crowds, device failures, misconfigurations, and so on. DoS attacks serve as the canonical example attack in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Subspace Method for Anomaly Detection</head><p>We briefly summarize the PCA-based anomaly detector introduced by Lakhina et al. <ref type="bibr" target="#b15">[16]</ref>. The authors observed high levels of traffic aggregation on ISP backbone links cause OD flow volume anomalies to often go unnoticed because they are buried within normal traffic patterns. They also observe that although the measured data has high dimensionality, N , normal traffic patterns lie in a subspace of low dimension K N . Inferring this normal traffic subspace using PCA (which finds the principal traffic components) makes it easier to identify volume anomalies in the remaining abnormal subspace. For the Abilene (Internet2 backbone) network, most variance can be captured by the first K = 4 principal components.</p><p>PCA is a dimensionality reduction method that chooses K orthogonal principal components to form a K-dimensional subspace capturing maximal variance in the data. Let Ȳ be the centered link traffic matrix, i.e., with each column of Y is translated to have zero mean. The k th principal component is computed as</p><formula xml:id="formula_0">v k = arg max w: w =1 ‚ ‚ ‚ ‚ ‚ Ȳ I - k-1 X i=1 viv i ! w ‚ ‚ ‚ ‚ ‚ . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>The resulting K-dimensional subspace spanned by the first K principal components V1:K = [v1, v2, . . . , vK] is the normal traffic subspace Sn and has a projection matrix Pn = V1:KV 1:K . The residual (N -K)-dimensional subspace is spanned by the remaining principal components VK+1:N = [vK+1, vK+2, . . . , vN ]. This space is the abnormal traffic subspace Sa with a corresponding projection matrix Pa = VK+1:N V K+1:N = I -Pn.</p><p>Volume anomalies can be detected by decomposing the link traffic into y(t) = yn(t) + ya(t) where yn(t) is the modeled normal traffic and ya(t) is the residual traffic, corresponding to projecting y(t) onto Sn and Sa, respectively. A volume anomaly at time t typically results in a large change to ya(t), which can be detected by thresholding the squared prediction error ya(t) 2 against Q β , the Q-statistic at the 1β confidence level <ref type="bibr" target="#b12">[13]</ref>. That is, the PCA-based detector classifies a link measurement vector as</p><formula xml:id="formula_2">c (y (t)) = ( anomalous, ya(t) 2 &gt; Q β innocuous, ya(t) 2 ≤ Q β . (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>While others have explored more efficient distributed variations of this approach <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>, we focus on the basic method introduced by Lakhina et al. <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">POISONING STRATEGIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Threat Model</head><p>The adversary's goal is to launch a Denial of Service (DoS) attack on some victim and to have the attack traffic successfully cross an ISP's network without being detected. The DoS traffic thus needs to traverse from an ingress point-ofpresence (PoP) node to an egress PoP of the ISP. Before launching a DoS attack, the attacker poisons the detector for a period of time, by injecting additional traffic, chaff, along the OD flow (i.e., from an ingress PoP to an egress PoP) that he eventually intends to attack. This kind of poisoning activity is possible if the adversary gains control over clients of an ingress PoP or if the adversary compromises a router (or set of routers) within the ingress PoP. For a poisoning strategy, the attacker needs to decide how much chaff to add, and when to do so. These choices are guided by the amount of information available to the attacker.</p><p>We consider poisoning strategies in which the attacker has increasing amounts of information at his disposal. The weakest attacker is one that knows nothing about the traffic at the ingress PoP, and adds chaff randomly (called an uninformed attack). An intermediate case is when the attacker is partially informed. Here the attacker knows the current volume of traffic on the ingress link(s) that he intends to inject chaff on. Because many networks export SNMP records, an adversary might intercept this information, or possibly monitor it himself (i.e., in the case of a compromised router). We call this type of poisoning a locally-informed attack. Although exported data from routers may be delayed in reaching the adversary, we consider the case of minimal delay in our first study of this topic.</p><p>In a third scenario, the attacker is globally-informed because his global view over the network enables him to know the traffic levels on all network links. Moreover, we assume this attacker has knowledge of future traffic link levels. (Recall that in the locally-informed scheme, the attacker only knows the current traffic volume of a link.) Although these attacker capabilities are very unlikely, we include this in our study in order to understand the limits of variance injection poisoning schemes. Also this scenario serves as a difficult test for our antidote technique.</p><p>Poisoning strategies can also vary according to the time horizon over which they are carried out. Most studies on the PCA-subspace method use a one week training period, so we assume that PCA is retrained each week. Thus the PCs used in any week m are those learned during week m-1 with any detected anomalies removed. Thus for our poisoning attacks, the adversary inserts chaff along the target OD flow throughout the one week training period. We also consider a long-term attack in which the adversary slowly, but increasingly, poisons the principal components over several weeks, by adding small amounts of chaff, in gradually increasing quantities. We call this the Boiling Frog poisoning method after the folk tale that one can boil a frog by slowly increasing the water temperature over time <ref type="foot" target="#foot_0">1</ref> .</p><p>We assume the adversary does not have control over existing traffic (i.e., he cannot delay or discard traffic). Similarly, the adversary cannot submit false SNMP reports to PCA. Such approaches are more conspicuous because the inconsistencies in SNMP reporting from neighboring PoPs could expose the compromised router.</p><p>This paper focuses on non-distributed poisoning of DoS detectors. Distributed poisoning that aims to evade a DoS detector is also possible; our globally-informed poisoning strategy is an example, as the adversary has control over all network links. We focus on DoS for a two reasons. In our first study on this topic, we aim to solve the basic problem first before tackling a distributed version. Second, we point out that results on evasion via non-distributed poisoning are stronger than distributed poisoning results: the DDoS attacker can monitor and influence many more links than the DoS attacker. Hence a DoS poisoning scenario is usually stealthier than a DDoS one.</p><p>For each of these scenarios of different information available to the adversary, we now outline specific poisoning schemes. In each scheme, the adversary decides on the quantity of c t chaff to add to the target flow time series at a time t. Each strategy has an attack parameter θ, which controls the intensity of the attack. For each scenario, we present only one specific poisoning scheme. We have studied others, but those included here are representative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Uninformed Chaff Selection</head><p>At each time t, the adversary decides whether or not to inject chaff according to a Bernoulli random variable. If he decides to inject chaff, the amount of chaff added is of size θ, i.e., ct = θ. This method is independent of the network traffic since our attacker is uninformed. We call this the Random scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Locally-Informed Chaff Selection</head><p>The attacker's goal is to increase traffic variance, on which the PCA detector's model is based. In the locally-informed scenario, the attacker knows the volume of traffic in the ingress link he controls, yS(t). Hence this scheme elects to only add chaff when the existing traffic is already reasonably large. In particular, we add chaff when the traffic volume on the link exceeds a parameter α (we typically use the mean). The amount of chaff added is ct = (max {0, yS(t) -α}}) θ . In other words, we take the difference between the link traffic and a parameter α and raise it to θ. In this scheme (called Add-More-If-Bigger ), the further the traffic is from the average load, the larger the deviation of chaff inserted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Globally-Informed Chaff Selection</head><p>The globally-informed scheme captures an omnipotent adversary with full knowledge of Y, A, and the future measurements ỹt, and who is capable of injecting chaff into any network flow during training. This latter point is important. In previous poisoning schemes the adversary can only inject chaff along their compromised link, whereas in this scenario, the adversary can inject chaff on any link. We formalize the problem of selecting a link n to poison, and selecting an amount of chaff Ctn as an optimization problem that the adversary solves to maximally increase his chances of evasion. Although these globally-informed capabilities are unrealistic, we include a globally-informed poisoning strategy in order to understand the limits of variance injection methods.</p><p>The PCA Evasion Problem considers an adversary wishing to launch an undetected DoS attack of volume δ along flow f at time t. If the vector of link volumes at future time t is ỹt, where the tilde distinguishes this future measurement from past training data Ȳ, then the vectors of anomalous DoS volumes are given by ỹ t = ỹt + δ * A f . Denote by C the matrix of link traffic injected into the network by the adversary during training. Then the PCA-based anomaly detector is trained on altered link traffic matrix Ȳ + C to produce the mean traffic vector μ, the top K eigenvectors V1:K, and the squared prediction error threshold Q β . The adversary's objective is to enable as large a DoS attack as possible (maximizing δ) by designing C. The PCA Evasion Problem corresponds to solving the following:</p><formula xml:id="formula_4">max δ∈R, C∈R T ×F δ s.t. (μ, V, Q β ) = PCA(Y + C) ‚ ‚ ‚V K+1:N (ỹ t -μ) ‚ ‚ ‚ 2 ≤ Q β C 1 ≤ θ ∀t, n Ctn ≥ 0 ,</formula><p>where θ is a constant constraining total chaff. The second constraint guarantees evasion by requiring that the contaminated link volumes at time t are classified innocuous (cf. Eq. 2). The remaining constraints upper-bound the total chaff volume by θ and constrain the chaff to be non-negative.</p><p>Unfortunately, this optimization is difficult to solve analytically. Thus we construct a relaxed approximation to obtain a tractable analytic solution. We make a few assumptions and derivations<ref type="foot" target="#foot_1">2</ref> , and show that the above objective seeks to maximize the attack direction A f 's projected length in the normal subspace max</p><formula xml:id="formula_5">C∈R T ×F ‚ ‚ V 1:K A f ‚ ‚ 2 .</formula><p>Next, we restrict our focus to traffic processes that generate spherical k-rank link traffic covariance matrices <ref type="foot" target="#foot_2">3</ref> . This property implies that the eigen-spectrum consists of K ones followed by all zeroes. Such an eigen-spectrum allows us to approximate the top eigenvectors V1:K in the objective, with the matrix of all eigenvectors weighted by their corresponding eigenvalues ΣV. We can thus convert the PCA evasion problem into the following optimization: max</p><formula xml:id="formula_6">C∈R T ×F ‚ ‚ ( Ȳ + C)A f ‚ ‚ 2 (3) s.t. C 1 ≤ θ ∀t, n Ctn ≥ 0 .</formula><p>Solutions to this optimization are obtained by a standard Projection Pursuit method from optimization: iteratively take a step in the direction of the objective's gradient and then project onto the feasible set.</p><p>These solutions yield an interesting insight. Recall that our adversary is capable of injecting chaff along any flow. One could imagine that it might be useful to inject chaff along an OD flow whose traffic dominates the choice of principal components (i.e., an elephant flow), and then send the DoS traffic along a different flow (that possibly shares a subset of links with the poisoned OD flow). However the solutions of Eq. ( <ref type="formula">3</ref>) indicates that the best strategy to evade detection is to inject chaff only along the links A f associated with the target flow f . This follows from the form of the initializer C (0) ∝ ȲA f A f (obtained from an L2 relaxation) as well as the form of the projection and gradient steps. In particular, all these objects preserve the property that the solution only injects chaff along the target flow. In fact, the only difference between this globally-informed solution and the locally-informed scheme is that the former uses information about the entire traffic matrix Y to determine chaff allocation along the flow whereas the latter use only local information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Boiling Frog Attacks</head><p>Boiling Frog poisoning can use any of the preceding chaff schemes to select ct. The duration of poisoning is increased as follows. We initially set the attack parameter θ to a small value and then increase it slowly over time. In the first week of the attack, the target flow is injected with chaff generated using parameter θ1. At the week's end, PCA is retrained on that week's data. Any anomalies detected by PCA during that week are excluded from future training data. This process continues with θt &gt; θt-1 used for week t. Even though PCA is retrained from scratch each week, the training data includes events not caught by the previous detector. Thus, each successive week will contain additional malicious training data, with the process continuing until the week of the DoS attack, when the adversary stops injecting chaff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ANTIDOTE: A ROBUST DEFENSE</head><p>For defenses against our attacks on PCA-based anomaly detection we explore techniques from Robust Statistics. Such methods are less sensitive to outliers, and as such are ideal defenses against variance injection schemes that perturb data to increase variance along the target flow. There have been two approaches to make PCA robust: the first computes the principal components as the eigenspectrum of a robust estimate of the covariance matrix <ref type="bibr" target="#b8">[9]</ref>, while the second approach searches for directions that maximize a robust scale estimate of the data projection. We propose one of the latter methods as a defense against our poisoning. After describing the method, we propose a new threshold statistic that can be used for any PCA-based method including robust PCA. Robust PCA and the new robust Laplace threshold together form a new network-wide traffic anomaly detection method, antidote, that is less sensitive to our poisoning attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Intuition</head><p>Fundamentally, to mitigate the effect of poisoning attacks, we need a learning algorithm that is stable in spite of data contamination; i.e., a small amount of data contamination should not dramatically change the model produced by our algorithm. This concept of stability has been studied in the field of Robust Statistics in which robust is the formal term used to qualify this notion of stability. In particular, there have been several approaches to developing robust PCA algorithms that construct a low dimensional subspace that captures most of the data's dispersion <ref type="foot" target="#foot_3">4</ref> and are stable under data contamination <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>The robust PCA algorithms we considered search for a unit direction v whose projections maximize some univariate dispersion measure S (•); that is,</p><formula xml:id="formula_7">v ∈ arg max a 2 =1 S (Ya) . (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>The standard deviation is the dispersion measure used by PCA; i.e., S SD (r1, r2, . . . , rn) = "</p><formula xml:id="formula_9">1 n-1 P n i=1 ri - r" 1/2</formula><p>. However, the standard deviation is sensitive to outliers making PCA non-robust to contamination. Robust PCA algorithms instead use measures of dispersion based on the concept of robust projection pursuit (RPP) estimators <ref type="bibr" target="#b18">[19]</ref>. As is shown by Li &amp; Chen, RPP estimators achieve the same breakdown points as their dispersion measure (the breakdown point is the (asymptotic) fraction of the data an adversary must control in order to arbitrarily change an estimator, and as such is a common measure of statistical robustness) as well as being qualitatively robust; i.e., the estimators are stable.</p><p>However, unlike the eigenvector solutions that arise in PCA, there is generally no efficiently computable solution for robust dispersion measures and so these must be approximated. Below, we describe the PCA-GRID algorithm, a successful method for approximating robust PCA subspaces developed by Croux et al. <ref type="bibr" target="#b5">[6]</ref>. Among the projection pursuit techniques we tried <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref>, PCA-GRID proved to be most resilient to our poisoning attacks. It is worth emphasizing that the procedure described in the next section is Projection on 1st PC Projeciton onto Target Flow simply a technique for approximating a projection pursuit estimator and does not itself contribute to the algorithm's robustness-that robustness comes from the definition of the projection pursuit estimator in Eq. (4). First, to better understand the efficacy of a robust PCA algorithm, we demonstrate the effect our poisoning techniques have on the PCA algorithm and contrast them with the effect on the PCA-GRID algorithm. In Figure <ref type="figure" target="#fig_1">1</ref>, we see the impact of a globally informed poisoning attack on both algo-rithms. Initially, the data was clustered in an ellipse. In the top plot, we see that both algorithms construct reasonable estimates for the center and first principal component for this data. However, in the bottom plot, we see that a large amount of poisoning dramatically perturbs some of the data and as a result the PCA subspace is dramatically shifted toward the target flow's direction (y-axis). Due to this shift, DoS attacks along the target flow will be less detectable. Meanwhile, the subspace of PCA-GRID is noticeably less affected.</p><formula xml:id="formula_10">• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • Initial PCA Initial ANTIDOTE Poisoned PCA Poisoned ANTIDOTE</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subspaces with 35 % Poisoning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PCA-GRID</head><p>The PCA-GRID algorithm introduced by Croux et al. <ref type="bibr" target="#b5">[6]</ref> is a projection pursuit technique as described above. It finds a K-dimensional subspace that approximately maximizes S (•), a robust measure of dispersion, for the data Y as in Eq. ( <ref type="formula" target="#formula_7">4</ref>). The first step is to specify our robust dispersion measure. We use the Median Absolute Deviation (MAD) robust measure of dispersion, over other possible choices for S (•). For scalars r1, . . . , rn the MAD is defined as</p><formula xml:id="formula_11">S MAD (r1, . . . , rn) = ω • median {|ri -median{rj }|} ,</formula><p>where the coefficient ω = 1.486 ensures asymptotic consistency on normal distributions.</p><p>The next step requires choosing an estimate of the data's central location. In PCA, this estimate is simply the mean of the data. However, the mean is not robust, so we center the data using the spatial median instead:</p><formula xml:id="formula_12">ĉ (Y) ∈ arg min μ∈R N n X i=1 yi -μ 2 ,</formula><p>which involves a convex optimization that is efficiently solved (see e.g., <ref type="bibr" target="#b10">[11]</ref>).</p><p>Given a dispersion measure and location estimate, PCA-GRID finds a (unit) direction v that is an approximate solution to Eq. ( <ref type="formula" target="#formula_7">4</ref>). The PCA-GRID algorithm uses a gridsearch for this task. Namely, suppose we want to find the best candidate between some pair of unit vectors a1 and a2 (a 2D search space). The search space is the unit circle parameterized by φ as a φ = cos(φ)a1 + sin(φ)a2 with φ ∈ [-π/2, π/2]. The grid search splits the domain of φ into</p><formula xml:id="formula_13">a mesh of Q + 1 candidates φ k = π 2 " 2k Q -1 "</formula><p>, k = 0, . . . , Q. Each candidate vector a φ k is assessed and the one that maximizes S (Ya φ k ) is the approximate maximizer â.</p><p>To search a more general N -dimensional space, the search iteratively refines its current best candidate â by performing a grid search between â and each of the unit directions ei. With each iteration, the range of angles considered progressively narrows around â to better explore its neighborhood. This procedure (outlined in Algorithm 1) approximates the direction of maximal dispersion analogous to an eigenvector in PCA.</p><p>To find the K-dimensional subspace {vi | v i vj = δi,j} that maximizes the dispersion measure, the Grid-Search is repeated K-times. After each repetition, the data is deflated to remove the dispersion captured by the last direction from the data. This process is detailed in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Robust Laplace Threshold</head><p>In addition to the robust PCA-GRID algorithm, we also use a robust estimate for its residual threshold in place of the Q-statistic described in Section 2.2. Using the Q-statistic as</p><formula xml:id="formula_14">Algorithm 1 Grid-Search(Y) Require: Y is a T × N matrix 1: Let: v = e1; 2: for i = 1 to C do 3: for j = 1 to N do 4:</formula><p>for k = 0 to Q do 5:</p><p>Let:</p><formula xml:id="formula_15">φ k = π 2 i " 2k Q -1 " ; 6: Let: a φ k = cos(φ k )â + sin(φ k )ej; 7:</formula><p>if S (Ya φ k ) &gt; S (Yv) then 8:</p><p>Assign: v ← a φ k ; 9: Return: v;</p><formula xml:id="formula_16">Algorithm 2 PCA-GRID(Y, K) 1: Center Y: Y ← Y -ĉ (Y); 2: for i = 1 to K do 3: vi ← Grid-Search(Y); 4:</formula><p>Y ← projection of Y onto the complement of vi; 5: end for 6: Return subspace centered at ĉ (Y) with principal directions {vi} K i=1 ;</p><p>a threshold was motivated by an assumption of normally distributed residuals <ref type="bibr" target="#b12">[13]</ref>. However, we found that the residuals for both the PCA and PCA-GRID subspaces were empirically non-normal leading us to conclude that the Q-statistic is a poor choice for our detection threshold. Instead, to account for the outliers and heavy-tailed behavior we observed from our method's residuals, we choose our threshold as the 1β quantile of a Laplace distribution fit with robust location and scale parameters. Our solution, antidote is the combination of the PCA-GRID algorithm and the Laplace threshold. The non-normality of the residuals has also been recently pointed out in <ref type="bibr" target="#b2">[3]</ref>.</p><p>As with the previous method described in Section 2.2, we select our threshold Q L,β as the 1β quantile of a parametric distribution fit to the residuals in the training data. However, instead of the normal distribution assumed by the Q-statistic, we use the quantiles of a Laplace distribution specified by a location parameter c and a scale parameter b. Critically, though, instead of using the mean and standard deviation, we robustly fit the distribution's parameters. We estimate c and b from the residuals ya(t) 2 using robust consistent estimates of location (median) and scale (MAD) 2 -ĉ˛w here P -1 (q) is the q th quantile of the standard Laplace distribution. The Laplace quantile function has the form</p><formula xml:id="formula_17">ĉ = median ` ya(t) 2 b = 1 √ 2P -1 (0.75) median ˘˛ ya(t)</formula><formula xml:id="formula_18">P -1 c,b (q) = c + b • k(q)</formula><p>for some k(q). Thus, our threshold only depends linearly on the (robust) estimates ĉ and b making the threshold itself robust. This form is also shared by the normal quantiles (differing only in the function k(q)), but because non-robust estimates for c and b are implicitly used by the Q-statistic, it is not robust. Further, by choosing a heavy-tailed distribution like the Laplace, the quantiles are more appropriate for the heavy-tails we observed, but the robustness of our threshold comes from our parameter estimation. Empirically, the Laplace threshold also proved to be better suited for thresholding the residuals of our models than the Q-statistic. As can be seen in Figure <ref type="figure" target="#fig_2">2</ref>, both the Q-statistic and the Laplace threshold produce a reasonable threshold on the residuals of the PCA algorithm but only the Laplace threshold produces a reasonable threshold for the residuals of the PCA-GRID algorithm; the Q-statistic vastly underestimates the spread of the residuals. As was consistently seen throughout our experiments, the Laplace threshold proved to be a more reliable threshold than the Q-statistic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Histogram of PCA Residuals</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Traffic Data</head><p>We use OD flow data collected from the Abilene (Inter-net2 backbone) network to simulate attacks on PCA-based anomaly detection. Data was collected over an almost continuous 6 month period from March 1, 2004 through September 10, 2004 <ref type="bibr" target="#b32">[33]</ref>. Each week of data consists of 2016 measurements across all 144 network OD flows binned into 5 minute intervals. At the time of collection the network consisted of 12 PoPs and 15 inter-PoP links. 54 virtual links are present in the data corresponding to two directions for each inter-PoP link and an ingress and egress link for each PoP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Validation</head><p>To evaluate the subspace method and antidote in the face of poisoning and DoS attacks, we use two consecutive weeks of data-the first for training and the second for testing. The poisoning occurs throughout the training phase, while the attack occurs during the test week. An alternate method (described later) is needed for the Boiling Frog scheme where training and poisoning occur over multiple weeks. Our performance metric for measuring the success of the poisoning strategies is through their impact on a PCAbased detector's false negative rate (FNR). The FNR is the ratio of the number of successful evasions to the total number of attacks (i.e., the attacker's success rate is PCA's FNR rate). We also use Receiver Operating Characteristic (ROC) curves to visualize a detection method's trade-off between detection rate (TPR) and false positive rate (FPR).</p><p>In order to compute the FNRs and FPRs, we generate synthetic anomalies according to the method of Lakhina et al. <ref type="bibr" target="#b15">[16]</ref> and inject them into the Abilene data. While there are disadvantages to this method, such as the conservative assumption that a single volume size is anomalous for all flows, we adopt it for the purposes of relative comparison between PCA and Robust PCA, to measure relative effects of poisoning, and for consistency with prior studies. We use week-long training sets, as such a time scale is sufficiently large to capture weekday and weekend cyclic trends <ref type="bibr" target="#b27">[28]</ref>, and previous studies operated on this same time scale <ref type="bibr" target="#b15">[16]</ref>. There is nothing inherent to our method that limits its use to this time scale; our methods will work as long as the training data is poisoned throughout. Because the data is binned in 5 minute windows (corresponds to the reporting interval of SNMP), a decision about whether or not an attack is present can be made at the end of each 5 minute window; thus attacks can be detected within 5 minutes of their occurrence.</p><p>Starting with the flow traffic matrix X for the test week, we generate a positive example (an anomalous OD flow) by setting flow f 's volume at time t, X t,f , to be a large value known to correspond to an anomalous flow (replacing the original traffic volume in this time slot). This value is defined <ref type="bibr" target="#b15">[16]</ref> to be 1.5 times a cutoff of 8×10 7 . After multiplying by the routing matrix A, the link volume measurement at time t is anomalous. We repeat this process for each time t (each 5 minute window) in the test week to generate a set of 2016 anomaly samples for the single target flow f .</p><p>In order to obtain FPRs, we generate negative examples (benign OD flows) as follows. We fit the data to an EWMA model that is intended to capture the main trends of the data without much noise. We use this model to select which points in time, in an Abilene flow's time series, to use as negative examples. We compare the actual data and the EWMA model, and if the difference is small (not in the flow's top one percentile) for a particular flow at a particular time, X t,f , then we label the element X t,f as "benign." We do this across all flows; when we find time slots where all flows are labeled as benign, we run our detectors and see whether or not they raise an alarm for those time slots.</p><p>We simulate a DoS attack along every flow at every time. We average FNRs over all 144 possible anomalous flows and all 2016 anomaly times. When reporting the effect of an attack on traffic volumes, we first average over links within each flow then over flows. Furthermore we generally report average volumes relative to the pre-attack average volumes. Thus a single poisoning experiment was based on one week of poisoning with FNRs computed during the test week that includes 144 × 2016 samples coming from the different flows and time slots. Because the poisoning is deterministic in Add-More-If-Bigger this experiment was run once for that scheme. In contrast, for the Random poisoning scheme, we ran 20 independent repetitions of poisoning experiments data because the poisoning is random.</p><p>To produce the ROC curves, we use the squared prediction errors produced by the detection methods, that consist of anomalous and normal examples from the test set. By varying the method's threshold from -∞ to ∞ a curve of possible (F P R, T P R) pairs is produced from the set of SPE's; the Q-statistic and Laplace threshold, each correspond to one such point in ROC space. We adopt the Area Under Curve (AUC) statistic from Information Retrieval to directly compare ROC curves. The area under an ROC curve of detector A estimates the conditional probability</p><formula xml:id="formula_19">AU C(A) ≈ Pr (SP E A(y1) &gt; SP EA(y2)) ,</formula><p>given anomalous and normal random link volume vectors y1 and y2. The ideal detector has an AUC of 1, while the random predictor achieves an AUC of 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Single Period &amp; Boiling Frog Poisoning</head><p>We evaluate the effectiveness of our attacker strategies using weeks 20 and 21 from the Abilene dataset to simulate the Single-Training Period attacks. The PCA algorithm is trained on the week 20 traffic matrix poisoned by the attacker; we then inject attacks during week 21 to see how often the attacker can evade detection. We select these particular weeks because PCA achieved the lowest FNRs on these during testing.</p><p>To test the Boiling Frog attack we simulate traffic matrix data, inspired by methods used in <ref type="bibr" target="#b15">[16]</ref>. Our simulations present multiple weeks of stationary data to the adversary. While such data is unrealistic in practice, it is an easy case on which PCA should succeed. Anomaly detection under non-stationary conditions is difficult due to the learner's inability to distinguish between benign data drift, and adversarial poisoning. Demonstrated flaws of PCA in the stationary case constitute strong results. We decided to validate the Boiling Frog attack on a synthesized multi-week dataset, because the 6 month Abilene dataset of <ref type="bibr" target="#b32">[33]</ref> proved to be too non-stationary for PCA to consistently operate well from one week to the next. It is unclear whether the non-stationarity observed in this is prevalent in general or whether it is an artifact of the dataset.</p><p>We synthesize a multi-week set of OD flow traffic matrices, with stationarity on the inter-week level. We use a three step generative procedure to model each OD flow separately. First the underlying daily cycle of the OD flow f time series is modeled by a sinusoidal approximation. Then the times at which the flow is experiencing an anomaly are modeled by a Binomial arrival process with inter-arrival times distributed according to the geometric distribution. Finally Gaussian white noise is added to the base sinusoidal model during times of benign OD flow traffic; and exponential traffic is added to the base model during times of anomalous traffic. We next describe the process of fitting this generative model to the week 20 Abilene data.</p><p>In step 1, we capture the underlying cyclic trends via Fourier basis functions. We use sinusoids of periods of 7, 5 and 3 days, and 24, 12, 6, 3 and 1.5 hours, as well as a constant function <ref type="bibr" target="#b15">[16]</ref>. For each OD flow, we find the Fourier coefficients from the flow's projection onto this basis. We next remove the portion of the traffic modeled by this Fourier forecaster and model the remaining residual traffic via two processes. One is a noise process modeled by a zero-mean Gaussian to capture short-term benign traffic variance. The second process models volume anomalies as being exponentially distributed.</p><p>In step 2 we select which of the two noise processes is used at each time interval. After computing our model's residuals (the difference between the observed and predicted traffic) we note the smallest negative residual value -m. We assume that residuals in the interval [-m, m] correspond to benign traffic and that residuals exceeding m correspond to traffic anomalies. We separate benign variation and anomalies in this way since these effects behave quite differently. (This is an approximation but it works reasonably well for most OD flows.) Negative residual traffic reflects benign variance, and since we assume that benign residuals have a zero-mean distribution, it follows that such residuals should lie within the interval [-m, m]. Upon classifying residual traffic as benign or anomalous we then model anomaly arrival times as a Bernoulli arrival process. Under this model the inter-anomaly arrival times become geometrically distributed. Since we consider only spatial PCA methods, the placement of anomalies is of secondary importance.</p><p>For the final step, the parameters for the two residual traffic volume and the inter-anomaly arrival processes are inferred from the residual traffic using the Maximum Likelihood estimates of the Gaussian's variance and exponential and geometric rates respectively. Positive goodness-of-fit results (Q-Q plots not shown) have been obtained for mouse, medium and elephant flows.</p><p>In our simulations, we constrain all link volumes to respect the link capacities in the Abilene network: 10gbps for all but one link that operates at one fourth of this rate. We cap chaff that would cause traffic to exceed the link capacities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">POISONING EFFECTIVENESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Single Training Period Poisoning</head><p>We evaluate the effectiveness of our three data poisoning schemes in Single-Training Period attacks. During the testing week, the attacker launches a DoS attack in each 5 minute time window. The results of these attacks are displayed in Fig. <ref type="figure">3</ref>. Although our poisoning schemes focus on adding variance, the mean of the OD flow being poisoned increases as well, increasing the means of all links over which the OD flow traverses. The x-axis in Fig. <ref type="figure">3</ref> indicates the relative increase in the mean rate. We average over all experiments (i.e., over all OD flows).</p><p>As expected the increase in evasion success is smallest for the uninformed strategy, intermediate for the locallyinformed scheme, and largest for the globally-informed poisoning scheme. A locally-informed attacker can use the Add-More-If-Bigger scheme to raise his evasion success to 28% from the baseline FNR of 3.67% via a 10% average increase in the mean link rates due to chaff. Although 28% may not be viewed as a high likelihood of evasion, the attacker success rate is nearly 8 times larger than the unpoisoned PCA model's rate. This number represents an average over attacks launched in each 5 minute window, so the attacker could simply retry multiple times. With our Globally-Informed with a 10% average increase in the mean link rates, the unpoisoned FNR is raised by a factor of 10 to 38% and eventually to over 90%. The big difference between the performance of the locally-informed and globally-informed attacker is intuitive to understand. Recall that the globallyinformed attacker knows a great deal more (traffic on all links, and future traffic levels) than the locally-informed one (who only knows the traffic status of a single ingress link). We consider the locally-informed adversary to have succeeded quite well with only a small view of the network. An adversary is unlikely to be able to acquire, in practice, the capabilities used in the globally-informed poisoning attack. Moreover, adding 30% chaff, in order to obtain a 90% evasion success is dangerous in that the poisoning activity itself is likely to be detected. Therefore Add-More-If-Bigger presents a nice trade-off, from the adversary's point of view, in terms of poisoning effectiveness, and attacker capabilities and risks. We therefore use Add-More-If-Bigger, the locallyinformed strategy, for many of the remaining experiments.</p><p>We evaluate the PCA detection algorithm on both anomalous and normal data, as described in Section 5.2, producing the Receiver Operating Characteristic (ROC) curves displayed in Fig. <ref type="figure">4</ref>. We produce a ROC curve (as shown) by first training a PCA model on the unpoisoned data from week 20. We next evaluate the algorithm when trained on data poisoned by Add-More-If-Bigger.</p><p>To validate PCA-based detection on poisoned training data, we poison exactly one flow at a time as dictated by the threat model. Thus, for relative chaff volumes ranging from 5% to 50%, Add-More-If-Bigger chaff is added to each flow separately to construct 144 separate training sets and 144 corresponding ROC curves for the given level of poisoning. The poisoned curves in Fig. <ref type="figure">4</ref> display the averages of these ROC curves (i.e., the average TPR over the 144 flows for each FPR).</p><p>We see that the poisoning scheme can throw off the balance between false positives and false negatives of the PCA detector: The detection and false alarm rates drop together rapidly as the level of chaff is increased. At 10% relative chaff volume performance degrades significantly from the ideal ROC curve (lines from (0, 0) to (0, 1) to (1, 1)) and at 20% the PCA's mean ROC curve is already close to that of blind randomized prediction (the y = x line with 0.5 AUC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Multi-Training Period Poisoning</head><p>We now evaluate the effectiveness of the Boiling Frog strategy, that contaminates the training data over multiple training periods. In Fig. <ref type="figure">5</ref> we plot the FNRs against the poisoning duration for the PCA detector. We examine four different poisoning schedules with growth rates g as 1.01, 1.02, 1.05 and 1.15 respectively. The goal of the schedule is to increase the attacked links' average traffic by a factor of g from week to week. The attack strength parameter θ (see Sec. 3) is chosen to achieve this goal. We see that the FNR dramatically increases for all four schedules as the poison duration increases. With a 15% growth rate the FNR is increased to more than 70% from 3.67% over 3 weeks of poisoning; even with a 5% growth rate the FNR is increased to 50% over 3 weeks. Thus Boiling Frog attacks are effective even when the amount of poisoned data increases rather slowly.</p><p>Recall that the two methods are retrained every week using the data collected from the previous week. However, the data from the previous week has been filtered by the de-    tector itself. At any time point flagged as anomalous, the training data is thrown out. Fig. <ref type="figure" target="#fig_5">6</ref> shows the proportion of chaff rejected each week by PCA (chaff rejection rate) for the Boiling Frog strategy. The three slower schedules enjoy a relatively small constant rejection rate close to 5%. The 15% schedule begins with a relatively high rejection rate, but after a month sufficient amounts of poisoned traffic mistrain PCA after which point the rates drop to the level of the slower schedules. We conclude that the Boiling Frog strategy with a moderate growth rate of 2-5% can significantly poison PCA, dramatically increasing its FNR while still going unnoticed by the detector.</p><p>By comparing Figs. <ref type="figure">3</ref> and<ref type="figure">5</ref>, we observe that in order to raise the FNR to 50%, an increase in mean traffic of roughly 18% for the Single-Training Period attack is needed, whereas in the Boiling Frog attack the same thing can be achieved with only a 5% average traffic increase spread across 3 weeks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">DEFENSE PERFORMANCE</head><p>We now assess how antidote performs in the face of two types of poisoning attacks, one that lasts a single training period, and one that lasts for multiple training periods. For those 2 time horizons, we use the Add-More-If-Bigger poisoning scheme to select how much chaff to add at each point in time. We compare its performance to the original PCAsubspace method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Single Training Period Poisoning</head><p>In Fig. <ref type="figure">7</ref> we illustrate antidote's FNR for various levels of average poisoning that occur in a Single-Training Period attack. We can compare this to Fig. <ref type="figure">3</ref> that shows the same metric for the original PCA solution. We see here that the evasion success of the attack is dramatically reduced. For any particular level of chaff, the evasion success rate is approximately cut in half. Interestingly, the most effective poisoning scheme on PCA, Globally-Informed, is the most ineffective poisoning scheme in the face of our robust PCA solution. We believe the reason for this is that our Globally-Informed scheme was designed in an approximately optimal fashion to circumvent PCA. Now that the detector has changed, Globally-Informed is no longer optimized for the right defense. For this detector, Random remains equally effective because constant shifts in a large subset of the data create a bimodality that is difficult for any subspace method to reconcile. This effect is still muted compared to the dramatic success of locally-informed methods on the original detector. Further, constant shift poisoning creates unnatural traffic patterns that we believe can be detected; we leave the investigation of such techniques to future work.</p><p>Since poisoning activities distort a detector, it will affect not only the FNRs but also the false positives. To explore this trade-off, we use ROC curves in Fig. <ref type="figure">8</ref> for both antidote and PCA. For comparison purposes, we include cases when the training data is both unpoisoned and poisoned. For the poisoned training scenario, each point on the curve is the average over 144 poisoning scenarios in which the training data is poisoned along one of the 144 possible flows. While antidote performs very similarly to PCA on unpoisoned training data, PCA significantly underperforms antidote under poisoning attacks. With a moderate mean chaff volume of 10%, antidote's average ROC curve remains close to optimal while PCA's curve collapses towards the y = x curve of the blind random detector. This means that the normal balance between FNRs and false positives is completely thrown off with PCA; however antidote continues to retain a good operating point for these two common performance measures. In summary, when we consider the two performance measures of FNRs and FPRs, we give up insignificant performance shifts when using antidote when no poisoning events occur, yet we see enormous performance gains for both metrics when poisoning attacks do occur.</p><p>Given Figs. 7 and 8 alone, it is conceivable that antidote outperforms PCA only on average, and not on all flows targeted for poisoning. In place of plotting all 144 poisoned ROC curves, we display the areas under these curves (AUC) for the two detection methods in Fig. <ref type="figure">9</ref> under 10% chaff. Not only is average performance much better for robust PCA, but it enjoys better performance for more flows and by a large amount. We note that although PCA performs slightly better for some flows, we see that in fact both methods have excellent detection performance (because their AUCs are close to 1), and hence the distinction between the two is insignificant, for those specific flows. Fig. <ref type="figure" target="#fig_1">10</ref> plots the mean AUC (averaged from the 144 ROC curves' AUCs where flows are poisoned separately) achieved by the detectors, as the level of chaff is intensified. Notice that antidote behaves similarly to PCA under no chaff conditions, yet its performance quickly becomes superior as the amount of contamination grows. In fact, it does not take much poisoning for antidote to exhibit much stronger performance. With PCA's performance drop, it starts approaching a random detector (equivalent to 0.5 AUC), for amounts of chaff exceeding 20%. In these last few figures, we have seen the FNR and FPR performance as it varies across flows and quantity of poisoning. In all cases, it is clear that antidote is an effective defense and dramatically outperforms a solution that was not designed to be robust. We believe this evidence indicates that the robust techniques are a promising avenue for SML algorithms used for security applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Multi-Training Period Poisoning</head><p>We now evaluate effectiveness of antidote against the Boiling Frog strategy, that occurs over multiple successive training periods. In Fig. <ref type="figure" target="#fig_8">11</ref> we see the FNRs for antidote with the four different poisoning schedules. We observe two interesting behaviors. First, for the two most stealthy poisoning strategies (1.01 and 1.02), antidote shows remarkable resistance in that the evasion success increases very slowly, e.g., after 10 training periods it is still below 20%. This is in stark contrast to PCA (see Fig. <ref type="figure">5</ref>) in which, for example, after 10 weeks, the evasion success is over 50% for the 1.02 poisoning growth rate scenario. Second, under PCA the evasion success keeps rising over time. However with antidote and the heavier poisoning strategies, we see that the evasion success actually starts to decrease after some time. The reason for this is that antidote has started rejecting so much of the training data, that the poisoning strategy starts to lose its effectiveness.</p><p>To look more closely at this behavior we show the proportion of chaff rejected by antidote under multi-training period poisoning episodes in Fig. <ref type="figure" target="#fig_10">12</ref>. We see that the two slower schedules almost have a constant rejection rate close to 9%, which is higher than that of original PCA (which is close to 5%). For the faster poisoning growth schedules (5% and 15%) we observe that antidote rejects an increasing amount of the poison data. This reflects a good target behavior for any robust detector-to reject more training data as the contamination grows. From these figures we conclude that the combination of techniques we use in antidote, namely a PCA-based detector designed with robust dispersion goals combined with a Laplace-based cutoff threshold, is very effective at maintaining a good balance between false negative and false positive rates throughout a variety of poisoning scenarios (different amounts of poisoning, on different OD flows, and on different time horizons).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSIONS</head><p>We studied the effects of multiple poisoning strategies while varying the amount of information available to the attacker and the time horizon over which the poisoning occurs.    We demonstrated that the PCA-subspace method can be easily compromised (often dramatically) under all of these poisoning scenarios. From the attacker's point of view, we illustrate that simple strategies can be effective and conclude that it is not worth the risk or extra amount of work for the attacker to engage in attempts at optimal strategies. We demonstrated that our antidote solution is robust to all of these attacks in that it does not allow poisoning attacks to shift the false positive and false negative rates in any significant way. We showed that antidote provides robustness for nearly all the ingress POP to egress POP flows in a backbone network, rejects much of the contaminated data, and continues to operate as a DoS defense even in the face of poisoning.</p><formula xml:id="formula_20">• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • 0.</formula><p>In the future, we plan to adapt our scheme to defend against poisoning strategies that enable DDoS evasion, and   intend to validate our findings on other traffic matrix datasets (e.g., G ÉANT or enterprise networks). It is also interesting to consider using robust statistical methods for other detectors such as general anomography <ref type="bibr" target="#b32">[33]</ref> techniques. We plan to go beyond rejection of poisoning data, and study methods for identifying the responsible flow for a poisoning attack by looking at correlations among links that are rejecting chaff.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Here the data has been projected into the 2D space spanned by the 1st principal component and the direction of the attack flow #118. The effect on the 1st principal components of PCA and PCA-GRID is shown under a globally informed attack (represented by •'s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Histograms of the residuals for the original PCA algorithm (left) and the PCA-GRID algorithm (the largest residual is excluded as an outlier). Red and blue vertical lines demarcate the threshold selected using the Q-statistic and the Laplace threshold, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: ROC curves of PCA under Single-Training Period poisoning attacks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Chaff rejection rates of PCA under poisoning attacks shown in Fig. 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Evasion success of antidote under Single-Training Period poisoning attacks using 3 chaff methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Figure 9: The 144 AUCs from the poisoned ROC curves for each possible target flow and their mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Evasion success of antidote under Boiling Frog poisoning attacks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Chaff rejection rates of antidote under Boiling Frog poisoning attacks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Evasion success of PCA under Single-Training Period poisoning attacks using 3 chaff methods.</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Single Poisoning Period: Evading PCA</cell><cell></cell><cell></cell><cell cols="2">Single Poisoning Period: ROC Curves</cell></row><row><cell></cell><cell>1.0</cell><cell>Uninformed</cell><cell></cell><cell>1.0</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Locally-informed</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Evasion success (FNR)</cell><cell>0.2 0.4 0.6 0.8</cell><cell>Globally-informed</cell><cell>DoS Detection Rate (TPR)</cell><cell>0.4 0.6 0.8 0.2</cell><cell></cell><cell>PCA -unpoisoned PCA -5% chaff PCA -10% chaff PCA -20% chaff PCA -50% chaff Random detector</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Q-statistic</cell></row><row><cell></cell><cell>0.0</cell><cell></cell><cell></cell><cell>0.0</cell><cell></cell><cell>Laplace threshold</cell></row><row><cell cols="5">Mean chaff volume 20% 30% Figure 3: 0.0 0% 10% 40% 50%</cell><cell>0.2</cell><cell>0.4 False Alarm Rate (FPR) 0.6</cell><cell>0.8</cell><cell>1.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Note that there is nothing inherent in the choice of a oneweek poisoning period. For a general SML algorithm, our strategies would correspond to poisoning over one training period (whatever its length) or multiple training periods.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The full proof is ommitted due to space constraints.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>While the spherical assumption does not hold in practice, the assumption of low-rank traffic matrices is met by published datasets<ref type="bibr" target="#b15">[16]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Dispersion is an alternative term for variation since the later is often associated with statistical variation. By a dispersion measure we mean a statistic that measures the variability or spread of a variable.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">ACKNOWLEDGEMENTS</head><p>We would like to thank Peter Bartlett, Fuching Jack Chi, Fernando Silveira, Anthony Tran and the anonymous reviewers for their helpful feedback on this project.</p><p>We gratefully acknowledge the support of our sponsors. This work was supported in part by TRUST (Team for Research in Ubiquitous Secure Technology), which receives support from the National Science Foundation (NSF award #CCF-0424422) and AFOSR (#FA9550-06-1-0244); RAD Lab, which receives support from California state MICRO grants (#06-148 and #07-012); DETERlab (cyber-DEfense Technology Experimental Research laboratory), which receives support from DHS HSARPA (#022412) and AFOSR (#FA9550-07-1-0501); NSF award #DMS-0707060; and the following organizations: Amazon, BT, Cisco, DoCoMo USA Labs, EADS, ESCHER, Facebook, Google, HP, IBM, iCAST, Intel, Microsoft, NetApp, ORNL, Pirelli, Qualcomm, Sun, Symantec, TCS, Telecom Italia, United Technologies, and VMware. The opinions expressed in this paper are solely those of the authors and do not necessarily reflect the opinions of any funding agency, the State of California, or the U.S. government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards highly reliable enterprise network services via inference of multi-level dependencies</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Can machine learning be secure?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sears</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tygar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASIACCS</title>
		<meeting>ASIACCS</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Applying PCA for Traffic Anomaly Detection: Problems and Solutions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brauckhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Salamatian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>May</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INFOCOM</title>
		<meeting>INFOCOM</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<title level="m">Prediction, Learning, and Games</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automating cross-layer diagnosis of enterprise wireless networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Afanasyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Verkaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Benko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Snoeren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Voelker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithms for projection-pursuit robust principal component analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Croux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Filzmoser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics and Intelligent Laboratory Systems</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">High breakdown estimators for principal components: the projection-pursuit approach revisited</title>
		<author>
			<persName><forename type="first">C</forename><surname>Croux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruiz-Gazen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial classification</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sanghai</surname></persName>
		</author>
		<author>
			<persName><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
		<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust estimation of dispersion matrices and principal components</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gnanadesikan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kettenring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evading network anomaly detection systems: Formal reasoning and practical techniques</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fogla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CCS</title>
		<meeting>ACM CCS</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalizing univariate signed rank statistics for testing and estimating a multivariate location parameter</title>
		<author>
			<persName><forename type="first">O</forename><surname>Hössjer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Croux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Nonparametric Statistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">In-network PCA and anomaly detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garofalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS &apos;06</title>
		<meeting>NIPS &apos;06</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Control procedures for residuals associated with principal component analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Mudholkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">What&apos;s going on? learning communication rules in edge networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Characterization of network-wide anomalies in traffic flows</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IMC</title>
		<meeting>IMC</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Diagnosing network-wide traffic anomalies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Detecting distributed attacks using network-wide flow traffic</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. FloCon 2005 Analysis Workshop</title>
		<meeting>FloCon 2005 Analysis Workshop</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mining anomalies using traffic feature distributions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM</title>
		<meeting>SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Projection-pursuit approach to robust dispersion matrices and principal components: primary theory and Monte Carlo</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Detection and identification of network anomalies using sketch subspaces</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Iannaccone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IMC</title>
		<meeting>IMC</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MIND: A distributed multidimensional indexing for network diagnosis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Iannaccone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INFOCOM</title>
		<meeting>INFOCOM</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adversarial learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
		<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Principal components and orthogonal regression based on robust scales</title>
		<author>
			<persName><forename type="first">R</forename><surname>Maronna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exploiting machine learning to subvert your spam filter</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I P</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tygar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LEET</title>
		<meeting>LEET</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Polygraph: Automatically generating signatures for polymorphic worms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. Security and Privacy</title>
		<meeting>IEEE Symp. Security and Privacy</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Paragraph: Thwarting signature learning by training maliciously</title>
		<author>
			<persName><forename type="first">J</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. RAID</title>
		<meeting>RAID</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Filtering spam with behavioral blacklisting</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Feamster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vempala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CCS</title>
		<meeting>ACM CCS</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sensitivity of PCA for traffic anomaly detection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ringberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rexford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGMETRICS</title>
		<meeting>SIGMETRICS</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stealthy poisoning attacks on PCA-based anomaly detectors</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I P</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tygar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Combining filtering and statistical methods for anomaly detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Soule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Salamatian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IMC</title>
		<meeting>IMC</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Limits of learning-based signature generation with adversaries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NDSS</title>
		<meeting>NDSS</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On attacking statistical spam filters</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Wittel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEAS</title>
		<meeting>CEAS</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Network anomography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IMC</title>
		<meeting>IMC</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
