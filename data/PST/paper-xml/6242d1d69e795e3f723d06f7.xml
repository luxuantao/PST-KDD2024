<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-View Multi-Task Campaign Embedding for Cold-Start Conversion Rate Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zijun</forename><surname>Yao</surname></persName>
							<email>zyao@ku.edu</email>
							<idno type="ORCID">0000-0003-3647-8770</idno>
							<affiliation key="aff0">
								<orgName type="institution">University of Kansas</orgName>
								<address>
									<postCode>66045</postCode>
									<settlement>Lawrence</settlement>
									<region>KS</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Deguang Kong is with Google</orgName>
								<address>
									<postCode>94043</postCode>
									<settlement>Mountain View</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">University of Kansas Libraries</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Deguang</forename><surname>Kong</surname></persName>
							<email>doogkong@gmail.com</email>
							<idno type="ORCID">0000-0001-9415-8439</idno>
							<affiliation key="aff0">
								<orgName type="institution">University of Kansas</orgName>
								<address>
									<postCode>66045</postCode>
									<settlement>Lawrence</settlement>
									<region>KS</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miao</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Kansas</orgName>
								<address>
									<postCode>66045</postCode>
									<settlement>Lawrence</settlement>
									<region>KS</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">is with Snap Inc</orgName>
								<address>
									<postCode>90405</postCode>
									<settlement>Santa Monica</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Bai</surname></persName>
							<email>xbai@yahooinc.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Kansas</orgName>
								<address>
									<postCode>66045</postCode>
									<settlement>Lawrence</settlement>
									<region>KS</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">are with Yahoo Research</orgName>
								<address>
									<postCode>94089</postCode>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Yang</surname></persName>
							<email>jianyang@yahooinc.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Kansas</orgName>
								<address>
									<postCode>66045</postCode>
									<settlement>Lawrence</settlement>
									<region>KS</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">are with Yahoo Research</orgName>
								<address>
									<postCode>94089</postCode>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
							<email>xionghui@ust.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Kansas</orgName>
								<address>
									<postCode>66045</postCode>
									<settlement>Lawrence</settlement>
									<region>KS</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Hong Kong University of Science and Technology (Guangzhou)</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-View Multi-Task Campaign Embedding for Cold-Start Conversion Rate Forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TBDATA.2022.3162150</idno>
					<note type="submission">received 29 June 2020; revised 16 Dec. 2021; accepted 18 Feb. 2022. Date of publication 24 Mar. 2022; date of current version 16 Jan. 2023.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Online advertising</term>
					<term>cold-start forecasting</term>
					<term>campaign embedding</term>
					<term>multi-view learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In online advertising, it is critical for advertisers to forecast conversion rate (CVR) of campaigns. Previous work on campaign forecasting concentrates on the time-series analysis which depend on the availability of a length of history. However, these approaches become inadequate for cold-start campaigns which lack for the observation of past. In this work, we attempt to mitigate this challenge by learning an unsupervised and composite campaign embedding to capture multi-view semantic relationships on campaign information, and consequently forecasting the cold-start campaigns using the nearest neighbor campaigns. Specifically, we propose a novel embedding framework which simultaneously extracts and fuses heterogeneous knowledge from multiple views of campaign data in a multi-task learning fashion, to learn the semantic relationship of ad message, conversion rule, and audience targeting. We develop a hierarchical attention mechanism to refine the embedding model at two levels -an intra-view attention to improve context aggregation, and an inter-task attention to balance task importance. Finally, we adopt the k-NN regression model to predict the CVR based on the neighboring campaigns in the embedding space which encodes the multi-view campaign proximity. We conduct extensive experiments on a real-world advertising campaign dataset. The results demonstrate the effectiveness of the proposed embedding method for CVR forecasting in cold-start scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? 1 INTRODUCTION</head><p>O NLINE advertisement, aiming to increase user engage- ment by displaying promotional messages to web visitors, has become one of the major businesses in advertising industry. For an advertiser who is preparing to launch a new campaign, it is crucial to make sure this campaign to be invested has high potential of triggering users to react, called conversion. Therefore, the capacity of forecasting conversion rate (CVR) (i.e., the ratio of conversions to clicks) of a new campaign is considered as a prerequisite for making informed spending decisions.</p><p>Ad conversion forecasting has attracted heavy interests in literature <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Usually, these studies utilize the availability of history like CVR, clicks, or browsing records for future prediction. However, when we are facing a different scenario -cold-start forecasting for new campaigns, the task becomes challenging as the lack of past makes the history-dependent methods inadequate. Therefore, an alternative way to forecast is to refer to the existing campaign -the idea of collaborative filtering, such as using k-nearest neighborhood (k-NN) to search similar but observed campaigns to guide the new campaign forecasting <ref type="bibr" target="#b4">[5]</ref>. To achieve this solution, a key task is to learn a comprehensive and descriptive representation, which can encode the heterogeneous information from different views of a campaign, in order to reflect the similarities that inspire the correlation of conversion performance between campaigns.</p><p>Campaigns consist of heterogeneous information presented in multiple views of data. As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, a typical campaign can be characterized from three following views of data. The first example view can be ad messagethe sentences showing the contents of campaign such as credit card application bonus or auto insurance discount. The second view is from the massive conversion rules which track various conversion types. For example, some rules may track "browsing a page" conversions while some others would track "submitting an order" conversions. These rules define massive and distinct user actions, and these actions can result very different conversion rates. In many cases, advertisers may place multiple conversion rules to form a funnel for tracking a conversion path from acquaintance to decision, such as "browsing product" ! "add to cart" ! "submit order". To learn the contents of conversion rules, we can utilize the sequential structure of funnels, like sentences, to learn rules through their contexts. The last view is the targeting of campaigns. Many online ad platforms can help advertisers to display the ads to a specific group of audience in terms of interests, locations, devices, etc. The logic in considering targeting for CVR forecasting is that different population react differently to the same campaign. Therefore, representing the group of targeting is the third important factor to realize campaign similarities. To represent all the three views of information in a single campaign embedding, we need to learn each view separately due to the information heterogeneity; meanwhile, we want to extract all the views simultaneously that all the knowledge can be fused properly to generate the composite campaign embeddings.</p><p>To represent these multi-view campaign data, a traditional way is to "hand-crafte" descriptive features such as image colorfulness, word number of ads <ref type="bibr" target="#b5">[6]</ref>, and numbers of positive users on landing pages <ref type="bibr" target="#b3">[4]</ref>. Building these features usually require knowledge-intensive feature engineering, and in many cases, they are not comprehensive enough to capture overall campaign characteristics. Another way is to use one-hot encoding to represent all the raw information of campaigns such as the presence of words, rules, and targetings. However, this will result high dimensional representations in order to accommodate data views with massive information like all the possible vocabulary, rules, and geographic information. More importantly, this representation reflecting the distinction in raw data can hardly express the underlying semantic relationship in the information, therefore they are not capable as well of showing campaign similarities to achieve CVR collaborative filtering.</p><p>In recent years, embedding methods which learn the distributed representation of words through the structure of sentences has made great progress in semantic learning, such as word2vec <ref type="bibr" target="#b6">[7]</ref> and glove <ref type="bibr" target="#b7">[8]</ref>. Without the prior knowledge of the target words, the semantic similarity can be encoded in their representation by analyzing the frequency distribution of their contexts (words appear around it in sentences). Comparing to the disadvantage of abovementioned representations, this method can be a promising choice to extract and fuse the multi-view information of ads campaign based on three main reasons: (1) campaign information appear in sequential structures, such as the ad messages consisting of words, and conversion funnels consisting of rules. With these "sentence"-like data, we are able to learn the semantics of information pieces like ad words or rules; (2) in addition to learning single information pieces, the whole campaign can be learned as a composite of information like "documents" <ref type="bibr" target="#b8">[9]</ref>, which serves our goal genuinely to summarize campaigns based on an individual view of data; (3) the way of bag-of-words learning in predicting words through a document provides an extension of fusing multi-view knowledge by making a campaign simultaneously predict heterogeneous information adopted from all the views. In this way, we are expecting to learn a composite space of campaigns, where the campaign proximity can be shown with a unified embedding, and the complex multi-view characteristics are encoded comprehensively.</p><p>In this work, we develop a Multi-View Multi-Task Embedding with Hierarchical Attention (MVTA) framework to generate composite campaign representations from heterogeneous ads data. Specifically, by treating the semantic learning within each view as an individual task, we learn the campaign embedding by (1) extracting heterogeneous knowledge from each view separately, and (2) learning all the views at the same time, in order to achieve the optimal fusion of heterogeneous semantics into a composite vector. To refine the embedding process, we apply a hierarchical attention mechanism where an intra-view attention helps to better aggregate the contexts within views, and an intertask attention aims to balance the importance across tasks in the overall optimization objective. Finally, we validate the quality of campaign embeddings in the scenario of coldstart campaign forecasting using a real-world advertisement campaign dataset. In summary, we highlight the technical contributions of this paper as follows:</p><p>We identify a different but important research problem of forecasting cold-start CVR for new campaigns. Under the circumstance where the past of campaigns is unknown, we propose an collaborative filtering way of utilizing similar but existing campaigns based on a sophisticated embedding space. We develop a multi-view multi-task embedding framework with a hierarchical attention mechanism to learn a composite campaign representation which is capable of capturing semantic relationship in multiple views of campaign data including ad message, conversion rule and audience targeting. Experimental results based on the real-world data demonstrate that the proposed embeddings manage to characterize the multi-view semantic relationship between campaigns and show the effectiveness in adopting k-NN approach to solve the problem of cold-start campaign forecasting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM STATEMENT</head><p>Definition 1. Conversion occurs when an ad click leads to an user engagement (i.e., a valuable action like "place an order"). A campaign conversion rate evaluates the overall conversionto-click ratio (between 0 and 1) from all the audience in a certain period of time (e.g., a day). Definition 2. Ad message is the sentences displayed by advertiser to inform the audience of promoted products, services or concepts. It can be viewed as a sequence of words and each unique word is associated with an ID. Definition 3. Conversion rule tracks the conversion about a specific action (e.g., "input the payment" or "view the white page"). Funnel is a sequence of rules for tracking a path of conversions, which usually shows user engagements from shallow to deep levels. Since the rules are designed for tracking finegrained actions, there are massive number of rules and each one is associated with a unique IDs. Definition 4. Audience targeting is the selection of campaign receivers by interests, device platforms, and so on. Advertisers decide a set of audience targetings based on campaign strategy to exclusively display their ads. In our work, each targeting is a audience group defined by a combination of a browsing interest and a device type, and each unique audience targeting is associated with an ID. Definition 5. Campaign is a particular promotion for which advertisers need to prepare the ad messages, the conversion funnel, and the audience targetings before the launch. In this work, a campaign consists of a set of campaign instances where each instance independently indicates the campaign under a unique combination of an ad message, a conversion rule, and an audience targeting. Thus, for each unique campaign instance, there exists a corresponding CVR.</p><p>Suppose we have a set of campaigns categorized into two groups: existing campaigns and cold-start campaigns. Accordingly, for existing campaigns we have N 1 campaign instances with observed CVR denoted by f?x i ; y i ?g N 1 i?1 and for cold-start campaigns we have N ? N 1 campaign instances fx j g N j?N 1 ?1 . For existing campaign instances we have x i denoting all the campaign information by three views: ad message, conversion funnel, and audience targeting; and the observed CVR label denoted by y i . For cold-start campaign instances we only have the campaign information x j but the CVR label is unknown.</p><p>Looking into each campaign instance k, the ad message is a sequence of words fw 1 ; w 2 ; :::; w T g; the conversion rule r is a rule from the funnel fr 1 ; r 2 ; :::; r Z g of the campaign; the audience targeting is a particular user group from the targeting set fa 1 ; a 2 ; :::; a M g of the campaign. Each unique campaign instance k, word w, rule r and targeting a is associated with a unique ID.</p><p>In the embedding phase, our goal is to use the multi-view campaign information x of all the instances k to learn the composite campaign instance embedding v k 2 R D . In the following prediction phase, we use the embedding and CVR label of existing campaign instances to train a k-nearest neighbors (k-NN) regressor and predict the unknown CVR of cold-start instances using their embeddings. Major notations can be found in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In this section, we describe the model of Multi-View Multi-Task Embedding with Hierarchical Attention (MVTA) for the goal of learning composite embedding to capture multiview campaign relationship. The modeling motivation and the overall model diagram are presented first. Then we introduce each module of the model in details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Overview</head><p>Given the multi-view information -ad message, conversion rule and audience targeting, we proposed to learn the three views of data in a separate-and-fuse fashion.</p><p>Separate: Each view of the campaign data has the heterogeneity thus express a different type of semantics. Therefore, in the information extraction we need to treat the views separately. We illustrate the semantics of each view as follows:</p><p>From the ad message we extract promoted contents. If two campaigns are having the related promoting themes, they are more likely to have similar CVR by being interesting to similar users, for example, "insurance" and "car sale" campaigns are both interesting to auto consumers. From the conversion rules we extract user reactions. If two rules track actions in very different aspects of user engagement, they are likely to have different CVR, such as "page view" versus. "order submit".</p><p>Fuse: While the heterogeneous views are being extracted, we need to fuse all the views to generate the composite campaign embedding. To achieve optimal information fusion, it is important to integrate the fuse stage with the extract stage as a whole optimization process, because (1) the campaign embedding can be as genuine as the embedding within each view, and (2) can be sophisticated enough to balance each view based on the importance of the information which is being fused.</p><p>Model Overview: Fig. <ref type="figure">2</ref> shows the overview of proposed method. Generally, we develop a multi-task framework by making campaign embeddings (1) separately extract information within multi-views, and (2) simultaneously fuse the target words, rules and targetings included in the campaign. In detail, the lower level of Fig. <ref type="figure">2</ref> illustrates the extraction of two sequences of information -ad message and conversion funnel. Within each view, we add an intraview attention function to better aggregate contexts by distinguishing important ones. In the upper level of Fig. <ref type="figure">2</ref>, we construct a multi-task prediction layer where the campaign embedding is used for fuse its target word, rule and targeting at the same time. Since we need to aggregate the losses of all tasks as an overall objective, we develop an inter-task attention function to better balance the importance of views to achieve descriptive embeddings where more related information gain more attentions in optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Architecture</head><p>Fig. <ref type="figure" target="#fig_1">3</ref> shows the detail architecture of the proposed model. We depict the model by three parts -each part will cover the knowledge extraction in a single view.</p><p>As illustrated in the part of ad message of Fig. <ref type="figure" target="#fig_1">3</ref>, each word w t is mapped to a input vector v w t and an output vector v 0 w t , and each campaign instance k is mapped to a vector v k . To predict the word w t that appears in the messages, we form the input using (1) the surrounding words w t?d ; :::; w t?d defined by a context windows size d and (2) the affiliated campaign instance k. Formally, the objective is to maximize the log likelihood over all words in the campaign instance as</p><formula xml:id="formula_0">L word ? X w t 2k</formula><p>log Pr?w t jw t?d : w t?d ; k?:</p><p>The probability Pr?w t jw t?d : w t?d ; k? is defined using a softmax function as in the Continuous Bag of Words (CBOW) model:</p><formula xml:id="formula_2">Pr?w t jw t?d : w t?d ; k? ? exp?v 0 w t &gt; v w I ? P jW j j?1 exp?v 0 w j &gt; v w I ? ; (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where W is the entire vocabulary, v 0 w is output vector of target words, and v w I is the aggregated input vector of context words and the campaign instance. Here we will continue to the introduction of the next view, and leave the aggregation of v w I with intra-attention to be specified in the following Section 3.3.</p><p>As shown in the part of conversion funnel in Fig. <ref type="figure" target="#fig_1">3</ref>, we aim to learn the semantic of conversion rules by considering the rule co-occurrences in campaign funnels. The goad is to maximize of the log likelihood as</p><formula xml:id="formula_4">L rule ? log Pr?r z jr 1 : r Z ; k?;<label>(3)</label></formula><p>where r z is the particular conversion rule of campaign instance k. r 1 : r Z denote all the rules assigned in the campaign except the one of current instance. Since the length of campaign rules are usually short, to make more samples of rule co-occurrence available in the study, we simply consider all the rest of rules in the funnel as contexts instead of applying a context window. The conditional probability Pr?r z jr 1 : r Z ; k? is also modeled using a CBOW style softmax function:</p><formula xml:id="formula_5">Pr?r z jr 1 : r Z ; k? ? exp?v 0 rz &gt; v r I ? P jRj j?1 exp?v 0 r j &gt; v r I ? ; (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where R is all the unique conversion rules, v 0 r is output vector of target rules, and v r I is input vector combined of the context rules and the campaign instance.</p><p>The last view is audience targeting as shown in Fig. <ref type="figure" target="#fig_1">3</ref>. Each campaign has a targeting set for multiple audience populations in terms of interests and device platforms. Unlike the sequences in ad message or funnel where semantic-revealing contexts exist in neighborhoods, the set of audience targeting is more dependent on particular advertising strategy (e.g., budget) rather than targeting semantic dependency. Due to this reason, we did not form the context of targeting following CBOW architecture, instead, we adopt Skip-Gram (SG) structure for learning this view by predicting the current targeting using the campaign instance solely to form the input vector. The objective in audience targeting learning is formulated by</p><formula xml:id="formula_7">L targeting ? log Pr?a m jk?;<label>(5)</label></formula><p>where a m is the audience targeting of campaign instance k.</p><p>The conditional probability Pr?a m jk? is computed with a softmax function: where A is all the unique audience targetings, v 0 am is the output vector of the current targeting, v k is the input vector of campaign instance.</p><formula xml:id="formula_8">Pr?a m jk? ? exp?v 0 a m &gt; v k ? P jAj j?1 exp?v 0 a j &gt; v k ? ;<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Context Aggregation With Intra-View Attention</head><p>For learning semantics of ad message or conversion funnel, the input vector v w I or v r I consists of two part: contexts and campaign instance. The contexts in each view need to be aggregated to form an intra-view context vector. To aggregate context words or rules as the input vector, all the context embeddings are averaged with a uniform weight traditionally. However, the influence of different words or rules are not always equally informative in real life. Therefore, we develop an intra-view attention to weight (sum up to 1) each context word or rule to obtain a better aggregation. In addition to weighting contexts, the attention function needs to also discriminate the weighting mechanism on different campaign categories. For example, words like "credit" is informative in financial service or real estate campaigns, but may be not in entertainment campaigns. Therefore, we further make the intra-view attention to have campaign category awareness.</p><p>We aggregate context words or rules as non-uniform weighted sum by intra-view attention</p><formula xml:id="formula_9">v ?I ? X t?d j t?d;j6 ?t a w j ;c k v w j v rI ? X 1 j Z;j6 ?z a r j ;c k v r j ;</formula><p>(7? where a w j ;c k and a r j ;c k denote the attention weights given to context word w or rule r in the campaign categories c. The attention weights are calculated by the parameters associated with each unique word or rule:</p><formula xml:id="formula_10">a w j ;c k ? exp?g w j ;c k ? b c k ? P t?d l t?d;l6 ?t exp?g w l ;c k ? b c k ? a r j ;c k ? exp?g r j ;c k ? b c k ? P 1 l Z;l6 ?z exp?g r l ;c k ? b c k ? ; (<label>8?</label></formula><p>where g w2W;c2C 2 R jW j?jCj and b c2C 2 R jCj are the parameters for intra-view attention of ad message; g r2R;c2C 2 R jRj?jCj and b c2C 2 R jCj are the attention parameters for conversion funnel. For simplifying the presentation, here we reuse the notation g and b for intra-view attention parameters of word and rule, which are actually independent from each other.</p><p>Once we obtain the aggregation of context words v ?I and rules v rI , we need to further combine them with campaign instance embeddings to form the final input vectors v w I and v r I . <ref type="bibr" target="#b8">[9]</ref> suggests that concatenation generally provide good input which also confirms the finding in our study. Therefore, for input vector of ad message v w I , we concatenate the campaign instance vector and the context words vector as</p><formula xml:id="formula_11">v w I ? concatenate?v k ; v ?I ?:<label>(9)</label></formula><p>For conversion funnels, some campaigns may only watch one conversion action (e.g., the final purchase). In these cases, unlike ad messages which always include more than one word, conversion funnel can consist of only one rule. Consequently, concatenation can not always be applicable since the rule context can be missing. Therefore, we use an weighted average way to combine the embedding of rule contexts v rI and the embedding of campaign instance v k . We employ a predefined weight 0 g 1 (e.g., g ? 0:5) to preserve the minimum impact of campaign instance against rule contexts:</p><formula xml:id="formula_12">v r I ? v k if Z k ? 1 gv k ? ?1 ? g?v rI otherwise; &amp;<label>(10)</label></formula><p>where Z k denotes the number of conversion rule in k's campaign. If only one rule is deployed in current campaign funnel which is the target rule itself, the input will consist of only the campaign instance v k . Otherwise, we use the weighted average for combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Joint Predictions With Inter-Task Attention</head><p>As shown in the output layer of Fig. <ref type="figure" target="#fig_1">3</ref>, we simultaneously predicting words, conversion rules and audience targetings in a multi-task fashion for fusing all the knowledge in the three views into a single campaign instance embedding. In this joint learning structure, the outputs of three tasks need to be combined as an overall loss for optimization. In real life, the importance of each task is different depends on the informativeness of the predicting word, rule or targeting to be output. For example, when the model is predicting a key word, a high-profit conversion rule, or a major audience group, optimization should put more attention to the loss of this predicting task comparing to others. Based on this motivation, we develop an inter-task attention across the output layer to weight the loss of each view. In objective function, for each time of outputting a combination of a word w t , a rule r z and a targeting a m , we sum up the predicting loss from each individual task L word ?w t ?, L rule ?r z ?, L targeting ?a m ? with non-uniform weights:</p><formula xml:id="formula_13">L overall ? X k2K X w t 2x k b w t L word ?w t ? ? b rz L rule ?r z ? ? ?b a m L targeting ?a m ? ? ;<label>(11)</label></formula><p>where b w t , b rz , b am denote the weights to coordinate the output loss of predicting particular word, rule and targeting. It is worth noting that the weights of view here are dynamically changing in each time of output depending on what the combination of three views is. For example, two b?w t ? of a same predicting word can be different in two times of output based on different rule or targeting accompanying. The inter-task attention weights b is parameterized by</p><formula xml:id="formula_14">b s i ? exp?h s i ? P s i 2fw;r;ag i exp?h s i ? ; (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>where s i 2 fw; r; ag i is a symbol to indicate one of the three predicting views in the i-th multi-task output. For example, when s i represents the output rule r i in the three-view combination of i-th output, we calculate b r i using the softmax function over all the predicting objects including the rest two viewsw i and a i . The inter-task attention parameters are h w2W 2 R jW j , h r2R 2 R jRj , and h a2A 2 R jAj which determine the influence of each unique word, rule, and targeting when they are being predicted. Here we reuse the notation h for each view for simplifying the presentation.</p><p>Once we explain the inter-task attention module, we can write the detail form of the overall loss to optimize the campaign instance embedding:</p><formula xml:id="formula_16">L overall ? X k2K X w t 2x k b w t exp?v 0 w t &gt; v w I ? P jW j j?1 exp?v 0 w j &gt; v w I ? ?b rz exp?v 0 r z &gt; v r I ? P jRj j?1 exp?v 0 r j &gt; v r I ? ? b am exp?v 0 a m &gt; v k ? P jAj j?1 exp?v 0 a j &gt; v k ? ! : (<label>13?</label></formula><p>To optimize Equation ( <ref type="formula" target="#formula_16">13</ref>), we use mini-batch with shuffling to train the model. We adopt sampled softmax loss to increase efficiency by converting the softmax computation from a large class number to a relatively small class number. We update campaign instance embeddings v k with network parameters v w , v r , v 0 w , v 0 r , v 0 a , and attention parameters g, b, h in each iteration. The detail algorithm is summarized in Algorithm 1. Finally, we obtain the trained embeddings of campaign instances v k when the optimization converges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. The Algorithm of MVTA Model</head><p>Input: A set of campaign instances k consisting of ad message {w 1 :::w T }, conversion rule r z , targeting a m . Output: Embedding of each campaign instance v k .</p><p>1: Random initialization for embeddings v k , network parameters v w , v r , v 0 w , v 0 r , v 0 a , and attention parameters g, b, h 2: while not reaching convergence criteria do 3:</p><p>for each campaign instance k do 4:</p><p>for each word w t 2 fw 1 :::w T g do 5:</p><p># Intra-view attention 6:</p><p>Prepare input vector v w I by Eqs. ( <ref type="formula">7</ref>), <ref type="bibr" target="#b7">(8)</ref>, and (9) 7:</p><p>Prepare input vector v r I by Eqs. ( <ref type="formula">7</ref>), <ref type="bibr" target="#b7">(8)</ref>, and (10) 8:</p><p># Inter-task attention 9:</p><p>Predict current word w t by Eqs. ( <ref type="formula" target="#formula_1">1</ref>) and (2) 10:</p><p>Predict current rule r z by Eqs. ( <ref type="formula" target="#formula_4">3</ref>) and (4) 11:</p><p>Predict current targeting a m by Eqs. ( <ref type="formula" target="#formula_7">5</ref>) and (6) 12:</p><p>Obtain the overall loss L i of current output by weighting prediction losses for the three views by Eqs. ( <ref type="formula" target="#formula_13">11</ref>), <ref type="bibr" target="#b11">(12)</ref>, and (13) 13:</p><p>end for 14:</p><p>end for 15:</p><p>Obtain the total loss L by accumulating losses of all outputs L ? P i2I L i 16:</p><p>Optimize L using gradient descent and update all the parameters 17: end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL STUDY</head><p>In this section, we empirically evaluate the performance of the proposed Multi-View Multi-Task Embedding with Hierarchical Attention (MVTA) framework on a real-world ads campaign dataset. 1   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Description</head><p>We format a campaign dataset on a major online ads platform in the U.S. market covering a full day in summer 2017. We obtain 1562 unique campaigns after removing inactive ones, which finally result in a total of 22661 campaign instances. Table <ref type="table" target="#tab_1">2</ref> shows the number of campaign instances in 14 campaign categories. We can see that most campaigns concentrate on "Entertainment", "Financial Services &amp; Insurance" and "Professional Services". Meanwhile, Fig. <ref type="figure">4</ref> shows the histogram of CVR value across campaign instances. We can see that most campaign instances receive less than 0.1 CVR.</p><p>For multi-view campaign information, we obtain 4850 unique words in ad message excluding stop words and rare words, 485 unique conversion rules in conversion funnel, and 182 unique audience targetings covering 3 device types (i.e., desktop, smartphone, tablet) and 84 browsing interests (e.g., mortgage, dating). We randomly sample 10% campaigns to construct the cold-start campaign set. In total we obtain 157 cold-start campaigns including all their 2884 campaign instances with CVR masked. The CVR prediction of these cold-start instances will be completely dependent on the neighboring instances of existing campaign with CVR observed through k-NN regression using the trained embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Approaches</head><p>The experimental study compares our proposed embedding (MVTA) framework with the following baselines:</p><p>Multi-Hot Encoding <ref type="bibr" target="#b9">[10]</ref>: Using one-hot with multiple labels to indicate the presence of all the unique words, rules and audience targetings in campaigns, where 1 indicate existence and 0 for otherwise. Principal Component Analysis (PCA) <ref type="bibr" target="#b10">[11]</ref>: A dimension reduction method using orthogonal transformation  <ref type="bibr" target="#b11">[12]</ref>: A generative statistical model that allows data to be explained by latent groups that explain why some parts of the data are similar. We consider each campaign instance as a document which contains the terms from all information views. Autoencoder (AE) <ref type="bibr" target="#b12">[13]</ref>: A type of artificial neural network used to learn efficient data representations in an unsupervised manner. We use this approach to obtain a low-dimensional representation of multihot vectors. Word2vec <ref type="bibr" target="#b6">[7]</ref>: A two-layer neural network that is trained to reconstruct linguistic contexts of words.</p><p>We use CBOW for this method, every campaign instance embedding is the average vector of all contained information. Doc2vec-DM, Doc2vec-DBOW <ref type="bibr" target="#b8">[9]</ref>: Embedding methods of paragraph and document for capturing the overall semantics. We view all the words, the rule and the targeting belonging to an campaign instance as terms of a document. Two implementations are used: the distributed memory (DM) and distributed bag of words models (DBOW).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Setting</head><p>We use Tensorflow to build the proposed embedding framework. For the hyperparameters, we set window size d to be 5 for the view of ad message following the general word2vec setting as <ref type="bibr" target="#b6">[7]</ref>. Smaller d results in insufficient training examples, while larger d is difficult to be accommodated since native ads usually do not have long paragraphs or sentences. For the intra-view learning of conversion funnels, we set aggregation factor g ? 0:5 to combine the embedding of rule contexts and the embedding of campaign instance to obtain input vector v r I . The intuition is that as the number of rules increase in the cases of long funnels, the learning of context rules will dominate the learning of campaign instance if using averaging aggregation. To prevent this issue, we use g to reserve at least half of the input for campaign instance, and let all the context rules to share the rest part. In this way, we give the rule contexts and the campaign instance the same importance within this view. For more details, we use the sampled softmax loss for more efficient computation. The number of negative samples is 200 for words, 100 for rules, and 100 for targetings. The size of mini batches is 30. The optimizor is Adam with learning rate as 0.0001. For all approaches, except multi-hot encoding, we learn the embedding of 50-dimension resulted from a tradeoff between performance and efficiency. For validation, we first learn the embedding for all campaign instances including both cold-start and existing ones. Then we train the CVR regression model on the existing campaign instances with observed CVR. Finally we obtain the predictions of cold-start instances and evaluate them using regression metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Comparison</head><p>We first evaluate the embeddings of campaign instances through our model against the baseline embedding approaches. We use k-NN regression as it is designed to utilize the information relationship: campaign instances with similar semantics are more likely to locate closely. In our method, we attempt to use trained embeddings to find nearest existing campaign instances, and then use their observed CVR to make prediction of cold-start campaign instances. Specifically, k-NN regression identify Top-K existing campaign instances in neighborhood, and use their CVR to make distance weighted interpolation. We evaluate the error between predicted CVR denoted by ? and groundtruth CVR denoted by y of cold-start campaign instances as follows:</p><p>Mean Square Error (MSE):</p><formula xml:id="formula_17">MSE?y; ?? ? 1 n samples X n samples i?1 ?y i ? ?i ? 2 :<label>(14)</label></formula><p>Mean Absolute Error (MAE) :</p><formula xml:id="formula_18">MAE?y; ?? ? 1 n samples X n samples i?1 jy i ? ?i j:<label>(15)</label></formula><p>R Squared Score (R 2 ) : R 2 ?y; ?? ? 1 ?</p><formula xml:id="formula_19">P n sample i?1 ?y i ? ?i ? 2 P n sample i?1 ?y i ? y i ? 2 :<label>(16)</label></formula><p>Explained Variance Score (EVS) :</p><p>EVS?y; ?? ? 1 ? Var?y ? ?? Var?y? :</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the Mean Square Error (MSE), Mean Absolute Error (MAE), R Squared Score (R 2 ), and Explained Variance Score (EVS) of cold-start CVR prediction results on all approaches with three different neighbor size K for k-NN regression algorithm: 10, 20, and 30. Generally, we can see that our proposed approach MVTA consistently outperforms baseline methods on all metrics in every K neighbor size settings. We also present the improvement percentage of our method over the second best in the baselines which are mostly D2V-DBOW.</p><p>Specifically, first we can see that raw feature approach multi-hot gives a medium-level performance. A possible reason is that although they do not contain semantic relationship as embedding methods do, they do preserve the complete information with the ultra-high dimension. As we discussed, this kind of encoding approach brings vulnerabilities like constraint for new information, computation inefficiency, and overfitting. As a dimension reduced feature of multi-hot, PCA gives average results too. We see that it is similar to multi-hot. A possible reason is that it picks the principle components which select the most informative features. As another common dimension reduction approach, LDA does not provide good results. Since multihot features are very sparse, sometimes it is hard for constructing comprehensive latent topic distribution. Then we have the worse approach in our study: autoencoder. A possible reason is that it focuses on encode data for deep neural network representation, which does not provide semantic expressing embeddings for k-NN methods. Another possible reason is also the sparsity problem of multi-hot features, which may make autoencoder network overfitted. Last, we have the three word2vec based methods. For classic word2vec, we can see that it gives nice results because the semantic similarity is captured. Then Doc2vec-DM does not perform well. A possible reason is that the information from all the views are mixed together for extraction, and attention mechanism is not performed in context aggregation. Doc2vec-DBOW perform relatively well, make the second place generally. Across all the K setting, we find that K = 20 gives the best overall results for almost all approaches.</p><p>To summarize, the experimental results demonstrate that (i) the proposed embedding framework is able to capture semantic relationship of campaign instances based on the three campaign information views; (ii) the proposed design which extracts multi-view information separately and fuses knowledge with multi-task objectives is helpful for better mining ads campaign data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Validation of Hierarchical Attention</head><p>To validate the effectiveness of the hierarchical attention mechanism, we conduct an ablation analysis as shown in Table <ref type="table">4</ref> to demonstrate the importance each attention module contributes to the MVTA model. In the first method "No attention" we utilize the multi-view multi-task architecture but without any attention mechanism. In the second and third methods we simply add the intra-view or the intertask attention function respectively. In the last row we show the performance of complete MVTA model with both attention functions.</p><p>From the results shown in Table <ref type="table">4</ref>, we can observe that the model with neither of attention functions (i.e., "No attention") shows the lowest performance, but still it performs better than the baselines. It suggests that when we are facing heterogeneous multi-view data, this "separate-andfuse" framework is able to effectively extract composite embeddings. Next, we compare the two partial attention models (i.e., "intra-view" and "inter-task") against the full attention model (i.e., "MVTA"). From the perspective of scores, we can see that (1) single intra-view attention has improved the performance by around 3% and 6% for MSE and R 2 while single inter-task attention has less improvement -2% on MSE and 3% on R 2 ; (2) by having both attention components working together (MVTA), we can achieve 6% improvement in average of MSE, and 13% improvement in average of R 2 . These results suggest a collaboration effect of two attentions which exceeds the sum of their individual performances. From the perspective of utility, we believe that attention mechanism is necessary for the proposed model to work on other potential applications or datasets. By flexibly coordinating the intra-view and the inter-task aggregations, the model can be sophisticated and robust to handle different data situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Validation of Multi-View Fusion</head><p>To compare the contribution of different views and to validate the effectiveness of view fusion, we conduct an ablation study of using individual views or two views instead of using them all. All the methods use the same MVTA model where one or two of the views are removed. As shown in Table <ref type="table" target="#tab_3">5</ref>, we have the first 3 rows showing the performance of using each individual view, and the next 3 rows showing the performance of using combination of any two views. Starting from the single views, we can see that generally individual views have the lowest performances in terms of MSE and R 2 . Among them, the view of conversion rules has the highest scores while the view of ad message has a close second place. When we see the combinations of any two views, we can see that first, combination of two views generally provide better performance than single views; and second, the combinations including the view of rules have the highest performance. Based on the best score cross all the neighbor K, the views of msg+rule rank the first place and the views of rule+target rank the second. The last row shows the combination of all views which is the full MVTA model. We can see that by fusing all the views of campaign information, we achieve the best performance. Through this analysis, we first rank the contribution of the views in our study as conversion rules &gt; ad message &gt; targeting. Second, we validate that the proposed model is capable of fusing multi-view information and using more views of data is helpful to improve forecasting results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Sensitivity on Dimensions</head><p>Fig. <ref type="figure" target="#fig_2">5</ref> shows the sensitivity of the model performance on embedding size. Three different dimensions are tested -25, 50, and 100 and two metrics are shown -MSE and R 2 . Generally, we see that the performance increases as the embedding size go large (except dim-100 versus. dim-50 at K=10).</p><p>But the computational cost also goes high when we increase the embedding size. Embedding at 50 dimension shows a relatively good tradeoff between performance and efficiency. For example on K = 20 which shows the best overall performance, we can see that the improvement from dim-25 to dim-50 is significant, but the growth from dim-50 to dim-100 slows down notably. In this case, it is not worth enough using expensive double size of embedding to buy this limited improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Visualization of Campaign Embeddings</head><p>Based on trained embeddings of campaign instances, we apply t-SNE <ref type="bibr" target="#b13">[14]</ref> to generate 2-D representation of them for visualization. We aim to see if the embeddings of campaign instances are able to capture important character of each information view, which can be expressed by proximity in t-SNE space.</p><p>Fig. <ref type="figure">6a</ref> shows the campaign instances colored based on the words in ad messages. We aim to see if the instances expressing similar promotions in their messages are close from each other. We use topics to represent the words in contents. As shown in Table <ref type="table" target="#tab_4">6</ref>, we collect the top frequent words for each campaign category, and try to label instances with topics based on the words in their messages. In detail, some words may belong to more than one topics, we count the frequency for each word on each topic in each instance. Then we choose the highest frequent topic as the instance's label. We color the instance with its ad message topic label. We can see that for "Financial Services" and "Entertainment" topics, instances are quite separated from other topics. But for "Professional Service", instances are easier to mix with other topics including "Technology" and "CPG". Generally, we can see that instance with similar ad messages are more likely to locate nearby.</p><p>Fig. <ref type="figure">6b</ref> colors the campaign instances based on their conversion rules. Although advertisers customize a large number of conversion rules for tracking various actions, each rule can be categorized by engagement themes generally. In our system, 83% conversion rules have categorical themes, and we visualize those available instances in Fig. <ref type="figure">6b</ref>. We find that the similar rules locate closely in embedding space.</p><p>Fig. <ref type="figure" target="#fig_4">7a</ref> shows the distribution of top-20 frequent audience targetings (ranked from bottom to top labels in color   It suggests that audiences from different device platforms also have different conversion behaviors. Fig. <ref type="figure" target="#fig_4">7b</ref> shows the correlation between the proximity on embedding and the difference on CVR value. The CVR of each campaign instance is indicated by color gradient between 0 and 1 where Red means high and blue means low. We can see that low CVR instances and high CVR instances tend to locate separately. This shows that two campaign instances are more likely to receive different CVR if they have small semantic similarity in terms of ad message, conversion rule, and audience targeting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Campaign Instance Relevance Analysis</head><p>In Table <ref type="table" target="#tab_5">7</ref>, we show a case study of k-NN search in the embedding space learned from the MVTA model.</p><p>The left panel of Table <ref type="table" target="#tab_5">7</ref> shows the cold-start campaign instance while the right panel shows the relevant existing campaign instance search by embedding distance. Each ad consists of a title and a description. In the first row, we can see two campaigns for different credit cards: airline card and hotel card. However, these two ads both aim for travel purpose. Therefore, using the hotel card campaign instance we can forecast the cold-start airline card campaign instance. In the second row, existing campaign instance for internet connection service is found to be one of the nearest neighbors for the cold-start campaign instance of TV cable service. The two campaign instances in the third row are both about mortgage loans. The forth row is about financial management. The coldstart campaign instance is related to the medicare expense while the existing campaign case is about financing. In the fifth row, cold-start ad is for car sales while the existing instance is for auto insurance. In the last row, both ads are for IT training. All these searching cases further validate the MVTA embedding in terms of capturing the semantic similarity between campaign instances, and mitigating the challenge on cold-start campaign forecasting.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Conversion Modeling</head><p>In computational ads, conversion rate models the ratio of number of conversions from all clicks, which is widely used for personalized targeting and cost-per-acquisition (CPA) optimization. For example, CVR for an e-commerce website models the likelihood of this visitor becoming a buyer after the visitor clicks the website, i.e., the probability the visitor may convert such as purchase, order, etc. In particular, accurately predicting the conversion rate for user post-click conversions (such as purchasing, filling forms, etc.) is very important for bid optimization. Almost all the existing works focus on user-level CVR prediction by leveraging various ad features to develop sophisticated algorithms, i.e., predicting CVR for a particular user. For example, <ref type="bibr" target="#b14">[15]</ref> introduced an enhanced collaborative filtering (CF) based approach for ad conversion event prediction. <ref type="bibr" target="#b0">[1]</ref> proposed an approach of conversion rate estimation by leveraging observations from user, publisher and advertiser data hierarchies for ad targeting. <ref type="bibr" target="#b15">[16]</ref> estimated the post-click engagement on native ads by predicting the dwell time on ad landing pages. <ref type="bibr" target="#b16">[17]</ref> proposed a novel probabilistic generative model by tightly integrating natural language processing and dynamic transfer learning for CVR prediction. <ref type="bibr" target="#b17">[18]</ref> proposed an additional multi-touch attribution model by considering the ad exposure time and ad exposure browsing path in order to enhance conversion prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ads Related Cold-Start Problem</head><p>Cold-start concerns the issue that the computation system is unable to perform prediction (e.g., CTR prediction, item recommendation, etc.) due to the lack of sufficient history information, which in fact appears frequently in ad serving platforms or recommender systems. To address these issues, <ref type="bibr" target="#b5">[6]</ref> extracted multimedia features such as brightness, colorfulness from display ads to model click prediction. <ref type="bibr" target="#b18">[19]</ref> proposed a new CNN type feature learning pipeline to learn distinctive features from images for cold-start CTR prediction in image display ads. <ref type="bibr" target="#b19">[20]</ref> addressed the cold-start conversation recommendation problem in the online learning setting by developing a preference elicitation framework to identify the questions that should be asked to the new users. <ref type="bibr" target="#b20">[21]</ref> presented a context-aware semi-supervised co-training method using factorization model to tackle the cold-start problem in recommendation systems. <ref type="bibr" target="#b21">[22]</ref> designed a framework to predict the pre-click quality of native ads based on a crowd-sourcing study to identify important ad criteria in native advertisement. <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref> developed multi-armed bandit algorithms for cold-start ads recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Embedding Learning</head><p>Word representation has been largely improved with the rise of neural networks <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. Recent years, the work in GloVE <ref type="bibr" target="#b7">[8]</ref> and word2vec <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b26">[27]</ref> which utilize word dependency in documents to infer word semantics, have greatly increased performances in key NLP tasks, such as document clustering <ref type="bibr" target="#b27">[28]</ref>, and word similarity <ref type="bibr" target="#b28">[29]</ref>. Doc2vec model <ref type="bibr" target="#b8">[9]</ref> has shown very promising performance in learning the representations of paragraph and document.</p><p>Later, <ref type="bibr" target="#b29">[30]</ref> introduced attention mechanism to differentiate word contexts in CBOW model. Because of the advantage in semantic learning, word2vec was then extended to broader application. For example, <ref type="bibr" target="#b30">[31]</ref> presented another query embedding model to capture similarity between queries for helping advertisers identify relevant queries in sponsored search advertising. <ref type="bibr" target="#b31">[32]</ref> learned word embeddings to capture similarity between queries and ads to improve ads display in sponsored search advertising. <ref type="bibr" target="#b32">[33]</ref> developed a time-aware attention mechanism for medical concept embedding from time-series health records. <ref type="bibr" target="#b33">[34]</ref> learned the embeddings of online listing of Airbnb for large-scale personalized searching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Multi-View and Multi-Task Learning</head><p>Multi-view representation learning has grown rapidly as information in multiple forms has been pervasively collected of in many applications <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. Generally, multi-view representation learning can be categorized into two groups: (1) multi-view representation alignment and (2) multi-view representation fusion. Our work falls under the second category which aims to integrate multiview knowledge into a single composite representation. For example, multi-view CNN <ref type="bibr" target="#b38">[39]</ref> was developed for integrating multiple 2D views of objects for 3D object recognition in image processing. RNN encoder-decoder <ref type="bibr" target="#b39">[40]</ref> can also be incorporated for connecting multi-modal sequences. Multi-modal deep autoencoder is proposed to learn shared representation for knowledge fusion <ref type="bibr" target="#b40">[41]</ref>. More recent efforts in this thread have been analyzing the unique properties of individual views in order to achieve an adaptive integration over multi-view information. <ref type="bibr" target="#b41">[42]</ref> proposed a model CPM-Nets to jointly consider the completeness and versatility to conduct flexible and generalizable partial multi-view learning, and the unified representation is able to improve the prediction performance because of its enhanced separability. <ref type="bibr" target="#b42">[43]</ref> developed a latent multi-view subspace clustering algorithm which exploits the complementary information from different views to study the underlying clustering structures comprehensively, and eventually achieves a self-expressive multiview integration. <ref type="bibr" target="#b43">[44]</ref> presented a classification model which dynamically assesses the quality of views in terms of uncertainty, therefore a trusted and interpretable multiview fusion can be assured at the sample level.</p><p>Multi-task learning (MTL) especially in deep neural networks <ref type="bibr" target="#b44">[45]</ref> has successfully improved performance in numerous applications by sharing representations over multiple related tasks for better generalization. For example, <ref type="bibr" target="#b45">[46]</ref> proposed a deep relationship network which use matrix priors to learn the relationship between tasks. Recently, self-paced MTL <ref type="bibr" target="#b46">[47]</ref> has attracted increasing interest by automatically assigning the weights to each task given that tasks have different complexity, importance, or uncertainty. <ref type="bibr" target="#b47">[48]</ref> proposed to adjust single task's relative weight in overall loss function by maximizing the Gaussian likelihood with task uncertainty. <ref type="bibr" target="#b48">[49]</ref> presented a gradient normalization algorithm which dynamically tunes the gradient magnitudes of each task for balancing the training of multiple tasks automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we developed a multi-view multi-task embedding framework (MVTA) with hierarchical attentions to learn an unsupervised and composite campaign embedding for solving cold-start forecasting of conversion rates (CVR) by searching for similar existing campaigns. Specifically, we proposed a multi-view multi-task model to learn campaign instance embedding by simultaneously extracting and fusing three views of campaign information including ad message, conversion rule, and audience targeting. We developed a hierarchical attention mechanism to better aggregate information during optimization at two hierarchies -intra-view attention for individual view context aggregation and inter-task attention for across-views output loss aggregation. In experimental study, we used k-nearest neighbor (k-NN) regression method to forecast cold-start campaign instances based on similar existing campaign instances which have observed CVR. The results based on the real-world ads campaign dataset demonstrated the effectiveness of the proposed method with a consistent performance improvement over baselines. We also conducted ablation analysis on attention mechanism, individual views, and sensitivity analysis on embedding size. In addition, we provided qualitative analysis including t-SNE visualization of campaign instance regarding different views, and case studies on search results for relevant ad campaigns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of multiple views of campaign information: (a) ad message; (b) audience targeting; (c) conversion funnel and rules.</figDesc><graphic url="image-1.png" coords="2,33.05,45.52,237.60,175.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. The model of multi-view multi-task embedding with hierarchical attentions. Three views of information are learned including ad word, targeting and conversion rule. Views of ad message and campaign funnel include context aggregation with the intra-view attentions. All the three views are predicted simultaneously using an inter-task attention to balance task importance. Different categories of color denote different attention functions and the color darkness shows the examples of importance for information on which the attention functions weight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Performance comparison on embedding sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>bar). Each targeting is defined by an fine-grained browsing interest and a device type. The most frequent interest targetings are credit cards, content providers and local services. Both of their desktop and smartphone targetings are on the top list. Meanwhile, we can see that even for the same interest, they are not embedded closely by different device types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. T-SNE visualization of campaign instance by the view of targeting and CVR value.</figDesc><graphic url="image-3.png" coords="10,27.67,544.31,511.20,182.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>Symbols and Notations</cell></row><row><cell>Symbol</cell><cell>Definition</cell></row><row><cell>w t</cell><cell>t-th word from the ad message</cell></row><row><cell>r z</cell><cell>z-th rule from the conversion funnel</cell></row><row><cell>a m</cell><cell>m-th audience targeting of the campaign</cell></row><row><cell>k</cell><cell>A campaign instance</cell></row><row><cell>v v 0</cell><cell>Input vector (embedding), e.g., v k , v w Output vector (parameters), e.g., v 0 w</cell></row><row><cell>g; b</cell><cell>Intra-view attention parameters</cell></row><row><cell>h</cell><cell>Inter-task attention parameters</cell></row><row><cell>d</cell><cell>Window size of words (hyperparam)</cell></row><row><cell>g</cell><cell>Aggregation factor of rules (hyperparam)</cell></row><row><cell></cell><cell>Fig. 2. Overview of campaign embedding framework.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2</head><label>2</label><figDesc>Statistics of Campaign Instances across Campaign Categories</figDesc><table><row><cell>Category</cell><cell>Number</cell><cell>Category</cell><cell>Number</cell></row><row><cell>Auto</cell><cell>137</cell><cell cols="2">Professional Services 2978</cell></row><row><cell>CPG</cell><cell>388</cell><cell>Real Estate</cell><cell>78</cell></row><row><cell cols="2">Careers &amp; Education 215</cell><cell>Reference</cell><cell>171</cell></row><row><cell>Entertainment</cell><cell>8109</cell><cell>Retail</cell><cell>943</cell></row><row><cell>Financial Services &amp;</cell><cell>7145</cell><cell>Technology</cell><cell>996</cell></row><row><cell>Insurance</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Health &amp; Wellness</cell><cell>300</cell><cell>Telecom &amp; Web</cell><cell>431</cell></row><row><cell></cell><cell></cell><cell>Services</cell><cell></cell></row><row><cell>Personals &amp; Social</cell><cell>443</cell><cell>Travel &amp;</cell><cell>319</cell></row><row><cell>Services</cell><cell></cell><cell>Transportation</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Fig. 4. Histogram of CVR.</cell></row></table><note><p>1. Codes are available at: https://github.com/zyao237/mvta to convert possibly correlated variables into a set of linearly uncorrelated variables. latent Dirichlet allocation (LDA)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3 Performance</head><label>3</label><figDesc>Comparisons of CVR Forecasting for Cold-Start Campaign Instances Using k-NN Regression</figDesc><table><row><cell>Methods</cell><cell></cell><cell>MSE</cell><cell></cell><cell></cell><cell>MAE</cell><cell></cell><cell></cell><cell>R 2</cell><cell></cell><cell></cell><cell>EVS</cell><cell></cell></row><row><cell>Neighbors K</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>10</cell><cell>20</cell><cell>30</cell></row><row><cell>Multi-hot</cell><cell cols="7">0.0390 0.0382 0.0385 0.1392 0.1370 0.1378 0.2978</cell><cell>0.3120</cell><cell>0.3075</cell><cell>0.2983</cell><cell>0.3134</cell><cell>0.3098</cell></row><row><cell>PCA</cell><cell cols="7">0.0391 0.0375 0.0374 0.1408 0.1380 0.1383 0.2957</cell><cell>0.3255</cell><cell>0.3269</cell><cell>0.2958</cell><cell>0.3257</cell><cell>0.3272</cell></row><row><cell>LDA</cell><cell cols="7">0.0439 0.0434 0.0435 0.1483 0.1472 0.1483 0.2102</cell><cell>0.2185</cell><cell>0.2166</cell><cell>0.2173</cell><cell>0.2265</cell><cell>0.2251</cell></row><row><cell>AE</cell><cell cols="7">0.0529 0.0507 0.0503 0.1671 0.1644 0.1646 0.0475</cell><cell>0.0883</cell><cell>0.0955</cell><cell>0.0565</cell><cell>0.0942</cell><cell>0.0989</cell></row><row><cell>Word2vec</cell><cell cols="7">0.0390 0.0378 0.0373 0.1403 0.1378 0.1370 0.2989</cell><cell>0.3199</cell><cell>0.3288</cell><cell>0.3004</cell><cell>0.3215</cell><cell>0.3302</cell></row><row><cell>D2V-DM</cell><cell cols="7">0.0444 0.0447 0.0452 0.1539 0.1568 0.1591 0.2017</cell><cell>0.1952</cell><cell>0.1864</cell><cell>0.2036</cell><cell>0.1958</cell><cell>0.1867</cell></row><row><cell>D2V-DBOW</cell><cell cols="7">0.0387 0.0369 0.0363 0.1395 0.1367 0.1364 0.3034</cell><cell>0.3361</cell><cell>0.3468</cell><cell>0.3043</cell><cell>0.3368</cell><cell>0.3470</cell></row><row><cell>MVTA</cell><cell cols="7">0.0338 0.0336 0.0342 0.1321 0.1319 0.1339 0.3902</cell><cell>0.3944</cell><cell>0.3843</cell><cell>0.3908</cell><cell>0.3949</cell><cell>0.3844</cell></row><row><cell cols="13">Improvement 12.67% 8.91% 5.77% 5.28% 3.52% 1.84% 28.60% 17.34% 10.82% 28.42% 17.27% 10.79%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 5 Ablation</head><label>5</label><figDesc>Study on Multi-View Fusion</figDesc><table><row><cell>Views</cell><cell></cell><cell>MSE</cell><cell></cell><cell></cell><cell>R 2</cell><cell></cell></row><row><cell>Nbr. K</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>10</cell><cell>20</cell><cell>30</cell></row><row><cell>Ad msg</cell><cell cols="6">0.0399 0.0395 0.0401 0.2824 0.2895 0.2786</cell></row><row><cell cols="7">Conv. rule 0.0398 0.0385 0.0378 0.2829 0.3062 0.3205</cell></row><row><cell>Target</cell><cell cols="6">0.0460 0.0442 0.0438 0.1717 0.2043 0.2119</cell></row><row><cell>Msg+rule</cell><cell cols="6">0.0361 0.0352 0.0352 0.3498 0.3661 0.3671</cell></row><row><cell cols="7">Msg+target 0.0378 0.0370 0.0370 0.3202 0.3335 0.3332</cell></row><row><cell cols="7">Rule+target 0.0361 0.0358 0.0357 0.3502 0.3560 0.3571</cell></row><row><cell>All views</cell><cell cols="6">0.0338 0.0336 0.0342 0.3902 0.3944 0.3843</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 6 Top</head><label>6</label><figDesc>Frequent Words of Each Campaign Category</figDesc><table><row><cell>Categorical topic</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 7 The</head><label>7</label><figDesc>Neighboring Campaign Instances Searched for the Cold-Start Campaign Instances Through Embeddings Explore Big Data Careers, "We need more people to create positive change through data. Are you up to the challenge?" Today's IT Jobs, "There's more than one career path in IT. Check out some common IT jobs."</figDesc><table><row><cell>Cold-start campaign instances</cell><cell>Relevant campaign instances</cell></row><row><cell>Amex Gold Delta SkyMiles Card, "Official Site. Earn More, Go</cell><cell>Special Offer Ends 5/31, "Earn 80,000 Hilton Honors Points &amp;</cell></row><row><cell>Further with the New 60K Bonus Miles &amp; $50 Statement Credit</cell><cell>Enjoy Travel Rewards! Ends 5/31. Terms Apply."</cell></row><row><cell>Offer from Gold Delta Skymiles. Offer Ends 7/5. Terms</cell><cell></cell></row><row><cell>Apply."</cell><cell></cell></row><row><cell>Premium TV Experience Has People Rushing Home, "See how</cell><cell>Get an Internet adrenaline rush., "Capture the excitement of</cell></row><row><cell>others are enjoying more control, more storage and more</cell><cell>FiOS with blazing fast upload and download speeds, 2 years</cell></row><row><cell>choice, now including over 150,000 Video On Demand titles all</cell><cell>of HBO included and over 150,000 Video On Demand titles."</cell></row><row><cell>with FiOS by Frontier."</cell><cell></cell></row><row><cell>Congress Gives Florida Homeowners Huge Bailout, "If you</cell><cell>Forget Social Security if you Own a FL Home, "If you own a</cell></row><row><cell>own a home in Florida and owe less than $625,000 on your</cell><cell>home, you should read this. Thousands of homeowners did</cell></row><row><cell>home, you better read this now."</cell><cell>this yesterday, and banks are furious! Do this now before</cell></row><row><cell></cell><cell>it's..."</cell></row><row><cell>2017 Lowest Medicare Supplement Rates, "Get a medicare</cell><cell>How Wealthy is Megyn Kelly?, "Some stars are the news;</cell></row><row><cell>supplement plan that will cover up to 100% of your yearly</cell><cell>others deliver the news ... and make a lot of money while</cell></row><row><cell>health expenses."</cell><cell>they're at it. Here's the top 18."</cell></row><row><cell>Best Small SUV, "Looking for a Small SUV? Find the Right</cell><cell>Boston Grads Disrupted A $19 Billion Industry, "This small</cell></row><row><cell>Information and Save Time"</cell><cell>team of data scientists has made an algorithm that is turning</cell></row><row><cell></cell><cell>the giant 19 billion dollar auto insurance industry upside</cell></row><row><cell></cell><cell>down"</cell></row></table><note><p>Left panel: cold-start campaign instances; right panel: the existing campaign instances which are relevant.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Authorized licensed use limited to: University of Kansas Libraries. Downloaded on April 25,2023 at 18:22:17 UTC from IEEE Xplore. Restrictions apply.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>IEEE TRANSACTIONS ON BIG DATA, VOL. 9, NO. 1, JANUARY/FEBRUARY 2023 Authorized licensed use limited to: University of Kansas Libraries. Downloaded on April 25,2023 at 18:22:17 UTC from IEEE Xplore. Restrictions apply.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Miao Lu is currently a machine learning engineer Snap Inc. He has strong interdisciplinary in statistics, machine learning and data mining, with wide applications in biomedical science and internet technology. He published peer-reviewed papers in journals/conferences like WWW, NIPS The Scientific World Journal, SDM MLREC, PLOS Neglected Tropical Diseases, EbioMedicine, Biomarker Research, mBio, Respiratory Medicine, etc, with global impact, particularly on child health and online advertisement.292IEEE TRANSACTIONS ON BIG DATA, VOL. 9, NO. 1, JANUARY/FEBRUARY 2023</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>" For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/csdl.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Estimating conversion rate in display advertising from past erformance data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Orten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dasdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
		<meeting>18th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="768" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-touch attribution in online advertising with survival theory</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Data Mining</title>
		<meeting>IEEE Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data-driven multi-touch attribution models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
		<meeting>17th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="258" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finding the right consumer: Optimizing for conversion in display advertising campaigns</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Josifovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Int. Conf. Web Search Data Mining</title>
		<meeting>5th ACM Int. Conf. Web Search Data Mining</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="473" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Google rolls out similar audiences for search and shopping</title>
		<author>
			<persName><forename type="first">G</forename><surname>Marvin</surname></persName>
		</author>
		<ptr target="https://searchengineland.com/google-rolls-similar-audiences-search-shopping-274210" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multimedia features for click prediction of new ads in display advertising</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
		<meeting>18th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="777" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv</title>
		<meeting>Adv</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empir. Methods Natural Lang. Process</title>
		<meeting>Conf. Empir. Methods Natural Lang. ess</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Mach. Learn</title>
		<meeting>Int. Conf. on Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Digital Design and Computer Architecture</title>
		<author>
			<persName><forename type="first">D</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Rafael, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Halko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-G</forename><surname>Martinsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="288" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonlinear principal component analysis using autoassociative neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIChE J</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="243" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">86</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adaptive online hyperparameters tuning for ad event-prediction models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kagian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Somekh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th Int. Conf. World Wide Web Companion</title>
		<meeting>26th Int. Conf. World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="672" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving post-click user engagement on native ads via survival analysis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int. Conf. World Wide Web</title>
		<meeting>25th Int. Conf. World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="761" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large scale CVR prediction through dynamic transfer learning of global and local features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Big Data, Streams Heterogeneous Source Mining</title>
		<meeting>Workshop Big Data, Streams Heterogeneous Source Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="103" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Additional multi-touch attribution for online advertising</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st AAAI Conf</title>
		<meeting>31st AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1360" to="1366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image feature learning for cold start problem in display advertising</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Int. Joint Conf</title>
		<meeting>24th Int. Joint Conf</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3728" to="3734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards conversational recommender systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Christakopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
		<meeting>22nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="815" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Addressing cold start in recommender systems: A semi-supervised co-training algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 37th Int</title>
		<meeting>37th Int</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Predicting pre-click quality for native advertisements</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Redi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lalmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int. Conf. World Wide Web</title>
		<meeting>25th Int. Conf. World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="299" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Collaborative filtering bandits</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gentile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 39th Int</title>
		<meeting>39th Int</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="539" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On context-dependent clustering of bandits</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gentile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zappella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Etrue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 34th Int. Conf. Mach. Learn</title>
		<meeting>34th Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1253" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int. Conf. Mach. Learn</title>
		<meeting>25th Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From word embeddings to document distances</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kolkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="957" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Not all contexts are created equal: Better word representations with variable attention</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empir. Methods Natural Lang. Process</title>
		<meeting>Conf. Empir. Methods Natural Lang. ess</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1367" to="1372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scalable semantic matching of queries to ads in sponsored search advertising</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grbovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 39th Int</title>
		<meeting>39th Int</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Joint embedding of query and ad by leveraging implicit feedback</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empir. Methods Natural Lang. Process</title>
		<meeting>Conf. Empir. Methods Natural Lang. ess</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="482" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Medical concept embedding with time-aware attention</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th Int. Joint Conf</title>
		<meeting>27th Int. Joint Conf</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3984" to="3990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Real-time personalization using embeddings for search ranking at airbnb</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grbovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
		<meeting>24th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A survey of multi-view representation learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1863" to="1883" />
			<date type="published" when="2019-10">Oct. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A survey on multi-view learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1304.5634</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multiview hessian discriminative sparse coding for image annotation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understanding</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="50" to="60" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Two souls in an adversarial image: Towards universal adversarial example detection using multi-view inconsistency</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Awan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu</title>
		<meeting>Annu</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="31" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multi-view convolutional neural networks for 3D shape recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="945" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multimodal deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Int. Conf. Mach. Learn</title>
		<meeting>28th Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep partial multi-view learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2402" to="2415" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Generalized latent multi-view subspace clustering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="99" />
			<date type="published" when="2020-01">Jan. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Trusted multi-view classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Int. Conf. Learn. Representations</title>
		<meeting>9th Int. Conf. Learn. Representations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">An overview of multi-task learning in deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05098</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Representation learning using multi-task deep neural networks for semantic classification and information retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. North Amer</title>
		<meeting>Conf. North Amer</meeting>
		<imprint>
			<publisher>Chapter Assoc. Comput. Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="912" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Self-paced multi-task learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st AAAI Conf</title>
		<meeting>31st AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2175" to="2181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7482" to="7491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">GradNorm: Gradient normalization for adaptive loss balancing in deep multitask networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 35th Int. Conf. Mach. Learn</title>
		<meeting>35th Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="793" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">His general interests lie in data mining with applications in health informatics, mobile intelligence, and natural language processing</title>
	</analytic>
	<monogr>
		<title level="m">TMIS, KDD, AAAI and IJCAI. Deguang Kong has been leading many ad qual-(e.g., response bidding and forecasting, marketplace optimization, etc) and machine learning projects (e.g., sparse learning, model compression, dialogues and natural language understanding) with Google</title>
		<imprint/>
		<respStmt>
			<orgName>the State University of New Jersey ; The University of Kansas</orgName>
		</respStmt>
	</monogr>
	<note>Yahoo Research. published more than 40 papers at major venues in NIPS, ICML, WWW, AAAI, KDD, WSDM, etc, and served as a PC for these top-tier conferences as well</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
