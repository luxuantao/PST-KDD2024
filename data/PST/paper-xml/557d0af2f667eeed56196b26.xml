<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structure from Stereo-A Review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>STUDENT MEMBER, IEEE</roleName><forename type="first">Umesh</forename><forename type="middle">R</forename><surname>Dhond</surname></persName>
						</author>
						<author>
							<persName><roleName>FELLOW, IEEE</roleName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer and Vision Research Center</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">College of Engineering</orgName>
								<orgName type="institution" key="instit1">ENS Building</orgName>
								<orgName type="institution" key="instit2">University of Texas</orgName>
								<address>
									<postCode>78712</postCode>
									<settlement>Austin</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structure from Stereo-A Review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5716B23967058C972789BA55E82224B0</idno>
					<note type="submission">received October 17, 1988; revised March 30, 1989.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Major recent developments in establishing stereo correspondence for the extraction of the 3-D structure of a scene are reviewed. Broad categories of stereo algorithms are identified based upon differences in image geomewy, matching primitives, and the computational structure used. Performance of these stereo techniques on various classes of test images is reviewed and the possible direction of future research is indicated. Manuscript</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION major portion of the research efforts of the computer</head><p>A vision community has been directed towards the study of the three-dimensional (3-D) structure of objects using machine analysis of images. Analysis of video images in stereo has emerged as an important passive method for extracting the 3-D structure of a scene. Earlier, <ref type="bibr">Barnard and Fischler [6]</ref> presented a review covering the major steps involved in stereo analysis, the evaluation criteria for stereo algorithms, and a survey of the different approaches to computational stereo developed starting from the mid-70's up to 1981. In this paper we review the computational structure of the major schemes that have evolved in the past decade for recovering depth using stereo.</p><p>The basic principle involved in the recovery of depth using passive imaging is triangulation. Many active range sensing techniques are also based upon the triangulation principle. However, in active ranging techniques that use triangulation, the nature of the problem is different in that the triangle for recovering depth is predefined by three points-the light source, the illuminated spot in the scene, and its image point. Thus, in active methods that use triangulation, the correspondence problem has already been solved by using an artificial source of illumination.</p><p>In stereopsis, which is a passive technique, the triangulation needs to be achieved with the help of only the existing ambient illumination. Hence a correspondence needs to be established between features from two images that correspond to some physical feature in space. Then, provided the position of centers of projection, the effective focal length, the orientation of the optical axis, and the sampling interval of each camera are known, the depth can be reconstructed using triangulation. Based upon this basic correspondence problem, a particular matching paradigm can be constructed depending upon the specific matching features used, the number of cameras used, the positioning of the cameras, and the scene domain.</p><p>The problem of passive range sensing is important where there are overriding circumstantial constraints that prevent the use of artificial illumination or other active sources of radiation. Applications of stereo-based depth measurement include automated cartography, aircraft navigation, autonomous land rovers, robotics, industrial automation and stereomicroscopy.</p><p>In the following sections, we identify broad categories of matching algorithms depending upon various factors like the imaging geometry, the matching primitives, as well as the matching strategy used. Within each category, the implementation details of the contemporary approaches will be highlighted. Section I1 gives an overview of the major steps involved in the process of stereopsis, namely, preprocessing, stereo matching, and depth reconstruction. Section I11 examines various computational theories of stereopsis that have been motivated by the human visual system. Sections IV through X describe the major computational techniques that have been successfully tested in the past decade for solving the stereo correspondence problem. In Section IV we review area-based correlation schemes. Relaxation labeling processes have been used by many researchers to iteratively impose global consistency constraints on multiple matches for the purpose of disambiguation, which we describe in Section V. Many stereo algorithms use edge segments obtained from fitting piecewise linear curves to connected edges. Section VI describes two approaches for using edge segments in stereo matching. Stereo algorithms that utilize hierarchical computational structures are described in Section VII. In Section VIII, we examine the use of dynamic programming methods for stereo matching. The trinocular camera setup and the resulting matching paradigm, with both point-and segment-based matching algorithms, are reviewed in Section IX. Section X briefly describes the formulation of the correspondence problem using structural descriptions. Section XI deals with the aspect of performance evaluation of stereo algorithms and the various classes of test data used. Section XI1 contains concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">THE PROCESS OF STEREOPSIS</head><p>The major steps involved in the process of stereopsis are preprocessing, establishing correspondence, and recovering depth. In this section we shall briefly examine each of them. operator (or a simplified version thereof) for feature point Preprocessing of images is an important component of stereopsis. During this stage image locations satisfying certain well-defined feature characteristics are identified in each image. They have to be chosen carefully because the subsequent matching strategy shall make extensive use of these feature characteristics.</p><p>Some of the earlier stereo algorithms used area-based matching schemes in which area patches from two images were matched <ref type="bibr">[18]</ref>, <ref type="bibr">[48]</ref>. Points of interest were located in one image using certain interest operators. Moravec 1481 proposed one such interest operator that computed the local maxima of a directional variance measure over a 4 x 4 (or 8 X 8) window around a point. The sums of squares of differences of adjacent pixels were computed along all four directions (horizontal, vertical, and two diagonal), and the minimum sum was chosen as the value returned by the operator. The site of the local maximum of the values returned by the interest operator was chosen as a feature point whose stereo counterpart was to be found.</p><p>By and large most of the contemporary stereo algorithms match features directly rather than areas (in Section 11-B we shall examine the issues regarding area-based and feature-based matching). Hence, the importance of good feature detectors has increased. Since physical discontinuities in a scene usually project as local changes in gray-level intensity in an image, edges have been increasingly used as matchmg primitives. A large number of edge operators have been proposed that compute the direction of orientation as well as the strength of an edge. Most of the edge operators currently in use can be classified <ref type="bibr">[4]</ref> into three main categories: 1) Operators that approximate certain mathematical derivative operators (such as the Laplacian operator); Operators that involve convolution of the image with a set of templates tuned to different orientations; and Operators that fit local gray-level intensity values surrounding a point with (edge) surface models and extract edge parameters from the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>3)</p><p>The Marr-Hildreth edge operator <ref type="bibr">[39]</ref> has been used by many algorithms for locating edge points during the feature extraction process. The operator convolves a mask approximating the Laplacian of Gaussian ( v *G) function (see Section 111-B) over the entire image and labels the zero-crossings of the convolution output as edge points. The edge orientation on a zero-crossing contour is given by the direction of the gradient of the convolution output. The edge strength is proportional to the magnitude of the gradient of the convolution output. Recently, <ref type="bibr">Torre,</ref><ref type="bibr">and Poggio [73]</ref> have also studied the problem of using differential operators for edge detection. <ref type="bibr">Grimson [19]</ref>--[21], <ref type="bibr">Mayhew and Frisby [44]</ref>, <ref type="bibr">[59]</ref>, Kim and Aggarwal <ref type="bibr">[35]</ref>, and <ref type="bibr">Ayache and Faverjon [l]</ref>, <ref type="bibr">Ayache and Lustman [2]</ref>, among others, use the Marr-Hildreth extraction. The edge detectors proposed by <ref type="bibr">Canny-[ll]</ref>, and <ref type="bibr">Deriche [13]</ref> are also used fairly widely for low-level feature extraction. <ref type="bibr">Baker and Binford [3]</ref> and <ref type="bibr">Ohta and Kanade [54]</ref> locate peaks of the magnitude of the first derivative of the intensity profile along a scan line as feature points for matching. Some, of the other popular gradient edge detectors are the Roberts, the Sobel, and the Prewitt operators <ref type="bibr">[4]</ref>. <ref type="bibr">Haralick [27]</ref> has proposed a stepedge detector based upon the second directional derivative, and compared its performance with the Marr-Hildreth zero-crossing detector and the Prewitt gradient operator.</p><p>[22] and <ref type="bibr">[26]</ref> contain interesting discussions about the comparison of the Marr-Hildreth and the Haralick edge operators. <ref type="bibr">Medioni and Nevatia [46]</ref> used a set of oriented step-edge masks (Type 11) spaced at 30" intervals to extract edge points. <ref type="bibr">Ito and Ishii [30]</ref>, Harwood and Peitikainen <ref type="bibr" target="#b51">[57]</ref>, and others have used Type (11) edge operators consisting of eight template masks tuned to the eight directions of the compass. The mask giving the maximum output decides the orientation and magnitude of the edge. The edges obtained using this type of operators need further processing in the form of edge thnning and edge linking. <ref type="bibr">Raj,</ref><ref type="bibr">,</ref><ref type="bibr">Binford,</ref><ref type="bibr">and Shekhar [62]</ref> have used an operator of Type (111) described in <ref type="bibr">[50]</ref> to detect an edgel (an edge element). The edgel operator fits a directional tanh-surface to a window in the image. Edgels are characterized by their position and orientation. <ref type="bibr">Ballard and Brown [4]</ref>, and Rosenfeld and Kak <ref type="bibr" target="#b63">[68]</ref> contain a more in-depth treatment of edge detectors.</p><p>Linear edge segments have also been used as matching primitives for stereo by <ref type="bibr">Medioni and Nevatia [46]</ref>, <ref type="bibr">Ayache and Faverjon [l]</ref>, <ref type="bibr">Ayache,</ref><ref type="bibr">and Lustman [2]</ref>, <ref type="bibr">Hansen,</ref><ref type="bibr">Ayache,</ref><ref type="bibr">and Lustman [25]</ref> and others. In the segment-based stereo algorithm of <ref type="bibr">Medioni and Nevatia [46]</ref> edge points were extracted using Type (11) edge operators and fitted with piecewise-linear edge segments using the Nevatia-Babu algorithm <ref type="bibr">[52]</ref>. Each edge segment description consisted of the coordinates of its endpoints, its orientation, and the average contrast (absolute value) in gray-level intensity along a direction normal to its orientation. <ref type="bibr">Ayache and Faverjon [l]</ref> obtained edge points by using two methods. The first involved locating the zerocrossings in the output of the convolution of the intensity image with a difference-of-averages filter, and connecting them to obtain a chain of edge points. Then, the magnitude of intensity gradient along each chain was computed by the Sobel operator and portions of chains having connected points with the magnitude of intensity gradient below a certain threshold were discarded. The second method used a modified version of the Canny edge detector <ref type="bibr">[ll]</ref>. In both cases, the intermediate results were chains of connected edges. Each chain of connected edges was then approximated by a set of linear edge segments using a polynomial approximation algorithm <ref type="bibr">[56]</ref>. Each of the resulting edge segments was described using the coordinates of its midpoint, its length, and its orientation. Thus, two of the major types of features extracted from images are edge points and line segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1491</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Matching</head><p>Matching is perhaps the most important stage in stereo computation. Given two (or more) views of a scene, correspondence needs to be established among homologous features, that is, features that are projections of the same physical identity in each view. Matching strategies can be differentiated in the broadest sense according to the primitives used for matching as well as the imaging geometry. Differences in the matching primitives separate area-based matching from feature-based matching. Imaging geometry creates distinctions that separate parallel-axis stereo from nonparallel axis stereo, and binocular stereo from trinocular (and oth6r multiocular) stereo paradigms. Local search procedures for possible matches are governed by the projection geometry of the imaging system, and are expressed in terms of the epipolar constraints. Various local properties of the features to be matched are used in order to achieve a reasonable amount of success in the local matching process. The global consistency of the local matches is then tested by figural continuity' or other similar constraints.</p><p>Area-based stereo techniques use correlation among brightness (intensity) patterns in the local neighborhood of a pixel in one image with brightness patterns in a corresponding neighborhood of a pixel in the other image. First, a point of interest is chosen in one image. A cross-correlation measure is then used to search for a point with a matching neighborhood in the other image. The area-based techniques have a disadvantage in that they use intensity values at each pixel directly, and are hence sensitive to distortions as a result of changes in viewing position (perspective) as well as changes in absolute intensity, contrast, and illumination. Also, the presence of occluding boundaries in the correlation window tends to confuse the correlation-based matcher, often giving an erroneous depth estimate.</p><p>Feature-based stereo techniques use symbolic features derived from intensity images rather than image intensities themselves. Hence, these systems are more stable towards changes in contrast and ambient lighting. The features used most commonly are either edge points or edge segments (derived from connected edge points) that may be located with subpixel precision. Also feature-based methods allow for simple comparisons between attributes of the features being matched, and are hence faster than correlation-based area matching methods.</p><p>Stereo matching paradigms are also characterized by the particular imaging geometry being used. Factors that could be changed include, but are not limited to, the mutual orientation of the optical axes of the cameras (either parallel or nonparallel) and the number of cameras used 'The concept of figure continuity constraint and its various interpretations are discussed in Section 111. (either two or mofe than two). The imaging geometry of a conventional stereo imaging system involves a pair of cameras with their optical axes mutually parallel and separated by a horizontal distance denoted as the stereo baseline. The cameras have their optical axes perpendicular to the stereo baseline, and their image scanlines parallel to the baseline (horizontal). Since the displacement between the optical centers of the two cameras is purely horizontal, the position of corresponding points in the two images can differ only in the horizontal component. Thus the epipolar constraint is obtained as a result of the imaging geometry of the stereo camera system and helps limit the search space in the correspondence problem for stereo analysis. In the conventional parallel-axis geometry, all epipolar planes intersect the image planes along horizontal lines. However if the optical axis of any one of the cameras were not parallel to the world z-direction, then the epipolar lines in the image would appear inclined to the horizontal. Fig. <ref type="figure" target="#fig_4">2</ref> depicts a special case when the coordinate axes (Z, and X,) of only the right camera have been rotated by a pan angle 9 (about the y-axis, Y, ) to Z A and X i , respectively. Then the epipolar lines in the right image L,, L,, and L,, corresponding to points P I L , PZL, and P3, intersect at point E, known as the epipole center of the right image. In general, the coordinate system of each camera could have a pan angle $I (about the world ydirection), a tilt angle 0 (about the world x-direction) as well as a roll angle a (about the world z-direction). Barnard and Fischler [4] contains a more detailed description of image acquisition and camera modeling.</p><p>Thus, extra epipolar line computations become necessary in the case of nonparallel imaging geometry. The advantage of nonparallel imaging geometry is that it allows for a greater overlap of the left and right images of the scene being observed. The epipolar search for matching edge points is usually aided by certain geometric similarity constraints like similarity of edge orientation or edge strength. This matching process is also referred to as local matching.</p><p>The match points obtained as a result of imposing the epipolar constraint on the local matching search could result in two or more candidate matches being judged as having almost equal possibility for getting matched. Or worse, an incorrect match point might satisfy the local matching constraints (epipolar constraint and geometric property constraint) and get chosen as a good match. The disparity obtained by computing the relative displacement of the matching feature points in the two images is used to extract the 3-D depth of the scene point that projects on the two matched points. Thus, if certain assumptions can be made regarding the nature of surfaces in the 3-D scene being observed, they could be used to determine the consistency of the disparities obtained as a result of the local matching, or guide the epipolar search so as to avoid inconsistent/false matching. An inherent assumption that is usually made about objects is that their surfaces are predominantly smooth. The smoothness in depth is expected to result in the smoothness of disparities obtained as a result of the matching process. This is formulated in the form of a regonal disparity continuity constraint. Also the contours on the scene surface project on each image as continuous (or piecewise continuous) curves, whch is the motivation behind the figural continuity constraint. Hence physical features on objects that satisfy the surface smoothness assumption and project on the stereo pair of images as image features would satisfy some form of the disparity continuity and figural continuity constraints. This is otherwise referred to as global matching. Thus, local matching and global matching can be regarded as two phases of the stereo matching process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. 3 -0 Structure Determination</head><p>The conventional parallel, axis stereo geometry provides a disparity value d for each matched pair of points Pr2(xL, y L )   The 3-D reconstruction process of nonparallel stereo systems ([l], [2], [30], [76]) requires a more general approach, since closed form solutions may not exist for many cases. The lines joining the center of projection and the image point in each of the stereo images are projected backwards into space. Then the point in space that minimizes the sum of its distance from each of the back-projected lines is chosen as the estimated 3-D position of the matched point. For nonparallel imaging systems using edge segments as matching features ([l], [2]), the end points of the matched edge segments are projected backwards in space and the 3-D position of the segment is determined using a similar minimization criterion. <ref type="bibr">Marr and Poggio [41]</ref> proposed a feature-point based computational model of human stereopis. Grimson [19],</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">COMPUTATIONAL THEORY OF STEREOPSIS</head><p>[21] developed a computer implementation of their algorithm and demonstrated the effectiveness of this model on standard psychological test images (random dot stereograms) as well as on natural images. A number of additional psychophysical predictions of the Marr-Poggio model have been tested and several modifications have been proposed [17], [44], [49], <ref type="bibr">[59]</ref>. After extensive testing, Grimson [20] embodied these modifications in a newer version of h s implementation. We shall briefly review the implementation of , examine the problems associated with it, and review the modifications whch appear in <ref type="bibr">Grimson's new implementation [20]</ref>.</p><p>A.  based their computational structure of the stereo fusion problem upon biological evidence. Some of the early works by neurophysiologists and psychologists on subjects like existence of independent spatial-frequency-tuned channels The  proposed that the human visual processor solved the stereo matching problem in five main steps. 1) The left and right images are filtered at twelve different orientation-specific masks each approximated by the difference of two Gaussian functions with space-constants in the ratio 1 : 1.75. 2) Zero-crossings in the filtered images are found by scanning them along lines perpendicular to the orientation of the mask. 3) For each mask size, matching takes place between the zero-crossing segments extracted from each filtered image output that are of the same sign and roughly the same orientation. Local matching ambiguities are resolved by considering the disparity sign of nearby unambiguous matches. 4) Matches obtained from wider masks control vergence movements aiding matches among output of smaller masks; 5 ) The correspondence results are stored in a dynamic buffer called the 2.5-D sketch. <ref type="bibr">Marr and Poggio [41]</ref> formulate two basic rules for matching left-and right-image descriptions. Each item in an image can be assigned to one and only one disparity value (uniqueness). Secondly, matter is cohesive. Hence disparity varies smoothly almost everywhere, except where depth discontinuities occur at surface boundaries (continuity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Grimson's Implementation</head><p>Grimson [ 191 implemented the computational theory of <ref type="bibr">Marr and Poggio [41]</ref> and addressed certain implementation details that were not covered earlier by the Marr-Poggio theory.</p><p>1) Feature Extraction: <ref type="bibr">Marr and Hildreth [39]</ref> have shown theoretically that, provided two simple conditions on the image intensity function in the neighborhood of an edge are satisfied, intensity changes occurring at a particular scale may be detected by locating the zero-crossings in the output of the v 2 G (Laplacian of Gaussian) filter. Instead of convolving each image with 12 directional DOG operators, each of which yield an approximation to the second directional derivative, Grimson [ 191 used the Laplacian of Gaussian ( v 2 G ) operator and grouped the zero-crossing points in 12 directional bins. The precise form of the operator is given in polar coordinates ( r , 0) by where U is the Gaussian space-constant. This is a rotationally symmetric function shaped like an inverted Mexican hat (Fig. <ref type="figure" target="#fig_6">3</ref>). The width of the central negative region is given by w 2 -D = 2 a u . <ref type="bibr">Grimson used three [20]</ref> or four <ref type="bibr">[19]</ref> different sizes of filters for his images.</p><p>2) Matching: The algorithm begins with images filtered by the largest filters because the reduced density of zerocrossings makes matching easier. The overall matching strategy of <ref type="bibr">Grimson [19]</ref> uses a coarse-to-fine iterative approach with disparities found at coarser resolutions used to guide match-point search at finer resolutions. <ref type="bibr">Marr [38]</ref>,</p><p>[41] studied the probability distribution of the interval between adjacent zero-crossings of the same sign obtained from the convolution of random dot stereograms with the Laplacian of Gaussian filter. The results indicated that if the disparity between the images is less than + ( w / 2 ) , a search for matches within the range ,(w/2) will yield only the correct match with probability 0.95. However the alternate strategy of using a search space with range f o is used by <ref type="bibr">Grimson [19]</ref> since it allows one to search for matches over a larger disparity range and yet get unambiguous and correct matches with probability 0.5. In <ref type="bibr">Grimson's implementation [19]</ref> for each zero crossing PL(x, y ) in the left image, possible candidate matches P;(x', y ) are searched for along the epipolar line in the right image such that,</p><formula xml:id="formula_0">x + d , -&lt; x'&lt; x + d , +<label>(2)</label></formula><p>as shown in Fig. <ref type="figure" target="#fig_7">4(a)</ref>, where d , is the estimated disparity and w ( = 2 a u ) is the width of the LOG filter. Zero-crossings in the left and right images having the same contrast sign and approximately the same orientation (within k 30') are matched. If only one match is found within the + w region, then that match is accepted as unambiguous, and the disparity is recorded.</p><p>3) Disambiguation of multiple matches: If more than one match is found within the + w region, then the one having disparity of the same type (convergent, divergent, or zero) as the dominant disparity in the neighborhood is accepted.</p><p>Otherwise the match at that point is left ambiguous. This can be regarded as the pulling effect which is described in the psychophysical experiments of <ref type="bibr">Julesz and Chang [32]</ref>. Each 2-D array of matched results is scanned and if the percentage of matched points is &lt; 0.7 then all matches in that region are discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Grimson's Modified Implementation of Marr -Poggio Theory</head><p>Grimson's earlier implementation <ref type="bibr">[19]</ref> of the Marr-Poggio theory [41] imposes a regional continuity check on disparity. Later, <ref type="bibr">Grimson [20]</ref> highlights some of the problems associated with the earlier implementation of the Marr-Poggio theory and presents a modified implementation.</p><p>1) Figural Continuity: Grimson's implementation [ 191 of the Marr-Poggio theory [41] used a regional continuity check on disparity in order to validate the matches. Grimson [20] observed that this caused difficulties in propagation of disparity at occluding boundaries between objects and along thin elongated surfaces. Elsewhere the matched feature points tended to form extended contours. Hence the figural continuity constraint of <ref type="bibr">Mayhew and Frisby [44]</ref> that required continuity of disparity along contours was deemed more appropriate.</p><p>, I (a) Vertical Disparity: There is psychophysical evidence [ 151, [16], <ref type="bibr">[53]</ref> to suggest that the human vision system does resort to eye movements in order to correct gross vertical misalignments in the images. Accordingly, the Marr-Poggio algorithm [41] uses a strict epipolar matchmg strategy (see Section 111-B) after aligning the images in the vertical direction. However, local distortions due to perspective effects, noise in early processing, and discretization effects cause deterioration in matching performance at finer resolutions <ref type="bibr">[20]</ref>. In the modified stereo algorithm, for a zero-crossing at a point PL(x, y ) in the left image, Grimson [20] searches for the corresponding zero-crossing match points P;(x', y') in the region</p><formula xml:id="formula_1">2 0 + 1 0 0 0 Q Q Q O Q Q Q 0 0 0 0 0 0 0 0 0 +I 2 0 + 1 O O O O Q O Q Q O Q O O O O O O O O O O O O O Q O Q Q O O O O O O O O O O O O O O O Q Q Q Q O Q O O O O O O O O O 0 0 0 9 Q Q O Q 0 0 0 0 0 0 0 0 0 0 0 O O O O Q O Q Q O Q O O O O O O O O O O O O O Q O Q Q O Q O O O O O O O O O O O O O Q O Q Q O O O O O O O O O O O</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PI</head><formula xml:id="formula_2">{ ( x ' , y') I x + d , -w &lt; x ' Q x + d , + O ; y -f &lt; y ' &lt; y + E } ( 3 )</formula><p>where w and d j denote quantities described in (2), and 2) Cross-Channel Activity: Mayhew and Frisby [44] postulate the existence of interaction between several spatialfrequency-tuned channels in parallel, as against the sequential coarse-to-fine process proposed by Marr and  Poggio [41]. In simple terms, the rule for cross-channel correspondence requires that any feature attribute or pattern at a disparity location should be supported by a similar feature attribute or pattern in other spatial frequency channels within a certain disparity range, and that dissimilar cross-channel activity patterns should be rejected as figurally rivalrous.</p><formula xml:id="formula_3">(2c + 1)</formula><p>In one stereo algorithm implemented by Mayhew and  Frisby [44], the contrast-signed zero-crossings and peaks of the convolution of each image with the v 2 G operator are encoded at each location for three spatial-frequency tuned channels , as a triplet. Fig. <ref type="figure">5</ref> shows a schematic representation of using cross-channel activity according to <ref type="bibr">Mayhew and Frisby [44]</ref>. The top row of Fig. <ref type="figure">5</ref> shows a triplet of measurement primitives found at a location in one image <ref type="bibr">(say, left)</ref>. Primitive values are marked + , -and . (nil) to signify positive, negative, or nonexistent zero-crossings, respectively. Beneath them are triplets at candidate match-points in the other image (say, right). The bottom row shows the result of the binocular cross-channel correspondence. Correct matches are marked M and incorrect (rivalrous) matches are marked R. If only one image has a primitive at a particular channel, the entry is marked U; and nil entries that match are ignored (marked .).</p><p>3) Disparity Gradient Limit: Burt and Julesz [lo] provide evidence supporting the claim that, for binocular fusion of randqm dot stereograms by the human visual system, the disparity gradient must not exceed 1. <ref type="bibr">Pollard,</ref><ref type="bibr">Mayhew,</ref><ref type="bibr">and Frisby [59]</ref> suggest that for most natural scene surfaces, including jagged ones, the disparity gradients between correct matches is usually &lt;1, whereas it is very rare among incorrect matches obtained for the same set of images.</p><p>Consider the binocular parallel imaging geometry as shown in Fig. <ref type="figure" target="#fig_10">6</ref>   <ref type="figure">Let A L ( x A L ,</ref><ref type="figure">y,</ref><ref type="figure">),</ref><ref type="figure">B,</ref><ref type="figure">(x,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">y e</ref> ) in the left image and AR(xAR, y,), BR(xBR, y,) in the right image be the projections of the world points A , and B,, respectively. Then a cyclopean space is defined such that the origin OC(x,,, yo,) is defined as,  <ref type="figure">= (d,</ref><ref type="figure">)/d( A,</ref><ref type="figure">B,</ref><ref type="figure">)</ref>, where d( A&amp;.) is the cyclopean separation between A , and B,. A disparity gradient limit of 1 defines a cone-shaped forbidden zone for the point A , in the cyclopean space, that is, any point within this forbidden zone violates the criterion for disparity gradient limit of 1. <ref type="bibr">Pollard,</ref><ref type="bibr">Mayhew,</ref><ref type="bibr">and Frisby [59]</ref> propose a new PMF algorithm that imposes a disparity gradient limiting constraint among correct matches. During the matching process, the matching strength of each potential match is evaluated as a sum of the support it receives from all potential matches in the neighborhood that satisfy the disparity limit criterion. In a match-pair of feature points (a,, b,), the support for the candidate match bJ is computed as a weighted sum of the number of potential matches in the neighborhood of b, that have a disparity gradient less than 1, and vice-versa for the support of a,. The PMF algorithm is interested only in the positive support to a potential match offered by surrounding matches that satisfy the within-disparity-gradient-limit criterion, and is unaffected by surrounding matches that exceed the disparity gradient limit. The uniqueness con-image straint is propagated using a discrete relaxation scheme such that if two image primitives a , and b, have the highest matching strength among their respective lists of candidate matches, then the match-pair (a,, b,) is considered as correct. <ref type="bibr">Pollard,</ref><ref type="bibr">Mayhew,</ref><ref type="bibr">and Frisby [59]</ref> also show that since a disparity gradient limit in cyclopean space translates to a gradient limit in the real-world space it is possible even for planar surfaces to violate the disparity gradient limit criterion provided they have a sufficiently steep slope. <ref type="bibr">Prazdny [61]</ref> has suggested the coherence principle to encompass the cohesiveness of matter <ref type="bibr">[41]</ref> as well as the disparity continuity principles, which hold for opaque surface only. It recognizes the case of transparent objects. It allows the occurrence of a discontinuous disparity field if it is a result of several interlaced continuous disparity fields, each corresponding to a piecewise smooth surface. Two disparities facilitate each other if they possibly contain information about the same surface. When they do not interact at all they possibly contain information about different surfaces. <ref type="bibr">Prazdny [61]</ref> suggests one similarity function to quantify similarity between neighboring disparities. A Gaussian similarity function s ( i , j ) is defined as This algorithm uses the quantity Id, -d,J/li -j l in the exponent of the Gaussian that is the disparity gradient used in <ref type="bibr">Julesz [9]</ref>. However, in the Burt and Julesz algorithm increase in disparity difference results in inhibition of support, whereas in the coherence principle of <ref type="bibr">Prazdny [61]</ref>, there is no inhbition. The disparity gradient used by Prazdny [61] is also similar to that in the PMF algorithm [591. V i € { 1 , 2 ; . . , n } where u(x) denotes the square root of the expected value of x 2 and kj are appropriate scaling constants. ( p L , p , ) is considered a correct match if matchp( p L , p , ) evaluates to true. In formulating matchp, Kass suggests one set of functionals 9* = 9uU9u,U9u,~ as the set of first and second partial derivatives of the Gaussian-smoothed images, with the sizes of the space constants being U , u s , and us', respectively. Each 3 is the set of four partial derivatives with space constant U as given by f, being the Gaussian smoothing mask</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0,</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. The Coherence Principle</head><formula xml:id="formula_4">1 -( X ' + y')</formula><p>It is also shown that for synthetic stereo images derived from stationary Gaussian white noise if s &gt;, 2.5, the 12 functionals will have sufficiently low cross-correlations so that they can be regarded as approximately independent.</p><p>IV. AREA-BASED STEREO Much of the earlier work done in stereo matching involves the use of correlation measures to match neighborhoods of points in the given images. Moravec [48] has used area-based correlation with a coarse-to-fine strategy to find corresponding match points. Initially feature points tor [48] that measures directional variance of image intensities in four directions surrounding a given pixel. Given a feature point P in one (source) image, the target image is searched at various resolutions ( X 16, X 8, X 4, and so on) starting from the coarsest. At each resolution the position in the target image that yields the highest correlation coefficient is enlarged to the next finer level of resolution. The process continues till the X l resolution is reached. The same correlation process is applied to nine images taken two at a time to give 36 (9C2) possible stereo disparity values for each point of interest. The disparities and correlation coefficients are combined into a histogram, and a confidence measure is defined based upon the histogram peak. Matches with a confidence measure above a certain threshold are accepted.</p><p>Gennery [ 181 developed a high-resolution correlator that used the matches provided by the previous correlation matcher and produced an improved estimate of the matching point based upon the statistics of noise in the image intensities. Thus high-resolution correlator not only provided improved match points but also gave an estimate of the accuracy of the match in the form of variances and covariance of the (x, y ) coordinates of the match in the second image.</p><p>Hannah [23] developed a correlation-based stereo system for an autonomous aerial vehicle. A modified Moravec operator is used to select control points. Autocorrelation in the neighborhood of a candidate match point is used to evaluate the goodness of a match. Subpixel matching accuracy is achieved through parabolic interpolation of correlation values. In Stereosys [24], Hannah has implemented a hierarchical correlation-based stereo system. Images of lower resolution (say, n X n ) are obtained by smoothing 2n X 2 n images by a Gaussian window and resampling.</p><p>The points for which matches are to be searched for are picked by an interest operator as in [23]. A hill-climbing procedure is used to search for a match-point whose neighborhood results in a maximum in normalized cross-correlation with that of the original interesting point. Matches are propagated over the finer resolution images in the herarchy. Matches found at the finest level are checked by reversing the role of left and right images, and repeating the hierarchical search starting from the just-found matching point. These initial matches are used to guide the match point search of neighboring points using the disparity continuity constraint. Finally the sparse density map is interpolated to construct a dense disparity map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RELAXATION PROCESS IN STEREO</head><p>Relaxation labeling is a fairly general model proposed earlier by <ref type="bibr">Rosenfeld,</ref><ref type="bibr">Hummel,</ref><ref type="bibr">and Zucker [67]</ref> for scene labeling. In the paradigm of matching a stereo pair of images using relaxation labeling, a set of feature points (nodes) are identified in each image, and the problem involves assigning unique labels (or matches) to each node out of a discrete feature space (list of possible matches).</p><p>For each candidate pair of matches, a matching probability is updated iteratively depending upon the matching probabilities of neighboring nodes so that stronger neighboring matches improve the chances of weaker matches in a globally consistent manner. This interaction between neighboring matches is motivated by the existence of cooperative processes in the biological vision systems postulated by Julesz <ref type="bibr" target="#b32">[31]</ref>, <ref type="bibr">Julesz and Chang [32]</ref>, <ref type="bibr">Marr and Poggio [42]</ref>, and others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Marr -Poggio Cooperative Algorithm</head><p>Marr and <ref type="bibr">Poggio [42]</ref> and <ref type="bibr">Marr,</ref><ref type="bibr">Palm,</ref><ref type="bibr">and Poggio [40]</ref> have used the neighborhood information of matchable primitives in a simple iterative scheme. For each scanline pair in the stereo images (Fig. <ref type="figure">7</ref>), a two-dimensional interconnected network of nodes (or cells) is set up. The horizontal and vertical connections are described as inhibitory, meaning all cells along each horizontal (or vertical) line inhibit each other, so that finally only one match remains on each horizontal (or vertical) line (uniqueness constraint). The diagonal connections are termed excitatory, meaning they favor diagonally adjacent matches to have the same disparity (disparity continuity). Fig. <ref type="figure">7(b)</ref> shows the local disposition of the excitatory (+) and inhibitory ( -) linkages in the neighborhood of a cell in the network. The bold lines ( L , = constant and R , = constant) denote inhibitory interactions, and the dotted lines (diagonal, with slope = 1) denote excitatory interactions. A twodimensional disparity continuity constraint can be effected by considering a disc-shaped excitatory neighborhood (Fig. <ref type="figure">7(c)</ref>). In the cooperative process, let Ci, y ; denote the state of a cell at time t corresponding to the coordinate ( x , y ) in Initially the nodes which represent possible stereo matchpoints are loaded with 1's and all others are loaded with 0's. Thus, when the iterations begin, each cell adds the states of the neighboring excitatory potential matches in S ( x , y , d ) (the excitatory neighborhood) to the previous state, and subtracts from it a weighted sum of the states of the neighboring inhibitory potential matches in O ( x , y , d ) (the inhibitory neighborhood). This iterative updating can be represented by the relation</p><formula xml:id="formula_5">-€ c x ' , v ' ; d ' E O ( X . . v , d )</formula><p>where, is the weighting factor for the inhibitor effect, and U is the threshold function. Ths algorithm was shown to obtain stereo fusion for random dot stereograms successfully. It represents a very simple mechanism for the propagation of the uniqueness and the continuity constraints among neighboring match-points for disambiguation of multiple stereo matches in an iterative manner. <ref type="bibr">Drumheller and Poggio [14]</ref> mapped the previous cooperative stereopsis model of <ref type="bibr">Marr,</ref><ref type="bibr">Palm and Poggio [40]</ref> on the Connection Machine [28], using the north-east-westsouth (NEWS) mechanism for near-neighbor communication. The uniqueness constraint in <ref type="bibr">Drumheller and Poggio's implementation [14]</ref> imposed an hour-glass shaped forbidden zone (see Fig. <ref type="figure" target="#fig_13">8</ref>) and did not allow more than one match in the entire forbidden zone, unless the scene contained transparent or narrow occluding objects. Other variations of the cooperative model are proposed by <ref type="bibr">Prazdny [61]</ref>, <ref type="bibr">Pollard,</ref><ref type="bibr">Mayhew,</ref><ref type="bibr">Porrill,</ref><ref type="bibr">and Frisby [60]</ref> and <ref type="bibr">Marroquin [43]</ref>. <ref type="bibr">Barnard and Thompson [7]</ref> and Kim and Aggarwal [ 351 have used the principle of cooperative processing to formulate the relaxation-based algorithms which incorporate more complicated disambiguating constraints. <ref type="bibr">Barnard and Thompson [7]</ref> extract feature points (nodes) from each image using the Moravec interest operator. Each node a , , at position Z,(x,, y,) in the left image L is assigned a set of labels L, that represent the possible candidate matches Z,(x,, y,) in the right image R within a disparity range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Barnard -Thompson Algorithm I ) Computation of Feature Attributes:</head><p>Every label set also contains a label I* in the initial stage, which denotes undefined disparity. A node a , has undefined disparity if point Z / ( x , , y,) in image L does not correspond to any point in image R. Each label 1 of node a , is assigned a weight function w,(l) that reflects the degree of similarity of intensity values in the neighborhoods of the candidate pair. An initial probability estimate pp(1) that the point Zl(x,, y,) in image L has a disparity 1 is then derived from the weight function w,(l).</p><p>2) Relaxation Process: The initial probabilities p:( I) computed from similarity in gray-level intensity values surrounding the match points are now updated iteratively to impose global consistency. That is, the probability p,!( I) is increased if the neighbors of a , have high probability values for disparities close to 1. In particular, at the kth iteration, for a node a , at ( x i , y,) having neighbors ai at (x,, y,), a quantity q,!(I) is defined as</p><formula xml:id="formula_6">4 3 4 = c P/k(I') 111 -1' 11 Q 1</formula><p>where only those neighbors ai are considered whose disparity label I ' differs from I by G 1 in both xand ydirections. The q,k(1) serves as a measure of consistency of disparity in the neighborhood because it increases if more neighbors of a ( i ) have disparities closer to 1. The probabilities p f ( 1 ) are updated at the kth iteration as a,""(</p><formula xml:id="formula_7">I ) = pk( I ) * ( a + b * q,!( I)), 1 # I* and j,!+'(I*) =j,"(l*) (7)</formula><p>where a is the rate constant to delay the suppression of unlikely labels (prevents jk+'(l) from going to 0 if qk(1) = 0), and b controls the speed of convergence.</p><p>The iterative procedure is continued either until the probabilities reach a steady state or a predetermined number of iterations are completed. This relaxation-based algorithm essentially imposes a disparity continuity constraint in the neighborhood of each matchpoint, favoring labels (disparities) consistent with the strong labels (disparities) occurring in the immediate neighborhood. This constraint is similar to the disparity continuity constraint over a region proposed by .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Kim -Agganval Algorithm</head><p>Kim and Aggarwal [35] propose a relaxation scheme that combines three disambiguating constraints, namely, continuity of disparity, figural continuity, and smoothness of probability (certainty) of matching. A conventional parallel-axis binocular setup is considered. Edge points are extracted by convolving each image with the LOG operator and locating the zero-crossings in the output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">) Matching Primitives:</head><p>A novel set of matching primitives is used. Depending upon the connectivity of the surrounding zero-crossings, 16 zero-crossing patterns are identified (see Fig. <ref type="figure">9</ref>). A similarity measure is defined between two zero-crossing points depending upon the zero-crossing pattern surrounding each of them. The relaxation process is set up on lines similar to that explained in <ref type="bibr">Barnard and Thompson [7]</ref>. The collection of all zerocrossings in the left image, which do not have horizontal patterns, form the set of nodes { a l } . Each node is assigned a set of labels L, = {I,} and a probability p , ( l , ) that node a , at point Z , ( x I , y,) in left image L matches Z,(x,, y,) in right image R. A weight function ~~ <ref type="bibr">( 1 , )</ref> for node a , with disparity I , is computed based upon the similarity of the zero-crossing patterns as well as the difference in the intensity gradients. The initial probability pp( I,) that node a , has disparity I, is computed using the weight functions</p><p>2) Relaxation Process: A three-dimensional probability array is constructed on the zero-crossing map. The probability of matching of node a , at Z / ( x , , y,) to a point in R at disparity value 1, is stored in the point ( Z / ( x , , y,), I,) in the 3-D array. In effect, it is a collection of 2-D arrays of probabilities corresponding to the zero-crossing map, with each 2-D array representing probabilities for one disparity value. Z,(x,, yf) and Z I ( x s , y,) are the first and second neighboring zero-crossing points of Z , ( x , , y,) (among the total 8 neighborhood points). <ref type="figure">The p:(l,), pfk(l,),</ref> and<ref type="figure">p,k(l,</ref>) represent the entries in the 3-D array at positions tively. The procedure for updating the matching probabilities is given by W, (1, &gt;.  <ref type="figure">( Z ,</ref><ref type="figure">( x ,</ref><ref type="figure">,</ref><ref type="figure">y,</ref><ref type="figure">),</ref><ref type="figure">I,</ref>) if the points in the neighborhood have a nonzero probability for disparities close to 1, by +1. This is similar to the area-based disparity continuity constraint which checks for surface smoothness and is in common with the implementation of <ref type="bibr">Barnard and Thompson [7]</ref>. However the control of the rate of convergence using F( p,k(l,)) is more flexible rather than a set of constants as used by <ref type="bibr">Barnard and Thompson [7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. STEREO MATCHING USING EDGE SEGMENTS</head><p>The use of piecewise-linear approximations to connected edge points as matching primitives has been shown to be a viable alternative to matching of individual edge points ([l], [2], [25], [46]). Linear edge segments have certain advantages over single-edge points in the matching process. Firstly when edge points are grouped into a piecewise-linear segment, positional error at an isolated point has little effect on the position and orientation of the edge segment and most of the remaining edge points lie very close to the best fit, Secondly the edge connectivity constraint, which states that connected edge points in one image must match to connected edge points in the other image, must be imposed as an explicit disambiguating constraint while matching point-like features as against while matching line segments. On the other hand, due to possible fragmentation of edge segments during preprocessing, allowance has to be made for matching a single segment in ofie image with two or more segments in the other image, and vice versa. <ref type="bibr">Medioni and Nevatia [46]</ref> describe a segment-based matching algorithm that uses a disparity continuity constraint called the minimal differential disparity criterion applied over neighboring edge segments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A, Minimum Differential Disparity Algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I ) Feature Extraction:</head><p>The two stereo images, L and R , are brought into vertical alignment and a parallel-axis imaging geometry is assumed such that the epipolar lines run along horizontal scan lines. The feature-extraction stage described by <ref type="bibr">Nevatia and Babu [52]</ref> is used to extract linear edge segments. Each edge segment is described by the coordinates of its end points, its orientation, and the average contrast in gray-level intensity (absolute value) along a direction normal to its orientation.</p><p>2) Matching Algorzthm: Let &amp;' = { a , } be the set of line segments in L , and B = { b,} be the set of line segments in R. For each segment a, in L , the search space is defined by a parallelogram-shaped window w ( a , ) in R whose one side is a, and the other side is a horizontal vector of length 2 xMAX D , where MAX D is the upper limit on the expected disparity (see Fig. <ref type="figure" target="#fig_15">10</ref>). Similarly for each segment b, in R , a window w(b,) is defined in L. Thus for a match (a,, b,), a, lies in w(b,) and b, lies in w(a,). Two segments x and y are said to be overlapping if by sliding either one of them along a direction parallel to the epipolar line, they can be made to intersect. Segments a, in L and b, in R can match only if a, and b, overlap, they have similar contrast in gray-levels, and have similar orientations. 9,(a,) c w ( a , ) denotes the set of all possible matches for a, of L. A segment a, in one image can be matched to two (or more) segments b,l, br2; . e , b,, in the other image provided none of the candidates b,l,. . . , b,, overlap with each other.</p><p>An evaluation function u'(z, j ) is computed iteratively to determine the merit of each match (a,, b,) as u ' + l ( i , j )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+ c min ' i j h k l d h k -d,,I/card(a,) (9) hk E w ( a , ) uh verifies C 2 ( h k )</head><p>where denotes the smaller of the overlap lengths for the match-pairs (a,, b,) and ( a h , bk). The card (a,) and card (b,) are the number of segments in w ( a , ) and w(b,), respectively. Condition Cl(ah) allows for a, and ah to be matched to the same segment b,( = bk) only if a, and ah do not overlap, and vice versa for condition C,(bk). This allows for the possibility that if a , and ah are parts of a fragmented segment, they can get mapped to a single (unfragmented) segment b,. The evaluation function U ( I , j ) is updated during each iteration depending upon the dis- parities between the segments neighboring a , and b,, and their respective preferred matches. For each segment a , in the window w(b,) (recall, w(b,) defines a neighborhood of a , ) a preferred match b, is found such that, Id,, -d,,l is minimized. During the first iteration, the selection of b, for each U,, is done from among the complete set YP(u,) since the set of preferred matches is empty. For each a,, the match which yields the lowest u ( i , j ) is chosen as the preferred match. Since this matching algorithm minimizes the disparity difference among matched line segments in a neighborhood it is termed as the minimum differential disparity algorithm. This, in effect, imposes a condition that the matched line segment pairs, when reconstructed in space, form 3-D contours of surfaces that are smooth almost everywhere. Thus this matching algorithm has implemented the surface continuity constraint proposed by <ref type="bibr">Marr and Poggio [41]</ref> for a paradigm of stereo matching that uses line segments as matching primitives.</p><p>Recently, Mohan, <ref type="bibr">Medioni,</ref><ref type="bibr">and Nevatia [47]</ref> have proposed a scheme to detect and correct local segment-matching errors based upon disparity variation across linear segments. Let A B and CD (Fig. <ref type="figure" target="#fig_16">11</ref>) be matching linear segments (or linear approximations to segments), and let C'D' be the position of CD when superposed such that pixels with zero disparity coincide. Then it can be shown that disparity varies linearly along the length of the matched segments, and</p><formula xml:id="formula_8">-constant (10) d A d B</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1-w-lEBl</head><p>where dA andd, are the disparities associated with the points A and B, respectively. Next we examine the matching algorithm of Ayache and Faverjon [ l ] that implements the disparity gradient limit approach for imposing a surface smoothness constraint on the reconstructed scene, and for disambiguation of false matches within the framework of segment-based matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Ayache -Fuuerjon Algorithm</head><p>Ayache and Faverjon [l] use descriptions of edge segments with the coordinates of the midpoint, the length of the segment, and its orientation for stereo matching. Un- like the minimum differential disparity algorithm <ref type="bibr">[46]</ref>, this method utilizes a generalized nonparallel axis imaging geometry and uses disparity between midpoints of matching line segments rather than average disparity between corresponding points that lie on matching line segments. A neighborhood graph is used to store the information regarding the adjacency of line segments in each image and a disparity gradient limit criterion (defined for line segments) is used to guide the global correspondence search. A neighborhood graph is constructed for each image using nodes to represent edge segments, and links to connect the nodes satisfying certain neighborhood relationships. Thus, each segment s, has a list of neighbors that is obtained as a union of buckets of segments { b,) attached to windows { w k } that it intersects (see Fig. <ref type="figure" target="#fig_17">12</ref>). The global matchmg stage uses a specialized representation of potential matches called the disparity graph. The idea is to use the disparity graph to propagate these matches within their neighborhoods to recover subsets of 3-D segments lying on a smooth surface patch.</p><p>1) Local Matching Constraints: A pair of line segments a , and b, in the left and right images, respectively, constitutes a pair of potential matches if they satisfy the geometrical similarity constraint for line segments and their midpoints satisfy the epipolar constraint. A pair of edge segments whose length ratio and orientation difference lies below a preset threshold satisfies the geometrical similarity constraint. For the midpoint I , of an edge segment a,, a corresponding point ZR is searched for along the corresponding epipolar line near an expected disparity value. <ref type="bibr">Ayache and Faverjon [1]</ref> compute disparity i n z c a s e of a pair of edge segments as follows (Fig. <ref type="figure" target="#fig_6">13</ref>). If P#,&amp; (part of segment b,) with midpoint I , be a candidate match-segment for P,Q, (part of segment a , ) with center I,., then the disparity d,, between a, and b, is defined by where, E, and ER are the epipole centers in the left and right images, respectively.</p><p>---' R Fig. <ref type="figure" target="#fig_6">13</ref>. Disparity for matched segment pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Global Matching Constraints:</head><p>The global matching scheme of the Ayache-Favejon algorithm [ l ] consists of a prediction and recursive propagation process. A disparity graph is constructed with nodes as pairs of potential matches (a,, b,) between the left and right images, and edges that connect pairs of nodes (a,, b,),( a:, b;) that are adjacent segments in their respective neighborhood graphs. The allowable difference in disparity among neighboring nodes of matched pairs in the disparity graph is called the disparity gradient limit and corresponds to an z variation in depth. For each node of the disparity graph (a,, b,), the neighborhood graphs of ( a , ) and (b,) are recursively explored for potential matched pairs that have disparities within the allowable disparity interval. Out of the potential matches the one with disparity closest to the predicted disparity is chosen. This favors those matches of line segments that make the 3-D scene maximally smooth in the sense of surface continuity as proposed by <ref type="bibr">Marr and Poggio [41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. HIERARCHICAL APPROACHES TO STEREO MATCHING</head><p>In this section we consider algorithms that utilize a hierarchical computational structure for stereo matching.</p><p>The hierarchical structure of the algorithms allows matching information to be interchanged amongst various levels of matching computations, thus imposing global consistency in the disparity map. Apart from the , <ref type="bibr">[41]</ref> considered in Section 111, the computational models of Terzopoulos [71], <ref type="bibr">Hoff and Ahuja [29]</ref>, <ref type="bibr">and Lim and Binford [37]</ref> are some examples of hierarchical approaches to stereo matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Concurrent Multilevel Relaxation</head><p>Terzopoulos [71], <ref type="bibr">[72]</ref> has developed an efficient multilevel relaxation computational model for low-level visual processing in concurrent mode. Conventional multigrid schemes employ recursive coordination of computations and flow of intermediate results starting from the coarsest level and proceeding successively to the finest level. Results at any level are used as approximations for the next level. With the advent of massively parallel architectures, such sequential algorithms result in inefficient use of hardware because most of the time is spent performing relaxations on only a single level, while processors at other levels (if configured in a multilevel architecture) remain idle. The concurrent strategy of Terzopoulos [71] maintains processors on all levels busy performing simultaneous relaxation operations. The concurrent strategy seeks to optimize a multilevel objective functional, with each term having three components: 1) A discrete version of the given functional at each level of a multigrid hierarchy; 2) an additive functional coupling each level (except the finest) to its next finer level; and 3 ) an additive functional coupling each level (except the coarsest) to the next coarser level. A concurrent multigrid algorithm for the problem of computing visible surface representations as formulated in [70] has been implemented. <ref type="bibr">Hoff and Ahuja [29]</ref> have argued in favor of integrating the steps of stereo matchng and surface interpolation. Objects have faces that have a smooth variation in surface normals. Object surface meet on ridges that are smooth (or piecewise smooth) curves in 3-D space. They propose an integration of the matchng and surface fitting processes in a way that the correctness of the choice of matches could be judged by the type of surface it produces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Surfaces from Stereo: An Integrated Approach</head><p>Consider a stereo pair of 4n X4n images. Edge points are extracted using the Laplacian of Gaussian ( v 2G)</p><p>operator at three resolutionsn X n , 2n X 2 n , and 4n X 4n. Initial matching is performed in both left-to-right and right-to-left directions. For each feature point PI in, say, the left image a set of candidate match points {Q,} is selected from the right image according to similarity of local (or geometric) properties of feature points. A set of parameterized functions, planar and quadratic, are fitted to circular image regions centered at each grid point ( x , y ) in sequence. First, up to two planar patches are chosen at each grid point (x,, y,) that give the best least-squares fit-rating with the observed disparity z,. Secondly, quadratic patches are fitted at each grid point to the above combinations of matches. The quadratic surface containing the most points is kept as the best fit for that grid point. Next, depth and orientation contours are detected by fitting bipartite planar patches and detecting discontinuities between the two halves. The bipartite planar patches are actually circular patches divided into two halves by a diameter with a given 3-D orientation. Finally a smooth surface is interpolated away from contours to yield a piecewise-smooth surface map at each resolution. Match-ing of edges at finer resolutions is guided by the interpolated surface at the coarser resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. From Objects to Surfaces to Edgels</head><p>In the hierarchical stereo algorithm proposed by <ref type="bibr">Lim and Binford [37]</ref>, matching begins at the highest level (objects). Results of matching are propagated to each successive lower level (surface boundaries, junctions, and edgels) and are used to guide the matching of lower-level features.</p><p>Edgels are detected using the Nalwa operator [SO] that fits a tanh surface to each window in the image. Edges are linked into connected edges and curves (straight lines or conic sections) are fitted using best-fit criteria of <ref type="bibr">Nalwa and Pauchon [51]</ref>. Surfaces are identified by tracing the boundaries of connected curves using both left-wall following as well as right-wall following strategies. Bodies are identified as groups of surfaces that share edges. The ordering information of surfaces in a body in the left-toright as well as the top-to-down directions is saved to be used later as a matching constraint.</p><p>Matching of bodies is attempted at the highest level. Bodies that lie within the limits of corresponding upper and lower epipolar lines (i.e., having the same extent) are candidate matches. Multiple candidate matches are disambiguated using the left-to-right ordering of bodies along epipolar lines, the number of surfaces in the bodies, and the ordering of surfaces in the bodies. Next the system attempts to match surfaces that have the same extent and so on, down to edge segments and edgels. The advantage of this hierarchical stereo system is that the depth map obtained is already segmented and ready for surface interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Hierarchical Stochastic Optimization</head><p>Barnard [5] has implemented a solution to the stereo matching problem using a stochastic optimization technique called microcanonical annealing. Poggio, Torre, and  Koch [58] have posed the stereomatching problem as imposing a regularization criterion on the stereo images,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-I,(x + D ( x , Y ) , v ) ) ] + h ( V D ) ) d x d ~ (12)</head><p>where <ref type="figure">I L ( x , y )</ref> and<ref type="figure">I,(x, y</ref> ) are continuous intensity functions in the left and right images, respectively, v*G is the LoG operator, O D is the gradient of disparity, and X is a constant. The first term of the integrand in ( <ref type="formula">12</ref>) can be understood as a measure of the difference in image brightness values of corresponding points, and the second term as a measure of disparity gradient.</p><p>In the discrete version, (12) can be represented as minimizing the total potential energy E = Z E ( i , j ) . Finding a disparity map D ( x , y ) that results in the minimal energy constitutes a solution to the stereo correspondence problem. A stochastic optimization technique called microcanonical annealing using the Creutz algorithm [12] is used to control the combinatorial explosion of the search in-volved. Actually the Creutz algorithm [ 121 (microcanonical annealing) is a variation of the standard simulated annealing technique <ref type="bibr">[36]</ref> used for solving combinatorial optimization problems. A coarse-to-fine method of computation speeds up the convergence process. At the coarser level, the number of pixel positions as well as the range of disparity is small. Hence a ground state can be reached quickly which can serve as an initial estimate for the next finer scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. STEREO MATCHING BY DYNAMIC PROGRAMMING</head><p>Baker and Binford [3] use the Viterbi algorithm, a dynamic programming technique, to partition the stereo matching problem recursively based upon the constraint that a left-to-right ordering of edges is preserved along a scanline in a stereo image pair. In this edge-based technique, each edge is treated as a doublet, with a left half-edge and a right half-edge. The dynamic programming procedure is repeatedly applied for matching edge points on each scanline pair. The first and second passes of the Viterbi algorithm (preliminary edge correlation) match half-edges in the left image to those in the right image, and vice-versa. Next, a cooperative procedure uses an edge connectivity constraint to identify surface contours that are not continuous in disparity. That is, a connected sequence of edges in one image should match a connected sequence of edges in the other (both L-to-R and R-to-L). Finally, an intensity-based Viterbi correlation performed between intensity pixels from scanline intervals lying between the paired edges in the two images yields a denser depth map.</p><p>Ohta and Kanade [54] have also used pixel intensities of scanline intervals (delimited by edge points) to guide the intrascanline matching search by dynamic programming. This intrascanline search is formulated as a path-finding problem in a 2-D search space in which vertical and horizontal axes are the right and left scanlines, respectively. This is achieved by defining a cost function associated with each partial path based upon variances of graylevel intensities of the scanline intervals being matched. The edges are numbered from left to right on each scanline, with two ends of each scanline being also treated as nodes. If there are A4 nodes in the left scanline and N nodes in the right scanline, the solution to the intra-scanline search could be represented as a path comprised of a sequence of straight lines form node (0,O) to node ( M , N ) with the optimum cost. The cost of the optimal path from node (0,O) to node m is denoted by D ( m ) , and is the sum of the costs of its primitive paths. A primitive path between nodes k and m is a partial path that contains no vertices as in Fig. <ref type="figure" target="#fig_19">14</ref>. The cost of the optimal path D ( m ) is obtained by recursively adding the cost of each newly added primitive path to the already existing partial optimal path. The results of this intrascanline search are used to establish global consistency among matches achieved in neighboring scanlines using an interscanline search. The interscanline search is aimed at imposing a consistency  constraint among matches obtained at each scanline using edge connectivity. The problem is posed as that of finding the least-cost path between 3-D nodes in a 3-D search space. Each 3-D node is formed as a collection of the 2-D nodes connected across scanlines. The optimal path in the 3 -0 search space is obtained by recursively adding an optimal 3-D primitive path to the existing optimal partial path.</p><p>The approaches of <ref type="bibr">Baker and Binford [3]</ref>, and Ohta and Kanade <ref type="bibr">[54]</ref> are based on the assumption that the ordering of edges remains unchanged for a stereo pair. The ordering of corresponding edges does not remain intact in scenes having large differences in depth, especially if these features were derived from thin, ribbon-like overlapping objects. Such a system is also liable to get confused in case of scenes with repetitive features especially if some of the features are missing in one of the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. TRINOCULAR STEREO</head><p>The trinocular approach to the stereo problem has been proposed recently as an alternative means to conduct the correspondence search. The basic advantage of the third camera has been the extra epipolar geometry constraints offered by the three cameras. Provided the centers of projection of the three cameras are noncolinear, the true match points in the three images satisfy the condition that they must lie on the conjugate epipolar lines of the other two cameras. This allows for disambiguation of the multiple candidate matches that are found during local binocular-type correspondence search. <ref type="bibr">Yachida,</ref><ref type="bibr">Kitamura,</ref><ref type="bibr">and Kimachi [76]</ref> use an edge-based trinocular algorithm to obtain 3-D information about objects. Consider three cameras with centers of projection OB, OH, and 0, at known positions and with their optical axes having known orientations (Fig. <ref type="figure" target="#fig_1">15</ref>). The trinocular the image plane I,, let there be multiple match point candidates { PH,, PH,; . e, P H m } along the epipolar line lBH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Edge-Based Trinocular Stereo</head><p>A set of epipolar lines { l,, } is constructed in I, for each candidate PH, E { pH,, PH,; . ., P H m } . At the intersection P, of each I, , and l,,, the presence of an edge point P, is tested. <ref type="figure">Each triplet ( P E ,</ref><ref type="figure">PH,</ref><ref type="figure">,</ref><ref type="figure">P,</ref><ref type="figure">,</ref>) is tested for local similarity of feature attributes, and the best match is considered. In case some matching ambiguities still persist, the matchpoint candidate that yields a disparity closest to that of the points in the surrounding neighborhood is considered the best match. <ref type="bibr">Ito and Ishii [30]</ref> have proposed a trinocular algorithm that uses a similar epipolar search procedure and a matching coefficient based upon the difference in gray-level intensity values in a 5 X 5 neighborhood of the candidate points. If any of the edge points do not get matched in the first pass due to occlusion, special one-sided matching coefficients are used in a second pass to match occluded points. <ref type="bibr">Ohta,</ref><ref type="bibr">Watanabe,</ref><ref type="bibr">and Ikeda [55]</ref> use a third camera and a relaxation procedure to improve the depth map obtained from binocular stereo. The camera geometry involves a left ( L ) , a right ( R ) , and an upper ( U ) camera, all having axes parallel to each other. The two image pairs L-U and L -R are processed independently using binocular stereo <ref type="bibr">[54]</ref> to give two separate depth maps, H-depth and Vdepth, respectively. The H-depth and V-depth values thus obtained are then combined into one depth image using a relaxation process. In this scheme, the trinocular geometry is used only to provide additional depth values that would be available from using two simultaneous binocular matching processes operating on mutually orthogonal epipolar lines.</p><p>Peitikainen and Hanvood <ref type="bibr" target="#b51">[57]</ref> have used a three-view system with a parallel-axis geometry. The camera geometry involves a base camera ( B ) and two other cameras, H and V, displaced in the horizontal and vertical directions, respectively. Local features of the edge points like edge orientations and intensity contrast are used as local similarity attributes. In addition to the trinocular epipolar constraints, a postprocessing algorithm using connectivity epipolar constraint works as follows:-For any point PE in of contours is also-used to disambiguate multiple matches.</p><p>scene. The edges of the skeletons form a set of primitives over which the following binary scalar parametric relations are defined. I ) Painvise Orientation: The mean orientation of the straight line segment joining the centroids of a pair of skeletal edges. 2) Distance: A function of the length of the straight line distance joining the two centroids of skeletal edge. 3 ) End-distance: A function of the length of the straight line distance joining the closest pair of end points between two edges. <ref type="bibr">Boyer and Kak [8]</ref> have modified the exact matchng approach developed by Shapiro and Haralick <ref type="bibr" target="#b64">[69]</ref> in favor of an information theoretic approach for acheving inexact structural matching by defining interprimitive distance measures and relational inconsistency measures. The stereomatching problem is framed as a consistent labeling problem. The set of primitives in the left image P = { p , } form the object set and the set of primitives in the right image Q = { q, } form the label set. The labeling process utilizes two kinds of information: knowledge about the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Segment-Based Trinocular Stereo</head><p>Ayache and Lustman [2], and Hansen, Ayache, and Lustman <ref type="bibr">[25]</ref> have applied the segment-based (binocular) matching technique of <ref type="bibr">Ayache and Faverjon [l]</ref> to three views.</p><p>In [2], Ayache and Lustman employ a prediction and verification scheme using neighborhood graphs of linear segments in three images that is an extension of the earlier binocular algorithm <ref type="bibr">[l]</ref>. For any segment S, in image 1, if a triplet ( S , , S,, S,) can be found to satisfy the trinocular epipolar constraint of lines LI2, L,,, and L,, (see Fig. <ref type="figure" target="#fig_20">16</ref>), and have sufficient similarity in local geometric properties then it is retained as a potential triplet.</p><p>Subsequently <ref type="bibr">Hansen,</ref><ref type="bibr">Ayache,</ref><ref type="bibr">and Lustman [25]</ref> made further developments in the trinocular matching system using image rectification in the preprocessing stage. The original images are reprojected, as shown in Fig. <ref type="figure" target="#fig_1">17</ref> (for a binocular system), on a new image plane that is parallel to the plane containing the centers of projection of the cameras. As a result, the conjugate epipolar lines become parallel to each other in an image, and align themselves with the image coordinate frame. This reduces the search for matches to the horizontal and vertical lines, thus speeding up the matching process. A problem occurs when, due to some noise in preprocessing, a single segment (say, S,) in the image 1 gets broken up into two (or more) segments, say S, and Si in image 2 (see Fig. <ref type="figure" target="#fig_21">18</ref>). <ref type="bibr">Hansen,</ref><ref type="bibr">Ayache,</ref><ref type="bibr">and Lustman [25]</ref> handle the problem by allowing flexibility in the order in which images are traversed for hypothesis generation. The problem of broken segments was also mentioned earlier by Peitikainen and Harwood <ref type="bibr" target="#b51">[57]</ref>. attributes of each label ( U ) and knowledge about the relationship between labels (9). 9 captures the information regarding the primitive distortion process (due to perspective effects as well as noise effects) and consists of a set of conditional probabilities of an attribute talung on a specific value in the right image, given its value in the left image. 9 captures the changes in the values of relational constraint parameters. It consists of a set of conditional probabilities, each item in the set being the probability that a relational parameter would take on a particular value in the right image having known its value in the left image. An event pp' is defined as the left image primitive p , being assigned to the right image primitive q, in the stereo mapping h. The solution to the consistent labeling problem is considered optimal if the prob [ ptl, p : ~, a , pin] is maximum, given the information in PEP and 9. That is max OPM: prob [ p f l , p i z ; . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, p,knIoEa, A!]</head><p>= prob <ref type="bibr">[hlU, 91. (13)</ref> where, OPM is the optimal probability measure. The following basic assumptions are made in this probabilistic model: 1) Information in U is independent of the information in %' . This is based upon the idea that relational information is perceived by higher-level cognition processes that may be independent of lower-level processes required for the perception of primitive attributes. 2) The a priori probabilities of any particular event p,"f is constant, which translates to the fact that no advance information is available about the correct mapping function. Based upon these assumptions (13) becomes (</p><formula xml:id="formula_9">)<label>15</label></formula><p>The matching of the structural descriptions of the two images is performed in the following steps. For each primitive p , in the left image, a match pool of potential primitives { 4,) is obtained. This is achieved by accessing a look-up table of attributes and computing the distance between the two primitives. Any right primitive whose distance from a left primitive lies withn a certain threshold is included in the match pool. The match pool for each left primitive is then stored in a best-first order. A nilmap entry is added as the last entry of any match pool if the cost associated with the best-fitting primitive in that pool were to exceed a certain threshold value, which signifies that the particular primitive in the left image may not have a matching primitive in the right image. Finally the consistent labeling problem is solved using a backtracking tree search. Out of the resulting list of possible mappings between the two primitive sets, the one that has the lowest value for INCA( R , S ) + DIST,( P, Q) is chosen as the solution to the consistent labeling formulation of the stereo matching problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XI. RESULTS AND DISCUSSION</head><p>In t h s section we shall review the experimental results of some of the stereo matching algorithms and the characteristics of the test images used therein. Testing of stereo algorithms has not been standardized as yet in the research community. Different algorithms have each been tested on different sets of stereo images. Without standardized test procedures, it is difficult to comment on the relative merits of stereo algorithms. However, one can identify the classes of images that have been used to test the algorithms, examine their performance, and know more about the domain of applicability of the algorithms.</p><p>The scene domains used for testing stereo algorithms have ranged from simple blocks world images to outdoor/aerial scenes. The block world images ([SI, <ref type="bibr">[30]</ref>,</p><p>[46], [54], [55], <ref type="bibr">[76]</ref>) are typically scenes depicting an assortment of objects with polyhedral, cylindrical, conical, or spherical surfaces characterized by sharp physical boundaries and/or surface markings, all laid against a sharply contrasting background. Since the features being matched are few and most of them correspond to object boundaries, these images serve well as test images. Indoor (laboratory) scenes ([I], [2], 1251, 1571) represent a hgher degree of complexity in that the background of objects is no longer controlled. This makes the matching task more compli-cated. Also, many straight line edges (provided by doors, windows, and furniture) with their repetitive structure add to the complexity of the correspondence problem. The outdoor/aerial scenes are by far the most unstructured of scene domains and pose more complex matching problems.</p><p>Secondly, the task of computing the accuracy of depth estimates and the correctness of matches is plagued with the problem of lack of reliable ground truth measurements. For example, in the case of random dot stereograms, exact knowledge is available about the disparity value at each pixel in the stereo pair. Such exactness is seldom available in natural outdoor scenes or indoor laboratory scenes. Hence accuracy of the depth estimates is, at best, determined at a few selected points by actual measurement and compared with the results obtained from the stereo algorithm. Finally, stereopsis being a passive method, it suffers from the additional drawbacks namely, the problem of false matches and the sparseness of the resulting depth maps.</p><p>The test images used can be broadly classified into the following categories:</p><p>1) Psychophysical test patterns, 2) Indoor scenes, 3) Synthetic scenes, 4) Outdoor/aerial scenes.</p><p>We shall discuss, in brief, the experimental results obtained in each category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Psychophysical Test Patterns</head><p>Grimson [ 191 used random dot stereograms to compare the performance of the computer implementation of the  of stereo fusion with the results of numerous psychophysical experiments conducted on the human vision system. Random dot stereograms are pairs of images, each consisting of two or more planar patches of random dots such that when a stereo pair is fused by humans a 3-D structure can be perceived. Since the disparity value is known at each pixel position for random dot stereograms, they can be used to test the correctness of the algorithm's performance. Typical 3-D structures used by <ref type="bibr">Grimson [19],</ref><ref type="bibr">[21]</ref> include a square block rising out of a planar background, a series of square planes arranged on top of each other like a wedding cake, and a rectangular staircase pattern. For most random dot stereograms, a 50 percent dot density was used. Each stereogram was analyzed at four spatial channels with w = 4, 9, 17 and 35 pixels. Disparities obtained at coarser channels were used to guide the fusion at finer channels. In case of the pattern with a central square separated in depth from a second plane, out of 11 847 zero-crossing points only three (roughly 0.03 percent) were wrongly matched. Similar patterns with dot densities 25 percent, 10 percent, and 5 percent gave percent mismatch errors of 0.07 percent, 0.04 percent, and 0.06 percent, respectively. The wedding cake pattern (at 50 percent dot density) gave 0.06 percent mismatches. Almost all of the mismatches occurred at the boundary between the planes.</p><p>Grimson also found that the computer implementation [19] of the Marr-Poggio theory was in agreement with other psychophysical test results. Julesz [ 311 found earlier that the human vision system could perform binocular fusion even when one of the images of the stereo pair was blurred. The blurring caused the flat surfaces to be perceived by humans as slightly warped; nevertheless the 3-D structure was preserved. Grimson used Gaussian smoothing to blurr one image of the random dot stereogram before running the algorithm on the computer. The resulting disparity map was consistent with the 3-D structure, but it had a slightly higher number of errors in the reconstructed depth. In addition, <ref type="bibr">Grimson studied [19]</ref> the effect of adding low-frequency as well as high-frequency noise to the random dot patterns. The results were in agreement with the psychophysical evidence found by <ref type="bibr">Julesz and Miller [33]</ref> that stereo fusion is possible for noisy stereograms if the spectrum of the noise is sufficiently far from the spectrum of the pattern. In one example, high-frequency noise was added to one image such that the maximum magnitude of the added noise was twice that of the maximum magnitude of the original image. Results showed that matching was severely impaired for the smallest (w = 4) channel (17 percent wrong matches) whereas the next larger ( w = 9) channel was only marginally affected (6 percent wrong matches). <ref type="bibr">Mayhew and Frisby [44]</ref> used stereograms of textured patterns in order to support the role of the figural continuity constraint in their computational theory of stereopsis. They report a significant (factor of 35) reduction in the ratio of potential false matches to the number of matchable points, after making explicit use of the figural continuity constraint. <ref type="bibr">Pollard,</ref><ref type="bibr">Mayhew,</ref><ref type="bibr">and Frisby [59]</ref> have tested the disparity gradient limit approach for imposing global consistency among matches using random dot stereograms. They report 98 percent correct matches for random dot stereograms that have disparity gradients up to 1.0. The matching performance degrades to about 50 percent correct matches for a disparity gradient of 1.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Indoor Scenes</head><p>The simplest of the indoor scenes are composed of a few objects scattered against a featureless (usually dark) background. Several stereo algorithms ([20], <ref type="bibr">[30]</ref>, <ref type="bibr">[351,</ref><ref type="bibr">[MI,</ref><ref type="bibr">[541,</ref><ref type="bibr">[55]</ref>, <ref type="bibr" target="#b51">[57]</ref>, and [76]) have been tested on blocks world images. <ref type="bibr">Grimson [20]</ref> presents results of matching stereo images of dark blocks placed against a bright background. In a typical blocks world scene, out of 2703 zero-crossing points as many as 1780 (65.9 percent) are reported to have been matched. The difficulty of matching blocks world images increases in the presence of occluding objects and repetitive features on the object surfaces. <ref type="bibr">Medioni and Nevatia [46]</ref> and Ohta and Kanade [54] each report a matching example of a blocks scene (containing the Rubik cube) that has the aforementioned characteristics. Ohta and Kanade [54] compared the number of mismatches (or inconsistencies in matching) before and after the interscanline search for the blocks world scene. The global constraint imposed by the interscanline search was shown to reduce the number of mismatches by more than a factor 4. <ref type="bibr">Ayache and Faverjon [l]</ref> and <ref type="bibr">Medioni and Nevatia [46]</ref> have reported the matching result of a stereo image pair depicting an industrial part. The objects being viewed are essentially similar and provide a means for comparing the performance of stereo algorithms on common ground.</p><p>Indoor scenes of real-life laboratory environments have also been used for verifying stereo matching algorithms. <ref type="bibr">Moravec's [48]</ref> stereo algorithm was used by a mobile cart to navigate its way around obstacles. The stereo system identified world position, the height of each obstacle, and the associated positional error caused by the pixel resolution of the camera and built an internal map of its immediate surroundings. The cart made successive short runs punctuated by halts during which the internal map was updated. The cart made successful runs in both indoor and outdoor environments. Kim and Aggarwal [35] tested their algorithm on indoor room scenes. Estimated depth was checked against actual (measured) depth at a few selected points. Percent error in depth varied between 0.17 percent and 3.7 percent. Percentage of false matches was as low as 2 percent for an optimum choice of parameters in the relaxation process. Ayache and Faverjon [l], and Hansen, Ayache, and Lustman [25] used indoor scenes for segment-based matching. The results report a maximum of 2 percent mismatches after applying global consistency validation.</p><p>such "spaghetti" contour scenes is evident by comparing the percentage matching errors of the highway aerial scene with that of the urban aerial scene (obtained from the Univ. of British Columbia, Vancouver) consisting mostly of buildings and a few roads. The same matching algorithm that resulted in 0.07 percent matching errors for the urban scene gave as high as 2.53 percent errors in the highway interchange scene. <ref type="bibr">Ohta and Kanade [54]</ref> have also tested their algorithm on aerial scenes of the Washington D.C. area ("Pentagon" and "White House" images). <ref type="bibr">Barnard and Thompson [7]</ref>, <ref type="bibr">Medioni and Nevatia [46]</ref>, and Ohta and Kanade [54] have used a synthetic image (obtained from Control Data Corporation) for testing their algorithms. The correctness of matches was checked manually. <ref type="bibr">Ito and Ishii [30]</ref> have tested their trinocular matchng algorithm using a synthetic image of a pyramid-shaped block. Accuracy of depth estimates was found at selected points and compared with the actual depth. The process was then repeated with an actual block placed under similar conditions. In the experimental results with synthetic as well as real blocks world images of Ito and I s h [30], the estimated maximum percent positional error of the selected 3-D points was within + O S percent with the maximum percent measured error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Synthetic Scenes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Outdoor Scenes</head><p>Grimson [20] tested his implementation of the Marr-Poggio theory on a number of aerial terrain images ("Phoenix" and "Ft. Sill" images). An interesting case depicts a highway interchange scene (" Boeing" image) that consists of a number of thin, elongated, and closely-spaced contours, each at different depths. The difficulty caused by " Y</p><p>One of the major differences among the different stereo algorithms discussed in this paper is the way they handle the global consistency of the matches obtained. As was mentioned earlier in Section 11-B, a stereo algorithm can detect false positive matches obtained as a result of the local matching procedure by looking for other matches in the neighborhood that are consistent in disparity with that particular match. The disparity value for a given match is easily translated to a depth estimate by inverting the perspective projection equations. The prime motivation for imposing some sort of continuity constraint on the disparity values is that a mismatch would result in a disparity value that would translate into a strikingly discontinuous depth estimate as compared to the other neighboring points. <ref type="bibr">Marr and Poggio [41]</ref> have proposed a coarse-to-fine approach for propagation of the disparity continuity in the neighborhood of the matches. A purely region-based approach, as in [41], for imposing disparity continuity does not work very well when the scene is composed of a large number of thin, ribbon-like overlapping objects at various depths that partially overlap each other. This was recognized by many researchers like Grimson [20], Mayhew and  Frisby [44], Kim and Aggarwal [35], Baker and Binford [3], and <ref type="bibr">Barnard and Thompson [7]</ref>, who among others have also included a figural continuity constraint in their stereo implementations. In the figural continuity constraint, a potential match (i, j ) is favored if all their connected, neighboring matches ( h , k ) also have similar disparities. Figural continuity is used in segment-based matching in an implicit manner by which connected edge points are grouped together into segments and are matched as a group. <ref type="bibr">Medioni and Nevatia [46]</ref> apply the minimal-differential-disparity rule for edge segments (a,, b,) by taking into account the disparity of each of the edge points in the segments and then taking an average disparity d l J . In the segment-based matchng of Ayache and Faverjon [l], for a match pair ( u l , b,), the disparity d,, does not explicitly take into account the disparities of the individual points in the edge segments but is computed using the positions of midpoint of a, ( I , ) and its corresponding potential match in segment b, (IR). The edge segments are treated as one unit, and the disparity of neighboring edge segment matches is constrained by a disparity gradient limit (defined meciallv for edge segments). <ref type="bibr">Kim and Aggarwal [35]</ref> have used a relaxation (cooperative) algorithm that uses a smoothness constraint on the probability of matching, in addition to the aforementioned constraints of regional continuity of disparity and figural continuity. Also, rather than using individual edge points or edge segments, they use 16 distinct edge (zero-crossing) patterns as matching primitives.</p><p>A disparity gradient limit approach is proposed in the PMF algorithm by <ref type="bibr">Pollard,</ref><ref type="bibr">Mayhew,</ref><ref type="bibr">and Frisby [59]</ref> as an alternative to the figural continuity criterion, and it allows for matching of smooth as well as jagged surfaces.</p><p>The left-to-right (L-to-R) ordering of edges has also been used as a global matching constraint to disambiguate multiple matches and identify false positive matches. <ref type="bibr">Baker and Binford [3]</ref>, and <ref type="bibr">Ohta and Kanade [54]</ref> have used the L-to-R ordering constraint in their dynamic programming algorithm to do the intrascanline search. In the <ref type="bibr">Ayache-Faverjon algorithm [l]</ref>, an L-R ordering relationship is used in building the disparity graph of edge segments from the left and right images. The disparity graph guides the prediction of matching hypotheses and thus controls the matching search. However, it must be noted that an L-R ordering constraint is not universally valid for guiding a binocular search. In the presence of transparent objects and/or thin, ribbon-like objects (also called spaghetti contours), differences in depth could result in the reversal of the L-R ordering of feature primitives on a scanline.</p><p>Apart from the factors discussed previously, the performance of various stereo algorithms can be dependent upon a lot of implementation details like the choice of threshold factors and the rate constants used to control the convergence of iterative algorithms. Also the behavior of a stereo algorithm in widely different scene domains needs to be understood carefully before choosing any one algorithm to be used in an application.</p><p>In this paper the authors have presented a broad review of the major recent developments in stereo algorithms. Experimental results of a variety of computational techniques have been grouped according to the scene domains on which the tests were conducted, and comparisons are made wherever possible. However it must be noted that the matching statistics like percentage error in depth, and percentage of mismatches mentioned in this paper appear as they were quoted in the respective technical publications of the said author(s) and were not observed under strictly identical conditions. Hence, if the reader is interested in building an application of a stereovision depth finder for a specific scene domain, a certain degree of caution needs to be exercised in the interpretation of the performance statistics and in understanding the trade-offs between various approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XII. CONCLUSION</head><p>In this paper we have presented a review of the major techniques developed in the recent past for recovering the 3-D structure of a scene from analysis of stereo images.</p><p>We have outlined the three main stages of stereo analysis, namely, preprocessing, establishing correspondence, and recovering depth. Based upon the differences in matching primitives as well as the imaging geometry being used, distinctions were made between area-based and featurebased matching, between parallel-axis and nonparallel axis stereo, between point-based and segment-based matching, and between binocular and trinocular matching.</p><p>We described the computational theory of stereopsis formulated by <ref type="bibr">Marr and Poggio [41]</ref>, which is motivated by a model of the human stereo vision system, and that formulates the basic constraints of uniqueness and regional continuity. Mayhew and Frisby developed further upon the figural continuity [44] and disparity gradient limit <ref type="bibr">[59]</ref> criteria that impose global consistency constraints in order to disambiguate false matches. In the successive sections, we describe the different approaches developed for solving the stereo correspondence problem: area-based matching <ref type="bibr">[MI,</ref><ref type="bibr">[48]</ref> The major issue involved in the stereo analysis of images is the correspondence problem. Algorithms need to be improved to give a lower percentage of false matches as well as better accuracy of depth estimates. Performance of algorithms needs to be evaluated over a broad range of image types in order to test their robustness. Most of the stereo work done so far has been limited to developing basic stereo matching capabilities for workmg with simplistic images. A great deal of research in stereo is needed in order to not only overcome the abovementioned difficulties but also to apply stereo techniques to solve more real-world problems.</p><p>dian Institute of Technology, Bombay, in 1985, and the M.S degree in electncal and computer engineenng from Louisiana State University, Baton Rouge, in 1987.</p><p>He is currentlv a Research Assistant at Computer and Vision Research Center, The University of Texas at Austin, and is working towards the Ph.D. degree. His research interests include computer vision, image processing, and artificial intelligence J. K. Aggarwal (S'62-M65-SM74-F'76) received the B S degree in mathematics and physics from the University of Bombay, India, in 1956, the B Eng degree from the University of <ref type="bibr">Liverpool, England, in 1960, and</ref>   Systems (1972), Nonlinear Systems Stability Analysis <ref type="bibr">(1977)</ref>, Computer Methods in Image Analysis <ref type="bibr">(1977)</ref>. Digital Signal <ref type="bibr">Processing (1979)</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>001 8-9472/89/1100-1489$01 .OO 01989 IEEE A. Preprocessing IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, VOL. 19, NO. 6. NOVEMBER/DECEMBER 1989</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Parallel axis stereo geometry.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig.1shows the imaging geometry of a stereo pair of cameras. The two cameras are represented by their equivalent pinhole approximation models with their image planes, IL and I,, reflected about their centers of projections, 0, and OR, respectively. The origin of the world coordinate system is at 0,, the effective focal length of each camera is f, and the stereo baseline is b. The world coordinate axes X,, Y,, and Z , coincide with the coordinate axes of the left camera, X,, Y, , and Z,, respectively. Let P,(xL, y,, z,)    and PR(xR,yR,zR) be the projections ofLhe 3-D scene point P ( x , y , z ) . The rays of projection PO, and PO, define the plane of projection of the 3-D scene point called the epipolar plane. For a given point PL in the left image, its corresponding match point PR in the right image must lie on the line of intersection of the epipolar plane and the image plane that is called the epipolar line. The epipolar line in the right image corresponding to a point P, in the left image defines the search space within which the corresponding matchpoint P, should lie in the right image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and PR(xR, yR) (see Fig. 1) as, d = xL -xR. By considering similar triangles, the world coordinates of the scene point P(x, y , z ) can be easily obtained as bx L by, bf x=-d , y = d , and z =d where b is the stereo baseline and f is the effective focal length of the camera.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Nonparallel axis stereo geometry</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>in the human and other biological vision systems were used to formulate the outline of the theory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3. 2-D Laplacian of Gaussian.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig 4</head><label>4</label><figDesc>Fig 4 Search space In Gnmson's algonthm P i ( x ' . y ) is shown as black dot Search space is shown as shaded dots around PR (a) Ongnal implementation (b) Modified implementation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>is the height of the search space in the vertical direction (see Fig. 4(b)). D. Mayhew -Frisby Theory of Disparity Gradient 1) Figural Continuity: Mayhew and Frisby [44] propose a new interpretation of the surface continuity constraint, to include figural continuity. They extend the Marr-Poggio concept [41] of continuity to imply that edges of surfaces and surface markings would also be continuous resulting in continuity of disparity along figural contours. Baker and Binford [3], and Ohta and Kanade [54] also used a similar figural continuity constraint along with the added restriction of left-to-right ordering of edges for stereo matching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>with image centers O,(xoL, yo) and OR( xoR, yo), separated by baseline b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 5. Cross-channel correspondence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>F</head><label></label><figDesc>. Multifeature-Based Matching are identified in each image by the Moravec interest opera-Kass [34] proposes the use of matching coefficients obtained from a large number of uncorrelated (independent) measurements to contribute towards the local matching constraint. If the local matching constraint is chosen appropriately it is postulated that a large fraction of the points in the first image will have only one potential match in the second image making it unnecessary to use global consistency measures. Kass [34] has used a stochastic image model to substantiate this computational framework. The local matching constraint proposed by Kass [34] relies on a representation of local intensity variation in the form of functionals f,( p , I ) , 1 &lt; i &lt; n for each point p in image I . No single image measurement (functional) is expected to contain all the information about the correspondence of a pair of image points. The functionals have been chosen to be orthogonal (low cross-correlation), linear, shift-invariant operators. At each point p , a vector Since each functiondl h( p , I ) in the representation defines a similarity measure for correspondence, F( p L , I L ) -F( p , , I , ) is expected to be very small in each component, if p L and p R are truly matched. If p L and p R do not correspond, F( p L , I L ) -F( p,, I,) will most probably have at least one large component. A predicate matchp(p,, p , ) is defined such that matchp( p L , p , ) is true if and only if, F( P , I ) = (f,&lt; P , I ) , f2( P , 0,-. ., f , ( p , 0) is formed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig</head><label></label><figDesc>Fig. 7. Excitatory and inhibitory neighborhoods for Marr-Poggio cooperative algorithm. (a) Network of nodes for one scanline pair. (b) Linear excitatory neighborhood. (c) Disc-shaped excitatory neighborhood.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Neighborhoods for Drumheller's implementation. the left-image matching ( x + d , y ) in the right image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>(</head><label></label><figDesc>Z / ( X , ? Y,)? I,)? ( Z / ( X f ' Y,). 1,) and ( Z / ( X , , Y,)? I,)? respec-P!+'@,) = P X l , ) + c * E.( P:(g) * (Pi)d * P W , ) * W F S ) Pfk ( ' J + I)] P," ('J ) P,k (I, + ')] psk =The foregoing formula combines three constraints-disparity continuity, figural continuity, and smoothness of probability of matching. The function F( pk( I,)) controls the rate of convergence in two ways: 1) It reduces the tendency to converge fast to the most probable disparity value so that less-probable values may still have chances to compete; and 2) If all other conditions are the same, the magnitudes of increases of higher probabilities are hgher. In other words, the third term in (8) implements the figural continuity criterion proposed by Mayhew and Frisby [a].The p i and p i check the existence of nonzero probabilities for a match with disparity I , in the connected neighborhood of Z / ( x , , y,). If the connected zero-crossings do not have disparities within the disparity gradient limit f 1 of I,, Z(P,) is set and the probability jk+l(l,) is decre-mented. The second term in (8) reinforces the probability at</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Parallelogram-shaped search window. (a) Left image. (b) Right image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Disparity change across linear segments. (a) Left image. (b) Right image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Partitioning of segments into buckets. Examples of neighbors of segments are S,: {SI, &amp;, S,, S,} and &amp;: {SI. &amp;, S,. S,, &amp;I}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Fig. 15. Trinocular imaging geometry.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. 2-D search plane for intra-scanline search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Trinocular segment matching. (a) Image 1. (b) Image 2.(c) Image 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 17. Rectification of two images by reprojection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>, relaxation labeling [7], [35], dynamic programming [54], hierarchical approaches [5], [29], [37], [71], segment-based matching [l], [46], trinocular matching (edge-based [30], [55], [57], [76], as well as segment-based [2], [25]), and structural matching [SI. The performance of various approaches was discussed for different classes of test images and the difficulties involved in the evaluation of stereo algorithms were addressed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>, and Deconuolution of Seismic Datu (1982) His current research interests are image processing and computer vision Dr Aggarwal IS an active member of IEEE Computer Society, ACM, AAAI, the International Society for Optical Engneenng, the Pattern Recognition Society, and Eta Kappa Nu He was CO-Editor of the Special Issue on Digital Filtenng and Image Processing of the IEEE TRANSAC-TIONS ON CIRCUITS AND SYSTEMS, March 1975, and on Motion and Time Varying Imagery, IEEE TRANSACTIONS PATTERN ANALYSIS AND MA-CHINE INTELLIGENCE, November 1980, and Editor of the two-volume Special Issue on Motion of Cornputer Vision, Graphics and Imuge Processing, January and February 1983 He was the General Charman for the IEEE Computer Society Conference and Pattern Recognition and Image Processing, Dallas, TX. 1981, and was the Program Charman for the First Conference on Artificial Intelligence Applications sponsored by the IEEE Computer Society and AAAI, Denver, CO, 1984 Currently he is an Associate Editor of the journals Puttern Recognition. Imuge und Vision Computing, and Computer Vision, Gruphics and Image Processing Further, he is a member of the IEEE Transnational Relations Committee, member of the Editonal Board of IEEE Press, and the Charman of the IEEE Computer Society Technical Committee on PAM1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>the M S and Ph D degrees from the University of Illinois, Urbana, in 1961 and 1964, respectively He joined the Umversity of Texas in 1964 as an Assistant Professor and has since held positions as Associate Professor (1968) and Professor (1972) Currently he is the John J McKetta Energy Professor of Electncal and Computer Engineenng and Computer Sciences at the University of Texas, Austin Further he was a Visiting Assistant Professor at Brown Umversity, Providence, RI (1968), and a Visiting Associate Professor at the Umversity of Cahfornia, Berkeley, during 1969-70 He has published numerous techmcal papers and several books, Notes on Nonlineur</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors wish to thank E. Grimson and various anonymous reviewers for several insightful suggestions that enhanced the usefulness of this paper. They are grateful to J. J. Rodriguez and F. Arman for their helpful comments and for careful proofreading of this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by a grant from the Army Research Office under Contract DAAL03-87-K-0089 and in part by a grant from the National Science Foundation under Contract NSF/ECS-8513123.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient registration of stereo images by matching graph descriptions of edge segments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Favejon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Comput. Vision</title>
		<imprint>
			<biblScope unit="page" from="107" to="131" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast and reliable trinocular stereovision</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lustman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Conf. Comput. Vision</title>
		<meeting>1st Int. Conf. Comput. Vision</meeting>
		<imprint>
			<date type="published" when="1987">June 8-11, 1987</date>
			<biblScope unit="page" from="422" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Depth from edge and intensity based stereo</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">0</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Int. Joint Conf. Artifirciul Intell., Vancouver</title>
		<meeting>7th Int. Joint Conf. Artifirciul Intell., Vancouver</meeting>
		<imprint>
			<date type="published" when="1981-08">Aug. 1981</date>
			<biblScope unit="page" from="631" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Brown</surname></persName>
		</author>
		<title level="m">Computer Vision</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stochastic stereo matching over scale</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Barnard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understanding Workshop</title>
		<meeting>DARPA Image Understanding Workshop<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-06-08">Apr. 6-8, 1988</date>
			<biblScope unit="page" from="769" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computational stereo</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><surname>Suruevs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-12">Dec. 1982</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="553" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Disparity analysis of images</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<title level="m">Structural stereopsis for 3-D vision</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">I E E E</forename><surname>Trans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Anal. Muchine Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="144" to="166" />
			<date type="published" when="1988-03">Mar. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A disparity gradient limit for binocular fusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<biblScope unit="page" from="615" to="617" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modifications of the classical notion of Panum&apos;s fusional area</title>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="671" to="682" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1985-01">Jan. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Microcanonical Monte Carlo simulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Creutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1141" to="1414" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using Canny&apos;s criteria to derive a recursively implemented optimal edge detector</title>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Computer Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1987-05">May 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On parallel stereo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Drumheller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robotics arid Automation</title>
		<meeting>IEEE Int. Conf. Robotics arid Automation</meeting>
		<imprint>
			<date type="published" when="1986-07-10">Apr. 7-10, 1986</date>
			<biblScope unit="page" from="1439" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Diplopia thresholds and the initiation of vergence eye movements</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Duwaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Brink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1727" to="1737" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">What is the diplopia threshold?</title>
		<author>
			<persName><surname>__</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception Psychophys</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="295" to="309" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The role of spatial frequency tuned channels in vergence control</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Frisby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E W</forename><surname>Mayhew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="727" to="732" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Object detection and measurement using stereo vision</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Gennery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ARPA Image Understanding Workshop</title>
		<meeting>ARPA Image Understanding Workshop<address><addrLine>College Park, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1980-04">Apr. 1980</date>
			<biblScope unit="page" from="161" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computational experiments with a feature-based stereo algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Truns. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">292</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="34" />
			<date type="published" when="1985-01">Jan. 1985</date>
		</imprint>
	</monogr>
	<note>Phil. Trans. Royal Soc. London</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">From Images to Surfaces: A Computational Study of the Human Earlv Vi.~ucrl S-vstem</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>M.I.T. Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Comments on digital step edges from zero-crossings of second directional derivatives</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern A n d . Machine Intell</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="126" />
			<date type="published" when="1985-01">Jan. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bootstrap stereo</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hannah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ARPA Image Understanding Workshop</title>
		<meeting>ARPA Image Understanding Workshop<address><addrLine>College Park, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1980-04">Apr. 1980</date>
			<biblScope unit="page" from="201" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">SRI&apos;S baseline stereo system</title>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understanding Workshop</title>
		<meeting>DARPA Image Understanding Workshop<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-12">Dec. 1985</date>
			<biblScope unit="page" from="149" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">High-speed trinocular stereo for mobile-robot navigation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><surname>Lustman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NATO Adu. Res. Workshop High/v Redundant Sensor S-vstems</title>
		<meeting>NATO Adu. Res. Workshop High/v Redundant Sensor S-vstems<address><addrLine>I1 Chioeco, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">May 16-20, 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Author&apos;s reply</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="126" to="128" />
			<date type="published" when="1985-01">Jan. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Digital step edges from zero crossing of second directional derivatives</title>
	</analytic>
	<monogr>
		<title level="j">I E E E Trans. Pattern Anal. Machine Intel</title>
		<imprint>
			<biblScope unit="volume">333</biblScope>
			<biblScope unit="issue">340</biblScope>
			<biblScope unit="page" from="217" to="253" />
			<date type="published" when="1980-07">July 1980. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pami-6</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984-01">Jan. 1984</date>
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The connection machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hillis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Elect. Eng. Comput. Sci.. M.I.T</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Surfaces from stereo: Integrating feature matching, disparity estimation, and contour detection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I E E E Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="136" />
			<date type="published" when="1989-02">Feb. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Three view stereo analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Truns. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="524" to="532" />
			<date type="published" when="1986-07">July 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Foundations of Cvclopean Perception</title>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<publisher>Univ. of Chicago Press</publisher>
			<pubPlace>Chcago, IL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Interaction between pools of binocular disparity detectors tuned to different disparities</title>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Chang ; Cvhern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="125" to="143" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
	<note>Biol.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Computing visual correspondence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DA RPA Image Understanding Workshop</title>
		<meeting>DA RPA Image Understanding Workshop<address><addrLine>Arlington, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983-06">June 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Positioning 3-D objects using stereo images</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">P. J. M. van Laarhoven and E. H. L. Aarts, Simulated Annealing: Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1987">1987</date>
			<publisher>D. Riedel Publishing Co</publisher>
			<pubPlace>Dordrecht, Holland</pubPlace>
		</imprint>
	</monogr>
	<note>IEEE J . Robotics and Automation</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Stereo correspondence: A hierarchical approach</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">0</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understunding Workshop</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</editor>
		<meeting>DARPA Image Understunding Workshop<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-02">Feb. 1987</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
	<note>Vision</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Theory of edge detection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Roval Soc. London</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Analysis of a cooperative stereo algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Palm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cvhern</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="223" to="229" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A computational theory of human stereo vision</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Royal Soc. London</title>
		<imprint>
			<biblScope unit="volume">204</biblScope>
			<biblScope unit="page" from="283" to="287" />
			<date type="published" when="1976">1979. 1976</date>
		</imprint>
	</monogr>
	<note>Science</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Design of cooperative networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Marroquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Lab, Mass. Inst. Technol</title>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note>working paper 253</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Psychophysical and computational studies towards a theory of human stereopsis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E W</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Frisby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificiul Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="349" to="385" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Stereo error detection, correction, and evaluation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia ; R. Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Graphics, Image Processing</title>
		<imprint>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="120" />
			<date type="published" when="1976">1976. 1985. Feb. 1989</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Pattern Anal. Machine Intell.</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Towards automatic visual obstacle avoidance</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Moravec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Int. Joint Conf. Artificial Intell</title>
		<meeting>5th Int. Joint Conf. Artificial Intell</meeting>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page">584</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Vergence eye movements made in response to spatial frequency filtered random dot stereograms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mowforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E W</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Frisby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="299" to="304" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On detecting edges</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Nalwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">0</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I E E E Trans. Pattern Anal. Muchine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="699" to="714" />
			<date type="published" when="1986-11">Nov. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Algorithms for edge1 aggregation and edge description</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Nalwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pauchon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understanding Workshop</title>
		<meeting>DARPA Image Understanding Workshop<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-12">Dec. 1985</date>
			<biblScope unit="page" from="176" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Vertical image registration in human stereopsis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R K</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graphics, Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">743</biblScope>
			<date type="published" when="1980">1980. 1983</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note>AI Lab, Mass. Inst. Technol.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Stereo by intra-and inter-scanline search</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="1985-03">Mar. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Improving depth map by trinocular stereo</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int. Conf. Puttern Recognition</title>
		<meeting>8th Int. Conf. Puttern Recognition<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">Oct. 27-31, 1986</date>
			<biblScope unit="page" from="519" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
		<title level="m">Structural Puttern Recognition</title>
		<meeting><address><addrLine>New York; San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Freeman</publisher>
			<date type="published" when="1976-08">1977. 1976. Aug. 1987. 1982</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="361" to="373" />
		</imprint>
	</monogr>
	<note>CJ? * &apos; &apos;</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Depth from three camera stereo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Peitik ; Inen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hanvood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE C S Conf. Pattern Recognition</title>
		<meeting>IEEE C S Conf. Pattern Recognition<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">2. June 22-26, 1986</date>
			<biblScope unit="page" from="2" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Computational vision and regularization theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">317</biblScope>
			<biblScope unit="page" from="314" to="319" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">PMF: A stereo correspondence algorithm using a disparity gradient limit</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E W</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Frisby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="449" to="470" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Disparity gradient, Lipschitz continuity, and computing binocular correspondences</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E W</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Porrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Frisby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Vision Research Unit</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>U. of Sheffield</publisher>
		</imprint>
	</monogr>
	<note>Tech. Rep. 010</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Detection of binocular disparities</title>
		<author>
			<persName><forename type="first">K</forename><surname>Prazdny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybernetics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="93" to="99" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Stereo matchmg using Viterbi algorithm</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V S</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Binford</surname></persName>
		</author>
		<author>
			<persName><surname>Shekhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DA RPA Image Understanding Workshop</title>
		<meeting>DA RPA Image Understanding Workshop<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">Feb. 23-25, 1987</date>
			<biblScope unit="page" from="766" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Disjunctive eye movements</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rashbass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Westheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Ph.vsio/ogy</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="339" to="360" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Independence of conjunctive and disjunctive eye movements</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rashhass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Westheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Physiology</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="361" to="364" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Eye movements recorded during convergence and divergence</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Riggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Niehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Opt. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Edge detection by compass gradient mask</title>
		<author>
			<persName><forename type="first">G</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m">Gruphics Iniuge Processing</title>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="492" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Scene labeling by relaxation operation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="420" to="423" />
			<date type="published" when="1976-06">June 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<title level="m">Digital Picture Processing</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Structural descriptions and inexact matching</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I E E E Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="504" to="519" />
			<date type="published" when="1981-09">Sept. 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Computing visible-surface representations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Lab, Mass. Inst. Technol</title>
		<imprint>
			<biblScope unit="volume">800</biblScope>
			<date type="published" when="1985">1985</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Concurrent multilevel relaxation</title>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understunding Workshop</title>
		<meeting>DARPA Image Understunding Workshop<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-12">Dec. 1985</date>
			<biblScope unit="page" from="156" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Multilevel computational processes for visual surface reconstruction</title>
	</analytic>
	<monogr>
		<title level="m">Conlpur. Vision Graphics Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">On edge detection</title>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Puttern A i d . Muchine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="163" />
			<date type="published" when="1986-03">Mar. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The sensory stimulus for disjunctive eye movements</title>
		<author>
			<persName><forename type="first">G</forename><surname>Westheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Fender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="303" to="306" />
			<date type="published" when="1969">1969. 1969</date>
		</imprint>
	</monogr>
	<note>Vision Res.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Trinocular vision: New approach for correspondence problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yachida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kimachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Inr</title>
		<meeting>8th Inr<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">Oct. 27-31, 1986</date>
			<biblScope unit="page" from="1041" to="1044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">He received the B.Tech. degree in electrical engineering from In-YSTEMS</title>
		<author>
			<persName><forename type="first">R</forename><surname>Umesh</surname></persName>
		</author>
		<author>
			<persName><surname>Dhond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SM89) was born in Bombay, India</title>
		<imprint>
			<date type="published" when="1964-03-13">March 13. 1964. NOVEMBER/DECEMBER 1989</date>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
