<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convolutional neural network based on SMILES representation of compounds for detecting chemical motif</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-12-31">31 December 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Maya</forename><surname>Hirohara</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yutaka</forename><surname>Saito</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Artificial Intelligence Research Center</orgName>
								<orgName type="department" key="dep2">National Institute of Advanced Industrial Science and Technology (AIST)</orgName>
								<address>
									<postCode>135-0064</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Computational Bio Big-Data Open Innovation Laboratory (CBBD-OIL)</orgName>
								<orgName type="institution">National Institute of Advanced Industrial Science and Technology (AIST)</orgName>
								<address>
									<postCode>169-8555</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuki</forename><surname>Koda</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kengo</forename><surname>Sato</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yasubumi</forename><surname>Sakakibara</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Biosciences and Informatics</orgName>
								<orgName type="institution">Keio University</orgName>
								<address>
									<postCode>223-8522</postCode>
									<settlement>Yokohama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">From 29th International Conference on Genome Informatics Yunnan</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Convolutional neural network based on SMILES representation of compounds for detecting chemical motif</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-12-31">31 December 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">6E61849E90002E4A065C86F4214DF116</idno>
					<idno type="DOI">10.1186/s12859-018-2523-5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convolutional neural network</term>
					<term>Chemical compound</term>
					<term>Virtual screening</term>
					<term>SMILES</term>
					<term>TOX 21 Challenge</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background: Previous studies have suggested deep learning to be a highly effective approach for screening lead compounds for new drugs. Several deep learning models have been developed by addressing the use of various kinds of fingerprints and graph convolution architectures. However, these methods are either advantageous or disadvantageous depending on whether they (1) can distinguish structural differences including chirality of compounds, and (2) can automatically discover effective features. Results: We developed another deep learning model for compound classification. In this method, we constructed a distributed representation of compounds based on the SMILES notation, which linearly represents a compound structure, and applied the SMILES-based representation to a convolutional neural network (CNN). The use of SMILES allows us to process all types of compounds while incorporating a broad range of structure information, and representation learning by CNN automatically acquires a low-dimensional representation of input features. In a benchmark experiment using the TOX 21 dataset, our method outperformed conventional fingerprint methods, and performed comparably against the winning model of the TOX 21 Challenge. Multivariate analysis confirmed that the chemical space consisting of the features learned by SMILES-based representation learning adequately expressed a richer feature space that enabled the accurate discrimination of compounds. Using motif detection with the learned filters, not only important known structures (motifs) such as protein-binding sites but also structures of unknown functional groups were detected. Conclusions: The source code of our SMILES-based convolutional neural network software in the deep learning framework Chainer is available at http://www.dna.bio.keio.ac.jp/smiles/, and the dataset used for performance evaluation in this work is available at the same URL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>In recent years, not only in vivo and in vitro but also in silico analysis, especially machine learning, which can predict chemical properties, has become increasingly important for chemical analysis. For example, predicting compound-protein interaction facilitates the screening of new lead compounds for drug discovery.</p><p>In the case of in silico analysis, several digital file formats are defined to enable computers to read chemical compounds. Among these formats, MOL, SDF, Fingerprints, and SMILES (Simplified Molecular Input Line Entry System) are the most widely used. MOL is a file format that represents a compound in the form of a graph connection table: each node represents an atom and the edges are the bonds between atoms. SDF is an extended version of MOL for writing multiple compounds into one file.</p><p>A "fingerprint" is a vector that represents a property of a chemical compound. Many methods for creating fingerprints have been reported. The launch pad we normally use for all fingerprints is 2D fingerprint to indicate what kind of partial structure the compound possesses. In this regard, the most commonly used algorithm is the extended-connectivity fingerprint (ECFP, also known as the circular fingerprint or Morgan fingerprint) <ref type="bibr" target="#b0">[1]</ref>. This algorithm first searches the partial structures around each atom recurrently, then assigns an integer identifier to each partial structure, and writes this as a binary vector by using a hash function. Potentially, an infinite number of structures exist in the chemical space; consequently, ECFP requires vectors with a large number of bits (usually 1024-2048 bits). A more advanced version of the algorithm, 3D fingerprint, encodes 3D information, including the molecular shape and electrostatics. For example, ROCS (Rapid Overlay of Chemical Structures) uses "color" features defined by a simple force field <ref type="bibr" target="#b1">[2]</ref>. A related method is USR (Ultrafast Shape Recognition), which calculates the 3D similarity without an alignment of chemical structures <ref type="bibr" target="#b2">[3]</ref>.</p><p>SMILES, which was proposed by Weininger <ref type="bibr" target="#b3">[4]</ref>, is currently widely recognized and used as a standard representation of compounds for modern chemical information processing. SMILES provides a linear notation method to represent chemical compounds in a unique way in the form of strings over a fixed alphabet. SMILES uses specific grammar and characters to describe all the atoms and structure of a chemical compound. SMILES can strictly express structural differences including the chirality of compounds. Such a linear structure of SMILES representation, referred to as a SMILES string, enables the straightforward application of convolutional neural network (CNN) to virtual screening of chemical compounds and identification of functional substructures, which we name chemical motifs.</p><p>Chemical analysis with machine learning continues to be actively researched and is motivated by contests such as the Merck Molecular Activity Challenge 2013 and TOX 21 Challenge 2014, at which the results obtained with deep neural networks were superior to those achieved with other architectures <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. However, these methods do not make full use of the capability of deep learning. Deep learning typified by CNN would benefit from the capability of automatically acquiring the features from data as much as possible instead of manually devising the features. This capability (known as representation learning) became a springboard for the development of machine-learning-based fingerprinting techniques focusing on the graph structure of compounds as an alternative to manually-designed fingerprints <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. Duvenaud et al., <ref type="bibr" target="#b9">[10]</ref> defined a way to generalize fingerprints with a backpropagation convolutional network. Kearnes et al., <ref type="bibr" target="#b10">[11]</ref> improved fingerprints by using graph convolution. These methods are useful to aim for the goal of acquiring fingerprints by machine learning. However, they have one or more limitations: (1) some models can input only a set of compounds with fixed structure, (2) some cannot distinguish among stereoisomers, and (3) most importantly, the graph structure is in general not a data structure of grid-like topology, such as two-dimensional images (2-D grid of pixels), for which CNN could be used effectively.</p><p>The above observations led us to propose a new approach using the SMILES linear representation of chemical compounds to apply CNNs for the classifications of chemical compounds and the detection of chemical motifs. A string is the simplest grid-like (1-D grid) structure, and molecular sequences such as DNA and protein sequences are also strings. CNNs have already been applied to the classification of DNA sequences and extraction of a sequence motif conserved among the DNA sequences <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>. In these methods, by employing onehot coding representation of four DNA nucleotides, a filter (kernel) with a one-dimensional convolution operation applied to a sequence can be considered a position weight matrix for representing a motif. The filters are learned by training CNNs on positive and negative samples of sequences such as those obtained in experiments on chromatin immunoprecipitation with high-throughput sequencing (ChIP-seq) <ref type="bibr" target="#b15">[16]</ref>. Here, a "one-dimensional" convolutional operation for sequences is interpreted as scanning the input sequence only in one direction along the sequence with a filter of the same width (dimension) as that of the distributed representation of input (see Fig. <ref type="figure" target="#fig_0">1a</ref>). Now, our approach is straightforward to simply apply one-dimensional CNN to the SMILES strings representing chemical compounds for the classification of these chemical compounds and extraction of the chemical motifs (structures) conserved among the compounds (see Fig. <ref type="figure" target="#fig_0">1b</ref>).</p><p>We experimented with the TOX 21 dataset and evaluated the results by using the ROC-AUC score. The evaluation showed that our method, one-dimensional CNN using the SMILES representation, was superior to the ECFP fingerprint methods and graph convolution method <ref type="bibr" target="#b10">[11]</ref>. Furthermore, several important known structures (motifs) such as protein-binding sites were detected from the learned filters in the one-dimensional CNN.</p><p>Another advanced feature of CNN is representation learning <ref type="bibr" target="#b16">[17]</ref>. Representation learning is a procedure in which the effective features can be automatically discovered in the process of machine learning. Thus, representation learning enables us to extensively obtain new fingerprints or descriptors for compounds that fit the prediction model (e.g., prediction of binding to a certain protein). Furthermore, it is possible to extract the "chemical motif, " which is an important functional substructure (e.g., the site at which a protein could bind). We showed that the new fingerprints discovered by representation learning based on SMILES representation provided a richer chemical space that enabled the accurate discrimination of compounds, whereas existing methods using ECFP were unable to express the properties of compounds. Here, "chemical space" is a term often used in the place of "multi-dimensional descriptor space".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>In this section, we describe a new convolutional neural network (CNN) based on the SMILES notation of compounds. An overview of our CNN is shown in Fig. <ref type="figure">2</ref>. The main idea of our method is that we represent a SMILES string as a distributed representation termed a SMILES feature matrix, and apply CNN to the matrix in a way similar to the application of conventional CNNs to image data. Our CNN transforms the SMILES feature matrix into a low-dimensional feature vector termed the SMILES convolution finger print (SCFP). We construct classification models for compounds by using the SCFP as input for subsequent fully connected layers. In addition, we propose a novel method for extracting the acquired feature representation from our CNN as a form of "chemical motif. "</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SMILES notation for representing chemical compounds</head><p>SMILES uses two sets of symbols: a set of atomic symbols and a set of SMILES original symbols. In SMILES representation, atoms are represented by their atomic symbols, and double bonds are written using "=" and triple bonds using "#", both of which are original SMILES symbols. Rings are represented by breaking one of the bonds in each ring, and the presence of the ring is indicated by appending an integer to each of the two atoms of the broken bond. The presence of a branch point is indicated by a left-hand bracket "(" and the right-hand bracket ")" indicates that all the atoms in that branch have been visited. We refer to a SMILES representation of a chemical compound as a SMILES string for the chemical Fig. <ref type="figure">2</ref> Overview of our CNN. The SMILES string of a compound is represented as a feature matrix. CNN has multiple layers consisting of two convolutional and pooling layers with a subsequent global pooling layer. CNN is applied to the feature matrix and produces a low-dimensional feature representation (actually, 64-dimensional vector) termed the SCFP. Classification models are constructed by using SCFP as input for subsequent fully connected layers compound. For example, the SMILES string for Aspirin is CC(=O)OC1=CC=CC=C1C(=O)O. Although ambiguity may occur in that a compound may be represented in more than one way using SMILES (generic SMILES), we use a normalization algorithm to ensure that one single SMILES representation is derived from one compound (this approach is also known as unique SMILES, canonical SMILES, or absolute SMILES) <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SMILES feature matrix</head><p>The input used for the CNN consists of a distributed representation of a SMILES string, which comprises a sequence of feature vectors representing the symbols that occur in the SMILES string.</p><p>First, the input compound is represented by a SMILES string. Next, for each symbol in the SMILES string, a feature vector that is a distributed representation of the symbol is calculated. Each feature vector consists of 42 features, of which 21 features are used as symbols for atoms, and the remaining 21 features are used for original SMILES symbols. Each dimension in the 21-dimensional vector for an atom consists of the type of atom, and its degree, charge, and chirality, and each 21-dimensional vector for an original SMILES symbol is a one-hot vector that is a distributed representation of 21 original SMILES symbols. Note that one-hot vector is a binary vector with a single high (1) bit and all the others low (0). The 42 elements are listed in Table <ref type="table" target="#tab_0">1</ref>. Numerical values related to atomic substance quantities such as degree, charge, and chirality were calculated using the program RDKit (version: 2016.09.4) <ref type="bibr" target="#b18">[19]</ref>. The length of the feature matrix is set to the maximum length of SMILES strings for compounds in a given dataset (400 in this study). In the feature matrix for SMILES strings of which the length is shorter than the maximum length, all the blank parts were padded with 0 to retain the input size. The resulting distributed representation is a two-dimensional feature matrix with the fixed size of (400, 42).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN</head><p>Figure <ref type="figure">2</ref> shows the architecture of our CNN. We used multiple layers consisting of two convolutional and pooling layers with a subsequent global pooling layer. In the first convolutional layer, we used filters with the same width as that of the SMILES feature matrices (i.e., 42). This ensured that convolution was performed only for the direction of SMILES strings. In the global pooling layer, we used global max pooling <ref type="bibr" target="#b19">[20]</ref>. Our CNN has several hyperparameters including the window size of filters, the number of filters, and others. These hyperparameters were summarized in Table <ref type="table" target="#tab_1">2</ref>, and determined by using Bayesian optimization, GpyOpt <ref type="bibr" target="#b20">[21]</ref>.</p><p>The output of the global pooling layer is a 64dimensional vector that we named SCFP. We can construct a prediction model by using SCFP as input for fully connected layers. Specifically, we constructed a model that connected the SCFP and the output layers with one hidden layer. The model was trained using mini-batch stochastic gradient descent. Optimization was achieved by using Adam <ref type="bibr" target="#b21">[22]</ref> with a learning rate of 0.01. All weights were initialized by a normal distribution with a mean of 0 and a standard deviation of 0.01. Other details are provided in Table <ref type="table" target="#tab_1">2</ref>. We implemented our CNN using Python 3.5.2 and Chainer v1.24.0 <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SMILES convolution fingerprint (SCFP)</head><p>Our CNN can be used not only as a prediction method but also as a method to compute a fingerprint. The 64dimensional vector computed by the convolutional layers is a kind of fingerprint in the sense that it contains chemical structure information from a SMILES feature matrix (Fig. <ref type="figure">2</ref>). In this regard, we designate this vector as the SMILES convolutional fingerprint (SCFP). Once the network is trained, we can compute SCFP for any compound For example, if the network is trained for classifying the ligands of some protein, SCFP will represent the features that are important for discriminating the ligands from other compounds. This is in contrast to ECFP, which considers fixed types of features regardless of their application context. In the "Results" section, we demonstrate this nature of SCFP through its application to chemical space analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chemical motif</head><p>Another merit of our CNN is its interpretability; i.e., it enables us to visualize the acquired features in SCFP as the substructures of an input compound. Since SCFP is computed by global max pooling, one dimension of SCFP corresponds to one of the filters in the second convolutional layer. As shown in Fig. <ref type="figure" target="#fig_1">3</ref>, this allows us to associate each dimension with the substructure of an input compound by tracing back through the network. If a certain dimension takes a large value, it means a large contribution of the corresponding filter, thereby indicating the importance of the associated substructure. From this aspect, we designate such a substructure as the "chemical motif. " The analysis of chemical motifs facilitates the interpretation of prediction results by the network. For example, when we conduct ligand prediction, we can visualize and interpret chemical motifs as important substructures for ligand binding.</p><p>In practice, each dimension of SCFP may have a different value scale, making it difficult to compare across dimensions for identifying large-contribution filters. Thus, we normalize SCFP by the following procedure. First, we compute SCFP for all compounds in a given dataset. Then, we look at the values in the global max-pooling layer, and calculate their mean and variance for each filter over all compounds. Finally, we transform SCFP into Z-scores for each dimension by using the mean and the variance of the corresponding filter. For detecting chemical motifs, we focus on those dimensions of SCFP with Z-scores larger than 2.58 (i.e., 99% percentile). Note that this normalization procedure is only used for detecting chemical motifs, but not for training and prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset and performance evaluation</head><p>In this study, we used the TOX 21 dataset <ref type="bibr" target="#b23">[24]</ref> to evaluate the performance of our CNN. The TOX 21 dataset was originally created for the TOX 21 Challenge 2014, a competition of machine-learning methods for compound classification problems, and it has commonly been used as a benchmark dataset in many previous studies. The dataset contains information about whether approximately 8000 compounds would bind to 12 proteins. Tables <ref type="table">3</ref> and<ref type="table" target="#tab_2">4</ref> summarize the dataset. It consists of 12 subdatasets, each of which contains "active" and "inactive" compounds obtained from a specific experimental assay, and is divided into three types of data: "Train", "Test", and "Score". The "Train" data are intended to be used as training data for machine-learning models. The "Test" data are intended to be used for the validation of models (e.g., hyperparameter optimization). The "Score" data are intended to be used for the final evaluation of model performance. Note that this nomenclature is not consistent with the standard terminology in machine learning: "Train", "Test", and "Score" data correspond to training, validation, and test data, respectively, in standard machine-learning terminology.</p><p>We evaluated the performance of the model by using the area under the receiver operating characteristic curve (ROC-AUC), which is a commonly used measure for evaluating the performance of classifiers. The ROC-AUC takes a value from 0 to 1, where a higher value indicates a more accurate classification between active and inactive compounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross validation</head><p>We first trained and evaluated our CNN by using five-fold cross validation, giving several statistics such as computation time, memory usage, and convergence speed. We combined the three types of data ("Train", "Test", and "Score") in the TOX 21 dataset into a single dataset, and performed a five-fold cross validation for the combined dataset. We continued the training until 300 epochs while measuring the ROC-AUC for validation. On average, the training took about 36 sec per epoch with several gigabytes of memory, and the ROC-AUC was converged at around 20 epochs. The detailed statistics for each subdataset is shown in Table <ref type="table" target="#tab_3">5</ref>.</p><p>We compared the ROC-AUC obtained by our model with conventional methods for compound classification problems. Specifically, the employed methods were: the logistic regression using ECFP as input, the random forest using ECFP as input, the deep neural network using ECFP as input <ref type="bibr" target="#b24">[25]</ref>, and the graph convolution proposed in <ref type="bibr" target="#b10">[11]</ref>. The performance of our model was better than these existing methods (Fig. <ref type="figure" target="#fig_2">4</ref>).  The computation time is measured with a GPU server with NVIDIA Tesla P100 SXM2 16GB</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with the winning model of TOX 21 challenge 2014</head><p>Next, we studied the potential of our CNN as a classification method by comparing its accuracy to that of the winning model of the TOX 21 Challenge 2014 <ref type="bibr" target="#b23">[24]</ref>.</p><p>For this purpose, we constructed a model where a fullyconnected hidden layer is used between the SCFP and the output layers. We optimized the number of hidden units as well as the number and the size of filters in the first and the second convolution layers by using Bayesian optimization, GpyOpt <ref type="bibr" target="#b20">[21]</ref>.</p><p>We evaluated the performance of our model based on the same procedure as in the TOX 21 Challenge 2014. Specifically, we used the "Train" and the "Test" data to determine the hyperparameters, then evaluated the ROC-AUC using the "Score" data.</p><p>We compared our model to DeepTox <ref type="bibr" target="#b5">[6]</ref>, the winner method of TOX 21 Challenge 2014. The DeepTox authors used five variations of their model as follows: deep neural network (DNN) using only ECFP, DNN using ECFP and "DeepTox features" (proposed by the DeepTox authors), support vector machine (SVM) using ECFP and DeepTox features, random forest (RF) using ECFP and DeepTox features, and elastic net (ElNet) using ECFP and DeepTox features. In the DeepTox DNN model, the activation function of the hidden layers is ReLU, the sigmoid function is used for the final output, the mini-batch size is 512, and L2 regularization and dropout are used to prevent overfitting. DeepTox uses thousands of features consisting of 2500 in-house toxicophores features which comprise substructures previously reported as toxicophores, 200 in-house scaffold features that include the most common scaffolds that appear in organic molecules, and other 18 sets of features (the supplementary material of <ref type="bibr" target="#b5">[6]</ref>). Table <ref type="table" target="#tab_4">6</ref> shows the results of the comparison of these models. On average, the ROC-AUC of our model was better than DNN using only ECFP, but slightly lower than those of the models using ECFP and "DeepTox features" except ElNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chemical space analysis with SCFP</head><p>To demonstrate that SCFP can be used as an alternative to conventional fingerprints, we conducted a chemical space analysis using SCFP. Specifically, we computed the SCFP for all compounds in the SR-MMP subdataset, and performed dimension reduction with multi-dimensional scaling (MDS). We also conducted a similar analysis using ECFP (length=1024, radius=2). Figure <ref type="figure" target="#fig_3">5</ref> compares the produced chemical space between SCFP and ECFP. In the chemical space produced by SCFP, active and inactive compounds were discriminated clearly. In contrast, ECFP failed to discriminate between the two groups in the chemical space. These results suggest that the expressive power of SCFP is stronger than that of ECFP for the chemical space analysis of the SR-MMP subdatasets.</p><p>Our results are especially surprising given the fact that the number of dimensions of SCFP (64) is much smaller than that of ECFP (1024). Although ECFP is often represented as a high-dimensional vector, the distance between fingerprints is not always proportional to the similarity of compounds because of hash collision. On the other hand, each element of SCFP represents the contribution of the corresponding substructure acquired from training. This means that the model preferentially extracts the substructure that greatly contributes to the label classification problem.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detection of chemical motifs</head><p>Even though the prediction accuracy of our CNN was not substantially superior to that of the state-of-the-art method, our method has the advantage that it enables us to extract learned feature representation in the form of a chemical motif. Here, we present the analysis of chemical motifs using the NR-AR subdataset. We applied active compounds to our CNN, and detected chemical motifs as described in the "Methods" section. Figure <ref type="figure" target="#fig_4">6</ref> shows examples of the detected chemical motifs. These examples show that each filter corresponds to a distinct chemical motif in the compounds. Specifically, the filters 61, 0, and 2 represent, respectively, a steroid-like substructure (Fig. <ref type="figure" target="#fig_4">6a</ref>), a substructure similar to a carboxy group (Fig. <ref type="figure" target="#fig_4">6b</ref>), and a substructure similar to a tert-butyl group (Fig. <ref type="figure" target="#fig_4">6c</ref>). By using this motif analysis, we can interpret these chemical motifs as important substructures for the NR-AR dataset, i.e., the binding of compounds to the androgen receptor (Table <ref type="table">3</ref>). Indeed, the steroid skeleton has been known as an important structure for the binding of the androgen receptor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this paper, we proposed a new CNN for analyzing chemical compound data. The CNN uses a SMILES-based feature matrix in a similar way to conventional CNNs for image data. We also developed a novel method for extracting acquired feature representation from our CNN as a form of chemical motif. Furthermore, we demonstrated that the analysis of chemical motifs greatly facilitates When used as a classification model, our CNN achieved higher accuracy than existing methods in the five-fold cross validation experiment (Fig. <ref type="figure" target="#fig_2">4</ref>). In the TOX 21 Challenge 2014 experiment, our model was more accurate than DNN using only ECFP, but slightly less accurate than the models using ECFP and DeepTox features (Table <ref type="table" target="#tab_4">6</ref>). These "DeepTox features" significantly contributed to improving the accuracy of classification models. In this sense, SCFP automatically acquired by representation learning outperformed the previously well-used ECFP, but has not yet reached the performance of handcrafted DeepTox features especially tailored to TOX 21 Challenge.</p><p>SMILES feature matrices contain the structural properties of each atom (e.g., valence) in addition to the one-hot vector representing the atom symbol (Table <ref type="table" target="#tab_0">1</ref>). Although the one-hot vector has been commonly used as features to represent symbols in string data in machine learning, we did not simply follow such a strategy in this study. This is because the property of an atom changes substantially depending on its structural environment in a compound. For example, the property of a carbon atom is different depending on whether it is in a benzene ring, or is bonded to an oxygen atom. On the other hand, different kinds of atoms may have a similar property if they belong to the same family (i.e., group of elements in the periodic table), and their structural environments are similar. SMILES feature matrices were designed to capture this behavior by using the structural properties of atoms.</p><p>The merit of SMILES convolution is that it is unnecessary to specify substructures in advance as input features.</p><p>Even when there is no prior knowledge about important substructures, our CNN can automatically acquire chemical motifs by representation learning. Moreover, since our CNN obtains important substructures preferentially, the size of the SCFP can be kept small (i.e., 64 in this study). This is in contrast to ECFP, which requires large-sized vectors for considering all possible substructures, but has limited expressive power due to hash collision.</p><p>In the analysis of chemical motifs, our CNN successfully detected a steroid-like chemical motif that has been known as an important structure for the binding of androgen receptors (Fig. <ref type="figure" target="#fig_4">6a</ref>). The other detected motifs can be considered as candidates for novel skeleton structures for androgen receptors. Therefore, our proposed method has potential not only as a classification method, but also as a means of providing clues for drug discovery.</p><p>Since the detection of chemical motifs is based on filters, the size of the detectable chemical motifs is limited by the window size of filters. Specifically, the maximum motif size is 2k 1 + k 2 , where k 1 and k 2 are the window sizes in the first and second convolutional layers, respectively (i.e., 21 in this study; Fig. <ref type="figure" target="#fig_1">3</ref>). However, as observed in Fig. <ref type="figure" target="#fig_5">7</ref>, multiple filters may represent slightly distinct overlapping substructures and their combination may represent an entire motif. Thus, we expect the detection of large chemical motifs to be possible by the combined analysis of these filters.</p><p>The TOX 21 dataset is highly imbalanced between the number of active compounds and the number of inactive compounds. We attempted the following methods to resolve this imbalance. • The learning rate was multiplied by a constant only for the positive data so that the positive data could be learned strongly. • Only for active compounds, a compound was described also in non-canonical SMILES so that the number of positive examples was increased.</p><p>However, both methods did not contribute to improve the accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this study, we designed a feature matrix based on SMILES linear notation of compounds and applied it to our CNN where the convolution operation was performed only in one direction along the SMILES string. The performance of our CNN based on SMILES string was superior to that of the conventional fingerprint method used for the virtual screening of chemical compounds. In addition, the use of motif detection with learned filters not only enabled important known substructures such as protein-binding sites but also substructures of unknown functional groups to be detected. Using the TOX 21 Challenge as benchmark, we achieved performance comparable to that of the current winning model. Furthermore, multivariate analysis confirmed that the chemical space consisting of the features learned by SMILES-based representation learning were able to adequately express a rich feature space that enabled the accurate discrimination of compounds.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Chemical motif detection by CNN in comparison with sequence motif detection. a One-hot coding representation of four DNA nucleotides, a filter (kernel) with a one-dimensional convolution operation that is considered a position weight matrix for representing a motif. b The same strategy for applying one-dimensional CNN to SMILES linear representations of chemical compounds and the extraction of learned filters to discover the chemical motifs</figDesc><graphic coords="3,136.39,194.43,314.44,244.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Detection of chemical motifs. Each dimension of SCFP is associated with the substructure of an input compound by tracing back through the CNN</figDesc><graphic coords="6,155.32,539.79,283.48,165.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 ROC-AUC of our model compared with those reported by previous studies. (Left) ROC-AUC averaged for 12 subdatasets were compared between our model (blue) and previous studies (gray). (Right) ROC-AUC of our model for each subdataset</figDesc><graphic coords="8,126.82,94.38,340.36,249.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Chemical space analysis of the SR-MMP subdataset. SCFP (a) and ECFP (b) computed for all compounds in the dataset were plotted by MDS</figDesc><graphic coords="9,156.46,94.47,283.48,419.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Examples of learned filters and chemical motifs for the NR-AR subdataset. a Filter 61 and corresponding chemical motifs on different compounds. b Filter 0 and corresponding chemical motifs on different compounds. c Filter 2 and corresponding chemical motifs on different compounds</figDesc><graphic coords="10,126.82,94.14,340.36,186.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7 Filters representing similar chemical motifs. Each filter represents a similar but slightly different chemical motif</figDesc><graphic coords="11,127.96,94.05,340.36,148.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,63.82,94.14,467.08,213.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 Features</head><label>1</label><figDesc></figDesc><table><row><cell>Feature</cell><cell>Description</cell><cell>Size</cell></row><row><cell>Atom</cell><cell></cell><cell>21</cell></row><row><cell>Atom type</cell><cell>H, C, O, N, or others</cell><cell>5</cell></row><row><cell>NumHs</cell><cell>Total number of H atoms attached to it</cell><cell>1</cell></row><row><cell>Degree</cell><cell>Its degree of unsaturation</cell><cell>1</cell></row><row><cell>Charge</cell><cell>Its formal charge</cell><cell>1</cell></row><row><cell>Valence</cell><cell>Its total valence</cell><cell>1</cell></row><row><cell>Ring</cell><cell>Whether it is included in a ring</cell><cell>1</cell></row><row><cell>Aromaticity</cell><cell cols="2">Whether it is included in an aromatic structure1</cell></row><row><cell>Chirality</cell><cell>R, S, or others</cell><cell>3</cell></row><row><cell>Hybridization</cell><cell>s, sp, sp 2 , sp 3 , sp 3 d, sp 3 d 2 , or others</cell><cell>7</cell></row><row><cell>SMILES original symbol</cell><cell></cell><cell>21</cell></row><row><cell>(</cell><cell>Branch start</cell><cell>1</cell></row><row><cell>)</cell><cell>Branch end</cell><cell>1</cell></row><row><cell></cell><cell>Atom or atom group start</cell><cell>1</cell></row><row><cell></cell><cell>Atom or atom group end</cell><cell>1</cell></row><row><cell>.</cell><cell>I o n i c b o n d</cell><cell>1</cell></row><row><cell>:</cell><cell>A r o m a t i c b o n d</cell><cell>1</cell></row><row><cell>=</cell><cell>Double bond</cell><cell>1</cell></row><row><cell>#</cell><cell>T r i p l e b o n d</cell><cell>1</cell></row><row><cell>\</cell><cell>c i s</cell><cell>1</cell></row><row><cell>/</cell><cell>t r a n s</cell><cell>1</cell></row><row><cell>@</cell><cell>Chirality (above or below)</cell><cell>1</cell></row><row><cell>+</cell><cell>Cation (positive ion)</cell><cell>1</cell></row><row><cell>-</cell><cell>Anion (negative ion)</cell><cell>1</cell></row><row><cell>Ion charge</cell><cell>Numbers show ionic charge (2-7)</cell><cell>6</cell></row><row><cell>Start</cell><cell>Numbers show ring start</cell><cell>1</cell></row><row><cell>End</cell><cell>Numbers show ring end</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Model hyperparameters</figDesc><table><row><cell>Hyperparameter</cell><cell>Considered values</cell></row><row><cell>1st convolution</cell><cell></cell></row><row><cell>No. of filters</cell><cell>[1, 1024]</cell></row><row><cell>Window size</cell><cell>[1, 51]</cell></row><row><cell>Stride size</cell><cell>{1,3,5}</cell></row><row><cell>Padding</cell><cell>{None, Half of window size}</cell></row><row><cell>1st pooling</cell><cell></cell></row><row><cell>Type</cell><cell>{Max, Average}</cell></row><row><cell>Window size</cell><cell>[1, 51]</cell></row><row><cell>Stride size</cell><cell>{1,3,5}</cell></row><row><cell>Padding</cell><cell>{None, Half of window size}</cell></row><row><cell>2nd convolution</cell><cell></cell></row><row><cell>No. of filters</cell><cell>[1, 1024]</cell></row><row><cell>Window size</cell><cell>[1, 51]</cell></row><row><cell>Stride size</cell><cell>{1,3,5}</cell></row><row><cell>Padding</cell><cell>{None, Half of window size}</cell></row><row><cell>2nd pooling</cell><cell></cell></row><row><cell>Type</cell><cell>{Max, Average}</cell></row><row><cell>Window size</cell><cell>[1, 51]</cell></row><row><cell>Stride size</cell><cell>{1,3,5}</cell></row><row><cell>Padding</cell><cell>{None, Half of window size}</cell></row><row><cell>Global pooling</cell><cell>{None, Max pooling}</cell></row><row><cell>Output layer</cell><cell>{softmax, sigmoid}</cell></row><row><cell>Activation function</cell><cell>{ReLU, Leaky ReLU, Parametric ReLU}</cell></row><row><cell>Minibatch size</cell><cell>{32, 64, 128, 256, 512}</cell></row><row><cell>Batch normalization</cell><cell>{None, after conv.}</cell></row><row><cell>Dropout</cell><cell>{None, before output}</cell></row><row><cell>Optimizer</cell><cell>{Adam, AdaGrad}</cell></row><row><cell>Learning rate</cell><cell>{0.0001, 0.001, 0.01, 0.1}</cell></row><row><cell>Loss function</cell><cell>{Mean squared error, Cross entropy}</cell></row><row><cell cols="2">not limited to those included in the training data. We</cell></row><row><cell cols="2">propose to use SCFP as an alternative to conventional fin-</cell></row><row><cell cols="2">gerprints such as ECFP. The advantage of SCFP over ECFP</cell></row><row><cell cols="2">is that it can represent important features acquired from</cell></row><row><cell>training.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>TOX 21 dataset    </figDesc><table><row><cell>Subdataset</cell><cell>Train</cell><cell></cell><cell>Test</cell><cell></cell><cell>Score</cell><cell></cell></row><row><cell></cell><cell cols="6">Active Inactive Active Inactive Active Inactive</cell></row><row><cell>NR-AR</cell><cell>380</cell><cell>8982</cell><cell>3</cell><cell>289</cell><cell>12</cell><cell>574</cell></row><row><cell>NR-AR-LBD</cell><cell>303</cell><cell>8296</cell><cell>4</cell><cell>249</cell><cell>8</cell><cell>574</cell></row><row><cell>NR-ER</cell><cell>937</cell><cell>6760</cell><cell>27</cell><cell>238</cell><cell>51</cell><cell>465</cell></row><row><cell>NR-ER-LBD</cell><cell>446</cell><cell>8307</cell><cell>10</cell><cell>277</cell><cell>20</cell><cell>580</cell></row><row><cell>NR-AhR</cell><cell>950</cell><cell>7219</cell><cell>31</cell><cell>241</cell><cell>73</cell><cell>537</cell></row><row><cell cols="2">NR-Aromatase 360</cell><cell>6866</cell><cell>18</cell><cell>196</cell><cell>39</cell><cell>489</cell></row><row><cell>NR-PPAR-γ</cell><cell>222</cell><cell>7962</cell><cell>15</cell><cell>252</cell><cell>31</cell><cell>574</cell></row><row><cell>SR-ARE</cell><cell>1098</cell><cell>6069</cell><cell>48</cell><cell>186</cell><cell>93</cell><cell>462</cell></row><row><cell>SR-ATAD5</cell><cell>338</cell><cell>8753</cell><cell>25</cell><cell>247</cell><cell>38</cell><cell>584</cell></row><row><cell>SR-HSE</cell><cell>248</cell><cell>7722</cell><cell>10</cell><cell>257</cell><cell>22</cell><cell>588</cell></row><row><cell>SR-MMP</cell><cell>1142</cell><cell>6178</cell><cell>38</cell><cell>200</cell><cell>60</cell><cell>483</cell></row><row><cell>SR-p53</cell><cell>537</cell><cell>8097</cell><cell>28</cell><cell>241</cell><cell>41</cell><cell>575</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>Summary of training statistics</figDesc><table><row><cell>Subdataset</cell><cell cols="3">Time (s/epoch) Memory (MiB) Convergence (epoch)</cell></row><row><cell>NR-AR</cell><cell>121.7</cell><cell>6551</cell><cell>15</cell></row><row><cell>NR-AR-LBD</cell><cell>12.9</cell><cell>6459</cell><cell>19</cell></row><row><cell>NR-ER</cell><cell>36.0</cell><cell>2763</cell><cell>17</cell></row><row><cell>NR-ER-LBD</cell><cell>37.7</cell><cell>2309</cell><cell>25</cell></row><row><cell>NR-AhR</cell><cell>13.3</cell><cell>1475</cell><cell>33</cell></row><row><cell cols="2">NR-Aromatase 15.2</cell><cell>6317</cell><cell>20</cell></row><row><cell>NR-PPAR-γ</cell><cell>2.7</cell><cell>4413</cell><cell>23</cell></row><row><cell>SR-ARE</cell><cell>16.7</cell><cell>1615</cell><cell>18</cell></row><row><cell>SR-ATAD5</cell><cell>74.7</cell><cell>4581</cell><cell>21</cell></row><row><cell>SR-HSE</cell><cell>49.0</cell><cell>3047</cell><cell>15</cell></row><row><cell>SR-MMP</cell><cell>40.3</cell><cell>3427</cell><cell>9</cell></row><row><cell>SR-p53</cell><cell>8.3</cell><cell>1211</cell><cell>11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>Comparison of our CNN and DeepTox (the winning model of the TOX 21 Challenge 2014)</figDesc><table><row><cell>Input</cell><cell cols="2">Model Ave.</cell><cell>AR</cell><cell cols="2">AR-LBD ER</cell><cell cols="2">ER-LBD AhR</cell><cell>Aromatase PPAR-γ ARE</cell><cell>ATAD5 HSE</cell><cell>MMP p53</cell></row><row><cell>SMILES Matrix</cell><cell>CNN</cell><cell cols="3">0.813 0.789 0.793</cell><cell cols="2">0.776 0.765</cell><cell cols="2">0.905 0.786</cell><cell>0.791</cell><cell>0.754 0.803</cell><cell>0.835 0.928 0.832</cell></row><row><cell>ECFP</cell><cell>DNN</cell><cell cols="3">0.768 0.850 0.690</cell><cell cols="2">0.840 0.760</cell><cell cols="2">0.660 0.720</cell><cell>0.700</cell><cell>0.730 0.860</cell><cell>0.810 0.820 0.780</cell></row><row><cell cols="2">ECFP+DeepTox DNN</cell><cell cols="3">0.837 0.778 0.825</cell><cell cols="2">0.791 0.811</cell><cell cols="2">0.923 0.804</cell><cell>0.856</cell><cell>0.829 0.775</cell><cell>0.863 0.930 0.860</cell></row><row><cell cols="2">ECFP+DeepTox SVM</cell><cell cols="3">0.832 0.882 0.748</cell><cell cols="2">0.799 0.798</cell><cell cols="2">0.919 0.819</cell><cell>0.856</cell><cell>0.818 0.781</cell><cell>0.848 0.946 0.854</cell></row><row><cell cols="2">ECFP+DeepTox RF</cell><cell cols="3">0.820 0.776 0.812</cell><cell cols="2">0.770 0.746</cell><cell cols="2">0.917 0.806</cell><cell>0.827</cell><cell>0.810 0.786</cell><cell>0.826 0.945 0.835</cell></row><row><cell cols="2">ECFP+DeepTox ElNet</cell><cell cols="3">0.803 0.788 0.692</cell><cell cols="2">0.765 0.805</cell><cell cols="2">0.897 0.763</cell><cell>0.805</cell><cell>0.778 0.768</cell><cell>0.844 0.924 0.818</cell></row></table><note><p>Our CNN takes SMILES feature matrices as input, while DeepTox uses ECFP and its original features</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Not applicable.</p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials</head><p>The software and the data are available at http://www.dna.bio.keio.ac.jp/ smiles/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>About this supplement</head><p>This article has been published as part of BMC Bioinformatics Volume 19 Supplement 19, 2018: Proceedings of the 29th International Conference on Genome Informatics (GIW 2018): bioinformatics. The full contents of the supplement are available online at https://bmcbioinformatics.biomedcentral. com/articles/supplements/volume-19-supplement-19.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was supported by a Grant-in-Aid for Scientific Research on Innovative Areas "Frontier Research on Chemical Communications". This work was also funded by a MEXT-supported Program for the Strategic Research Foundation at Private Universities. Publication costs are funded by Grant-in-Aid for Scientic Research on Innovative Areas "Frontier Research on Chemical Communications".</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics approval and consent to participate</head><p>Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent for publication</head><p>Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare that they have no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Publisher's Note</head><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extended-connectivity fingerprints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Chem Inf Model</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="742" to="754" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Comparison of shape-matching and docking as virtual screening tools</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Skillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nicholls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Med Chem</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="82" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ultrafast shape recognition to search compound databases for similar molecular shapes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Chem</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1711" to="1723" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules</title>
		<author>
			<persName><forename type="first">D</forename><surname>Weininger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Chem Inf Comput Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="36" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep neural nets as a method for quantitative structure-activity relationships</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Svetnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Chem Inf Model</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="274" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">DeepTox: toxicity prediction using deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front Environ Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural network for graphs: A contextual constructive approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="498" to="511" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lusci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Chem Inf Model</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1563" to="1575" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gómez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Aided Mol Des</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Delong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Weirauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Biotechnol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="831" to="838" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Predicting effects of noncoding variants with deep learning-based sequence model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">G</forename><surname>Troyanskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="931" to="934" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Rinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="990" to="999" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DEEP MOTIF DASHBOARD: VISUALIZING AND UNDERSTANDING GENOMIC SEQUENCES USING DEEP NEURAL NETWORKS</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac Symp Biocomput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="254" to="265" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for predicting DNA-protein binding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Gifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="121" to="127" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Representation learning: a review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<ptr target="http://opensmiles.org" />
		<title level="m">OpenSMILES Home Page</title>
		<imprint>
			<date type="published" when="2018-03-29">29 Mar 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<ptr target="http://www.rdkit.org/" />
		<title level="m">RDKit: Open-Source Cheminformatics Software</title>
		<imprint>
			<date type="published" when="2018-03-29">29 Mar 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Network in network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4400</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><surname>Gpyopt</surname></persName>
		</author>
		<ptr target="http://github.com/SheffieldML/GPyOpt" />
		<title level="m">Bayesian Optimization Framework in Python</title>
		<imprint>
			<date type="published" when="2018-03">Mar 2018</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Machine Learning Systems in the 29th Annual Conference on Neural Information Processing Systems</title>
		<meeting>Workshop on Machine Learning Systems in the 29th Annual Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tox21challenge to build predictive models of nuclear receptor and stress response pathways as mediated by exposure to environmental chemicals and drugs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D-T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sakamuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Shahane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rossoshek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Simeonov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front Environ Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">In silico prediction of chemicals binding to aromatase with machine learning methods</title>
		<author>
			<persName><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chem Res Toxicol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1209" to="1218" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
