<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners</title>
				<funder ref="#_ZwAF9DB">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_raED3t7">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-07-04">4 Jul 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Allen</forename><forename type="middle">Z</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anushri</forename><surname>Dixit</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandra</forename><surname>Bodrova</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sumeet</forename><surname>Singh</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Tu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Noah</forename><surname>Brown</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leila</forename><surname>Takayama</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jake</forename><surname>Varley</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenjia</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dorsa</forename><surname>Sadigh</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andy</forename><surname>Zeng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anirudha</forename><surname>Majumdar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Google DeepMind</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-07-04">4 Jul 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2307.01928v1[cs.RO]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Language-based planning</term>
					<term>uncertainty estimation</term>
					<term>conformal prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) exhibit a wide range of promising capabilities -from step-by-step planning to commonsense reasoning -that may provide utility for robots, but remain prone to confidently hallucinated predictions. In this work, we present KNOWNO, which is a framework for measuring and aligning the uncertainty of LLM-based planners such that they know when they don't know and ask for help when needed. KNOWNO builds on the theory of conformal prediction to provide statistical guarantees on task completion while minimizing human help in complex multi-step planning settings. Experiments across a variety of simulated and real robot setups that involve tasks with different modes of ambiguity (e.g., from spatial to numeric uncertainties, from human preferences to Winograd schemas) show that KNOWNO performs favorably over modern baselines (which may involve ensembles or extensive prompt tuning) in terms of improving efficiency and autonomy, while providing formal assurances. KNOWNO can be used with LLMs out of the box without modelfinetuning, and suggests a promising lightweight approach to modeling uncertainty that can complement and scale with the growing capabilities of foundation models. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>How can we endow our robots with the ability to know when they don't know? Accurately modeling and accounting for uncertainty is a longstanding challenge towards robots that operate reliably in unstructured and novel environments. In this work, we study this challenge in the context of language-instructed robots. Language provides a natural and flexible interface for humans to specify tasks, contextual information, and intentions, while also allowing us to provide help and clarification to robots when they are uncertain.</p><p>Recently, approaches that leverage large language models (LLMs) for planning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> have demonstrated the ability to respond to natural and unstructured language instructions to generate temporally extended plans. These approaches enable leveraging the vast amount of prior knowledge and rich context embedded in pretrained LLMs, and lead to substantial abstract reasoning capabilities. However, one of the major challenges with current LLMs is their tendency to hallucinate, i.e., to confidently generate outputs that are plausible but incorrect and untethered from reality. Such false confidence in incorrect outputs poses a significant challenge to LLM-based planning in robotics. Moreover, natural language instructions in realworld environments often contain a high degree of ambiguity inherently or unintentionally from humans, and confidently following an incorrectly constructed plan could lead to undesirable or even unsafe actions.</p><p>As an example (Fig. <ref type="figure">1</ref>), a robot tasked with heating food may be asked to "place the bowl in the microwave"; if there are multiple bowls on the counter, the instruction is ambiguous. Moreover, the metal bowl may not be safe for the microwave. Rather than acting in this ambiguous setting and damaging the microwave or even causing a fire, the robot should know when it doesn't know and ask for clarification instead (e.g., ask which bowl should be placed in the microwave). Prior work in language-based planning either does not seek such clarifications <ref type="bibr" target="#b0">[1]</ref> or does so via extensive prompting <ref type="bibr" target="#b1">[2]</ref>, which requires careful prompt engineering to prevent the robot from excessively relying on seeking assistance. Moreover, prior Figure <ref type="figure">1</ref>: KNOWNO uses Conformal Prediction (CP) to align the uncertainty of LLM planners. Given a language instruction, an LLM generates possible next steps and its confidences (scores) in these options. CP then provides a prediction set that includes the options with scores above a certain quantile. If there is more than one option in the set, the robot asks for help. Experiments across multiple embodiments and a variety of ambiguous situations show that KNOWNO significantly improves efficiency and autonomy compared to baselines.</p><p>approaches do not provide a way to ensure that asking for help results in a desired level of task success. We formalize these challenges via two desiderata: (i) calibrated confidence: the robot should seek sufficient help to ensure a statistically guaranteed level of task success specified by the user, and (ii) minimal help: the robot should minimize the overall amount of help it seeks by narrowing down possible ambiguities in a task. We collectively refer to these sufficiency and minimality conditions as uncertainty alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of contributions.</head><p>We propose KNOWNO-Know When You Don't Know -a framework for aligning the uncertainty of LLM-based planners utilizing the theory of conformal prediction (CP) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. We make the following contributions: (1) Given a language instruction, we utilize a pre-trained LLM with uncalibrated confidence to generate a set of possible actions for the robot to execute next. We demonstrate how to use CP to select a subset of these options, which allows the robot to decide an action to execute (if the subset is a singleton) or to ask for help otherwise. <ref type="bibr" target="#b1">(2)</ref> We prove theoretical guarantees on calibrated confidence in both single-step and multi-step planning problems: with a user-specified level 1-?, the robot performs the tasks correctly in 1-? % of scenarios by asking for help when it deems it necessary. CP also minimizes the average size of prediction sets, thus addressing the goal of minimal help. (3) We evaluate KNOWNO in both simulation and hardware with a suite of language-instructed manipulation tasks with various types of potential ambiguities (e.g., based on spatial locations, numerical values, attributes of objects, and Winograd schemas). Experiments across multiple settings and embodiments validate the ability of KNOWNO to provide statistically guaranteed levels of task success while reducing the amount of help required by 10-24% as compared to baseline approaches.</p><p>2 Overview: Robots that Ask for Help Language-based planners. Language model planners can generate step-by-step robot plans, where each step y is composed of variable-length sequences of symbols (? 1 ,? 2 ,...,? k ), e.g., text tokens as input to a language-conditioned policy <ref type="bibr" target="#b0">[1]</ref> (see Fig. <ref type="figure">1</ref>), or robot code executed by an interpreter <ref type="bibr" target="#b4">[5]</ref>. Pretrained autoregressive LLMs predict each step y, whose joint probability over tokens can be factorized as the product of conditional probabilities of next token prediction p(y) = k i=1 p(? i | ? 1 ,...,? i-1 ). Here, we are interested in characterizing the uncertainty of next step prediction p(y). The distribution of p remains highly sensitive to variable-length k; hence p(y) on its own serves as a rather poor scoring function <ref type="bibr" target="#b5">[6]</ref> particularly when steps in a plan are expressed in natural language (our experiments in Section A9 also show that using p(y) directly for calibration leads to poor performance). Figure <ref type="figure">2</ref>: KNOWNO formulates LLM planning as MCQA by first prompting an LLM to generate plausible options, and then asking it to predict the correct one. Based on the next-token likelihoods from a calibration dataset, CP finds the quantile value q such that all options with a score ?1-q are included in the prediction set in a test scenario. The resulting sets are guaranteed to cover the true option with the user-specified probability.</p><p>Planning as multiple-choice Q&amp;A. We can address this length bias with a simple trick. First, with a few-shot prompt that includes possible next steps in a few scenarios (Fig. <ref type="figure" target="#fig_5">A1</ref>), the LLM generates a set {y i } of candidate next steps (e.g., "Put plastic bowl in microwave", "Put metal bowl in microwave", etc., in Fig. <ref type="figure">1</ref>) that are semantically different. Then the task of choosing among them is formatted as multiple-choice Q&amp;A (MCQA). This eliminates plans that the LLM considers unlikely and reduces the problem of next-step prediction down to a single next-token prediction -aligning with LLM log-likelihood loss functions and LLM training data (e.g., MCQA datasets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>). These probabilities can serve as normalized scores that can be used by various uncertainty quantification methods such as thresholding and ensemble methods. In this work, we use these normalized scores within a conformal prediction (CP) framework. Specifically, CP uses a held-out calibration set of example plans in different scenarios to generate a reduced prediction set of plans among {y i } (Fig. <ref type="figure">2</ref>). The LLM is certain if this prediction set is a singleton, and triggers help from a human otherwise. Section A1 details additional rationale of applying MCQA to evaluate the semantic uncertainty of the LLM.</p><p>Robots that ask for help. In this work, we show that LLM planning -combined with CP for uncertainty estimation -can effectively enable robots to interact with an environment, and ask for help when needed. The environment e can be formulated as a partially observable Markov decision process (POMDP): at any given state s t at time t, given a user instruction ?, the robot executes an action a t according to a policy ?, then transitions to a new state s t+1 . Our policy ? is composed of four parts (Fig. <ref type="figure">1</ref>):</p><p>1. Multiple-choice generation: An LLM generates a diverse set of candidate plans labeled with 'A', 'B', 'C', 'D' , and an additional possible plan, 'E) an option not listed here', which is appended post-hoc. We denote the set of labels by Y :={'A','B','C','D','E'}. These plans are generated by prompting the LLM with context x t , which is text that includes (1) the robot observation at each time step (e.g., using a vision-based object detector or an oracle; see Fig. <ref type="figure">1</ref>), (2) the user instruction, and (3) few-shot examples of possible plans in other scenarios. An augmented context xt is obtained by appending the LLM-generated plans to the context x t . 2. Prediction set generation: We use CP to choose a subset C(x t )?Y of candidate plans using the LLM's (uncalibrated) confidence f(x t ) y in each prediction y ?Y given the context xt . 3. Human help: If the prediction set is a non-singleton, the robot leverages help from a human (or any other supervisor agent, denoted as a function f H ) to arrive at an unambiguous next step y H ?C(x t ). 4. Low-level control: A low-level module ? converts the plan in y H to an action a t =?(y H ).</p><p>Goal: uncertainty alignment. Often in real-world settings, language instructions ? can be ambiguous, e.g., "place the bowl in the microwave" does not specify that the human means the plastic bowl (Fig. <ref type="figure">1</ref>). Our goal in this work is to address uncertainty alignment: achieve a desired level of task success while minimizing human help. We formalize this by considering a joint distribution D over scenarios ? :=(e,?,g), where e is an environment (POMDP), ? is a (potentially ambiguous) language instruction, and g is a goal (e.g., formulated as a subset of acceptable states in the POMDP and partially observable through l). Importantly, we do not assume knowledge of D, except that we can sample a finite-size dataset of i.i.d. scenarios from it. We formalize uncertainty alignment in our setting as (i) calibrated confidence: the robot's policy (with human help as described above) succeeds with a user-specified probability 1-? over new scenarios ? ?D, and (ii) minimal help: the policy minimizes the number |C(?)| of options presented to the human on average across scenarios ? ?D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Calibrating LLM Confidence with Conformal Prediction</head><p>The MCQA setup above allows us to apply CP to obtain calibrated confidence guarantees while (approximately) minimizing help. We introduce CP below, and then present the different practical settings we consider (possibly involving multiple planning steps and/or multiple correct plans per step).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background: Conformal Prediction</head><p>For now, we drop the timestep superscript and consider a generic MCQA setup with pairs (x,y) consisting of input x and true label y. Suppose there is a calibration set Z ={z i =(x i ,y i )} N i=1 of such pairs drawn i.i.d. from an unknown distribution D over Z :=X ?Y. Now, given a new i.i.d. sample z test =(x test ,y test ) with unknown true label y test , CP generates a prediction set C(x test )?Y that contains y test with high probability <ref type="bibr" target="#b2">[3]</ref>:</p><formula xml:id="formula_0">P y test ?C(x test ) ?1-?,<label>(1)</label></formula><p>where 1-? is a user-specified value (desired task success level in our setting) that affects the size of C(?).</p><p>To generate C(x test ), CP first uses the LLM's confidence f (cf. Section 2) to evaluate the set of nonconformity scores {s i = 1 -f(x i ) yi } N i=1 over the calibration set -the higher the score is, the less each data in the calibration set conforms to the data used for training f. Then CP performs calibration by defining q to be the ?(N+1)(1-?)? N empirical quantile of s 1 ,...,s N . Lastly, CP generates C(x test )={y ?Y | f(x test ) y ?1-q)}, i.e., the prediction set that includes all labels that the predictor is at least 1-q confident in. The generated prediction set ensures that the coverage guarantee in Eq. ( <ref type="formula" target="#formula_0">1</ref>) holds.</p><p>Dataset-conditional guarantee. The probability in Eq. ( <ref type="formula" target="#formula_0">1</ref>) is over both the sampling of the calibration set Z and z test (i.e., a marginal guarantee). Thus, to ensure the desired probability of coverage for each new z test , one needs a fresh calibration set. But, in practice, we only calibrate once with a fixed set. The following dataset-conditional guarantee <ref type="bibr" target="#b8">[9]</ref> holds with probability 1-? over the sampling of the calibration set Z:</p><formula xml:id="formula_1">P y test ?C(x test ) | {z 1 ,...,z N } ?Beta -1 N+1-v,v (?), v :=?(N +1)??,<label>(2)</label></formula><p>where Beta -1 N+1-v,v (?) denotes the inverse CDF (quantile) level of ? in a Beta distribution with parameters N +1-v and v, and ? is the threshold used for calibration. In practice, we use a modest-sized calibration dataset (N = 400) and ? = 0.01, and adjust ? to achieve the desired 1 -? coverage (with probability 1-? =0.99 over the sampling of the calibration set).</p><p>Minimal prediction set size. From [10, Thm. 1], C(?) achieves the smallest average set size among possible prediction schemes C that achieve the coverage guarantee, if f(x) y models true conditional probabilities:</p><formula xml:id="formula_2">min C?C E (x,?)?D |C(x)| , subject to (1).<label>(3)</label></formula><p>The assumption that f models true conditional probabilities may be a good approximation for LLMs trained on large-scale data with a proper scoring rule <ref type="bibr" target="#b10">[11]</ref>; one can also obtain bounds on near-optimal average set size for CP using f that approximately models conditional probabilities <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b9">10]</ref>, but we omit these results for brevity. We emphasize that the CP coverage guarantees hold regardless of the accuracy of f. Overall, CP is a powerful and easy-to-use statistical tool to produce (1) tight coverage guarantees-addressing the goal of calibrated confidence, and (2) small prediction sets for unseen data given a blackbox predictor like an LLM and an unknown data distribution-addressing our second goal of minimal help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Single-Step Uncertainty Alignment</head><p>We now demonstrate how to use CP to achieve uncertainty alignment for LLM-based planning with a user-specified task completion rate 1-?. We first consider a single-step setting, where the LLM plans only once given a context. For simplicity, we again drop the timestep superscript t in this section.</p><p>Data collection. We collect N i.i.d. scenarios from the distribution D, and the corresponding contexts summarizing the robot observation and instruction (Section 2). We use the MCQA approach from Section 2 to generate candidate plans and then label each augmented context x (i.e., context combined with plans) with the correct label (here and in Section 3.3, we assume that there is a unique correct candidate plan;</p><p>we provide an extension to multiple acceptable options in Section A3). We thus obtain a calibration set Z ={z i =(x i ,y i )} N i=1 with pairs of augmented contexts and correct labels. Calibration. Next we follow Section 3.1 to perform calibration: first adjust ? to achieve the 1 -? coverage based on Eq. ( <ref type="formula" target="#formula_1">2</ref>) and then find the quantile q. Given a new context xtest (after MCQA in a new scenario) at test time, we can construct the calibration set C(x test ) that contains y test with 1-? probability.</p><p>Triggering help. If C(x test ) is a singleton, the robot executes the corresponding plan. Otherwise, we deem the LLM uncertain over possible actions and trigger human help. The robot presents the human with C(x test ) (including the corresponding plans in text) and asks the human to choose one<ref type="foot" target="#foot_1">2</ref> . The human chooses y test if y test ?C(x test )<ref type="foot" target="#foot_2">3</ref> , or halts the operation otherwise. This setup turns the coverage guarantee from CP to the task completion guarantee:</p><p>Proposition 1 (Single-step uncertainty alignment) Consider a single-step setting where we use CP with coverage level 1-? to generate prediction sets and seek help whenever the set is not a singleton. With probability 1-? over the sampling of the calibration set, the task completion rate over new test scenarios drawn from D is at least 1-?. If f models true conditional probabilities, the average prediction set size is minimized among possible prediction schemes that achieve 1-? completion rate.</p><p>The proof immediately follows from the fact that under the assumption of accurate human help, the robot fails only when the prediction set does not contain the true label; the prediction set minimality follows from Eq. ( <ref type="formula" target="#formula_2">3</ref>). Thus, our approach addresses the goals of calibrated confidence and minimal help from Section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multi-Step Uncertainty Alignment</head><p>Now we extend the CP-based uncertainty alignment approach to settings where the LLM plans in multiple timesteps. This setting can be helpful when the LLM receives feedback from the environment or human between steps. However, the original CP formulation cannot be applied here since the context x t between steps are dependent; moreover, the robot's actions at step t influence the distribution over contexts that the robot observes at future steps. Thus, the i.i.d. assumption for the coverage guarantee is no longer valid. Here, we present a novel extension of CP to multi-step settings that tackles this challenge.</p><p>Sequence-level calibration. The key ideas are to (i) lift the data to sequences, and (ii) perform calibration at the sequence level using a carefully designed nonconformity score function that allows for causal construction of the prediction set at test time. Suppose that each data point consists of a sequence of augmented context x = (x 0 , x1 ,..., xT-1 ) and true labels y = (y 0 ,y 1 ,...,y T -1 ), where T is the time horizon and xt arises from having performed the correct actions in previous steps. The distribution D over scenarios induces a distribution over data sequences. We can again collect a calibration set</p><formula xml:id="formula_3">Z ={z i =(x i ,y i )} N i=1 .</formula><p>Next we use the lowest score over the timesteps as the score for the sequence <ref type="foot" target="#foot_3">4</ref> :</p><formula xml:id="formula_4">f(x) y := min t?[T ] f(x t ) y t .<label>(4)</label></formula><p>With the standard calibration procedure in Section 3.1, we construct a sequence-level prediction set C(x test ):={y ?Y T | f(x test ) y ?1-q} for a new context sequence x test with the quantile q.</p><p>Causal construction of C(x) at test time. Note that C(x test ) is constructed with the full sequence x test at once. However, at test time, we do not see the entire sequence of contexts all at once but rather x t test one at a time. We thus need to construct C( x test ) in a causal manner (i.e., always relying only on current and past information). Consider the causally constructed prediction set C t (x t test ) := {y t | f(x t test ) y t ? 1 -q} at time t using the same quantile level q from the non-causal calibration above, and define C(</p><formula xml:id="formula_5">x test ) := C 0 (x 0 test ) ? C 1 (x 1 test ) ? ??? ? C T -1 (x T -1 test ).</formula><p>We would like to obtain a lower bound on the sequence-level coverage: P(y test ?C(x test ))?1-?.</p><p>Claim 1 For any y ?Y T , y ?C(x test ) ?? y ?C(x test ).</p><p>Proposition 2 (Multi-step uncertainty alignment) Consider a multi-step setting where we use CP with coverage level 1-? to causally construct the prediction set and seek help whenever the set is not a singleton at each timestep. With probability 1-? over the sampling of the calibration set, the task completion rate over new test scenarios drawn from D is at least 1-?. If f models true conditional probabilities, the average prediction set size is minimized among possible prediction schemes that achieve 1-? completion rate.</p><p>The proofs are deferred to Section A2. Claim 1 allows us to construct causal prediction sets from non-causal calibration. We then show that the sequence-level task completion rate guarantee still holds.</p><p>Multiple acceptable options. Often, there can be multiple acceptable options at the same timestep, e.g., the task is to bring the human a soda, and either the Coke or Sprite on the table is acceptable. In such settings, we would like the prediction set to contain at least one acceptable option. We extend our method and confidence guarantees to this setting for both single-and multi-step problems in Section A3 and Section A4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our framework in a diverse set of language-instructed tasks and environments below, and demonstrate its effectiveness in achieving a user-specified task completion rate while minimizing user help. We use PaLM-2L <ref type="bibr" target="#b12">[13]</ref> as the LLM in all examples unless otherwise noted. Section A7 shows details of the scenario distribution in each example and additional information on the baselines. Section A8 shows details of robot perception and low-level policies. Section A9 shows additional discussions and experiment results.</p><p>Baselines. A straightforward way to construct prediction sets given a desired 1-? coverage is to rank options according to confidence and construct a set such that the cumulative confidence exceeds 1-?; we consider two baselines that are based on such cumulative thresholding but use different kinds of scores: Simple Set uses the same f as KNOWNO; Ensemble Set <ref type="bibr" target="#b13">[14]</ref> instead uses the frequencies of the LLM outputting y ?Y (out of 20 trials total) with randomized sampling of few-shot examples in the prompt. However, the resulting prediction sets are not guaranteed to achieve 1-? coverage as the probabilities can be miscalibrated <ref type="bibr" target="#b14">[15]</ref>, and often include additional unnecessary options <ref type="bibr" target="#b15">[16]</ref>. Instead of using cumulative thresholding, KNOWNO constructs prediction sets by including options with scores higher than a threshold computed using CP, which results in statistical guarantees. We also introduce two prompt-based baselines: Prompt Set prompts the LLM to directly output the prediction set (e.g., "Prediction set: [A, C]"); Binary prompts the LLM to directly output a binary indicator for uncertainty (e.g., "Certain/Uncertain: Certain"), which is used in other LLM-based planning work <ref type="bibr" target="#b1">[2]</ref> for triggering human intervention. Note that the ? level is not used in Prompt Set or Binary, and so the user cannot explicitly control the task success rate. Lastly, we consider No Help where the option with the highest score is always executed without any human intervention. A robot arm is asked to rearrange objects on a table in the PyBullet simulator <ref type="bibr" target="#b16">[17]</ref> (Fig. <ref type="figure">1</ref> right top). Each scenario is initialized with three bowls and blocks of green, yellow, and blue colors. The task is to move a certain number of blocks or bowls towards a different object or at a specific location around it. We introduce three settings based on different types of ambiguities in the user instruction: (1) Attribute (e.g., referring to the bowl with the word "receptacle"), ( <ref type="formula" target="#formula_1">2</ref>) Numeric (e.g., under-specifying the number of blocks to be moved by saying "a few blocks"), and (3) Spatial (e.g., "put the yellow block next to the green bowl", but the human has a preference over placing it at the front/back/left/right). For each setting, we construct a distribution over scenarios (detailed in Section A7) and perform experiments separately.</p><p>KNOWNO achieves target task success rate consistently. First, we investigate whether KNOWNO and the baselines achieve a given target task success rate consistently in the three settings -we set the failure level ?=0.15. In Fig. <ref type="figure">3</ref> we show the difference between achieved and target rates for all methods. Results show that KNOWNO achieve the least deviations overall, due to the coverage guarantee from CP. Simple Set and Ensemble Set cannot achieve coverage consistently. Prompt Set, Binary, and No Help have larger deviations from the target since the user has no control over the error rate. Also, as the scenarios get increasingly ambiguous (least in Attribute and most in Spatial), the baselines show larger deviations.</p><p>KNOWNO achieves high task success rate with lower human help as ? varies. In Fig. <ref type="figure" target="#fig_2">4</ref> we vary the target error rate ? and show the curves of task success rate vs. prediction set size and human help rate averaged over the three settings. For KNOWNO, Simple Set, and Ensemble Set, specifying a lower ? improves the empirical task success rate while also requiring more human help. The most natural comparison is between KNOWNO and Simple Set, as both use next-token probabilities from the LLM as the confidence score. KNOWNO achieves higher success-to-help ratios across ? levels, thanks to calibrated confidence from CP. Meanwhile, Prompt Set and Binary do not allow controlling success rates. Prompt Set performs the worst, indicating the challenge of prompting-based methods for calibrated prediction sets. Binary works favorably at some success levels, but lacks flexibility and doesn't provide prediction sets for human feedback. In addition, Fig. <ref type="figure" target="#fig_10">A9</ref> shows the results for individual ambiguity settings. As the scenarios become more ambiguous, KNOWNO shows a greater reduction of human help compared to Simple Setas much as 24% at certain success levels. Ensemble Set can perform well but is computationally expensive. Fig. <ref type="figure" target="#fig_2">4</ref> also shows that Ensemble Set provides high task success rate with small amount of human help at higher ? levels. However, there are two main drawbacks. First, we find in some scenarios that even with 20 randomized prompts, the LLM can fail to choose the correct option and thus assigns zero probability to it. As shown in Fig. <ref type="figure" target="#fig_2">4</ref>, this means that Ensemble Set can fail to improve once it reaches some level of human help. Second, it requires 20? inference time compared to other methods. Investigating how to lower the computational burden and combining ensemble-based probabilities with CP can be a fruitful future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hardware: Multi-Step Tabletop Rearrangement</head><p>In this example, a UR5 robot arm is asked to sort a variety of toy food items on a table (Fig. <ref type="figure" target="#fig_3">5 left</ref>). In each scenario, three items are placed on the table initially, and the task is to sort them based on human preferences; we simulate a human with strong preferences for healthy food like eggs and fruits, and dislike for less healthy food like donuts and Skittles candies. To introduce ambiguities, the context for the LLM reveals only a subset of the preferences. Here we consider a multi-step setting with possibly multiple acceptable options per step -the LLM plans the new step conditioned on the previous action taken. KNOWNO reduces step-wise and trial-wise intervention rates in multi-step setting. Since Section 4.1 has shown that Ensemble Set can be expensive (even more so in the multi-step setting) and Prompt Set and Binary can fail to achieve the user-specified success level, we focus on comparing KNOWNO with Simple Set for the remainder of the evaluation. Here we set the desired error level ?=0.25. Since Simple Set does not provide calibrated coverage, we first find ?=0.42 for Simple Set to achieve the same planning error rate as KNOWNO in simulation. Then we run 50 trials for both methods in hardware. Table <ref type="table" target="#tab_0">1</ref> shows that KNOWNO reduces the human help rate by 14% step-wise and 8% trial-wise, while also reducing the average prediction set size. Compared to Simple Set which uses a much higher ?, KNOWNO achieves the specified trial-level task success rate precisely by leveraging the Multi-Step Uncertainty Alignment from Sec. 3.3. We also find that if we set ?=0.25 for Simple Set, the planner is grossly over-conservative and requires a step-wise help rate of 87%. Bimanual manipulation. We additionally present results for a bimanual object rearrangement setup where ambiguities arise from the choice of the arm due to the limited reachability of each arm (Fig. <ref type="figure" target="#fig_3">5</ref> right); results are deferred to Section A5. In this example, each scenario involves a mobile manipulator in front of a countertop and next to a set of recycling/compost/landfill bins in an office kitchen (Fig. <ref type="figure">1</ref>). The tasks include picking up some object from the counter, and possibly putting it in the drawer, or disposing of it in one of the bins. For the distribution of possible scenarios, we introduce new types of ambiguities based on Winograd Schemas <ref type="bibr" target="#b17">[18]</ref> (e.g., "There is an apple and bottled water on the counter...it is rotten. Can you dispose of it?"), and ones that potentially involve unsafe actions (e.g., "place the bowl in the microwave."; there is a plastic bowl and a metal bowl, but only the plastic one is safe for the microwave).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Hardware: Mobile Manipulator in a Kitchen</head><p>In Table <ref type="table" target="#tab_1">2</ref>, we compare KNOWNO to Simple Set again by first setting ?=0.15 and also finding ?=0. <ref type="bibr" target="#b23">24</ref> for Simple Set that achieves the same plan success rate in simulation. The hardware experiment results again show that KNOWNO reduces the human help rate by 14% and also reduces the average prediction set size.</p><p>Target success guarantee from KnowNo is robust to varying LLM choice. We also run KNOWNO with two other LLMs (without hardware evaluation). First, we use an instruction-finetuned version of PaLM-2L (PaLM-2L-IF); there is no significant performance difference from PaLM-2L; however, it generates smaller prediction sets in general by reducing the number of larger prediction sets (size 3 and 4) significantly. Second, we run GPT-3.5 (text-davinci-003) from OpenAI. However, we find that it exhibits significant MCQA bias towards options D and E and against A and B, affecting the overall performance. Nonetheless, KnowNo still achieves 1-? target success rate, as the coverage guarantee from CP makes no assumption about the LLM confidences (e.g., calibrated or accurate) -KnowNo flexibly compensates for the degraded LLM performance by triggering more human intervention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>LLMs for robot planning and interaction. Large language models have shown a wide range of capabilities: reasoning <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, logic <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, math <ref type="bibr" target="#b22">[23]</ref>, physics <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>, high-level planning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref> with language feedback <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b1">2]</ref>, and writing robot code <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>. The generated outputs can be guided to a certain extent with sufficient prompting, but LLMs are still prone to confidently hallucinating outputs (e.g., referring to objects not observed in the scene <ref type="bibr" target="#b30">[31]</ref>, or calling motion primitive APIs that may not exist <ref type="bibr" target="#b4">[5]</ref>). We hypothesize that these challenges can be alleviated while obtaining statistical guarantees by modeling the uncertainty of LLMs <ref type="bibr" target="#b33">[34]</ref> and generating prediction sets via CP.</p><p>Uncertainty quantification for LLMs. Motivated by LLMs' overconfidence and hallucinations, there has been a growing body of work in quantifying and better calibrating uncertainty <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>.</p><p>In contrast to typical calibration methods that associate uncertainty with point-valued outputs, CP-based methods for language modeling provide coverage guarantees for set-valued predictors <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref>. However, there have been few applications of CP in quantifying uncertainty of LLMs with free-form outputs <ref type="bibr" target="#b45">[46]</ref>: Kumar et al. <ref type="bibr" target="#b46">[47]</ref> apply CP to next-token prediction in MCQA tasks exclusively, while KNOWNO builds on MCQA but is applicable to general natural language generation tasks.</p><p>Conformal prediction in robotics. To the best of our knowledge, this work is the first to employ CP for language-based planning. Prior work has utilized CP for fault detection, trajectory prediction, and planning in dynamic environments <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. At each point in the planning horizon, the probabilistic safety guarantee either holds on average <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b47">48]</ref>, or is too conservative due to union bounding <ref type="bibr" target="#b48">[49]</ref>, or requires additional calibration data to reduce conservatism <ref type="bibr" target="#b49">[50]</ref>. In contrast, we provide a novel multi-step extension to CP to guarantee correctness for the entire planning horizon by performing sequence-level calibration in settings where the robot's actions influence the distribution of future inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Summary: We propose KNOWNO, a framework that applies conformal prediction (CP) to address the problem of uncertainty alignment for language-instructed robots, which we formalize as providing statistical guarantees of task completion while minimizing human help. Experiments across a variety of simulated and hardware setups demonstrate that KNOWNO achieves user-specified task completion levels consistently while reducing human help by 10-24% compared to baseline approaches that lack formal assurances.</p><p>Limitations and future work: The primary limitation of our work is that the task completion guarantee assumes environments (objects) are fully grounded in the text input to the LLM, and the actions proposed by the LLM planner can be executed successfully. In the future, we are looking to incorporate uncertainty of the perception module (e.g., vision-language model) and the low-level action policy (e.g., languageconditioned affordance prediction) into the CP calibration. Another exciting direction is to combine our methods with active preference learning <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref> to generate open-ended queries that maximally reduce uncertainty about human preferences. On the theoretical front, modifying CP to optimize different metrics for human help (e.g., minimizing human intervention rate by maximizing number of singleton sets) would be of practical interest. Overall, we hope that the work presented here spurs further efforts towards uncertainty alignment for safe and reliable language-instructed robots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1 Evaluating Semantic Uncertainty of the LLM with MCQA</head><p>Here we provide additional rationale of using the MCQA setup for evaluating LLM uncertainty. The uncertainty of the language model can be thought of as the predictive entropy of the output distribution. Consider the input tokens x=(? i ,...? k ) and the output distribution Y where y =(? i ,...? k )?Y :</p><formula xml:id="formula_6">U(x) :=H(Y |x) = -p(y|x)lnp(y|x)dy. (<label>A1</label></formula><formula xml:id="formula_7">)</formula><p>Evaluating this is very challenging for LLMs: the output distribution over Y lies on the space of dimension O(|T | k-i+1 ) where T is the set of possible tokens, and it has to be evaluated with a large number of samples and Monte-Carlo integration. Among the samples, there is also the bias against longer sequences <ref type="bibr" target="#b5">[6]</ref>.</p><p>We are partially inspired by Kuhn et al. <ref type="bibr" target="#b37">[38]</ref> that instead consider the semantic uncertainty of the model: among samples in Y , there are groups of samples that have the same semantic meanings, such as "put the sponge in the top drawer by first opening it" and "open the top drawer and put the sponge in it". They may differ in p(y|x) but we are not concerned with such uncertainty since it does not reflect the uncertainty of the LLM about the scenario. Kuhn et al. <ref type="bibr" target="#b37">[38]</ref> addresses this by first sampling a large number of samples from Y , and then grouping them based on some semantics classifier before evaluating the semantic uncertainty, which is the predictive entropy over the groups instead of over Y .</p><p>Could we improve the efficiency of finding semantically distinct groups in Y ? The MCQA setup that we propose addresses this by prompting the LLM to generate likely, and also semantically different, options given the task using few-shot exemplars. We can think of this as splitting the output space Y into multiple spaces representing semantically different outputs. MCQA first samples the representative outputs from the spaces with higher weights in Y (top four), and then includes the additional option "an option not listed here" to cover rest of the spaces. Unlike Kuhn et al. <ref type="bibr" target="#b37">[38]</ref> who calculate the entropy among the groups to decide whether to trust the answer to a question, KNOWNO instead combines the normalized probabilities with conformal prediction to provide set-based predictions with coverage guarantees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2 Proofs for CP in Multi-Step Setting</head><p>Algorithm 1 Multi-step LLM planning with human help. . This is true with the same argument that functions of independent random variables are independent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A5 Additional Experiment Setting: Hardware Bimanual Setup</head><p>In this example, a bimanual setup with two Kuka IIWA 7 arms move objects on the table, with one bin at each side (Fig. <ref type="figure" target="#fig_3">5 right</ref>). The reachable workspace of each arm is limited so that one arm cannot reach the other end of the table or the other bin. Thus, there can be ambiguities in the choice of the arm depending on the task; e.g., Fig. <ref type="figure" target="#fig_3">5</ref> shows the human asking the robot to pass over the mango, but not specifying which side the human is standing at. KNOWNO is able to capture such ambiguities and triggers clarification. We design a scenario distribution with all instructions being ambiguous (thus requiring high human intervention rate): with ?=0.15, the robot achieves 84% plan success with 92% help. With 10 trials, the robot succeeds 9 times while triggering help for 9 times. Details of the scenario distribution are shown in Section A7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A6 LLM Prompt Setup</head><p>Next we detail the LLM prompt setup for MCQA applied in KNOWNO. We will use Mobile Manipulation from Section 4.3 as the example.</p><p>Multiple choice generation. Given a scenario, we first prompt the LLM to generate four semantically different options for possible next step. We apply few-shot prompting as shown in Fig. <ref type="figure" target="#fig_5">A1</ref> below. In this scenario, there is a Coke, a bottled tea, and a Pepsi on the counter, and the task is to put the Coke in the top drawer but the choice of drawer is under-specified ("Put the Coke in the drawer please.").</p><p>We: You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a middle one. There is also a landfill bin, a recycling bin, and a compost bin.</p><p>We: On the counter, there is an orange soda, a Pepsi, and an apple. We: Put that drink in the top drawer. We: On the counter, there is a bottled water, a bag of jalapeno chips, and a bag of rice chips. We: I would like a bag of chips. You: A) pick up the bottled water B) pick up the jalapeno chips C) pick up the kettle chips D) pick up the rice chips</p><p>We: On the counter, there is a Coke, a bottled unsweetened tea, and a Pepsi. We: Put the Coke in the drawer please. You: After the LLM generates four options, we append an additional option 'an option not listed here' to the four generated ones and then randomize the order to further prevent bias. We then use a zero-shot prompt in Fig. <ref type="figure" target="#fig_6">A2</ref> for querying next-token probabilities ('A', 'B', 'C', D', 'E').</p><p>We: You are a robot operating in an office kitchen. You are in front of a counter with two closed drawers, a top one and a middle one. There is also a landfill bin, a recycling bin, and a compost bin.</p><p>We: On the counter, there is a Coke, a bottled unsweetened tea, and a Pepsi. We: Put the Coke in the drawer please. You: A) pick up the coke B) pick up the coke and put it in the top drawer C) pick up the coke and put it in the bottom drawer D) an option not listed here E) pick up the pepsi We: Which option is correct? Answer with a single letter. You: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A7 Additional Experiment Details</head><p>Environments. In addition to Fig. <ref type="figure">1</ref> and Fig. <ref type="figure" target="#fig_3">5</ref>, here Fig. <ref type="figure" target="#fig_7">A3</ref> shows the office kitchen environment with the set of drawers and bins used in Mobile Manipulation (left), and the bimanual setup with the set of objects used on the mat used in Bimanual (right). There is another set of drawers used in the mobile manipulation experiments underneath a much bigger countertop not shown here. Scenario distributions. Next, we provide more details on the task settings, in particular, the possible ambiguities in the scenario distribution. With the distributions set up, it is straightforward to sample 400 i.i.d. scenarios from them for conformal prediction calibration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KnowNo white shallow container</head><p>? Attribute ambiguities in Simulation: besides unambiguous terms like "green", "yellow", "blue", "block" and "bowl" ("put green block in yellow bowl"), refer to the block as one of "cube", "cuboid", "box", "square object", to the bowl as one of "container", "round object", "receptacle", or to either block or bowl as one of "object", "item", "thing" ("move the blue object in yellow bowl"); refer to "blue" as one of "cyan", "navy", to "green" as one of "greenish", "grass-colored", and to "yellow" as "orange" or "gold". This setting is the least ambiguous one among the three ambiguity types. ? Numeric ambiguities in Simulation: besides unambiguous terms like "a", "one", "a single of", "two", "a pair of", "three", "all" ("put a block in yellow bowl"), refer to either two or three numerically with one of "a few", "a couple of", "some", "a handful of" ("put some blocks in the green bowl"). ? Spatial ambiguities in Simulation: besides unambiguous terms like "in front of", "behind", "to the left", and "to the right" ("put the green block to the left of green bowl"), refer to any of the four possible directions with "near", "close to", "beside", "next to", refer to either left to right with "lateral to", and refer to either front or behind with "along the line of sight". This setting is the most ambiguous one among the three ambiguity types. ? Hardware Tabletop Rearrangement: we split the 28 toy items (Fig. <ref type="figure">A6</ref>) to simulate human preferences in healthy foods over less healthy ones: human likes corn, avocado, celery, carrot, tomato, lettuce, apple, orange, pear, lemon, peanut butter, sunny-side-up egg, egg, and pea; human dislikes pretzel, cracker, waffle, mustard, ketchup, pizza, meat patty, cheese, chicken drumstick, peach, mango M&amp;M, Skittles, and donut. In each scenario, three items are involved with either two or one of them from the preferred list. Baselines -Prompt Set. First, multiple choices are generated in the same way as KNOWNO. Then LLM is prompted to generate the prediction set, with few-shot examples in the prompt showing the possible labels (Fig. <ref type="figure" target="#fig_8">A4</ref>). For example, "We: Which options are possibly correct? You: A, C, D.".</p><p>Baselines -Binary. Instead of generating multiple choices, the LLM is first prompted to give the most likely action (e.g., "We: Put the Coke can in the drawer. You: I will" shown in Fig. <ref type="figure">A7</ref>). Then we attach the generated response to the same prompt, and ask LLM to label "Certain/Uncertain:" given few-shot examples (Fig. <ref type="figure" target="#fig_3">A5</ref>).</p><p>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A9 Additional Discussions</head><p>Sentence-level score leads to worse performance. In Section 2 we hypothesize that the distribution of probabilities of LLM outputs p(y) is highly sensitive to the output length. Here we explore the effect of using sentence output and the perplexity score for CP in Simulation. We still apply multiple choice generation first to obtain the possible options from LLM, and then query LLM scoring, for example, the probability of "put the blue block in the green bowl" with the prompt ending with "I will" (Fig. <ref type="figure">A7</ref>). We test two different method: CP with RawProb, which uses the raw product of conditional probabilities p(y)= k i=1 p(? i |? 1 ,...,? i-1 ), and CP with Perplexity, which applies length normalization and commonly used in language modeling, perplexity(y) = exp{-1 k k i=1 log p(? i | ? 1 ,...,? i-1 )}. Table <ref type="table" target="#tab_5">A1</ref> shows that for all three settings, using either sentence-level score leads to worse performance, and performance degradation correlates with variance of the multiple choice lengths. We also notice that there is no significant difference in performance between CP with RawProb and CP with Perplexity; this could indicate that beyond eliminating length bias, applying MCQA setup in KNOWNO affords additional benefit of soliciting more accurate confidence from the LLM. Figure <ref type="figure">A7</ref>: Prompt used when evaluating the sentence-level scores in Simulation. We first generate the multiple choices in the same way as KNOWNO, and then evaluate the score of each multiple choice with this prompt. This prompt is also used to generate the option in the Binary baseline.</p><p>Potentially stronger baselines with model fine-tuning. In Section 4 we introduce the two prompt-based baselines Prompt Set and Binary, and demonstrate them being (1) inflexible (not allowing controlling the target success rate) and ( <ref type="formula" target="#formula_1">2</ref>) do not properly model the uncertainty. We note that these two baselines can be potentially strengthened by fine-tuning the LLM to better predict the binary uncertainty or the uncertainty set, if the true labels can be properly defined. In fact, some recent work <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b38">39]</ref> have explored model fine-tuning and exhibiting the effectiveness of Binary for uncertainty calibration. We also explored fine-tuning the GPT3 model (davinci) from OpenAI, which is the most powerful one from OpenAI available for fine-tuning. However, we find the model performing at very low accuracy with MCQA, and fine-tuning the model always results in overfitting to the dataset, even with thousands of data and varying hyperparameters (including ones from <ref type="bibr" target="#b39">[40]</ref> and default ones from the API). We suspect that our scenarios exhibit high complexity and variance, and it is non-trivial to fine-tune the model well with our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># Attribute ambiguity</head><p>We: On the table there are these objects: green block, blue bowl, yellow block, green bowl, yellow bowl, blue block. We: Now, put the yellow square object at the right side of the orange container. You: A) put yellow block to the right of green bowl B) put yellow block to the right of yellow bowl C) put yellow block to the right of blue bowl D) an option not listed here E) put yellow block to the right of blue block # Numeric ambiguity We: On the table there are these objects: yellow bowl, blue bowl, green block, yellow block, blue block, green bowl. We: Now, put a handful of receptacles at the right side of the blue block. You: A) an option not listed here B) put yellow bowl and blue bowl to the right of blue block C) put green block and yellow block to the right of blue block D) put yellow bowl and blue bowl and green bowl to the right of blue block E) put green block and yellow block and blue block to the right of blue block # Spatial ambiguity We: On the table there are these objects: green bowl, yellow bowl, blue bowl, yellow block, green block, blue block. We: Now, put the yellow block along the line of sight of the blue square object. You: A) an option not listed here B) put yellow block behind blue block C) put yellow block to the left of blue block D) put yellow block in front of blue block E) put yellow block to the right of blue block Low-level control success rate. KNOWNO translates the coverage guarantee from CP to task completion guarantee leveraging human help. However, this relies on the low-level control working reliably. In Simulation Tabletop Rearrangement, we find the pick-and-place primitives always executed as the object diversity is limited to square blocks and normal bowls (only differing in color). In Hardware Tabletop Rearrangement, we find the pick-and-place primitive only failed once during the 50 trials of running KNOWNO and twice for Simple Set (Table <ref type="table" target="#tab_0">1</ref>). The high success rate is largely thanks to the precise object masks from Segment Anything <ref type="bibr" target="#b57">[58]</ref>. Also, to allow reliable suctioning, we apply clear scotch tape on some of the objects (e.g., donut, waffle) to smoothen the surfaces. In Hardware Mobile Manipulation, we find the low-level action success rate to be around 86%, which causes the non-trivial discrepancies between plan success and task success rates in Table <ref type="table" target="#tab_1">2</ref>. One exciting future direction is to quantify and better calibrate the uncertainty of the low-level action module, and take such uncertainty into account of the end-to-end task completion guarantee. We: On the counter, there is a RedBull, a bottled unsweetened tea, and a bag of multigrain chips.</p><p>We: I drank it already. Can you dispose of it? You: A) an option not listed here B) pick up the redbull and put it in the landfill bin C) pick up the bottled unsweetened tea and put it in the landfill bin D) pick up the bottled unsweetened tea and put it in the recycling bin E) pick up the redbull and put it in the recycling bin We: On the counter, there is an apple, a orange, and an energy bar. We: Bring me a fruit. We: On the counter, there is an apple, a bag of multigrain chips, and a bag of rice chips. We: I want a healthy snack. Figure <ref type="figure" target="#fig_5">A10</ref>: Randomly sampled scenarios from Mobile Manipulation, where KNOWNO generates singleton prediction sets that contains one of the true labels and avoids human intervention, while Simple Set generates non-singleton prediction sets and asks for human help. In Table <ref type="table" target="#tab_1">2</ref> we show that KNOWNO reduces the human intervention rate by 14%. We also point out the third example where the instruction is to 'Put the soda in the drawer', which is ambiguous in the choice of top and middle drawer. In this scenario, it happens that the human means the top drawer, and KNOWNO generates the prediction set that only include the option 'open the top drawer and put the coke in it'. This example exhibits the inherent bias in LLM (e.g., bias towards top drawer over middle drawer).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>44 -</head><label>44</label><figDesc>Put plastic bow 0.41 -Put metal bow 0.03 -Put metal bow 0.08 -Put plastic bow Number of pos Predictio There is a metal bowl and a plastic bowl. Put the bowl in the microwave. There is an apple and a dirty sponge? It is rotten. Can you dispose of it? There is a Coke, a Sprite, and a bottled water? Can you get me a soda? There are rice chips and multigrain chips? Put rice chips in the drawer. ?? MCQA A) Put the dirty sponge in landfill bin B) Put the apple in compost bin C) Put the apple in landfill bin D) Put the dirty sponge in compost bin E) An option not listed here Which option is correct? A: 0.20 B: 0.56 C: 0.12 D: 0.08 E: 0.04 Multiple Choice Generation Next-token Likelihood Conformal Prediction is a Coke, a Sprite, and a l water? Can you get me a ? k up the Coke h option is correct? a Coke, a Sprite, and a bottl an you get me a soda? p the Coke ption is correct? an apple and a dirty sponge? n. Can you dispose of it? e dirty sponge in landfill bin tion is correct? Scores from Calibration Data A: 0.20 B: 0.56 C: 0.12 D: 0.08 E: 0.04 Score Threshold Score Threshold</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4. 1 Figure 3 :</head><label>13</label><figDesc>Figure 3: Deviation from specified task success level 1-?=0.85 to the empirical success rate for the three settings in Simulation.</figDesc><graphic url="image-31.png" coords="6,357.16,456.99,147.76,159.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison of task success rate vs average prediction set size (Left) and vs. human help rate (Right) in Simulation averaged over the three settings. 200 trials are run for each method. ? is varied from 0.25 to 0.01 for KNOWNO, and from 0.6 to 0.01 for Simple Set and Ensemble Set. Binary and No Help are not shown on the left since prediction sets are not provided.</figDesc><graphic url="image-37.png" coords="7,270.11,291.55,287.59,175.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (Left) Multi-step CP is applied in Hardware Tabletop Rearrangement. (Right) CP models ambiguity in possible human locations and triggers clarification from the human in Bimnual.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>You: A) open the top drawer and put the orange soda in it B) open the middle drawer and put the Pepsi in it C) open the middle drawer and put the orange soda in it D) open the top drawer and put the Pepsi in itWe: On the counter, there is an energy bar, a banana, and a microwave. We: Put the snack next to the microwave. You: A) pick up the energy bar and put it next to the microwave B) pick up the banana and put it next to the energy bar C) pick up the banana and put it next to the microwave D) pick up the energy bar and put it next to the banana We: On the counter, there is a Coke, a Sprite, and a sponge. We: Can you dispose of the can? It should have expired. You: A) pick up the sponge and put it in the landfill bin B) pick up the Coke and put it in the recycling bin C) pick up the Sprite and put it in the recycling bin D) pick up the Coke and put it in the landfill bin</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure A1 :</head><label>A1</label><figDesc>Figure A1: Prompt used for multiple choice generation in Mobile Manipulation. With few-shot prompting show examples of possible next steps in different scenarios, the LLM can generate semantically different plans that are more likely than others (see prompting result in Fig. A2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure A2 :</head><label>A2</label><figDesc>Figure A2: Prompt used for next-token prediction with generated multiple choices in Mobile Manipulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure A3 :</head><label>A3</label><figDesc>Figure A3: (Left) Office kitchen environment with drawers and bins for Mobile Manipulation. (Right) Bimanual setup with the set of objects used in the experiments.</figDesc><graphic url="image-66.png" coords="17,147.60,263.87,166.57,111.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A4 :</head><label>A4</label><figDesc>Figure A4: Prompt with few-shot examples (two shown) for LLM generating the prediction set in Prompt Set baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure A8 :</head><label>A8</label><figDesc>Figure A8: Sample multiple choices generated with Attribute, Numeric, and Spatial ambiguities in Simulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure A9 :</head><label>A9</label><figDesc>Figure A9: Comparison of task success rate vs average prediction set size (Top row) and vs. human help rate (Bottom row) in Simulation for each of the three ambiguity settings: Attribute, Numeric, and Spatial (Columns), as ? varies from 0.25 to 0.01 for KNOWNO, and from 0.6 to 0.01 for Simple Set and Ensemble Set. Binary and No Help are not shown in the top row since prediction set is not involved. Prompt Set does not show up in the human help rate plot for the Spatial setting as it only achieves 35% task success. As the setting gets more ambiguous (least in Attribute and most in Spatial), the performance difference between KNOWNO and Simple Set grows.</figDesc><graphic url="image-77.png" coords="21,242.09,583.58,154.97,78.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>True label: ['D']; Prediction set with KnowNo: ['D']; Prediction set with Simple Set: ['D', 'E']We: On the counter, there is a bottled tea, a RedBull, and a Pepsi. We: Bring me something to drink. You: A) an option not listed here B) pick up the redbull C) pick up the pepsi D) pick up the bottled tea E) pick up the bottled tea and put it in the recycling bin True label: ['B', 'C', 'D']; Prediction set with KnowNo: ['D']; Prediction set with Simple Set: ['A', 'D'] We: On the counter, there is a Sprite, a bag of kettle chips, and a Coke. We: Put the soda in the drawer. You: A) open the top drawer and put the coke in it B) an option not listed here C) open the middle drawer and put the coke in it D) open the middle drawer and put the sprite in it E) open the top drawer and put the sprite in it True label: ['A']; Prediction set with KnowNo: ['A']; Prediction set with Simple Set: ['A', 'C', 'E']</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>You: A) an option not listed here B) pick up the apple C) pick up the orange D) pick up the energy bar E) pick up the apple and put it in the landfill bin True label: ['B', 'C']; Prediction set with KnowNo: ['B']; Prediction set with Simple Set: ['A', 'B']</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>You: A) pick up the rice chips B) pick up the multigrain chips C) pick up the apple D) pick up the apple and put it in the compost bin E) an option not listed here True label: ['B', 'C']; Prediction set with KnowNo: ['C']; Prediction set with Simple Set: ['A', 'C'] We: On the counter, there is an orange soda, a Sprite, and a Pepsi. We: Can you put away the soda? It should have expired. You: A) pick up the pepsi and put it in the recycling bin B) an option not listed here C) pick up the sprite and put it in the recycling bin D) pick up the orange soda and put it in the compost bin E) pick up the orange soda and put it in the recycling bin True label: ['E']; Prediction set with KnowNo: ['E']; Prediction set with Simple Set: ['D', 'E'] We: On the counter, there is a bag of jalapeno chips, a bag of multigrain chips, and a bag of rice chips. We: Bring me a bag of chips. You: A) pick up the multigrain chips B) pick up the rice chips C) pick up the jalapeno chips D) an option not listed here E) pick up the jalapeno chips and put it in the recycling bin True label: ['A', 'B', 'C']; Prediction set with KnowNo: ['A']; Prediction set with Simple Set: ['A', 'E']</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results for Hardware Multi-Step Tabletop Rearrangement. Plan success rate is fixed between KNOWNO and Simple Set for comparing the other metrics.</figDesc><table><row><cell cols="7">Method 1-? Plan Succ Task Succ Set Size Help-Step Help-Trial</cell></row><row><cell cols="3">KNOWNO 0.75 0.76</cell><cell>0.74</cell><cell>1.72</cell><cell>0.58</cell><cell>0.92</cell></row><row><cell cols="3">Simple Set 0.58 0.76</cell><cell>0.72</cell><cell>2.04</cell><cell>0.72</cell><cell>1.00</cell></row><row><cell>No Help</cell><cell>-</cell><cell>0.41</cell><cell>0.38</cell><cell>-</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results for Hardware Mobile Manipulation.Plan success rate is fixed between KNOWNO and Simple Set to compare the other metrics.</figDesc><table><row><cell>Method</cell><cell cols="6">Model 1-? Plan Succ Task Succ Set Size Help</cell></row><row><cell cols="4">KNOWNO PaLM-2L 0.85 0.87</cell><cell>0.76</cell><cell cols="2">2.22 0.67</cell></row><row><cell cols="4">Simple Set PaLM-2L 0.76 0.87</cell><cell>0.75</cell><cell cols="2">2.38 0.81</cell></row><row><cell cols="2">No Help PaLM-2L</cell><cell>-</cell><cell>0.62</cell><cell>0.51</cell><cell>-</cell><cell>0</cell></row><row><cell cols="4">KNOWNO PaLM-2L-IF 0.85 0.86</cell><cell>-</cell><cell cols="2">1.86 0.67</cell></row><row><cell cols="4">KNOWNO GPT-3.5 0.85 0.87</cell><cell>-</cell><cell cols="2">2.50 0.86</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Now let's derive the bound in Eq. (A18) and Eq. (A19). Again we need to consider the causal construction issue. As seen in Section 3.3, we construct the prediction set C(x test ) non-causally using the score functions i =1-f(x i ) y max i (taking minimum over steps). For a test sequence x test , we apply ? T -1 to the true label set of sequences Y test to get y max test = ? T -1 (x test ,Y test ). Now suppose y max test ? C(x test ), then we can show y max test ?C(x test ) with the same proof as the single-label setting, which gives us the bound. Lastly we need to show the sampled test sequence from D leads to a sample from D ? i.i.d. with S ?</figDesc><table><row><cell>2: 3: 4:</cell><cell>Observe input x t test and predict the set C(x t test ) if C(x t test ) is a singleton then Execute the action in C(x t test )</cell></row><row><cell>5:</cell><cell>else</cell></row><row><cell>6:</cell><cell>Ask for human help</cell></row><row><cell>7:</cell><cell>end if</cell></row><row><cell cols="2">8: end for</cell></row></table><note><p>1: for time t?0 to T -1 do</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>? Hardware Mobile Manipulation: please refer to https://robot-help.github.io/prompts/ -label, e.g., 'Bring me a cola.' and either Coke or Pepsi is acceptable; (4) creative-multi-label, e.g., 'Bring me something with a kick.' and either RedBull or jalapeno chips are acceptable; (5) spatiallyambiguous, e.g., 'Put the Coke in the drawer' or 'Put the Coke near the fruit' which under-specifies the drawer or fruit;<ref type="bibr" target="#b5">(6)</ref> unsafe, e.g., 'Can you dispose of the bottle drink? It should have expired.' or 'Place the bowl on the cooktop, please.';<ref type="bibr" target="#b6">(7)</ref> Winograd, e.g., 'There is a sponge and a bag of rice chips...I don't want to use it for cleaning any more. Can you please dispose of it?" We use the GPT-4 model for generating the creative tasks. ? Hardware Bimanual: please refer to https://robot-help.github.io/prompts/bimanual_ tasks.txt for the full list of scenarios sampled from the distribution. The distribution is a mixture of different task types: (1) 'Pick up the {object} and pass it to me. I am next to the bin.' (2) 'Pick up the {object} with the left arm.' (3) 'Put the {object} in the bin closer to it.' (4) 'Pick up the {object} with the arm closer to it.' (5) 'Pick up the {object}.' (6) 'Pick up the {object} at the handle.' (7) 'Move the {object} to the front of the table.' (8) 'Move the {object} on the sticky rubber mat to the front of the table.' Next we provide more details on the baselines that require additional prompting strategies. Baselines -Ensemble Set. Our ensemble-based method is a weaker method than the traditional modelbased ensemble where multiple copies of neural network are trained and inferred with; however, this is infeasible with the LLM we use. In our work, we randomize over the few-shot examples in the prompt as the ensemble. We select a pool of 20 possible MCQA examples (see examples in Fig. A1), and then randomly sample a certain amount from it for each inference. Note that in this case, Ensemble Set actually has advantage over KNOWNO and Simple Set that, for the same data, it has seen many more examples than the fixed ones in the prompt used in KNOWNO and Simple Set. We only apply ensemble for next-token prediction; the same set of multiple choices generated is used.</figDesc><table /><note><p>mobile_tasks.txt for the full list of scenarios sampled from the distribution. The distribution is a mixture of different task types: (1) single-label, e.g., 'Bring me a Coke' (unambiguous); (2) creativesingle-label, e.g., 'I want a healthy fruit to munch on.' which means the apple (unambiguous); (3) multi</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>..</figDesc><table><row><cell>We: On the table there are these objects: yellow bowl, blue bowl, blue block, green block, green bowl,</cell></row><row><cell>yellow block.</cell></row><row><cell>We: Now, Put the blue object at the right side of the grass-colored square object.</cell></row><row><cell>You: These are some options:</cell></row><row><cell>A) an option not listed here</cell></row><row><cell>B) put blue block to the right of green block</cell></row><row><cell>C) put blue block to the left of green bowl</cell></row><row><cell>D) put blue bowl to the right of green block</cell></row><row><cell>E) put blue block to the left of green block</cell></row><row><cell>Me: Which options are possibly correct?</cell></row><row><cell>You: B, D</cell></row><row><cell>We: On the table there are these objects: blue bowl, green block, yellow bowl, yellow block, blue block,</cell></row><row><cell>green bowl.</cell></row><row><cell>We: Now, Put the green round object at the left side of the greenish block.</cell></row><row><cell>You: These are some options:</cell></row><row><cell>A) put green bowl to the left of yellow block</cell></row><row><cell>B) an option not listed here</cell></row><row><cell>C) put green bowl to the left of green block</cell></row><row><cell>D) put green bowl to the left of blue bowl</cell></row><row><cell>E) put green bowl to the left of blue block</cell></row><row><cell>Me: Which options are possibly correct?</cell></row><row><cell>You: C</cell></row><row><cell>We: On the table there are these objects: yellow block, yellow bowl, blue block, green block, blue bowl,</cell></row><row><cell>green bowl.</cell></row><row><cell>We: Now, put the cyan bowl behind the gold object.</cell></row><row><cell>You: These are some options:</cell></row><row><cell>A) put blue bowl behind yellow block</cell></row><row><cell>B) put blue bowl behind green block</cell></row><row><cell>C) put blue bowl behind yellow bowl</cell></row><row><cell>D) an option not listed here</cell></row><row><cell>E) put blue bowl behind blue block</cell></row><row><cell>We: Which options are possibly correct?</cell></row><row><cell>You:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table A1 :</head><label>A1</label><figDesc>Comparison of KNOWNO with CP with sentence output and perplexity score in the three ambiguity settings in Simulation. ?=0.15. See Fig.A8for samples of multiple choices generated with varying lengths.</figDesc><table><row><cell cols="2">Setting Multiple Choice Length Variance</cell><cell>Method</cell><cell>Set Size Help</cell></row><row><cell></cell><cell></cell><cell>KNOWNO</cell><cell>1.18 0.18</cell></row><row><cell>Attribute</cell><cell>1.52</cell><cell cols="2">CP w/ RawProb 1.33 0.32</cell></row><row><cell></cell><cell></cell><cell cols="2">CP w/ Perplexity 1.35 0.36</cell></row><row><cell></cell><cell></cell><cell>KNOWNO</cell><cell>2.23 0.69</cell></row><row><cell>Spatial</cell><cell>2.81</cell><cell cols="2">CP w/ RawProb 2.50 0.82</cell></row><row><cell></cell><cell></cell><cell cols="2">CP w/ Perplexity 2.67 0.88</cell></row><row><cell></cell><cell></cell><cell>KNOWNO</cell><cell>2.17 0.79</cell></row><row><cell>Numeric</cell><cell>8.51</cell><cell cols="2">CP w/ RawProb 4.06 1.00</cell></row><row><cell></cell><cell></cell><cell cols="2">CP w/ Perplexity 4.06 1.00</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Webpage with additional results and videos: https://robot-help.github.io</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>In practice we convert the prediction set to a question in natural language (Section A8).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>If the correct option in C(xtest) is 'E', the human provides the correct action that was not listed by the robot.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>We overload notation here and use f to also assign confidence scores to sequences.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>We: You are a robot, and you are asked to move objects to precise locations on the table. Our instructions can be ambiguous.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially supported by the <rs type="funder">NSF</rs> <rs type="programName">CAREER Award</rs> [#<rs type="grantNumber">2044149</rs>] and the <rs type="institution">Office of Naval Research</rs> [<rs type="grantNumber">N00014-23-1-2148</rs>]. We thank <rs type="person">Chad Boodoo</rs> for helping set up the UR5 hardware experiments, and <rs type="person">Jensen Gao</rs>, <rs type="person">Nathaniel Simon</rs>, and <rs type="person">David Snyder</rs> for their helpful feedback on the paper.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZwAF9DB">
					<idno type="grant-number">2044149</idno>
					<orgName type="program" subtype="full">CAREER Award</orgName>
				</org>
				<org type="funding" xml:id="_raED3t7">
					<idno type="grant-number">N00014-23-1-2148</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof of Claim 1: Suppose y ?C(x test ). We have,</p><p>??y t ?C t (x t test ), ?t?[T ] (A4) ??y ?C(x test ).</p><p>(A5)</p><p>Proof of Proposition 2: Since we can bound the probability that y test / ? C(x test ), we can also bound the probability that y test / ?C(x test ). From the conformalization procedure, we have the following datasetconditional guarantee: with probability 1-? over the sampling of the calibration set Z, we have</p><p>where ? is chosen such that ?=1-Beta -1 N+1-v,v (?). Hence, the following marginal guarantee also holds:</p><p>This result provides a bound on the task completion rate if x test is drawn using the distribution D. However, recall that the sequence x of augmented contexts as defined in Section 3.3 arises from having performed the correct actions in previous steps; incorrect actions may result in a distribution shift. In order to obtain a bound on the task completion rate, we consider three cases at any given timestep: (1) the prediction set is a singleton and contains the correct label, (2) the prediction set is not a singleton but does contain the correct label, and (3) the prediction set does not contain the true label. The robot performs the correct action in the first two cases (without help in <ref type="bibr" target="#b0">(1)</ref> and with help in (2)), while CP bounds the probability of case (3). Thus, the CP bound translates to a bound on the task success rate.</p><p>As seen in Eq. ( <ref type="formula">3</ref>), we have from [10, Thm. 1], that we achieve the smallest average set size among all possible sequence-level prediction schemes, C, if f models the prediction uncertainty accurately,</p><p>A3 CP in Settings with Multiple Acceptable Options Per Step Proposition 3 (Multi-label uncertainty alignment) Consider a setting where we use CP with coverage level 1-? to construct the prediction set when there are multiple true labels and seek help whenever the set is not a singleton at each timestep. With probability 1-? over the sampling of the calibration set, the task completion rate over new test scenarios drawn from D is at least 1-?.</p><p>Proof: We have a dataset of Z ={(x i ,Y i ),...} N i=1 sampled i.i.d. from a data distribution D for calibration (we use the same notation D as in the single-label setting here), where Y i := {y i,j } Ji j=1 is the set of true labels for a single trial. For each label, we use the same heuristic notion of confidence, f(x) y ?[0,1].</p><p>We define an operator ? :X ?Y J ?Y where X is the space of contexts and Y is the space of labels:</p><p>which takes the true label with the highest confidence value from the true label set.</p><p>If we consider applying ? to every point in the support of D, a new distribution D ? is induced. We also consider the induced dataset of samples</p><p>Then we can perform the usual conformalization and obtain the guarantee that with</p><p>the following marginal guarantee holds,</p><p>and the following dataset-conditional guarantee holds when we choose ? such that ?=1-Beta -1 N+1-v,v (?) where v =?(N +1)??,</p><p>Hence, C(x test ) contains the true label with the highest confidence with probability at least 1-?. Proof: For the multi-step setting, each trial now involves a sequence of contexts x and a set of sequences of true labels:</p><p>where y m :=(y 0 m ,y 2 m ,...,y T -1 m ). For example, Y can contain the sequence of "blue block, yellow block, green block", "green block, blue block, yellow block", ..., for the task of picking up three blocks. We collect a dataset of Z ={(x i ,Y i )} of i.i.d. samples from the data distribution D.</p><p>Unlike the single-step setting, here we cannot apply ? to the set of true labels in each step since we are reasoning over a set of sequences, and not a sequence of sets of true labels. Notably, the true label set at time step t depends upon the sequence of previously chosen true labels. Let Y t [x 0 ,? t-1 ] denote the set of true labels at timestep t, conditioned upon the initial context x 0 and a partial sequence of past true labels ?t-1 :=(y 0 ,...,y t-1 ) extracted from Y . We then autoregressively define the following sequence:</p><p>For convenience, we denote ? t (x,Y )[?] the ? element in ? t (x,Y ),? ?t. An intuitive interpretation is that, we can consider Y forming a tree of valid executions (all possible actions that can be taken by choosing each of true labels). Hence, at each time step t, ? t (x,Y ) prunes the tree to a single branch by taking the true label with the highest heuristic value f(x t ). This reduces the tree of all possible sequences of true labels to a single branch of true labels with highest confidence. Given this single branch of true labels, we can now perform CP as shown in the multi-step setting in Section A2.</p><p>We apply ? T -1 to every point in the support of D, and a new distribution D ? is induced. We consider</p><p>Let Y test be the set of sequences of true labels for x test . Suppose we get the marginal bound with ? T -1 as the labels:</p><p>and dataset-conditional bound when we choose ? such that ?=1-Beta -1 N+1-v,v (?) where v =?(N +1)??,</p><p>which states that at test time, given a context sequence x test , we produce a prediction set of sequences; if we consider a sequence consisting of the true label with the highest score at each step, the probability of this sequence covered by C(x test ) is lower bounded by 1-?. However, we need to be careful of following ? t at each step at test time. Conside the three cases:</p><p>? (1) At a given time-step, the prediction set C t (x t test ) does not contain the true label,</p><p>The prediction set is a singleton and does contain the true label.</p><p>? (2b) The prediction set is not a singleton (but does contain the correct label).</p><p>We already bound the probability of (1) happening with the CP bound; (2a) is fine since the LLM will take the correct action; (2b) is more challenging -in this case the robot asks the human for help, and we need to make sure the human "follows" the true label, by choosing the true label in the prediction set with the highest confidence by f. In practice, we present the labels ranked by f and ask the human to choose the true label with the highest rank.</p><p>... We: On the table there are these objects: blue bowl, green block, yellow bowl, yellow block, blue block, green bowl. We: Now, Put the green round object at the left side of the greenish block. You: I will put green bowl to the left of yellow block. Certain/Uncertain: Uncertain We: On the table there are these objects: blue block, yellow bowl, green block, green bowl, blue bowl, yellow block. We: Now, Put the yellow box in front of the cyan receptacle. You: I will put yellow block at the front of blue block Certain/Uncertain: Certain We: On the table there are these objects: blue bowl, blue block, green bowl, yellow bowl, green block, yellow block. We: Put the yellow box at the right side of the navy receptacle. You: I will put yellow block to the right of blue block. Certain/Uncertain: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A8 Additional Implementation Details</head><p>While the focus of KNOWNO is mainly on providing uncertainty alignment for the LLM-based planner, below we provide details of the perception and action modules applied in all examples.</p><p>Perception. For all examples except for the Mobile Manipulation, we use either MDETR <ref type="bibr" target="#b55">[56]</ref> (Hardware Tabletop Rearrangement) or Owl-ViT <ref type="bibr" target="#b56">[57]</ref> (Simulation and Bimanual) open-vocabulary object detector for recognizing the objects in the environment and obtaining the object locations for low-level action. In Simulation and Bimanual, the variations of the object types are limited, and with general prompting, the objects are detected without issue. In Hardware Tabletop Rearrangement, since we are use a wide variety of toy items (Fig. <ref type="figure">A6</ref> right), the detector has issues often differentiating objects like peanut butter and meat patty that are both darker colors. We modify the scenario distributions to avoid using such items together in one scenario. In addition, we apply the Segment Anything model <ref type="bibr" target="#b57">[58]</ref> to extract the object segmentation masks (shown overlaid in Fig. <ref type="figure">A6</ref> left), and then use the polylabel algorithm <ref type="bibr" target="#b58">[59]</ref> to find the most distant internal point of the mask as the suction point (shown as red dots). Low-level action. In Simulation and Hardware Tabletop Rearrangement, simple pick-and-place actions are executed based on object locations and solving the inverse kinematics. In Bimanual, the reachability of the Kuka arm is limited, and the pick-and-place action trajectories are solved using Sequential Quadtratic Programming (SQP) instead <ref type="bibr" target="#b59">[60]</ref>. In Mobile Manipulation, for most of the tasks that involve simple pick-and-place and opening the drawers, the action is from an end-to-end policy from the RT-1 policy (please refer to <ref type="bibr" target="#b60">[61]</ref> for details), which takes in the raw observation. For some of the hard tasks such as putting the plastic bowl in the microwave and putting the metal bowl on the bowl, object locations are assumed known and we use scripted action policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KnowNo white shallow container</head><p>Human feedback. In KNOWNO, once human help is triggered, human is presented with the prediction set to choose the correct action from (if there is one). For example, the prediction set could include 'A) put peanut butter in blue plate' and 'C) put peanut butter in green plate' in Hardware Tabletop Rearrangement. In practice, we can convert the prediction set to a question in more natural language, e.g., "Do you like peanut butter or not?" using simple heuristics. In Mobile Manipulation and Bimanual, we prompt the LLM to generate the question based on the prediction set.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Do as I can, not as I say: Grounding language in robotic affordances</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herzog</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.01691</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Inner monologue: Embodied reasoning through planning with language models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=3R3" />
	</analytic>
	<monogr>
		<title level="m">6th Annual Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Pz5i0tye</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Algorithmic Learning in a Random World</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gammerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shafer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conformal prediction: A gentle introduction</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Angelopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="494" to="591" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.07753</idno>
		<title level="m">Code as policies: Language model programs for embodied control</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.10006</idno>
		<title level="m">Correcting length bias in neural machine translation</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A M</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garriga-Alonso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04615</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03300</idno>
		<title level="m">Measuring massive multitask language understanding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Conditional validity of inductive conformal predictors</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vovk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="475" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Least ambiguous set-valued classifiers with bounded error levels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sadinle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">525</biblScope>
			<biblScope unit="page" from="223" to="234" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">How can we know when language models know? on the calibration of language models for question answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="962" to="977" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Efficient and differentiable conformal prediction with general function classes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.11091</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">PaLM 2 technical report</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08786</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Uncertainty sets for image classifiers using conformal prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Angelopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.14193</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Pybullet, a python module for physics simulation for games, robotics and machine learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Coumans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<ptr target="http://pybullet.org" />
		<imprint>
			<biblScope unit="page" from="2016" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The winograd schema challenge</title>
		<author>
			<persName><forename type="first">H</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<title level="m">Chain of thought prompting elicits reasoning in large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11916</idno>
		<title level="m">Large language models are zero-shot reasoners</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Challenging big-bench tasks and whether chain-of-thought can solve them</title>
		<author>
			<persName><forename type="first">M</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sch?rli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.09261</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Selection-inference: Exploiting large language models for interpretable logical reasoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=3Pf3Wg6o-A4" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Solving quantitative reasoning problems with language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramasesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Slone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Schlag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gutman-Solo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.14858</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Mind&apos;s eye: Grounded language model reasoning through simulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.05359</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Leveraging language for accelerated learning of tool manipulation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Govil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Language models as zero-shot planners: Extracting actionable knowledge for embodied agents</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="9118" to="9147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Soh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.05128</idno>
		<title level="m">Translating natural language to planning goals with large-language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Task and motion planning with large language models for object rearrangement</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.06247</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11477</idno>
		<title level="m">LLM+P: Empowering large language models with optimal planning proficiency</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Antonova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lepert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05658</idno>
		<title level="m">Tidybot: Personalized robot assistance with large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Attarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choromanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Welker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florence</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.00598</idno>
		<title level="m">Socratic models: Composing zero-shot multimodal reasoning with language</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Progprompt: Generating situated robot task plans using large language models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Blukis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mousavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.11302</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Parsel: A (de-) compositional framework for algorithmic reasoning with language models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Poesia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10561</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.10376</idno>
		<title level="m">Clara: Classifying and disambiguating user commands for reliable interactive robotic agents</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13439</idno>
		<title level="m">Navigating the grey area: Expressions of overconfidence and uncertainty in language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Quantifying uncertainties in natural language processing tasks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7322" to="7329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Uncertainty quantification with pre-trained language models: A large-scale empirical analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.04714</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farquhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.09664</idno>
		<title level="m">Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Conerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schiefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hatfield-Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tran-Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>El-Showk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kravec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lovitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.05221</idno>
		<title level="m">Language models (mostly) know what they know</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.14334</idno>
		<title level="m">Teaching models to express their uncertainty in words</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Reducing conversational agents&apos; overconfidence through linguistic calibration</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="857" to="872" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08803</idno>
		<title level="m">Consistent accelerated inference via confident adaptive transformers</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Confident adaptive language modeling</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="17456" to="17472" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Conformal prediction for text infilling and part-of-speech prediction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kapper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lovig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Planchon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.51387/22-NEJSDS8</idno>
	</analytic>
	<monogr>
		<title level="j">The New England Journal of Statistics in Data Science</title>
		<idno type="ISSN">2693-7166</idno>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="83" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Transformer-based conformal predictors for paraphrase detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Giovannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gammerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conformal and Probabilistic Prediction and Applications</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="243" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Quach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.10193</idno>
		<title level="m">Conformal language modeling</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Conformal prediction with large language models for multi-choice question answering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Palepu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bellamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18404</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sample-efficient safety assurances using conformal prediction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schmerling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Foundations of Robotics XV</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="149" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Safe planning in dynamic environments using conformal prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lindemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cleaveland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Pappas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.10254</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Conformal prediction for STL runtime verification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lindemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Pappas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE 14th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2023)</title>
		<meeting>the ACM/IEEE 14th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2023)</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="142" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Adaptive conformal prediction for motion planning among dynamic agents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lindemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cleaveland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Burdick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.00278</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Active preference-based learning of reward functions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sadigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Dragan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
		</author>
		<idno type="DOI">10.15607/RSS.2017.XIII.053</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Robotics: Science and Systems (RSS)</title>
		<meeting>Robotics: Science and Systems (RSS)</meeting>
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Learning Preferences For Interactive Autonomy</title>
		<author>
			<persName><forename type="first">E</forename><surname>Biyik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
		<respStmt>
			<orgName>EE Department, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Better-than-demonstrator imitation learning via automatically-ranked demonstrations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Goo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Niekum</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="330" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Active reward learning from online preferences</title>
		<author>
			<persName><forename type="first">V</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Biyik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sadigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">MDETR-modulated detection for end-to-end multi-modal understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1780" to="1790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Simple open-vocabulary object detection with vision transformers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gritsenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.06230</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mintun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rolland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Whitehead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02643</idno>
		<title level="m">Segment anything</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Polylabel: a fast algorithm for finding the pole of inaccessibility of a polygon</title>
		<author>
			<persName><forename type="first">V</forename><surname>Agafonkin</surname></persName>
		</author>
		<ptr target="https://github.com/mapbox/polylabel" />
		<imprint>
			<date type="published" when="2016-07">July 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Optimizing trajectories with closed-loop dynamic SQP</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Slotine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5249" to="5254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">We: Now, put two blocks at the blueish bowl. You: I will put green block and yellow block on blue bowl. We: On the table there are these objects: yellow bowl, blue bowl, green block, yellow block, blue block, green bowl. We: Now, put a couple of receptacles at the right side of the blue block. You: I will put yellow bowl and blue bowl to the right of blue block. We: On the table there are these objects: green block, yellow bowl, yellow block, blue bowl, blue block, green bowl. We: Now, put one bowl at the front of amber-colored block. You: I will put green bowl at the front of yellow block</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carbajal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.06817</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>We: On the table there are these objects: green block, yellow bowl, yellow block, blue bowl, blue block, green bowl. We: On the table there are these objects: green block, blue block, green bowl, yellow bowl, blue bowl, yellow block. We: Now, put all cuboids at the right side of the yellow round object. You: I will</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
