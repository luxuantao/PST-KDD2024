<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vector Coding for Partial Response Channels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sanjay</forename><surname>Kasturia</surname></persName>
						</author>
						<author>
							<persName><roleName>AND</roleName><forename type="first">James</forename><forename type="middle">T</forename><surname>Aslanis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Cioffi</surname></persName>
						</author>
						<title level="a" type="main">Vector Coding for Partial Response Channels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4B8EA22EA8B278410BDCBFE0D44C130A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Absrrucr -The combination of equalization and coding for the additive Gaussian noise channel with linear intersymbol interference (1%) has received attention recently. A linear technique for combining equalization and coset codes on partial response channels with additive white Gaussian noise is developed. The technique, entitled "vector coding", uses a set of transmit filters or "vectors" to partition the channel into an independent set of parallel ISI-free channels for any given finite (or infinite) block length. The optimal transmit vectors for such channel partitioning are shown to be the eigenvectors of the channel covariance matrix for the specified block length, and the gains of the individual channels are the eigenvalues. An optimal bit allocation and energy distribution are derived for the set of parallel channels, under an accurate extension of the "continuous approximation" for power in optimal multidimensional signal sets for constellations with unequal signal spacing in different dimensions. Examples are presented that demonstrate performance advantages with respect to zero-forcing decision feedback methods that use the same coset code on the same partial response channel. Only resampling the channel at an optimal rate, and assuming no errors in the feedback path, will bring the performance of the decision feedback methods up to the level of the vector coded system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>H E STUDY of reliable data transmission over linear T channels with intersymbol interference (ISI) and additive gaussian noise has traditionally been separated into two distinct areas: channel equalization and channel coding. An example of this separation is the common practice of designing an optimal linear (feedforward) equalizer for a channel with IS1 (to remove ISI) and then applying a good code, designed for an ISI-free, additive white Gaussian noise channel, to the resultant equalized channel. Indeed, such an approach has led to reliable data transmission at rates that are significantly higher than those achievable with equalization alone; for example, good codes, such as those introduced by <ref type="bibr">Ungerboeck [l]</ref> and extended by Forney er al. <ref type="bibr">[2]</ref>, <ref type="bibr">Wei [3]</ref>, <ref type="bibr">and Calderbank and Sloane [4]</ref>, <ref type="bibr">[5]</ref> are successfully applied to band-limited channels. A comprehensive study of coset codes for ISIfree channels has been compiled by <ref type="bibr">Forney [61,</ref><ref type="bibr">[71.</ref> While these codes achieve near cutoff rate performance on the additive white gaussian noise channel, the achievable rates using a conventional linear equalizer and coset code combination will fall below the cutoff rate on linear channels Manuscript received <ref type="bibr">February 2, 1988;</ref><ref type="bibr">revised November 30, 1989.</ref> This work was presented in part at the 1988 International Symposium on Information Theory, Kobe, Japan. This work was supported in part by an IBM Faculty Development Award. by NSF Grant MIP 86-57266, and by the Stanford Joint Services Electronics Program (JSEP) under Contract DAAG 29-85-K-0048. S. <ref type="bibr">Kasturia</ref>  with ISI, with the rate loss increasing with the severity of the intersymbol interference.</p><p>The poorer performance of linear equalization based systems on channels with severe IS1 has generated vigorous interest in using decision feedback based techniques (with coset codes) on these channels. This interest is also motivated by a result, traceable to a paper by Price [SI, (also recently emphasized by <ref type="bibr">Eyuboglu [9]</ref> and generalized by <ref type="bibr">Kalet and Zervos [lo]</ref>), which shows that under certain conditions a zero-forcing DFE permits a pulse amplitude modulated (PAM) system to utilize channel capacity as efficiently on an IS1 channel as on an ISI-free channel. This result, however, requires the assumption of no errors in the feedback path of the DFE. For real systems errors will occur in the feedback path, and their frequency increase when coding is used with the DFE. Accumulated errors in the feedback path of the DFE may cause large losses in effective SNR, especially when the channel SNR is low or when coding is used in an attempt to improve the error rate. While several approaches <ref type="bibr">[9]</ref>, <ref type="bibr">[ll]</ref>, <ref type="bibr">[12]</ref> have been proposed to compensate for this effect, all of them substantially increase the complexity of practical implementations. An alternative approach to avoiding the assumption of no errors in the feedback path is based on the "Tomlinson" precoder <ref type="bibr" target="#b12">[13]</ref>, which moves the feedback section of the DFE to the transmitter, thus avoiding error propagation. The properties of this precoder, along with several extensions have been studied by <ref type="bibr">Ketchum [14]</ref>, <ref type="bibr">Forney and Calderbank [15]</ref>, and Calderbank and Mazo [161; recently Eyuboglu and Forney developed a ''trellis precoder" that can provide substantial shaping gain and also does not sustain the power loss problem of Tomlinson precoding at low rates <ref type="bibr">[17]</ref>, <ref type="bibr">[18], [191.</ref> All of these papers however, do not explicitly optimize the bandwidth usage as suggested by Price in his paper on the efficiency of the DFE [SI; some assume operation at a sufficiently high SNR such that the optimal bandwidth derived by Price includes the entire channel bandwidth. We shall not pursue these approaches except to use the Tomlinson precorded system and the ideal DFE, without optimizing bandwidth usage, as a benchmark for comparison with the vector coding methods. Instead we focus on a linear technique, and study the joint design of (linear) equalization and coding.</p><p>We present a specific method for combining equalization and coding, herein called "vector coding," which can 0018-9448/90/0700-0741$01.00 01990 IEEE be applied to any additive white Gaussian noise channel with a finite length pulse response.' We find that the combination of equalization and coding can lead to as efficient a utilization of channel capacity for channels with ISI, as is possible on the ISI-free channel with the coset codes of [ 11-[7]. The performance advantage provided by vector coding depends on the channel characteristic, and increases with the severity of the ISI.</p><p>Our approach is based on a linear partitioning of the channel into ISI-free subchannels. This partitioning can be seen as a generalization and optimization of "multitone" methods traceable back to at least 1964 <ref type="bibr">(Holsinger [21]</ref>). The multitone method partitions the channel into a set of independent frequency bands, each with its own carrier or "tone." <ref type="bibr">Researchers [22]</ref>- <ref type="bibr">[26]</ref> have studied approximations to the ideal multitone system using subchannels that overlap in the frequency domain, and multitone methods have found applications in commercial modems <ref type="bibr">[27]</ref>, <ref type="bibr">[28]</ref>. This body of work does not optimize the choice of channel partitioning to create the multichannel system. Our paper optimizes the channel partitioning technique and develops important results applicable to the use of coset codes over parallel independent channels2 Our analysis of the resulting technique easily extends to the limiting case of an infinite number of infinitesimally narrow subchannels, where it parallels the techniques used to compute channel capacity on spectrally shaped channels <ref type="bibr">(Holsinger [311,</ref><ref type="bibr">Gallager [321)</ref>.</p><p>Following this introduction, in Section 11, we examine the Tomlinson precoding based approach and show that although it is efficient for M-level PAM signaling when M is large, it can be improved for systems operating at smaller M. We motivate the development of our technique using capacity plots for the IS1 channel.</p><p>In Section 111, we present a transform domain approach called "vector coding," which partitions the IS1 channel into a set of parallel independent subchannels, on which we use ISI-free signaling. The optimal finite length modulator consists of a set of transmit filters or "vectors" that are the eigenvectors of the "Nth" order channel autocorrelation matrix. Good coset codes are then applied to the resultant ISI-free subchannels, whose gains are the corresponding eigenvalues. The efficiency of this linear method in dealing with IS1 with a minimal loss of channel capacity is illustrated by the capacity plots. We present a simple example for the (1 -0 ) channel. Although no physical channel exactly matches the (1 -0 ) partial response, we use this response in our examples to illustrate the ideas as simply as possible. The partition technique can easily be extended to general IS1 channels.</p><p>In Section IV, we derive the optimal distribution of energy and the corresponding allocation of bits (including any redundant bits required by the applied coset code) between the subchannels obtained by the partitioning. The derivation uses a generalization of the "continuous" approximation [2] that relates energy to bits in a signal constellation for the case of parallel independent channels with unequal gains. Through this approach the vector coding solution to the combined equalization and coding problem separates into two (nearly) independent parts: channel partitioning into independent subchannels and energy/bit allocation. We then calculate coding gains obtained with the vector coding technique for some examples that use lattice based coset codes.</p><p>In Section V, we calculate coding gain limits for infinite block length systems at various bits/T. We show that although the coding gain decreases as the bit rate increases, it never drops below the gain of the precoded (or decision feedback equalized) system operating at rate 1/T. Furthermore we show that as the block length increases, coset codes with vector coding achieve nearly the same coding gains on channels with IS1 as on channels without ISI. We derive a formula for the coding gain of the vector coded system for any applied code and any partial response characteristic. This gain can be separated into two components, the gain of the equalization implicit in the channel partitioning and the gain of the code applied on the subchannels. The formula suggests that the system is approximately equivalent to an ideal3 zeroforcing decision feedback equalized (DFE) system operating at an optimized rate over a part of the channel bandwidth for channels with spectral nulls only at the band edges. This relationship between a vector coded system and a DFE at a lower signaling rate is similar to the relationship between the multitone system and the single tone DFE system that Kalet and <ref type="bibr">Zervos [lo]</ref> derive in the context of high SNR and QAM constellations.</p><p>We finally distinguish this paper from recent work of others <ref type="bibr">[33]-[35]</ref> that studies a similar problem with the additional constraint of a bipolar channel input, such as encountered in saturation recording systems which trade data rate for coding gain on any particular (fixed) partial response channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">CAPACITY WITH PRECODING O R DECISION FEEDBACK EQUALIZATION</head><p>Both <ref type="bibr">Ketchum [14]</ref> and <ref type="bibr">Forney and Calderbank [15]</ref> propose multilevel coding schemes for the (1 -D ) chan- U k = y k mod M . The precoded channel operates on the residue system defined by the mod operation. Note that the mod operation in the decoder discards information about the channel state. Let A. denote the distance between adjacent points in a uniformly spaced one dimensional signal constellation. In the system illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, selecting the ak from this constellation will (ignoring noise) preserve A() at the output of the mod operator in the receiver. In this sense, the precoded system is similar to an ISI-free channel. However, because of the ll/h(,l scaling factor, the precoded channel requires [l/h012 as much input power as the ISI-free channel requires. If the decoder ignores the channel state, the precoded system input and output alphabets are the line segment</p><formula xml:id="formula_0">[ -M / 2 , M / 2 ] .</formula><p>The noise in this system is white with a Gaussian probability density function that is mapped into the output alphabet using the mod M operation. The noise processed by the mode operation remains approximately Gaussian, and the accuracy of the approximation increases as the variance of the noise decreases relative to M . With this approximation, and an additional assumption that E[ a k ] equals E[Xk], we can use Shannon's capacity formula to show that the capacity of the precoded normalized ( 1 -D ) channel is 0.5 log, ( 1 + SNR/2). The SNR is halved because twice as much input power (since l / h i equals 2) is needed on this system as is needed on the flat channel, to attain the same A(). In this computation of capacity, SNR denotes the ratio of average signal power measured at the channel input, to the noise power measured at the re-ceiver input. The channel normalization assumes time scaling such that the unit delay D represents a delay of one second, and that the amplitude response is scaled such that the power gain of the channel is unity.</p><p>Fig. <ref type="figure" target="#fig_2">2</ref> shows a partial response channel with a zeroforcing decision feedback equalizer (DFE) at rate 1/T. The DFE cancels all IS1 if the decisions fed back are correct. Because the decision feedback subtracts signal power from each received pulse, the DFE also reduces A" by a factor of ll/hOl. The capacity of the channel cascaded with a DFE can be represented (ignoring feedback errors) by the formula used to compute the capacity of the precoded system. The reader should note that the same channel parameter ho determines the performance of both the DFE based system and the precoder based system subject to the assumptions stated earlier. From here on, references to the performance of precoded systems may also be considered to apply to systems with a zero-forcing DFE. For convenience, we will use the term symbol-by-symbol detection (SSD) to refer to both the precoded system (with no trellis code), and the system with an ideal zero-forcing DFE.  In Fig. <ref type="figure">3</ref> we plot the capacity of the normalized (1 -D ) channel and also the computed capacity of the precoded channel. At high SNR the two curves converge4; see Appendix A.l for a proof of convergence. The convergence in capacities for the channel and SSD at high SNR justifies using precoding or decision feedback equalization at high bits/T (for a fixed TI. Price [8] noted this convergence earlier for strictly bandlimited channels, and Eyuboglu [9] recently reemphasized it to justify using a decision feedback equalizer on channels with IS1 and sharp rolloffs. This convergence also justifies the result in [15, 91 that only marginal improvement can be obtained over systems that use precoding (and decode withcut channel state information) or decision feedback equalization for large M (M-level signaling), assuming that the signaling rate is held constant.</p><p>Signal-IoNolse Ratio in dB Fig. <ref type="figure">3</ref>. Capacity: Normalized (1 -D). <ref type="bibr">Forney and Calderbank [15]</ref> show that trellis codes developed for ISI-free channels can be applied to the precoded channel. Their results encompass Ketchum's [14] approach, so we borrow from their terminology and refer to the precoder based technique by the phrase "Trellis coding with coset precoding" (TCP). Others, including Eyuboglu [9], apply trellis codes with decision feedback equalizers. We refer to the use of trellis codes with zero-forcing decision feedback equalization as TCDFE. The capacity based arguments developed about SSD carry over to TCP and TCDFE. Fig. <ref type="figure">3</ref> shows that at low SNR, the (1 -D) channel capacity curve lies significantly (about 2 dB at an SNR of 10 dB) to the left of the capacity curve of a precoder based system that uses a receiver that ignores channel state. This gap is much larger on some of the other channels that we consider later. This suggests that at low 4For a general impulse response, the convergence requires that no channel zeros lie outside the unit circle in the Z-plane. This is not a severe restriction since an all pass network (whitened matched filter) can be used to move channel zeros that lie outside the unit circle and place them within the unit circle.</p><p>bits/T, we can improve on the precoding. To do so, we must develop an alternative preprocessor that still permits the use of codes designed for ISI-free channels. The capacity of the system with this preprocessor should be higher than the capacity of SSD, and should come very close to the channel capacity. The same technique used to compute the channel capacity (i.e., Gallager's "water filling" technique [321) suggests that we try partitioning the channel. If we do partition the channel into an infinite number of infinitesimally narrow subchannels, each subchannel can be considered essentially ISI-free, and we will attain the channel capacity. In the next section, we will show how a finite partitioning gives us an alternative preprocessor which removes IS1 with a minimal loss in the capacity of the channel being partitioned.</p><p>In this paper, we consider discrete channel responses of the form (1 -0 x 1 + DIk for k = 2,3,4 in addition to the  </p><formula xml:id="formula_1">(1 -0 ) channel considered</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">0</head><p>Signal-to-Noise Ratio in dB Fig. <ref type="figure">4</ref>.</p><formula xml:id="formula_2">Capacity: Normalized (1 -0 x 1 + D)3.</formula><p>It is possible for the capacity of a scalar DFE system to equal the channel capacity by adding transmitter bandwidth optimization as discussed in detail in [37]. The DFE must be significantly altered by appending a set of filters that depend on the channel SNR. The vector coding methods present an alternative means of transmitter bandwidth optimization that also reaches the channel</p><formula xml:id="formula_3">Shaping filters 1 0 c = -0 a 0 745 Matchcd fillers 1 -1 0 0 0 1 -1 0 - 0 0 1 -1 ao -I SI a = .</formula><p>aN capacity result as the block length of the vector code increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">CONSTRUCTION OF PARALLEL INDEPENDENT CHANNELS</head><p>We begin by describing how to partition a partial response channel into parallel subchannels. Later, in Section III-B, we show that the aggregate capacity of the partitioned system obtained by this technique exceeds the capacity of the precoded system for a range of SNR's. As an illustrative example, in Section III-C, we apply a simple 16-state four-dimensional code to the normalized (1 -D) channel using the channel partitioning technique developed in Section III-A. We will compute the gain of this code over the uncoded ISI-free channel and show that it exceeds the gain obtained by trellis coding (using the same code) with coset precoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Construction Procedure</head><p>We will describe how to partition ,a partial response channel with unit sample response h = ( h o h , h , 1 . h / ) . Fig. <ref type="figure" target="#fig_4">5</ref> illustrates the basic approach. The partition is determined by the choice of the pulse shaping vectors, io, F',; . e, FN-, and the filtering vectors at the receiver, m',,, 6 , ; . ., r n N -/ . The channel input is a linear superposition of the outputs of the pulse shaping filters. The output of the ith pulse shaping filter is given by the corresponding pulse shaping vector &lt; scaled by a , (the input to the ith subchannel). At the receiver, each receive filter computes the inner product of the received vector with the vector m', corresponding to that subchannel. For brevity of notation, the pulse shaping vectors &lt; are specified as the rows of a pulse shaping matrix R and the filtering vectors m', are specified as the rows of the matched filter matrix M . In general, M is an orthogonal matrix so noise samples taken every NT at the output of the matched filters are independent, white, and of equal variance when the noise at the input to the receiver is assumed white. We will show that the rows of an optimal R are left eigenvectors of CC' where C,, = h,-,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Dealing with ISI:</head><p>We consider channels with zeros on the unit circle in the Z-plane. For such channels, exact cancellation of IS1 can be achieved using either a) decision feedback equalization, or b) sending zeros after each symbol (zero stuffing). For simplicity of presentation in This choice of Q defines the partitioning of the channel into parallel independent subchannels. The channel power gains are the reciprocals of the eigenvalues of X . The new input vectors are the rows of QR, which are orthogonal to each other since QRR'Q' = AQQ' = AZ. A is a diagonal matrix whose diagonal entries are eigenvalues of RR'. For convenience, we denote QR by P . The output vectors corresponding to P are given by QM, and we denote these as B. The reader is reminded that PCB' is equal to z.</p><formula xml:id="formula_4">M = 0.</formula><p>The rows of P are shown to be left eigenvectors of CC' in Appendix B. <ref type="bibr">Lechleider [41]</ref> arrives at essentially the same partitioning scheme in the context of a decision feedback equalizer by maximizing the SNR on each subchannel, and Malvar and Staelin [42] derive a similar result in the context of correlated input signals and an</p><p>In the following section, we see that the capacity of the partitioned system of parallel channels increases as N increases. This suggests that we should use large block lengths. However, the real time computational burden involved in multiplying the received vectors by M' increases proportionally to N. We can increase N if we reduce the computation required for a given N . For example, we could choose a suboptimal Q such that B is a submatrix of the fast Hartley transform matrix.' To illustrate this in the context of the (1 -D) channel with N equal to six, we could choose Q such that M i , is propor-'Suggested to the authors by our colleague, Paul Fortier. tional to ( c o s ( ~' T T ~~/ ~) + sin(2rij/6)). The inner products of the received vector with the rows of this matrix gives us all but the DC term in the discrete Hartley transform of the received vector. Hence, instead of a matrix multiplication at the receiver, we must only compute the discrete Hartley transform. Fast algorithms for the discrete Hartley transform require computations proportional to N log N <ref type="bibr">[43]</ref>. An alternative approach to simplifying computational requirements at the receiver, which uses the discrete Fourier transform, is discussed in [301.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Capacity of the Partitioned Channel</head><p>We now examine the capacity of the partitioned system, which consists of parallel independent ISI-free channels, and compare it to the channel capacity. Such a comparison will show the capacity loss incurred while removing IS1 by the partitioning technique we have outlined. A partial response channel's capacity is computed using the "water filling" construction <ref type="bibr">[32]</ref>. We compute the capacity of the system of parallel channels using the "discrete water filling" construction [321. Note that each subchan-ne1 is constrained to 1%-free transmission; thus the aggregate capacity of the parallel channels falls short of the capacity of the original channel. Fig. <ref type="figure">6</ref> shows the capacities for the normalized (1 -D) channel, and Fig. <ref type="figure">7</ref> shows the capacities for the normalized (1 -0x1 + DI3 channel. The capacities are plotted as a function of SNR assuming a normalized bandwidth of 0.5 Hz, and the SNR is computed as the ratio of average signal power at the channel input to the noise power at the receiver input. The capacity curves for the partitioned system are parameterized by the block length N . Let us now examine the SNRs corresponding to a given bits/ T for all three curves on a plot. We see that at low bits/T, the SNR required by the partitioned system is only slightly greater than that indicated by the channel capacity curve. The corresponding SNR required by the precoded system is significantly larger. On the (1 -D ) channel, the precoded system requires 1.5 dB more SNR than the partitioned system to achieve a capacity of lbit/ T. This difference translates directly into lower coding gain for the precoded system. Fig. <ref type="figure">7</ref> indicates that for the normalized (1 -DI(1-t DI3 channel, partitioning offers a larger (5 dB) advantage over precoding at a capacity of lbit/T. The advantage also persists for higher bits/ T on this channel than it does on the (1 -D ) channel. The perceptive reader may note that the capacity of the precoded system may be improved if the sampling rate of the discrete time channel is optimized for each SNR. This suggests that the sampling rate chosen to convert a continuous time channel to a discrete time channel should be optimized based on operating SNR. Our analysis in Section V bears out the importance of the sampling rate, which is a factor not given adequate emphasis in <ref type="bibr">[15]</ref>, <ref type="bibr">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Example for the (1 -D ) Channel</head><p>We now illustrate the use of a multidimensional trellis code on a partitioned (1 -D ) channel. The application of the code relies on the partitioning technique that we have developed in the preceeding sections. The code we use is very similar to Wei's 16-state four-dimensional (4-D) code described in [3, <ref type="bibr">Fig. 71 and [6,</ref>, except in selecting the signal points from the underlying lattice. A few details of this code are presented in Appendix C. More complex coset codes [6] could be used here to achieve higher gains. Each row of B is a discrete "matched filter" at the channel output for a pulse given by the corresponding row of P . It can be verified that B and P are orthogonal matrices and that PCB' = 1. Thus the structure illustrated by appending a zero.</p><formula xml:id="formula_5">1 1 1 1 \ 3 1 1 1 1 3 1 1 1 1 3 1 3 3 1 1 ' 3 1 3 1 1 3 3 1</formula><p>The input n' produces the 6-D row vector y' at the channel output. For the normalized (1 -0) channel, yI = ( x , -x,-,)/fi.</p><p>The channel memory is assumed to be zero initially. The channel memory will always be zero at the beginning of a block because x5, the last component of x', equals zero. The symbol rate on each of the subchannels equals 1/(6T) to ensure no interference between yccessive a's. In the absence of noise, the 4-D vector a^ obtained from the received vector y' by postmultiplication with B' will exactly equal the 4-D vector a' since PCB' = I .</p><p>Input Signal Constellation: An uncoded pulse amplitude modulation (PAM) system operating over an ISI-free channel at 1 bit/T will transmit 6 information bits in a period of 6T. To maintain the same information bit rate in the coded system on the partial response channel, we must send at least 6 information bits per block. Since the trellis code chosen doubles the number of signal points to get the redundancy required to provide the gain, we need 27 signal points in the input constellation. In the domain of Z, these 27 4-D points can be obtained by permuting the signs of the elements of each row of</p><p>We use a 4-D encoder to encode the 6 information bits, selecting one of the 27 available input signals once every 6T. Each signal point is translated into a sequence of 5</p><p>inputs by multiplying by P . We append a zero to this input sequence and apply it to the channel. See Fig. <ref type="figure">9</ref> for a block diagram of the coded system. very quickly to 1.5 dB as the constellation size increases A. Coset Coding Method beyond 16:A 4-D Code consequently has 1.5 dB less gain at lbit/ T than it can provide at high bits/ T. Because the vector coded system discards some subchannels, the remaining subchannels operate with larger 4-D constellations than the constellations used in the baseline system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Gain</head><p>We would also like to point out that the performance of trellis coding with coset precoding may be improved by retaining information on the channel state, however the complexity of using this channel state information is strongly dependent on the specific channel response as well as the code trellis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. APPLICATION OF COSET CODES TO PARTIAL RESPONSE CHANNELS</head><p>In the previous section, we described how to divide the partial response channels into parallel, independent channels. In this section we analyze one method to apply multidimensional coset codes to the partitioned partial response channel. Section IV-A describes how to combine a coset code with the vectors that partition the channel. Section IV-B establishes the figure of merit by which we measure the new system's performance and determine how best to use the partitioned channel. In Section IV-C-IV-E we derive the optimal allocation of input signal power among the ISI-free subchannels. Sections IV-F-IV-G apply the results to example partial response channels, confirming the coding gain improvements expected for vector coding.</p><p>The example in Section III-C illustrated the application of a 4-D code using four pulse shaping vectors. In that example, the dimension of the code word equaled the number of pulse shaping vectors used, so we could send one code word per block symbol. If we increase the number of pulse shaping vectors used, we may not choose to increase the dimension of the code; good codes are not available for all dimensions, and the increased complexity of a higher-dimensional code may not prove acceptable.</p><p>Fig. <ref type="figure" target="#fig_10">10</ref> illustrates how to combine a 4-D code with eight pulse shaping vectors on the (1 -0 ) partial response channel. Essentially two 4-D codes are sent and received in parallel. Note that the block symbol extends over a period of 12T. To transmit one information bit/T, the coded system must send twelve information bits in a period of 12T; thus twelve bits enter the encoder in one block symbol period. As shown in Section IV-F, the optimization procedure determines that eight of the eleven available pulse shaping vectors should be used for coding. We divide the vectors into two groups and modulate each group by 4-D signal points. The two 4-D trellis codes add two redundancy bits per 12T, thereby increasing the total number of coded bits to fourteen bits in a period of 12T. The optimal allocation requires one signal set to contain 256 points (8 bits) and the other signal set 64 points (6 bits). Because the 4-D coset code divides the Z4 lattice into sixteen cosets, in the first code each coset will contain sixteen points (4 bits), while in the second code, each coset will contain four points (2 bits). The signal points B. Figure ofMen't chosen from these coseis by the encoder then modulate the pulse shaping vectors. We can extend this technique to any number of pulse shaping vectors by dividing the vectors into more groups. In general, consider the application of a d-dimensional code to a system using block symbols of length N . If the channel's unit sample remonse extends for 1 + 1 samples We compare this new technique against an uncoded PAM system transmitting over an ISI-free channel. Because we normalize the channel impulse response to unity, we effectively compare the coded system to the one-shot matched filter bound (MFB). Our figure of merit of coding gain is defined as then the channel partitioning procedure creates N -1 d 2 . /' coded ' 0 /' ""coded pulse shaping vectors, each of length N . Modulate M of 10log,,, ( ) . We assume the same additive noise power per dimension for the coded system and the uncoded system, so average input power replaces SNR in the usual coding gain formula, For trellis code gain calculations, we set the mini- mum distance between the closest received signal points in both the uncoded and coded systems to be the same, herein labeled A,. On a noiseless ISI-free channel, the input and output constellations are identical; thus the closest signal points in the input PAM constellation are separated by A, units as well. The uncoded system will require the following average power per symbol block of length N as measured at the channel input</p><formula xml:id="formula_6">22h -1 Puncoded = ( 1 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>w.</head><p>The average power of the coded system, as measured at the channel input, depends on the norm of the pulse shaping vectors used and the number of signal points in each d-dimensional signal set that modulates them. Recall that, by construction, vector coding guaranteed that the input constellation, as seen at the input to the vector preprocessor, and the output constellation, as seen after the matched filter postprocessor, are identical except for the additive noise (because PCB' = I). Because we separate the closest points in the output constellation by A. units, the closest points in the input constellation are also separated by A,. In the next two sections we derive a simple method to approximate the average coded power needed, as measured at the channel input. Finally, the coset code guarantees an increase in the minimum distance between received signal sequences such that d,&amp; = 6 A;.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Signal Point Selection</head><p>To transmit at an information bit rate of b bits/T, a vector coded system using a d-dimensional code with block symbols of length N must transmit Nb information bits per block symbol. M / d concatenated code words per block add M / d redundancy bits to each block for a total of Nb + M / d coded bits per block. These bits are divided among the M pulse shaping vectors by selecting the signal constellations, whose signal points modulate each group of d pulse shaping vectors.</p><p>The signal points are chosen from the lattice A of the coset code. For the coset code used in our example, the signal points are chosen from the Z4 lattice shifted by (1/2,1/2,1/2,1/2), i.e., a translate of A that is symmetric about the origin but does not include the origin. The signal sets together must contain enough points to carry the coded information and redundancy bits. On an ISI-free channel, all pulse shaping vectors would have equal power; in this case, one would then choose identical spherical signal constellations.</p><p>For partial response channels, the pulse shaping vectors require unequal power l l Z.11' to achieve the same A.</p><p>in each dimension at the channel output. The signal constellations may no longer be spherical or identical, and they must be chosen to minimize the channel input power.</p><p>The number of signal points in a constellation depends on the amount of signal power allocated to that signal set;</p><p>Section IV-E explains how to allocate the power. To calculate the average signal power of a signal constellation, as measured at the channel input, we consider the input lattice to be stretched in the ith dimension by the norm ll&amp;ll of the ith vector. We then choose the n signal points closest to the origin on this scaled lattice. The signal points define a 4-D sphere on the scaled lattice, but on the unscaled lattice, they define a 4-D ellipsoid. Fig. <ref type="figure" target="#fig_0">11</ref> illustrates these principles for a 2-D lattice.</p><p>To ensure the coset partition A/A' correctly carries over to vector coding, we also require the d-dimensional signal sets to be symmetric about the axes in each dimension. For a small signal set, one can exactly determine the lowest average energy points by a computer search, as was done for the example in Section 111-C, but for large signal sets, the brute force approach becomes computationally infeasible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Signal Set Approximation</head><p>To optimize the distribution of power among the subchannels, we need a formula linking power to the number of points in a constellation. We can approximate the average power in an optimal, i.e., lowest average energy, d-dimensional signal set whose points lie on the Zd lattice, the lattice A for the coset codes considered in this .</p><formula xml:id="formula_7">average energy = ad n n llZll i i = o )</formula><p>For the Z 2 , Z4, Z', and Z'' lattices, ad = 0.1592, 0.3001, 0.5636 and 1.4017, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Coding Gain Maximization (Input Signal Power Minimization)</head><p>Using the power approximation, we derive a formula for the maximum attainable coding gain. The maximization reveals how to divide the power, or equivalently the bits, among the subchannels. For a single group of d pulse shaping vectors, modulated by a d-dimensional signal set of n points chosen from the Z d lattice, the least average power, as measured at the channel input, equals single group coded power = ad For a coded system using M / d groups of pulse shaping vectors the average signal power equals</p><formula xml:id="formula_8">M / d -1 d -1 2/ d total coded power = c adin; J n = 0 l l ~~+ j l l ) i = o</formula><p>where ni equals the number of points in the d-dimensional signal set assigned to the vectors with powers</p><p>The coding gain maximization problem can be stated as a nonlinear programming minimization of the coded input power l l Zd1I2 through IIZd+(d-1)112.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M log, ni</head><formula xml:id="formula_9">= Nb + - d M / d -1 subject to i = O log, ni 2 0, V i .</formula><p>The equality constraint ensures that the coded signal sets contain sufficient points to carry the coded bits. The inequality constraint disallows signal sets with "negative" bits. We assume the number of signals ni in a signal set to be continuous for the nonlinear programming optimization, although, actual ni must be integers. Using a coset code further restricts the integers. Thus these calculated optimal gains differ slightly from gains obtainable with implementable codes. For actual codes, one would perform an integer programming search for a suboptimal solution in the local neighborhood of the optimal distribution derived from the minimization procedure. We find the optimal distribution of input signal energy assuming M vectors are used. The best M is easily found by exhaustive search. Start from M = d, and assume all of the inequality constraints are inactive, i.e., ni &gt; 1, for all i.</p><p>Then use the Kuhn-Tucker conditions, as detailed in Appendix D, to find the minimum solution. The number of points in each signal set correlated with the norm of the pulse shaping vectors, which the signal set modulates. Within the accuracy of the continuous approximation, each group of vectors used is allocated the same average power as measured at the channel input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Example for the (1 -0) Channel</head><p>To illustrate the use of the previously derived formulas, let us calculate the coding gain when using block symbols of length 12: block length N = 12 number vectors used M = 8 information bit rate b = 1 signal set dimension d = 4.</p><p>The powers of the vectors used, ll&amp;'0112 through 11$7112, equal 0.5087, 0.5359, 0.5858, 0.6667, 0.7944, 1.000, 1.349, and 2.000, respectively. We thus calculate c = 88.47 number of points in signal set 1, n , = 271.1 (256) number of points in signal set 2,n, = 60.43(64) total uncoded power, Puncoded = 3.00. Therefore, moves the trailing IS1 from all previous input symbols so -.</p><p>-</p><p>that y , = h,,x,. We assume for analytic simplicity that the DFE experiences no feedback error propagation from the coding gain = 10 log (2.09) = 3.26 dB (3.26).</p><p>The numbers in parentheses indicate the gains for the nearest suboptimal integer power of two to the optimal signal set values. Within the accuracy of the average power approximation, we see that actual implementable codes differ only slightly, if at all, from the calculations given.</p><p>Fig. <ref type="figure" target="#fig_2">12</ref> illustrates the optimal coding gains for the normalized (1-D ) channel using the 16-state 4-D code up to block length 100. The dashed horizontal line indicates the asymptotic (high bits/ T ) coding gain that trellis coding with coset precoding (TCP) [151 or trellis coding with decision feedback equalization (TCDFE) would achieve using the same code on the same channel. We observe the following. noisy data symbols. This ideal cascaded channel and DFE system then acts simply as an ISI-free channel scaled by the first tap of the channel response. Without a code the DFE or TCP system reaches the performance of the symbol by symbol detection (SSD) scheme. With a code the TCDFE or TCP systems achieve exactly the gain of the coset code at the appropriate throughput rate (bits/ T ) as calculated in Appendix C. For 1 and 2 bits/T, the vector coded system, using block symbols of moderate length, provides better coding gain than the precoded system. As discussed in Section V a precoded system can approach the same performance (ideally) as the vector coded system if the signaling rate is optimized.</p><p>Coding gain increases to an asymptotic value as the G. Examples for the (1 -D)(I + D)k Channels block length N increases.</p><p>For fixed block length, coding gain decreases as the bits/ T increases. The asymptotic coding gain for long block length also decreases as the bits/ T increases.</p><p>As both bits/ T and block length increase, coding gain approaches a limiting value.</p><p>Table I details information for several points from Fig. <ref type="figure" target="#fig_2">12</ref> for the (1 -D) channel. We include the coding gain over symbol by symbol detection (SSD), as well as the coding gain using TCP or TCDFE. TCP indicates the coding gains when combining an ideal Tomlinson precoder or an ideal decision feedback equalizer with the four-dimensional 16-state Wei code. The ideal precoder correlates the data symbols that enter the channel such that an output symbol of the channel at time k depends only on the corresponding input at time k . We assume no power amplification at channel nulls due to the precoding feedback. Similarly an ideal decision feedback equalizer re- Figs. <ref type="bibr" target="#b12">13,</ref><ref type="bibr">14</ref>, and 15 illustrate coding gains for the family of normalized (1 -0 x 1 + DIk channels for k = 2, 3, and 4. Note that at relatively short block lengths the vector coded system exceeds the coding gain expected for the precoded channel. We will show in Section V that at high bits/T, the vector coding gain for long block length converges from above to the same coding gain as TCP.</p><p>Examining Figs. 12-15 more closely, we notice that, for a given number of bits/T, the coding gain peaks at regular intervals. To explain this behavior, we plot in Fig. <ref type="figure" target="#fig_0">16</ref> the ratio of vectors used (MI to block length ( N I for the (1 -D ) channel. For one bit/T, the coding gain peaks when M / N equals 2/3, and even for very long block lengths, only this fraction of the vectors are used.</p><p>Moreover, this fraction correlates with the use of the channel bandwidth. Fig. <ref type="figure" target="#fig_0">17</ref> illustrates the time average power spectra of the vector coded channel input for several different block lengths at one bit/ T on the (1 -D ) channel. Comparing this plot with the squared channel transfer function, as shown in Fig. <ref type="figure" target="#fig_8">18</ref>, we see that vector coding concentrates the input spectrum into portions of the channel with superior transfer characteristics. Asymptotically, for very long block length, vector coding would concentrate all of the coded energy into 2/3 of the bandwidth. Fig. <ref type="figure" target="#fig_0">19</ref> plots the scaled fourier transforms of the length 18 eigenvectors for the (1 -0 ) channel. The eigenvector with the largest eigenvalue peaks at the Nyquist frequency, where the (1 -D ) channel power spectrum also peaks. To maximize the throughput while minimizing the input power, vector coding begins by using only the eigenvectors with largest eigenvalue, which directly corresponds to regions of the frequency domain with maximum power transfer. In Section V we invoke the eigenvalue Toeplitz distribution theorem to show that the optimal choice of eigenvectors corresponds to choosing an optimal region of bandwidth in which to transmit the coded energy. Table <ref type="table">I1</ref> tabulates several coding gains for the (1 -0 x 1 + 0)' channel. As shown in Figs. <ref type="figure" target="#fig_2">20</ref> and<ref type="figure"></ref> 21, the vector coding also shifts the input spectrum for  the (1 -OX1 + channel. As expected from the capacity plots, vector coding provides even greater improvement over SSD or precoding on this channel. The vector coding gains in Tables <ref type="table">I</ref> and<ref type="table">I1</ref> may seem high, but actually vector coding performs nearly as well on the partial response channels as on the flat channel. Assuming a decoding error probability of we can calculate the average input signal power required to sustain a given bit rate (equivalently bits/T because we fix the signaling rate) using a particular code. Similarly we know the signal power at which capacity achieves the same bit rate. between capacity and vector coding using the 16-state 4-D code on both the ISI-free flat channel and two of the partial response channels considered. Vector coding approaches approximately the same asymptotic distance from capacity on all of the channels considered. At 1 bit/T vector coding on a flat channel performs more poorly because the power penalty for doubling the signal set size asymptotically nears 1.5 dB for large signal sets but equals 3.0 dB at 1 bit/T. In the next section we consider the following questions.</p><p>1) Why does the maximum coding gain decrease, even for very long block length, as bits/ T increases? 2) What is the coding gain for infinite block length, given bits/ T? 3) What is the coding gain for infinite block length and infinite bits/ T? 4) How does the coding gain for the precoding and decision feedback systems compare with the coding gains of vector coding?</p><p>V. CODING GAIN BOUNDS</p><p>The capacity plots in Section 111-B indicated that appreciable gain over the precoding technique could be achieved at practical SNR, and the coding gain graphs in Section IV confirmed that vector coding provides an improvement in gain. As proven in Appendix A, the capacity curves for a partial response channel and for a precoded channel converge as SNR -m, assuming the sampling rate is fixed. In this section, we show that for very long block length, the vector coding gain approaches from the same asymptotic value at high bits/T as the precoded system for a fixed sampling rate.</p><p>We shall derive coding gain bounds for vector coding when the block length N increases, as well as when bits/T increases. As derived in Section IV, for a fixed block length N 22h -1</p><formula xml:id="formula_10">Puncoded = N A ? 1 ( 7 )</formula><p>where M is previously defined. For a given information bit rate, b bits/T, define M limp = M,N-.m N where p equals the ratio of vectors used to block length at infinite block length. Because the power spectrum of each pulse shaping vector narrows about a single frequency as its block length increases, this ratio also equals the fraction of bandwidth used. Using the fundamental eigenvalue distribution theorem of Szego A pulse shaping vector with smaller norm requires less power to transmit the same information, so we use the best pulse shaping vectors first. In fact, when we use M pulse shaping vectors, we choose those with norms less than or equal to llZM-I(). Thus The region of integration R determines the part of the channel bandwidth used. The coding gain consists of two terms. The first term depends on the trellis code, the signal set, and the channel transfer characteristic. The channel, however, affects this term only in determining p for a particular bits/ T. The second term only depends on the channel. Equation ( <ref type="formula">7</ref>) in Appendix A shows that the second term equals the precoding (or zero-forcing DFE) loss of the channel when the region of integration R covers the whole bandwidth.</p><p>When R denotes a fully connected subset of the channel bandwidth, we can use (7) to interpret the second term in (1) as the precoding (or zero-forcing DFE) loss of a modified channel. The modified channel is formed by zeroing H(f) for all f e R and cascading it with an all pass filter that converts it into a minimum phase channel. This modified channel operates at a signalling rate of p / T . The decrease in signaling rate requires an increase in bits/T to maintain the bit rate through the channel. The effect of this increase in per symbol bit rate is reflected in the 2 b / p term in the first term in (1). Hence we see that the gain of the vector coded system will be approximately equal to the gain of a precoded system (or DFE based system) operating at rate p / T cascaded with a trellis code. This corresponds to the result obtained by <ref type="bibr">Kalet and Zervos [lo]</ref> in the context of multitone systems with no trellis code.</p><p>The reader should note that the equivalence of vector coding and the DFE at rate p / T assumes that the decisions fed back in the DFE are always correct. While this may be a reasonable assumption for an uncoded system, it is inaccurate for systems cascaded with high gain trellis codes. Since the decisions are required without delay' for feedback, we cannot get them from the output of the Viterbi decoder for the trellis code. Hence, in a coded system, the decisions fed to the DFE will have to be made on a symbol by symbol basis and are likely to have an error rate much higher than that at the Viterbi decoder output. This is likely to degrade the performance of the DFE and the degradation will be worse for systems using more powerful trellis codes.</p><p>It is important to note that if the channel has one or more nulls subdividing the channel bandwidth, R is likely to consist of multiple unconnected sets. Note that the region of integration ll consists of those frequencies at which the power spectrum IH(f)l exceeds the variable l / x . At any finite throughput rate (or equivalently finite input energy) the optimal value for the variable x is finite.</p><p>Vector coding over a channel with intraband spectral nulls would thus exclude regions of frequencies near the nulls wherein IH(f)l&lt; l / x dividing R into two or more disjoint regions. The optimized resampled DFE uses a continuous band of frequencies and can only change the total bandwidth it uses by changing the Nyquist frequency. In this case the equivalence of vector coding to a lower rate DFE will not hold. codes perform significantly better than the Wolf-Ungerboeck codes that do no spectral shaping. When using all of the bandwidth, we see that the coding gain quickly approaches an asymptotic value from below as the information bit rate increases. Since vector coding chooses the peak from each curve, we also approach the same asymptotic coding gain, this time from above. Fig. <ref type="figure" target="#fig_2">24</ref> illustrates infinite block length coding gains for various fractions of bandwidth used for the (1 -0x1 + 0 ) ' channel.</p><p>Table <ref type="table">111</ref> contains maximum coding gains as calculated from (1) for different partial response channels when transmitting 1 bit/T. The vector coding gains over SSD increase as IS1 increases, while the precoding gains remain constant.</p><p>For high bits/ T, as b -+ 03, or equivalently as SNR + 03, capacity arguments imply that all of the bandwidth must be used. Reexamining (11, we assume that the integral term is finite over any interval R, which holds if IIH(f)ll = 0 only on a set of measure zero. In this case, for high values of b , the nonintegral term in equation 1 can be  As shown in (7) in Appendix A, Thus the second term in (2) equals the same loss that precoding causes at rate 1/T.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. SUMMARY A N D CONCLUSION</head><p>We develop an alternative preprocessor that applies ISI-free codes to partial-response channels. The preprocessor uses blocks of N symbols and converts the channel into a set of parallel independent channels that use ISIfree signaling. The removal of IS1 by this preprocessor is done linearly with a minimal loss in channel capacity.</p><p>This method uses a discrete-time finite length code that optimizes the transmit spectrum. For low bits/ T , this optimization becomes important, as we illustrate by the coding gains achieved over conventional (unoptimized bandwidth) precoding. Increasing the block length increases this gain to an asymptotic value. As the bits/T increase, the coding gain drops, and the advantage of our technique over ideal symbol-by-symbol decoding based techniques decreases, as the optimal bandwidth becomes the entire Nyquist bandwidth (0,1/(2T)). For channels with longer pulse responses, the advantage of our technique persists for higher bits/ T .</p><p>We have described the procedure to convert a discrete time partial response channel into a set of parallel channels and also the optimal allocation of levels between the parallel channels. A large part of our analysis has been confined to comparing vector coding to fixed rate signaling systems. Most real channels are continuous time channels, and conversion to a discrete channel requires selection of a signaling rate. For a given information rate (bits/s), there is a tradeoff between the bits/T and the signaling rate ( l / T ) . The effect of the signaling rate needs to be examined carefully, especially in view of our results"' in Section V, which show that resampling the channel using brick-wall filters will permit ideal DFE based systems to perform approximately as well as an optimized vector coded system on some channels. In comparing vector coding to rate optimized real DFE based systems, we need accurate estimates of the performance penalties of error propagation. We also need to know the dependence of these penalties on design parameters such as decoding delay and the filters used in adjusting the rate.</p><p>Implications of finite register lengths have not been examined, nor has timing recovery been studied. Timing recovery may be especially complicated because we use block symbols which do not have uniformly spaced values in the time domain. Issues of complexity have largely a factor of l / h , , to obtain the same lattice spacing at the output of the mod decoder. This implies that the precoded channel performs (approximately) like a flat channel with SNR multiplied by a factor of hi (note that we have normalized Zh; to 1). The capacity of a band-limited channel with frequency response H(f), normalized in the frequency domain to extend to 0.5 Hz is given by [32],</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>( 3 )</p><p>The capacity of the precoded channel is approximated by <ref type="bibr">CP=O.5l~g[1+h$SNR]</ref>.</p><p>For large SNR, h i SNR can be assumed to be much larger than 1 so we have C, = 0.5 log [ h i SNR]</p><p>= log(h,,) +OSlog(SNR) which is identical to the asymptotic channel capacity as SNR -+ W.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.</head><p>Proof that P is a Left Eigencector Math of CC'</p><p>We will show that PCC', which is QRCC', can be written as DP where D is a diagonal matrix. Since Q is a left eigenvector matrix of RR' we have QRR' equal to AQ. By premultiplying by A-' we can write Q as A-'QRR', which is A-IPR'. Hence Let h , denote the normalized unit sample reyonse of the channel. The first term on the right is h,, where h , denotes the complex cepstrum <ref type="bibr">[49, (10.3311 of h,,.</ref> If the Z transform of h , has no zeros at the origin The proof is based on the existence of a region of convergence of the Z-transform of h,, that includes almost all of the unit circle [49, Chapter 101. Substituting this in (5) the asymptotic capacity for large SNR is given by C = log(h,,) +OSlog(SNR). With precoding, the channel input symbols need a minimum distance that is greater than that required by the flat channel by</p><p>2) The points are chosen to have the minimum power subject This gives us the gains listed in Table <ref type="table" target="#tab_7">V</ref>. Forney [6, Table <ref type="table" target="#tab_7">V</ref>-61 states a gain of 4.52 dB for the Wei code based on arguments about the density of the lattices' underlying the code. His technique gives the coding gain for the code for large bits/ T , and is only approximate for low bits/T. Forney also assumes that the signal points are chosen from a hypercube rather than a hypersphere. Because of this, his gain differs from our gain of 4.97 dB by 0.45 dB that is exactly the shaping gain of a 4-D sphere over a 4-D cube.</p><p>to the first requirement. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Precoded channel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Decision feedback equalizer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Parallel channels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig. 6. Capacity plots: (1 -D ) channel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig. 7. Capacity plots: ( 1 -OX1 + D)' channel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>I ) Channel Partitioning: In Fig. 8, the 4-D input vectors, a'= (aoa1a2_a3&amp; _ar:ive once every 6T. P' = (&amp;Z{$i$i),and B'=(b[,b',bib:) are obtained from the P and B derived earlier by discarding the worst subchannel. We discard the worst subchannel because it has a very high loss. The decision to discard the subchannel can be justified by the optimization explained in Section IV.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Example for (1 -D) channel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Fig. 9. Block diagram of coded system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Concatenation of two-4-D codes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>these vectors by M / d d-dimensional signal points chosen by M / d parallel d-dimensional codes. Any coset code in [6] can be adapted to this technique; however, all specific numerical examples in this paper use the same 16-state 4-D code used in Section 111-C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Fig. 11. Scaling 2-D lattices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>paper. For a d-dimensional hypersphere ( d even) of radius R, one can fit approximately n unit volume hypercubes inside[45], the axes of the shifted Zd lattice by [Ip'oll through llFdd-, 11 then this continuous approximation becomes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Note that the average power in each d-dimensional signal set is identical, average power = ad</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>total coded power, Pcoded = 5.65 (5.65) For the 16-state 4-D uncoded system A:) = 1 coded system d i i n = 4. IEEE TKANSAC'TIONS ON INFOKMATION THEOKY. VOI.. 36, NO. 4, JULY 1990</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Fig. 12. Normalized (1 -D ) channel coding gains (dB) 1-4 bits/ T.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Normalized (1 -DX1+ 0 ) ' channel coding gains (dB) 1-4 bits/ T.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>FigFig. 15 .Fig. 16 .Fig. 17 .Fig. 19 .Fig. 22 .</head><label>1516171922</label><figDesc>Fig. 15. Normalized (1 -0 x 1 + DI4 channel coding gains (dB) 1-4 bits/ T.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>We evaluate these integrals over the one-sided frequency range zero to one-half (the normalized Nyquist rate). As For the maximization over M , we implicitly order the pulse shaping vectors IIP'Oll 5 llP'lll 5 ' * 5 llP'M-111.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 23 Fig. 24 .</head><label>2324</label><figDesc>Fig.23plots coding gains for the (1 -D) channel for an infinite block length partition when transmitting one bit/ T as p varies from 0.5 to 1. As noted in Section lV, for one bit/T, the coding gain peaks when using 2 / 3 of the bandwidth. As bits/ T increases, the fraction of bandwidth used also increases. Because the precoding technique does not alter the power spectrum, one might expect precoding gains not to exceed the coding gains shown in Fig.23when all the bandwidth is used.Karabed  and Siege1 [34]  use run length constraints to shape the spectrum of codes for the ( 1 -D ) channel, and their 'Eyuboglu [91 suggests a technique for permitting limited delays in the feedback path but these require an interleaver and some modification of the branch metrics in the decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>this paper. The aforementioned problems and the tradeoff between signaling rate and bits/T re- main open for further investigation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>=</head><label></label><figDesc>PCC' = A -I PR'RCC' = A-~PR'MC' = A-'PR'MC'R'R-'= A-~PR'MM'R-' where FB is the range of f for which N ( F ) / llH(f)1I2 I B, and= A -IpR'R-' B is the solution to = K I P .A-' is the inverse of a diagonal matrix hence it is diagonal.C. The Four-Dimensional CodeWei presents a 16-state 4-D code in [3, Fig.71. His example has a coding gain of 4.66 dB with a constellation of 215 points. This gain consists of a gain of 6.02 dB from the trellis, and a loss For veq large SNR FB approaches [-0'570.51. Only Of f at which IIH(f)ll is zero are not included in FB as SNR --)O0* since of 1.36 dB due to the signal set expansion from 214 to 215 in 4-D space. This code is based on a partition of the 2 4 lattice by the for large SNR we can approximate by lfN(f)/I(ff(f)112 is finite while S is assumed to approach assume N( f 1 is flat and equals unity, we get log[lIff(f)l12SNR] df m4 lattice.partitioning as Wei's code, but selects signal points differently. The signal constellation that we use consists of points chosen from the Z4 lattice to satisfy the following two requirements. infinity. Substituting this in (31, and dropping N(f 1 since we The code we use the Same trellis and the Same lattice j-,, ~ 1% [ II ff(f &gt;Ill df + o s 1% ( S W .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>was supported in part by an IBM graduate fellowship.</figDesc><table /><note><p>IEEE Log Number 9035259.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE I NORMALIZED ( 1</head><label>I(</label><figDesc>-D) CHANNEL CODING GAINS (dB) 1-3 bits/ T</figDesc><table><row><cell></cell><cell></cell><cell>1 bit/T</cell><cell></cell><cell></cell><cell>2 bits/ T</cell><cell></cell><cell></cell><cell>3 bits/ T</cell><cell></cell></row><row><cell>Block length</cell><cell>6</cell><cell>12</cell><cell>18</cell><cell>5</cell><cell>10</cell><cell>14</cell><cell>5</cell><cell>9</cell><cell>13</cell></row><row><cell cols="10">Gain over MFB(dB) 2.83 3.27 3.41 1.38 2.15 2.38 0.09 1.35 1.66</cell></row><row><cell>Numberofvectors</cell><cell>4</cell><cell>8</cell><cell>12</cell><cell>4</cell><cell>8</cell><cell>12</cell><cell>4</cell><cell>8</cell><cell>12</cell></row><row><cell cols="10">Gain over SSD(dB) 5.84 6.28 6.42 4.39 5.16 5.39 3.10 4.36 4.67</cell></row><row><cell>TCP over SSD</cell><cell></cell><cell>3.01</cell><cell></cell><cell></cell><cell>4.72</cell><cell></cell><cell></cell><cell>4.90</cell><cell></cell></row><row><cell>4 ,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>I block length</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE I11 INFINITE BLOCK CODING GAINS (1 bit/ T ) Partial Fraction Gain Gain Overall Gain over TCP Gain Response of Bandwidth (1st term) (2nd term) Gain (dB) SSD (dB) SSD (db)</head><label>I11</label><figDesc></figDesc><table><row><cell>( I -D ) (1 -0 x 1 + D)' (1 -DM1 + D)' (1 -0 x 1 + D)4</cell><cell>0.67 0.62 0.57 0.53</cell><cell>2.47 2.10 1.61 1.30</cell><cell>1.20 1.42 1.60 1.65</cell><cell>3.67 3.52 3.21 2.95</cell><cell>6.68 9.54 13.52 17.42</cell><cell>3.01 3.01 3.01 3.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>1st term) (2nd term) Gain (dB) SSD (dB) over SSD (dB)</head><label></label><figDesc></figDesc><table><row><cell></cell><cell cols="2">TABLE IV</cell><cell></cell><cell></cell></row><row><cell cols="4">INFINITE BLOCK CODING GAINS (= bits/ T )</cell><cell></cell></row><row><cell>Gain</cell><cell>Loss</cell><cell>Overall</cell><cell>Gain over</cell><cell>TCP Gain</cell></row><row><cell>Partial Response ((1 -D ) (1 -DX1+ D)' (1 -0 x 1 + DV (1 -DXI + D)4 4.97 4.97 4.97 4.97</cell><cell>-3. C I -6.02 -10.00 -14.47</cell><cell>1.96 -1.05 -5.03 -9.50</cell><cell>4.97 4.97 4.97 4.97</cell><cell>4.97 4.97 4.97 4.97</cell></row><row><cell>approximated as</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Over the range O &lt; p i l this term is maximized when</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">p = 1. Thus at large transmission rates, as b -+m, the</cell><cell></cell><cell></cell><cell></cell></row><row><cell>coding gain simplies to</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Table IV summarizes the limiting coding gains for infinite</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">block length and infinite transmission rate for several</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">partial response channels. We see that TCP results in the</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">same gain for all the partial response channels consid-</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">ered. We can easily separate the coding gain in (2) into</cell><cell></cell><cell></cell><cell></cell></row><row><cell>two components.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">1) Coding gain from the trellis code distance increase</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">(8) and from the use of higher-dimensional signal</cell><cell></cell><cell></cell><cell></cell></row><row><cell>sets ( d / ( 1 2 ~, 2 ~/ ~) ) .</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">2) Coding gain (loss) from partial response channel</cell><cell></cell><cell></cell><cell></cell></row><row><cell>characteristics.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V CODING GAIN vs. BITS/ T</head><label>V</label><figDesc></figDesc><table><row><cell>Bits/ T</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>m</cell></row><row><cell>Gain (dB)</cell><cell>3.01</cell><cell>4.72</cell><cell>4.90</cell><cell>4.97</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>M = sc.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V l</head><p>Recognizing t h e parallels, we find t h e gradients of t h e functions f a n d h, 1 n j I n 2</p><p>Vh( n), = -</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Channel coding with multilevel/phase signals</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ungerboeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="67" />
			<date type="published" when="1982-01">Jan. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient modulation for band-limited channels</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Forney</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Longstaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Selected Areas in Commun</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1984-09">Sept. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Trellis-coded modulation with multidimensional constellations</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Four-dimensional modulation with an eight-state trellis code</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J A</forename><surname>Sloane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AT&amp;T Tech. J</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1005" to="1018" />
			<date type="published" when="1985-06">May-June 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">New trellis codes based on lattices and cosets</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="195" />
			<date type="published" when="1987-03">Mar. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coset codes I: Geometry and classification</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Forney</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1123" to="1151" />
			<date type="published" when="1988-09">Sept. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Coset codes 11: Binary lattices and related codes</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1152" to="1187" />
			<date type="published" when="1988-09">Sept. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nonlinearly feedback-equalized PAM vs. capacity for noisy filter channels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf. Commun</title>
		<imprint>
			<date type="published" when="1972-06">June 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Detection of coded modulation signals on linear, severely distorted channels using decision feedback noise prediction with interleaving</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Eyuboglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="409" />
			<date type="published" when="1988-04">Apr. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimal decision feedback equalization versus optimized orthogonal frequency division multiplexing for high-speed data transmission over the local cable network</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Zervos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kalet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Globecom &apos;89</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-06">June 1989</date>
			<biblScope unit="page" from="1080" to="1085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reduced-state sequence estimation with set partitioning and decision feedback</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Eyuboglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="20" />
			<date type="published" when="1988-01">Jan. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Decoding of TCM-encoded signals in the presence of IS1 and noise</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Chevillat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Eleftheriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. Inform. Theory &apos;88</title>
		<meeting><address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-07">June 1988. 483-501, July 1987</date>
			<biblScope unit="page" from="22" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coset codes for partial response channels; or, Coset codes with spectral nulls</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ketchum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Forney</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Calderbank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Globecom&apos;87</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1971-03">Mar. 1971. Nov. 1987. Sept. 1989</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="925" to="943" />
		</imprint>
	</monogr>
	<note>Electron. Lett.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Baseband line codes via spectral factorization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Selected Areas Commun</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Trellis precoding</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Eyuboglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Forney</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ARO Commun. Workshop</title>
		<imprint>
			<date type="published" when="1989-05">May 1989</date>
			<pubPlace>Ruidoso, NM</pubPlace>
		</imprint>
	</monogr>
	<note>I81 -, &quot;Trellis precoding. submitted to IEEE Trans. Inform. Theory</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Trellis precoding</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Symp. Inform. Theory</title>
		<imprint>
			<date type="published" when="1990-01">1990. Jan. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Vector coding for digital communication on spectrally shaped channels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kasturia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989-04">Apr. 1989</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Digital communication over fixed time-continuous channels with memory, with special applications to telephone channels</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Holsinger</surname></persName>
		</author>
		<idno>no. 430</idno>
	</analytic>
	<monogr>
		<title level="j">M.I.T. Res. Laboratory Electron</title>
		<imprint>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Synthesis of band-limited orthogonal signals for multichannel data transmission</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Sys?. Tech. J</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="275" to="296" />
			<date type="published" when="1966-12">Dec. 1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Performance of an efficient parallel data transmission system</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Saltzberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun. Technol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="805" to="811" />
			<date type="published" when="1967-12">Dec. 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Data transmission by fre-[I51 SAC-7</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Ebert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An orthogonally multiplexed QAM system using the discrete Fourier transform</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hirosaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="982" to="989" />
			<date type="published" when="1971-10">Oct. 1971. July 1981</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Commun.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Trailblazer modems: High-powered technology in a low-cost package</title>
		<author>
			<persName><forename type="first">E</forename><surname>Feig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Spier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Luhowy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in H F parallel tone modem technology,&quot; in MILCUM&apos;88</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-10">May 1989. 1988. Oct. 1988</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
	<note>IEEE Trans. Mag.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A frequency-domain approach to combined spectral shaping and coding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cioffi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICC&apos;87</title>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-06">June 1987</date>
			<biblScope unit="page" from="1711" to="1715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Frequency-specified coset codes for spectrally-constrained channels</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cioffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kasturia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">submitted to IEEE Trans. Commun.. Also Tech. report RJ</title>
		<imprint>
			<biblScope unit="volume">6161</biblScope>
			<date type="published" when="1988-03">Mar. 1988</date>
			<publisher>IBM Almaden Research Center</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Digital communication over fixed-time dispersive Channels</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Holsinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First IEEE Ann</title>
		<imprint>
			<date type="published" when="1965-06">June 1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
		<title level="m">Information Theory and Reliable Communication</title>
		<meeting><address><addrLine>New York; NY</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Trellis coding for partialresponse channels</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ungerboeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="765" to="773" />
			<date type="published" when="1986-08">Aug. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Matched spectral null trellis codes for partial response channels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Karabed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Siegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. Inform. Theory &apos;88</title>
		<meeting><address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-06">June 1988</date>
			<biblScope unit="page" from="142" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On minimum-mean-squared error decision-feedback equalizers, and the mean-square whitened matched filter</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cioffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pasupathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cioffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dudevoir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Eyuboglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Forney</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Commun</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="921" to="934" />
			<date type="published" when="1975-09">Apr. 1990. Sept. 1975. Sept. 1989</date>
			<pubPlace>Atlanta, GA</pubPlace>
		</imprint>
	</monogr>
	<note>Channel coding for binary recording with intersymbol interference. in preparation for submission to IEEE Trans. Commun.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Vector coding with decision feedback equalization for partial response channels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kasturia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cioffi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Globecom&apos;88</title>
		<meeting>Globecom&apos;88<address><addrLine>Hollywood, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-12">Dec. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spectrally constrained codes for the high rate ISDN subscriber loop</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kasturia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dudevoir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cioffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. In?. Conf. Commun</title>
		<meeting>In?. Conf. Commun<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-06-13">June 13. 1988</date>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="731" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Linear Algebra and its Applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Strang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Academic Press</publisher>
			<pubPlace>Orlando, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">The optimum combination of block codes and receivers for arbitrary channels</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Lechleider</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted to IEEE Trans. Cummun</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Optimal pre-and postfilters for multichannel signal processing</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Markel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Staelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust. Speech Signal Processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="287" to="289" />
			<date type="published" when="1988-02">Feb. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Bracewell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Maximum likelihood sequence detection in the presence of intersymbol interference</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Forney</surname><genName>Jr</genName></persName>
		</author>
		<idno>431 [441 [45] [46</idno>
	</analytic>
	<monogr>
		<title level="j">J. M. Wozencraft and I. M. Jacobs</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="378" />
			<date type="published" when="1965">May 1972. 1965</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>IEEE Trans. Inform. Theo y</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Multidimensional constellations I: Introduction, figures of merit, and generalized cross constellations</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Forney</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note>to appear in IEEE J. Selected Areas Cornrnun</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On the asymptotic eigenvalue distribution of Toeplitz matrices</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Szego</surname></persName>
		</author>
		<title level="m">Torplitz Forms and their Applications</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Chelsea</publisher>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Oppenheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Schafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Luenberger</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Introduction to Linear and Nonlinear Programming</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
