<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Diaformer: Automatic Diagnosis via Symptoms Sequence Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-12-20">20 Dec 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Junying</forename><surname>Chen</surname></persName>
							<email>junying.chen.cs@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dongfang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
							<email>qingcai.chen@hit.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenxiu</forename><surname>Zhou</surname></persName>
							<email>wen.xiu.zhou@outlook.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Shenzhen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Diaformer: Automatic Diagnosis via Symptoms Sequence Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-12-20">20 Dec 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2112.10433v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic diagnosis has attracted increasing attention but remains challenging due to multi-step reasoning. Recent works usually address it by reinforcement learning methods. However, these methods show low efficiency and require taskspecific reward functions. Considering the conversation between doctor and patient allows doctors to probe for symptoms and make diagnoses, the diagnosis process can be naturally seen as the generation of a sequence including symptoms and diagnoses. Inspired by this, we reformulate automatic diagnosis as a symptoms Sequence Generation (SG) task and propose a simple but effective automatic Diagnosis model based on Transformer (Diaformer). We firstly design the symptom attention framework to learn the generation of symptom inquiry and the disease diagnosis. To alleviate the discrepancy between sequential generation and disorder of implicit symptoms, we further design three orderless training mechanisms. Experiments on three public datasets show that our model outperforms baselines on disease diagnosis by 1%, 6% and 11.5% with the highest training efficiency. Detailed analysis on symptom inquiry prediction demonstrates that the potential of applying symptoms sequence generation for automatic diagnosis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic diagnosis has recently attracted increasing attention from researchers because of its potential in simplifying diagnostic procedures <ref type="bibr">(Tang et al. 2016;</ref><ref type="bibr" target="#b5">Kao, Tang, and Chang 2018)</ref>, helping make better and more effective diagnostic decisions <ref type="bibr" target="#b13">(Shivade et al. 2014;</ref><ref type="bibr" target="#b18">Xia et al. 2020)</ref>, and even helping build a diagnostic dialogue system as a dialogue management <ref type="bibr" target="#b6">(Li et al. 2017;</ref><ref type="bibr" target="#b17">Wei et al. 2018;</ref><ref type="bibr" target="#b20">Xu et al. 2019;</ref><ref type="bibr" target="#b16">Teixeira, Maran, and Dragoni 2021</ref>). An automatic diagnosis system is built on conversations between the agent and the patient where allows the agent to probe for symptoms and make diagnoses. As an example is shown in Table <ref type="table">1</ref>, the agent interacts with users to inquiry about additional symptoms (i.e., implicit symptoms) beyond their self-reports (i.e., explicit symptoms) and make a disease diagnosis at the end. When inquiring about additional symptoms, the automatic diagnosis system can only obtain the explicit symptoms (the symptoms from self-reports): {cough:true, snot:true} implicit symptoms (the symptoms from conversation): {sore throat:true, fever:true, harsh respiration:false} disease tag (the target disease): bronchitis of childhood Table <ref type="table">1</ref>: An example of automatic diagnosis data. value of symptoms in the "implicit symptoms" set or get a "not sure" answer for outside symptoms. Thus, the disease diagnosis task can be defined as inquiring the implicit symptoms step by step with limited interaction turns, and then diagnosing the disease based on explicit symptoms and the additional symptoms inquired. Note that different from the dialogue system of automatic diagnosis, automatic diagnosis we called here is symptom checking task in <ref type="bibr">(Tang et al. 2016)</ref>, which also serves as dialogue manager in taskoriented dialogue system of automatic diagnosis <ref type="bibr" target="#b17">(Wei et al. 2018;</ref><ref type="bibr" target="#b20">Xu et al. 2019;</ref><ref type="bibr" target="#b9">Luo, Li, and Glass 2020;</ref><ref type="bibr" target="#b18">Xia et al. 2020;</ref><ref type="bibr" target="#b16">Teixeira, Maran, and Dragoni 2021)</ref>.</p><p>Due to the existing of implicit symptoms, this task can be considered as a multi-step reasoning problem. The challenge of the task is how to capture the underlying dynamics and uncertainties of reasoning process, then inquiry about accurate symptoms under small labeled data and limited turns. Most previous methods usually address this problem as a sequential decision-making process, then formulate the process as Markov Decision Processes (MDPs) and employ Reinforcement Learning (RL) for policy learning <ref type="bibr">(Tang et al. 2016;</ref><ref type="bibr">Peng et al. 2017;</ref><ref type="bibr" target="#b9">Liu et al. 2017;</ref><ref type="bibr" target="#b8">Ling et al. 2017;</ref><ref type="bibr" target="#b5">Kao, Tang, and Chang 2018;</ref><ref type="bibr" target="#b17">Wei et al. 2018;</ref><ref type="bibr" target="#b20">Xu et al. 2019;</ref><ref type="bibr" target="#b7">Liao et al. 2020;</ref><ref type="bibr" target="#b18">Xia et al. 2020;</ref><ref type="bibr" target="#b4">Hou et al. 2021;</ref><ref type="bibr" target="#b16">Teixeira, Maran, and Dragoni 2021)</ref>. However, RL learns how to inquire about symptoms and make a disease diagnosis only with final accuracy rewards, which partly deviates from the actual doctor's diagnostic process. In real clinical diagnosis scenario, doctors carefully select relevant questions and ask patients with a medical diagnostic logic <ref type="bibr" target="#b18">(Xia et al. 2020)</ref>. The policy learning of RL tries to learn which symptom inquiry improves the rewards but not the doctor's diagnostic logic directly. As a result, RL relies on the random trials to learn how to improve the reward, but don't learn directly the correlation among symptoms and the standard diagnosis paradigm. It leads to low efficiency in learning how to make symptom inquiry decisions. Besides, there is still no explicit solution to find ideal reward functions, which may make the RL-based model hard to balance the decision learning between disease diagnosis and symptom inquiry.</p><p>Considering the diagnosis process can be naturally seen as the generation of a sequence, we reformulate automatic diagnosis as a Sequence Generation (SG) task in this work. Different from RL-based methods, the multi-step inquiry process is explicitly modeled at generating a sequence including symptoms and diagnoses. This can improve the efficiency and explainability of multi-step reasoning process. Moreover, the latent relationship among previous explicit symptoms and current symptom can be learned. Hence, the accurate inquiry of implicit symptoms would help to improve the accuracy of disease diagnosis, which is similar to doctors' diagnostic logic. As the example shown in Table <ref type="table">1</ref>, RL-based models tentatively learn which symptom inquiry helps to predict the children's bronchitis target using policy learning in large state/action spaces. By contrast, the SGbased model learn to inquire sore throat, fever and brash breath sequentially based on the explicit symptoms, so that the model can learn the latent relationship of symptoms inquiry and the diagnosis decision-making more efficiently.</p><p>As a step forward, we propose a simple but effective automatic Diagnosis model based on Transformer (Diaformer). It consists of a symptom attention framework and learns with three orderless training mechanisms. The symptom attention framework is introduced to model the automatic diagnosis using the Transformer architecture <ref type="bibr" target="#b17">(Vaswani et al. 2017)</ref>. The self-attention mechanism of Transformer can reduce the position dependence and learn multiple relationships among the multiple symptoms. To consider previous symptoms in current step, we also propose a attention mask mechanism. Each implicit symptom can attend to the given explicit symptoms and the previous implicit symptoms, while each explicit symptom can only see the explicit symptoms. As we learn the symptom inquiry by symptoms sequence generation, there is a bias caused by the discrepancy between the order of symptoms sequence learned and the disorder of golden implicit symptoms. To address this challenge, we further propose three orderless training mechanisms: sequence shuffle, synchronous learning, and repeated sequence. The main idea is to encourage the model to inquire symptoms in an orderless but accurate way, whereby improving the generalizability at inference time. Extensive experiments on MuZhi dataset <ref type="bibr" target="#b17">(Wei et al. 2018)</ref>, Dxy dataset <ref type="bibr" target="#b20">(Xu et al. 2019</ref>) and Synthetic dataset <ref type="bibr" target="#b7">(Liao et al. 2020)</ref> show that our proposed model (Diaformer) outperforms baselines on disease diagnosis by 1%, 6% and 11.5% with the highest training efficiency. Further analysis on symptom inquiry prediction demonstrates applying symptoms sequence generation is an plausible way to automatic diagnosis task.</p><p>Our contributions are summarized as follows: • To the best of our knowledge, we are the first to apply symptoms sequence generation for automatic diagnosis.</p><p>We further show that our method can be applied under few conversation turns scenarios.</p><p>• We propose three orderless training mechanisms to alleviate the discrepancy between the sequential generation and the disorder of given implicit symptoms sets. The ablation studies show that these orderless mechanisms can significantly alleviate this bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this section, we first formulate the automatic diagnosis task as a sequence generation (SG) task. Formally, an automatic diagnosis data includes an explicit symptom set S exp , an implicit symptom set S imp and a target disease Dis. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, S exp = {Sym 1 , Sym 2 } and S imp = {Sym 3 , Sym 4 , Sym 5 }. For the task, the automatic diagnosis system can only access the explicit symptoms S exp at the beginning. Then the system can inquire symptoms in limited turns to obtain the implicit symptoms in S imp . When the symptom inquires a symptom, the user simulator will take one of the three answer including True for the positive symptom, False for the negative symptom, and Not sure for the symptom that is not mentioned in user goal S exp ∪S imp . We denote S add which S add ⊆ S imp as the additional symptoms that had been inquired by the system. In the end, the system is asked to make a disease diagnosis based on the explicit symptoms and the addition symptoms. </p><formula xml:id="formula_0">|Timp| i=1 P (T i imp | S exp , T &lt;i imp )<label>(2)</label></formula><p>where the T i imp denote i-th symptom in T imp and T &lt;i imp denote all the symptoms in front of T i imp . Hence we change the symptom inquire task to a sequence generation task. Since the discrepancy between the order of T imp and the disorder of S imp , the SG training objective Eq.( <ref type="formula" target="#formula_0">2</ref>) is unequal to the Eq.( <ref type="formula">1</ref>), which seriously hinder the performance in automatic diagnosis. We propose three training mechanisms to make training objective Eq.(2) approximate to Eq.(1).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>In this section, we introduce the Diaformer, which consists of symptom attention framework and the orderless training mechanisms. Then we elaborate the generative inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symptom Attention Framework</head><p>The illustration of symptom attention framework is shown in Figure <ref type="figure" target="#fig_0">1</ref>. In this framework, we adopt multiple stacked Transformer blocks to model the automatic diagnosis by SG. Each block contains a feed forward network and a multihead attention, in which all input tokens share the parameters via self-attention <ref type="bibr" target="#b17">(Vaswani et al. 2017)</ref>.</p><p>Input Representation As shown in Figure <ref type="figure" target="#fig_0">1a</ref>, all the symptoms in S exp and S imp are converted to the specific token embedding. Different from Transformer, we remove the position embedding, and the symptom input representation is computed by summing the corresponding token embedding, symptom state embedding and symptom type embedding. For the symptom state embedding, [T rue] and [F alse] indicate positive symptom and negative symptom. For the symptom type embedding, [Exp] and [Imp] signal whether the symptom belong to S exp or S imp . In addition, we add two special tokens [S] and <ref type="bibr">[D]</ref>, which are used to predict symptom and disease respectively.</p><p>Attention Masks Figure <ref type="figure" target="#fig_0">1b</ref> show the attention mask matrix M, which determines whether query and key can attend to each other in self-attention by modifying the attention weight <ref type="bibr" target="#b17">Vaswani et al. 2017)</ref>. Specifically, M is assigned as:</p><formula xml:id="formula_1">W = sof tmax( QK T √ d k + M ) (</formula><formula xml:id="formula_2">M ij = 0, can be attended −∞, cannot be attended<label>(3)</label></formula><p>, where 0 and −∞ indicate red point and white point in Figure <ref type="figure" target="#fig_0">1b</ref>. With it, we can prevent symptom prediction from seeing leaked information in self-attention layer to achieve autoregressive generation training of implicit symptoms.</p><p>Symptom Token Attention Before input the framework, we initialize a implicit symptoms sequence T imp by S imp .</p><p>As shown in Figure <ref type="figure" target="#fig_0">1c</ref>, in each multi-head attentions of Transformer block, each explicit symptom can merely see the explicit symptoms and each implicit symptom can see the explicit symptoms and the previous implicit symptoms.</p><p>To be specific, the representations of symptom tokens are update in multi-head attention <ref type="bibr" target="#b17">(Vaswani et al. 2017)</ref> as:</p><formula xml:id="formula_3">S (l) exp ← MH-Attn(Q = S (l−1) exp , KV = S (l−1) exp ) T i(l) imp ← MH-Attn(Q = T i(l−1) imp , KV = [S (l−1) exp , T ≤i(l−1) imp ])<label>(4)</label></formula><p>where Q, K, V denote the query, key and value in multihead attention, [.] denotes concatenation along the sequence dimension, T target symptom and the implicit symptoms after the target symptom in T imp , aimed to learn the target symptom without information leakage. Specifically, the representation of [S] token is update as:</p><formula xml:id="formula_4">[S] (l) i ← MH-Attn(Q = [S] (l−1) i , KV = [S (l−1) exp , T &lt;i(l−1) imp , [S] (l−1) i ])<label>(5)</label></formula><p>where [S]</p><p>(l)</p><p>i denotes the l-th layer output of the i-th token in [S] sequence. For the last layer outputs of [S], we use a symptom classification layer that contains a liner layer weights W sym ∈ R H×Cinq , where H is the hidden size and C inq is the number of symptom inquiry types. For the symptom classification layer output z, we compute the cross entropy loss with softmax, i.e. −log(sof tmax(z)), as the symptom inquiry loss L sym . As for the disease classification, we insert a special token [D] to input sequence, shown in Figure <ref type="figure" target="#fig_0">1a</ref>. As shown in Figure <ref type="figure" target="#fig_0">1d</ref>, the token [D] can attend all the symptoms. The vector of [D] is updated as:</p><formula xml:id="formula_5">[D] (l) ← MH-Attn(Q = [D] (l−1) , KV = [S (l−1) exp , T (l−1) imp , [D] (l−1) ])<label>(6)</label></formula><p>Similar to [S], on the last layer output of [D], we adopt a disease classification layer weights W dis ∈ R H×C dis , where C dis is the number of disease types. We compute the cross entropy loss of it as the disease classification loss L dis . The final training loss is computed as</p><formula xml:id="formula_6">L = L dis + L sym .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Orderless Training Mechanisms</head><p>To alleviate the bias caused by the discrepancy between the order of the sequential generation of </p><formula xml:id="formula_7">y i = 1, y i ∈ S imp − S add 0, y i / ∈ S imp − S add<label>(7)</label></formula><p>where y i denote the label of inquiry class i. As for the symptom classification layer ouput z, the cross entropy loss of concurrent softmax is presented as:</p><formula xml:id="formula_8">L sym (y, z) = − Cinq i=1 y i logσ * i with σ * i = e zi Cinq j=1 (1 − y j )e zj + e zi<label>(8)</label></formula><p>where C inq denote the number of inquiry type. To balance label learning in [S] sequence, the loss of a single [S] is divided by the number of synchronous labels. With the synchronous learning, the training objective Eq.( <ref type="formula" target="#formula_0">2</ref>) transfer to</p><formula xml:id="formula_9">|Timp| i=1 |Timp| j=i P (T j imp | S exp , T &lt;i imp )<label>(9)</label></formula><p>, which is more approximate to the Eq.(1). Moreover, the synchronous learning helps improve training efficiency. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Repeated Sequence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative Inference</head><p>During inference stage, we firstly inserted a symptom prediction token [S] behind the symptoms sequence to calculate the probability distribution of symptoms. Then we mask the symptoms have been inquired and inquire the rest highest probability symptom. Next, the user simulator would determine if the inquired symptom is in the implicit symptoms set. If the symptom is not an implicit symptom, the model will find the next highest probability symptom to inquire user. Once the inquiry symptom is a implicit symptom, the user simulator will reply True or False for the symptom, and then the model insert it into the symptoms sequence and predict new probabilities of inquiry symptom, detailed as Figure <ref type="figure" target="#fig_2">3</ref>. When the model predict END symbol with probability greater than ρ e or infer the inquiry symptom with probability less than ρ p , the model will stop symptom inquiry to diagnose disease. In disease diagnosis, we insert the disease prediction token [D] into the symptoms sequence to predict the disease. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Details</head><p>For all model setting, the train set and test set both use the original format, as shown in Table <ref type="table" target="#tab_3">2</ref>. All the experiment is carried by 5 times and the final result is the average of the best results on test set. Diaformer and its variants use small transformer networks (L=5, H=512, A=6). For training, the learning rate is 5e − 5 and the batch size is 16. For inference, we set ρ e as 0.9 and set ρ p as 0.009 for MuZhi dataset, 0.012 for Dxy dataset and 0.01 for synthetic dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison</head><p>Baselines Firstly, we use SVM to classify disease based on explicit symptoms without any symptom inquiry and name it SVM-exp to give a a minimum baseline of diagnosis accuracy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head><p>We perform an ablation study to understand the importance of three training mechanisms of orderless generation. In Sequence Generation Sequence generation task aims to generate a target sequence condition on a source input. It covers many areas with a lot of tasks <ref type="bibr" target="#b22">(Zhang et al. 2020</ref>). Among them, the natural language generation (NLG) have achieved great success with the development of neural networks. Recently, the Transformer-based models have obtained superior performance in NLG, such as <ref type="bibr" target="#b12">(Radford et al. 2019;</ref><ref type="bibr" target="#b21">Yang et al. 2019;</ref><ref type="bibr" target="#b14">Song et al. 2019;</ref><ref type="bibr" target="#b1">Brown et al. 2020;</ref><ref type="bibr" target="#b0">Bao et al. 2020;</ref><ref type="bibr" target="#b19">Xiao et al. 2020;</ref><ref type="bibr" target="#b15">Sun et al. 2021)</ref>. Most of them train as auto-regressive (AR), in which the probability of an output token depends on all previous tokens. Based on AR training objective, the sequence generation model can learn all the target tokens in parallel. Besides, some of them use the additional artificial symbol sequence <ref type="bibr" target="#b19">(Xiao et al. 2020;</ref><ref type="bibr" target="#b1">Brown et al. 2020)</ref> or combine Masked Language model <ref type="bibr" target="#b3">(Devlin et al. 2018)</ref> as auto-encoding (AE) <ref type="bibr" target="#b4">(Dong et al. 2019;</ref><ref type="bibr" target="#b0">Bao et al. 2020)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices A Why Use Concurrent Softmax</head><p>In the synchronous learning, we attend to train the output of [S] to predict multiple symptoms, which can be regarded as a multi-label task. Normally, the Bernoulli parameter for each symptom inquiry label is considered as a good choice to the multi-label task. However, there are three reason that we choose the concurrent softmax: (1) the synchronous labels are sparse, due to the number of implicit symptoms is much less than the number of symptom inquiry types. Training as Bernoulli parameter will perform inefficiently.</p><p>(2) The synchronous learning is a training mechanism in the training stage, while we still use softmax to compute the probability distribution of symptom inquiry. As a result, if we use the Bernoulli parameter, it will lead to a big discrepancy between training and inference. In contrast, the concurrent softmax is almost same as softmax, used to learn the probability distribution of symptom inquiry.</p><p>(3) Due to the imbalance of the symptom inquiry label, the independent learning in the Bernoulli parameter give rise to a serious overfitting problem. In our pilot experiments, the concurrent softmax indeed perform much better than the Bernoulli parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Dataset Details</head><p>MuZhi Dataset The MuZhi dataset is constructed by <ref type="bibr" target="#b17">(Wei et al. 2018</ref>). The data is collected from the pediatric department of a Chinese online medical website, which is a popular website for users to consult doctors online. Usually, a patient will provide a self-report to indicate his or her basic information.Then the doctor will initiate a conversation to collect more information and make a diagnosis based on parent's self-report and conversations. The doctor can obtain additional symptoms not mentioned in the self-report during the conversation. For each patient, the doctor will give the final diagnosis as the label. In the dataset, symptoms extracted from self-report are regarded as explicit symptoms and the ones extracted from conversation are implicit symptoms. More detailed dataset statistics are shown in Table <ref type="table" target="#tab_9">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dxy Dataset</head><p>The Dxy dataset is constructed by <ref type="bibr" target="#b20">(Xu et al. 2019</ref>) and the data is collected from a Chinese online healthcare community, where users asking doctors for medical diagnosis or professional medical advice. The dataset contains five types of diseases, including allergic rhinitis, upper respiratory infection, pneumonia, children hand-foot-mouth disease, and pediatric diarrhea. And <ref type="bibr" target="#b20">(Xu et al. 2019</ref>) extract the symptoms that appear in self-reports and conversation and normalize them into 41 symptoms. More detailed dataset statistics are shown in Table <ref type="table" target="#tab_9">6</ref>. Similar to the MuZhi dataset, symptoms appearing in self-reports are regarded as symptoms while the others are implicit symptoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic Dataset</head><p>The Synthetic dataset is constructed by <ref type="bibr" target="#b7">(Liao et al. 2020)</ref>  the UniLM training setting, 1/3 of the time we use the bidirectional objective, 1/3 of the time we employ the sequence-to-sequence generation objective, and the rest 1/3 time we use unidirectional generation objective, which replace left-to-right and right-to-left in UniLM since sequence shuffle. For the bidirectional objective, the model allows all tokens to attend to each other in prediction and mask a symptom token at each time. As for the mask, 80% of the time we replace the token with [MASK], 10% of the time with a random token, and keeping the original token for the rest. For the sequenceto-sequence generation objective, we asked the model to generate implicit symptoms sequence by explicit symotoms. We set the UniLM variant comparison to test the advanced SG model with auto-encoder on automatic diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Model Implementation Details</head><p>Because it is small scale of automatic diagnosis datasets, Diaformer use a small transformer network (L=5, H=512, A=6), where L denotes the number of layers, H denotes the hidden size, A denotes the number of attention heads. The learning rate is set to 5e − 5 and the batch size is 16.</p><p>For the inference step, we set ρ e =0.9 and set ρ p as 0.009 for MuZhi dataset, 0.012 for Dxy dataset and 0.01 for synthetic dataset. The hyper parameters of Diaformer GP T 2 and Diaformer U niLM are the same as Diaformer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Standard Errors of Result</head><p>Due to space limitation, we give the standard error of our models in each experiment, which is carried by 5 times. The standard errors are given in Table <ref type="table">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Examples of Result</head><p>To help readers to comprehend the models output on the datasets, we give a success example and a failure example on Synthetic dataset, that shown in Table <ref type="table">8</ref>. In the task, models are asked to sequentially inquire the implicit symptoms based on explicit symptoms and then diagnose the disease by the explicit symptoms and the inquired implicit symptoms. Besides, in the outputs of Diaformer, we find that model tend to inquire more symptoms in the failure examples, while inquire less symptoms in success example, e.g. the examples in Table <ref type="table">8</ref>. It indicates the model has learned the diagnosis paradigm to some extent.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of symptom attention framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Demonstrations of three orderless training mechanisms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Schematic of inference process. User is the user simulator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results of ablation studies on the synthetic dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The task objective of learning is maximize the likelihood of disease diagnosis P (Dis | S exp ∪ S add )P (S add | S exp ).</figDesc><table><row><cell cols="2">Since the implicit symptoms contain important information</cell></row><row><cell cols="2">that inquired by the doctors, the intuition is that the more</cell></row><row><cell cols="2">implicit symptoms the model inquires, the higher diagnosis</cell></row><row><cell cols="2">accuracy model can get. We transfer task learning objective</cell></row><row><cell>to maximize P (S imp | S exp ) as well as:</cell><cell></cell></row><row><cell>P (Sym | S exp , S add )</cell><cell>(1)</cell></row><row><cell>S add ⊆Simp Sym∈Simp−S add</cell><cell></cell></row><row><cell cols="2">then we use a symptom attention framework, shown in Fig-</cell></row><row><cell cols="2">ure 1, to learn predicting the implicit symptoms sequentially.</cell></row><row><cell cols="2">Thus, we need to change the orderless S imp into the ordered</cell></row><row><cell cols="2">symptoms sequence T imp as the target generation sequence.</cell></row><row><cell cols="2">According to the autoregressive generation, the probability</cell></row><row><cell cols="2">of output token depends on all previous. The objective of</cell></row><row><cell cols="2">model learning is transferred to maximize the likelihood of</cell></row><row><cell>T imp generation:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>add symptom state embedding add symptom type embedding (b) Attention masks</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Transformer Blocks</cell></row><row><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row><row><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>can be attended</cell><cell>cannot be attended</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>T imp and the disorder of implicit symptoms S imp , We propose three orderless training mechanisms of SG, which is demonstrated in Figure 2 and detailed as follow.Synchronous Learning While the model predicts the next symptom inquiry, we expect all the implicit symptoms, which have not been inquired, have equal probability to be inquired. As shown in Figure1a, the [S] 1 is trained to predict the Sym 3 . However, Sym 3 , Sym 4 and Sym 5 should have the same priority to be inquired in the orderless set of the implicit symptoms. Therefore, we design the synchronous learning objective to train the model to synchronously predict the rest implicit symptoms that it can't see. As shown in the Figure2, each symptom prediction token [S] is trained to predict all the rest implicit symptoms synchronously. There-</figDesc><table><row><cell>Sequence Shuffle We randomly shuffle the implicit symp-</cell></row><row><cell>toms sequence T imp to obtain new implicit symptoms se-</cell></row><row><cell>quence T imp in different order before input the model in</cell></row><row><cell>each training step, so that the model can learning different</cell></row><row><cell>order of symptom inquiry after multiple training epoch. It</cell></row><row><cell>can prevent the model to impose over-fitting on inquiring</cell></row><row><cell>symptoms in a specific order and fail to inquire the correct</cell></row></table><note>implicit symptom in a slightly different context. With the increase of training epoch, the model will gradually fit the symptom disorder distribution, whereby the T imp sequence generation approximate to the S imp inference. fore, we use a concurrent softmax<ref type="bibr" target="#b10">(Peng et al. 2020)</ref> replacing the original softmax to train [S] to predict multiple symptoms synchronously. We remove the concurrent rate in (Peng et al. 2020) and only use the concurrent softmax as a training mechanism, as we still use softmax in inference. The concurrent softmax can enable the model to learn multiple symptoms synchronously and eliminate the discrepancy between training and inference. The reset implicit symptoms S imp −S add is set as the training objective, so the concurrent softmax label y is defined as:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the three datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="4"># Disease # Symptom # Training # Test</cell></row><row><cell>MuZhi</cell><cell>4</cell><cell>66</cell><cell>568</cell><cell>142</cell></row><row><cell>Dxy</cell><cell>5</cell><cell>41</cell><cell>423</cell><cell>104</cell></row><row><cell>Synthetic</cell><cell>90</cell><cell>266</cell><cell>24,000</cell><cell>6,000</cell></row><row><cell></cell><cell></cell><cell>4 Experiments</cell><cell></cell><cell></cell></row><row><cell>Datasets</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">We evaluate our model on three public automatic diagno-</cell></row><row><cell cols="5">sis datasets, namely MuZhi dataset (Wei et al. 2018), Dxy</cell></row><row><cell cols="5">dataset (Xu et al. 2019) and Synthetic dataset (Liao et al.</cell></row><row><cell cols="5">2020). MuZhi dataset and Dxy dataset are real-data from</cell></row><row><cell cols="5">self-reports and the conversations. Synthetic dataset is a</cell></row><row><cell cols="5">much bigger synthetic data constructed by symptom-disease</cell></row><row><cell cols="4">dataset. The datasets statistics are shown in Table 2.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results on three datasets. DAcc is the accuracy of diagnosis; SRec is the recall of the implicit symptoms; ATurn is the average of symptom inquiry turn; Ttime indicates the training time to get the best diagnosis result running on a 1080Ti GPU; Ttime's unit "m" indicate minute; ‡ marks the results reported by the original papers. other models in diagnosis accuracy with highest training efficiency. Especially on Dxy dataset and Synthetic dataset, our model outperforms the current state-of-the-art model by 6% and 11.5% in diagnosis accuracy. Note that SG-based models have considerably high recall of implicit symptoms and perform much better on bigger dataset, i.e. Synthetic dataset. The upsurge on bigger dataset demonstrates the high training efficiency of SG-based models, which only need to be trained in 2 minutes on Dxy dataset and MuZhi dataset.It indicates that the symptoms sequence generation has considerable potential in automatic diagnosis. Additionally, Diaformer surpass the other SG-based mdoel, which demonstrates the symptom attention framework and the orderless mechanisms can further improve the performance and training efficiency in SG-based models. Moreover, we observe that SG-based models request more inquiry turns, due to the higher recall of symptoms lead to more inquiry turns. For simulate the process of doctor diagnosis, SG-based models tend to generate more implicit symptoms. For this limitation, we conduct the experiments of smaller limited turns.</figDesc><table><row><cell>Then we have selected five competitive</cell></row><row><cell>RL-based models as comparison, including Flat-DQN (Wei</cell></row><row><cell>et al. 2018), HRL (Liao et al. 2020), KR-DS (Xu et al.</cell></row><row><cell>2019), GAMP (Xia et al. 2020) and PPO (Teixeira, Maran,</cell></row><row><cell>and Dragoni 2021). Besides, we add two SG-based mod-</cell></row><row><cell>els, namely Diaformer GPT2 and Diaformer UniLM , serve as</cell></row><row><cell>strong SG-based baseline of Diaformer. Diaformer GPT2 and</cell></row><row><cell>Diaformer UniLM base on our symptom attention framework</cell></row><row><cell>and train on the objective in GPT2 (Radford et al. 2019) and</cell></row><row><cell>UniLM (Dong et al. 2019), which are two classic sequence</cell></row><row><cell>generation model fitted to automatic diagnosis. For fair com-</cell></row><row><cell>parison, Diaformer GPT2 and Diaformer UniLM are extra added</cell></row><row><cell>with the sequence shuffle training mechanisms, and use the</cell></row><row><cell>same hyper parameters of Diaformer.</cell></row><row><cell>Overall Performance According to the task definition in</cell></row><row><cell>(Wei et al. 2018) and (Liao et al. 2020), we set the maxi-</cell></row><row><cell>mum inquiry turn as 20. We evaluate all the model by three</cell></row><row><cell>metrics, which are diagnosis accuracy, average inquiry turns</cell></row><row><cell>and recall of the implicit symptoms. The recall of the im-</cell></row><row><cell>plicit symptoms is a significant metric for SG-based mod-</cell></row><row><cell>els, which aim to inquire the implicit symptoms out as much</cell></row><row><cell>as possible and then diagnose the disease. Besides, we add</cell></row><row><cell>a training time metric to evaluate the training efficiency</cell></row><row><cell>of models. The results on three datasets are shown in Ta-</cell></row><row><cell>ble 3. In the results, Diaformer overwhelmingly outperforms</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 ,</head><label>5</label><figDesc>we compare three Diaformer variants (rows 2 -4) without one of the three orderless training mechanisms. As shown in Table5, we can see each mechanism contribute to improve the performance. Without sequence shuffle, the model obtain lower recall of symptoms with higher inquiry turns. Without synchronous learning or repeated sequence, the accuracy of diagnosis and the recall of symptoms both reduce. Specifically, Figure4show the results of on Synthetic dataset in the series of training epoch as the same parameter initialization, in which Diaformer obviously performs best on diagnosis accuracy and recall of implicit symptoms. It indicates that orderless training mechanism help to improve the performance of symptoms sequence generation in automatic diagnosis.</figDesc><table><row><cell>5 Related Work</cell></row><row><cell>Automatic Diagnosis There are some previous works for</cell></row><row><cell>automatic diagnosis, which mostly use RL (Tang et al. 2016;</cell></row></table><note><ref type="bibr" target="#b5">Kao, Tang, and Chang 2018;</ref><ref type="bibr" target="#b11">Peng et al. 2018;</ref><ref type="bibr" target="#b17">Wei et al. 2018;</ref><ref type="bibr" target="#b20">Xu et al. 2019;</ref><ref type="bibr" target="#b7">Liao et al. 2020;</ref><ref type="bibr" target="#b4">Hou et al. 2021;</ref><ref type="bibr" target="#b16">Teixeira, Maran, and Dragoni 2021)</ref>.Tang et al. (2016)  propose neural symptom checking, which adopts reinforcement</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Results with smaller different limited turns. DAcc, SRec and ATurn are same as Table3.</figDesc><table><row><cell># Model</cell><cell cols="2">MuZhi dataset</cell><cell>Dxy dataset</cell><cell></cell><cell cols="2">Synthetic dataset</cell></row><row><cell></cell><cell cols="6">DAcc SRec ATurn DAcc SRec ATurn DAcc SRec ATurn</cell></row><row><cell>1 Diaformer</cell><cell>0.742 0.752</cell><cell>15.3</cell><cell>0.829 0.827</cell><cell>13.1</cell><cell>0.733 0.906</cell><cell>13.7</cell></row><row><cell>2 w/o Sequence Shuffle</cell><cell>0.737 0.723</cell><cell>17.3</cell><cell>0.825 0.824</cell><cell>14.4</cell><cell>0.658 0.730</cell><cell>13.2</cell></row><row><cell cols="2">3 w/o Synchronous Learning 0.742 0.738</cell><cell>14.3</cell><cell>0.826 0.790</cell><cell>11.1</cell><cell>0.725 0.891</cell><cell>12.8</cell></row><row><cell>4 w/o Repeated Sequence</cell><cell>0.735 0.705</cell><cell>13.4</cell><cell>0.817 0.773</cell><cell>11.0</cell><cell>0.713 0.877</cell><cell>12.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Results of ablation study. DAcc, SRec and ATurn are same as Table3.</figDesc><table><row><cell>learning to simultaneously conduct symptom inquiries and</cell></row><row><cell>diagnose. Based on the work of (Tang et al. 2016), Kao,</cell></row><row><cell>Tang, and Chang (2018) employ hierarchical reinforcement</cell></row><row><cell>learning to make a joint diagnostic decision and introduce</cell></row><row><cell>context to make the symptom checker context aware. Wei</cell></row><row><cell>et al. (2018) use a Deep Q-network from conversation with</cell></row><row><cell>patients to collect additional symptoms, which can greatly</cell></row><row><cell>improve the accuracy of diagnosis. Xu et al. (2019) intro-</cell></row><row><cell>duce prior medical knowledge to guide policy learning. Liao</cell></row><row><cell>et al. (2020) classify diseases into several groups and uses a</cell></row><row><cell>hierarchy of two levels for automatic disease diagnosis using</cell></row><row><cell>HRL methods. Xia et al. (2020) propose a policy gradient</cell></row><row><cell>framework based on the Generative Adversarial Network to</cell></row><row><cell>optimize the RL model. Recently, Hou et al. (2021) propose</cell></row><row><cell>a multi-level reward RL-based model and Teixeira, Maran,</cell></row><row><cell>and Dragoni (2021) customize the settings of the reinforce-</cell></row><row><cell>ment learning leveraging the dialogue data.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>to enhance the model. With more and more relevant models being proposed, Transformer has shown great potential in sequence generation.</figDesc><table><row><cell>6 Conclusion</cell></row><row><cell>In this work, we reformulate the automatic diagnosis prob-</cell></row><row><cell>lem as a sequence generation task and propose a symptom</cell></row><row><cell>attention framework for automatic diagnosis with symptoms</cell></row><row><cell>sequence generation. Besides, we propose three orderless</cell></row><row><cell>training mechanisms to alleviate the bias of the discrepancy</cell></row><row><cell>between the sequential generation and the disorder of symp-</cell></row><row><cell>toms. Experimental results show that our model outperforms</cell></row><row><cell>other models on three datasets of automatic diagnosis and</cell></row><row><cell>demonstrates the potential of symptoms sequence genera-</cell></row><row><cell>tion in automatic diagnosis. Future work includes incorpo-</cell></row><row><cell>rating Diaformer into task-oriented dialogue system of diag-</cell></row><row><cell>nosis and effectively lessen the inquiry turns.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>following<ref type="bibr" target="#b5">(Kao, Tang, and Chang 2018)</ref>, which is based on symptom-disease database called Sym-Cat. There are 801 diseases in the database and<ref type="bibr" target="#b7">(Liao et al. 2020</ref>) classify them into 21 departments (groups) according to International Classification of Diseases (ICD-10-CM) and choose 9 representative departments from the database.Each department contains top 10 diseases according to the occurrence rate in the Centers for Disease Control and Prevention (CDC) database. More detailed dataset statistics are shown in Table6. This is the model from<ref type="bibr" target="#b7">(Liao et al. 2020)</ref>, which integrates a hierarchical policy of two levels into the dialogue policy learning. The high level policy consists of a model named master that is responsible for triggering a model in low level, and the low level policy consists of several symptom checkers and a disease classifier. • KR-DS: This is the model from<ref type="bibr" target="#b20">(Xu et al. 2019)</ref>, which seamlessly incorporates rich medical knowledge graph into the topic transition in dialogue management. This is the model from<ref type="bibr" target="#b16">(Teixeira, Maran, and Dragoni 2021)</ref>, which is proposed to leverage the models learned from the dialogue data to customize the settings of the reinforcement learning for more efficient action space exploration.SG-based variant models• Diaformer GP T 2 : This is a Diaformer variant model. Diaformer GP T 2 uses the symptom attention framework and GP T 2 (Radford et al. 2019) SG training objective, that each symptom token, including explicit symptoms, predict the next symptom in the symptoms sequence without [S] token. To be fair comparison, we add the sequence shuffle mechanism for it. GPT2 is a classics autoregression generation model with high efficiency of training. The Diaformer GP T 2 is compared as a conventional generative model. • Diaformer U niLM : This is a Diaformer variant model based on the symptom attention framework using the UniLM (Dong et al. 2019) training objective. Basd on Dataset # Disease # Symptom # ave ex. sym. # ave im. sym. # Training # Test Statistics of the three datasets. Ave ex. sym. and ave im. sym. are the average number of explicit and implicit symptoms.</figDesc><table><row><cell>C Comparison Models</cell></row><row><cell>Minimum Baseline</cell></row><row><cell>• SVM-exp: To indicate the significance of symptom in-</cell></row><row><cell>quiry and give the minimum boundaries in automatic di-</cell></row><row><cell>agnosis, we use SVM model learned to distinguish the</cell></row><row><cell>disease on explicit symptoms directly without any symp-</cell></row><row><cell>tom inquiry. The SVM we used is based on the linear ker-</cell></row><row><cell>nel and adopt one-vs-one scheme to support multiclass.</cell></row><row><cell>RL-based Models</cell></row><row><cell>• Flat-DQN: This is the model from (Wei et al. 2018),</cell></row><row><cell>which has one layer policy and an action space includ-</cell></row><row><cell>ing both symptoms and diseases.</cell></row><row><cell>• HRL: The model use a novel Knowledge-routed Deep Q-</cell></row><row><cell>network (KR-DQN) ,which integrates a relational re-</cell></row><row><cell>finement branch for encoding relations among different</cell></row><row><cell>symptoms and symptom-disease pairs, and a knowledge-</cell></row><row><cell>routed graph branch for topic decision-making.</cell></row><row><cell>• GAMP: This is the model from (Xia et al. 2020). GAMP</cell></row><row><cell>is a generative adversarial regularized Mutual informa-</cell></row><row><cell>tion Policy gradient framework (GAMP) for automatic</cell></row><row><cell>diagnosis, that based on the Generative Adversarial Net-</cell></row><row><cell>work (GAN) to optimize the RL model for automatic di-</cell></row><row><cell>agnosis.</cell></row><row><cell>• PPO:</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank all the reviewers for their constructive comments and useful suggestions. This work is supported by the Natural Science Foundation of China (Grant No. 61872113), Strategic Emerging Industry Development Special Funds of Shenzhen (No. XMHT20190108009), and Fundamental Research Fund of Shenzhen (No. JCYJ20190806112210067).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>The problem of facilitating diagnosis is important in artificial intelligence applications. Our method shows promising accuracy and noticeable efficiency on automatic diagnosis, which is a multi-step reasoning problem as well as a symptom checking task in <ref type="bibr">(Tang et al. 2016)</ref>. Besides strong performance, the automatic diagnosis models learned from the insufficient and incomplete dataset has considerable risk of predicting error that may cause seriously harm. Under the ethical considerations, we suggest users regard it as an auxiliary tool that can help doctors make diagnose or help to give patients some advice.</p><p>In fact, the proposed Diaformer is not limited to the automatic diagnosis problem. It can extend to use in some decision-making problems or RL problems through slight change. As for the usage on other problems, we suggest users design more intermediate-state tokens along with the decision tokens to form a decisions sequence and adjust the type embedding and attention mask mechanism for specific problems. Different from Decision Transformer <ref type="bibr" target="#b2">(Chen et al. 2021)</ref> in the typical RL problems, our model tends to learn the relationship among the decisions directly and focus on alleviating the order bias for orderless or non-sequential RL problems. Note that all the decision-making models run the risk of biased prediction in real-life application scenarios, and be careful to use them. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unilmv2: Pseudo-masked language models for unified language model pre-training</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="642" to="652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Decision Transformer: Reinforcement Learning via Sequence Modeling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<idno>CoRR, abs/2106.01345</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
				<meeting><address><addrLine>Bert</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imperfect also Deserves Reward: Multi-Level and Sequential Reward Modeling for Better Dialog Management</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Hon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.03197</idno>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
				<imprint>
			<date type="published" when="2019">2019. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Unified language model pre-training for natural language understanding and generation</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Context-aware symptom checking for disease diagnosis using hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">End-to-end task-completion neural dialogue systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01008</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14254</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to Diagnose: Assimilating Clinical Narratives using Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Farri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<title level="s">Long Papers</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Asian Federation of Natural Language Processing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="895" to="905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">End-to-End Optimization of Task-Oriented Dialogue Model with Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wong</surname></persName>
		</author>
		<idno>CoRR, abs/1704.03084</idno>
	</analytic>
	<monogr>
		<title level="m">Prototypical Q Networks for Automatic Conversational Diagnosis and Few-Shot New Disease Adaption</title>
				<imprint>
			<date type="published" when="2017">2017. 2020. 2017</date>
		</imprint>
	</monogr>
	<note>Composite Task-Completion Dialogue System via Hierarchical Deep Reinforcement Learning</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large-scale object detection in the wild from imbalanced multi-labels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9709" to="9718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Refuel: Exploring sparse features in deep reinforcement learning for fast disease diagnosis</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="7322" to="7331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A review of approaches to identifying patient phenotype cohorts using electronic health records</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shivade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fosler-Lussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Embi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="221" to="230" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">MASS: Masked Sequence to Sequence Pre-training for Language Generation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno>CoRR, abs/1905.02450</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ERNIE 3.0: Largescale Knowledge Enhanced Pre-training for Language Understanding and Generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno>ArXiv, abs/2107.02137</idno>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Reinforcement Learning</title>
				<editor>
			<persName><forename type="first">K.-F</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-C</forename><surname>Kao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C.-N</forename><surname>Chou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2016">2021. 2016</date>
		</imprint>
	</monogr>
	<note>Inquire and diagnose: Neural symptom checking ensemble using deep reinforcement learning</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The interplay of a conversational ontology and AI planning for health dialogue management</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dragoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on Applied Computing</title>
				<meeting>the 36th Annual ACM Symposium on Applied Computing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Task-oriented dialogue system for automatic diagnosis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2017">2017. 2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="201" to="207" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generative Adversarial Regularized Mutual Information Policy Gradient Framework for Automatic Diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1062" to="1069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Ernie-gen: An enhanced multi-flow pre-training and fine-tuning framework for natural language generation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.11314</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">End-to-end knowledge-routed relational dialogue system for automatic diagnosis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7346" to="7353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-vehicle routing problems with soft time windows: A multi-agent reinforcement learning approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transportation Research Part C: Emerging Technologies</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page">102861</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
