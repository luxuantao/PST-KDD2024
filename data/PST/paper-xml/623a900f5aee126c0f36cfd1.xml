<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation</title>
				<funder ref="#_bzVkvVW">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_qbSWpTD">
					<orgName type="full">Hong Kong Research Grants Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-22">22 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yingxiu</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhiliang</forename><surname>Tian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
							<email>huaxiu@cs.stanford.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yinhe</forename><surname>Zheng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dongkyu</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiping</forename><surname>Song</surname></persName>
							<email>songyiping@pku.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
							<email>jian.sun@alibaba-inc.com</email>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nevin</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
							<email>lzhang@cse.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-22">22 Mar 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2203.11670v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Building models of natural language processing (NLP) is challenging in low-resource scenarios where only limited data are available. Optimization-based meta-learning algorithms achieve promising results in low-resource scenarios by adapting a well-generalized model initialization to handle new tasks. Nonetheless, these approaches suffer from the memorization overfitting issue, where the model tends to memorize the meta-training tasks while ignoring support sets when adapting to new tasks. To address this issue, we propose a memory imitation meta-learning (MemIML) method that enhances the model's reliance on support sets for task adaptation. Specifically, we introduce a task-specific memory module to store support set information and construct an imitation module to force query sets to imitate the behaviors of some representative supportset samples stored in the memory. A theoretical analysis is provided to prove the effectiveness of our method, and empirical results also demonstrate that our method outperforms competitive baselines on both text classification and generation tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Building natural language processing (NLP) models in low-resource scenarios is of great importance in practical applications because labeled data are scarce. Meta-learning-based methods <ref type="bibr" target="#b36">(Thrun and Pratt, 2012)</ref> have been commonly used in such scenarios owing to their fast adaptation ability. Notable successes have been achieved by metalearning on low-resource NLP tasks, such as multidomain sentiment classification <ref type="bibr" target="#b47">(Yu et al., 2018;</ref><ref type="bibr" target="#b6">Geng et al., 2019)</ref> and personalized dialogue generation <ref type="bibr" target="#b17">(Madotto et al., 2019;</ref><ref type="bibr" target="#b31">Song et al., 2020;</ref><ref type="bibr" target="#b50">Zheng et al., 2020)</ref>.</p><p>Among different meta-learning approaches <ref type="bibr" target="#b11">(Hospedales et al., 2021)</ref>, optimization-based ap-proaches have been widely used in various lowresource NLP scenarios <ref type="bibr" target="#b17">(Madotto et al., 2019;</ref><ref type="bibr" target="#b24">Qian and Yu, 2019;</ref><ref type="bibr" target="#b15">Li et al., 2020;</ref><ref type="bibr" target="#b18">Mi et al., 2019)</ref> because they are model-agnostic and easily applicable. Concretely, optimization-based meta-learning algorithms aim to learn a well-generalized global model initialization ? that can quickly adapt to new tasks within a few steps of gradient updates. In the meta-training process, we first train ? on a support set (i.e., a few training samples of a new task i) to obtain task-specific parameters ? i . Then, we optimize ? based on the performance of ? i on a query set (i.e., another set of samples in task i).</p><p>Despite its effectiveness, optimization-based meta-learning algorithms usually suffer from the memorization overfitting issue<ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b46">(Yin et al., 2020;</ref><ref type="bibr" target="#b25">Rajendran et al., 2020)</ref>, where the learned model tends to solve all the meta-training tasks by memorization, rather than learning how to quickly adapt from one task to another via support sets. This is acceptable for training process, but results in poor generalization on the meta-testing sets, because the memorized model does not have knowledge of those tasks and does not know how to utilize the base learner to learn new tasks. Hence, this issue hinders the model from capturing task-specific characteristics from support sets and thus prevents the model from adapting to distinct new tasks <ref type="bibr" target="#b25">(Rajendran et al., 2020)</ref>. For instance, in personalized dialogue generation, this implies that the dialog model cannot adapt to individual users based on short conversation histories and hence fails to generate personalized responses.</p><p>Several works have been proposed to tackle the memorization overfitting issue for regression and image classification tasks. Some studies try to explicitly regularize the model parameters <ref type="bibr">(Yin et al.,</ref> 1. A novel method MemIML is proposed to alleviate the memorization overfitting for optimization-based meta-learning algorithms. It encourages the utilization of support sets with the help of a memory module and an imitation module when adapting to new tasks. 2. Comprehensive experiments on text classification and generation tasks show that MemIML significantly outperforms competitive baselines. 3. Theoretical proofs are given to demonstrate the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Meta-Learning. Meta-Learning aims to improve the learning algorithm itself based on the previously learned experience <ref type="bibr" target="#b35">(Thrun and Pratt, 1998;</ref><ref type="bibr" target="#b11">Hospedales et al., 2021)</ref>. In general, there are three categories of meta-learning methods: model-based methods, <ref type="bibr" target="#b28">(Santoro et al., 2016;</ref><ref type="bibr" target="#b21">Obamuyide et al., 2019)</ref> which depend on the particular model design to facilitate fast learning; metric-based methods, <ref type="bibr" target="#b40">(Vinyals et al., 2016;</ref><ref type="bibr" target="#b30">Snell et al., 2017;</ref><ref type="bibr" target="#b6">Geng et al., 2019)</ref> which encode samples into an embedding space and classify them based on the learned distance metric; optimization-based methods <ref type="bibr" target="#b5">(Finn et al., 2017;</ref><ref type="bibr" target="#b18">Mi et al., 2019)</ref> that learn a wellgeneralized model initialization which allows for fast adaptation to new tasks. For low-resource scenarios in NLP, optimization-based meta-learning methods achieved promising results on tasks such as personalized dialog generation <ref type="bibr" target="#b17">(Madotto et al., 2019;</ref><ref type="bibr" target="#b31">Song et al., 2020;</ref><ref type="bibr" target="#b37">Tian et al., 2021)</ref>, lowresource machine translation <ref type="bibr" target="#b7">(Gu et al., 2018;</ref><ref type="bibr" target="#b29">Sharaf et al., 2020)</ref> and question answering <ref type="bibr" target="#b44">(Yan et al., 2020)</ref>, few-shot slot tagging <ref type="bibr" target="#b41">(Wang et al., 2021)</ref>, and so on.</p><p>Memorization overfitting of Meta-learning. Meta-learning algorithms suffer from memorization overfitting. <ref type="bibr" target="#b46">Yin et al. (2020)</ref> build an information bottleneck to the model, while this approach decreases the model performance with this passive regularization. <ref type="bibr" target="#b25">Rajendran et al. (2020)</ref> inject random noise to the ground truth of both support and query sets, while little extra knowledge is introduced to learn a good initialization. <ref type="bibr" target="#b45">Yao et al. (2021)</ref> address overfitting issues by augmenting meta-training tasks through mixing up support and query sets. However, such augmentation for text needs to be based on the assumption of keeping the label and the data distribution unchanged, which is often not true in practice <ref type="bibr" target="#b1">(Chen et al., 2021)</ref>. Instead of regularization and data augmentation, we leverage the support sets information stored in the memory to augment the meta-learning.</p><p>External Memory for Few-shot Learning.</p><p>Memory mechanism has proven to be powerful for few-shot learning <ref type="bibr" target="#b6">(Geng et al., 2019;</ref><ref type="bibr" target="#b28">Santoro et al., 2016;</ref><ref type="bibr" target="#b19">Munkhdalai et al., 2019)</ref>. Current methods either refine representations stored in the memory <ref type="bibr" target="#b26">(Ramalho and Garnelo, 2018)</ref> or refining parameters using the memory <ref type="bibr" target="#b20">(Munkhdalai and Yu, 2017;</ref><ref type="bibr" target="#b0">Cai et al., 2018;</ref><ref type="bibr" target="#b42">Wang et al., 2020)</ref>. In the NLP domain, some methods store encoded contextual information into a memory <ref type="bibr" target="#b12">(Kaiser et al., 2017;</ref><ref type="bibr" target="#b10">Holla et al., 2020;</ref><ref type="bibr" target="#b49">Zheng et al., 2019)</ref>. <ref type="bibr" target="#b6">Geng et al. (2019)</ref> propose a memory induction module with a dynamic routing algorithm for few-shot text classification tasks. <ref type="bibr" target="#b19">Munkhdalai et al. (2019)</ref> augment the model with an external memory by learning a neural memory. <ref type="bibr" target="#b41">Wang et al. (2021)</ref> reuse learned features stored in the memory on the few-shot slot tagging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head><p>We first formulate model-agnostic meta-learning (MAML) <ref type="bibr" target="#b5">(Finn et al., 2017)</ref>. Specifically, denote the base model used in MAML as f ? and assume each task T i sampled from a task distribution p(T ) associates with a dataset D i . Each dataset D i consists of a support set</p><formula xml:id="formula_0">D s i = {(X s j , Y s j )} N s j=1 and a query set D q i = {(X q j , Y q j )} N q j=1</formula><p>, where X and Y denote the input and ground truth of a sample, respectively. During the meta-training stage, a taskspecific (a.k.a., post-update) model f ? i is first obtained for each task T i via gradient descent over its support set D s i . Then MAML updates its initialization (a.k.a., pre-update) ? according to the performance of f ? i on the query set D q i as in Eq.1:</p><formula xml:id="formula_1">? * = min ? E T i ?p(T ) L f ? i (X q i ) , Y q i (1) s.t. ? i = ? -?? ? L (f ? (X s i ) , Y s i ) (2)</formula><p>where ? is the inner loop learning rate. During the meta-testing stage, the learned initialization ? * is fine-tuned on the support set D s t for task T t , and the resulting model is evaluated on the query set D q t with the post-update parameters ? t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>To alleviate the memorization overfitting issue in meta-learning, we propose MemIML, which includes a memory module and an imitation module on the grounds of a base model. The memory module is task-specific, recording the mapping behaviors between inputs and outputs of support sets for each task. The imitation module is shared across tasks and predicts values for each query-set sample by dynamically imitating the memory construction.</p><p>The acquired support set information leveraged by the imitation module augments the model initialization learning, enhancing the dependence of the model's task adaptation on support sets. Fig. <ref type="figure" target="#fig_0">1</ref> shows our model architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Memory Module</head><p>We design a memory module M i for each task T i and incorporate it in the MAML framework. In order to fully leverage information from support sets, we construct key-value pairs from support-set samples and store them in the memory module. The key is the sentence representation of a sample input from support sets obtained from an introduced key network. The corresponding value is constructed to store the information of the sample output (ground truth) as in Sec. 4.3: in NLG tasks, the value is the sentence embedding of the output sentence; in NLU tasks, the value is the one hot embedding of the class label (a scalar) of the sample. Our memory has two operations: memory writing that constructs the memory and memory reading that acquires information from memory. In the following, we elaborate on these contents in detail.</p><p>Key Network represents a sample with a vector. Specifically, we use a frozen pre-trained BERT model <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> as the key network. The input of the key network is the sample input sentence X s j ? D s i (X q j ? D q i ), and the output is the encoded representation of the first token (i.e. [CLS] token) of the sentence. The acquired representation is regarded as the key K s j for X s j (K q j for X q j ). Memory Writing constructs the memory using the information of samples in the support set D s i . For each task T i , the task-specific memory M i consists of N i memory slots (i.e. key-value pairs {K s l , V s l } N i l=1 ). To build these memory slots, we select samples from support sets and write their information into the memory. The sample selection is according to a diversity-based selection criterion <ref type="bibr" target="#b43">(Xie et al., 2015)</ref> to ensure the diversity and representativeness of the memory content. The detailed description of this criterion is in Appendix D.</p><p>For each task-specific memory module M i , we adopt the diversity score as S(M i ) on the stored keys. Here, a more diverse memory gets a higher diversity score. When the memory is not full, we directly write support-set samples without selection; otherwise, we compute the diversity score of the current memory and scores after every old key-value pair is replaced with a new key-value pair. Then we replace the old pair with the new one where the replacement can maximize the diversity score. In this way, the memory we build can carry more distinguishable and representative information and efficiently utilize the storage space.</p><p>Memory Reading obtains information from memory to enhance the meta-learning. The input is the sentence representation of the sample in query sets encoded by the key network, and the output is the memory slots similar to the query sample. Specifically, given the key representation K q j of a sample X q j ? D q i , we retrieve the top N most similar slots from its task-specific memory M i . The similarity is measured based on the Euclidean distance between K q j and each key K s l in the memory slots. The retrieved key-value pairs {K s l , V s l } N l=1 act as the output of memory reading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Imitation Module</head><p>In order to better leverage the retrieved memory and enhance the dependence of our model on support sets, we propose an imitation module to encourage the imitation of support sets behaviors when making predictions on query sets. For each sample X q j in the query set, the inputs of the imitation module are the key K q j and its retrieved N memory slots, and the output is the predicted value V q j for X q j . To achieve the imitation, we construct a value predictor that can model the behaviors of supportset samples (i.e. key-value matching) stored in the memory. For estimating the value of each query-set sample, we conduct local adaptation on the value predictor to adapt the matching.</p><p>In this way, the proposed imitation module is customized for each query-set sample, which facilitates better capture of specific task information than directly using the memory reading output, especially when tasks are versatile. The reason is that the similarity measurement of previous memory reading operations is based on the fixed BERT representations, which ignores the task-specific information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Value Predictor</head><p>In MemIML, the proposed value predictor aims to build a mapping from keys to values of the memory module mentioned in Sec. 4.1. The input of the value predictor is a key obtained from the key network, and the output is the associated value.</p><p>Specifically, we use a two-layer fully-connected network g ? with parameters ? to build the mapping. The value predictor is learned over constructed keyvalue pairs of support sets across all tasks. Given the key K q j of a query-set sample input X q j , we can then estimate its associated value as V q j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Training of The Value Predictor</head><p>To train the value predictor, we minimize the reconstruction loss L rec ? ( V , V ) to make the predicted values as close as possible to values constructed from the ground truths of support-set samples, where L rec ? is the cross-entropy loss if the value V is a label and is the mean square loss if V is a vector.</p><p>The training procedure includes the global optimization shared across tasks and the local adaptation for each specific task. Specifically, we first train the value predictor with samples from support sets of all tasks. After feeding the memory reading output of a query-set sample to this network, we perform local adaptation and employ the adapted network to estimate the value for the query sample.</p><p>Global Optimization. To obtain the taskindependent global parameters ?, we train the value predictor over constructed keys (i.e., as inputs) and values (i.e., as outputs) from support-set samples of all tasks. The global optimization keeps updating in the whole meta-training phase.</p><p>Local Adaptation. To make the value predictor adaptive to each query-set sample X q j , inspired by <ref type="bibr" target="#b32">(Sprechmann et al., 2018)</ref>, we propose local adaptation that fine-tunes the global value predictor g ? to get an adapted one with parameters ? q j . The local adaptation only works when predicting X q j . Based on the initial parameters ? from the global optimization, we perform several gradient descent steps to minimize the loss L loc , which is:</p><formula xml:id="formula_2">L loc = ? ? -? 2 2 + 1 N N l=1 L rec ? ( V s l , V s l ) (3) Here, V s l = g ?(K s l ), {K s l , V s l } N l=1</formula><p>is the memory reading output of the query-set sample, and the factor ? restricts the distance between ? q j and ?. Minimizing the second term encourages g ? q j to better estimate the retrieved memory values {V s l } N l=1 . Then we can acquire the locally adapted value prediction network g ? q j with parameters ? q j = arg min ? L loc (?). Given a query-sample key K q j , we can thus predict its associated value as V q j = g ? q j (K q j ),</p><p>where the adapted parameters ? q j are discarded thereafter, and the model does not back-propagate through V q j . In this sense, besides the task-specific parameter ? i provided by MAML, there will also be ? q j learned from support sets specific to each query-set sample. This guarantees that the model relies more on support sets for task adaptation. Fig. <ref type="figure" target="#fig_0">1</ref> (right part) illustrates the mechanism of local adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MemIML on NLP Applications</head><p>In this part, we will elaborate on two few-shot applications in NLP (i.e., text generation and text classification) to solve the memorization overfitting problem of MAML. The model structures of these applications are basically the same, except for the following three points: the base model, the way to get the value V s l stored in the memory module, and the way to leverage the output V q j of Sec. 4.2.</p><p>Personalized Dialogue Generation. The base model is the transformer <ref type="bibr" target="#b38">(Vaswani et al., 2017)</ref> consisting of an encoder and a decoder. In this task, each sample consists of an input utterance and a ground truth utterance, so the value V s l stored in the memory is obtained from the ground truth utterance Y s l of a support-set sample, which is embedded by the key network followed by an LSTM <ref type="bibr" target="#b9">(Hochreiter and Schmidhuber, 1997)</ref>. This LSTM is optimized with the base model. The V q j , concatenated with the encoder outputs, serves as a new input for the decoder. Hence, we acquire the prediction of a query-set sample via ? q j = Decoder([ V q j ; Encoder(X q j )]).</p><p>Multi-domain Sentiment Classification. The base model is a BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> followed by a fully-connected network. Each sample consists of an input sentence and a sentiment label (ground truth), so the memory value V s l is the sentiment label. To leverage V q j , we interpolate it with the original output of the base model ? q j as</p><formula xml:id="formula_4">? q j = ? ? q j + (1 -?) V q j (5)</formula><p>where ? balances ? q j and V q j . Notice that the interpolation not only works on the prediction output but also guides the training via gradient descent based on the interpolated output. We verify the effectiveness of the interpolation in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Memory Imitation Meta-training</head><p>Require: p(T ): task distribution, ?1-4: step sizes 1: Initialize ? from pretrained model; initialize ? randomly; initialize memory for T tasks as {Mi} T i=1 = {?} T j=1 2: while not converge do 3:</p><p>Sample batch of tasks {Ti} n i=1 , where Ti ? p(T )</p><p>4:</p><p>for all task Ti do 5:</p><p>Sample support set D s i and query set D q i from Ti 6:</p><p>Obtain the keys {K s l } N s l=1 and the values {V s l } N s l=1 for the support set D s i as in Sec. 4.1 7:</p><formula xml:id="formula_5">Mi ? {&lt; K s l , V s l &gt;} N s l=1 # Write memory 8: ? ? ? -?1??L rec # Global optimization 9: ? i ? ? -?2? ? L base # Learn ? i in Eq. 2 10:</formula><p>for (X q j , Y q j ) in D q i do 11:</p><p>Obtain the keys K q j for each sample X q j 12:</p><p>Retrieve N nearest neighbors of K q j from Mi.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>? q j ? ? -?3??L loc # Local adaptation 14:</p><p>V q j = g ? q j (K q j ) # Predict memory output 15:</p><p>Predict ? q j as in Sec. 4.3 16:</p><p>end for 17:</p><p>end for</p><formula xml:id="formula_6">18: Update ? ? ? -?4? ? T i ?p(T ) L base T i ,? i ( ? q , Y q )</formula><p>19: end while </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Theoretical Analysis</head><p>We theoretically investigate how our method helps to alleviate the memorization overfitting problem. Following <ref type="bibr" target="#b46">Yin et al. (2020)</ref>, we use mutual information I( ? q i ; D s i |?, X q i ) to measure the level of the memorization overfitting. When the learned model ignores support sets to predict query sets, I( ? q i ; D s i )|?, X q i ) = 0 occurs, which indicates the complete memorization overfitting in metalearning <ref type="bibr" target="#b46">(Yin et al., 2020)</ref>. Hence, lower mutual information means more serious memorization overfitting issues.</p><p>We propose a criterion similar to <ref type="bibr" target="#b45">(Yao et al., 2021)</ref> to measure the validity of our method for tackling this problem. For a task T i = {D s i , D q i }, the criterion aims to mitigate the memorization overfitting by enhancing the model's dependence on the support set D s i , i.e. increasing the mutual information between support set and ? q i as follows:</p><formula xml:id="formula_7">I( ? q i ;[D s i , M i ] | ?, X q i ) &gt; I( ? q i ; D s i | ?, X q i ),<label>(6)</label></formula><p>where M i means additional memory information we provide, which contains support sets information to augment the inference of the sample X q i in D q i . We demonstrate our method MemIML meets the above criterion (See details in Appendix A.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">The Procedure of Training and Testing</head><p>In the meta-training phase (shown in Alg. 1), MemIML first constructs an empty memory for each task and then follows the bi-level optimization process of MAML. In the inner loop, MemIML adapts the base model initialization ? to taskspecific parameters via training on the support set. At the same time, from each support-set sample, MemIML obtains a key-value pair and determines whether to write it into the memory or not. Then, MemIML conducts the global optimization of the value predictor over these key-value pairs. In the outer loop, each sample of the query set reads the memory to retrieve the most similar memory slots. Local adaptation fine-tunes the value predictor on those retrieved slots. Next, the adapted value predictor estimates the value of each query sample and uses it to augment the learning of the model initialization. The total loss function in the inner loop is L total = L base + L rec , where</p><formula xml:id="formula_8">L base = L(f (X s ), Y s ) is the cross-entropy loss.</formula><p>The procedure of meta-training and meta-testing are almost the same except that meta-testing does not optimize the learned model initialization ? and the initial parameter ? of the value predictor. For each task T t in the meta-testing phase, MemIML also adapts ? to task-specific parameters ? i in the inner-loop and constructs the task-specific memory. In the outer-loop, MemIML retrieves key-value pairs from the memory to conduct local adaptation based on the initial parameter ?. The estimated value V q t from local adaptation helps the base model to infer the final output ? q t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Analysis</head><p>Experiments on personalized dialogue generation and multi-domain sentiment classification verify our model on text generation and classification, respectively, where we use Persona-Chat and ARSC datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Personalized Dialogue Generation</head><p>Dataset. Following <ref type="bibr" target="#b48">(Zhang et al., 2018)</ref>, we use Persona-chat <ref type="bibr" target="#b17">(Madotto et al., 2019)</ref>  model over all the training tasks ignoring the speakers' personality. Fine-tune: We fine-tune the pretrained base model on the support sets of each metatesting task. MAML: We apply MAML <ref type="bibr" target="#b17">(Madotto et al., 2019)</ref> to the base model. MR-MAML: Yin et al. ( <ref type="formula">2020</ref>) tackle the memorization overfitting of MAML via regularization.</p><p>Metrics. Automatic evaluation has three aspects,</p><p>? Quality: BLEU-n <ref type="bibr" target="#b22">(Papineni et al., 2002</ref><ref type="bibr">), CIDEr (Vedantam et al., 2015)</ref>, and ROUGE <ref type="bibr" target="#b16">(Lin, 2004)</ref> measures the n-gram matching between the generated response and ground truth. PPL (perplexity) measures the sentence fluency. ? Diversity. Dist-n <ref type="bibr" target="#b14">(Li et al., 2016)</ref> evaluates the response diversity by counting unique n-grams. ? Consistency: C score <ref type="bibr" target="#b17">(Madotto et al., 2019)</ref> measures the consistency between the generated responses and persona descriptions through a pretrained natural language inference model.</p><p>Human evaluation consists of Quality and Consistency. (See details in Appendix B.1).</p><p>Overall Performance. As shown in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Fine-tune outperforms Base Model in all metrics, which verifies that the task-specific data is helpful to its performance on specific tasks. Compared to Fine-tune, MAML behaves better on diversity and consistency but behaves worse on quality. Pretraining the base model achieves the best perplexity (lowest PPL) as shown by Base Model and Fine-tune. We analyze that it's because pretraining leads to a considerable degree of fluency in their generated utterances and is careless about each task's specific information, resulting in low consistency with tasks. Our model, MemIML, performs the best in most aspects, including quality, diversity, and task consistency. In particular, MemIML significantly improves MR-MAML in alleviating the memorization overfitting issue, suggesting that memory imitation is more effective than only regularizing model initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multi-domain Sentiment Classification</head><p>Dataset. Amazon Review sentiment classification dataset (ARSC) <ref type="bibr" target="#b47">(Yu et al., 2018)</ref> contains 69 tasks in total. Following <ref type="bibr" target="#b6">(Geng et al., 2019)</ref>, we build a 2-way 5-shot meta-learning with 57 tasks for meta-training and 12 tasks for meta-testing.</p><p>We conduct experiments on the ARSC <ref type="bibr" target="#b47">(Yu et al., 2018)</ref>. It contains English reviews of 23 types of Amazon products, where each product consists of three different binary classification tasks. Following Geng et al. ( <ref type="formula">2019</ref>), we select 12 tasks from 4 domains (Books, DVD, Electronics, Kitchen) for meta-testing tasks, and the support sets of these tasks are fixed <ref type="bibr" target="#b47">(Yu et al., 2018)</ref>.</p><p>Baselines. We compare our methods with the following baselines: Fine-tune: We fine-tune a pre-trained BERT on the support set of metatesting tasks (non-meta-learning method) as in Appendix B.2. We choose five metric-based meta-learning baselines: Matching Net <ref type="bibr" target="#b40">(Vinyals et al., 2016)</ref>, Prototypical Net <ref type="bibr" target="#b30">(Snell et al., 2017)</ref>, Proto ++, <ref type="bibr" target="#b27">(Ren et al., 2018)</ref>, Relation Net <ref type="bibr" target="#b34">(Sung et al., 2018)</ref>, and Induction Net <ref type="bibr" target="#b6">(Geng et al., 2019)</ref>. We apply an optimization-based baseline (MAML) <ref type="bibr" target="#b5">(Finn et al., 2017)</ref> to the base model, and implement some approaches tackling the memorization overfitting problem based on MAML: MR-MAML <ref type="bibr" target="#b46">(Yin et al., 2020)</ref>, MetaMix, <ref type="bibr" target="#b45">(Yao et al., 2021)</ref> and Meta-Aug <ref type="bibr" target="#b25">(Rajendran et al., 2020)</ref>.</p><p>Overall Performance. Table <ref type="table" target="#tab_1">2</ref> shows the performance measured by the mean accuracy of meta-testing tasks. Our model, MemIML outperforms all competing approaches including nonmeta-learning, metric-based meta-learning, and optimization-based meta-learning methods. Particularly, our model surpasses the current solutions to the memorization overfitting problem (MR-MAML, Meta-Aug, MetaMix), indicating that our method is more effective compared to regularization and textual augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Memorization Overfitting Analysis</head><p>In Figure <ref type="figure" target="#fig_1">2</ref>, the gaps of the losses on query sets between pre-update ? (before training on support sets)   In Figure <ref type="figure" target="#fig_1">2</ref> (c), MemIML has large gaps between ? and ? i , implying that ? i better leverages support sets when adapting to new tasks and thus alleviates the memorization overfitting issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Studies</head><p>In Table <ref type="table" target="#tab_2">3</ref>, we conduct ablation studies to verify the effectiveness of each component. Removing Similarity-Search means the memory reading operation randomly outputs memory slots instead of searching for similar memory slots. This variant underperforms MemIML, indicating that similar samples stored in the memory provide more useful information to improve the model performance.</p><p>Removing the value predictor means directly using the memory output without a learnable network. Its results are not too bad, indicating that the memory module helps to mitigate the memorization overfitting problem. However, this usage simply aggre-gates the support set information into the query set, which is not as precise as learning the information required by the query set itself. Therefore, it is still inferior to our model. Removing Local adaptation means we only use the global value predictor to estimate the memory output. It is crucial to the value predictor since removing it from the value predictor results in an even worse performance than removing the value predictor. Besides, the significant drop in task consistency (C-score) shows that local adaptation contributes a lot to making the model adaptive to specific tasks, as it learns to adapt to each query-set sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Analysis of Memory Operations</head><p>Memory Size. In Table <ref type="table" target="#tab_3">4</ref> and<ref type="table" target="#tab_4">5</ref> Number of Neighbors. We also investigate the effects of different numbers of neighbors for the model performance in Table <ref type="table" target="#tab_3">4</ref> and<ref type="table" target="#tab_4">Table 5</ref>. In both datasets, the model performs better with a larger number of neighbors. However, when the number of neighbors is too large, the model retrieves some dissimilar slots from the memory module. These dissimilar slots bring much noise, which makes the predictions of query samples inaccurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Case Study</head><p>We present two generated in personalized dialog in Table . 6. Base Model, Fine-tune, and MAML generate general responses with little useful information or responses that are not consistent with the personality of personas. MR-MAML generates irrelevant responses to the dialogue context. Our model not only responds coherently to the dialog history but also caters to the persona descriptions of each user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we tackle the memorization overfitting problem of meta-learning for text classification and generation applications. We propose MemIML to enhance the dependence of the model on the support sets for task adaptation. MemIML introduces a memory module storing the information of support sets, and propose an imitation module to better leverage the support set information by imitating the behaviors of the memory. Both empirical and theoretical results demonstrate that our method MemIML effectively alleviates the memorization overfitting problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Ethical Considerations</head><p>The persona-based dialogue generation task aims to build a dialogue model which generates meaningful, fluent, and consistent responses. It will facilitate human-computer interactions in practice. However, the training of the model for personalized  dialogues may lead to the leakage of personal privacy information. In this work, the data source we use is from a published dataset and does not involve privacy issues for the data collection. Our proposed method does not include inference or judgments about individuals and does not generate any discriminatory, insulting responses. Our work validates the proposed method and baseline models on human evaluation which involves manual labor. We hire five annotators to score 750 generated sentences in total (250 sentences for each model we evaluate). The hourly pay is set to 15 US$ per person, which is higher than the local statutory minimum wage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: The architecture of our model, MemIML. The left area details the procedure of predicting a query-set sample X q j in each task with a task-specific memory module and an imitation module shared across tasks. The right area illustrates the local adaption of the value predictor. The two green areas represent the neighboring areas of the global parameters ? for two query-set samples in one task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Memorization overfitting analysis on Persona-Chat. Small loss gaps between pre-update ? and postupdate ? i (in MAML and MR-MAML) indicate the serious memorization overfitting issue (i.e., the gap between sky-blue and blue curves in meta-training and the gap between pink and red curves in meta-testing). The large gap in MemIML demonstrates the effectiveness of our method.</figDesc><graphic url="image-2.png" coords="8,231.88,70.87,131.52,91.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Overall performance over Persona-Chat dataset. The results with * indicate that the improvements of our model overall baselines are statistically significant with p &lt; 0.05 under t-test.</figDesc><table><row><cell>Methods</cell><cell>Quality</cell><cell>Automatic Metrics</cell><cell>Diversity</cell><cell>Consistency</cell><cell cols="2">Human Evaluation</cell></row><row><cell></cell><cell cols="3">PPL BLEU1 BLEU2 BLEU3 BLEU4 ROUGE CIDEr Dist1 Dist2 Dist3 Dist4</cell><cell cols="3">C-score Quality Consistency</cell></row><row><cell cols="4">Base Model 38.14 15.53 6.810 3.430 1.948 0.163 0.136 0.006 0.023 0.048 0.080</cell><cell>-0.024</cell><cell>0.689</cell><cell>0.395</cell></row><row><cell cols="4">Fine-tune 34.14 16.10 7.222 3.678 2.100 0.166 0.147 0.007 0.028 0.063 0.111</cell><cell>0.012</cell><cell>0.886</cell><cell>0.641</cell></row><row><cell>MAML</cell><cell cols="3">43.24 15.56 7.456 3.858 2.229 0.172 0.152 0.013 0.046 0.099 0.169</cell><cell>0.156</cell><cell>0.807</cell><cell>0.651</cell></row><row><cell cols="4">MR-MAML 52.52 13.35 5.571 2.783 1.601 0.142 0.110 0.004 0.011 0.021 0.034</cell><cell>0.132</cell><cell>0.512</cell><cell>0.562</cell></row><row><cell cols="4">MemIML 41.61 16.23* 7.941* 4.295* 2.557* 0.183* 0.173* 0.014* 0.053* 0.114* 0.195*</cell><cell>0.241*</cell><cell>0.932</cell><cell>0.807</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The results of mean accuracy over the ARSC. * indicates that our improvement overall baselines is statistically significant with p &lt; 0.01 under t-test.</figDesc><table><row><cell>by regarding</cell></row></table><note><p>Baselines. We compare our methods with the following baselines: Base Model: We pretrain a conventional transformer-based dialog generation</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablation Studies. -means deleting MemIML's components.</figDesc><table><row><cell cols="4">Memory Analysis on ARSC</cell></row><row><cell cols="4">Store ratio Acc # Neighbors Acc</cell></row><row><cell>100%</cell><cell>84.91</cell><cell>5</cell><cell>84.04</cell></row><row><cell>80%</cell><cell>85.69</cell><cell>10</cell><cell>84.47</cell></row><row><cell>50%</cell><cell>84.84</cell><cell>20</cell><cell>85.69</cell></row><row><cell>20%</cell><cell>84.35</cell><cell>50</cell><cell>85.04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Memory analysis on ARSC.</figDesc><table><row><cell>and post-update ? i (after training on support sets)</cell></row><row><cell>indicate the memorization overfitting problem. The</cell></row><row><cell>gap between sky-blue and blue curves measures</cell></row><row><cell>the memorization overfitting of meta-training (the</cell></row><row><cell>gap between pink and red curves measures meta-</cell></row><row><cell>testing). Small loss gaps indicate a severe memo-</cell></row><row><cell>rization overfitting where support sets are almost</cell></row><row><cell>useless for task adaptation. Those loss gaps be-</cell></row><row><cell>tween ? and ? i collapse in MAML and MR-MAML</cell></row><row><cell>after about 3000 steps. This indicates that the post-</cell></row><row><cell>update ? i barely benefits from the support set, and</cell></row><row><cell>thus the memorization overfitting issue is severe.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>, we investigate the variants of our task-specific memory module of different sizes. We control the memory size through |M | = store ratio ? |D s |. Analysis of Persona-Chat dataset.</figDesc><table><row><cell>The results</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Where are you from? I grew up in South Carolina. B: I was born in Arkansas, but I now live in Chicago. A: Did you go to college there? B: Yes, I am in school now while working parttime as a barista.</figDesc><table><row><cell></cell><cell>I am a professional singer.</cell></row><row><cell>Persona A</cell><cell>I graduated from USC. I love watching horror films.</cell></row><row><cell></cell><cell>I was born in South Carolina.</cell></row><row><cell cols="2">Dialogues A: Human I graduated recently from USC.My parents pushed</cell></row><row><cell>Response</cell><cell>me into it.</cell></row><row><cell>Base Model</cell><cell>What do you do for a living?</cell></row><row><cell>Fine-tune</cell><cell>Are you in trouble?</cell></row><row><cell>MAML</cell><cell>Do you work in the fitness industry?</cell></row><row><cell>MR-MAML</cell><cell>That sounds illegal. Are they not protected?</cell></row><row><cell>MemIML</cell><cell>That would be cool! I love horror films.</cell></row><row><cell></cell><cell>I have a large garden.</cell></row><row><cell>Persona A</cell><cell>My hobby is walking. I love to travel.</cell></row><row><cell></cell><cell>I teach biology at a college.</cell></row><row><cell></cell><cell>B: Hi, Merna here. Single, 32 and scared of dogs.</cell></row><row><cell>Dialogues</cell><cell>You? A: I am dave, 40.</cell></row><row><cell></cell><cell>B: Oh, okay. I am a good cook!</cell></row><row><cell>Human</cell><cell>Cool, I grow my own vegetables in my garden gar-</cell></row><row><cell>Response</cell><cell>den.</cell></row><row><cell>Base Model</cell><cell>What do you do for a living?</cell></row><row><cell>Fine-tune</cell><cell>What do you teach?</cell></row><row><cell>MAML</cell><cell>What do you do?</cell></row><row><cell>MR-MAML</cell><cell>I am doing great. How are you tonight?</cell></row><row><cell>MemIML</cell><cell>Oh, i am a science teacher and love travel.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Two generated examples in the Persona-Chat dataset. Colored texts indicate that the responses match the personality descriptions.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Memorization overfitting is different from the overfitting in conventional supervised learning(Hawkins,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2004). The latter means that the model overfits to the training tasks and fails to generalize to the testing tasks.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Research on this paper was supported by <rs type="funder">Hong Kong Research Grants Council</rs> (Grant No. <rs type="grantNumber">16204920</rs>) and <rs type="funder">National Natural Science Foundation of China</rs> (Grant No. <rs type="grantNumber">62106275</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qbSWpTD">
					<idno type="grant-number">16204920</idno>
				</org>
				<org type="funding" xml:id="_bzVkvVW">
					<idno type="grant-number">62106275</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Validity of Memory Imitation Strategy</head><p>Proof of inequality in Eqn. 6. We check the validity of memory imitation by examining whether the criterion in Section 4.4 is met. We check the increase of mutual information between predictions of query sets with the provided support-set information after augmented with the memory information M.</p><p>For short, we use notation Z = (X q , X s , Y s , ?) to denote a set of variables. Then we can rewrite ( <ref type="formula">7</ref>) as</p><p>Note that trivially, we have E M [1] = 1, so we get</p><p>since p( ? q , Z) does not rely on the variable M. Hence, we can just write E ? q ,Z,M as E for short.</p><p>Then the equation (7) will become to</p><p>where the last inequality holds due to ? q is dependent on M.</p><p>We also investigate that memory imitation improves the learning of model initialization via another criterion I(?; [D q , M]|D q ) &gt; 0 following <ref type="bibr" target="#b45">Yao et al. (2021)</ref>. This criterion guarantees that the additional memory knowledge contributes to updating the initialization in the outer loop. Since all the meta-training tasks satisfy this criterion, the generalization ability of the model initialization improves.</p><p>Proof.</p><p>Experimental Setup. We implement our model based on the transformer <ref type="bibr" target="#b2">(Dehghani et al., 2018;</ref><ref type="bibr" target="#b38">Vaswani et al., 2017)</ref> with pre-trained Glove embedding <ref type="bibr" target="#b23">(Pennington et al., 2014)</ref> following <ref type="bibr" target="#b17">(Madotto et al., 2019)</ref>. The hidden dimensions of the LSTM unit are set to 1024. We set the number of neigh- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Multi-domain Sentiment Classification</head><p>Experimental Setup. We utilize a BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> as the encoder. We fine-tune the off-the-shelf pre-trained BERT on the masked language modeling task following <ref type="bibr" target="#b4">(Dopierre et al., 2021)</ref> as it greatly improves embeddings' quality <ref type="bibr" target="#b33">(Sun et al., 2019)</ref>. The fine-tuned BERT is then used as the initialization for all few-shot models. We use Adam (Kingma and Ba, 2015) optimizer for both inner and outer loop update with learning rate 2e -5 and 1e -5 respectively, and we set ? = 0.2 in Eqn. 5, the number of neighbors N = 20 and the number of local adaptation steps L = 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Effectiveness of the Interpolation</head><p>To measure whether MemIML improves the learned model initialization, we add an experiment that does not incorporate the memory module during meta-testing (i.e., ? = 1 in Eq. 5) for the multi-domain sentiment classification task.  2 (Kj, K h ) = arccos(</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Diversity-selection Criterion</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Memory matching networks for oneshot image recognition</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenggang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4080" to="4088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">An empirical survey of data augmentation for limited data learning in nlp</title>
		<author>
			<persName><forename type="first">Jiaao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">2106</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Universal transformers</title>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A neural few-shot text classification reality check</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Dopierre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Gravier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilfried</forename><surname>Logerais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16</title>
		<meeting>the 16</meeting>
		<imprint>
			<publisher>Main Volume</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="935" to="943" />
		</imprint>
	</monogr>
	<note>th Conference of the European Chapter</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Induction networks for text classification</title>
		<author>
			<persName><forename type="first">Ruiying</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binhua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3904" to="3913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Meta-learning for lowresource neural machine translation</title>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3622" to="3631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The problem of overfitting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><surname>Hawkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and computer sciences</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to learn to disambiguate: Meta-learning for few-shot word sense disambiguation</title>
		<author>
			<persName><forename type="first">Nithin</forename><surname>Holla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushkar</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4517" to="4533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Meta-learning in neural networks: A survey</title>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2021.3079209</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ofir</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03129</idno>
		<title level="m">Learning to remember rare events</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR (Poster)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Metamt, a meta learning method leveraging multiple domain data for low resource machine translation</title>
		<author>
			<persName><forename type="first">Rumeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8245" to="8252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Personalizing dialogue agents via meta-learning</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5454" to="5459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Meta-learning for low-resource natural language generation in task-oriented dialogue systems</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiyong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boi</forename><surname>Faltings</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05644</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Metalearned neural memory</title>
		<author>
			<persName><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="13331" to="13342" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Meta networks</title>
		<author>
			<persName><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2554" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Meta-learning improves lifelong relation extraction</title>
		<author>
			<persName><forename type="first">Abiola</forename><surname>Obamuyide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Domain adaptive dialog generation via meta learning</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2639" to="2649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Meta-learning requires meta-augmentation</title>
		<author>
			<persName><forename type="first">Janarthanan</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Irpan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5705" to="5715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adaptive posterior learning: few-shot learning with a surprisebased memory module</title>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Metalearning for semi-supervised few-shot classification</title>
		<author>
			<persName><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Metalearning with memory-augmented neural networks</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Meta-learning for few-shot nmt adaptation</title>
		<author>
			<persName><forename type="first">Amr</forename><surname>Sharaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NGT@ ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4080" to="4090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to customize model structures for few-shot dialogue generation tasks</title>
		<author>
			<persName><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zequn</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5832" to="5841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adria Puigdomenech Badia, Benigno Uria, Oriol Vinyals, Demis Hassabis, Razvan Pascanu, and Charles Blundell</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Sprechmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><surname>Pritzel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Memorybased parameter adaptation. International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">How to fine-tune bert for text classification?</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yige</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">China National Conference on Chinese Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="194" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Philip Hs Torr</surname></persName>
		</author>
		<author>
			<persName><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning to Learn: Introduction and Overview. Learning to Learn: Introduction and Overview</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning from my friends: Few-shot personalized conversation systems via social networks</title>
		<author>
			<persName><forename type="first">Zhiliang</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongkyu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nevin</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13907" to="13915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cider: Consensus-based image description evaluation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Ramakrishna Vedantam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="4566" to="4575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Mcml: A novel memory-based contrastive meta-learning method for few shot slot tagging</title>
		<author>
			<persName><forename type="first">Hongru</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zezhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Pui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheong</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.11635</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Generalizing from a few examples: A survey on few-shot learning</title>
		<author>
			<persName><forename type="first">Yaqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lionel</forename><forename type="middle">M</forename><surname>Ni</surname></persName>
		</author>
		<idno type="DOI">10.1145/3386252</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Diversifying restricted boltzmann machine for document modeling</title>
		<author>
			<persName><forename type="first">Pengtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1315" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multi-source meta transfer for low resource multiple-choice question answering</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.654</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7331" to="7341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Improving generalization in meta-learning via task augmentation</title>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long-Kai</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="11887" to="11897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Metalearning without memorization</title>
		<author>
			<persName><forename type="first">Mingzhang</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Diverse few-shot text classification with multiple metrics</title>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saloni</forename><surname>Potdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1206" to="1215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Personalizing dialogue agents: I have a dog, do you have pets too?</title>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2204" to="2213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">Yinhe</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09672</idno>
		<title level="m">Personalized dialogue generation with diversified traits</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A pre-training based personalized dialogue generation model with persona-sparse data</title>
		<author>
			<persName><forename type="first">Yinhe</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongsheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxi</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9693" to="9700" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
