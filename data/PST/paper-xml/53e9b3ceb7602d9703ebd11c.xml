<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Single View Point Omnidirectional Camera Calibration from Planar Grids</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Mei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">INRIA</orgName>
								<address>
									<addrLine>2004 Route des Lucioles -BP 93</addrLine>
									<postCode>06902</postCode>
									<settlement>Sophia-Antipolis, Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Patrick</forename><surname>Rives</surname></persName>
							<email>patrick.rives@sophia.inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">INRIA</orgName>
								<address>
									<addrLine>2004 Route des Lucioles -BP 93</addrLine>
									<postCode>06902</postCode>
									<settlement>Sophia-Antipolis, Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Single View Point Omnidirectional Camera Calibration from Planar Grids</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F0EECC2944BD040BB9FB17D536EBECCD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a flexible approach for calibrating omnidirectional single viewpoint sensors from planar grids. These sensors are increasingly used in robotics where accurate calibration is often a prerequisite. Current approaches in the field are either based on theoretical properties and do not take into account important factors such as misalignment or camera-lens distortion or over-parametrised which leads to minimisation problems that are difficult to solve. Recent techniques based on polynomial approximations lead to impractical calibration methods. Our model is based on an exact theoretical projection function to which we add well identified parameters to model real-world errors. This leads to a full methodology from the initialisation of the intrinsic parameters to the general calibration. We also discuss the validity of the approach for fisheye and spherical models. An implementation of the method is available as OpenSource software on the author's Web page. We validate the approach with the calibration of parabolic, hyperbolic, folded mirror, wide-angle and spherical sensors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Many calibration methods for omnidirectional cameras have been presented in the past few years, they differentiate themselves mainly by the type of mirror taken into account (hyperbolic or parabolic), by the projection model used (skewness, alignment errors, ...), the information that is considered as known (for example the mirror parameters) and the method used (auto-calibration, grids, ...). Non-parametric <ref type="bibr" target="#b10">[11]</ref> approaches have also been studied. These provide interesting insights into general sensor calibration but in practice a stable calibration is difficult to obtain.</p><p>Auto-calibration techniques inspired by the division model <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> have lead to uncalibrated omnidirectional structure and motion <ref type="bibr" target="#b6">[7]</ref>. However a limitation to the approach comes from the precision reported, that is well adapted to outlier rejection (RANSAC) but less satisfying for reconstruction and motion estimation. In robotics it is often a prerequisite to have accurately calibrated sensors.</p><p>In the specific case of perspective cameras, methods using planar grids <ref type="bibr" target="#b13">[14]</ref> are popular because of the simplicity of use and the accurate results they procure. This article aims at generalising this type of approach to central catadioptric sensors. We made the choice of using standard planar grids because they are commonly available and simple to make. In <ref type="bibr" target="#b9">[10]</ref>, the authors propose a method relying on a polynomial approximation of the projection function. With this model, initial values of the projection function are difficult to obtain so the user has to select each point of the calibration grid independently for the calibration. We will show that by using an exact model to which we add small errors, only four points need to be selected for each calibration grid. The parameters that appear in the proposed model can also be easily interpreted in terms of the optical quality of the sensor.</p><p>Figure <ref type="figure">1</ref> presents the different parameters that could be taken into account for example in the case of a parabolic mirror with a telecentric lens. Gonzalez-Barbosa <ref type="bibr" target="#b4">[5]</ref> describes a calibration method to estimate all of these parameters. However too many parameters make the equations difficult to minimise because of the numerous local minima, the need for a lot of data and the numerical instability introduced into the Jacobian. We decided to reduce the number of parameters by making the assumption that the errors due to the assembly of the system are small (Fig. <ref type="figure" target="#fig_0">2</ref>).</p><p>To obtain a calibration that stays valid for all central catadioptric systems, we use the unified model of Barreto-Geyer <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b0">[1]</ref> and justify its validity for fisheye and spherical sensors (Section II). In Section III we describe the different steps of the projection model. Section IV discusses the initialisation of the parameters and Section V the calibration steps. Finally, we validate the approach on real data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. UNIFIED PROJECTION MODEL</head><p>For sake of completeness, we present here a slightly modified version of the projection model of Geyer and Barreto <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b0">[1]</ref> (Fig. <ref type="figure" target="#fig_2">4</ref>). We choose the axis convention depicted in Figure <ref type="figure">3</ref>. The projection of 3D points can be done in the following steps (the values for (ξ, η) are detailed Table <ref type="table">I</ref> and the mirror equations are given in Table <ref type="table">II</ref>) :  1) world points in the mirror frame are projected onto the unit sphere, (X )</p><formula xml:id="formula_0">Fm -→ (X s ) Fm = X X = (X s , Y s , Z s )</formula><p>2) the points are then changed to a new reference frame centered in C p = (0, 0, ξ), (X s ) Fm -→(X s ) Fp = (X s , Y s , Z s + ξ) 3) we then project the point onto the normalised plane, m = ( Xs Zs+ξ , Ys Zs+ξ , 1) = (X s ) 4) the final projection involves a generalised camera projection matrix K (with [f 1 , f 2 ] the focal length, (u 0 , v 0 ) the principal point and α the skew)</p><formula xml:id="formula_1">p = Km =   f 1 η f 1 ηα u 0 0 f 2 η v 0 0 0 1   m = k(m) (1)</formula><p>A generalised camera projection matrix indicates we are no longer considering the sensor as a separate camera and mirror but as a global device. This is particularly important for calibration because it shows that f and η cannot be estimated independently. We will note γ i = f i η.</p><p>We will call lifting the calculation of the X s corresponding to a given point m (or p according to the context) :</p><formula xml:id="formula_2">-1 (m) =      ξ+ √ 1+(1-ξ 2 )(x 2 +y 2 ) x 2 +y 2 +1 x ξ+ √ 1+(1-ξ 2 )(x 2 +y 2 ) x 2 +y 2 +1 y ξ+ √ 1+(1-ξ 2 )(x 2 +y 2 ) x 2 +y 2 +1 -ξ      (<label>2</label></formula><formula xml:id="formula_3">) TABLE I UNIFIED MODEL PARAMETERS ξ η Parabola 1 -2p Hyperbola d √ d 2 +4p 2 -2p √ d 2 +4p 2 Ellipse d √ d 2 +4p 2 2p √ d 2 +4p 2 Planar 0 -1 d : distance between focal points 4p : latus rectum TABLE II MIRROR EQUATIONS Parabola p x 2 + y 2 + z 2 = z + 2p Hyperbola (z+ d 2 ) 2 a 2 -x 2 b 2 -y 2 b 2 = 1 Ellipse (z+ d 2 ) 2 a 2 + x 2 b 2 + y 2 b 2 = 1 Plane z = -d 2</formula><p>With '-' for a hyperbola and '+' for an ellipse :</p><formula xml:id="formula_4">a = 1/2( p d 2 + 4p 2 ± 2p) b = q p( p d 2 + 4p 2 ± 2p)</formula><p>a) Validity for fish-eye lenses: In <ref type="bibr" target="#b12">[13]</ref>, the authors show that the unified projection model can approximate fisheye projections. A point imaged by perspective projection can be written:</p><formula xml:id="formula_5">m u = (x, y, 1) = ( X Z , Y Z , 1)</formula><p>with ξ = 1, the same point imaged by the unified projection model gives:</p><formula xml:id="formula_6">m d = ( X Z + X , Y Z + X , 1)</formula><p>By algebraic manipulation, we obtain the following relation:</p><formula xml:id="formula_7">ρ u = 2ρ d 1 -ρ 2 d , with ρ = m 2 x + m 2 y</formula><p>which is the division model, known to approximate a large range of fisheye lenses <ref type="bibr" target="#b1">[2]</ref>. b) Validity for spherical mirrors: A spherical sensor does not have a single viewpoint. However the results obtained by approximating it by a single projection center give satisfying results <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROJECTION MODEL</head><p>Compared to the theoretical model, an extra distortion function is added that models the misalignment between the mirror and camera but also the telecentric distortion (ie. the deviation of the telecentric lens's projection function from the ideal, orthographic projection model) for the parabolic case. The different transformations that intervene and the associated unknowns (Fig. <ref type="figure" target="#fig_0">2</ref>) are:</p><p>1) rotation and translation from the grid reference frame to the mirror reference frame (extrinsic parameters), 2) reflexion on the mirror and projection of the points on the normalised plane (mirror parameter ξ), 3) application of the distortion induced by the lens(es) (distortion parameters), 4) projection in the image with the generalised camera projection matrix (camera intrinsic parameters).</p><p>Had we considered the system as a separate mirror and camera, the distortion would have been applied before the collineation induced by η. The effect is however the same as it consists only in a change of variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FrC2.3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Extrinsic parameters</head><p>The extrinsic parameters describe the transformation between the grid frame and the camera frame. Quaternions can be used advantageously to parametrise the rotation <ref type="bibr" target="#b8">[9]</ref>. We will note V 1 = [q w1 q w2 q w3 q w4 t w1 t w2 t w3 ] the unknowns and W the corresponding transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Mirror transformation</head><p>The mirror transformation was detailed in Section II and consists simply in applying that depends only on</p><formula xml:id="formula_8">V 2 = [ξ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Distortion</head><p>We will consider two main sources of distortion <ref type="bibr" target="#b11">[12]</ref> : imperfection of the lens shape that are modeled by radial distortion and improper lens and camera assembly (which can also include misalignment between the camera optical axis and the mirror rotational axis) that generate both radial and tangential errors. In the case of a paracatadioptric sensor, an extra telecentric lens is often added to enable the use of a perspective camera (and not orthographic). The lens has the same size as the mirror border and introduces radial errors.</p><p>Five parameters can be used to model the distortion <ref type="bibr" target="#b5">[6]</ref>. A three parameter model was chosen for the radial distortion (with ρ = x 2 + y 2 ) :</p><formula xml:id="formula_9">L(ρ) = 1 + k 1 ρ 2 + k 2 ρ 4 + k 5 ρ 6<label>(3)</label></formula><p>Different models can be used for the tangential distortion according to the relative importance of the alignment and angular errors. We added two extra variables to model the tangential distortion dx :</p><formula xml:id="formula_10">dx = 2k 3 xy + k 4 (ρ 2 + 2x 2 ) k 3 (ρ 2 + 2y 2 ) + 2k 4 xy (4)</formula><p>We will note D the distortion function and</p><formula xml:id="formula_11">V 3 = [k 1 k 2 k 3 k 4 k 5 ] the parameters.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Camera model</head><p>A standard pin-hole model was used for the generalised camera projection P :</p><formula xml:id="formula_12">P (X, V 4 ) = γ 1 (x + αy) + u 0 γ 2 y + v 0 , V 4 = [α γ 1 γ 2 u 0 v 0 ]<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Final equation</head><p>Let G be the composition of the different projection functions and let V be the 18 parameters :</p><formula xml:id="formula_13">G = P • D • H • W, V = [V 1 V 2 V 3 V 4 ]</formula><p>If the grid is composed of m points g i , with their associated image values e i , the solution to the calibration problem can be obtained by minimising the following function :</p><formula xml:id="formula_14">F (x) = 1 2 m i=1 [G(V, g i ) -e i ] 2<label>(6)</label></formula><p>This cost function minimises the euclidean distance between the projection of the grid and the extracted values in the image. The corresponding Jacobians can be written as :</p><formula xml:id="formula_15">∂G ∂V = ∂P ∂D 2×2 ∂D ∂H 2×2 ∂H ∂W 2×2 ∂W ∂V 1 2×7 ∂H ∂V 2 2×1 . . . ∂D ∂V 3 2×5 2×12 ∂P ∂V 4 2×5 2×18<label>(7)</label></formula><p>IV. INITIALISATION OF THE PARAMETERS The presented method is based on the non-linear minimisation of (6) that can be solved using for example a Levenberg-Marquardt approach. For the minimisation to be successful, we need to obtain initial estimates of the parameters.</p><p>By assuming that the errors from the theoretical model are small, we have</p><formula xml:id="formula_16">k 1 ≈ k 2 ≈ k 3 ≈ k 4 ≈ k 5 ≈ α ≈ 0, γ 1 ≈ γ 2 .</formula><p>We still need to find the extrinsic parameters of the grids and values for [ξ, γ, u 0 , v 0 ]. The image center can be used to initialise the principal point (u 0 , v 0 ) or it can be approximated by the center of the mirror border (assumed to be a circle).</p><p>Experimentally, we will show that errors in the values of (ξ, γ) do not have a strong influence over the accuracy of the extraction process (Section VI-F). We will start by assuming ξ = 1 and show that we can estimate linearly the focal length from at least three image points that belong to a non-radial line image. Once this step applied, the extrinsic parameters can be estimated from four points of a grid of known size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Mirror border extraction for principal point estimation</head><p>The mirror border extraction is not straight forward because of the density of information around the mirror edge. However from an estimate of the mirror radius and center given by the user (for example by clicking on an image), we can refine the values by applying the following steps :</p><p>1) remove the points that are too far from the given circle, 2) remove the points on the rays between the center and the edge points, 3) from the remaining points, create a list of possible circle centers and radii by random sampling. The median values of the lists give a robust estimate of the mirror center and radius.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Estimation of the generalised focal length</head><p>From equation ( <ref type="formula" target="#formula_2">2</ref>), with ξ = 1, we obtain:</p><formula xml:id="formula_17">-1 (m) ∼   x y f (x, y)   , f(x, y) = 1 2 - 1 2 (x 2 + y 2 ) (8)</formula><p>Let p = (u, v) be a point in the image plane. Thanks to the estimate of the principal point, we can center the points and calculate a corresponding point p c = (u c , v c ). This point follows the equation on the normalised plane that depends on γ: p c = γm:</p><formula xml:id="formula_18">-1 (m) ∼   u c v c g(u c , v c )   , g(m) = γ 2 - 1 2γ (u 2 c + y 2 c ) (9)</formula><p>FrC2.3</p><p>If this point belongs to a line image defined by the normal N = n x n y n z , we obtain:</p><formula xml:id="formula_19">-1 (m) N = 0 ⇐⇒      n x u c + n y v c + a 2 -b u 2 c +v 2 c 2 = 0 a = γn z b = nz γ</formula><p>Let us assume, we have n points p 1 , p 2 , ..., p n belonging to a same line image, they verify the system :</p><formula xml:id="formula_20">P n×4 C 4×1 = 0, with P =     u c1 v c1 1 2 - u 2 c1 +v 2 c1 2 . . . . . . . . . . . . u cn v cn 1 2 - u 2 cn +v 2 cn 2    </formula><p>By singular value decomposition (SVD) P = USV , the least square solution is obtained from the last column of V associated to the minimal singular value.</p><p>To obtain N and in particular γ from C = [c 1 c 2 c 3 c 4 ] , the following steps can be applied:</p><formula xml:id="formula_21">1) Calculate t = c 2 1 + c 2 2 + c 3 c 4 and check that t &gt; 0. 2) Let d = 1/t, n x = c 1 d and n y = c 2 d.</formula><p>3) We check that n 2</p><p>x + n 2 y &gt; thresh (with for example thresh = 0.95) to be sure the line image is not radial, 4) If the line is not radial, n z = 1n 2</p><p>xn 2 y . 5) Finally, γ = c3d nz If the user selects three points or more on a line image, we can obtain an estimate of the focal length. (This process can in fact be applied to three randomly chosen points in the image to obtain an estimate of the focal length in a RANSAC fashion. This way we obtain an auto-calibration approach.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CALIBRATION STEPS</head><p>We suggest the following calibration steps to initialise the unknown parameters, make the associations between the grid points and their reprojection in the image and finally launch the minimisation: 1) (Optional) the user selects the mirror center and a point on the mirror border. The values are then re-estimated to obtain the center of the circle that is an estimate of the principal point (u 0 , v 0 ) (Fig. <ref type="figure" target="#fig_3">5</ref>). Alternatively, the center of the image is used, 2) the user selects at least three non-radial points belonging to a line image, from here we estimate the focal length γ (Fig. <ref type="figure">6</ref>), 3) for each calibration image, the user is then asked to select the four grid corners and the extrinsic parameters are estimated (Fig. <ref type="figure" target="#fig_4">7</ref>), 4) the grid pattern is then reprojected and a sub-pixel accuracy extraction is performed (Fig. <ref type="figure">8</ref>), 5) we can then perform the global minimisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-pixel point extraction:</head><p>The sub-pixel point extraction for perspective cameras stays locally valid for omnidirectional sensors. Our calibration approach was tested with five different configurations: parabolic, hyperbolic, folded mirror, wideangle and spherical sensors. A different camera was used each time. Care was taken to obtain points over the entire field of view for each sensor. An image was set aside during the calibration and then used to validate the intrinsic parameters.</p><p>To validate our model, we need to obtain a low residual error after minimisation and a uniform distribution of the error. It is not necessary do check the error distribution over the complete image as we assume a rotational symmetry of the sensor. For each calibration, we will show the radial distribution of the fitting error with a curve representing the median value of the fitting error for different intervals of ρ.</p><p>We may note that polynomial approximations are often valid only locally and badly approximate the projection around the edges. This bias will have a negative impact for  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Calibration of the parabolic sensor</head><p>The parabolic sensor (ξ = 1) used in this study consists of a S80 parabolic mirror from RemoteReality with a telecentric lens and a perspective camera with an image resolution of 2048 × 1016. The calibration points were obtained from 8 images of a grid of size 6 × 8 with squares of 42 mm. Table <ref type="table">III</ref> summarises the results. After minimisation, we can see that the error is correctly distributed over the image (Fig. <ref type="figure" target="#fig_6">9</ref>). Distortion: If we do not take into account the distortion during the calibration, the error increases to [0.74, 0.82] which confirms that the radial distortion function is needed to account for the error induced by the telecentric lens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Calibration of the hyperbolic sensor</head><p>In the hyperbolic case, the mirror is a HM-N15 from Accowle (Seiwapro) with a perspective camera with an image resolution of 800 × 600. 6 images of a grid of size 8 × 10 with squares of 30 mm were taken. Table <ref type="table" target="#tab_1">IV</ref> summarises the results. After minimisation, we can see a slight bias in the error that is more important in the center of the image (Fig. <ref type="figure" target="#fig_7">10</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Calibration of a folded catadioptric camera</head><p>Folded catadioptric sensors combine typically two mirrors and follow the single viewpoint constraint <ref type="bibr" target="#b7">[8]</ref>. They have the    <ref type="table" target="#tab_2">V</ref> summarises the results. We can see a very slight bias in the error that is stronger around the mirror border (Fig. <ref type="figure">11</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Calibration of a wide-angle sensor</head><p>The calibration was also tested on a wide-angle sensor (∼ 70 o ) on 21 images of resolution 320×240 . The grid used was the same as in the hyperbolic case. For the wide-angle sensor, there is no border so the center of the image was taken to initialise the principal point. Table VI summarises the results. As before, we can see a very slight bias towards the edges in Figure <ref type="figure" target="#fig_0">12</ref>.</p><p>The strong change in γ after minimisation is probably due to the radial distortion and the change in ξ. The value of ξ does not have a simple interpretation for wide-angle sensors.</p><p>FrC2. <ref type="bibr" target="#b2">3</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FFig. 2 .</head><label>2</label><figDesc>Fig. 1. Complete calibration parameters</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 3. Axis convention</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Extraction of the mirror border</figDesc><graphic coords="4,360.09,192.82,150.63,116.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Grid corners used to initialise the extrinsic grid parameters</figDesc><graphic coords="4,360.05,603.20,150.84,106.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FrC2. 3 Fig. 8 .</head><label>38</label><figDesc>Fig. 8. Sub-pixel accuracy extraction of the remaining points</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Pixel error versus distance -parabolic sensor</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Pixel error versus distance -hyperbolic sensor</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE IV CALIBRATION</head><label>IV</label><figDesc>RESULTS FOR THE HYPERBOLIC SENSOR Initialisation [u 0 ,v 0 ] (b) = [390.67,317.69], γ = 270, [ex,ey] = [1.02, 1.24]</figDesc><table><row><cell></cell><cell></cell><cell>Final</cell><cell></cell><cell cols="2">Values</cell><cell>3σ</cell></row><row><cell></cell><cell cols="2">[γ 1 ,γ 2 ]</cell><cell cols="3">[237.89, 237.23]</cell><cell>[8.14, 7.89]</cell></row><row><cell></cell><cell cols="2">[u 0 ,v 0 ]</cell><cell cols="3">[387.21, 321.34]</cell><cell>[ 1.69, 1.76 ]</cell></row><row><cell></cell><cell></cell><cell>[ξ]</cell><cell></cell><cell cols="2">0.75</cell><cell>0.05</cell></row><row><cell></cell><cell cols="2">[k 1 , k 2 ]</cell><cell></cell><cell cols="2">[-0.105, 0.013]</cell><cell>[0.009, 0.001]</cell></row><row><cell></cell><cell cols="2">[ex,ey]</cell><cell></cell><cell cols="2">[0.29, 0.31]</cell><cell>[0.73, 0.82]</cell></row><row><cell></cell><cell cols="2">Val. [ex,ey]</cell><cell></cell><cell cols="2">[0.24, 0.26]</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Errors in pixels</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>200 0</cell><cell>300</cell><cell>400 ρ</cell><cell>500</cell><cell>600</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE V CALIBRATION</head><label>V</label><figDesc>RESULTS FOR THE FOLDED CATADIOPTRIC CAMERA Initialisation [u 0 ,v 0 ] (b) = [298.53, 269.50], γ = 156.14, [ex,ey] = [0.368, 0.576]</figDesc><table><row><cell>Final</cell><cell>Values</cell><cell>3σ</cell></row><row><cell>[γ 1 ,γ 2 ]</cell><cell>[136.29, 132.80]</cell><cell>[3.21, 3.14]</cell></row><row><cell>[u 0 ,v 0 ]</cell><cell>[299.01, 267.72]</cell><cell>[1.47, 1.23]</cell></row><row><cell>[ξ]</cell><cell>0.69</cell><cell>0.03</cell></row><row><cell>[k 1 , k 2 , k 3 , k 4 ] × 1e -3 [ex,ey]</cell><cell>[-108.03, 11.79, -2.38, 2.28] [0.12, 0.18]</cell><cell>[4.67, 0.79, 0.55, 0.44] [0.28, 0.44]</cell></row><row><cell>Val. [ex,ey]</cell><cell>[0.16, 0.15]</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Calibration of a camera with a spherical mirror</head><p>Finally we tested a low-quality camera consisting of a webcam in front of a spherical ball. The image resolution was of 352 × 264. 7 images were used with a similar grid as in the parabolic case.</p><p>The border extraction process did not prove very efficient for this sensor so the image center was used as an initial value for the principal point. Table <ref type="table">VII</ref> summarises the results.</p><p>Figure <ref type="figure">13</ref> shows the radial distribution of the error. The error seems to be uniformly distributed (Fig. <ref type="figure">13</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Point extraction</head><p>To analyse the effect of errors on the mirror parameters over the point extraction process, we counted the amount of correctly extracted points obtained after the extrinsic parameters were estimated from four points, and the grid was reprojected followed by a sub-pixel accuracy extraction.   process presents a certain robustness to imprecise initial values. We still managed to calibrate the sensor with an error of 40 %.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>In this article, we presented a general calibration approach for single viewpoint omnidirectional cameras. The calibration steps are simple without the need to know the mirror parameters. We justified theoretically that the method can be used to model central catadioptric, fisheye and spherical sensors. These results were confirmed experimentally with the calibration of a wide range of sensors.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Issues on the geometry of central catadioptric image formation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Barreto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Araujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A new algorithm to correct fisheye-and strong wide-angle-lens-distortion from single images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Brauer-Burchardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Voss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simultaneous linear estimation of multiple view geometry and lens distortion</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A unifying theory for central panoramic systems and practical implications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="445" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Vision panoramique pour la robotique mobile : stéréovision et localisation par indexation d&apos;images</title>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Gonzalez-Barbosa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Université de Toulouse III</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A four-step camera calibration procedure with implicit image correction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heikillä</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Silvén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Two-view geometry of Omnidirectional Cameras</title>
		<author>
			<persName><forename type="first">B</forename><surname>Micusik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Center for Machine Perception, Czech Technical University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Folded Catadioptric Cameras</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Peri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Panoramic Vision</title>
		<imprint>
			<date type="published" when="2001-04">Apr 2001</date>
			<biblScope unit="page" from="103" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Application of quaternions to computation with rotations. Stanford AI Lab</title>
		<author>
			<persName><forename type="first">E</forename><surname>Salamin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A toolbox for easy calibrating omnidirectional cameras</title>
		<author>
			<persName><forename type="first">A</forename><surname>Scaramuzza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Martinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A generic concept for camera calibration</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Camera calibration with distortion models and accuracy evaluation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herniou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="965" to="980" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Can we consider central catadioptric cameras and fisheye cameras within a unified imaging model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Flexible camera calibration by viewing a plane from unknown orientations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
