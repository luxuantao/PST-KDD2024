<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ReSiPE: ReRAM-based Single-Spiking Processing-In-Memory Engine</title>
				<funder ref="#_VECnSSP">
					<orgName type="full">Air Force Research Laboratory</orgName>
					<orgName type="abbreviated">AFRL</orgName>
				</funder>
				<funder ref="#_QHMsfEU">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ziru</forename><surname>Li</surname></persName>
							<email>ziru.li@duke.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Duke University Durham</orgName>
								<address>
									<region>North Carolina</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bonan</forename><surname>Yan</surname></persName>
							<email>bonan.yan@duke.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Duke University Durham</orgName>
								<address>
									<region>North Carolina</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hai</forename><forename type="middle">"</forename><surname>Helen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Duke University Durham</orgName>
								<address>
									<region>North Carolina</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">"</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Duke University Durham</orgName>
								<address>
									<region>North Carolina</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ReSiPE: ReRAM-based Single-Spiking Processing-In-Memory Engine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Authorized licensed use limited to: Macquarie University. Downloaded on October 19,2020 at 01:54:37 UTC from IEEE Xplore. Restrictions apply.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> Processing-in-memory (PIM)  <p>designs that leverage emerging nanotechnologies like resistive random access memory (ReRAM) have demonstrated enormous potential in accelerating deep learning applications due to high energy efficiency and integration density. The common approach of existing ReRAMbased PIM designs is to encode data into either voltage levels with the assist of power-thirsty analog/digital conversion circuits or spike series by sacrificing computing latency. In this paper, we introduce ReSiPE, a ReRAM-based Single-spiking PIM Engine, which uses the arrival time of a single spike to represent the data. We analyze how to encode data into a set of single spikes and develop the circuit to realize the matrix-based computation. The proposed design can minimize the spike numbers, shorten the computation period, and thus improve energy efficiency dramatically. Our simulation results show that ReSiPE achieves 67.1% power reduction and 1.97? power efficiency improvement compared to rate-coding based ReRAM PIM designs under the comparable area, throughput, and accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The applications of deep neural networks (DNNs) have been widely extended to a variety of domains. To obtain state-of-the-art performance, popular network structures such as convolutional neural networks (CNNs) involve millions of parameters <ref type="bibr" target="#b0">[1]</ref>. Deploying these networks on conventional von Neumann hardware platforms inevitably confronts with massive data movements and memory accesses, inducing high energy consumption and long latency overhead <ref type="bibr" target="#b1">[2]</ref>.</p><p>Processing-in-memory (PIM) is regarded as an effective solution for deploying DNNs. The approach integrates processing units with memory and performs data execution within the memory to decrease and even eliminate the unnecessary data movement overhead. Many PIM designs have been explored on various memory technologies, including the traditional CMOS technology <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> and emerging non-volatile memory (NVM) devices <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>. Among all these technologies, resistive random access memory (ReRAM) demonstrates great potential, for its capability of data storage and matrix-vectormultiplication (MVM) computation, exceptionally high density, and compatibility with CMOS technology <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>In conventional ReRAM-based PIM paradigms, the elements of a weight matrix are mapped to the conductance values of the corresponding cells in a ReRAM crossbar. When supplying an input vector to the wordlines, the signals along bitlines form the computed output vector. Such a multiple-input multiple-output (MIMO) operation naturally realizes the MVM computation <ref type="bibr" target="#b8">[9]</ref>. A typical implementation is the level-based design <ref type="bibr" target="#b9">[10]</ref>, which represents the input data in the form of analog voltages and collects the bitline currents/voltages as the output. These designs usually require complicated digital/analog and analog/digital converters (DAC &amp; ADC) to facilitate the signal transition, resulting in a high area and energy overhead. Moreover, the level-based design needs to continually supply the input signals during the entire MVM computation period, incurring high power consumption. Alternatively, the rate-coding based designs <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref> encode data into a series of spikes and use the frequency of spike series to record the data strength. The peripheral circuitry in these designs can be simplified, presenting advantages in area and energy efficiency. However, the rate-coding based designs suffer from quantization errors and thus usually prolong the computing period for ensuring satisfactory performance (e.g., classification accuracy).</p><p>The data format schemes of both level-based designs and rate-coding based designs are not energy-friendly. When values of inputs increase, the power consumption will accordingly increase due to the rise of voltage amplitude in the level-based designs or the increase of spike numbers in the rate-coding based designs. A key insight to overcome this disadvantage is to decouple the power consumption with data representation. Instead of adopting spike series in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13]</ref>, we propose singlespiking data format, which uses only a single spike for a datum and denotes its value with the time duration from the beginning of the period to the arrival of the spike. Furthermore, to support single-spiking data format-based MVM computation, we introduce ReSiPE, a ReRAM-based Single-spiking PIM Engine. The key contributions are summarized as follows: 1) We recognize the energy bottleneck of ReRAM-based PIMs and propose the unique single-spiking data format in PIM design. 2) We design the circuit to support the single-spiking multiplyaccumulate (MAC) scheme and analyze its feasibility. We also generalize the approach to MVM operation at the architectural level and propose ReSiPE.</p><p>3) We evaluate the efficiency of ReSiPE in terms of power consumption, throughput, area, and accuracy based on several typical neural network benchmarks. Our analysis shows that ReSiPE can achieve 67.1% power reduction and 1.97? power efficiency improvement compared to state-ofthe-art rate-coding based ReRAM PIM designs. The rest of the paper is organized as follows. Section II summarizes state-of-the-art ReRAM-based PIM designs based on the data formats. We describe the single-spiking data format and our proposed ReRAM-based single-spiking PIM engine in Section III. Section IV elaborates the evaluation results of ReSiPE. In the end, we conclude this paper in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>As summarized in TABLE I, we categorize the existing ReRAM-based PIM designs into the following three classes based on the data formats.</p><p>Level-based designs: Data are modulated as voltage potentials and fed to ReRAM array <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref>. Power-and area-hungry interface circuits, such as DAC and ADC, are necessary for this type of processing engines to convert input signals and produce output data. Inputs are supplied to ReRAM crossbars and fully occupy the entire computation period.</p><p>PWM-based design: In order to better utilize the computation period, Jiang et al. <ref type="bibr" target="#b14">[15]</ref> proposed to encode information into pulse widths in the time-domain by using pulse width modulation (PWM) recently. The work still requires ADC to generate output data.</p><p>Spike-based design: Prior spike-based ReRAM PIM designs usually adopt temporal-coding or rate-coding. Temporalcoding refers to the relative spike timing between pre-and post-synapses. Special-shaped spikes are carefully designed to fulfill certain functions, e.g., spike-timing-dependent plasticity (STDP). As such, the peripheral circuitry usually is complicated. The enriched functionality provided by the temporalcoding can largely reduce the power consumption but result in long latency to accurately emulate neural-alike dynamics <ref type="bibr" target="#b15">[16]</ref>. As a compromise, the rate-coding scheme encodes data into the spike frequency <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>. The circuit is hence greatly simplified. However, repetitive spike generation hinders further enhancement of energy efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED RESIPE DESIGN</head><p>In this work, we aim at a novel ReRAM-based PIM design for higher power efficiency, area, and performance. To be more specific, our proposed ReSiPE is based on the singlespiking data format and leverages the timing information for data representation and processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Single-spiking Data Format</head><p>Fig. <ref type="figure">1</ref> depicts the signal relation of two sequential layers when applying the single-spiking data format. The MVM computation in each layer is accomplished in two stages with identical latency. Each stage is regarded as a full-scale time slice, or a slice in the following context.</p><p>As illustrated, an input of layer n is given in the first slice (S1). The duration from the beginning of S1 to the rising edge of the spike (t n ) is taken as the input value. At the end of S1, the computation stage kicks in with a short period of ?t, during which the ReRAM crossbar will perform the MVM computation. The output of layer n will be generated in the second slice (S2), which can be directly used as the input of its subsequent layer n + 1. In this way, the operation across different layers can be realized in the pipeline form.</p><p>The proposed single-spiking data format has a few advantages. First, the input is represented by the arrival time of the spike, independent of spike width and shape. Second, the MVM computation is carried out in a short computation period, consequently lowering the energy consumption incurred by ReRAM crossbar. In addition, the identical format of input and output signals simplifies the peripheral circuity design, removing power-thirsty readout circuits and ADCs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Design Principle of Single-spiking MAC</head><p>As a novel form of data representation, the single-spiking data format simplifies an input or an output signal as a single spike and uses the relative timing information to express its value. The challenge is how to enable the MVM operations based on timing information on ReRAM-based PIM designs. In this subsection, we will introduce our proposed circuit implementation for executing MAC operations, and demonstrate the MVM computation in the single-spiking data  S1: Transit the input timing to voltage. The capacitor C gd is used as the timing reference. At the beginning of each slice, we start to charge it from 0V through a constant voltage source V s . V (C gd ) continues to rise up until the computation stage, during which M gd turns on and quickly discharges V (C gd ) to 0V. In S1, V (C gd ) is fed into a sample and hold (S/H) circuit associated with an input signal to the ReRAM crossbar. When an input spike, e.g., S in1 , comes in with the arrival time of t in1 , V (C gd ) at the moment will be captured, such as</p><formula xml:id="formula_0">M cog R 1 R 2 V(C gd ) V in1 V in2 V(C cog ) S in1 S in2 S out V out RST 1 RST 2 S1 &amp; S2: RST 1 = 0, RST 2 = 1; Comp. stage: RST 1 = 1, RST 2 = 0.</formula><formula xml:id="formula_1">V in1 = V s 1 -e - t in1 R gd C gd ? V s t in1 R gd C gd . (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>In this way, t in1 , the timing information of S in1 , is converted into V in1 , the voltage to the ReRAM cells. The approximation in Eq. ( <ref type="formula" target="#formula_1">1</ref>) is satisfied when tin1 R gd C gd 1, which means that the charging of C gd can be regarded as a linear process. If t in1 is relatively large, the non-linearity will be induced in the charging process. We will discuss the impact of this nonlinearity in Section III-D.</p><p>Computation. The short-time computation stage with a duration of ?t happens at the end of S1. In the computation stage, the capacitor C cog is charged simultaneously by V in1 and V in2 , respectively via R 1 and R 2 . In this process, the equivalent voltage source and resistance can be calculated as:</p><formula xml:id="formula_3">V eq = V in1 G 1 + V in2 G 2 G 1 + G 2 and R eq = 1 G 1 + G 2 , (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where G 1 and G 2 refer to the conductance of the two ReRAM cells R 1 and R 2 , respectively. V (C cog ) sampled at the end of the computation stage can be calculated as:</p><formula xml:id="formula_5">V out = V eq 1 -exp - ?t Req Ccog ? V eq ?t R eq C cog . (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>The approximation in Eq. ( <ref type="formula" target="#formula_5">3</ref>) is valid when the charging of C cog can be regarded as a linear process. When R eq is too small, the condition cannot be satisfied. The impact of the non-linearity on the computation results shall be discussed in Section III-D. S2: Transit V out to output spiking timing. In S2, C gd follows the same charging and discharging operation as in S1. Different from S1, however, V (C gd ) is supplied to the comparator and compared with V out . When V (C gd ) surpasses V out , the comparator will generate a rising signal. The subsequent inverter is used to generate a pulse-width delay and the AND gate produces the falling edge to form an output spike. The duration from the beginning of S2 to the presence of the generated spike is denoted by t out , which can be calculated by using the following function:</p><formula xml:id="formula_7">V out = V s 1 -e - t out R gd C gd ? V s t out R gd C gd . (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>By combining Eqs (2)?(4), we can present t out in the format of the MAC result of G 1 , G 2 and t in1 , t in2 : As such, the computation result in voltage format is transferred into the time information of a single-spiking signal. Fig. <ref type="figure" target="#fig_1">3</ref> shows a simulation result of the proposed design. Here, the length of a slice is set to 100ns. Performing the entire process including S1 and S2 takes 200ns. The computation stage with ?t = 1ns occurs at the end of S1, i.e., during 99ns ? 100ns.</p><formula xml:id="formula_9">t out = ?t C cog (t in1 G 1 + t in2 G 2 ).<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Column Output Generator</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Column</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Overview of ReSiPE Design</head><p>In Section III-B, we takes a simplified example to elaborate how to implement the MAC operation with two input signals in the single-spiking data format. Here, we generalize the design concept to the MVM operation and propose a ReRAM-based single-spiking PIM engine, namely, ReSiPE. Fig. <ref type="figure" target="#fig_2">4</ref> presents the overview of ReSiPE microarchitecture. It consists of two main components-the I/O in single-spiking data format and the implementation of single-spiking MVM. ReSiPE supports I/O based on single-spiking data format, which has been hereinbefore interpreted. Here, we will focus on the implementation of single-spiking MVM. We append two additional modules to the ReRAM crossbar, which are a global decoder (GD) and a column output generator (COG) cluster. These two modules are derived from the example circuit proposed in Section III-B.</p><p>Global decoder (GD): A ReRAM crossbar array is associated with one GD module. Its primary function is decoding input single-spiking signals into wordline (WL) voltage levels of the ReRAM crossbar. During S1, GD takes in input singlespike signals, produces the input voltages according to the arrival time of the spikes, and drives the ReRAM crossbar during the instant computation stage.</p><p>Column output generator (COG) cluster: A COG cluster consists of multiple COG modules, each of which is assigned to a bitline (BL) of the ReRAM crossbar. During the computation stage, a COG module samples the voltage that represents the computation result, and generates an output signal in the single-spiking data format during S2.</p><p>Single-spike MVM: Following the two-stage execution discussed previously, the ReRAM crossbar performs MVM operations with signals in single-spiking data format. Similar to the analysis in Section III-B, for a ReRAM crossbar with M wordlines, the jth bitline generates a spike with the timing approximating to</p><formula xml:id="formula_10">t out,j = ?t C cog M i=1 t in,i G i . (<label>6</label></formula><formula xml:id="formula_11">)</formula><p>The output signals of bitlines will then be passed to the sequential layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Computational Result Analysis</head><p>In this subsection, we present our simulation result and show that ReSiPE can correctly execute single-spiking MVM. The simulation was implemented on Cadence Virtuoso 6.1.6, under a 65nm technology. The size of the ReRAM crossbar is 32 ? 32. We adopted the one-transistor-one-ReRAM (1T1R) structure of ReRAM cells. The low and high resistance states were respectively set to LRS = 10k? and HRS = 1M?. Both C gd and C cog were 100fF. V s was set to 1V and R gd was set to 100k?. The length of a slice was 100ns and the pulse width of a single spike was set to 1ns. The simulation waveform for each bitline output is similar to the waveform in Fig. <ref type="figure" target="#fig_1">3</ref>. Fig. <ref type="figure">5</ref> shows the relation of the actual MVM simulation results and the input strength using 100 random sample points with different t in and G. Here, the x-axis is the the input strength of t in G and the y-axis represents t out that is actually acquired by ReSiPE. The total G varies from 0.32mS ? 3.2mS and t in varies from 10ns ? 80ns.  Our result indicates that t out is affected by the non-linearity of V (C cog ) and V (C gd ) so we further investigated it. Here, Curve 1 is the fitting curve of the sample points with total G ? 1.6mS. Non-linearity of V (C gd ) is due to the large input t in , which can be observed along Curve 1 with the increase of t in G. The extent of the non-linearity is subtle, because C gd is used for calibration in both S1 and S2, which partially cancels out the effect.</p><p>Non-linearity of V (C cog ) is due to the large total G of a column of ReRAM cells. It can be seen that the sample points in light blue color below Curve 1 belong to the cases where the total conductance is larger than 1.6mS. The charging process of C cog in the computation stage approaches to saturation quickly and thus t out is smaller than the linear calculation, especially at big t in . To better illustrate the scenario, we highlight Curve 2 and Curve 3 that fit the sample points with G = 2.5mS and G = 3.2mS, respectively.</p><p>The simulation result leads to the conclusion that t out can represent the MVM results of t in and G with slight nonlinearity under the condition that the total G ? 1.6mS. This condition can be satisfied by setting the resistance range of ReRAM cells from 50k? to 1M? <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, though the slight non-linearity still exists. More analysis related to the impact of this slight non-linearity on the accuracy of the neural networks shall be shown in Section IV-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment Setup</head><p>We evaluate the proposed ReSiPE engine in terms of power efficiency, latency, area, and accuracy. We implement it with Cadence Virtuoso under a 65nm technology. The size of ReRAM crossbar was set to 32 ? 32. We adopted the 1T1R structure of ReRAM cells in simulation <ref type="bibr" target="#b13">[14]</ref>. Calibrated with the clock frequency of 1GHz, the length of a slice is 100ns and the length of the computation stage is set to 1ns. The same circuitry parameters in Section III-D are adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Power, Latency and Area Comparison</head><p>We compare the power, power efficiency, computation latency and area of our proposed ReSiPE with several representative PIM designs. The results are summarized in TABLE II. The comparison counterparts were carefully selected to cover different data formats, including the level-based <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17]</ref>, the PWM-based <ref type="bibr" target="#b14">[15]</ref>, and rate-coding based <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13]</ref>. Temporal coding is often specially designed for training <ref type="bibr" target="#b15">[16]</ref>. Considering the prevailing use of PIMs as inference-only processing engine, we purposely exclude temporal coding paradigms here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Power efficiency:</head><p>We test the power efficiency of PEs under the assumption that the same array sizes of ReRAM devices are fully utilized. ReSiPE shows 1.97?, 2.41? and 49.76? higher power efficiency than the representative levelbased, rate-coding and PWM designs, respectively. This improvement originates from the simplification of mixed-signal interface circuit, the reduction of spike numbers and the elimination of the time-domain drivers. According to our estimation, the major component of the power consumption comes from the COG cluster, because the capacitor C cog assigned to each bitline needs charging during S2. Experimental results show that the COG cluster contributes to 98.1% of the entire power consumption. Future technology scaling that enables smaller Metal-Insulator-Metal (MIM) capacitors in COG clusters could induce further energy reduction.</p><p>2) Latency: Previous rate-coding based and PWM-based designs require a relatively long computing latency to transfer a spike series or a modulated pulse. Due to the elaborated data format scheme, ReSiPE shortens the computing latency 50% and 68.8% than rate-coding and PWM-based baselines, respectively. It doesn't improve computing speed much compared to the level-based baselines as these designs utilize high-speed DAC/ADC to speedup the computation.</p><p>3) Area: We estimate the areas by scaling all the designs to the same ReRAM crossbar size. ReSiPE can dramatically reduce the design area than other counterparts. Experimental results demonstrate that ReSiPE saves 14.2% and 85.3% area compared to rate coding-based and level-based baselines, respectively. The reason why ReSiPE considerably reduces the area compared to level-based designs lies in the elimination of area-consuming DAC/ADCs <ref type="bibr" target="#b19">[20]</ref>.</p><p>The analysis also indicates a trade-off between computing latency and area to achieve higher throughput. For example, to compete with level-based designs in terms of throughput, we  may increase the ReSiPE numbers to improve the parallelism. Fig. <ref type="figure" target="#fig_4">6</ref> shows the estimated throughput of such an approach. Under the same area budget, ReSiPE provides much higher throughput than other designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Accuracy Analysis</head><p>We adopted six pretrained networks to evaluate accuracy:</p><p>? MLP-1: 1-layer perceptron network on MNIST;</p><p>? MLP-2: 2-layer perceptron network on MNIST;</p><p>? CNN-1: 4-layer LeNet on MNIST;</p><p>? CNN-2: AlexNet on Cifar-10;</p><p>? CNN-3: VGG16 on Cifar-10; and</p><p>? CNN-4: VGG19 on Cifar-10.</p><p>The pretrained networks are mapped to the circuitry implementation to acquire the final classification accuracy. The non-linearity of circuit design principle that is discussed in Section III-D is taken into account. The impact of process variations (PVs) of ReRAM cells is also investigated, which follows the normal distribution according to <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. In the experiment, we adopt the process variations with the standard deviations ? = 0, 5%, 10%, 15%, 20%.</p><p>As shown in Fig. <ref type="figure" target="#fig_5">7</ref>, the classification accuracy drop of the case ? = 0 compared to the ideal accuracy is caused by the non-linearity presented in Section III-D. The slight nonlinearity leads to an accuracy drop of less than 2.5%. The device variation of 20% leads to 1% ? 15% accuracy drop. The impact of PVs is more significant in more complex neural networks models, as they are more sensitive to the weight values. Nevertheless, the accuracy is still competitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we propose a novel ReRAM-based singlespiking processing-in-memory engine called ReSiPE, aiming at improving the power efficiency of ReRAM-based PIM designs. ReSiPE features the single-spiking data format and MVM schemes, which represents both input and output data in single-spiking signals and executes MVM computation. Experiments show that ReSiPE achieves 67.1% power reduction with the competitive area, throughput, and accuracy. With our proposed single-spiking data format, post-spike latency could be potentially reduced by multi-layer pipelining. ReSiPE is hence open to future microarchitecture optimization toward better layer-wise computing latency. Our future work will also focus on the elaborated circuit designs based on the proposed ReSiPE architecture to achieve better performance, energy efficiency and robustness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The schematic of a simplified circuit to implement single-spiking MAC.</figDesc><graphic url="image-1.png" coords="3,308.68,208.77,262.45,124.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The circuit simulation. (a) The active waveform in S1; (b) The active waveform in the computation stage and S2.</figDesc><graphic url="image-2.png" coords="3,308.68,345.69,262.45,124.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. An overview of ReSiPE architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. 5. Input-output characterization: the MVM computing results tout versus the input strength t in G.</figDesc><graphic url="image-4.png" coords="4,324.16,553.32,215.81,112.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. The trade-off between computing latency and design area. Dashed lines imply the overall throughput under certain latency and area budgets.</figDesc><graphic url="image-5.png" coords="5,325.00,565.11,226.75,109.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Accuracy comparison between models considering PV.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I VARIOUS DATA FORMATS IN RERAM PIM DESIGNS</head><label>I</label><figDesc></figDesc><table><row><cell>Data Format</cell><cell>Level</cell><cell>PWM</cell><cell>Rate Coding</cell><cell>Temporal Coding Spike</cell><cell>This work</cell></row><row><cell></cell><cell>0.43V</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Shape</cell><cell>w</cell><cell>w</cell><cell>w</cell><cell>w</cell><cell>w</cell></row><row><cell></cell><cell>0.71V</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Interface Circuit</cell><cell>DAC &amp; ADC</cell><cell>Pulse Modulator</cell><cell>Spike Modulator</cell><cell>Neuron Circuit</cell><cell>ReSiPE</cell></row><row><cell>Non-zero Voltage Applying Duration</cell><cell>Long</cell><cell>Medium</cell><cell>Medium</cell><cell>Medium</cell><cell>Short</cell></row><row><cell>In/Out Scale</cell><cell>Same</cell><cell>Same</cell><cell>Different</cell><cell>Same</cell><cell>Same</cell></row><row><cell>Latency</cell><cell>Fast</cell><cell>Medium</cell><cell>Medium</cell><cell>Slow</cell><cell>Medium</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>licensed use limited to: Macquarie University. Downloaded on October 19,2020 at 01:54:37 UTC from IEEE Xplore. Restrictions apply.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>This work was in part supported by <rs type="funder">National Science Foundation (NSF)</rs> under grant <rs type="grantNumber">CSR-1717885</rs> and <rs type="funder">Air Force Research Laboratory (AFRL)</rs> under grant <rs type="grantNumber">FA8750-18-2-0121</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QHMsfEU">
					<idno type="grant-number">CSR-1717885</idno>
				</org>
				<org type="funding" xml:id="_VECnSSP">
					<idno type="grant-number">FA8750-18-2-0121</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">NDA: Near-DRAM acceleration architecture leveraging commodity DRAM devices and standard memory modules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Farmahini-Farahani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HPCA</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Conv-RAM: An energy-efficient SRAM with embedded convolution computation for low-power CNN-based machine learning applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Biswas</surname></persName>
		</author>
		<editor>ISSCC</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">In-memory computation of a machine-learning classifier in a standard 6T SRAM array</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JSSC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">PRIME: A novel processing-in-memory architecture for neural network computation in ReRAM-based main memory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCA</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spin-transfer torque devices for logic and memory: Prospects and perspectives</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TCAD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nonvolatile 3D-FPGA with monolithically stacked RRAM-based configuration memory</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Liauw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISSCC</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">GraphR: Accelerating graph processing using ReRAM</title>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hardware realization of BSB recall function using memristor crossbar arrays</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shafiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCA</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A spiking neuromorphic design with resistive crossbar</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pipelayer: A pipelined reram-based accelerator for deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">RRAM-based Spiking Nonvolatile Computing-In-Memory Processing Engine with Precision-Configurable In Situ Nonlinear Activation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLSI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A 65nm 1Mb nonvolatile computingin-memory ReRAM macro with sub-16ns multiply-andaccumulate for binary DNN AI edge processors</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Chen</surname></persName>
		</author>
		<editor>ISSCC</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Pulse-width modulation based dot-product engine for neuromorphic computing system using memristor crossbar array</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCAS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Self-adaptive spike-time-dependent plasticity of metal-oxide memristors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Prezioso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A 4M synapses integrated analog ReRAM based 66.5 tops/w neural-network processor with cell current controlled writing and flexible network architecture</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mochida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLSI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Investigating the switching dynamics and multilevel capability of bipolar metal oxide resistive switching memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Physics Letters</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">High-density crossbar arrays based on a Si memristive system</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Jo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nano letters</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A 2.3-mw, 950-mhz, 8-bit fully-time-based subranging ADC using highly-linear dynamic VTC</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ohhata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLSI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DL-RSIM: A simulation framework to enable reliable ReRAM-based accelerators for deep learning</title>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCAD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Design of Reliable DNN Accelerator with Unreliable ReRAM</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DATE</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
