<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Electrodermal Activity to Recognize Ease of Engagement in Children during Social Interactions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Media Lab Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Interactive Computing</orgName>
								<orgName type="institution">Georgia Institute of Technology Atlanta</orgName>
								<address>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Electrodermal Activity to Recognize Ease of Engagement in Children during Social Interactions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">13B56589E6E5308CB085861C4792FA89</idno>
					<idno type="DOI">10.1145/2632048.2636065</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Electrodermal Activity</term>
					<term>social engagement</term>
					<term>physiology</term>
					<term>feature analysis</term>
					<term>Support Vector Machines H.5.3. Group and Organization Interfaces: Evaluation/methodology, Synchronous interaction</term>
					<term>J.4 Social and Behavioral Sciences: Sociology Experimentation, Measurement, Performance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recent emergence of comfortable wearable sensors has focused almost entirely on monitoring physical activity, ignoring opportunities to monitor more subtle phenomena, such as the quality of social interactions. We argue that it is compelling to address whether physiological sensors can shed light on quality of social interactive behavior. This work leverages the use of a wearable electrodermal activity (EDA) sensor to recognize ease of engagement of children during a social interaction with an adult. In particular, we monitored 51 child-adult dyads in a semistructured play interaction and used Support Vector Machines to automatically identify children who had been rated by the adult as more or less difficult to engage. We report on the classification value of several features extracted from the child's EDA responses, as well as several other features capturing the physiological synchrony between the child and the adult.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>A basic feature of successful social interactions is synchrony, or the tendency of social partners to modulate and coordinate their behaviors and affective states <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>Even though there is strong evidence that synchrony occurs at the physiological level as well <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref>, most approaches to assessing interactive synchrony focus on how two social partners coordinate externally observable behaviors -patterns of attention, affective expression, gesture, and speech. Until recently, explorations in recognizing the quality of social interactions for other purposes, such as augmenting behavior annotation, have been hampered by limitations of the sensing hardware: a reliance on wired and bulky sensors that precluded assessment of physiological states in the context of actual social interactions. For young children, using invisible physiological signals, such as electrodermal activity, to assess interactive synchrony is particularly appealing since their capacities for social coordination are just emerging.</p><p>With recent advances in wearable biosensing technologies, it is now feasible to develop systems that automatically monitor not only outwardly observable behaviors, but also inward physiological states of children that may serve as key markers of social engagement. Such technologies may not only help characterize qualitative aspects of children's social engagement, but may potentially also assist with the identification and quantification of developmental delays <ref type="bibr" target="#b21">[22]</ref>. This paper explores whether we can successfully leverage modern biosensors to identify children who have been rated by an adult interactive partner as more or less difficult to engage. In particular, we monitored the electrodermal activity of 51 child-adult dyads during a short naturalistic social interaction (see Figure <ref type="figure">1</ref> for an example of interaction), and used Support Vector Machines to automatically differentiate children who were rated as easier versus harder to engage.</p><p>The paper is organized as follows. We begin by summarizing related research on measuring engagement and the use of physiological information in the context of social engagement. We then outline our procedure for collecting data and rating children's engagement. After explaining how the physiological signals are preprocessed, we describe a variety of features to characterize the child and adult's physiological responses. We then report our main findings in terms of classification performance of combinations of different types of features. We conclude by providing some discussion and highlighting future steps to push forward this line of research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BACKGROUND AND PREVIOUS WORK Measuring Engagement</head><p>Analyzing the engagement level of people has been the focus of interest in a wide variety of situations. Although the definition of engagement is very context-specific, there are three well differentiated approaches to measuring it: self-reports, external ratings, and physiological information.</p><p>Self-reports can take many forms such as interviews or surveys taken during or after a situation of study <ref type="bibr" target="#b26">[27]</ref>. This method is arguably one of the fastest and most direct approaches to gather information but is subjective and can suffer from information recall bias. Moreover, self-reports are disruptive and are not appropriate for certain populations, such as young children who may not be able to reflect on and articulate their affective state. An alternative method involves having experienced coders review videos of recorded interactions to rate the perceived interactive experience, or to mark onsets and offsets of individual interactive behaviors or engagement states <ref type="bibr" target="#b0">[1]</ref>. This method is very common in the field of facial expression analysis where Facial Action Unit coders <ref type="bibr" target="#b7">[8]</ref> annotate the appearance of specific facial movements associated with basic emotions. Although this approach is useful for the development of automatic expression recognition systems, it can be relatively time intensive and laborious to train coders to reliability <ref type="bibr" target="#b4">[5]</ref>.</p><p>A less disruptive approach involves measuring physiological signals. A wide variety of signals have been used in different settings. In the context of market research, for example, researchers have shown that signals such as gaze behavior <ref type="bibr" target="#b30">[31]</ref>, heart rate <ref type="bibr" target="#b19">[20]</ref> and EDA <ref type="bibr" target="#b18">[19]</ref> can be used in laboratory settings as effective indicators of the interest levels of people to certain stimuli. For instance, Hernandez et al. <ref type="bibr" target="#b13">[14]</ref> and, more recently, Silveira et al. <ref type="bibr" target="#b28">[29]</ref> have shown that physiological metrics such as facial expressions and EDA, respectively, can be used to recognize the engagement level of TV viewers. In other social environments such as conference meetings, head pose orientation has been widely used to identify the visual focus of attention of participants <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32]</ref>, with the underlying assumption that people pay attention to whatever they are looking at. Although facial and head gestures can be measured at a distance, they are easier to voluntarily control and may not always be congruent with the internal affective experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social Engagement and Synchrony</head><p>A key property of engagement during social interactions is interactional synchrony <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22]</ref>, which is associated with the coordination of behaviors between individuals during social interactions. Traditionally, a high degree of synchrony indicates a high level of engagement, consisting of closely coordinated behaviors and contingent social responses <ref type="bibr" target="#b17">[18]</ref>.</p><p>The synchrony of physiology during social interactions (also known as physiological linkage) has been studied in a broad set of applications. For instance, Levenson and Gottman <ref type="bibr" target="#b20">[21]</ref> monitored several physiological signals such as heart rate and EDA in 30 married couples to study marital satisfaction. They found that greater synchronization was associated with more distressed interactions. In a different study, Marci et al. <ref type="bibr" target="#b23">[24]</ref> analyzed EDA to study the empathy between 20 patient-therapist dyads. In this case, greater synchronization was associated with higher patients' ratings of perceived therapist empathy. Physiological synchrony has also been used as a measure of the intensity of gaming and social interactions <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12]</ref>, irrespective of the emotional valence of the interaction.</p><p>Methodological limitations such as wired and cumbersome sensors traditionally have made impractical the study of inward responses of children in the context of naturalistic interactions. However, the availability of modern wearable physiological sensors provides an opportunity to begin to study internal physiological markers of social engagement in the course of naturally-occurring scenarios. One relevant example is the work of Hedman et al <ref type="bibr" target="#b12">[13]</ref>, which monitored and visualized the EDA of 22 children with sensory challenges while they used zip lines, jumped in ball pits, and otherwise engaged in occupational therapy services. More recently, Chaspari et al <ref type="bibr" target="#b6">[7]</ref> explored the utility of EDA of three children with Autism Spectrum Disorder and their therapists to better quantify the quality of interventions. In comparison with previous studies, the work presented in this paper considers 51 children-adult interactions and is the first to explore physiological synchrony in automating recognition of social engagement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DATA COLLECTION</head><p>The data utilized in this analysis came from a larger dataset collected by a multi-disciplinary team with the ultimate goal of building a broad set of computational tools for measuring and analyzing child social-communication behavior <ref type="bibr" target="#b27">[28]</ref>. This section provides details on the experimental setting, the social interaction, and the experimental procedure relevant to our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Children between the ages of 15 and 30 months were recruited through advertisements distributed to daycare centers, community and parent mailing lists, and through targeted mailings to families of young children identified through a commercially available newborn mailing list. The age range was chosen to correspond to a period in development when key social-communicative behaviors are emerging and becoming consolidated. Both children and parents were invited for a 30-45 minute play session. During the first 10-15 minutes, there was a warm-up period when the child and adult examiner played together on the floor so that the child could get acclimated to the new environment and to the wearable sensors. Then, the child and the adult moved to a small table where the adult engaged the child in a 2-5 minute semi-structured play interaction (described below). The child was seated in the parent's lap or, in cases where a child preferred to sit alone, the parent remained in the room seated at a nearby sofa. Each family received a $50 gift card for their participation, and the child was given a small toy at the end of the session. The experimental protocol was reviewed and approved by the university's Institutional Review Board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Apparatus</head><p>To capture the interaction, we equipped a laboratory room with several cameras, microphones, and physiological sensors (see Figure <ref type="figure" target="#fig_1">2</ref>). Both child and adult wore Affectiva Q TM (htttp://www.qsensortech.com) biosensors on both of their wrists. However, we only utilized the information captured by the left wrists, which corresponded to the nondominant hand of the adults and is in accordance with standard practice <ref type="bibr" target="#b3">[4]</ref>.</p><p>The Q TM sensors use dry Ag-AgCl 1cm diameter electrodes and record EDA, skin surface temperature, and actigraphy through 3-axis accelerometry (sampling rate of 32Hz). To improve signal acquisition, K-Y gel was placed on each electrode and the biosensors were attached during the warm-up period so that a baseline level was reached before the beginning of the semi-structured social interaction. To synchronize the streams of different biosensors, the adult switched on all of the devices at the same time and then simultaneously pressed the event-mark buttons on the sensors three consecutive times. Finally, the sensors were horizontally moved for a few seconds in front of one of the cameras to synch visual and accelerometer data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social Interaction</head><p>The interaction between the child and the adult consisted of five scripted activities during which the adult actively attempted to engage the child. These included saying hello to the child, rolling a ball back and forth, looking through pictures in a book together, putting the book on one's head as a hat, and gentle tickling (see Figures <ref type="figure">1</ref> and<ref type="figure" target="#fig_2">3</ref> for representative moments). These interactions were carefully designed to elicit behaviors that are developmentally relevant to the social and communicative growth of a young  child <ref type="bibr" target="#b24">[25]</ref>. The ordering of the different activities remained constant for all sessions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Engagement Scoring</head><p>Adults were research assistants with extensive experience in interacting with young children. Each adult was trained to consistently and naturally guide children through the five activities, and score child's engagement for each of the five activities. As part of the training, adults were required to obtain over 90% agreement for 3 consecutive sets of 10 sessions previously rated by a clinical consultant.</p><p>Although the definition of engagement varies for different settings and studies, our play protocol defined engagement as the amount of effort required to engage the child. The scoring guidelines used by the adults were as follows: Score 0: The interaction with the child required little effort for the adult and/or the child was ready and eager to engage. Score 1: The interaction with the child required some effort on the part of the adult due to the child's shyness or distractibility.</p><p>Score 2: The interaction with the child required extensive effort and/or the child was highly fussy or refused to interact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Overview</head><p>In this work, we collected and synchronized information from 74 sessions. However, 7 of the sessions contained abnormally high electrodermal responses (&gt;20 μSiemens) and the Q TM sensor was unable to record the data without quantization problems (e.g., see left in Figure <ref type="figure" target="#fig_3">4</ref>). Furthermore, 16 other sessions were discarded due to the presence of large amounts of artifacts in at least one of the sensors. These sessions could be easily characterized by long periods of flat responses (i.e., 0 μSiemens) and/or abrupt signal drops that were incongruent with the slow exponential decays of typical EDA responses <ref type="bibr" target="#b3">[4]</ref>. Abrupt signal drops such as those observed on the right in Figure <ref type="figure" target="#fig_3">4</ref> are mostly due to movement of the sensor. The distribution of engagement ratings of the excluded sessions was similar to the one observed when considering all the sessions.</p><p>After excluding the sessions with quantization and artifact problems, the final subset of data contained 51 sessions (27 females), guided by 4 different adults (all female and right handed). For these 51 sessions, the average age of the children was 21 months (SD = 5.23), and the average duration of the social interaction was 2.72 minutes (SD = 1.02 minutes). Furthermore, 79.6% of the individual stage engagement rating scores were 0, indicating that most children were easy to engage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CHARACTERIZATION OF EDA RESPONSES Electrodermal Activity and Arousal</head><p>Electrodermal activity, often referred to in earlier work as galvanic skin response, has been one of the most widely used signals in psychophysiological research during the last century <ref type="bibr" target="#b3">[4]</ref>. EDA has been commonly measured as skin conductance off the finger or palmar surface, which provides an indication of the activation of eccrine sweat glands. Since this type of sweat gland is purely innervated by the sympathetic nervous system, skin conductance has been considered as one of the best indicators of sympathetic arousal <ref type="bibr" target="#b3">[4]</ref>. Increased levels of arousal typically result in sensory alertness, increased readiness to respond, and mobility. Furthermore, arousal regulates attention and emotion, which are critical for successful social interactions and daily functioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocessing</head><p>Prior to analyzing physiological responses, the data typically undergoes several preprocessing steps. Quick sensor movements may introduce signal artifacts in the form of high frequency changes that need to be considered. This problem is very common in uncontrolled settings such as social interactions as these typically involve gestures and body movements. In order to attenuate these artifacts, we use a Hanning filter with a 1 second window <ref type="bibr" target="#b0">[1]</ref>.  be between zero and one in accordance with standard practice (e.g., <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b22">[23]</ref>). This normalization not only amplifies the physiological changes associated with the session but also facilitates comparison across people (both within training set and between training and testing sets).</p><p>Finally, while common EDA measurements are a one dimensional time series signal, there are typically two distinct components: a phasic component which shows quick changes associated with stimulus-specific or nonspecific responses, and a tonic level which changes more slowly and can be observed in the absence of any particular discrete environmental event or external stimuli. While some studies using EDA in the context of classification use the original 1D signal (e.g., <ref type="bibr" target="#b14">[15]</ref>), this work explores the discriminative power of each of the components separately. This approach has the additional benefit of being able to better capture complementary aspects of the physiological responses. In order to extract the two components from the original signal, we utilized the deconvolution approach proposed by Benedek and Kaernbach <ref type="bibr" target="#b0">[1]</ref>. Figure <ref type="figure" target="#fig_4">5</ref> shows an example of the decomposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features</head><p>Before the physiological responses can be used for classification, it is necessary to extract representative features. In this work, we explored the utility of multiple features, which can be grouped into two categories: individual features (IF), and synchrony features (SF).</p><p>From the tonic and phasic components of each child's EDA signal, we extracted the following IF features: mean, standard deviation, area under the curve, relative positions of maximum and minimum values, slope (estimated by linear interpolation), average number of peaks, and average of the peaks amplitudes. Peaks were detected using the findpeaks MATLAB function and were required to have an amplitude of at least 0.01 after normalization and a minimum distance between peaks of at least 1 second. While some of the features aim to capture the temporal aspects of the responses (e.g., slope captures an overall increase or decrease of the response), other features aim to capture overall activation throughout the period (e.g., average number of peaks can be seen as an indicator of arousal).</p><p>Motivated by previous research in physiological synchrony (e.g., <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref>), we also explored several SF features to capture the relationship between the EDA responses of the child and the adult. One of the most effective and commonly used methods is the Pearson product-moment correlation (PC), which measures the linear dependence between two variables. Although this method works well in practice, we also evaluated the following two methods:</p><p>Canonical Correlation (CC). This method similarly measures linear dependence between two variables but also tries to represent the information in a different dimensional space where the correlation is maximized.</p><p>An important property of this method is that the result is invariant with respect to affine transformations of the variables. Therefore, we hypothesized that this method could address some of the individual differences of the signals that could not be corrected by the preprocessing steps. To the best of our knowledge, this approach has not been previously explored in the context of social engagement from EDA.</p><p>Dynamic Time Warping (DTW). This method utilizes a dynamic programming approach to find the similarity between two signals. The main advantage of this method is that it allows some temporal flexibility in terms of signal durations and delayed responses. We hypothesized that this method would help align and compare asynchronous responses between child and adult, such as those that could be observed during turn-taking interactions (e.g., ball play interaction).</p><p>As part of the SF features, we also computed the difference between some individual features extracted from both the adult and the child's responses. In particular, we extracted mean, number of peaks, and average amplitude of these peaks. Then, we utilized the L2-norm as a distance metric to capture the difference between the pairs of features. Figure <ref type="figure" target="#fig_6">6</ref> shows an overview of the features we explored, grouped into the two categories. Note that the dimensionality of each feature is one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXPERIMENTAL SETTING</head><p>The goal of the study is to explore the feasibility of accurately and automatically identifying children rated as more or less difficult to engage by relying solely on the physiological responses of a 5-stage social interaction. While the original goal was to provide fine grained  engagement scores for each of the sub-stages of the social interaction, we encountered two major complications with the dataset. First, some of the stages are too short to make meaningful physiological assessments and explore some of the synchrony-based features, especially since EDA responses may appear 1 to 5 seconds after a specific stimulus <ref type="bibr" target="#b3">[4]</ref>. For instance, the stages of saying "hello" and putting the book on one's head as a hat lasted 6 and 9 seconds on average, respectively. Second, the distributions of engagement ratings within stages are very unbalanced, making it very challenging for the classifier to appropriately model all the classes and not ignore the least common one.</p><p>For instance, 84% of the engagement ratings for rolling the ball and gentle tickle were zero (i.e., easy to engage). In order to attenuate these problems and start exploring the feasibility of automatically characterizing social engagement, we divided the sessions into the following two groups: easier to engage (n = 29), consisting of the children who scored zero for all five stages, and harder to engage (n = 22), consisting of the children who scored 1 or 2 for at least in one of the stages. This division enabled us to not only examine a longer observation window (2.7 minutes on average) but also to address the problem as a binary classification problem with relatively balanced distribution of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification</head><p>In order to perform classification, we used the LIBSVM library <ref type="bibr" target="#b5">[6]</ref>, which provides an efficient implementation of Support Vector Machines (SVMs) <ref type="bibr" target="#b2">[3]</ref>. We used a 10-foldcross-validation protocol for testing and training of the algorithm. Therefore, we divided the sessions into 10 different groups and used 9 of them as a training set and the remaining one as the testing set. This process was iteratively repeated until engagement labels were automatically generated for all the groups. During the training phase, the training set was divided into 10 different groups and followed the same iterative process to gather performance for different misclassification costs (log 2 C, for C = {0, 1, 2 ... 18}) of a Linear SVMs with probabilistic estimates. Once the process was completed, we used the whole training set and the best cost to obtain the final classifier model, which then was used in the testing set. The misclassification weights for each class were set to be the class priors of the other class to force the algorithm to make more balanced predictions of the labels <ref type="bibr" target="#b15">[16]</ref>. When considering the whole dataset, for example, the misclassification weight of the smallest class (i.e., harder to engage) class was 29/51. Note that data from the same child was never used for training and testing at the same time.</p><p>For some of the experiments, we also incorporated the Sequential Forward Selection (SFS) approach <ref type="bibr" target="#b10">[11]</ref> in the training phase, allowing us to identify some of the most discriminative combinations of features. Starting from the best single feature, this method iteratively incorporates features that improve performance. The algorithm stops iterating if there are not more remaining features or the best performance is achieved with a smaller subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance</head><p>Two of the most common methods to evaluate performance of a classifier are the area under the Receiver Operating Characteristic (ROC) curve, and the area under the Precision/Recall (PR). In this work we use the average between the areas under the two curves obtained when considering different thresholds on the probability estimates provided by SVMs (similar to <ref type="bibr" target="#b13">[14]</ref>). This metric was used as a reference to find the optimal misclassification cost of SVMs during the training phases and will be used in the following section to report classification performance. In particular, this metric ranges from 0 (worst performance) to 100 (maximum performance) and its main advantage is that it provides a classification performance that is more invariant to unbalanced classes than traditional metrics (e.g. Accuracy, F1 score). Furthermore, this metric captures the discriminative power of the classifier for several configurations (i.e., different thresholds on the probability estimates). Note that a classifier that always predicts the most likely class will obtain a performance of 0 as none of the curves can be computed (i.e., probability estimates are always one).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>In this section we analyze the physiological responses of 51 children during their interaction with an adult. The first two parts of the analysis provide graphical and quantitative intuition of the most relevant EDA characteristics, respectively. The final part of the analysis provides quantitative evaluation of the different types of features and recognition performance in the context of social engagement recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Physiological Responses</head><p>In order to provide a preliminary graphical intuition of the physiological responses, Figure <ref type="figure" target="#fig_8">7</ref> shows the average normalized EDA response and standard error of children in the easier (left) and harder (right) to engage groups. Since the completion time was different for each session, we resampled each response to last the average session time of each group, and then computed the average across sessions within the same group. While the average session time of children in the first group was 2.44 minutes (STD = 0.4), the average session time of the second group was 2.93 minutes (STD = 1.25). This difference is to be expected as by definition in the latter group the adults had to spend more time trying to maintain the child's engagement. As can be observed in the graph, the average physiological responses of each group show distinctive trends. While children who were easier to engage displayed a more constant response throughout the session (around the average), children who were more difficult to engage displayed a response that continuously increased over time. Note, however, that the distribution of engagement ratings throughout the interaction stages varied for each child. Figure <ref type="figure" target="#fig_7">8</ref> shows the average engagement score throughout the whole interaction for children in the harder to engage group. The engagement scores for children in the easier to engage group remained constant throughout the whole interaction (zero by definition). As can be seen, the ratings fluctuate for the different parts of the interactions, indicating that children were more difficult to engage right at the beginning (corresponding to the adult saying hello to the child) and easier to engage by the end of session (corresponding to the gentle tickling). Furthermore, the lowest engagement scores were achieved between the 60 and 120 seconds of the session, corresponding to the part where the adult and the child looked through pictures in a book together. Interestingly, both positive and negative fluctuations of the engagement scores seem to be associated with EDA increases. In the following sections, we explore different EDA characteristics in terms of classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EDA Characteristics</head><p>In order to further characterize the physiological responses, this section quantifies the utility of different features in terms of classification performance. In particular, we consider each of the individual and synchrony features and extract them from both the tonic and the phasic components.   Table <ref type="table" target="#tab_2">1</ref> shows the classification performance obtained for each of the IF features extracted from the child's physiological responses. As can be seen, the relative position of the maximum tonic value yielded the highest classification performance (69.91%), followed by the tonic mean and area under the curve (66.23%). For the phasic component, the standard deviation yielded the highest performance (64.67%). Similarly, Table <ref type="table" target="#tab_1">2</ref> shows the classification performance for each of the SF features. While PC yielded the best performance among the tonic features (59.38%), the difference between the number of peaks of the dyad yielded the best performance above all the features, which is 10% higher than the best tonic feature. The best result achieved by IF features is comparable to the best result achieved by SF features, demonstrating that both types are relevant in the context of engagement recognition. However, while the tonic component may be more relevant when only analyzing the responses of children (in accordance with Figure <ref type="figure" target="#fig_8">7</ref>), the phasic component provides more discriminative information when capturing the synchrony of the dyad.</p><p>In order to assess if the decomposition of EDA into the two components provided meaningful information, we also included a mixed component, which corresponds to the original one dimensional EDA response. As can be seen on the tables (bottom rows), the best performance achieved with this approach is below the best performance achieved by the best feature of the other two components. Furthermore, extracting the two components can help better interpret the results. For instance, higher average peak amplitude in the mixed component may correspond to a case where there is a high tonic level and small phasic peaks, or another case where there is low tonic level and large phasic peaks. By looking at features from the two components separately, such as mean and average of peak amplitudes of the tonic and phasic components, we can infer that the tonic component provides more discriminative information in this case. These results suggest the decomposition of EDA responses is recommended for this type of analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Engagement Recognition</head><p>While the previous section focused on the discriminative power of each feature independently, this section explores combining several features to determine the best possible performance. Furthermore, in order to assess the benefit of monitoring both interactive partners, we applied Sequential Forward Selection to IF and SF features separately, and then combined the two types.</p><p>When considering the IF features extracted from the child responses, incorporating SFS during the training phase yielded a performance of 74.35%. While different subsets of features were selected at each training fold, the top 3 most selected features were the position of maximum value (6 times) and the average peak amplitude (5 times) from the tonic component, and the standard deviation from the phasic component (4 times). When considering the SF features, incorporating SFS yielded a performance of 76.16%, which is slightly higher than using only individual features. In this case, the top 3 features were: DTW (8 times) and the differences between the number of peaks from the phasic components (6 times), and DTW from the tonic components (7 times). Interestingly, DTW were not among the best features when considered separately (53.12% and 50.52% from tonic and phasic components, respectively), but still provided relevant complementary information when combined with other features. outperforming any of the previous experiments. In this case the top 3 most selected features were the difference between the peaks of the dyad (7 times) from the phasic component, and the STD and DTW from the tonic components (5 times each).</p><p>Figure <ref type="figure">9</ref> provides an overall overview of the best results achieved by each feature type with and without incorporating SFS during the training phase. By combining different types of features, we were able to improve the recognition performance by 11.42%. Figure <ref type="figure">10</ref> shows in more detail the traditional ROC and Precision/Recall curves of the best subsets of features. Note that the results reported above correspond to the average between the two curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>Physiological signals have been extensively measured and analyzed in short controlled interactions that usually have not included spontaneous social interaction. This work is novel in examining continuous EDA activation during a spontaneous and structured social interaction, and using this information to build automated tools for recognizing how easy or hard a person is to engage.</p><p>Among some of the main findings, we found that the relative position of the maximum tonic value was the most discriminative feature to automatically identify easy to engage children. Furthermore, we compared several methods that captured the physiological synchrony of the dyad, and found the difference between the number of peaks of phasic components to yield similar performance. This finding indicates that both individual and synchrony features are relevant to modeling engagement during social interaction. However each component captures different aspects. While the tonic component is the most relevant information when only monitoring the child, the phasic component is especially helpful when capturing synchrony. Furthermore, we have shown that decomposing EDA responses into the tonic and phasic components provides some benefits for the analysis, such as improved recognition performance (&gt;6%) and increased interpretability of the findings. Finally, we showed that the combination of two feature types (IF+SF) yielded the highest classification performance (11% higher than using only the best single feature). In other words, using just the child's physiology to predict the ease of engagement score assigned by the adult was not as accurate as when the automatic system used both the child's physiology and its synchrony with the adult's physiology.</p><p>Despite the significant effort to maximize the utility of the EDA data -use of gel, a warm-up period to get children acclimated to the sensor and to gather extensive baseline data -data from 31% participants had to be excluded from the analysis due to the presence of large artifacts and quantization problems in at least one of the sensors.</p><p>Although we preprocessed the data to reduce short and high frequency motion artifacts, there were several cases where this approach was not enough. This challenge points out a limitation of our study but also highlights the great challenge of monitoring physiological information in uncontrolled environments, especially with small children.</p><p>In our case, one of the main sources of artifacts was due to the loss of contact of the sensor to the skin. Although this problem can be easily fixed by tightening the Velcro band that comes with the Q TM sensor, we noticed that doing so increased the child's awareness of the sensor, leading to fiddling with the sensor and thus additional motion artifacts. Finding the right trade-off between sensor tightness and awareness as well as finding the best location for the sensor (e.g., wrist vs. ankle) will probably be dependent on the age and skin of each person, and promises to be a relevant research area in the field of wearable computing.</p><p>Our final dataset consists of 51 sessions in which we monitored the time-varying physiological signals of both the child and the adult. Using this information, the present study has taken several steps towards maximizing the generalizability of the findings. First, we analyzed the recognition value of one single feature at a time, which ensures a high ratio between the number of samples and the dimensionality of the data. Second, we used an SVM in its linear form, which significantly reduces the complexity of the model. Third, we used a 10-fold-cross validation approach, which is typically used to avoid overfitting of the learned models, and ensured that we did not use data from the same people for training and testing simultaneously. Finally, we incorporated SFS as a feature selection method, which tends to find a small subset of features (i.e., reduced dimensionality) to help avoid overfitting. In the future, we plan to incorporate additional sessions and validate our method in similar conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p>This work extends the possibility of recognizing the ease of engagement of children from physiological data during naturalistic social interactions that can take place almost anywhere. Leveraging modern wearable biosensors, we monitored the electrodermal responses of 51 child-adult dyads in a semi-structured social interaction. We proposed several physiological features to characterize the responses of the children and their synchrony with the responses of the adults. We found that a combination of features extracted from the child's EDA activity and features capturing the physiological synchrony between the child and the adult resulted in the highest classification accuracy in distinguishing children who had been rated as more or less difficult to engage by the adult.</p><p>Future efforts may focus on analyzing the correlation of the EDA responses with features from other modalities (e.g., head pose, voice pitch) as they can provide relevant information to further understand and better recognize children's engagement. However, these modalities require additional sensors that may not be readily accessible in daily life situations. We may also analyze each of the different interactive stages independently, as well as taking into account the influence of preceding stages and large variability of stage durations.</p><p>This study has shown that new biosensor technology can be used to capture unobtrusively, in a playful spontaneous social interaction, objective physiological time-series data that is informative about an individual child's outwardly rated engagement. As such, this work takes an important first step towards providing better measures to reliably and objectively quantify interactive social behavior, an important advancement for the study of human development.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Javier Hernandez 1 1 Figure 1 .</head><label>111</label><figDesc>Figure 1. Interaction between child and adult during a ball play game.</figDesc><graphic coords="1,319.67,356.30,234.07,113.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Experimental setting.</figDesc><graphic coords="3,55.67,56.78,240.97,180.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. (From left to right) Representative moments of looking pictures in a book, book on as a hat, and tickling.</figDesc><graphic coords="3,58.97,541.70,175.21,132.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Examples of noisy EDA responses: quantization error (left), and movement of the sensor (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Normalized skin conductance (top-blue) and its tonic (green-dashed) and phasic (red-bottom) components for one of the child's sessions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Summary of features extracted from the physiological responses: (top) individual features extracted from the child, and (bottom) synchrony features extracted from both child and adult's responses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Average engagement score (blue) and standard error (green) for children in the harder to engage group. Low scores indicate easier interactions and high scores indicate more difficult interactions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Average EDA (blue) and standard error (green) of children in the easier (left) and harder (right) to engage groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .Figure 9 .</head><label>109</label><figDesc>Figure 10. Receiver Operating Characteristic (left) and Precision/Recall (right) curves for the best subsets of features when considering different types of features (individual features, synchrony features, and the combination of both). 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 . Classification scores (%) of synchrony features. (PC: Pearson product-moment correlation; CC: Canonical correlation; DTW: Dynamic Time Warping)</head><label>2</label><figDesc>Finally, we examined the recognition value of combining both IF and SF features. In this case, incorporating SFS yielded a classification performance of 81.03%,</figDesc><table><row><cell>Component</cell><cell>Mean</cell><cell>STD</cell><cell>Area</cell><cell>Position min.</cell><cell>Position max.</cell><cell>Slope</cell><cell>#Peaks</cell><cell>Avg. Peak Amplitude</cell></row><row><cell>Tonic</cell><cell>66.23</cell><cell>44.85</cell><cell>66.23</cell><cell>53.91</cell><cell>69.61</cell><cell>41.59</cell><cell>45.19</cell><cell>58.12</cell></row><row><cell>Phasic</cell><cell>55.33</cell><cell>64.67</cell><cell>50.33</cell><cell>49.50</cell><cell>57.75</cell><cell>53.83</cell><cell>42.10</cell><cell>47.68</cell></row><row><cell>Mixed</cell><cell>60.92</cell><cell>47.34</cell><cell>60.92</cell><cell>49.92</cell><cell>47.18</cell><cell>40.19</cell><cell>46.59</cell><cell>62.30</cell></row><row><cell cols="2">Component</cell><cell>PC</cell><cell>CC</cell><cell>DTW</cell><cell>Mean</cell><cell>#Peaks</cell><cell cols="2">Avg. Peak Amplitude</cell></row><row><cell></cell><cell>Tonic</cell><cell>59.38</cell><cell>54.13</cell><cell>53.12</cell><cell>50.32</cell><cell>45.73</cell><cell>50.45</cell><cell></cell></row><row><cell cols="2">Phasic</cell><cell>45.06</cell><cell>55.30</cell><cell>50.52</cell><cell>46.35</cell><cell>69.29</cell><cell>47.09</cell><cell></cell></row><row><cell cols="2">Mixed</cell><cell>63.18</cell><cell>50.36</cell><cell>45.64</cell><cell>48.54</cell><cell>43.21</cell><cell>51.79</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 . Classification scores (%) of individual features. (STD: Standard deviation)</head><label>1</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This material is based upon work supported by the National Science Foundation under Grant No. NSF CCF-1029585.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Early Interests and Joint Engagement in Typical Development, Autism, and Down Syndrome</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Adamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Autism Developmental Disorders</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="665" to="676" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Decomposition of skin conductance data by means of nonnegative deconvolution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Benedek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaernbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="647" to="658" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fifth Annual Workshop on Computational Learning Theory</title>
		<meeting>of the Fifth Annual Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Boucsein</surname></persName>
		</author>
		<title level="m">Electrodermal Activity</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>nd Ed</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Affect detection: An interdisciplinary review of models, methods, and their applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dmello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="37" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">LIBSVM: a library for Support Vector Machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Non-Homogeneous Poisson Process Model of Skin Conductance Responses Integrated with Observed Regulatory Behaviors for Autism Intervention</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chaspari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wilder-Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gulsrud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mucchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kasari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Audio, Speech and Signal Processing</title>
		<meeting>IEEE International Conference on Audio, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Facial Action Coding System: a technique for the measurement of facial movement</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Friesen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<publisher>Consulting Psychologists Press</publisher>
			<pubPlace>Palo Alto, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Social interaction in games: measuring physiological linkage and social presence</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chanel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kivikangas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salminen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jarvela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ravaja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Simulation and Gaming</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="321" to="338" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parent-infant synchrony and the construction of shared timing: physiological precursors, developmental outcomes, and risk conditions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Child Psychology and Psychiatry</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="329" to="354" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An introduction to variable and feature selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisseeff</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1157" to="1182" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Emotional contagion</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cacioppo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rapson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Measuring autonomic arousal during therapy</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schoen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Design and Emotion</title>
		<meeting>of Design and Emotion</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="11" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Measuring the engagement level of TV Viewers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hulten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Debarr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Krum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Call Center Stress Recognition with Person-Specific Models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Affective Computing and Intelligent Interaction</title>
		<meeting>of the Affective Computing and Intelligent Interaction</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weighted support vector machine for classification with uneven training class sizes</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning and Cybernetics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="4365" to="4369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Vision-based method for detecting driver drowsiness and distraction in driver monitoring system</title>
		<author>
			<persName><forename type="first">Jo</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="127202" to="127203" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural correlates of emotional synchrony</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Kühn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C N</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Leij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dijksterhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Van Baaren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="368" to="374" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">GSR reconsidered: a behavior based approach to evaluating and improving the sales potency of advertising</title>
		<author>
			<persName><forename type="first">P</forename><surname>Labarbera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tucciarone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Advertising Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="33" to="53" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Involuntary attention and physiological arousal evoked by structural features and mild emotion in TV commercials</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Proceedings of Communication Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="299" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Marital interaction: physiological linkage and affective exchange</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Levenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Gottman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="587" to="597" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Physiological aspects of emotional knowledge and rapport</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Levenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Ruef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empathic Accuracy</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Ickes</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Guilford Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="44" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Direct measurement of skin conductance: A proposal for standardization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Lykken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Venables</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="656" to="672" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Physiologic Correlates of Perceived Therapist Empathy and Social-emotional Process during Psychotherapy</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Marci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="middle">S P</forename><surname>Orr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Nervous and Mental Disease</title>
		<imprint>
			<biblScope unit="volume">195</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="111" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Joint attention and social-emotional approach behavior in children with autism</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mundy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Development and Psychopathology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="82" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Joint attention and neurodevelopment</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mundy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burnette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Autism and Pervasive Developmental Disorders</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Volkmar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Klin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</editor>
		<meeting><address><addrLine>Hoboken, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="650" to="681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How to capture the heart? Reviewing 20 years of emotion measurement in advertising</title>
		<author>
			<persName><forename type="first">K</forename><surname>Poels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dewitte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Advertising Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Abowd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rozga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Clements</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">Y</forename><surname>Ousley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Presti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lantsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Computer Vision and Pattern Recognition</title>
		<meeting>Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3414" to="3421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Predicting audience responses to movie content from electro-dermal activity signals</title>
		<author>
			<persName><forename type="first">F</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheppard</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Pervasive and Ubiquitous Computing</title>
		<meeting>Pervasive and Ubiquitous Computing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="707" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deducing the visual focus of attention from head pose estimation in dynamic multi-view meeting scenarios</title>
		<author>
			<persName><forename type="first">M</forename><surname>Voit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Multimodal Interfaces</title>
		<meeting>the International Conference on Multimodal Interfaces</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Eye fixations on advertisements and memory for brands: a model and findings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pieters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="297" to="312" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Head pose estimation in seminar room using multi view face detectors</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimodal Technologies for Perception of Humans</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="299" to="304" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
