<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Near Optimal Event-Triggered Control of Nonlinear Discrete-Time Systems Using Neurodynamic Programming</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Avimanyu</forename><surname>Sahoo</surname></persName>
						</author>
						<author role="corresp">
							<persName><roleName>Member, IEEE</roleName><forename type="first">Hao</forename><surname>Xu</surname></persName>
							<email>hao.xu@tamucc.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Intelligent Systems Center</orgName>
								<orgName type="institution">Missouri University of Science and Technology</orgName>
								<address>
									<settlement>Rolla</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Missouri University of Science and Technology</orgName>
								<address>
									<postCode>65409</postCode>
									<settlement>Rolla</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Electrical Engineering</orgName>
								<orgName type="department" key="dep2">College of Science and Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University-Corpus Christi</orgName>
								<address>
									<addrLine>Corpus Christi</addrLine>
									<postCode>78412</postCode>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Near Optimal Event-Triggered Control of Nonlinear Discrete-Time Systems Using Neurodynamic Programming</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1FBCE56AB1EB4CC5C48B0B7EC621BF01</idno>
					<idno type="DOI">10.1109/TNNLS.2015.2453320</idno>
					<note type="submission">received January 23, 2014; revised May 15, 2015 and June 7, 2015; accepted June 19, 2015. This work was supported in part by</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Event-triggered control (ETC)</term>
					<term>Hamilton-Jacobi-Bellman equation</term>
					<term>neural networks (NNs)</term>
					<term>neurodynamic programming (NDP)</term>
					<term>optimal control</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an event-triggered near optimal control of uncertain nonlinear discrete-time systems. Eventdriven neurodynamic programming (NDP) is utilized to design the control policy. A neural network (NN)-based identifier, with event-based state and input vectors, is utilized to learn the system dynamics. An actor-critic framework is used to learn the cost function and the optimal control input. The NN weights of the identifier, the critic, and the actor NNs are tuned aperiodically once every triggered instant. An adaptive event-trigger condition to decide the trigger instants is derived. Thus, a suitable number of events are generated to ensure a desired accuracy of approximation. A near optimal performance is achieved without using value and/or policy iterations. A detailed analysis of nontrivial inter-event times with an explicit formula to show the reduction in computation is also derived. The Lyapunov technique is used in conjunction with the event-trigger condition to guarantee the ultimate boundedness of the closedloop system. The simulation results are included to verify the performance of the controller. The net result is the development of event-driven NDP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>E VENT-TRIGGERED control (ETC) [1]- [6], which is evolved as an alternate control paradigm in the recent times, is found to be effective in terms of resource utilization. The ETC scheme uses events to sample the system state and execute the controller in an aperiodic manner. The aperiodic sampling and execution reduces the computational costs for the closed-loop system. In the case of a networked control system (NCS) <ref type="bibr" target="#b6">[7]</ref>, the ETC scheme saves network bandwidth due to the event-based aperiodic transmissions. The sampling and transmission instants, referred to as event-trigger instants, are decided using a state-dependent criterion. The threshold in the criterion is designed analytically via the Lyapunov stability technique. Thus, the event-triggered paradigm saves resources, and maintains both stability and closed-loop performance.</p><p>Recently, various ETC schemes <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b5">[6]</ref> have been introduced in the literature for linear <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> and nonlinear systems <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Typically, in the ETC schemes, the system dynamics are considered either completely known <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, or with a small uncertainty <ref type="bibr" target="#b2">[3]</ref>.</p><p>In contrast, in <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b5">[6]</ref>, an attempt has been made to design the event-based controllers for systems with uncertain dynamics. In <ref type="bibr" target="#b4">[5]</ref>, the knowledge of the system dynamics is partially relaxed using an event-based neural network (NN) approximator. The NN-based design is extended to the case of completely unknown dynamics in <ref type="bibr" target="#b5">[6]</ref>. In both the cases, the state-dependent criteria, referred to as event-trigger conditions, are made adaptive. This is in contrast with the traditional nonadaptive event-trigger conditions <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. These adaptive criteria generated a required number of events during the initial online learning phase of NN. This facilitated the eventbased approximation of the unknown dynamics with aperiodic weight update. A tradeoff is observed between the accuracy of NN approximation and the reduction in computation. However, these controller designs <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> render only stability without optimizing any performance index.</p><p>Imer and Basar <ref type="bibr" target="#b8">[9]</ref> studied the optimal ETC in a constrained communication scenario using the certainty equivalence principle. Furthermore, Molin and Hirche <ref type="bibr" target="#b9">[10]</ref> extended the linear quadratic Gaussian approach to an event-triggered context using a separation principle. However, these methods <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> use backward-in-time Riccati equation-based solution with completely known system dynamics.</p><p>Traditionally, adaptive dynamic programming <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[14]</ref> or neurodynamic programming (NDP) <ref type="bibr" target="#b14">[15]</ref> techniques are used to design the optimal control policy in a forward-in-time and online manner. These techniques use the policy and/or value iterations to solve the Hamilton-Jacobi-Bellman (HJB) equation online. However, a significant number of iterations within a sampling interval are needed to maintain the system stability resulting in a high computational cost. Furthermore, the knowledge of the control coefficient function is also necessary to compute the optimal control policy.</p><p>For a finite-time <ref type="bibr" target="#b15">[16]</ref> optimal control, the solution to the HJB equation (i.e., the cost function) becomes explicitly time varying. The terminal cost constraint must also be satisfied at the same time. The event-based sampling of the state vector and uncertain system dynamics complicate the problem further. Therefore, NDP over the finite-horizon becomes more involved than in the infinite horizon case.</p><p>Motivated by the above limitations, in this paper, we propose a novel NDP technique to solve the fixed final time optimal control. An event-triggered uncertain nonlinear discrete-time system is considered for the purpose of design. The proposed approach functions in a forward-in-time and online manner. Two NNs, in an actor-critic <ref type="bibr" target="#b16">[17]</ref> framework, are used to approximate the time-varying cost function and the optimal control input. An NN identifier is also used to relax the complete knowledge of the system dynamics. A novel adaptive event-trigger condition is developed which not only reduces the number of controller updates but also facilitates the NN approximation.</p><p>Aperiodic NN tuning laws are introduced to update the identifier, the actor, and the critic NN weights. The NN weights are updated once a triggered instant and held during the interevent times. These aperiodic updates reduce the computation when compared with the traditional NN-based schemes <ref type="bibr" target="#b17">[18]</ref>. The Lyapunov direct method in <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b18">[19]</ref> is used to prove the ultimate boundedness (UB) of the closed-loop eventtriggered system.</p><p>The contributions of this paper include: 1) the design of the event-triggered finite-time optimal control scheme for an uncertain nonlinear discrete-time system; 2) the design of a novel adaptive event-trigger condition; 3) the development of the tuning scheme to update the NNs aperiodically to save the computation; and 4) the demonstration of the closed-loop stability using the Lyapunov technique.</p><p>The rest of this paper is organized as follows. Section II presents the background along with the problem statement. Section III details the finite-horizon event-based optimal control design. The main results are claimed in Section IV, and the nontriviality of the inter-event times is discussed in Section V. The simulation results are included in Section VI. Finally, the conclusions are drawn in Section VII. The Appendix contains the detailed proofs of the lemmas and the theorems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>In this section, we present a brief background on the ETC. Subsequently, the near optimal control design is formulated. A discussion on the extension of NN approximation to eventbased sampling is also presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Background on ETC</head><p>Consider the uncertain nonlinear discrete-time system represented as</p><formula xml:id="formula_0">x k+1 = f (x k ) + g(x k )u k (1)</formula><p>where x k ∈ n and u k ∈ m represent the system state and the control input vectors, respectively. The smooth functions f (x k ) ∈ n and g(x k ) ∈ n×m denote the system dynamics that are considered unknown. Let the equilibrium point x = 0 be unique in a compact set D x for all</p><formula xml:id="formula_1">x k ∈ D x ⊂ n .</formula><p>The following standard assumption is necessary in order to proceed.</p><p>Assumption 1: The system (1) is controllable and observable. The unknown control coefficient matrix g(x k ) is bounded for all x k ∈ D x , such that g(x k ) ≤ g M , where g M &gt; 0 is a known positive constant. The state vector is available for the measurement.</p><p>In the event-triggered formalism, the system state vector x k is released, and the controller is updated only when an event occurs. Hence, zero-order-holds (ZOHs) are used to retain the last event-sampled state and the control input vectors until the next arrive. The error between the current measured state vector, x k , and the state vector at the ZOH, xk , is referred to as event-trigger error. It is defined by</p><formula xml:id="formula_2">e ET,k = x k -xk .</formula><p>(</p><formula xml:id="formula_3">)<label>2</label></formula><p>The event-trigger error ( <ref type="formula" target="#formula_3">2</ref>) is used to determine the event-trigger instants by comparing it with a state-dependent threshold. A monotonically increasing subsequence of time instants {k i } ∞ i=1 with k 0 = 0 can be defined as the event-trigger instants. The last held state vector, xk , at ZOH is updated at each k = k i for i = 1, 2, . . . with the current system state. Thus, the last held state vector can be written as</p><formula xml:id="formula_4">xk = x k i , k i ≤ k &lt; k i+1 , i = 1, 2, . . . (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>In an event-based framework, the control input can be described as</p><formula xml:id="formula_6">u k = υ( xk ), k i ≤ k &lt; k i+1 ∀ i = 1, 2, . . . (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where υ( xk ) is a function of the event-based state vector.</p><p>Next, the problem for the finite-horizon optimal control in an event-based scenario is formulated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Problem Formulation</head><p>Our primary objective is to design a sequence of control inputs, u k , to minimize a time-varying cost function in an ETC framework. The cost function is given by</p><formula xml:id="formula_8">V (x k , k) = ψ(x N , N) + N-1 j =k r (x j , u j , j )<label>(5)</label></formula><p>where r (x j , u j , j</p><formula xml:id="formula_9">) = Q(x j , j ) + u T j Ru j is the cost-to-go in the interval of interest j ∈ [k, N]. The function Q(x k , k) ∈</formula><p>is a positive definite function that penalizes the system state, x k . The matrix R ∈ m×m is a positive definite matrix that penalizes the control input, u k . The terminal cost ψ(x N , N) penalizes the terminal state x N , where N is the terminal time instant. For the finite-horizon case, the cost-to-go, r (x k , u k , k), depends explicitly on time k in the interval of interest [k, N]. Therefore, the control input also becomes time varying.</p><p>Assumption 2: The initial control input, u 0 , is admissible <ref type="bibr" target="#b16">[17]</ref> to keep the cost function finite.</p><p>The terminal cost for the finite-horizon cost function ( <ref type="formula" target="#formula_8">5</ref>) can be written as</p><formula xml:id="formula_10">V (x N , N) = ψ(x N , N)<label>(6)</label></formula><p>where V (x N , N) is the cost at the terminal time N. The cost function <ref type="bibr" target="#b4">(5)</ref> can also be rewritten as</p><formula xml:id="formula_11">V (x k , k) = r (x k , u k , k) + V (x k+1 , k + 1)<label>(7)</label></formula><p>where V (x k+1 , k + 1) = V (x N , N ) + N-1 j =k+1 r (x j , u j , j ) is the cost from time instant k + 1 onward. According to Bellman's principle of optimality, the optimal cost, V * (x k , k), satisfies the discrete-time HJB equation. It is given by</p><formula xml:id="formula_12">V * (x k , k) = min u k {r (x k , u k , k) + V * (x k+1 , k + 1)} (8)</formula><p>where V * (x k , k) is the optimal cost at the time instant k, and V * (x k+1 , k + 1) is the optimal cost for k + 1 onward. The optimal control sequence u * k can be derived using the stationarity condition <ref type="bibr" target="#b7">[8]</ref> and written as</p><formula xml:id="formula_13">u * k = -(1/2)R -1 g T (x k )∂ V * (x k+1 , k + 1)/∂ x k+1 . (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>The optimal control policy (9) depends explicitly on the solution of the HJB equation, i.e., the optimal cost V * (x k , k). The control policy is also a function of control coefficient function g(x k ) and the state vector x k+1 at the time instant k.</p><p>It is practically almost impossible to find an analytical solution of the HJB equation. Therefore, approximationbased techniques (NDP) are used to solve the HJB equation. In this paper, the actor and the critic NNs are utilized to approximate both the optimal control policy and the cost function, respectively, with the event-based availability of the system state vector. Hence, the universal approximation property of the NNs is revisited with an extension to eventbased approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. NN Approximation with Event-Based Sampling</head><p>The universal approximation property <ref type="bibr" target="#b17">[18]</ref> of NN can be extended to achieve a desired level of accuracy with the eventbased availability of the state vector in <ref type="bibr" target="#b2">(3)</ref>. The following theorem extends the approximation property of NNs for eventbased sampling.</p><p>Theorem 1: Let h(x k , k) ∈ n be a smooth and continuous function in a compact set for all x ∈ D x . Then, there exists an NN with a sufficient number of neurons, such that h(x k , k) can be approximated with event-sampled inputs. Furthermore, the function h(x k , k) with the constant weights and the eventbased time-varying activation function is given by</p><formula xml:id="formula_15">h(x k , k) = W T σ ( xk , k) + ε e ( xk , e ET,k , k) (<label>10</label></formula><formula xml:id="formula_16">)</formula><p>where  <ref type="figure">ε(x k ,</ref><ref type="figure">k</ref>). An arbitrarily small event-based reconstruction error can be obtained by increasing both the frequency of events and the number of neurons. Consequently, the design of an event-trigger condition is necessary by considering a tradeoff between the reconstruction error and the computational load.</p><formula xml:id="formula_17">W</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EVENT-BASED OPTIMAL CONTROLLER DESIGN</head><p>In this section, the near optimal event-triggered controller design is detailed for the uncertain discrete-time system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proposed Solution</head><p>The proposed optimal ETC system is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. It consists of: 1) a nonlinear discrete-time system, smart sensor, and trigger mechanism with a mirror actor-critic network and 2) an event-based optimal controller. The event-based optimal controller entails three NNs as online approximators: 1) the identifier; 2) the critic; and 3) the actor NNs. These three NNs are used to approximate the system dynamics, the time-varying cost function, which is the solution to the HJB equation, and the control input, respectively. All the NNs use activation functions with event-sampled inputs. The NN weights are updated at the trigger instants only in an aperiodic manner.</p><p>The event-trigger instants, k i for i = 1, 2, . . . are decided by the smart sensor and the trigger-mechanism. The event-trigger condition is evaluated at every time instant k to determine the trigger instants. At the trigger instants, the current system state vector, x k i , and its previous value x k i -1 for i = 1, 2, . . . are together sent to the controller. These event sampled state vectors are subsequently used to update the NN weights and the control input. The updated value of the control input is then sent to the system and held by the ZOH, and utilized until the next update.</p><p>Most importantly, the event-trigger condition is made adaptive by designing a suitable threshold. This adaptive trigger condition ensures an online approximation of nonlinear functions, as discussed in Remark 1. The threshold is designed as a function of the actor NN weight estimates and the system state vector. To evaluate the event-trigger condition, the trigger mechanism consists of a mirror actor-critic NN (see Fig. <ref type="figure" target="#fig_0">1</ref>). This mirror actor-critic NN operates in synchronism with the one at the controller. Both the actor-critic NNs are initialized with the same initial values. The NN weights are adjusted with the events. Thus, the adaptive trigger condition gets updated at every trigger instant. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS Remark 2: The mirror actor-critic NN estimates the NN weights locally at the trigger mechanism, thus relaxing the need for the transmission of NN weights from the controller to the trigger mechanism in the case of NCS. Therefore, the transmission cost only depends upon the transmission of the system state and the control input vector. Although, the addition of a mirror actor-critic NN increases the computational cost, the overall computation is still reduced due to the eventbased execution (also see the simulation section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Identifier Design</head><p>The input coefficient matrix function g(x k ) is required to compute the optimal control policy (9). This will be generated by the NN-based identifier. The universal approximation property of NNs, in a compact set, can be used to represent the nonlinear system in <ref type="bibr" target="#b0">(1)</ref>. It is given by</p><formula xml:id="formula_18">x k+1 = W T I σ I (x k ) ūk + ε I (x k ) (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>where</p><formula xml:id="formula_20">W I = [W T f W T g ] T ∈ (m+1</formula><p>)l I ×n denotes the unknown constant target weight matrix of the identifier NN. The matrices</p><formula xml:id="formula_21">W f ∈ l I ×n , W g = [W T g1 W T g2 . . . W T gm ] T ∈ ml I ×n and W gp ∈ l I ×n for p = 1, . . . , m. The function σ I (x k ) = diag{σ f (x k ), σ g (x k )} ∈ (m+1)l I ×(m+1) represents the NN activation function matrix, where σ f (x k ) ∈ l I and σ g (x k ) = diag{σ g1 (x k ), σ g2 (x k ), . . . , σ gm (x k )} ∈ ml I ×m . Furthermore, ε I (x k ) = ε f (x k ) + ε g (x k )u k ∈ n</formula><p>denotes the identifier NN reconstruction error, where ε f (x k ) ∈ n and ε g (x k ) ∈ n×m are the traditional reconstruction errors and ūk = [1 u T k ] T ∈ m+1 is the augmented control input. The subscript f and g are used to denote the variable for the functions f (x k ) and g(x k ), respectively. The number of neurons in the hidden layer is denoted by l I . The notation diag{•} denotes the matrix formed by the activation function vectors as diagonal blocks, and the off diagonals are zero vectors of appropriate dimensions.</p><p>Assumption 3 <ref type="bibr" target="#b17">[18]</ref>: The target weight vector, W I , the activation function, σ I (x k ), and the traditional reconstruction error,</p><formula xml:id="formula_22">ε I (x k ), of the NN are upper bounded, such that W I ≤ W I,M , σ I (•) ≤ σ I,M and ε I (•) ≤ ε I,M</formula><p>, where W I,M , σ I,M , and ε I,M are positive constants.</p><p>The control input is updated only at the event-trigger instants and requires the approximated identifier dynamics at these instants. Therefore, the event-based identifier dynamics can be represented as <ref type="bibr" target="#b11">(12)</ref> where xk ∈ n being the identifier state vector at the time instant k. The functions f ( xk ) ∈ n and ĝ( xk ) ∈ n×m represent the approximated identifier dynamics. Note that the identifier structure is based on event-sampled states and held during the inter-event times. This novel event-based structure is selected to reduce an additional and redundant computation during the inter-event times.</p><formula xml:id="formula_23">xk+1 = f ( xk ) + ĝ( xk )u k , k i ≤ k &lt; k i+1 , i = 1, 2, . . .</formula><p>The identifier dynamics <ref type="bibr" target="#b11">(12)</ref> with the NN approximation can be written as</p><formula xml:id="formula_24">xk+1 = Ŵ T I,k σ I ( xk ) ūk , k i ≤ k &lt; k i+1 (<label>13</label></formula><formula xml:id="formula_25">)</formula><p>where</p><formula xml:id="formula_26">ŴI,k = [ Ŵ T f,k Ŵ T g,k ] T ∈ (m+1</formula><p>)l I ×n is the actual estimated weight matrix, and σ I ( xk ) ∈ (m+1)l I ×(m+1) is the event-sampled activation function matrix for the identifier NN.</p><p>The identification error can be written as e I,k = x k -xk . Hence, the identification error dynamics using <ref type="bibr" target="#b10">(11)</ref> and ( <ref type="formula" target="#formula_24">13</ref>) are found to be</p><formula xml:id="formula_27">e I,k+1 = W T I,k σ I (x k ) ūk + Ŵ T I,k (σ I (x k ) -σ I ( xk )) ūk + ε I,k<label>(14)</label></formula><p>for Consider the case when an event is triggered, i.e., xk = x k for k = k i . The identifier dynamics in <ref type="bibr" target="#b12">(13)</ref> with the updated state vector can be expressed as</p><formula xml:id="formula_28">k i ≤ k &lt; k i+1 , i = 1,</formula><formula xml:id="formula_29">xk+1 = Ŵ T I,k σ I (x k ) ūk , k = k i , i = 1, 2, . . . (<label>15</label></formula><formula xml:id="formula_30">)</formula><p>Therefore, the identification error dynamics from ( <ref type="formula" target="#formula_27">14</ref>) for k = k i are written as</p><formula xml:id="formula_31">e I,k+1 = W T I,k σ I (x k ) ūk + ε I,k , k = k i , i = 1, 2, . . . (<label>16</label></formula><formula xml:id="formula_32">)</formula><p>The event-based tuning law for the NN identifier weights now can be selected as</p><formula xml:id="formula_33">ŴI,k = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ ŴI,k-1 + α I σ I (x k-1 ) ūk-1 e T I,k [σ I (x k-1 ) ūk-1 ] T [σ I (x k-1 ) ūk-1 ] + 1 k = k i ŴI,k-1 , k i-1 &lt; k &lt; k i (<label>17</label></formula><formula xml:id="formula_34">)</formula><p>where α I is the learning gain. The update law (17) requires the state vector x k i -1 at trigger instant k = k i . Hence, the current state, x k i , and the previous state, x k i -1 , are together sent to the controller, as proposed in Section III-A. The weight update law ( <ref type="formula" target="#formula_33">17</ref>) is aperiodic in nature and hence saves the computation. The identifier NN weight estimation error dynamics from <ref type="bibr" target="#b16">(17)</ref>, forwarding one time instant ahead, can be expressed as</p><formula xml:id="formula_35">WI,k+1 = ⎧ ⎪ ⎨ ⎪ ⎩ WI,k - α I σ I (x k ) ūk e T I,k+1 [σ I (x k ) ūk ] T [σ I (x k ) ūk ] + 1 , k = k i WI,k , k i &lt; k &lt; k i+1 . (<label>18</label></formula><formula xml:id="formula_36">)</formula><p>The UB of the identifier NN weight estimation error is guaranteed by the following lemma. Before introducing the lemma, the following assumption is needed.</p><p>Assumption 4: The identifier NN activation function</p><formula xml:id="formula_37">σ I (x k ) is Lipschitz continuous in a compact set for all x k ∈ D x . Then, there exists a constant C σ I , such that σ I (x k ) -σ I ( xk ) ≤ C σ I x k -xk .</formula><p>Lemma 1: Consider the nonlinear discrete-time system (1) along with the identifier <ref type="bibr" target="#b12">(13)</ref>. Assume Assumption 1 through 4 hold and the NN initial weights, ŴI,0 , is initialized in a compact set. Let the identifier NN weights are tuned by <ref type="bibr" target="#b16">(17)</ref> at the event-trigger instants, and the activation function σ I (x k ) satisfies the persistency of excitation (PE) condition <ref type="bibr" target="#b17">[18]</ref>.</p><p>Suppose the control input is stabilizing and the learning gain α I satisfies 0 &lt; α I &lt; 1/2. Then, there exist two positive integers T and T , such that the weight estimation error WI,k is UB with a bound B M W ,I for all k i &gt; k 0 + T or, alternatively,</p><formula xml:id="formula_38">k ≥ k 0 + T for T is a function of T.</formula><p>Proof: Refer to the Appendix. The stabilizing assumption for the control input is later relaxed in the closed-loop stability proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Controller Design</head><p>In this section, event-based actor-critic NN designs are presented. Besides the HJB or temporal difference (TD) error, an additional error term corresponding to the terminal cost is defined and used to tune the critic NN, such that the terminal cost can be properly satisfied.</p><p>1) Critic NN Design: Consider <ref type="bibr" target="#b6">(7)</ref>. It can be rewritten as</p><formula xml:id="formula_39">0 = V (x k+1 , k + 1) + Q(x k , k) + u T k Ru k -V (x k , k). (<label>19</label></formula><formula xml:id="formula_40">)</formula><p>The cost function in (5) using the universal approximation property of NN <ref type="bibr" target="#b17">[18]</ref> in a compact set can be written as</p><formula xml:id="formula_41">V (x k , k) = W T V ϕ(x k , k) + ε V ,k<label>(20)</label></formula><p>where W V ∈ l V is the unknown constant target critic NN weights, and</p><formula xml:id="formula_42">ϕ(x k , k) ∈ l V is the time-varying activation function. The traditional NN reconstruction error is denoted by ε V ,k = ε V (x k , k) ∈ , for brevity.</formula><p>The number of hidden layer neurons in the network is given by l V . The following assumption holds for the critic NN.</p><p>Assumption 5 <ref type="bibr" target="#b16">[17]</ref>: The target NN weights, the activation functions, and the reconstruction errors of the critic NN are bounded above and satisfy</p><formula xml:id="formula_43">W V ≤ W V ,M , ϕ(•, •) ≤ ϕ M , and |ε V (•, •)| ≤ ε V ,M</formula><p>, where W V ,M , ϕ M and ε V ,M are positive constants. The gradient of the activation function and the reconstruction error satisfies ∂ϕ(</p><formula xml:id="formula_44">•, k)/∂(•) ≤ ∇ϕ M and ∂ε V (•, k)/∂(•, k) ≤ ∇ε V ,M</formula><p>, where ∇ϕ M and ∇ε V ,M are positive constants. In addition, the activation function,</p><formula xml:id="formula_45">ϕ(x k , k), is Lipschitz continuous for all x k ∈ D x and satisfies ϕ(x k , k) -ϕ( xk , k) ≤ C ϕ x k -xk = C ϕ e ET,k</formula><p>, where C ϕ is a positive constant. Equation ( <ref type="formula" target="#formula_39">19</ref>) with ( <ref type="formula" target="#formula_41">20</ref>) can be expressed as</p><formula xml:id="formula_46">0 = W T V ϕ(x k , k) + Q(x k , k) + u T k Ru k + ε V ,k (21)</formula><p>where</p><formula xml:id="formula_47">ϕ(x k , k) = ϕ(x k+1 , k + 1) -ϕ(x k , k) and ε V ,k = ε V ,k+1 -ε V ,k .</formula><p>The approximated/estimated cost function by the critic NN with the event-based system states, xk , can be represented as</p><formula xml:id="formula_48">V ( xk , k) = Ŵ T V ,k ϕ( xk , k), k i ≤ k &lt; k i+1 , i = 1, 2, . . . (<label>22</label></formula><formula xml:id="formula_49">)</formula><p>where Ŵ T V ,k ∈ l V is the estimated weight, and ϕ( xk , k) ∈ l V is the event-based time-varying activation function. The activation function is selected, such that ϕ(0, k) = 0 for x k = 0 in order to ensure V (0) = 0. The approximated cost function <ref type="bibr" target="#b21">(22)</ref> with the event-based availability of the system state xk for k i ≤ k &lt; k i+1 , i = 1, 2, . . . does not satisfy the relation <ref type="bibr" target="#b20">(21)</ref>. Therefore, the HJB error or the TD error, e HJB,k , associated with ( <ref type="formula">21</ref>) can be written as</p><formula xml:id="formula_50">e HJB,k = Q( xk , k) + u T k Ru k + V ( xk+1 , k + 1) -V ( xk , k) (23) for k i ≤ k &lt; k i+1 , i = 1, 2, . . . Note that Q( xk , k</formula><p>) is a function of the event-based state vector.</p><p>The HJB equation or the TD error (23) with the approximated cost function <ref type="bibr" target="#b21">(22)</ref> can be represented as</p><formula xml:id="formula_51">e HJB,k = Ŵ T V ,k ϕ( xk , k) + Q( xk , k) + u T k Ru k , k i ≤ k &lt; k i+1 (24) where V ( xk+1 , k + 1) = Ŵ T V ,k ϕ( xk+1 , k + 1), and ϕ( xk , k) = ϕ( xk+1 , k + 1) -ϕ( xk , k).</formula><p>The terminal cost <ref type="bibr" target="#b5">(6)</ref> in term of NN approximation <ref type="bibr" target="#b19">(20)</ref> can also be represented as</p><formula xml:id="formula_52">V (x N , N) = W T V ϕ(x N , N) + ε V ,N<label>(25)</label></formula><p>where ϕ(x N , N) and ε V ,N = ε V (x N , N) are the activation function and the reconstruction error, respectively, at the terminal time N.</p><p>The approximated/estimated terminal cost from ( <ref type="formula" target="#formula_48">22</ref>) can be expressed as</p><formula xml:id="formula_53">V (x N , N) = Ŵ T V ,N ϕ(x N , N). (<label>26</label></formula><formula xml:id="formula_54">)</formula><p>The terminal state vector, x N , is not known. Thus, it is not possible to compute the estimated terminal cost (26) at time k and hence the actual terminal cost error. Therefore, a projected terminal cost error, e FC,k , can be represented as the difference between the desired terminal cost and the estimated cost at time instant, k. It is represented by</p><formula xml:id="formula_55">e FC,k = ψ(x N , N) -Ŵ T V ,k ϕ( xk , N) k i ≤ k &lt; k i+1 , i = 1, 2, . . . (<label>27</label></formula><formula xml:id="formula_56">)</formula><p>The activation function, ϕ( xk , N), is an explicit function of the final time N which is known. Thus, we can compute ϕ( xk , N) at time k. The total error in cost function estimation becomes</p><formula xml:id="formula_57">e total,k = e HJB,k + e FC,k , k i ≤ k &lt; k i+1 , i = 1, 2, . . . (<label>28</label></formula><formula xml:id="formula_58">)</formula><p>At the event-trigger instants, k = k i , i = 1, 2, . . . the HJB equation or the TD error can be written from (24) as</p><formula xml:id="formula_59">e HJB,k = Ŵ T V ,k ϕ(x k , k) + Q(x k , k) + u T k Ru k (29) where ϕ(x k , k) = ϕ(x k+1 , k + 1) -ϕ(x k , k). Similarly, the terminal cost error from (27) for k = k i , i = 1, 2, . . . becomes e FC,k = ψ(x N , N) -Ŵ T V ,k ϕ(x k , N). (<label>30</label></formula><formula xml:id="formula_60">)</formula><p>The total error at trigger instant by combining (29) and ( <ref type="formula" target="#formula_59">30</ref>) becomes</p><formula xml:id="formula_61">e total,k = Ŵ T V ,k φ(x k , k) + Q(x k , k) + u T k Ru k + ψ(x N , N) (31) for k = k i , i = 1, 2, . . ., where φ(x k , k) = ϕ(x k , k) - ϕ(x k , N). IEEE</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</head><p>To minimize the total error in an event-triggered context, the update law of the critic NN, using the previous values, can be selected as</p><formula xml:id="formula_62">ŴV,k = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ ŴV,k-1 - α V φ(x k-1 , k -1)e T total,k-1 φT (x k-1 , k -1) φ(x k-1 , k -1) + 1 k = k i ŴV,k-1 , k i-1 &lt; k &lt; k i (<label>32</label></formula><formula xml:id="formula_63">)</formula><p>where α V &gt; 0 is the learning gain,</p><formula xml:id="formula_64">φ(x k-1 , k -1) = ϕ(x k-1 , k -1) -ϕ(x k-1 , N).</formula><p>The total error e total,k-1 can be computed from (31) by moving one time step backward.</p><p>Remark 3: Similar to the identifier NN, the critic NN weights are updated at the trigger instants only and held during the inter-event times in an aperiodic manner. This further saves the computation when compared to the traditional NN-based control.</p><p>Adding the difference between ( <ref type="formula">21</ref>) and ( <ref type="formula">24</ref>) to ( <ref type="formula" target="#formula_55">27</ref>), the total error can be represented in terms of the critic NN weight estimation error, WV,k = W V -ŴV,k . It is found to be</p><formula xml:id="formula_65">e total,k = -W T V ,k φ( xk , k) -W T V φ(x k , xk , k) -Q(x k , xk , k) + W T V (ϕ(x N , N)-ϕ( xk , N))-εV,k , k i ≤ k &lt; k i+1 (33)</formula><p>where</p><formula xml:id="formula_66">εV,k = ε V ,k -ε V ,N , φ( xk , k) = ϕ( xk , k) - ϕ( xk , N), Q(x k , xk , k) = Q(x k , k) -Q( xk , k), and φ(x k , xk , k) = ϕ(x k , k) -ϕ( xk , k). It is routine to check φ(•, •) ≤ φM and</formula><p>εV,k ≤ εV,M from Assumption 5, where φM and εV,M are positive constants. The total error at the event-trigger instant from (33) with</p><formula xml:id="formula_67">xk = x k for k = k i becomes e total,k = -W T V ,k φ(x k , k) + W T V (ϕ(x N , N) -ϕ(x k , N)) -εV,k . (34)</formula><p>The critic NN weight estimation error dynamics, from (32) by moving one step forward, can be expressed as</p><formula xml:id="formula_68">WV,k+1 = ⎧ ⎪ ⎨ ⎪ ⎩ WV,k + α V φ(x k , k)e T total,k φT (x k , k) φ(x k , k) + 1 , k = k i WV,k , k i &lt; k &lt; k i+1 . (<label>35</label></formula><formula xml:id="formula_69">)</formula><p>Next, the actor NN design is presented.</p><p>2) Actor NN Design: In this section, we approximate the optimal control policy through the actor NN to implement it forward in time. The identified control coefficient matrix of the NN identifier is also used to update the actor NN.</p><p>The optimal control input (9) by the approximation property of NN <ref type="bibr" target="#b17">[18]</ref> in a compact set can be written as</p><formula xml:id="formula_70">u * k = W T u σ u (x k , k) + ε u,k<label>(36)</label></formula><p>where W u ∈ l u ×m is the unknown constant target weight matrix, σ u (x k , k) ∈ l u is the time-varying activation function, and</p><formula xml:id="formula_71">ε u,k = ε u (x k , k) ∈ m</formula><p>is the traditional reconstruction error with l u neurons in the hidden layer.</p><p>Assumption 6: The target NN weights, the activation function, and the reconstruction error of the actor NN are upper bounded and satisfy</p><formula xml:id="formula_72">W u ≤ W u,M , σ u (•, •) ≤ σ u,M and ε u (•, •) ≤ ε u,M</formula><p>, where W u,M , σ u,M , and ε u,M are positive constants. The actor NN activation function is Lipschitz continuous for all</p><formula xml:id="formula_73">x k ∈ D x , such that σ u (x k , k) -σ u ( xk , k) ≤ C σ u x k -xk = C σ u e ET,k , where C σ u is a positive constant.</formula><p>Moreover, the optimal control input (9) using the gradient of cost function <ref type="bibr" target="#b19">(20)</ref> can be expressed as</p><formula xml:id="formula_74">u * V ,k = -(1/2)R -1 g T (x k )∇ϕ T (x k+1 , k + 1)W V -(1/2)R -1 g T (x k )∇ε V ,k+1<label>(37)</label></formula><p>where ∇ϕ(x k+1 , k + 1) = ∂ϕ(x k+1 , k + 1)/∂ x k+1 and ∇ε V ,k+1 = ∂ε V (x k+1 , k + 1)/∂ x k+1 . Both the optimal control inputs (36) and (37) should be equal. Their difference can be expressed as</p><formula xml:id="formula_75">0 = W T u σ u (x k , k)+ε u,k +(1/2)R -1 g T (x k ) ∇ϕ T (x k+1 , k +1)W V + (1/2)R -1 g T (x k )∇ε V ,k+1 . (38)</formula><p>The approximated/estimated optimal control input by the actor NN in an event-trigger context can be represented as</p><formula xml:id="formula_76">u k = Ŵ T u,k σ u ( xk , k), k i ≤ k &lt; k i+1 , i = 1, 2, . . . (<label>39</label></formula><formula xml:id="formula_77">)</formula><p>where Ŵu,k ∈ l u ×m is the estimated actor NN weights, and σ u ( xk , k) ∈ l u denotes the time-varying event-based activation function. Furthermore, the estimated control input, u V ,k , using the gradient of the estimated cost function <ref type="bibr" target="#b21">(22)</ref>, can also be written as</p><formula xml:id="formula_78">u V ,k = -(1/2)R -1 ĝT ( xk )∇ϕ T ( xk+1 , k + 1) ŴV,k (40)</formula><p>for k i ≤ k &lt; k i+1 , i = 1, 2, . . ., where ĝ( x) is the approximated event-based control coefficient matrix from the NN-based identifier and ∇ϕ( xk+1 , k + 1) = ∂ϕ( xk+1 , k + 1)/∂ x k+1 . The control policy (39) applied to the system (1) and the control policy (40), which minimizes the estimated cost function <ref type="bibr" target="#b21">(22)</ref> will not satisfy (38). Hence, the control input estimation error, e u,k for k i ≤ k &lt; k i+1 , i = 1, 2, . . . is represented as the difference between (39) and (40), and found to be</p><formula xml:id="formula_79">e u,k = Ŵ T u,k σ u ( xk , k) + (1/2)R -1 ĝT ( xk )∇ϕ T ( xk+1 , k + 1) ŴV,k . (41)</formula><p>Similar to the critic NN, the actor NN weight update law in an event-triggered context, using the previous values, is chosen as</p><formula xml:id="formula_80">Ŵu,k = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ Ŵu,k-1 - α u σ u (x k-1 , k -1)e T u,k-1 σ T u (x k-1 , k -1)σ u (x k-1 , k -1) + 1 k = k i Ŵu,k-1 , k i-1 &lt; k &lt; k i (<label>42</label></formula><formula xml:id="formula_81">)</formula><p>where α u is the learning gain. The error e u,k-1 , k = k i can be computed form (41) with</p><formula xml:id="formula_82">xk i -1 = x k i -1 as e u,k-1 = Ŵ T u,k-1 σ u (x k-1 , k -1) + (1/2)R -1 ĝT (x k-1 )∇ϕ T (x k-1 , k -1) ŴV,k-1 . (43)</formula><p>The control input estimation error can be expressed in terms of the actor NN weight estimation error, Wu,k , by subtracting (38) from (41). This is described by</p><formula xml:id="formula_83">e u,k = -W T u,k σ u ( xk , k) -(1/2)R -1 g T ( xk ) × ∇ϕ T ( xk+1 , k + 1) WV,k + (1/2)R -1 gT (x k ) × ∇ϕ T ( xk+1 , k + 1) WV,k -(1/2)R -1 gT ( xk ) × ∇ϕ T ( xk+1 , k + 1)W V + ε sum1 u,k k i ≤ k &lt; k i+1 , i = 1, 2, . . . (<label>44</label></formula><formula xml:id="formula_84">)</formula><p>where</p><formula xml:id="formula_85">ε sum1 u,k = -W T u σ u (x k , xk , k) -(1/2)R -1 g T ( xk ) ×∇ φT (x k+1 , xk+1 , k + 1)W V -(1/2)R -1 gT (x k , xk ) ×∇ϕ T (x k+1 , k + 1)W V -(1/2)R -1 g T (x k ) ×∇ε V ,k+1 -ε u,k with g(x k , xk ) = g(x k ) -g( xk ), σ u (x k , xk , k) = σ u (x k , k) - σ u ( xk , k) and ∇ φ(x k+1 , xk+1 , k + 1) = ∇ϕ(x k+1 , k + 1) - ∇ϕ( xk+1 , k + 1). It clear that 0 ≤ ε sum1 u,k ≤ ε sum1 u,M</formula><p>, where ε sum1 u,M is a positive constant. Furthermore, from (44), the control input estimation error at k = k i , i = 1, 2, . . . can be written as</p><formula xml:id="formula_86">e u,k = -W T u,k σ u (x k , k) -(1/2)R -1 g T (x k ) ∇ϕ T (x k+1 , k + 1) WV,k + (1/2)R -1 gT (x k )∇ϕ T (x k+1 , k + 1) WV,k -(1/2)R -1 gT (x k ) × ∇ϕ T (x k+1 , k + 1)W V + ε sum u,k , k = k i (45) where ε sum u,k = -(1/2)R -1 g T (x k )∇ε V ,k+1 -ε u,k and it holds that ε sum u,k ≤ ε sum u,M</formula><p>, where ε sum u,M is a positive constant. The weight estimation error dynamics of the actor NN, from (42), moving one time step ahead, become</p><formula xml:id="formula_87">Wu,k+1 = ⎧ ⎪ ⎨ ⎪ ⎩ Wu,k + α u σ u (x k , k)e T u,k σ T u (x k , k)σ u (x k , k) + 1 , k = k i Wu,k , k i &lt; k &lt; k i+1 . (<label>46</label></formula><formula xml:id="formula_88">)</formula><p>Next, the main results of the near optimal event-triggered system are claimed.</p><p>IV. EVENT-TRIGGER CONDITION AND STABILITY ANALYSIS In this section, we formulate the closed-loop event-triggered dynamics. The main results are claimed by designing an adaptive event-trigger condition.</p><p>The closed-loop system dynamics are obtained using (1), the actual control input (39), and the ideal control input (36). With simple mathematical manipulation, it is given by</p><formula xml:id="formula_89">x k+1 = f (x k ) + g(x k )u * k -g(x k ) W T u,k σ u (x k , k) + ε u,k -g(x k ) Ŵ T u,k (σ u (x k , k) -σ u ( xk , k)), k i ≤ k &lt; k i+1 . (<label>47</label></formula><formula xml:id="formula_90">)</formula><p>At the event-trigger instants, k = k i with updated state vector, the closed-loop system dynamics from (47) become</p><formula xml:id="formula_91">x k+1 = f (x k ) + g(x k )u * k -g(x k ) W T u,k σ u (x k , k) + ε u,k . (<label>48</label></formula><formula xml:id="formula_92">)</formula><p>Before, claiming the main result in the theorem, the following lemma is necessary.</p><p>Lemma 2 <ref type="bibr" target="#b16">[17]</ref>: Consider the nonlinear discrete-time system given by (1). Then, there exists an optimal control policy u * k for (1), such that the closed-loop dynamics satisfy the inequality</p><formula xml:id="formula_93">f (x k ) + g(x k )u * k 2 ≤ K * x k 2 (49)</formula><p>where 0 &lt; K * &lt; 1 is a constant. Now, consider the event-trigger error (2). The following condition is given by:</p><formula xml:id="formula_94">D( e ET,k ) &gt; σ ET,k x k (50)</formula><p>is selected as the event-trigger condition, where the threshold coefficient is denoted by</p><formula xml:id="formula_95">σ ET,k = (1 -2K * ) ET /4g 2 M C 2 σ u Ŵu,k 2 (51) 0 &lt; ET &lt; 1, 0 &lt; K * &lt; 1/2, provided Ŵu,k &gt; κ and the dead-zone operator D(•) is defined as D( e ET,k ) = e ET,k , x k &gt; b x 0, otherwise<label>(52)</label></formula><p>with b x being the ultimate bound for the state. The constant κ is a user-defined small positive constant to ensure the threshold coefficient is well defined. The system state and the control input vectors are transmitted to the controller and the plant, respectively, when the event-trigger condition in (50) is satisfied or the event-trigger error exceeds the threshold. Furthermore, an event is also triggered when the estimated NN weight Ŵu,k &lt; κ irrespective of (50).</p><p>Next, the theorem guarantees the UB of the closed-loop event-trigger system. The UB is shown using a Lyapunov function for both the cases of triggering, i.e., at the events and the inter-event. It is important to mention that, the Lyapunov function is not monotonically converging to the ultimate bound during both the events and the inter-event times. This is also not necessary to show the stability of the system, as discussed in <ref type="bibr" target="#b1">[2]</ref>, for the ETC system, and <ref type="bibr" target="#b18">[19]</ref> for the switched systems. Therefore, in our case, during the interevent times, the Lyapunov function is allowed to increase but within a time-varying upper bound. Furthermore, it is shown that with trigger of events, the time-varying upper bound and the Lyapunov function converge to the UB, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>Theorem 2: Consider the nonlinear discrete-time system (1), the NN identifier <ref type="bibr" target="#b12">(13)</ref>, the NN critic <ref type="bibr" target="#b21">(22)</ref>, and the NN actor networks (39). Assume u 0 be an initial stabilizing control policy for the system (1) and Assumption 1 through 6 hold. Let the identifier, the critic, and the actor NN weight estimates are ŴI,0 , ŴV,0 , and Ŵu,0 , respectively, are initialized in their IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS Fig. <ref type="figure" target="#fig_1">2</ref>. Evolution of the Lyapunov function.</p><p>respective compact sets with nonzero Ŵu,0 . Suppose, the system state vector is sent to the controller, and the NN weights are updated using ( <ref type="formula" target="#formula_33">17</ref>), (32), and (42) through the eventtrigger condition (50). Let the activation functions σ I (x k ), ϕ(x k , k), and σ u (x k , k) satisfy the PE condition <ref type="bibr" target="#b17">[18]</ref>. Then, there exist positive constants 0 &lt; α I &lt; 1/2, 0 &lt; α V &lt; 1/3, and 0 &lt; α u &lt; 1/5, such that the closed-loop event-triggered system state vector, x k , the identifier, the critic, and the actor NN weight estimation errors WI,k , WV,k , and Wu,k , respectively, are UB for all k i ≥ k 0 + T or, alternatively k ≥ k 0 + T . Furthermore, V * -V ≤ b V and u *u ≤ b u with b V and b u are small positive constants.</p><p>Proof: Refer to the Appendix. Remark 4: The selection of 0 &lt; K * &lt; 1/2 satisfies Lemma 2 and varies according to the desired performance of the system. The adaptive event-trigger condition (50) with (51) implicitly depends upon the actor NN weight estimation error, Wu,k . During the initial learning phase, the NN weight estimation error will be large. Hence, the events are triggered frequently. This facilitates the approximation of the cost function, the control policy, and the system dynamics to achieve the optimal performance.</p><p>Remark 5: The dead-zone operator (52) used with the eventtrigger condition helps to stop unnecessary triggering due to the NN reconstruction error. The dead zone is enabled once the system state is in the ultimate bound b x = max(b x 1,M , b x 2,M ) computed from (A.14) and (A.18). The ultimate bound is a function of the tuning parameters α I , α V , and α u , and the NN reconstruction error bounds ε I,M , ε V ,M , and ε u,M . Therefore, the bound can be made arbitrarily small, as mentioned in Remark A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. NONTRIVIAL MINIMUM INTER-EVENT TIMES</head><p>In this section, we discuss the minimum and the nontriviality of the inter-event times for the near optimal ETC system. The minimum inter-event time is the minimum time interval between two consecutive event sampling instants over all sampling instants, i.e., δk min = min i∈N {δk i }, where δk i = k i+1k i for i = 1, 2, . . . are the inter-event times. This is implicitly defined by the event-trigger condition (50). In the case of a discrete-time system, the minimum inter-event time is trivial and becomes the sampling time, T s or δk min = 1. Therefore, it is important to guarantee nontrivial inter-event times, i.e., δk i &gt; 1 to reduce the computational load. In the case of approximation-based control design, the inter-event times largely depend on the NN weight estimation error and presented in the following theorem.</p><p>Theorem 3: Let the hypothesis in Theorem 2 holds. The minimum inter-event time can be expressed as</p><formula xml:id="formula_96">δk min ≥ min i∈N {ln(1 + (1/N i )((M i -1)σ ET,min ))/ln(M i )} (53)</formula><p>for i = 1, 2, . . . and the nontriviality of the inter-event times are guaranteed if the following condition is satisfied:</p><formula xml:id="formula_97">ln(1+(1/N i )(M i -1)σ ET,min )&gt; ln(M i ), for each i= 1, 2, . . . (<label>54</label></formula><formula xml:id="formula_98">)</formula><p>where</p><formula xml:id="formula_99">N i = (( √ K * + 1) x k i + g M (σ u,M Wu,k i + ε u,M )) and M i = ( √ K * + g M C σ u Ŵu,k i ),</formula><p>and σ ET,min = min k∈N {σ ET,k x k } is the minimum event-trigger threshold.</p><p>Proof: Refer to the Appendix. Remark 6: It is important to note that the inter-event times will be nontrivial, i.e., δk i &gt; 1, i = 1, 2, . . . if (54) is satisfied. To achieve nontrivial inter-event times during the initial learning, the initial NN weights need to be selected close to the target parameters. This will reduce the NN weight estimation error, Wu,k , which in turn decreases the value of N i and increases M i in (53). Thus, the condition (54) can be satisfied leading to nontrivial inter-event times. In addition, along with the update of the NN weights, Ŵu,k , the weight estimation error, Wu,k , will further decrease and hence the variable N i . This, further, ensures larger inter-event times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. SIMULATION RESULTS</head><p>In this section, a two-link robot has been considered for the simulation. The dynamics of the two-link robot are given by (1) with internal dynamics f (x k ) and control coefficient matrix g(x k ), as given in <ref type="bibr" target="#b19">[20]</ref>. The following simulation parameters were selected to carry out the simulation. The cost-to-go was selected as a quadratic function with</p><formula xml:id="formula_100">Q(x k ) = x T k Q x x k , Q x = I 4×4 and R = 0.001 × I 2×2</formula><p>, where I is the identity matrix. The nonquadratic terminal cost was chosen as ψ(x N , N) = 1. The initial weights for the critic NN were selected as zero. The actor and the identifier NN weights were initialized with random values from a uniform distribution in the interval of zero to one. The time-varying activation functions for both the critic and the actor NNs were constructed as state-dependent and time-dependent terms, i.e., ϕ(</p><formula xml:id="formula_101">x k , k) = ϕ t (k)ϕ x (x k ).</formula><p>The state-dependent part, ϕ x (x k ), was chosen as <ref type="bibr" target="#b19">[20]</ref>, and the time-dependent part, ϕ t (k), was also selected as</p><formula xml:id="formula_102">ϕ x (x k ) = {x 2 1,k , . . . , x 2 4,k , x 1,k x 2,k , . . . , x 3 1,k x 2,k , . . . , x 4 1,k , . . . , x 4 4,k , . . . , x 1,k x 2,k x 3,k x 4,k } ∈ 45×1</formula><formula xml:id="formula_103">ϕ t (k) = {1, [exp(-τ )] 1 , . . . , [exp(-τ )] 44 ; . . . ; [exp(-τ )] 44 , [exp(-τ )] 43 , . . . , 1}<label>∈</label></formula><p>45×45 <ref type="bibr" target="#b16">[17]</ref>, where τ = (Nk)/N is the normalized time index. The identifier activation function was chosen as tanh{(x 1,k ) 2 , x 1,k x 2,k , . . . , (x 1,k ) 5 (x 2,k ), . . . , (x 4,k ) 6 }.</p><p>The number of neurons for the identifier was 39, and the critic and the action NN were 45 each. The learning rates for the NN tuning were selected as α I = 0.03, α V = 0.01, and α u = 0.05 per the conditions derived in Theorem 2. The event-trigger condition parameters were K * = 0.45, ET = 0.92, C σ u = 2,  and g M = 1.5. The initial admissible control was selected as</p><formula xml:id="formula_104">u 0 = [-500x 1 -500x 3 , -200x 2 -200x 4</formula><p>] T , and the terminal time was N = 10 000. The ultimate bound selected for the system state was 0.0005. The event-trigger threshold was computed using (50), with (51), and (52) with the above parameters selected for the simulation. Fig. <ref type="figure" target="#fig_2">3</ref>(a) shows the evolution of the threshold (solid line) over time along with the event-trigger error (dotted line). From this figure, it is evident that the event-trigger error reset to zero once it reaches the threshold with trigger of events. In Fig. <ref type="figure" target="#fig_2">3(b)</ref>, the cumulative number of trigger instants is plotted against the total sampling instants. Even though a large number of triggering occurs in the initial phase, the cumulative number of triggers is reduced. The cumulative triggering became constant after 8000 time instants. This implies the system state is in the ultimate bound b x = 5e -4. The number of events during the simulation time of 10 s with a sampling interval of 0.001 s was found to be 110.</p><p>A comparison of the computational load in terms of the multiplication and addition that is required to compute the event-trigger condition and the controller is given in Table <ref type="table" target="#tab_1">I</ref>. It indicates a reduction in the computation of around 65.5% for the event-triggered system. Furthermore, if a communication network is included between the plant and the controller, fewer transmissions are needed due to event-based sampling. This will reduce the communication cost significantly. The performance of the optimal controller is shown in Fig. <ref type="figure" target="#fig_3">4</ref>. The optimal control input [Fig. <ref type="figure" target="#fig_3">4(b)</ref>] regulates the system states to zero, as shown in Fig. <ref type="figure" target="#fig_3">4(a)</ref>. The control input also converges to zero with the system states. This implies that with a reduced number of controller executions, the system is near optimally regulated. Furthermore, the HJB equation or the TD error, shown in Fig. <ref type="figure" target="#fig_3">4(c</ref>), converges to the near zero implying the optimality achieved in finite time. The terminal cost error also converges to the near zero and shown in Fig. <ref type="figure" target="#fig_3">4(d)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>In this paper, a near optimal ETC of an uncertain nonlinear discrete-time system in affine form is introduced. The actorcritic framework used to solve the finite-horizon optimal control problem with event-based approximation was able to regulate the system. The novel adaptive event-trigger condition generated the required number of events at the initial learning phase to achieve a small approximation error. This also saved the computation by fewer updates in the control law. Near optimality was achieved in a finite time with complete unknown system dynamics. With an explicit formula, it is shown that a nontrivial inter-event time can exist with a proper initialization of weights and event-based NN weight updates. It was observed that the cumulative number of triggered events varies with the initial NN weights. The effectiveness of the controller is validated using the simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>Proof of Theorem 1: The smooth and continuous function h(x k , k), with the universal approximation theorem <ref type="bibr" target="#b20">[21]</ref> of NN, can be represented in a compact set as</p><formula xml:id="formula_105">h(x k , k) = W T σ (x k , k) + ε(x k , k) (A.1)</formula><p>with x k as input to the activation function at every sampling instant k. Consider the event-based sampling, where the state x k is available intermittently as defined in (3). Equation (A.1) can be expressed as</p><formula xml:id="formula_106">h(x k , k) = W T σ (x k , k)-W T σ ( xk , k)+W T σ ( xk , k) + ε(x k , k) (A.2)</formula><p>where σ ( xk , k) and xk are the event-based activation function and the state vectors. The state, x k , in terms of the event-based state, xk , and event-trigger error, e ET,k , in (2) can be written as x k = ϑ( xk , e ET,k ) = xk + e ET,k . Substituting this expression, (A.2) can be represented as</p><formula xml:id="formula_107">h(x k , k) = W T σ ( xk , k) + ε e ( xk , e ET,k , k) (A.3)</formula><p>where</p><formula xml:id="formula_108">ε e ( xk , e ET,k , k) = W T [σ (ϑ( xk , e ET,k ), k) -σ ( xk , k)] + ε(ϑ( xk , e ET,k ), k).</formula><p>Proof of Lemma 1: The UB of the identifier weight estimation error is proven by demonstrating the boundedness of the weight estimation error for both cases of trigger condition. A single Lyapunov function is used to evaluate the first difference and combined at the end to show an overall UB.</p><p>Case I: Event instants, i.e., k = k i , i = 1, 2, . . . Consider a Lyapunov function candidate given by</p><formula xml:id="formula_109">L I,k = tr W T I,k WI,k . (A.4)</formula><p>The first difference, L I,k = tr{ W T I,k+1 WI,k+1 } -tr{ W T I,k WI,k }, along the dynamics of the identifier NN weight estimation error <ref type="bibr" target="#b17">(18)</ref> for k = k i , becomes</p><formula xml:id="formula_110">L I,k = -2α I tr W T I,k σ I (x k ) ūk e T I,k+1 /([σ I (x k ) ūk ] T [σ I (x k ) ūk ] + 1) + α 2 I tr e I,k+1 [σ I (x k ) ūk ] T [σ I (x k ) ūk ]e T I,k+1 / ([σ I (x k ) ūk ] T [σ I (x k ) ūk ]+1) 2 .</formula><p>Substituting the identification error dynamics <ref type="bibr" target="#b15">(16)</ref>, and using the Cauchy-Schwartz (C-S) inequality with the fact that</p><formula xml:id="formula_111">[σ I (x k ) ūk ] T [σ I (x k ) ūk ]/([σ I (x k ) ūk ] T [σ I (x k ) ūk ] + 1) ≤ 1, the first difference is bounded by L I,k ≤ -α I (1 -2α I )tr W T I,k [σ I (x k ) ūk ][σ I (x k ) ūk ] T WI,k [σ I (x k ) ūk ] T [σ I (x k ) ūk ] + 1 + α I (2 + α I ) σ I (x k ) ūk 2 + 1 ε I,k 2 .</formula><p>By the definition, the augmented control input ūk ≥ 1, and 0 &lt; σ I,m ≤ σ I (x k ) ≤ σ I,M is satisfied due to the PE condition <ref type="bibr" target="#b16">[17]</ref> and Assumption 3. Hence, it holds that 0 &lt; σ I,m ≤ σ I (x k ) ūk . By the above facts, the first term in the above equation tr</p><formula xml:id="formula_112">W T I,k [σ I (x k ) ūk ][σ I (x k ) ūk ] T WI,k [σ I (x k ) ūk ] T [σ I (x k ) ūk ] + 1 = W T I,k σ I (x k ) ūk 2 ( σ I (x k ) ūk 2 + 1) ≥ W T I,k σ I (x k ) ūk 2 / ūk 2 ( σ I (x k ) 2 ūk 2 + 1)/ ūk 2 ≥ 2 I,m σ 2 I,M + 1 WI,k 2 where 0 &lt; I,m ≤ σ I (x k ) ūk / ūk .</formula><p>Substituting the above inequality, the first difference leads to</p><formula xml:id="formula_113">L I,k ≤ -α I (1 -2α I ) 2 I,m / σ 2 I,M + 1 WI,k 2 + B WI (A.5)</formula><p>where</p><formula xml:id="formula_114">B WI = α I (1 + 2α I )ε 2 I,M /(1 + σ 2 I,m ). From (A.5), by selecting 0 &lt; α I &lt; 1/2, the Lyapunov first difference L I,k &lt; 0 as long as WI,k &gt; ((σ 2 I,M + 1)B WI /α I (1 -2α I ) 2 I,m ) 1/2 = B M W ,I</formula><p>. Therefore, by the Lyapunov theorem <ref type="bibr" target="#b17">[18]</ref>, the identifier weight estimation error, WI,k , is UB with a bound B M W ,I for all k i ≥ k 0 + T with the occurrence of events.</p><p>Case II: inter-event times, i.e., k i &lt; k &lt; k i+1 i = 1, 2, . . . Consider the same Lyapunov function (A.4). The first difference along the identifier weight estimation error dynamics <ref type="bibr" target="#b17">(18)</ref> for</p><formula xml:id="formula_115">k i &lt; k &lt; k i+1 L I,k = tr W T I,k+1 WI,k+1 -tr W T I,k WI,k = 0. (A.6) From (A.6</formula><p>), the Lyapunov first difference, L I,k , during the inter-event time remains at zero. This implies the NN weight estimation error, WI,k , remains constant during the interevents times. The initial weight estimate, ŴI,0 , is finite and from Assumption 3, and the target weight matrix is bounded. Therefore, the initial weight estimation error, WI,0 , is also bounded. Furthermore, WI,k is bounded at the trigger instants, as shown in Case I. Thus, the initial value WI,k i , i = 1, 2, . . ., for each inter-event time, which is the updated value at the previous trigger instant, is also bounded. Consequently, the weight estimation error, WI,k , is constant and bounded during the inter-event times, i.e., k i &lt; k &lt; k i+1 for i = 1, 2, . . .</p><p>From Cases I and II, the identifier weight estimation error is bounded both at the trigger instants and at the inter-event times. Furthermore, with the occurrence of events followed by each inter-event time, the identifier weight estimation error, WI,k , is UB with a bound B M W ,I for all k i ≥ k 0 + T .</p><p>Alternatively, WI,k is UB for all k ≥ k 0 + T as k i is a subsequence of k and T is a function of T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof of Theorem 2:</head><p>The stability of the closed-loop system is proved by considering both cases of the event condition, i.e., event instants k = k i and inter-event times, k i &lt; k &lt; k i+1 , i = 1, 2, . . . A single Lyapunov function is evaluated for both the cases and combined at the end to show the UB.</p><p>Case 1: Event instants, k = k i , i = 1, 2, . . . Consider the Lyapunov function candidate given by</p><formula xml:id="formula_116">L cl,k = L x,k + L I,k + L V ,k + L u,k + L A,k + L B,k (A.7)</formula><p>where</p><formula xml:id="formula_117">L x,k = x x T k x k , L I,k = I tr W T I,k WI,k L V ,k = V W T V ,k WV,k , L u,k = tr W T u,k Wu,k L A,k = I 2 tr W T I,k WI,k 2 , L B,k = V 2 W T V ,k WV,k<label>2</label></formula><p>The positive constants</p><formula xml:id="formula_118">x = α u (1 -5α u )σ 2 u,m / 8g 2 M σ 2 u,M (σ 2 u,M + 1) I = 2 σ 2 I,M + 1 /α I (1 -2α I ) 2 I,m V = 2ϑ φ2 M + 1 /α V (1 -3α V ) φ2 m I 2 = 2α u (4 + 5α u )λ 2 max (R -1 )∇ϕ 2 M σ 2 I,M σ 2 I,M + 1 2 / 4α I (1 -2α I ) 2 σ 2 I,M + 1 -α I (1 -2α I ) 2 I,m × 2 I,m σ 2 u,m + 1 and V 2 = 2α u (4 + 5α u )λ 2 max (R -1 )∇ϕ 2 M σ 2 I,M ( φ2 M + 1) 2 / 4α V (1-3α V )(2 φ2 M + 1 -α V (1 -3α V ) φ2 m ) φ2 m × (σ 2 u,m + 1) with = {α u (4 + 5α u )λ 2 max (R -1 )∇ϕ 2 M W 2 V ,M σ 2 I,M /2(σ 2 u,m + 1)} + { I 2 B WI (2(σ 2 I,M +1)-α I (1-2α I ) 2 I,m )/(σ 2 I,M +1)} and ϑ = α u (4+5α u )λ 2 max (R -1 ) g 2 M +2ε 2 I,M ∇ϕ 2 M /4 σ 2 u,m + 1 + V 2 ε 1,M V 2 φ2 M + 1 -α V (1 -3α V ) φ2 m / φ2 M + 1 .</formula><p>Consider the first term in the Lyapunov function candidate (A.7), L x,k = x x T k x k . The first difference along the closed-loop system dynamics (48) is bounded above by</p><formula xml:id="formula_119">L x,k ≤ x x k+1 2 -x x k 2 ≤ x f (x k ) + g(x k )u * k -g(x k ) W T u,k σ u (x k , k) + ε u,k 2 -x x k 2 .</formula><p>Recalling Lemma 2 and applying the C-S inequality (a + b) 2 ≤ 2a 2 + 2b 2 , it reveals that</p><formula xml:id="formula_120">L x,k ≤ -(1 -2K * ) x x k 2 + 4g 2 M σ 2 u,M x Wu,k 2 + 4 x g 2 M ε 2 u,M . (A.8)</formula><p>Consider the second term in the Lyapunov function (A.7), L I,k = I tr{ W T I,k WI,k }. The first difference can be written from (A.5) and is given by</p><formula xml:id="formula_121">L I,k ≤ -I α I (1-2α I ) 2 I,m / σ 2 I,M +1 WI,k 2 + I B WI .</formula><p>(A.9)</p><p>Moving on for the third term </p><formula xml:id="formula_122">L V ,k = V W T V ,k WV,</formula><formula xml:id="formula_123">L V ,k = 2 V α V W T V ,k φ(x k , k)e T total,k φT (x k , k) φ(x k , k) + 1 φ(x k , k)e T total,k + V α 2 V e total,k φT (x k , k) ( φT (x k , k) φ(x k , k) + 1) 2 .</formula><p>Substituting e total,k from (34) into the above equation and using the C-S inequality, the first difference leads to</p><formula xml:id="formula_124">L V ,k ≤ - 2 V α V W T V ,k φ(x k , k) φT (x k , k) WV,k φT (x k , k) φ(x k , k) + 1 +2 V α V W T V ,k φ(x k , k)(ϕ(x N ,N)-ϕ(x k , N)) T W T V φT (x k , k) φ(x k , k)+1 -2 V α V W T V ,k φ(x k , k) εT V ,k φT (x k , k) φ(x k , k) + 1 + 3 V α 2 V W T V ,k φ(x k , k) ( φT (x k , k) φ(x k , k) + 1) 2 × φT (x k , k) φ(x k , k) φT (x k , k) WV,k + 3 V α 2 V W T V (ϕ(x N , N) -ϕ(x k , N)) ( φT (x k , k) φ(x k , k) + 1) 2 × φT (x k , k) φ(x k , k)(ϕ(x N , N)-ϕ(x k , N)) T W V + 3 V α 2 V εV,k φT (x k , k) φ(x k , k) εT V ,k ( φT (x k , k) φ(x k , k) + 1) 2 . Using Young's inequality 2a T b ≤ qa T a + (1/q)b T b, with q &gt; 0, φT (x k , k) φ(x k , k)/( φT (x k , k) φ(x k , k) + 1) ≤ 1 and 1/( φT (x k , k) φ(x k , k) + 1) ≤ 1, the first difference becomes L V ,k ≤ -V α V (1 -3α V ) W T V ,k φ(x k , k) φT (x k , k) WV,k φT (x k , k) φ(x k , k) + 1 + V α V (2 + 3α V ) W T V (ϕ(x N , N) -ϕ(x k , N)) φT (x k , k) φ(x k , k) + 1 × (ϕ(x N , N) -ϕ(x k , N)) T W V + V α V (2 + 3α V ) εV,k εT V ,k φT (x k , k) φ(x k , k) + 1 .</formula><p>From Assumption 5, ϕ(x N , N) -ϕ(x k , k) &lt; 2ϕ M and εV,k ≤ εV,M . With these facts, simple manipulation using the C-S inequality and Frobenius norm, we arrive at</p><formula xml:id="formula_125">L V ,k ≤ -V α V (1 -3α V ) × φ2 m / φ2 M + 1 WV,k 2 + V ε 1,M V (A.10)</formula><p>where</p><formula xml:id="formula_126">ε 1,M V = α V (2 + 3α V )(ϕ 2 M W 2 V ,M /( φ2 m + 1)) + α V (2 + 3α V ) ( ε2 V ,M / φ2 m + 1), 0 &lt; α V &lt; 1/3 and 0 &lt; φm ≤ φ(x k , k) ≤ φM</formula><p>, which is satisfied by ensuring the PE condition <ref type="bibr" target="#b16">[17]</ref>.</p><p>Consider the next term in the Lyapunov function candidate (A.7), L u,k = tr{ W T u,k Wu,k }. The first difference along the actor NN weight estimation error dynamics (46) for k = k i becomes</p><formula xml:id="formula_127">L u,k = 2α u tr W T u,k σ u (x k , k)e T u,k / σ T u (x k , k)σ u (x k , k) + 1 + α 2 u tr e u,k σ T u (x k , k)σ u (x k , k)e T u,k / σ T u (x k , k)σ u (x k , k)+1 2 .</formula><p>Substitute the control input estimation error e u,k from (45) in the above equation. After some mathematical manipulation using the C-S inequality and the fact</p><formula xml:id="formula_128">σ T u (x k , k)σ u (x k , k)/(σ T u (x k , k)σ u (x k , k) + 1) ≤ 1, IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS we arrive at L u,k ≤ -α u (1 -5α u )tr W T u,k σ u (x k , k)σ T u (x k , k) Wu,k σ T u (x k , k)σ u (x k , k) + 1 + α u (4 + 5α u )tr (R -1 g T (x k )∇ϕ T (x k+1 , k + 1) WV,k ) 4(σ T u (x k , k)σ u (x k , k) + 1) × (R -1 g T (x k )∇ϕ T (x k+1 , k +1) WV,k ) T + α u (4 + 5α u )tr (R -1 gT (x k )∇ϕ T (x k+1 , k + 1) WV,k ) 4(σ T u (x k , k)σ u (x k , k) + 1) × (R -1 gT (x k )∇ϕ T (x k+1 , k + 1) WV,k ) T + α u (4 + 5α u )tr (R -1 gT (x k )∇ϕ T (x k+1 , k + 1)W V ) 4(σ T u (x k , k)σ u (x k , k) + 1) × (R -1 gT (x k )∇ϕ T (x k+1 , k + 1)W V ) T + α u (4+5α u )tr ε sum u,k ε sum u,k T / σ T u (x k , k)σ u (x k , k)+1 .</formula><p>Using Frobenius norm, Young's inequality and the relation</p><formula xml:id="formula_129">g(x k ) ≤ σ I,M WI,k + ε I,M , it holds that L u,k ≤ -α u (1 -5α u )σ 2 u,m / σ 2 u,M + 1 Wu,k 2 + α u (4 + 5α u ) λ 2 max (R -1 ) g 2 M + 2ε 2 I,M ∇ϕ 2 M /4 × σ 2 u,m + 1 WV,k 2 + α u (4+5α u ) λ 2 max (R -1 )σ 2 I,M ∇ϕ 2 M /4 σ 2 u,m + 1 WI,k 4 + α u (4+5α u ) λ 2 max (R -1 )σ 2 I,M ∇ϕ 2 M /4 σ 2 u,m + 1 WV,k 4 + α u (4 + 5α u ) λ 2 max (R -1 )σ 2 I,M W 2 V ,M ∇ϕ 2 M /2 × σ 2 u,m + 1 WI,k 2 + α u (4 + 5α u ) λ 2 max (R -1 )W 2 V ,M ∇ϕ 2 M ε 2 I,M /2 σ 2 u,m + 1 + α u (4 + 5α u ) ε sum u,M 2 /4 σ 2 u,m + 1 (A.11) where 0 &lt; σ u,m ≤ σ u (x k , k) ≤ σ u,M is ensured by the PE condition, λ max (R -1 ) is the maximum eigenvalue of R -1 . Considering the next term L A,k = I 2 tr{ W T I,k WI,k } 2 . The first difference, L A,k = I 2 tr{ W T I,k+1 WI,k+1 } 2 - I 2 tr{ W T I,k WI,k } 2 , from (A.9), becomes L A,k ≤ -I 2 α I (1 -2α I ) 2 -α I (1 -2α I ) 2 I,m / σ 2 I,M + 1 × 2 I,m / σ 2 I,M + 1 WI,k 4 + I 2 (B WI ) 2 + I 2 B WI × 2 -α I (1 -2α I ) 2 I,m / σ 2 I,M + 1 WI,k 2 (A.12)</formula><p>where (2</p><formula xml:id="formula_130">-(α I (1 -2α I ) 2 I,m /(σ 2 I,M + 1))) &gt; 0 with 0 &lt; α u &lt; 1/5.</formula><p>Similarly, the first difference of the last term L B,k = { W T V ,k WV,k } 2 using (A.10) can be written as</p><formula xml:id="formula_131">L B,k ≤ -V 2 α V (1 -3α V ) φ2 m / φ2 M + 1 × 2-α V (1 -3α V ) φ2 m / φ2 M + 1 WV,k 4 + V 2 ε 1,M V 2-α V (1-3α V ) φ2 m / φ2 M +1 × WV,k 2 + V 2 ε 1,M V 2 . (A.13)</formula><p>At the final step, combine the individual first differences (A.8)-(A.13) to get the overall first difference. Substituting the constants</p><p>x , I , V , I 2 , and V 2 , from (A.7), the overall first difference satisfies</p><formula xml:id="formula_132">L cl,k ≤ -(1 -2K * ) x x k 2 - WI,k 2 -ϑ WV,k 2 - 1 2 α u (1 -5α u ) σ 2 u,m /σ 2 u,M + 1 Wu,k 2 -α u (4 + 5α u ) × λ 2 max (R -1 )∇ϕ 2 M σ 2 I,M /4 σ 2 u,m + 1 WI,k 4 + ε c1 cl,total -α u (4+5α u ) λ 2 max (R -1 )∇ϕ 2 M σ 2 I,M /4 σ 2 u,m + 1 WV,k 4 (A.14)</formula><p>where ε c1 cl,total <ref type="bibr" target="#b13">14)</ref>, and selecting 0 &lt; α u &lt; 1/5, the first difference of the Lyapunov function, L cl,k &lt; 0 as long as</p><formula xml:id="formula_133">= I B WI + V ε 1,M V + I 2 (B WI ) 2 + (2α u (4 + 5α u )λ 2 max (R -1 )∇ϕ 2 M W 2 V ,M ε 2 I,M /4(σ 2 u,m + 1)) + (α u (4 + 5α u )(ε sum u,M ) 2 /(σ 2 u,m +1))+4 x g 2 M ε 2 u,M + V 2 (ε 1,M V ) 2 . From (A.</formula><formula xml:id="formula_134">WI,k &gt; max 4 4(σ 2 u,m +1)ε c1 cl,total α u (4+5α u )λ 2 max (R -1 )∇ϕ 2 M σ 2 I,M, ε c1 cl,total ≡ b WI or WV,k &gt; 4 4(σ 2 u,m + 1)ε c1 cl,total /α u (4 + 5α u )λ 2 max (R -1 )∇ϕ 2 M σ 2 I,M , ε c1 cl,total /ϑ ≡ b WV or Wu,k &gt; (2(σ 2 u,M + 1)ε c1 cl,total /α u (1 -5α u )σ 2 u,m ) ≡ b Wu or x k &gt; ε c1 cl,total /(1 -K * ) x = b x 1,M</formula><p>. This implies the system state, x k , the NN weight estimation errors for the identifier, the critic, and the actor, WI,k , WV,k , and Wu,k are UB for all k i ≥ k 0 + T .</p><p>Case 2: inter-event times, i.e., k i &lt; k &lt; k i+1 , i = 1, 2, . . . Consider the same Lyapunov function candidate (A.7) as in Case I. The first difference L x,k = x x k+1 2x x k 2 of the first term along (47) with Lemma 2 and the C-S inequality can be written as</p><formula xml:id="formula_135">L x,k ≤ 2K * x k 2 + 4g 2 M Ŵ T u,k σ (x k , k) -Ŵ T u,k σ ( xk , k) 2 -x k 2 + 4g 2 M σ 2 u,M Wu,k 2 + ε 2 u,M .</formula><p>From the Lipschitz continuity of the actor NN activation function, in Assumption 6, it holds that</p><formula xml:id="formula_136">L x,k ≤ -(1 -2K * ) x k 2 + 4g 2 M C 2 σ u Ŵu,k 2 e ET,k 2 + ε c2 cl,total,k (A.15) with ε c2 cl,total,k = 4g 2 M (σ 2 u,M Wu,k 2 + ε 2 u,M</formula><p>). Recall the eventtrigger condition (50). During the inter-event times, for the case when the system state vector is outside the ultimate bound, it holds that e ET,k ≤ σ ET,k x k . Substituting this inequality in (A.15), the first difference satisfies</p><formula xml:id="formula_137">L x,k ≤ -(1 -2K * )(1 -ET ) x k 2 + ε c2 cl,total,k (A.16)</formula><p>where 0 &lt; ET &lt; 1 and 0 &lt; K * &lt; 1/2. Considering the remaining terms of Lyapunov function candidates (A.7), the first differences become zero due to no update. They are represented as</p><formula xml:id="formula_138">L I,k = 0, L V ,k = 0, L A,k = 0 and L B,k = 0. (A.17)</formula><p>Finally, combining (A.16) and (A.17), the first difference of the overall system is given by</p><formula xml:id="formula_139">L cl,k ≤ -(1 -2K * )(1 -ET ) x k 2 + ε c2 cl,total,k . (A.18) From (A.18), the first difference L cl,k &lt; 0 as long as x k &gt; (ε c2 cl,total,k /(1 -2K * )(1 -ET )) 1/2 = b x 2,k .</formula><p>The actor NN weight estimation error, Wu,k , is constant during each i th inter-event time, k i &lt; k &lt; k i+1 , as the weights are held. Therefore, ε c2 cl,total,k and hence b x 2,k are piecewise constant functions. Thus, the system state is bounded by a time-varying bound b x 2,k during the inter-event times. The boundedness of the NN weight estimation errors during the inter-event times can be shown as follows. The NN initial weight estimates are finite. Therefore, the initial the weight estimation errors are also bounded. From Case I, the NN weight estimation errors are bounded at the trigger instants. Therefore, the initial values during the inter-event times are bounded. Furthermore, from (A.17), the NN weight estimation errors are remain constant at their respective previous values during the interevent times. Therefore, the NN weight estimation errors WI,k , WV,k , and Wu,k remain bounded during the inter-event times.</p><p>Note that, from Case I, with trigger of events, the system state vector and the NN weight estimation errors converge to UB for all k i ≥ k 0 + T . During the inter-event times, from Case II, the system states are bounded by the time-varying bound, b x 2,k , and the NN weight estimation errors are held at their previous values. During the initial learning phase, the piecewise constant bound b x 2,k may be large. Therefore, the system state vector may increase. Alternatively, the Lyapunov function L cl,k may increase during the inter-event times, k i &lt; k &lt; k i+1 , for i = 1, 2, . . . as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Since the change in the system state vector is governed by the eventtrigger condition, a large value of the system state vector will lead to an event. Hence, the NN weights and the control inputs will be updated which will make the state and the weight estimation error to converge.</p><p>Furthermore, since each inter-event is followed by an event, the function ε c2 cl,total,k for k i &lt; k &lt; k i+1 , in (A. <ref type="bibr" target="#b17">18)</ref>, is less than the previous inter-event time k i-1 &lt; k &lt; k i and hence b x 2,k . This implies that for all k i ≥ k 0 + T , the function ε c2 cl,total,k → ε c2 cl,M , where ε c2 cl,M = 4g 2 M (σ 2 u,M b 2 Wu + ε 2 u,M ) is a constant and b Wu is the ultimate bound for Wu,k from Case I. Therefore, the bound for the system state b x 2,k will also converge, i.e., b x 2,k → b x 2,M for k i ≥ k 0 + T , where b x 2,M = (ε c2 cl,M /(1 -2K * )(1 -ET )) 1/2 is a constant. Consequently, from Cases I and II, the system state, x k , the NN weight estimation errors for the identifier, the critic, and the actor, WI,k , WV,k , and Wu,k are UB with trigger of events for all k i ≥ k 0 + T , or alternatively, for all k ≥ k 0 + T , since k i is a subsequence of k and hence T is a function of T . Therefore, the Lyapunov function converges to its ultimate value.</p><p>Remark A.1: From both the cases, the UB for the system state, the NN weight estimation errors of the identifier, the critic, and the actor NNs are found to be Finally, to show the convergence of estimated value function and control input to their optimal values, subtract ( <ref type="formula" target="#formula_48">22</ref>) from ( <ref type="formula" target="#formula_41">20</ref>) and ( <ref type="formula" target="#formula_76">39</ref>) from (36) to get Remark A.2: The variables M i and N i are the piecewise constant functions, since Wu,k i , Ŵu,k i , and x k i are constant for each i th inter-event time. Hence, the error e ET,k is also a piecewise continuous function.</p><formula xml:id="formula_140">V * -V = W T V ,k ϕ(x k , k) + Ŵ T V ,k (ϕ(x k , k) -ϕ( xk , k)) + ε V ,k ≤ b WV ϕ M + ŴV,max C ϕ σ ET,max b x + ε V ,M ≡ b V (A.</formula><p>By comparison lemma <ref type="bibr" target="#b21">[22]</ref>, the solution of the inequality (A.21) is bounded above as Since the triggering instants are decided by the event-trigger condition, at k i+1 for the i th inter-event interval, it holds that e ET,k i+1 = σ ET,min . Therefore, from (A.22), we obtain</p><formula xml:id="formula_141">e ET,k ≤ k-1 j =k i M k-j -1 i N i = N i M k-k i i -N i /(M i -1) (A.</formula><formula xml:id="formula_142">N i M k i+1 -k i i</formula><p>-N i /(M i -1) ≥ σ ET,min , i = 1, 2, . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(A.24)</head><p>Solving the above inequality, the lower bound on the interevent times found to be δk i ≥ ln(1+(1/N i )((M i -1)σ ET,min ))/ln(M i ), i = 1, 2, . . . The inter-event times becomes nontrivial, i.e., δk i &gt; 1 when ln(1 + (1/N i )((M i -1)σ ET,min )) &gt; ln(M i ), i ∈ N, is satisfied.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Block diagram representation of the ETC system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 ,</head><label>2</label><figDesc>. . ., where WI.k = W I -ŴI,k is the identifier NN weight estimation error. The reconstruction error is denoted by ε I,k = ε I (x k ) for brevity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Triggering threshold with event-trigger error. (b) Cumulative number of triggered events versus sampling instants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Convergence of (a) system state, (b) near optimal control inputs, (c) HJB equation or TD error, and (d) terminal cost error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>k , in the Lyapunov function candidate (A.7), the first difference becomes L V ,k = W T V ,k+1 WV,k+1 -W T V ,k WV,k . for k = k i , the first difference can be represented as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>b x = max(b x 1,M , b x 2,M ), b WI , b WV and b Wu , respectively. The bounds b x , b WI , b WV , and b Wu are a function of learning parameters α I ,α V , and α u , and the NN reconstruction error bounds ε I,M , ε V ,M , and ε u,M . Hence, a smaller UB for the closed-loop system can be obtained by selecting α I , α V , and α u properly and increasing the number of neurons in the NN to reduce ε I,M , ε V ,M , and ε u,M .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc><ref type="bibr" target="#b18">19)</ref> and||u * ku k || = W T u,k σ u (x k , k) + Ŵ T u,k (σ u (x k , k) -σ u ( xk , k)) + ε u,k ≤ b Wu σ u,M + Ŵu,max C σ u σ ET,max b x + ε u,M ≡ b u (A.20)where ŴV,max = max k { ŴV,k } and Ŵu,max = max k { Ŵu,k } are the maximum estimated values for the critic and the actor NNs, and σ ET,max is the maximum value of the eventtrigger threshold coefficient. The constants C ϕ and C σ u are the Lipschitz constants for the critic and the actor NN activation functions, respectively. Note that bounds b V and b u depend on the UB of the system state vector b x , the NN weights b WV and b Wu , which are small, as mentioned in Remark A.1. Thus, b V and b u are small constants and the estimated control input converge to the near optimal value.Proof of Theorem 3: Consider the event-trigger error (2) e ET,k = x k -xk . The error dynamics, e ET,k+1 = x k+1 -xk+1 , using the closed-loop system dynamics (47) are upper bounded bye ET,k+1 ≤ M i e ET,k + N i , k i &lt; k &lt; k i+1 , i = 1, 2, . . . (A.<ref type="bibr" target="#b20">21)</ref> whereN i = (( √ K * + 1) x k i + g M (σ u,M Wu,k i + ε u,M )) and M i = ( √ K * + g M C σ u Ŵu,k i ), i = 1,2, . . . with 0 &lt; K * &lt; 1/2. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc><ref type="bibr" target="#b21">22)</ref> for k i &lt; k &lt; k i+1 , each i = 1, 2, . . . The lower bound on the inter-event times for the i th inter-event duration, δk i = k i+1k i , is the time it takes e ET,k in (A.22) to reach the minimum threshold, σ ET,min , for all k ∈ N. It is computed using (50) given asmin k∈N {σ ET x k } = (1 -2K * ) ET /4g 2 M C 2 σ u Ŵ 2 u,max b x = σ ET,min (A.23)where b x is the lower bound of the system state for an event to trigger, as in (52). The weight matrix Ŵu,max = max k { Ŵu,k } is the maximum value of the actor NN weight estimates for all k ∈ N. The maximum value of the NN weight matrix Ŵu,max exists, since the weight estimates are bounded for all time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>(</head><label></label><figDesc>A.25)From (A.25), the minimum value of inter-event timeδk min = min i∈N (δk i ) ≥ min i∈N (ln(1 + (1/N i )((M i -1)σ ET,min ))/ln(M i )).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The event-based reconstruction error ε e ( xk , e ET,k , k) is a function of event-trigger error, e ET,k , and the traditional NN reconstruction error,</figDesc><table><row><cell>∈ l×n is the constant unknown target weight</cell></row><row><cell>matrix with l hidden-layer neurons, while σ ( xk , k) ∈ l</cell></row><row><cell>is a bounded event-based time-varying activation function.</cell></row><row><cell>The function ε e ( xk , e ET,k , k) = W T [σ (ϑ( xk , e ET,k ), k) -</cell></row><row><cell>σ ( xk , k)] + ε(ϑ( xk , e ET,k ), k) is the event-sampled recon-</cell></row><row><cell>struction error, where ϑ( xk , e ET,k ) = xk + e ET,k . Then, the</cell></row><row><cell>function σ (ϑ( xk , e ET,k ), k) = σ (x k , k) is the periodic time-</cell></row><row><cell>based activation function, ε(ϑ( xk , e ET,k ), k) = ε(x k , k) is the</cell></row><row><cell>traditional reconstruction error, and xk is the latest available</cell></row><row><cell>event-sampled state.</cell></row><row><cell>Proof: Refer to the Appendix.</cell></row><row><cell>Remark 1:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I COMPARISON</head><label>I</label><figDesc></figDesc><table><row><cell>OF THE COMPUTATIONAL LOAD BETWEEN</cell></row><row><cell>THE TRADITIONAL AND THE EVENT-BASED</cell></row><row><cell>DISCRETE-TIME SYSTEMS</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hao Xu (M <ref type="bibr">'12)</ref> was born in Nanjing, China, in 1984. He received the master's degree in electrical engineering from Southeast University, Nanjing, in 2009, and the Ph.D. degree from the Missouri University of Science and Technology, Rolla, MO, USA, in 2012.</p><p>He is currently with Texas A&amp;M University-Corpus Christi, Corpus Christi, TX, USA, where he is an Assistant Professor with the College of Science and Engineering and the Director of the Unmanned Systems Research Laboratory. His current research interests include autonomous unmanned aircraft systems, wireless passive sensor network, localization, detection, networked control system, cyberphysical system, distributed network protocol design, optimal control, and adaptive control. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Event-triggered real-time scheduling of stabilizing control tasks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tabuada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1680" to="1685" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On event design in event-triggered feedback systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lemmon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2319" to="2322" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Model-based event-triggered control for systems with quantization and time-varying network delays</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Antsaklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="422" to="434" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-based periodic event-triggered control for linear systems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P M H</forename><surname>Heemels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C F</forename><surname>Donkers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="698" to="711" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural network-based adaptive event-triggered control of affine nonlinear discrete time systems with unknown internal dynamics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Amer. Control Conf. (ACC)</title>
		<meeting>Amer. Control Conf. (ACC)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="6418" to="6423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural network-based adaptive event-triggered control of nonlinear continuous-time systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Intell. Control (ISIC)</title>
		<meeting>IEEE Int. Symp. Intell. Control (ISIC)<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08">Aug. 2013</date>
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Stochastic optimal control of unknown linear networked control system in the presence of random delays and packet losses</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1017" to="1030" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Syrmos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimal Control</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Wiley</publisher>
			<pubPlace>Hoboken, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">To measure or to control: Optimal control with scheduled measurements and controls</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">C</forename><surname>Imer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Basar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Amer. Control Conf</title>
		<meeting>Amer. Control Conf<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">Jun. 2006</date>
			<biblScope unit="page" from="14" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the optimality of certainty equivalence for event-triggered control systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Molin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hirche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="470" to="474" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Infinite horizon self-learning optimal control of nonaffine discrete-time nonlinear systems</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="866" to="879" />
			<date type="published" when="2015-04">Apr. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Finite-approximation error based discrete-time nonlinear systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="779" to="789" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">GrDHP: A general utility function representation for dual heuristic dynamic programming</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Prokhorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="614" to="627" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Data-driven neuro-optimal temperature control of water-gas shift reaction using stable iterative adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="6399" to="6408" />
			<date type="published" when="2014-11">Nov. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Neuro-Dynamic Programming</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Athena Scientific</publisher>
			<pubPlace>Belmont, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural network based finite horizon stochastic optimal controller design for nonlinear networked control systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Joint Conf. Neural Netw</title>
		<meeting>IEEE Int. Joint Conf. Neural Netw<address><addrLine>Dallas, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08">Aug. 2013</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online optimal control of affine nonlinear discrete-time systems with unknown internal dynamics by using timebased policy update</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dierks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1118" to="1129" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Neural Network Control of Nonlinear Discrete-Time Systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stability theory for hybrid dynamical systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="461" to="474" />
			<date type="published" when="1998-04">Apr. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generalized Hamilton-Jacobi-Bellman formulation-based neural network control of affine nonlinear discretetime systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="106" />
			<date type="published" when="2008-01">Jan. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Approximation by superpositions of a sigmoidal function</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Control Signals Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="303" to="314" />
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">His current research interests include event sampled control, adaptive control, neural network control</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bitsoris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gravalou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008, and the M.S. degree in electrical engineering from IIT Varanasi</title>
		<meeting><address><addrLine>Cochin, India; Varanasi, India; Rolla, MO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-02">Feb. 1995. 2011</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="217" to="222" />
		</imprint>
		<respStmt>
			<orgName>Cochin University of Science and Technology ; Missouri University of Science and Technology</orgName>
		</respStmt>
	</monogr>
	<note>Comparison principle, positive invariance and constrained regulation of nonlinear systems. networked control system, and optimal control</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
