<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NASRec: Weight Sharing Neural Architecture Search for Recommender Systems</title>
				<funder ref="#_gJ8WpCX">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_ahtzN9G #_9Qz8QHz #_kuZa8M3">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-07-14">14 Jul 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tunhou</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dehua</forename><surname>Cheng</surname></persName>
							<email>dehuacheng@fb.com</email>
						</author>
						<author>
							<persName><forename type="first">Zhengxing</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
							<email>xiaoliangdai@fb.com</email>
						</author>
						<author>
							<persName><forename type="first">Liang</forename><surname>Xiong</surname></persName>
							<email>lxiong@fb.com</email>
						</author>
						<author>
							<persName><forename type="first">Feng</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hai</forename><surname>Li</surname></persName>
							<email>hai.li@duke.edu</email>
						</author>
						<author>
							<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
							<email>yuchenhe@fb.com</email>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Wen</surname></persName>
							<email>wewen@fb.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Duke University Durham</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Meta AI Menlo Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>Meta AI Menlo Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<settlement>Meta AI Menlo Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<settlement>Meta AI Menlo Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<address>
									<settlement>Meta AI Menlo Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">University of Houston Houston</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Duke University Durham</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Duke University Durham</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<address>
									<settlement>Meta AI Menlo Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NASRec: Weight Sharing Neural Architecture Search for Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-07-14">14 Jul 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2207.07187v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The rise of deep neural networks provides an important driver in optimizing recommender systems. However, the success of recommender systems lies in delicate architecture fabrication, and thus calls for Neural Architecture Search (NAS) to further improve its modeling. We propose NASRec, a paradigm that trains a single supernet and efficiently produces abundant models/sub-architectures by weight sharing. To overcome the data multi-modality and architecture heterogeneity challenges in recommendation domain, NAS-Rec establishes a large supernet (i.e., search space) to search the full architectures, with the supernet incorporating versatile operator choices and dense connectivity minimizing human prior for flexibility. The scale and heterogeneity in NASRec impose challenges in search, such as training inefficiency, operator-imbalance, and degraded rank correlation. We tackle these challenges by proposing single-operator any-connection sampling, operator-balancing interaction modules, and post-training fine-tuning. Our results on three Click-Through Rates (CTR) prediction benchmarks show that NAS-Rec can outperform both manually designed models and existing NAS methods, achieving state-of-the-art performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep learning is playing an essential role on designing modern recommender systems at web-scale in real-world applications. For example, the most widely used search engines and social medias harness recommender systems (or ranking systems) to optimize the Click-Through Rates (CTR) of personalized pages <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17]</ref>. The improvement of recommender systems is driven by neural architecture engineering of deep learning models.</p><p>Deep learning based recommender systems, especially CTR prediction, carries a neural architecture design upon multi-modality features. In practice, various challenges arise in such a procedure. The multi-modality features, such as floating-point, integer, and categorical features, present a concrete challenge in feature interaction modeling and neural network optimization. Finding a good backbone model with heterogeneous architectures assigning appropriate priors upon multi-modality features are common practices in deep learning recommender systems <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref>]. Yet, these approaches still rely on significant manual efforts and suffer from limitations such as narrow design spaces and insufficient experimental trials bounded by available resources. As a result, these limitations add difficulty in designing a capable feature extractor.</p><p>The rise of Automated Machine Learning (AutoML), especially Neural Architecture Search (NAS) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31]</ref> in the vision domain, sheds light in optimizing models of recommender systems. However, applying NAS to recommendation domain is much more challenging than vision domain because of the multi-modality in data and the heterogeneity in the architectures. For example, <ref type="bibr" target="#b0">(1)</ref> in vision, inputs of building blocks are homogeneously 3D tensors, but recommender systems take in multi-modality features generating 2D and 3D tensors. <ref type="bibr" target="#b1">(2)</ref> Vision models simply stack the same building blocks, and thus state-of-the-art NAS in vision converges to simply searching size configurations instead of architecture motifs, such as channel width, kernel sizes, and layer repeats <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30]</ref>. However, recommendation models are heterogeneous with each stage of the model using a completely different building block <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>(3) Vision models mainly use convolutional operator as the main building block while recommender systems are built over heterogeneous operators, such as, Fully-Connected layer, Gating, Sum, Dot-Product, Attention, etc.</p><p>Due to the aforementioned challenges, study of NAS in recommender systems is limited. For example, search spaces in Au-toCTR <ref type="bibr" target="#b22">[23]</ref> and DNAS <ref type="bibr" target="#b12">[13]</ref> follow the design principle of humancrafted DLRM <ref type="bibr" target="#b16">[17]</ref> and they only include fully-connected layer and dot product as searchable operators. They also heavily reply on manually crafted operators, such as Factorization Machine <ref type="bibr" target="#b22">[23]</ref> or feature interaction module <ref type="bibr" target="#b7">[8]</ref> in the search space to increase architecture heterogeneity. Moreover, existing works either suffer from huge computation cost <ref type="bibr" target="#b22">[23]</ref> or challenging bi-level optimization <ref type="bibr" target="#b12">[13]</ref>, and thus they only employ narrow design spaces (sometimes with strong human priors <ref type="bibr" target="#b7">[8]</ref>) to craft architectures. Although these approaches can explore better models than handcrafted solutions, their limitations discourage diversified feature interactions and limit the potential of discovered models.</p><p>In this paper, we hereby propose NASRec, a new paradigm to fully enable NAS for recommender systems via Weight Sharing Neural Architecture Search (WS-NAS) under data modality and Connectivity? Search? Log Loss Cost DNAS <ref type="bibr" target="#b12">[13]</ref> FC, Dot-Product 0.4442 One supernet PROFIT <ref type="bibr" target="#b7">[8]</ref> FC, FM 0.4427 One supernet AutoCTR <ref type="bibr" target="#b22">[23]</ref> FC, Dot-Product, FM, EmbedFC 0.4413 Many models NASRec FC, Gating, Sum, Attention 0.4407 One supernet Dot-Product, EmbedFC architecture heterogeneity. Table <ref type="table" target="#tab_0">1</ref> summarizes the advancement of NASRec over other NAS approaches. We achieve this by first building up a supernet that incorporates much more heterogeneous operators than previous works, including Fully-Connected (FC) layer, Gating, Sum, Dot-Product, Self-Attention, and Embedded Fully-Connected (EmbedFC) layer. In the supernet, we densely connect a cascade of blocks, each of which includes all operators as options. As any block can take in any raw feature embeddings and intermediate tensors by dense connectivity, the supernet is not limited by any particular data modality. Such supernet design minimizes the encoding of human priors by introducing "NASRec Search Space", supporting the nature of data modality and architecture heterogeneity in recommender systems, and covering models beyond popular recommendation models such as Wide &amp; Deep <ref type="bibr" target="#b4">[5]</ref>, DLRM <ref type="bibr" target="#b16">[17]</ref>, AutoCTR <ref type="bibr" target="#b22">[23]</ref>, DNAS <ref type="bibr" target="#b12">[13]</ref> and PROFIT <ref type="bibr" target="#b7">[8]</ref>.</p><p>The supernet itself forms a search space. We obtain a model by zeroing out some operators and connections in the supernet, that is, a subnet of the supernet is equivalent to a model. As all subnets share weights from the same supernet, it is dubbed as Weight Sharing NAS. To efficiently search models/subnets in the NASRec search space, we advance one-shot approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30]</ref> to recommendation domain. We propose Single-operator Any-connection sampling to decouple operator selections and increase connection coverage, operator-balancing interaction blocks to fairly train subnets in the supernet, and post-training fine-tuning to reduce weight co-adaptation. These approaches allow a better ranking of subnet models in the supernet (i.e., 0.16 Pearson ? improvement and 0.11 Kendall ? improvement on full NASRec search space) and a more efficient training of the supernet (i.e., up to 2.5? lower training time). An improved ranking quality and training efficiency gives searchers a stronger signal and lower cost to distinguish models.</p><p>We evaluate NASRec on three popular CTR benchmarks and demonstrate the significant improvements compared to both handcrafted models and NAS-crafted models. Remarkably, NASRec advances the state-of-the-art with log loss reduction of ? 0.001, ? 0.002 on Criteo and KDD Cup 2012, respectively. On Avazu, NAS-Rec advances the state-of-the-art PROFIT <ref type="bibr" target="#b7">[8]</ref> with AUC improvement of 0.002 and on-par log loss, while outperforming PROFIT <ref type="bibr" target="#b7">[8]</ref> on Criteo by 0.002 log loss reduction.</p><p>In addition, NASRec only needs to train a single supernet thanks to the efficient weight sharing mechanism, and thus greatly reduces the search cost. We summarize our major contributions below.</p><p>? We propose NASRec, a new paradigm to scale up automated modeling of recommender systems. NASRec establishes a flexible supernet (search space) with minimal human priors, overcoming data modality and architecture heterogeneity challenges in recommendation domain.</p><p>? We advance weight sharing NAS to recommendation domain by introducing single-operator any-connection sampling, operatorbalancing interaction modules, and post-training fine-tuning. ? NASRec outperforms both manually crafted models and models discovered by NAS methods with smaller search cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Deep learning based recommender systems. Machine-based recommender systems such as click-through rate prediction has been thoroughly investigated in various approaches, such as Logistic Regression <ref type="bibr" target="#b19">[20]</ref>, and Gradient-Boosting Decision Trees <ref type="bibr" target="#b11">[12]</ref>. More recent approaches study deep learning based interaction of different types of features via Wide &amp; Deep Neural Networks <ref type="bibr" target="#b4">[5]</ref>, Deep-Crossing <ref type="bibr" target="#b20">[21]</ref>, Factorization Machines <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14]</ref>, Dot Product <ref type="bibr" target="#b16">[17]</ref> and gating mechanism <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. Yet, these works operate the cost of tremendous manual efforts and suffer from sub-optimal performance and constrained design choices due to the limitations in resource supply.  <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31]</ref>, Natural Language Processing <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26]</ref>, and Recommendation Systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23]</ref>. Recently, Weight-Sharing NAS (WS-NAS) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b25">26]</ref> attracts the attention of researchers: it trains a supernet that represents the whole search space directly on target tasks, and efficiently evaluate subnets (i.e., sub architectures of supernet) with shared supernet weights. Yet, carrying WS-NAS on recommender systems is challenging because recommender systems are brewed upon heterogeneous architectures that are dedicated for interacting multi-modality data, thus require more flexible search spaces and effective supernet training algorithms. Those challenges make WS-NAS provide a lower rank correlation to distinguish models. NASRec addresses them by proposing single-operator any-connection sampling, operatorbalancing interaction modules, and post-training fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HIERARCHICAL NASREC SPACE FOR RECOMMENDER SYSTEMS</head><p>To support data modality and architecture heterogeneity in recommender systems, the flexibility of search space is the key. We establish a new paradigm free of human priors by introducing  NASRec search space enables a full architecture search on building operators and dense connectivity. Here, "blue" blocks produce dense outputs, and "red" blocks produce sparse outputs.</p><p>NASRec search space, a hierarchical search space design that incorporates heterogeneous building operators and dense connectivity, see Figure <ref type="figure" target="#fig_0">1</ref>. The major manual process in designing the search space is simply collecting common operators used in existing approaches <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>. Beyond that, we further incorporate the prevailing self-attention operator into the NASRec search space for better flexibility and higher potential in searched architectures, thanks to its dominance in applications such as ViT <ref type="bibr" target="#b6">[7]</ref> for image recognition, Transformer <ref type="bibr" target="#b24">[25]</ref> for natural language processing, and its emerging exploration in recommender systems <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref>. Next, we demonstrate the NASRec search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NASRec Search Space</head><p>In recommender systems, we define a dense input as ? ? ? R ????? ? which is a 2D tensor from either raw dense features or generated by operators, such as FC, Gating, Sum, and Dot-Product. A sparse input ? ? ? R ??? ? ???? ? is a 3D tensor of sparse embeddings either generated by raw sparse/categorical features or by operators such as EmbedFC and self-attention. Similarly, a dense or sparse output (i.e., ? ? or ? ? ) is respectively defined as a 2D or 3D tensor produced via a corresponding building blocks/operators. In NASRec, all sparse inputs and outputs share the same ??? ? , which equals to the dimension of raw sparse embeddings. Accordingly, we define a dense (sparse) operator as an operator that produces a dense (sparse) output. In NASRec, dense operators include FC, Gating, Sum, and Dot-Product which form the "dense branch" (marked in blue), and sparse operators include EmbedFC and self-attention, which form the "sparse branch" (marked in red).</p><p>A candidate architecture in NASRec search space is a stack of ? choice blocks, followed by a final FC layer to compute logits. Each choice block admits an arbitrary number of multi-modality inputs, each of which is ? = (? ? , ? ? ) from a previous block or raw inputs, and produces a multi-modality output ? = (? ? , ? ? ) of both a dense tensor ? ? and a sparse tensor ? ? via internal building operators. Within each choice block, we can sample operators for search.</p><p>We construct a supernet to represent the NASRec search space, see Figure <ref type="figure" target="#fig_0">1</ref>. The supernet subsumes all possible candidate models/subnets and performs weight sharing among subnets to simultaneously train all of them. We formally define the NASRec supernet S as a tuple of connections C, operators O, and dimensions D as follows: S = (C, D, O) over all ? choice blocks. Specifically, the operators: O = [? (1) , ..., ? (? ) ] enumerates the set of building operators from choice block 1 to ? . The connections: C = [? (1) , ..., ? (? ) ] contains the connectivity &lt; ?, ? &gt; between choice block ? and choice block ?. The dimension: D = [? (1) , ..., ? (? ) ] contains the dimension settings from choice block 1 to ? .</p><p>A subnet ? ?????? = (O ?????? , C ?????? , D ?????? ) in the supernet S represents a model in NASRec search space. A block uses addition to aggregate the outputs of sampled operators in each branch (i.e. "dense branch" or "sparse branch"). When the operator output dimensions do not match, we apply a zero masking to mask out the extra dimension. A block uses concatenation ?????? to aggregate the outputs from sampled connections. Given a sampled subnet ? ?????? , the input ? (? ) to choice block ? is computed as follows given a list of previous block outputs {? (1) , ..., ? (? -1) } and the sampled connections ? (? ) ?????? :</p><formula xml:id="formula_0">? (? ) ? = ?????? ? -1 ?=1 [? (? ) ? ? 1 &lt;?,? &gt;?? (? ) ?????? ],<label>(1)</label></formula><formula xml:id="formula_1">? (? ) ? = ?????? ? -1 ?=1 [? (? ) ? ? 1 &lt;?,? &gt;?? (? ) ?????? ].<label>(2)</label></formula><p>Here, 1 ? is 1 when ? is true otherwise 0. An optional FC/embedded FC layer is inserted to match dimension of 2-D/3-D inputs if needed.</p><p>A building operator ? ? ? (? )</p><p>?????? transforms the concatenated input ? (? ) into an intermediate output with a sampled dimension</p><formula xml:id="formula_2">? (? )</formula><p>?????? . This is achieved by a mask function that applied on the last dimension for dense output and middle dimension for sparse output. For example, a dense output ? (? ) ? is obtained as follows:</p><formula xml:id="formula_3">? (? ) ? = ?? ??O 1 ??O (? ) ?????? ? ???? (? (? (? ) ? ), ? (? ) ??????,? ).<label>(3)</label></formula><p>where</p><formula xml:id="formula_4">???? (? , ?) = ? :,? , if ? &lt; ? 0, Otherwise. .<label>(4)</label></formula><p>Next, we clarify the set of building operators as follows:</p><p>? Fully-connected (FC) layer. Fully-connected layer is the backbone of DNN models for recommender systems <ref type="bibr" target="#b4">[5]</ref> that extracts dense representations. FC is applied on 2D dense inputs, and followed by a ReLU activation.</p><p>? Sigmoid Gating (Gating) layer. We follow the intuition in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b27">28]</ref> and employ a dense building operator, Sigmoid Gating, to enhance the potential of the search space. Given two dense inputs</p><formula xml:id="formula_5">? ? = (? ?1 ? R ????? ?1 , ? ?2 ? R ????? ?2</formula><p>), Sigmoid Gating interacts these two inputs as follows: ??????(? ?1 , ? ?2 ) = ??????? (?? (? ?1 )) * ? ?2 . If the dimension of two dense inputs does not match, a FC layer is applied on ? ?2 as a projection. ? Sum layer. This dense building operator adds two dense inputs:</p><formula xml:id="formula_6">? ? = (? ?1 ? R ????? ?1 , ? ?2 ? R ????? ?2</formula><p>) and merges these two inputs from different levels of the recommender system models by simply performing ???(? ?1 , ? ?2 ) = ? ?1 + ? ?2 . Similar to Sigmoid Gating, a FC layer is utilized as a projection if the dimensions are unmatched. layer is a sparse building operator that applies FC along the middle dimension. Specifically, an EmbedFC with weights ? ? R ? ?? ?? ??? transforms an input ? ? ? R ??? ?? ???? ? to ? ? ? R ??? ??? ???? ? ? Self-Attention (Attn) layer. We use attention <ref type="bibr" target="#b24">[25]</ref> mechanism in vision and natural language processing to learn the weighting of different sparse inputs and better exploit their interaction in recommendation systems. Specifically, self-attention is applied on a given sparse input ? ? ? R ??? ? ???? ? . Self-attention uses identical queries, keys, and values to interact different sparse inputs as follows: ????(? ? ) = ?? ? ???? (</p><formula xml:id="formula_7">? ? ? ? ? ? ??? ? ? ? ).</formula><p>We observe that the aforementioned set of building operators provide opportunities for the sparse inputs to transform into the "dense branch". Yet, these operators do not permit a transformation of dense inputs towards the "sparse branch". To address this limitation, we allow dense outputs to optionally merge into the "sparse branch" and design a new module Project-Concatenate to optionally interact dense and sparse outputs. Specifically, Project-Concatenate first projects the dense output to match the sparse dimension (i.e., embedding dimension) and concatenates it with sparse outputs. As Project-Concatenate module is a new way to interact outputs, it enhances data modality to the NASRec search space with more heterogeneous architecture choices.</p><p>Beyond the rich choices of building operators, each choice block can also receive inputs from any preceding choice blocks, and raw input features. This involves an exploration of any connectivity among choice blocks and raw inputs, extending the wiring heterogeneity for search. Next, we introduce the search components in NASRec and provide two search spaces that we use in experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Search Components</head><p>In NASRec search space, we search the connectivity, operator dimensions, and building operators in each choice block. We illustrate the three key search components as follows:</p><p>? Connection. We place no restrictions on the number of connections that a choice block can receive: each block can choose inputs from an arbitrary number of preceding blocks and raw inputs. Specifically, the n-th choice block can connect to any previous ? -1 choice blocks and the raw dense (sparse) features.</p><p>The outputs from all preceding blocks are concatenated as inputs for dense (sparse) building blocks. We separately concatenate the dense (sparse) outputs from preceding blocks. building operator to transform inputs to a dense (sparse) output. Each block should maintain at least one operator in the dense (sparse) branch to ensure the flow of information from inputs to logit. We independently sample building operators in the dense (sparse) branch to form a validate candidate architecture. In addition, we independently sample Project-Concatenate path to allow optional dense-to-sparse interaction.</p><p>We craft two NASRec search spaces as examples to demonstrate the power of NASRec search space.</p><p>? NASRec-Small. We limit the choice of operators within each block to FC, EmbedFC, and Dot-Product as inspired by AutoCTR <ref type="bibr" target="#b22">[23]</ref> <ref type="foot" target="#foot_0">1</ref> . We allow any connectivity between blocks. ? NASRec-Full. We enable all building operators and connections to construct an aggressive search space for exploration with minimal human priors. Under the constraint that at least one operator must be sampled in both dense and sparse branch, the NASRec-Full search space size is 15 ? ? of NASRec-Small, where ? is the number of choice blocks. This full search space extremely tests the capability of NASRec.</p><p>The combination of full dense connectivity search and independent dense/sparse dimension configuration gives the NASRec search space a large cardinality. NASRec-Full has ? = 7 blocks, 5 possible dimension choices for both dense and sparse dimensions. NASRec search space contains up to 5 ? 10 29 architectures with strong heterogeneity. With minimal human priors and such unconstrained search space, brutal-force sample-based methods may take enormous time to find a state-of-the-art model. This calls for a NASRec supernet to cover the overall search space and brew all candidate architectures in an efficient manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">WEIGHT SHARING NEURAL ARCHITECTURE SEARCH FOR RECOMMENDER SYSTEMS</head><p>A NASRec supernet simultaneously brews different subnet models in the NASRec search space, yet imposes challenges to training efficiency and ranking quality due to its large cardinality. In this section, we first propose a novel path sampling strategy, Single-operator Any-connection sampling, that decouples operator sampling with a good connection sampling converge. We further observe the operator imbalance phenomenon induced by some over-parameterized operators, and tackle this issue by operator-balancing interation to improve supernet ranking. Finally, we employ post-training finetuning to alleviate weight co-adaptation, and further utilize regularized evolution to obtain the subnet with the best performance. WE also provide a set of insights that effectively explore the best recommender models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Single-operator Any-Connection Sampling</head><p>The supernet training adopts a drop-out like approach. At each minibatch, we sample and train a subnet. During training, we train lots of subnets under weight sharing, with the goal that subnets are well trained to predict the performance of models. Sampling strategies are important to meet the goal. We explore three path sampling strategies depicted in Figure <ref type="figure" target="#fig_1">2</ref> and discover Single-operator Any-Connection sampling is the most effective way:</p><p>? Single-operator Single-connection strategy. This path sampling strategy has its root in Computer Vision <ref type="bibr" target="#b10">[11]</ref>: it uniformly samples a single dense and a single sparse operator in each choice block, and uniformly samples a single connection as an input to block. The strategy is efficient because, on average, only a small subnet is trained at one mini-batch, however, this strategy only encourages chain-like formulation of models without extra connectivity patterns. The lack of connectivity coverage yields slower convergence, poor performance, and inaccurate ranking of models as we will show. ? Any-operator Any-connection Strategy. This sampling strategy increases the coverage of sub-architectures of supernet during subnet training: it uniformly samples an arbitrary number of dense and sparse operators in each choice block, and uniformly sample an arbitrary number of connections to aggregate different block outputs. Yet, the training efficiency is poor when training sampled large subnets. More importantly, the weight co-adaptation of multiple operators within a choice block may affect independent evaluation of the subnets, and thus eventually lead to poor ranking quality as we will show. ? Single-operator Any-connection. We propose this path sampling strategy to combine the strengths from above two strategies. Single-operator Any-connection samples a single dense and a single sparse operator in each choice block, and samples an arbitrary number of connections to aggregate the outputs from different choice blocks. The key insight of this strategy is separating the sampling of parametric operators to avoid the co-adaptation of weights, and allowing arbitrarily sample of non-parametric connections to gain a good coverage of the NASRec search space. Thus, it provides a more accurate performance evaluation and ranking of the subnets.  In more details, compared to Any-operator Any-connection sampling, Single-operator Any-connection sampling achieves higher training efficiency: the reduced number of sampled operators reduces the training cost by up to 1.5?. In addition, Single-operator Any-connection samples medium-sized networks more frequently. These medium-sized networks achieve the best trade-off between model size and performance as we will show in Table <ref type="table" target="#tab_9">5</ref>.</p><p>We evaluate the ranking of subnets by WS-NAS on Criteo and by 100 randomly sampled networks in Figure <ref type="figure" target="#fig_2">3</ref>. Here, we adopt the design of operator-balancing interaction modules in Section 4.2 to maximize the potential of each path sampling strategy. In the figure, the y-axis is the Log Loss of subnets, whose weights are copied from corresponding architectures in the trained supernet. Single-operator Any-connection achieves at least 0.16 higher Kendall Tau and 0.11 higher Pearson rho compared to other path sampling strategies. In addition, we observe that Single-operator Any-connection sampling allows better convergence of the NASRec supernet and subnets that inherit weights from supernet achieve lower log loss during validation, leading to a better exploitation of their ground-truth performance for a better ranking quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Operator-Balancing Interaction Modules</head><p>Recommender systems involve multi-modality data with an indefinite number of inputs, for example, a large number of sparse inputs. We define operator imbalance as the imbalance of the numbers of weights between operators within a block. In weight-sharing NAS, operator imbalance may cause the issue that supernet training may favor operators with more weights. This will offset the gains due to poor ranking correlations of subnets: the subnet performance in supernet may deviate from its ground-truth performance when trained from scratch. We identify that, in our NASRec, such an issue is strongly related to the Dot-Product operator, and provide mitigation to address such operator imbalance.</p><p>Given ? ? sparse embeddings, a Dot-Product block produces</p><formula xml:id="formula_8">? 2</formula><p>? /2 pairwise interactions as a quadratic function on the number of sparse embeddings. As detailed in Section 3.1, the supernet requires a linear projection layer (i.e., FC) to match the output dimensions of operators within each choice block. Typically for Dot-Product, this leads to an extra (? 2 ? ? ??? ? /2) trainable weights. However, the weight consumption of such projection layer is large given a large number of sparse embeddings. For example, given ? ? = 448 and ??? ? = 512 in a 7-block NASRec supernet, the projection layer induces over 50? parameters in the NASRec supernet, which has a similar scale of parameter consumption with sparse embedding layers. Moreover, such tremendous weight parameterization is a quadratic function of the number of sparse inputs ? ? , yet other building operators have much fewer weights, such as, the number of trainable weights in EmbedFC is a linear function of the number of sparse inputs ? ? . As a result, the over-parameterization in Dot-Product leads to an increased convergence rate for the Dot-Product operator and consequently favor parameter-consuming subnets with a high concentration of Dot-Product operations as we observed. In addition, the ignorance of other heterogeneous operators other than Dot-Product provides a poor ranking of subnets, leading to sub-optimal performance on recommender systems.</p><p>We insert a simple EmbedFC as a projection layer before the Dot-Product to mitigate such over-parameterization, see  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Post-training Fine-tuning</head><p>Although dropout-like subnet training provide a great way to reduce the adaptation of weights for a specific subnet, the subnet performance prediction by supernet can fail when weights should not share across some subnets. After the supernet training and during a stand alone subnet evaluation, we carry a post-training fine-tuning that re-adapt its weights back to the specific subnet. This can re-calibrate the weights which are corrupted when training other subnets during the supernet training. In practice, we find that fine-tuning the last FC on the target dataset for a few training steps (e.g., 0.5K) is good enough. With only marginal extra search cost, this novel post-training fine-tuning technique boosts the ranking of subnets by addressing the underlying weight adaptation issue, and thus provides a better chance to discover better models for recommender systems.</p><p>Table <ref type="table" target="#tab_6">3</ref> demonstrates the improvement of post-training finetuning on different path sampling strategies. Surprisingly, posttraining fine-tuning achieves decent ranking quality improvement under Single-operator Single-connection and Any-operator Anyconnection path sampling strategy. This is because subnets under these strategies do not usually converge well in supernet: they either suffer from poor supernet coverage, or poor convergence induced by co-adaptation. The fine-tuning process releases their potential and approaches their real performance on the target dataset. Remarkably, Single-operator Any-connection path sampling strategy cooperates well with post-training fine-tuning, and achieves the global optimal Pearson ? and Kendall ? ranking correlation among different approaches, with at least 0.15 Kendall ? improvement and 0.14 Pearson ? improvement on NASRec-Full search space over Single-operator Single-connection sampling without fine-tuning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evolutionary Search on Best Models</head><p>We utilize regularized evolution <ref type="bibr" target="#b17">[18]</ref> to obtain the best child subnet in NASRec search space, including NASRec Small and NASRec-Full.</p><p>Here, we first introduce a single mutation of a hierarchical genotype with the following sequence of actions in one of the choice blocks:</p><p>? Re-sample the dimension of one dense building operator.</p><p>? Re-sample the dimension of one sparse building operator.</p><p>? Re-sample one dense building operator.</p><p>? Re-sample one sparse building operator.</p><p>? Re-sample its connection to other choice blocks.</p><p>? Re-sample the choice of Project-Concat block that enables the interaction between dense and sparse outputs.</p><p>The mutation space covers both the search components of operators, connections, and dimensions in NASRec search spaces. We use Adaptive Mutation Strategy to explore subnets in NASRec search space. The original regularized evolution performs a single mutation to generate child architectures from a given parent architecture. Unfortunately, directly applying regularized evolution may suffer from locally optimal solution, mostly caused by a bad initialization point (i.e., initial population) during the initial phase of regularized evolution. To mitigate this issue, we envision that, at the initial phase of regularized evolution, we can perform multiple mutations to generate a child architecture from a parent architecture. Because initial parent architectures are unlikely to be optimal, performing more mutations at the early stage allow the evolutionary search to explore a wider region of the NASRec search space, thus leads to potentially better solutions. In addition, the number of mutations to generate a child architecture will gradually decay to 1 as the search progresses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We first show the detailed configuration that NASRec employs during architecture search, model selection and final evaluation. Then, we demonstrate empirical evaluations on three popular recommender system benchmarks for Click-Through Rates (CTR) prediction: Criteo<ref type="foot" target="#foot_1">2</ref> , Avazu<ref type="foot" target="#foot_2">3</ref> and KDD Cup 2012 <ref type="foot" target="#foot_3">4</ref> . All three datasets are pre-processed in the same fashion as AutoCTR <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Search Configuration</head><p>We first demonstrate the detailed configuration of NASRec-Full search space as follows:</p><p>? Connection Search Components. We utilize ? = 7 blocks in our NASRec search space to keep a fair comparison with existing NAS methods, such as AutoCTR <ref type="bibr" target="#b22">[23]</ref>. All choice blocks can arbitrarily connect to previous choice blocks or raw features. ? Operator Search Components. In each choice block, our search space contains 6 distinct building operators, including 4 dense building operators: FC, Gating, Sum, Dot-Product and 2 distinct sparse building operators: Self-Attention and EmbedFC. ? Dimension Search Components. For each dense building operator, the dense output dimension can choose from {32, 64, 128, 256, 512}. For each sparse building operator, the sparse output dimension can be chosen from {16, 32, 64}.</p><p>? Capped Embedding Table . We cap the maximum embedding table size to 0.5M during supernet training for search efficiency. This gives 2?3 ? speedup compared to using the full embedding table . During the final evaluation, we maintain the full embedding table to retrieve the best performance, i.e., a total of 540M parameters in DLRM <ref type="bibr" target="#b16">[17]</ref> on Criteo to ensure a fair comparison. ? Supernet Warm-up. We observe that the supernet may collapse at initial training phases due to the varying sampled paths and uninitialized embedding layers. To mitigate the initial collapsing of supernet, we randomly sample the full supernet at the initial 1/4 of the training steps, with a probability ? that linearly decays from 1 to 0. This provides dimension warm-up, operator warmup <ref type="bibr" target="#b1">[2]</ref> and connection warm-up for the supernet with minimal impact on the quality of sampled paths. ? Supernet Training Settings. We insert layer normalization <ref type="bibr" target="#b0">[1]</ref> into each building operator to normalize varying subnet statistics during supernet training. Our choice of hyperparameters is robust over different NASRec search spaces and recommender system benchmarks. We train the supernet for only 1 epoch with Adagrad optimizer, an initial learning rate of 0.04, a cosine learning rate schedule <ref type="bibr" target="#b15">[16]</ref>, and a batch size 256 to perform sufficient path sampling on target recommender system benchmarks.</p><p>Finally, we present the details of regularized evolution and model selection strategies over NASRec search spaces.</p><p>? Regularized Evolution. Despite the large size of NASRec-Full and NASRec-small, we employ an efficient configuration of regularized evolution to seek the optimal subnets from supernet. Specifically, we maintain a population of 64 architectures and run regularized evolution for 100 iterations. In each iteration, we first pick up the best architecture from 32 sampled architectures from the population as the parent architecture, and generate 16 child architectures to update the population. Following the aforementioned "Adaptive Mutation Strategy", each child architecture is derived from the parent architecture with 5 mutations. We decay the number of mutations by 1 every 20 iterations. ? Model Selection. We follow the evaluation protocols in Au-toCTR <ref type="bibr" target="#b22">[23]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Recommender System Benchmark Results</head><p>We select baselines from both hand-crafted state-of-the-arts (SOTA) and automatically designed models for comparison. We follow the  data preprocessing protocol in AutoCTR <ref type="bibr" target="#b22">[23]</ref> and report their reproduced baseline results for fair comparison. We train the best model discovered by NASRec from scratch on three classic recommender system benchmarks, and compare the performance (i.e., Log Loss, AUC) of models that are crafted by NASRec on three general recommender system benchmarks. In Table <ref type="table" target="#tab_8">4</ref>, we report the evaluation results of our end to end NASRec-crafted models and a random search baseline which randomly samples and trains models in our NASRec search space. NASRec Revolutionizes Hand-crafted Recommender System Models. Even within an aggressively large NASRec-Full search space, NASRec achieves record-breaking performance over handcrafted CTR models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref> with minimal human priors as shown in Table <ref type="table" target="#tab_8">4</ref>. Compared with AutoInt <ref type="bibr" target="#b23">[24]</ref>, the hand-crafted SOTA that fabricates feature interactions with delicate engineering efforts, NASRec achieves ? 0.002 Log Loss reduction on Criteo, ? 0.007 Log Loss reduction on Avazu, and ? 0.003 Log Loss reduction on KDD Cup 2012. Thus, NASRec revolutionizes the design of CTR models: it shows promising prospects on improving full architecture search on recommender systems, with minimal human expertise and interventions. NASRec is the SOTA NAS method. Even compared to the most recent NAS-crafted models <ref type="bibr" target="#b22">[23]</ref>, NASRec achieves the state-of-theart (SOTA) Log Loss and AUC on all three recommender system benchmarks. With the same scale of search space as AutoCTR (i.e., NASRec-Small search space), NASRec yields better performance on all three benchmarks: it achieves 0.0006 Log Loss reduction on Criteo, 0.004 Log Loss reduction on Avazu, and 0.003 Log Loss reduction on KDD Cup 2012. This demonstrates the generic superiority of NASRec towards different recommendation system applications. Compared to DNAS <ref type="bibr" target="#b12">[13]</ref> and PROFIT <ref type="bibr" target="#b7">[8]</ref> which only focuses on configuring part of the architectures, such as dense connectivity and raw feature interactions, NASRec achieves at least ? 0.002 Log Loss reduction on Criteo and justifies the significance of full architecture search on recommender system benchmarks. By extending NASRec to an extremely large NASRec-full search space, the best discovered NAS models further improves its result on Avazu and out-performs PROFIT by 0.002 AUC improvement with on-par Log Loss, justifying the design of NASRec-full with aggressively large cardinality and minimal human priors. On Criteo and KDD Cup 2012, NASRec maintains the edge in discovering state-of-the-art CTR models compared to existing NAS methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23]</ref>. Efficient Search within a Versatile Search Space. Despite a larger NASRec search space that presents more challenges to fully explore, NASRec achieves at least 1.7? searching efficiency compared to state-of-the-art efficient NAS methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref> with significant Log Loss improvement on all three benchmarks. This is greatly attributed to the efficiency of Weight-Sharing NAS applied on heterogeneous operators and multi-modality data.</p><p>We also establish a random search baseline on both NASRec-Full and NASRec-Small. We first plot the Cumulative Distribution Function in NASRec-small. A higher density of top-performing architectures exists compared to NASRec-full, making random search relatively easier to obtain top-performing architectures within a limited budget. However, as the cardinality of the search space increases, random search obtains worse performance due to a lower density of top-performing architectures, see Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>Despite a lower random search baseline, the scalable Weight-Sharing NAS tackles the exploration of full NASRec-Full search space thanks to the broad coverage of the supernet. With an effective Single-Operator Any-connection path sampling strategy, Weight-Sharing NAS narrows the gap of random search on Criteo and KDD Cup 2012, yet surprisingly discovers a significantly better model on Avazu. This indicates that a larger NASRec search space has the potential to explore more architecture possibilities and obtain better models for recommendation system designs, and justify our usage of the flexible and hierarchical NASRec-Full search space. We compare the model complexity of NASRec with SOTA handcrafted models and SOTA NAS models. We collect all baselines from AutoCTR <ref type="bibr" target="#b22">[23]</ref>, and list performance versus the number of theoretical Floating-point Operations (FLOPs) in Table <ref type="table" target="#tab_9">5</ref>. We profile all FLOPS of NASRec models using FvCore <ref type="foot" target="#foot_4">5</ref> .</p><p>Even without any FLOPs constraints, the best crafted NASRec models surprisingly out-perform existing arts in efficiency. Despite achieving lower Log Loss, our NAS-crafted model achieves 8.2?, 4.2?, and 3.1? FLOPS reduction on Criteo, Avazu, and KDD Cup 2012 benchmarks. One reason is our Single-operator Anyconnection sampling strategies favor medium-sized models to trade off model cost and performance as introduced in Section 4.1. One possible reason lies in the use of operator-balancing interaction modules projects the large number of sparse inputs to a smaller dimension before carrying cross-term feature interaction. This leads to significantly lower computation costs. As a result, our Weight-Sharing NAS enables discovering of compact yet high-performing models, and greatly contributes efficient models towards recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we propose NASRec, a new paradigm to fully enable NAS for recommender systems via Weight Sharing Neural Architecture Search (WS-NAS) under data modality and architecture heterogeneity. NASRec establishes a large supernet to represent the full architecture space, and incorporates versatile building operators and dense block connections to minimize human priors in automated architecture design for recommender systems. NAS-Rec identifies the scale and heterogeneity challenges of large-scale NASRec search space that compromises supernet, and proposes a series of techniques to improve training efficiency and mitigate ranking disorder. NASRec achieves state-of-the-art performance on 3 popular recommender system benchmarks, shows promising prospects on full architecture search space and directs motivating research towards fully automated architecture fabrication with minimal human priors'.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Overview of NASRec search space. NASRec search space enables a full architecture search on building operators and dense connectivity. Here, "blue" blocks produce dense outputs, and "red" blocks produce sparse outputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: We propose Single-operator Any-connection path sampling by combining the advantages of the first two sampling strategies. Here, dashed connections and operators denotes a sampled path in supernet. Single-operator Single-connection: Pearson=0.05, Kendall=0.02 Any-operator Any-connection: Pearson=0.367, Kendall=0.280 Single-operator Any-connection: Pearson=0.457, Kendall=0.436</figDesc><graphic url="image-47.png" coords="5,322.84,305.49,228.24,68.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Ranking evaluation of various path sampling strategies on NASRec-Full supernet. We evaluate all ranking coefficients over 100 randomly sampled subnets on Criteo.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .Figure 4 :</head><label>44</label><figDesc>Figure 4: Operator-balancing interaction. A simple projection layer before Dot-Product ensures linear parameter consumption and balances building operators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Cumulative Distribution Function (CDF) comparison of randomly sampled architectures from different NAS-Rec search spaces.data preprocessing protocol in AutoCTR<ref type="bibr" target="#b22">[23]</ref> and report their reproduced baseline results for fair comparison. We train the best model discovered by NASRec from scratch on three classic recommender system benchmarks, and compare the performance (i.e., Log Loss, AUC) of models that are crafted by NASRec on three general recommender system benchmarks. In Table4, we report the evaluation results of our end to end NASRec-crafted models and a random search baseline which randomly samples and trains models in our NASRec search space. NASRec Revolutionizes Hand-crafted Recommender System Models. Even within an aggressively large NASRec-Full search space, NASRec achieves record-breaking performance over handcrafted CTR models<ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref> with minimal human priors as shown in Table4. Compared with AutoInt<ref type="bibr" target="#b23">[24]</ref>, the hand-crafted SOTA that fabricates feature interactions with delicate engineering efforts, NASRec achieves ? 0.002 Log Loss reduction on Criteo, ? 0.007 Log Loss reduction on Avazu, and ? 0.003 Log Loss reduction on KDD Cup 2012. Thus, NASRec revolutionizes the design of CTR models: it shows promising prospects on improving full architecture search on recommender systems, with minimal human expertise and interventions. NASRec is the SOTA NAS method. Even compared to the most recent NAS-crafted models<ref type="bibr" target="#b22">[23]</ref>, NASRec achieves the state-of-theart (SOTA) Log Loss and AUC on all three recommender system benchmarks. With the same scale of search space as AutoCTR (i.e., NASRec-Small search space), NASRec yields better performance on all three benchmarks: it achieves 0.0006 Log Loss reduction on Criteo, 0.004 Log Loss reduction on Avazu, and 0.003 Log Loss reduction on KDD Cup 2012. This demonstrates the generic superiority</figDesc><graphic url="image-50.png" coords="8,52.72,271.23,80.59,71.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of NASRec vs. existing NAS methods for recommender systems.</figDesc><table><row><cell>Method</cell><cell>Building Operators?</cell><cell>Dense</cell><cell>Full arch</cell><cell>Criteo</cell><cell>Training</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>? Dot-Product (DP) layer. We leverage Dot-Product to grasp the interactions among multi-modality inputs via a pairwise inner products. Dot-Product can take dense and/or sparse inputs, and produce a dense output. These sparse inputs, after being sent to "dense branch", can later take advantage of the dense operators to learn better representations and interactions. Given a dense input ? ? ? R ????? ? and a sparse input ? ? ? R ??? ? ????</figDesc><table /><note><p><p><p>? </p>, a Dot-Product first concatenate them as ? = ?????? [? ? , ? ? ], and then performs pair-wise inner products: ??? -??????? (? ? , ? ? ) = ? ??? (?? ? ). ??? ? is first projected to ??? ? if they do not match.</p>? Embedded Fully-Connected (EmbedFC) layer Embedded FC</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>? Dimension. In a choice block, different operators may produce different tensor dimensions. In NASRec, we set the output sizes of FC and EmbedFC to ??? ? and ? ? , respectively; and other operator outputs in dense (sparse) branch are linearly projected to ??? ? (? ? ). This ensures operator outputs in each branch have the same dimension and can add together. This also give the maximum dimensions ??? ? and ? ? for the dense output ? ? ? R ????? ? and the sparse output ? ? ? R ??? ? ???? ? . Given a dense or sparse output, a mask in Eq. 4 zeros out the extra dimensions, which allows flexible selections of dimensions of building operators.? Operator. Each block can choose at least one dense (sparse)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Operator-Balancing Interactions reduces supernet training cost and improves ranking of subnets.??2??? ? ]) trainable weights and ensures a linear growth of parameter consumption with the number of sparse EmbedFC ? ? . Thus, we balance interaction operator to allow a more similar convergence rate of all building operators. Table2reflects a significant enhancement on the training efficiency and ranking quality of the NASRec-full supernet with Single-operator Any-connection path sampling strategy.</figDesc><table><row><cell cols="4">Interaction Type Training Cost Pearson ? Kendall ?</cell></row><row><cell>Imbalanced DP</cell><cell>5 hours</cell><cell>0.31</cell><cell>0.32</cell></row><row><cell>Balanced DP</cell><cell>2 hours</cell><cell>0.46</cell><cell>0.43</cell></row><row><cell cols="4">minimal projection layer to match the dimension. As such, the Dot-</cell></row><row><cell cols="3">Product operator consumes at most (??? 2 ? +? ? [</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Effects of post-training fine-tuning on different path sampling strategies on NASRec-Full. We demonstrate Pearson ? and Kendall ? over 100 random subnets on Criteo.</figDesc><table><row><cell>Path Sampling Strategy</cell><cell cols="4">No Fine-tuning Pearson ? Kendall ? Pearson ? Kendall ? Fine-tuning</cell></row><row><cell>Any-operator Any-connection</cell><cell>0.37</cell><cell>0.28</cell><cell>0.46</cell><cell>0.43</cell></row><row><cell>Single-operator Single-connection</cell><cell>0.05</cell><cell>0.02</cell><cell>0.43</cell><cell>0.29</cell></row><row><cell>Single-operator Any-connection</cell><cell>0.46</cell><cell>0.43</cell><cell>0.57</cell><cell>0.43</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Performance of NASRec on General CTR Predictions Tasks.</figDesc><table><row><cell></cell><cell cols="2">Method</cell><cell cols="2">Criteo Log Loss AUC</cell><cell cols="2">Avazu Log Loss AUC</cell><cell cols="2">KDD Cup 2012 Log Loss AUC</cell><cell>Search Cost (GPU days)</cell></row><row><cell></cell><cell cols="2">DLRM [17]</cell><cell>0.4436</cell><cell>0.8085</cell><cell>0.3814</cell><cell>0.7766</cell><cell>0.1523</cell><cell>0.8004</cell><cell>-</cell></row><row><cell>Hand-crafted Arts</cell><cell cols="2">xDeepFM [14] AutoInt+ [24]</cell><cell>0.4418 0.4427</cell><cell>0.8052 0.8090</cell><cell>-0.3813</cell><cell>-0.7772</cell><cell>-0.1523</cell><cell>-0.8002</cell><cell>--</cell></row><row><cell></cell><cell cols="2">DeepFM [10]</cell><cell>0.4432</cell><cell>0.8086</cell><cell>0.3816</cell><cell>0.7767</cell><cell>0.1529</cell><cell>0.7974</cell><cell>-</cell></row><row><cell></cell><cell cols="2">DNAS [13]</cell><cell>0.4442</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell cols="2">PROFIT [8]</cell><cell>0.4427</cell><cell>0.8095</cell><cell>0.3735</cell><cell>0.7883</cell><cell>-</cell><cell>-</cell><cell>?0.5</cell></row><row><cell></cell><cell cols="2">AutoCTR [23]</cell><cell>0.4413</cell><cell>0.8104</cell><cell>0.3800</cell><cell>0.7791</cell><cell>0.1520</cell><cell>0.8011</cell><cell>?0.75</cell></row><row><cell>NAS-crafted Arts</cell><cell cols="2">Random Search @ NASRec-Small</cell><cell>0.4411</cell><cell>0.8105</cell><cell>0.3748</cell><cell>0.7885</cell><cell>0.1500</cell><cell>0.8123</cell><cell>1.0</cell></row><row><cell></cell><cell cols="2">Random Search @ NASRec-Full</cell><cell>0.4418</cell><cell>0.8098</cell><cell>0.3767</cell><cell>0.7853</cell><cell>0.1509</cell><cell>0.8071</cell><cell>1.0</cell></row><row><cell></cell><cell cols="2">NASRec @ NASRec-Small</cell><cell>0.4407</cell><cell>0.8109</cell><cell>0.3757</cell><cell>0.7872</cell><cell>0.1494</cell><cell>0.8141</cell><cell>?0.25</cell></row><row><cell></cell><cell cols="2">NASRec @ NASRec-Full</cell><cell>0.4409</cell><cell>0.8107</cell><cell>0.3739</cell><cell>0.7900</cell><cell>0.1498</cell><cell>0.8117</cell><cell>?0.3</cell></row><row><cell>Criteo</cell><cell>Avazu</cell><cell cols="2">KDD Cup 2012</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>13 dense features</cell><cell>0 dense features</cell><cell cols="2">3 dense features</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>26 sparse features</cell><cell>23 sparse features</cell><cell cols="2">10 sparse features</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">NASRec-Small</cell><cell>NASRec-Full</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Model Complexity Analysis.</figDesc><table><row><cell>Method</cell><cell>Log Loss</cell><cell></cell><cell></cell><cell>FLOPS(M)</cell></row><row><cell></cell><cell>Criteo Avazu</cell><cell cols="3">KDD Criteo Avazu KDD</cell></row><row><cell>DLRM</cell><cell cols="3">0.4436 0.3814 0.1523 26.92</cell><cell>18.29 25.84</cell></row><row><cell>DeepFM</cell><cell cols="3">0.4432 0.3816 0.1529 22.74</cell><cell>22.50 21.66</cell></row><row><cell>AutoInt+</cell><cell cols="3">0.4427 0.3813 0.1523 18.33</cell><cell>17.49 14.88</cell></row><row><cell>AutoCTR</cell><cell cols="3">0.4413 0.3800 0.1520 12.31</cell><cell>7.12</cell><cell>3.02</cell></row><row><cell cols="3">NASRec @ NASRec-Small 0.4407 0.3757 0.1494</cell><cell>1.64</cell><cell>2.13</cell><cell>0.76</cell></row><row><cell cols="3">' NASRec @ NASRec-Full 0.4409 0.3739 0.1498</cell><cell>1.50</cell><cell>1.70</cell><cell>0.96</cell></row><row><cell cols="5">5.3 Complexity Analysis of Crafted Models.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We do not utilize FM because it does not appear in the best found models in AutoCTR.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.kaggle.com/c/avazu-ctr-prediction/data</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.kaggle.com/c/kddcup2012-track2/data In NASRec-Small, we employ the same settings except that we use only 2 dense building operators: FC, Dot-Product and 1 sparse building operator: EmbedFC. Then, we illustrate some techniques on brewing the NASRec supernet, including the configuration of embedding, supernet warm-up, and supernet training settings.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://github.com/facebookresearch/fvcore</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">ACKNOWLEDGEMENTS</head><p><rs type="person">Yiran Chen</rs>'s work is partially supported by the following grants: <rs type="grantNumber">NSF-2120333</rs>, <rs type="grantNumber">NSF-2112562</rs> and <rs type="grantNumber">NSF-1937435</rs>. Feng's work is partially supported by the following grants: <rs type="funder">NSF</rs> <rs type="grantNumber">CAREER-2048044</rs> and IIS-1838024. We also thank <rs type="person">Maxim Naumov</rs>, <rs type="person">Jeff Hwang</rs> and <rs type="person">Colin Taylor</rs> in <rs type="affiliation">Meta Platforms, Inc.</rs> for their kind help on this project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ahtzN9G">
					<idno type="grant-number">NSF-2120333</idno>
				</org>
				<org type="funding" xml:id="_9Qz8QHz">
					<idno type="grant-number">NSF-2112562</idno>
				</org>
				<org type="funding" xml:id="_gJ8WpCX">
					<idno type="grant-number">NSF-1937435</idno>
				</org>
				<org type="funding" xml:id="_kuZa8M3">
					<idno type="grant-number">CAREER-2048044</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lei Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Ryan Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<title level="m">Layer normalization</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Can weight sharing outperform random architecture search? an investigation with tunas</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="14323" to="14332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Oncefor-all: Train one network and specialize it for efficient deployment</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09791</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Behavior sequence transformer for e-commerce recommendation in alibaba</title>
		<author>
			<persName><forename type="first">Qiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pipei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data</title>
		<meeting>the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Heng-Tze</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levent</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremiah</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishi</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glen</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Ispir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st workshop on deep learning for recommender systems</title>
		<meeting>the 1st workshop on deep learning for recommender systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM conference on recommender systems</title>
		<meeting>the 10th ACM conference on recommender systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Progressive Feature Interaction Search for Deep Sparse Network</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Depeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13313</idno>
		<title level="m">Modularized transfomer-based ranking framework</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">DeepFM: a factorization-machine based neural network for CTR prediction</title>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04247</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Single path one-shot neural architecture search with uniform sampling</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyuan</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="544" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Practical lessons from predicting clicks on ads at facebook</title>
		<author>
			<persName><forename type="first">Xinran</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ou</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Atallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Bowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth international workshop on data mining for online advertising</title>
		<meeting>the eighth international workshop on data mining for online advertising</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Kalaiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Naumov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dheevatsa</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Misha</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14812</idno>
		<title level="m">Differentiable NAS Framework and Application to Ads CTR Prediction</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">xdeepfm: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</title>
		<meeting>the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
	<note>Xing Xie, and Guangzhong Sun</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.09055</idno>
		<title level="m">Darts: Differentiable architecture search</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<title level="m">Sgdr: Stochastic gradient descent with warm restarts</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Deep learning recommendation model for personalization and recommendation systems</title>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Naumov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dheevatsa</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hao-Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narayanan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongsoo</forename><surname>Sundaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Udit</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carole-Jean</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alisson</forename><forename type="middle">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Azzolini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00091</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the aaai conference on artificial intelligence</title>
		<meeting>the aaai conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4780" to="4789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast context-aware recommendations with factorization machines</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</title>
		<meeting>the 34th international ACM SIGIR conference on Research and development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Predicting clicks: estimating the click-through rate for new ads</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewa</forename><surname>Dominowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ragno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="521" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep crossing: Web-scale modeling without manually crafted combinatorial features</title>
		<author>
			<persName><forename type="first">Ying</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Hoens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haijing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The evolved transformer</title>
		<author>
			<persName><forename type="first">David</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5877" to="5886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards automated neural interaction discovery for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Qingquan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dehua</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiyan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="945" to="955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Autoint: Automatic feature interaction learning via selfattentive neural networks</title>
		<author>
			<persName><forename type="first">Weiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chence</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiping</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijian</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yewen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1161" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Hat: Hardware-aware transformers for efficient natural language processing</title>
		<author>
			<persName><forename type="first">Hanrui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14187</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep &amp; cross network for ad click predictions</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingliang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ADKDD&apos;17</title>
		<meeting>the ADKDD&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">DCN V2: Improved deep &amp; cross network and practical lessons for web-scale learning to rank systems</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Shivanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1785" to="1797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neural predictor for neural architecture search</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-01">Jan Kindermans. 2020</date>
			<biblScope unit="page" from="660" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ruoming Pang, and Quoc Le. 2020. Bignas: Scaling up neural architecture search with big single-stage models</title>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengchong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="702" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
