<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Non-greedy Optimization of Decision Trees</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maxwell</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><surname>Johnson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Cambridge</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Non-greedy Optimization of Decision Trees</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EEAD2995D20A155F59D4D08DF0968DF0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Decision trees and randomized forests are widely used in computer vision and machine learning. Standard algorithms for decision tree induction optimize the split functions one node at a time according to some splitting criteria. This greedy procedure often leads to suboptimal trees. In this paper, we present an algorithm for optimizing the split functions at all levels of the tree jointly with the leaf parameters, based on a global objective. We show that the problem of finding optimal linear-combination (oblique) splits for decision trees is related to structured prediction with latent variables, and we formulate a convex-concave upper bound on the tree's empirical loss. Computing the gradient of the proposed surrogate objective with respect to each training exemplar is O(d 2 ), where d is the tree depth, and thus training deep trees is feasible. The use of stochastic gradient descent for optimization enables effective training with large datasets. Experiments on several classification benchmarks demonstrate that the resulting non-greedy decision trees outperform greedy decision tree baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Decision trees and forests <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b3">4]</ref> have a long and rich history in machine learning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b6">7]</ref>. Recent years have seen an increase in their popularity, owing to their computational efficiency and applicability to large-scale classification and regression tasks. A case in point is Microsoft Kinect where decision trees are trained on millions of exemplars to enable real-time human pose estimation from depth images <ref type="bibr" target="#b21">[22]</ref>.</p><p>Conventional algorithms for decision tree induction are greedy. They grow a tree one node at a time following procedures laid out decades ago by frameworks such as ID3 <ref type="bibr" target="#b20">[21]</ref> and CART <ref type="bibr" target="#b4">[5]</ref>. While recent work has proposed new objective functions to guide greedy algorithms <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b11">12]</ref>, it continues to be the case that decision tree applications (e.g., <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref>) utilize the same dated methods of tree induction. Greedy decision tree induction builds a binary tree via a recursive procedure as follows: beginning with a single node, indexed by i, a split function s i is optimized based on a corresponding subset of the training data D i such that D i is split into two subsets, which in turn define the training data for the two children of the node i. The intrinsic limitation of this procedure is that the optimization of s i is solely conditioned on D i , i.e., there is no ability to fine-tune the split function s i based on the results of training at lower levels of the tree. This paper proposes a general framework for non-greedy learning of the split parameters for tree-based methods that addresses this limitation. We focus on binary trees, while extension to N -ary trees is possible. We show that our joint optimization of the split functions at different levels of the tree under a global objective not only promotes cooperation between the split nodes to create more compact trees, but also leads to better generalization performance.</p><p>One of the key contributions of this work is establishing a link between the decision tree optimization problem and the problem of structured prediction with latent variables <ref type="bibr" target="#b24">[25]</ref>. We present a novel formulation of the decision tree learning that associates a binary latent decision variable with each split node in the tree and uses such latent variables to formulate the tree's empirical loss. Inspired by advances in structured prediction <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>, we propose a convex-concave upper bound on the empirical loss. This bound acts as a surrogate objective that is optimized using stochastic gradient descent (SGD) to find a locally optimal configuration of the split functions. One complication introduced by this particular formulation is that the number of latent decision variables grows exponentially with the tree depth d. As a consequence, each gradient update will have a complexity of O(2 d p) for p-dimensional inputs. One of our technical contributions is showing how this complexity can be reduced to O(d 2 p) by modifying the surrogate objective, thereby enabling efficient learning of deep trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Finding optimal split functions at different levels of a decision tree according to some global objective, such as a regularized empirical risk, is NP-complete <ref type="bibr" target="#b10">[11]</ref> due to the discrete and sequential nature of the decisions in a tree. Thus, finding an efficient alternative to the greedy approach has remained a difficult objective despite many prior attempts.</p><p>Bennett <ref type="bibr" target="#b0">[1]</ref> proposes a non-greedy multi-linear programming based approach for global tree optimization and shows that the method produces trees that have higher classification accuracy than standard greedy trees. However, their method is limited to binary classification with 0-1 loss and has a high computation complexity, making it only applicable to trees with few nodes.</p><p>The work in <ref type="bibr" target="#b14">[15]</ref> proposes a means for training decision forests in an online setting by incrementally extending the trees as new data points are added. As opposed to a naive incremental growing of the trees, this work models the decision trees with Mondrian Processes.</p><p>The Hierarchical Mixture of Experts model <ref type="bibr" target="#b12">[13]</ref> uses soft splits rather than hard binary decisions to capture situations where the transition from low to high response is gradual. The use of soft splits at internal nodes of the tree yields a probabilistic model in which the log-likelihood is a smooth function of the unknown parameters. Hence, training based on log-likelihood is amenable to numerical optimization via methods such as expectation maximization (EM). That said, the soft splits necessitate the evaluation of all or most of the experts for each data point, so much of the computational advantage of the decision tree are lost. <ref type="bibr" target="#b16">[17]</ref> argue that non-greedy tree learning methods that work by looking ahead are unnecessary and sometimes harmful. This is understandable since their methods work by minimizing the empirical loss without any regularization, which is prone to overfitting. To avoid this problem, it is a common practice (see Breiman <ref type="bibr" target="#b3">[4]</ref> or Criminisi and Shotton <ref type="bibr" target="#b6">[7]</ref> for an overview) to limit the tree depth and introduce limits on the number of training instances below which a tree branch is not extended, or to force a diverse ensemble of trees (i.e., a decision forest) through the use of bagging. Bennett and Blue <ref type="bibr" target="#b1">[2]</ref> describe a different way to overcome overfitting by using max-margin framework and the Support Vector Machines (SVM) at the split nodes of the tree. Subsequently, Bennett et al. <ref type="bibr" target="#b2">[3]</ref> show how enlarging the margin of decision tree classifiers results in better generalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Murthy and Salzburg</head><p>Our formulation for decision tree induction improves on prior art in a number of ways. Not only does our latent variable formulation of decision trees enable efficient learning, it can handle any general loss function while not sacrificing the O(dp) complexity of inference imparted by the tree structure. Further, our surrogate objective provides a natural way to regularize the joint optimization of tree parameters to discourage overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem formulation</head><p>For ease of exposition, this paper focuses on binary classification trees, with m internal (split) nodes, and m + 1 leaf (terminal) nodes. Note that in a binary tree the number of leaves is always one more than the number of internal (non-leaf) nodes. An input, x ∈ R p , is directed from the root of the tree down through internal nodes to a leaf node. Each leaf node specifies a distribution over k class labels. Each internal node, indexed by i ∈ {1, . . . , m}, performs a binary test by evaluating a node-</p><formula xml:id="formula_0">+1 h 1 -1 h 2 θ 1 θ 2 +1 h 3 θ 3 θ 4 f ([+1, -1, +1] T ) = [0, 0, 0, 1] T = 1 4 θ = Θ T f (h) = θ 4 -1 h 1 +1 h 2 θ 1 θ 2 +1 h 3 θ 3 θ 4 f ([-1, +1, +1] T ) = [0, 1, 0, 0] T = 1 2 θ = Θ T f (h) = θ 2 Figure 1:</formula><p>The binary split decisions in a decision tree with m = 3 internal nodes can be thought as a binary vector h = [h 1 , h 2 , h 3 ] T . Tree navigation to reach a leaf can be expressed in terms of a function f (h). The selected leaf parameters can be expressed by θ = Θ T f (h). specific split function s i (x) : R p → {-1, +1}. If s i (x) evaluates to -1, then x is directed to the left child of node i. Otherwise, x is directed to the right child. And so on down the tree. Each split function s i (•), by parameterized a weight vector w i , is assumed to be a linear threshold function, i.e., s i (x) = sgn(w i T x). We incorporate an offset parameter to obtain split functions of the form sgn(w i T x -b i ) by appending a constant "-1" to the input feature vector.</p><p>Each leaf node, indexed by j ∈ {1, . . . , m + 1}, specifies a conditional probability distribution over class labels, l ∈ {1, . . . , k}, denoted p(y = l | j). Leaf distributions are parametrized with a vector of unnormalized predictive log-probabilities, denoted θ j ∈ R k , and a softmax function; i.e.,</p><formula xml:id="formula_1">p(y = l | j) = exp θ j[l] k α=1 exp θ j[α] ,<label>(1)</label></formula><p>where θ j[α] denotes the α th element of vector θ j .</p><p>The parameters of the tree comprise the m internal weight vectors, {w i } m i=1 , and the m + 1 vectors of unnormalized log-probabilities, one for each leaf node, {θ j } m+1 j=1 . We pack these parameters into two matrices W ∈ R m×p and Θ ∈ R (m+1)×k whose rows comprise weight vectors and leaf parameters, i.e., W ≡ [w 1 , . . . , w m ]</p><p>T and Θ ≡ [θ 1 , . . . , θ m+1 ] T . Given a dataset of input-output pairs, D ≡ {x z , y z } n z=1 , where y z ∈ {1, . . . , k} is the ground truth class label associated with input x z ∈ R p , we wish to find a joint configuration of oblique splits W and leaf parameters Θ that minimize some measure of misclassification loss on the training dataset. Joint optimization of the split functions and leaf parameters according to a global objective is known to be extremely challenging <ref type="bibr" target="#b10">[11]</ref> due to the discrete and sequential nature of the splitting decisions within the tree.</p><p>One can evaluate all of the split functions, for every internal node of the tree, on input x by computing sgn(W x), where sgn(•) is the element-wise sign function. One key idea that helps linking decision tree learning to latent structured prediction is to think of an m-bit vector of potential split decisions, e.g., h = sgn(W x) ∈ {-1, +1} m , as a latent variable. Such a latent variable determines the leaf to which a data point is directed, and then classified using the leaf parameters. To formulate the loss for (x, y), we introduce a tree navigation function f : H m → I m+1 that maps an m-bit sequence of split decisions (H m ≡ {-1, +1} m ) to an indicator vector that specifies a 1-of-(m + 1) encoding. Such an indicator vector is only non-zero at the index of the selected leaf. Fig. <ref type="figure">1</ref> illustrates the tree navigation function for a tree with 3 internal nodes.</p><p>Using the notation developed above, θ = Θ T f (sgn(W x)) represents the parameters corresponding to the leaf to which x is directed by the split functions in W . A generic loss function of the form (θ, y) measures the discrepancy between the model prediction based on θ and an output y. For the softmax model given by (1), a natural loss is the negative log probability of the correct label, referred to as log loss,</p><formula xml:id="formula_2">(θ, y) = log (θ, y) = -θ [y] + log k β=1 exp(θ [β] ) .<label>(2)</label></formula><p>For regression tasks, when y ∈ R q , and the value of θ ∈ R q is directly emitted as the model prediction, a natural choice of is squared loss, (θ, y) = sqr (θ, y) = θy 2 .</p><p>(3) One can adopt other forms of loss within our decision tree learning framework as well. The goal of learning is to find W and Θ that minimize empirical loss, for a given training set D, that is,</p><formula xml:id="formula_3">L(W, Θ; D) = (x,y)∈D Θ T f (sgn(W x)), y .<label>(4)</label></formula><p>Direct global optimization of empirical loss L(W, Θ; D) with respect to W is challenging. It is a discontinuous and piecewise-constant function of W . Furthermore, given an input x, the navigation function f (•) yields a leaf parameter vector based on a sequence of binary tests, where the results of the initial tests determine which subsequent tests are performed. It is not clear how this dependence of binary tests should be formulated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Decision trees and structured prediction</head><p>To overcome the intractability in the optimization of L, we develop a piecewise smooth upper bound on empirical loss. Our upper bound is inspired by the formulation of structured prediction with latent variables <ref type="bibr" target="#b24">[25]</ref>. A key observation that links decision tree learning to structured prediction, is that one can re-express sgn(W x) in terms of a latent variable h. That is,</p><formula xml:id="formula_4">sgn(W x) = argmax h∈H m (h T W x) .<label>(5)</label></formula><p>In this form, decision tree's split functions implicitly map an input x to a binary vector h by maximizing a score function h T W x, the inner product of h and W x. One can re-express the score function in terms of a more familiar form of a joint feature space on h and x, as w T φ(h, x), where φ(h, x) = vec (hx T ), and w = vec (W ). Previously, Norouzi and Fleet <ref type="bibr" target="#b18">[19]</ref> used the same reformulation (5) of linear threshold functions to learn binary similarity preserving hash functions.</p><p>Given (5), we re-express empirical loss as,</p><formula xml:id="formula_5">L(W, Θ; D) = (x,y)∈D (Θ T f ( h(x)), y) , where h(x) = argmax h∈H m (h T W x) .<label>(6)</label></formula><p>This objective resembles the objective functions used in structured prediction, and since we do not have a priori access to the ground truth split decisions, h(x), this problem is a form of structured prediction with latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Upper bound on empirical loss</head><p>We develop an upper bound on loss for an input-output pair (x, y), which takes the form,</p><formula xml:id="formula_6">(Θ T f (sgn(W x)), y) ≤ max g∈H m g T W x + (Θ T f (g), y) -max h∈H m (h T W x) .<label>(7)</label></formula><p>To validate the bound, first note that the second term on the RHS is maximized by h = h(x) = sgn(W x). Second, when g = h(x), it is clear that the LHS equals the RHS. Finally, for all other values of g, the RHS can only get larger than when g = h(x) because of the max operator. Hence, the inequality holds. An algebraic proof of ( <ref type="formula" target="#formula_6">7</ref>) is presented in the supplementary material.</p><p>In the context of structured prediction, the first term of the upper bound, i.e., the maximization over g, is called loss-augmented inference, as it augments the inference problem, i.e., the maximization over h, with a loss term. Fortunately, the loss-augmented inference for our decision tree learning formulation can be solved exactly, as discussed below.</p><p>It is also notable that the loss term on the LHS of ( <ref type="formula" target="#formula_6">7</ref>) is invariant to the scale of W , but the upper bound on the right side of ( <ref type="formula" target="#formula_6">7</ref>) is not. As a consequence, as with binary SVM and margin-rescaling formulations of structural SVM <ref type="bibr" target="#b23">[24]</ref>, we introduce a regularizer on the norm of W when optimizing the bound. To justify the regularizer, we discuss the effect of the scale of W on the bound.</p><p>Proposition 1. The upper bound on the loss becomes tighter as a constant multiple of W increases, i.e., for a &gt; b &gt; 0:</p><formula xml:id="formula_7">max g∈H m ag T W x + (Θ T f (g), y) -max h∈H m (ah T W x) ≤ max g∈H m bg T W x + (Θ T f (g), y) -max h∈H m (bh T W x).<label>(8)</label></formula><p>Proof. Please refer to the supplementary material for the proof.</p><p>In the limit, as the scale of W approach +∞, the loss term (Θ T f (g), y) becomes negligible compared to the score term g T W x. Thus, the solutions to loss-augmented inference and inference problems become almost identical, except when an element of W x is very close to 0. Thus, even though a larger W yields a tighter bound, it makes the bound approach the loss itself, and therefore becomes nearly piecewise-constant, which is hard to optimize. Based on Proposition 1, one easy way to decrease the upper bound is to increase the norm of W , which does not affect the loss.</p><p>Our experiments indicate that a lower value of the loss can be achieved when the norm of W is regularized. We therefore constrain the norm of W to obtain an objective with better generalization. Since each row of W acts independently in a decision tree in the split functions, it is reasonable to constrain the norm of each row independently. Summing over the bounds for different training pairs and constraining the norm of rows of W , we obtain the following optimization problem, called the surrogate objective:</p><formula xml:id="formula_8">minimize L (W, Θ; D) = (x,y)∈D max g∈H m g T W x + (Θ T f (g), y) -max h∈H m (h T W x) s.t. w i 2 ≤ ν for all i ∈ {1, . . . , m}<label>(9)</label></formula><p>where ν ∈ R + is a regularization parameter and w i is the i th row of W . For all values of ν, we have L(W, Θ; D) ≤ L (W, Θ; D). Instead of using the typical Lagrange form for regularization, we employ hard constraints to enable sparse gradient updates of the rows of W , since the gradients for most rows of W are zero at each step in training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Optimizing the surrogate objective</head><p>Even though minimizing the surrogate objective of ( <ref type="formula" target="#formula_8">9</ref>) entails a non-convex optimization, L (W, Θ; D) is much better behaved than empirical loss in (4). L (W, Θ; D) is piecewise linear and convex-concave in W , and the constraints on W define a convex set.</p><p>Loss-augmented inference. To evaluate and use the surrogate objective in <ref type="bibr" target="#b8">(9)</ref> for optimization, we must solve a loss-augmented inference problem to find the binary code that maximizes the sum of the score and loss terms:</p><formula xml:id="formula_9">g(x) = argmax g∈H m g T W x + (Θ T f (g), y) .<label>(10)</label></formula><p>An observation that makes this optimization tractable is that f (g) can only take on m+ 1 distinct values, which correspond to terminating at one of the m+1 leaves of the tree and selecting a leaf parameter from {θ j } m+1 j=1 . Fortunately, for any leaf index j ∈ {1, . . . , m+1}, we can solve argmax</p><formula xml:id="formula_10">g∈H m g T W x + (θ j , y) s. t. f (g) = 1 j ,<label>(11)</label></formula><p>efficiently. Note that if f (g) = 1 j , then Θ T f (g) equals the j th row of Θ, i.e., θ j . To solve <ref type="bibr" target="#b10">(11)</ref> we need to set all of the binary bits in g corresponding to the path from the root to the leaf j to be consistent with the path direction toward the leaf j. However, bits of g that do not appear on this path have no effect on the output of f (g), and all such bits should be set based on g [i] = sgn(w i T x) to obtain maximum g T W x. Accordingly, we can essentially ignore the off-the-path bits by subtracting sgn(W x) T W x from <ref type="bibr" target="#b10">(11)</ref> to obtain,</p><formula xml:id="formula_11">argmax g∈H m g T W x + (θ j , y) = argmax g∈H m g -sgn(W x) T W x + (θ j , y) . (<label>12</label></formula><formula xml:id="formula_12">)</formula><p>Algorithm 1 Stochastic gradient descent (SGD) algorithm for non-greedy decision tree learning.</p><p>1: Initialize W (0) and Θ (0) using greedy procedure 2: for t = 0 to τ do 3:</p><p>Sample a pair (x, y) uniformly at random from D 4:</p><p>h ← sgn(W (t) x)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>g ← argmax g∈H m g T W (t) x + (Θ T f (g), y)</p><p>6:</p><formula xml:id="formula_13">W (tmp) ← W (t) -η gx T + η hx T 7:</formula><p>for i = 1 to m do 8:</p><formula xml:id="formula_14">W (t+1) i, . ← min 1, √ ν W (tmp) i, .<label>2</label></formula><formula xml:id="formula_15">W (tmp) i, .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>end for 10:</p><formula xml:id="formula_16">Θ (t+1) ← Θ (t) -η ∂ ∂Θ (Θ T f ( g), y) Θ=Θ (t) 11: end for Note that sgn(W x)</formula><p>T W x is constant in g, and this subtraction zeros out all bits in g that are not on the path to the leaf j. So, to solve <ref type="bibr" target="#b11">(12)</ref>, we only need to consider the bits on the path to the leaf j for which sgn(w i T x) is not consistent with the path direction. Using a single depth-first search on the decision tree, we can solve <ref type="bibr" target="#b10">(11)</ref> for every j, and among those, we pick the one that maximizes <ref type="bibr" target="#b10">(11)</ref>.</p><p>The algorithm described above is O(mp) ⊆ O(2 d p), where d is the tree depth, and we require a multiple of p for computing the inner product w i x at each internal node i. This algorithm is not efficient for deep trees, especially as we need to perform loss-augmented inference once for every stochastic gradient computation. In what follows, we develop an alternative more efficient formulation and algorithm with time complexity of O(d 2 p).</p><p>Fast loss-augmented inference. To motivate the fast loss-augmented inference algorithm, we formulate a slightly different upper bound on the loss, i.e., (Θ T f (sgn(W x)), y) ≤ max g∈B1(sgn(W x))</p><formula xml:id="formula_17">g T W x + (Θ T f (g), y) -max h∈H m h T W x ,<label>(13)</label></formula><p>where B 1 (sgn(W x)) denotes the Hamming ball of radius 1 around sgn(W x), i.e., B 1 (sgn</p><formula xml:id="formula_18">(W x)) ≡ {g ∈ H m | g -sgn(W x) H ≤ 1}, hence g ∈ B 1 (sgn(W x))</formula><p>implies that g and sgn(W x) differ in at most one bit. The proof of ( <ref type="formula" target="#formula_17">13</ref>) is identical to the proof of <ref type="bibr" target="#b6">(7)</ref>. The key benefit of this new formulation is that loss-augmented inference with the new bound is computationally efficient. Since g and sgn(W x) differ in at most one bit, then f ( g) can only take d + 1 distinct values. Thus we need to evaluate <ref type="bibr" target="#b11">(12)</ref> for at most d + 1 values of j, requiring a running time of O(d 2 p).</p><p>Stochastic gradient descent (SGD). One reasonable approach to minimizing (9) uses stochastic gradient descent (SGD), the steps of which are outlined in Alg 1. Here, η denotes the learning rate, and τ is the number of optimization steps. Line 6 corresponds to a gradient update in W , which is supported by the fact that ∂ ∂W h T W x = hx T . Line 8 performs projection back to the feasible region of W , and Line 10 updates Θ based on the gradient of loss. Our implementation modifies Alg 1 by adopting common SGD tricks, including the use of momentum and mini-batches.</p><p>Stable SGD (SSGD). Even though Alg 1 achieves good training and test accuracy relatively quickly, we observe that after several gradient updates some of the leaves may end up not being assigned to any data points and hence the full tree capacity is not exploited. We call such leaves inactive as opposed to active leaves that are assigned to at least one training data point. An inactive leaf may become active again, but this rarely happens given the form of gradient updates. To discourage abrupt changes in the number of inactive leaves, we introduce a variant of SGD, in which the assignments of data points to leaves are fixed for a number of gradient updates. Thus, the bound is optimized with respect to a set of data point leaf assignment constraints. When the improvement in the bound becomes negligible the leaf assignment variables are updated, followed by another round of optimization of the bound. We call this algorithm Stable SGD (SSGD) because it changes the assignment of data points to leaves more conservatively than SGD. Let a(x) denote the 1-of-(m + 1) encoding of the leaf to which a data point x should be assigned to. Then, each iteration of SSGD</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SensIT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connect4</head><p>Protein MNIST with fast loss-augmented inference relies on the following upper bound on loss,</p><formula xml:id="formula_19">(Θ T f (sgn(W x)), y) ≤ max g∈B1(sgn(W x)) g T W x + (Θ T f (g), y) - max h∈H m |f (h)=a(x) h T W x .<label>(14)</label></formula><p>One can easily verify that the RHS of ( <ref type="formula" target="#formula_19">14</ref>) is larger than the RHS of ( <ref type="formula" target="#formula_17">13</ref>), hence the inequality.</p><p>Computational complexity. To analyze the computational complexity of each SGD step, we note that Hamming distance between g (defined in <ref type="bibr" target="#b9">(10)</ref>) and h = sgn(W x) is bounded above by the depth of the tree d. This is because only those elements of g corresponding to the path to a selected leaf can differ from sgn(W x). Thus, for SGD the expression ( gh) x T needed for Line 6 of Alg 1 can be computed in O(dp), if we know which bits of h and g differ. Accordingly, Lines 6 and 7 can be performed in O(dp). The computational bottleneck is the loss augmented inference in Line 5. When fast loss-augmented inference is performed in O(d 2 p) time, the total time complexity of gradient update for both SGD and SSGD becomes O(d 2 p + k), where k is the number of labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>Experiments are conducted on several benchmark datasets from LibSVM <ref type="bibr" target="#b5">[6]</ref> for multi-class classification, namely SensIT, Connect4, Protein, and MNIST. We use the provided train; validation; test sets when available. If such splits are not provided, we use a random 80%/20% split of the training data for train; validation and a random 64%/16%/20% split for train; validation; test sets. We compare our method for non-greedy learning of oblique trees with several greedy baselines, including conventional axis-aligned trees based on information gain, OC1 oblique trees <ref type="bibr" target="#b16">[17]</ref> that use coordinate descent for optimization of the splits, and random oblique trees that select the best split function from a set of randomly generated hyperplanes based on information gain. We also compare with the results of CO2 <ref type="bibr" target="#b17">[18]</ref>, which is a special case of our upper bound approach applied greedily to trees of depth 1, one node at a time. Any base algorithm for learning decision trees can be augmented by post-training pruning <ref type="bibr" target="#b15">[16]</ref>, or building ensembles with bagging <ref type="bibr" target="#b3">[4]</ref> or boosting <ref type="bibr" target="#b7">[8]</ref>. However, the key differences between non-greedy trees and baseline greedy trees become most apparent when analyzing individual trees. For a single tree the major determinant of accuracy is the size of the tree, which we control by changing the maximum tree depth. Fig. <ref type="figure" target="#fig_0">2</ref> depicts test and training accuracy for non-greedy trees and four other baselines as function of tree depth. We evaluate trees of depth 6 up to 18 at depth intervals of 2. The hyper-parameters for each method are tuned for each depth independently. While the absolute accuracy of our non-greedy trees varies between datasets, a few key observations hold for all cases. First, we observe that non- greedy trees achieve the best test performance across tree depths across multiple datasets. Secondly, trees trained using our non-greedy approach seem to be less susceptible to overfitting and achieve better generalization performance at various tree depths. As described below, we think that the norm regularization provides a principled way to tune the tightness of the tree's fit to the training data. Finally, the comparison between non-greedy and CO2 <ref type="bibr" target="#b17">[18]</ref> trees concentrates on the non-greediness of the algorithm, as it compares our method with its simpler variant, which is applied greedily one node at a time. We find that in most cases, the non-greedy optimization helps by improving upon the results of CO2.  Total time to execute 1000 epochs of SGD on the Connect4 dataset using loss-agumented inference and its fast varient.</p><p>A key hyper-parameter of our method is the regularization constant ν in <ref type="bibr" target="#b8">(9)</ref>, which controls the tightness of the upper bound. With a small ν, the norm constraints force the method to choose a W with a large margin at each internal node. The choice of ν is therefore closely related to the generalization of the learned trees. As shown in Fig. <ref type="figure" target="#fig_1">3</ref>, ν also implicitly controls the degree of pruning of the leaves of the tree during training. We train multiple trees for different values of ν ∈ {0.1, 1, 4, 10, 43, 100}, and we pick the value of ν that produces the tree with minimum validation error. We also tune the choice of the SGD learning rate, η, in this step. This ν and η are used to build a tree using the union of both the training and validation sets, which is evaluated on the test set.</p><p>To build non-greedy trees, we initially build an axis-aligned tree with split functions that threshold a single feature optimized using conventional procedures that maximize information gain. The axisaligned split is used to initialize a greedy variant of the tree training procedure called CO2 <ref type="bibr" target="#b17">[18]</ref>. This provides initial values for W and Θ for the non-greedy procedure. Fig. <ref type="figure" target="#fig_3">4</ref> shows an empirical comparison of training time for SGD with loss-augmented inference and fast loss-augmented inference. As expected, run-time of loss-augmented inference exhibits exponential growth with deep trees whereas its fast variant is much more scalable. We expect to see much larger speedup factors for larger datasets. Connect4 only has 55, 000 training points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We present a non-greedy method for learning decision trees, using stochastic gradient descent to optimize an upper bound on the empirical loss of the tree's predictions on the training set. Our model poses the global training of decision trees in a well-characterized optimization framework. This makes it simpler to pose extensions that could be considered in future work. Efficiency gains could be achieved by learning sparse split functions via sparsity-inducing regularization on W . Further, the core optimization problem permits applying the kernel trick to the linear split parameters W , making our overall model applicable to learning higher-order split functions or training decision trees on examples in arbitrary Reproducing Kernel Hilbert Spaces.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Test and training accuracy of a single tree as a function of tree depth for different methods. Non-greedy trees achieve better test accuracy throughout different depths. Non-greedy exhibit less vulnerability to overfitting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The effect of ν on the structure of the trees trained by MNIST. A small value of ν prunes the tree to use far fewer leaves than an axis-aligned baseline used for initialization (dotted line).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4:Total time to execute 1000 epochs of SGD on the Connect4 dataset using loss-agumented inference and its fast varient.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment. MN was financially supported in part by a Google fellowship. DF was financially supported in part by NSERC Canada and the NCAP program of the CIFAR.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Global tree optimization: A non-greedy decision tree algorithm</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing Science and Statistics</title>
		<imprint>
			<biblScope unit="page" from="156" to="156" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A support vector machine approach to decision trees</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Blue</surname></persName>
		</author>
		<idno>97-100</idno>
	</analytic>
	<monogr>
		<title level="s">Department of Mathematical Sciences Math Report</title>
		<imprint>
			<biblScope unit="page" from="2396" to="2401" />
			<date type="published" when="1997">1997</date>
			<publisher>Rensselaer Polytechnic Institute</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enlarging the margins in perceptron decision trees</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="313" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Classification and regression trees</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Olshen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Stone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Decision Forests for Computer Vision and Medical Image Analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName><surname>Jerome H Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hough forests for object detection, tracking, and action recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2188" to="2202" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The elements of statistical learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Constructing optimal binary decision trees is NP-complete</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hyafil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="17" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Loss-specific training of non-parametric image restoration models: A new state of the art</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jancsary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hierarchical mixtures of experts and the em algorithm</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="214" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neighbourhood approximation forests</title>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention-MICCAI 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="75" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mondrian forests: Efficient online random forests</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3140" to="3148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An empirical comparison of pruning methods for decision tree induction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mingers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="243" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">On growing better decision trees from data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Salzberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>John Hopkins University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Co2 forest: Improved random forest by continuous optimization of oblique splits</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.06155</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Minimal Loss Hashing for Compact Binary Codes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improved information gain estimates for decision tree induction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Induction of decision trees</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="106" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient human pose estimation from single depth images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Finocchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Max-margin Markov networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Support vector machine learning for interdependent and structured output spaces</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning structural SVMs with latent variables</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
