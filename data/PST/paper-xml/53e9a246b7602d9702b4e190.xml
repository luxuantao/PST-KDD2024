<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Biometric Animal Databases from Field Photographs: Identification of Individual Zebra in the Wild</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mayank</forename><surname>Lahiri</surname></persName>
							<email>mlahiri@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chayant</forename><surname>Tantipathananandh</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rosemary</forename><surname>Warungu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">The Ol&apos;Pejeta Conservancy Laikipia</orgName>
								<address>
									<country key="KE">Kenya</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">I</forename><surname>Rubenstein</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Dept. of Ecology and Evolutionary Biology Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tanya</forename><forename type="middle">Y</forename><surname>Berger-Wolf</surname></persName>
							<email>tanyabw@uic.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Biometric Animal Databases from Field Photographs: Identification of Individual Zebra in the Wild</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">85F204F17B5839B0489BC9D254E2956B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.2.8 [Information Systems]: Database Management Applications-Image databases; J.3 [Computer Applications]: Life and Medical Sciences-Biology Ecology</term>
					<term>biometrics</term>
					<term>image databases</term>
					<term>edit distance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe an algorithmic and experimental approach to a fundamental problem in field ecology: computer-assisted individual animal identification. We use a database of noisy photographs taken in the wild to build a biometric database of individual animals differentiated by their coat markings. A new image of an unknown animal can then be queried by its coat markings against the database to determine if the animal has been observed and identified before. Our algorithm, called StripeCodes, efficiently extracts simple image features and uses a dynamic programming algorithm to compare images. We test its accuracy against two different classes of methods: Eigenface, which is based on algebraic techniques, and matching multi-scale histograms of differential image features, an approach from signal processing. StripeCodes performs better than all competing methods for our dataset, and scales well with database size.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In wild animal populations, collecting behavioral data about a species often entails identifying individual animals between sightings taken at different places and times. This is a primitive operation in ecological analysis that underlies broader aspects of animal behavior research <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b26">26]</ref>. Electronic tracking devices embedded in animals are one approach to identifying individual animals, but can be prohibitively expensive and difficult to design for field conditions, and involve considerable cost and risk for larger animals <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b33">33]</ref>. Researchers are therefore left with no alternative other than to manually record data about individual animals in the field using methods such as manual visual identification from photographs or video <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b32">32]</ref>, genetic markers in excrement <ref type="bibr" target="#b27">[27]</ref>, or capture-recapture techniques <ref type="bibr" target="#b20">[20]</ref>. Advances in hardware and the corresponding drop in prices of digital cameras have increased the availability of digital photographs of wild animal sightings at high resolutions and qualities, making fully-automatic or computer-assisted animal identification an attractive approach.</p><p>We describe a technique for identifying individual animals from their coat markings in typically noisy field pictures (non-cooperative subjects, coat deformations, occlusion, and variations in exposure, scale, and perspective). Working with field ecologists, we collected a dataset under these conditions for automatic individual animal identification in two species of zebra in Kenya, to augment the efforts of professionally trained field assistants. The techniques we develop are applicable to animals with prominent morphological characteristics like stripes or large patches <ref type="foot" target="#foot_0">1</ref> , and are intended to be part of a cost-effective, computer-assisted individual animal identification system. Our algorithm capitalizes on the high resolution of modern field pictures (typically 8 or more megapixels with commodity hardware) to offer excellent retrieval accuracy, transparency in terms of visual feedback on image matches (i.e., the algorithm is not a black box), and extremely simple implementation.</p><p>We approach the problem by first extracting a set of discriminative mathematical (as opposed to biological) features from an image of an animal, tolerant to noise from variances in scale and exposure, occlusion, partial deformations, and mild shear. These features allow us to efficiently and robustly compare images in a database by their appearance. We then develop a distance measure between a pair of fea- ture sets taken from two images, and an efficient algorithm for computing it, that allows us to judge how different the coat markings depicted in two pictures are. A lower distance between images of two animals signifies a higher chance that the two animals are the same. This measure is used to determine whether an animal just photographed in the wild exists in a database of prior sightings. The lack of availability of an open-access dataset, or source code, for individual animal identification seems to have been an impediment to progress in this area, and is likely the reason why prior studies have been unable to test competing classes of methods <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b22">22]</ref>. We attempt to rectify this by not only releasing our dataset and code, but by performing one of the first comparative studies of three different classes of techniques (PCA, edit distance, and differential image features). We have published our dataset on two species of zebras publicly, with many annotations (GPS coordinates, date and time, camera model, focal length of image, exposure, etc.).<ref type="foot" target="#foot_1">2</ref> </p><note type="other">Animal Photos</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROBLEM DEFINITION</head><p>Let D be a database of animal coat marking images q1, ..., qN . Each image is associated with an animal identifier ai. Individual animal identification requires a ranking algorithm A that operates directly on a query image Q ∈ D to produce a ranking.</p><formula xml:id="formula_0">A : D × Q → R</formula><p>where R is a permutation (ranking) of the original set of images D based on similarity to the query image Q. The similarity should return an approximate distance between the coat markings of animals.</p><p>(Optimal ranking) For a query image qi of a known animal ai, an optimal ranking algorithm will always return qj at the highest rank where aj = ai.</p><formula xml:id="formula_1">AOP T (D × qi) → qj , ... if ai = aj</formula><p>In general, for a query image of animal ai, we want to minimize the rank of a database image with the same animal identifier. The ranking algorithm therefore needs to model the similarity (or distance) between animal coat markings, and not necessarily images, which can vary substantially for the same animal.</p><p>A line of research in population biology examines the relationship between morphological characteristics of an animal and genetic traits or physiological processes <ref type="bibr" target="#b6">[6,</ref><ref type="bibr">9]</ref>. A natural question would be to ask whether the distance function we learn above can be used as an approximation of 'morphological distance' between individual animals. It should be noted that if the algorithm is truly a distance function on the bodily markings of individual animals (assuming one exists), then it is optimal by the definition above. However, if it is optimal by the definition above, then it is not necessarily a true distance function on the bodily markings of individual animals. This can be easily proved by noting that randomly permuting the lower ranks of the output of an optimal ranking function does not affect its optimality, even when it would destroy the true ordering by morphological distance. Since we cannot hope for an optimal algorithm, we instead aim to minimize the rank of the correct animal in the ranking. However, given the impossibility of any exact methods for characterizing the phenotypic markings of animals, a suboptimal but well-performing ranking function can serve as a useful, if imperfect, biological index of morphological similarity between animals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ANIMAL RECOGNITION</head><p>A number of ecological datasets on animal behavior in the wild are currently compiled using variations of the following basic workflow.</p><p>1. Scouts or camera traps photograph animals at various locations and times. 2. A trained field assistant codes each image using ad-hoc codes to describe various physical features.</p><p>3. A database of reference image codes is searched using the textual code for the observed animal.</p><p>4. If the database contains a match for the code, the field assistant verifies that the query and reference animals match by visually comparing images, after which the observation is recorded.</p><p>5. If the database does not contain a match, then it is presumed that the animal is new, and is added to the database with its code. If there was a human error in coding the photograph, then this is a false positive for a new animal (i.e., rejecting a previously seen animal from the database).</p><p>Errors in the identification process can have serious consequences. False positives can cause over-counting of an endangered species. They can also cause missing animal association data, which as a form of sampling error can cause non-trivial biases in higher-order analysis, such as network analysis <ref type="bibr" target="#b8">[8]</ref>. False negatives (i.e., not identifying a new animal as one) also introduce errors in behavioral analysis, and can be triggered by changes in an animal's appearance due to growth, aging, pregnancy, and scars from fighting. We simplify the workflow described above by attempting to eliminate the ad-hoc manual coding process, which is time-consuming and the primary source of error. In its place, we describe a ranking algorithm for an image database that operates directly on a query image. An effective ranking algorithm will rank the correct reference animal highly, which would reduce the false positive rate. On the other hand, drastic changes in an animal's appearance can make it impossible for even humans to tell if the animal has been observed before, so we focus on minimizing the rank of the correct animal if it exists in the database, as opposed to determining whether an animal exists in the database or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Image acquisition</head><p>Our procedure starts with an image of the region of interest (ROI) of an animal, manually cropped "as consistently as possible," but subject to some variation. <ref type="foot" target="#foot_2">3</ref> Unlike the approach of Foster et al. <ref type="bibr" target="#b11">[11]</ref> and Burghardt and Campbell <ref type="bibr" target="#b5">[5]</ref>, we do not place any constraints on where the ROI should be located. We do, however, assume that the animal being identified has coat markings of a small number of distinctive colors, and relatively large and prominent morphological features (e.g., stripes in zebras and tigers, or large patches in a giraffe). Specifically, regions of each color should be accurately separable by a color segmentation algorithm (see Cheng et al. <ref type="bibr" target="#b7">[7]</ref> for a review). We also assume that image rotation is not a significant factor, or that the image has been rotation-aligned in a consistent way. Coincidentally, a recent paper on unsupervised image region segmentation used zebra images as a test dataset <ref type="bibr" target="#b18">[18]</ref>. We leave the incorporation of such methods to future research, since they introduce an additional source of error.</p><p>Assuming that the coat marking has C principal colors, the image is first filtered into k horizontal bands. Within each band, we retain a single summary row of pixels that is their average value in the column, yielding an image of 1/k th the height of the original. This is done to accommodate small vertical shifts in the cropping process (horizontal shifts are accounted for by the matching algorithm). Each row of the resultant image is thresholded so that the pixel at each column contains a principal color of the animal's coat at that point. Since we deal with zebras, median thresholding segments the image into two colors. Figure <ref type="figure" target="#fig_1">2</ref> shows the feature extraction process visually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">StripeCodes: animal coat features</head><p>Starting with a C-color thresholded image, as shown in Figure <ref type="figure" target="#fig_1">2</ref>(c), we read off k rows of C-ary values (C = 2 for zebras and giraffe) in run-length encoding <ref type="bibr" target="#b21">[21]</ref>. This yields a sequence of size n of (color, length) values, denoted:</p><formula xml:id="formula_2">X = (c1, l1), ..., (cn, ln) , ci ∈ {1...C}, li &gt; 0</formula><p>To impose scale invariance, we perform the following transformation on X:</p><formula xml:id="formula_3">li = li li-1 , i &gt; 1</formula><p>We express each li as a ratio of its length to that of the previous color block, and drop the first color block from the sequence. We call X a StripeString. As a sequence of ratios of lengths, by definition, it is preserved under affine transformations such as shear, or in practice, tolerant to small changes in perspective. Furthermore, it is also tolerant to occlusion; for example, if the left part of the image is clipped, the remainder of the resultant sequence will still match the suffix of the original sequence, with at most the first two ratios being altered. An image of an animal is therefore represented by an ordered set (e.g., top of animal to bottom) of StripeStrings, which we call a StripeCode. The space complexity of this representation for an image is proportional to k multiplied by the average number of color blocks in a row. Simply put, in zebras, it is proportional to the number of stripes in the region of interest. <ref type="foot" target="#foot_3">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Distance function</head><p>Assuming that exactly the same portion of the animal's body was consistently cropped as the region of interest across photographs, and that the animal was photographed at the exact position in its walking gait as a stored picture, we could directly compare two sets of StripeStrings to determine how similar they are. Since these are unreasonable assumptions, we develop an approximate distance function on two StripeStrings using a variation of the edit distance algorithm for two strings. This allows us to partially match two StripeStrings while taking into account factors such as translation (caused by inconsistent cropping of the ROI) and localized deformations (caused by physical deformations of the animal's coat during movement). In principle, our approach is inspired by Blum's original shape representation scheme <ref type="bibr" target="#b3">[3]</ref>, but the specific underlying methods we use to implement it are different. The distance between two StripeCodes is defined as the average of the distance between corresponding StripeStrings. <ref type="foot" target="#foot_4">5</ref>We use the notation of Marzal and Vidal <ref type="bibr" target="#b17">[17]</ref>. Given two StripeStrings X = x1, ..., xM and Y = y1, ..., yN , where xi = (ci, li) and yj = (c j , l j ) are color blocks, we seek a transformation of X to Y that minimizes a cost function. The transformation is defined as a sequence S of edit operations, where each edit operation Si = (a, b) operates on a pair of color blocks or the null string λ.</p><formula xml:id="formula_4">S = S1 = (a1, b1), ..., SP (1) ai ∈ {X ∪ λ}, bj ∈ {Y ∪ λ}, Si = (λ, λ)</formula><p>The cost of a single edit operation Si = (a, b) is defined as γ(a → b), subject to the conditions above. The cost function above can be trivially extended to the entire edit sequence of length P , defined in Equation <ref type="formula">1</ref>. This yields the total cost of aligning two StripeStrings using a given edit sequence as the sum of costs of each element in the edit sequence S. The edit distance between two StripeStrings is then the minimum cost achievable over all possible editing paths.</p><formula xml:id="formula_5">γ(a → b) = ⎧ ⎪ ⎨ ⎪ ⎩ D if a = λ or b = λ ∞ if ca = c b 1 -min(la,l b ) max(la,l b ) if ca = c b</formula><formula xml:id="formula_6">d(X, Y ) = min S= S 1 ,...,S P P i=1 γ(Si)<label>( 3 )</label></formula><p>Marzal and Vidal <ref type="bibr" target="#b17">[17]</ref> have noted that an edit distance computed using Equation 3 is not always appropriate for matching strings of different lengths because the final edit cost does not take the lengths of the strings into account; longer strings will generally have a higher cost associated with their matching. The authors propose the use of a normalized edit distance measure dN , where the edit cost of two strings is divided by the length of the edit path (which ranges between  However, minimizing the distance in Equation <ref type="formula">4</ref>is not necessarily the same as minimizing the un-normalized cost in Equation 3 and then dividing by the length of the resultant editing path, a procedure known as post-normalization <ref type="bibr" target="#b17">[17]</ref>.</p><p>Instead, we used an iterative, unbiased fractional programming algorithm described by Vidal et al. <ref type="bibr" target="#b29">[29]</ref> to directly compute the normalized edit distance. In our experiments, however, we found that editing paths and costs rarely varied significantly between post-normalization and the unbiased algorithm. Since the unbiased algorithm generally has a larger constant factor, we use post-normalization as an approximation in practice.</p><p>A fractional programming algorithm to compute Equation 4 uses an inner loop that computes Equation 3 along the way using the standard dynamic programming method for edit distance <ref type="bibr" target="#b31">[31]</ref>. We create a dynamic programming matrix Z (M +1)×(N+1) , which is filled in as follows.</p><formula xml:id="formula_7">Z[1, n] = (n -1)D, ∀n Z[m, 1] = (m -1)D, ∀m Z[m, n] = min ⎧ ⎪ ⎨ ⎪ ⎩ Z[m -1, n] + γ(λ, (c n , l n )), Z[m, n -1] +γ((cm, lm), λ), Z[m -1, n -1] +γ((cm, lm), (c n , l n ))<label>(5)</label></formula><p>The matrix is filled row by row and the cost of the optimal alignment is contained in cell</p><formula xml:id="formula_8">Z[M + 1, N + 1]</formula><p>. By storing which case of Equation 5 was selected at each cell, backtracking from cell Z[M, N] returns the optimal edit path.</p><p>The cost function γ from Definition 2 defines a substitution matrix for an edit distance computation. More formally, for any given pair of StripeStrings, the combination of γ and D define the StripeCode substitution matrix if the (otherwise numeric) li values are treated as symbols.</p><p>Figure <ref type="figure" target="#fig_4">3</ref> shows the edit path taken to align two StripeStrings in our dataset, with D = 0.6. Horizontal and vertical bars in the edit path represent insertions and deletions that incur cost D, and diagonal bars represent matches. Notice that different colors are never matched because of the high penalty associated with such an action.</p><p>Finally, the complexity of the distance algorithm has some unique features in the animal identification domain. If M The fractional programming formulation for computing the normalized edit distance is an iterative procedure that runs the unnormalized edit distance algorithm for (usually) a very small number of iterations. However, M and N are both bounded by the number of distinctive color patches (stripes, in our case) in the ROI, and can be effectively considered constant for a given animal species. The efficiency of the algorithm is therefore heavily reliant on a particular implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RELATED WORK</head><p>The need for individual animal identification in ecology and field biology has been long recognized, as has the tedious and error-prone nature of the task when performed manually <ref type="bibr" target="#b14">[14]</ref>. There are three broad categories of methods: those designed for humans to follow manually <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b32">32]</ref>, semi-automatic methods developed with a specific species in mind <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b15">15]</ref>, and semi-automatic methods that can be applied to a class of species that share similar morphological characteristics <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b22">22]</ref>. Our approach falls in the last category.</p><p>Intuition would suggest that obvious candidates for animal recognition algorithms are human biometric identification techniques like fingerprint and face recognition algorithms. A major difference from human biometric identification is that wild animals are almost never cooperative, resulting in large pose and occlusion variances in the images  of even a single animal. Furthermore, the coat patterns of an animal can be altered drastically by attacks from other animals, disease, or pregnancy. For zebras, Foster et al. <ref type="bibr" target="#b11">[11]</ref> describe why fingerprint recognition algorithms are inappropriate. Human face recognition algorithms, however, are more generic, and we test one such method here. was developed by Turk and Pentland <ref type="bibr" target="#b28">[28]</ref>, and uses principal component analysis and covariance between image matrices to recognize faces. Ravela and Gamble <ref type="bibr" target="#b22">[22]</ref> use multi-scale histograms of differential image features to identify individual salamanders. In an initial preprocessing stage, the image is treated as a three-dimensional intensity map and filtered with invariant combinations of specific Gaussian derivative operators <ref type="bibr" target="#b23">[23]</ref>, at multiple scales. The resultant image features are then binned into a histogram. Comparing two images in a database scan is reduced to computing an inner product between two such histogram vectors, which is a very efficient process. However, the use of multi-scale histograms is essentially a black box, with little meaningful feedback available to the user. This could be a disadvantage when developing a computer-assisted identification system, since the user does not get any feedback beyond a similarity score.</p><p>Other more sophisticated approaches include that of Burghardt and Campbell <ref type="bibr" target="#b5">[5]</ref>, who use successive video frames to map a two-dimensional image onto a three-dimensional model of the animal's body. Our algorithm is much simpler, and does not require either video or a three-dimensional model of the animal's body. Foster et al. <ref type="bibr" target="#b11">[11]</ref> present partial details of a zebra identification system, but require the user to manually select six pre-defined points on each image, corresponding to specific parts of the zebra's body. In comparison, our method simply requires the user to draw a box around any (presumably distinctive) part of the animal's body, and is not specifically tailored to specific features of zebra stripes. Other approaches exploit features of specific species of animals. Curve-extraction and matching, for example, has been used to identify individual dolphins <ref type="bibr" target="#b12">[12]</ref> and elephants <ref type="bibr" target="#b1">[1]</ref>.</p><p>In principle, a multitude of approaches in pattern recognition could be applied to the individual animal recognition problem. Shape matching is an obvious candidate for animals with large, prominent coat markings <ref type="bibr" target="#b19">[19]</ref>. While these might ultimately be the best performing approaches, we demonstrate in this paper that a simple approach based on dynamic programming is both transparent (i.e., yields visual feedback for a human operator), and performs on par with the multi-scale histograms described by Ravela and Gamble <ref type="bibr" target="#b22">[22]</ref>. Other sophisticated object recognition approaches include shape contexts <ref type="bibr" target="#b2">[2]</ref> and shock graphs <ref type="bibr" target="#b25">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DATASET</head><p>We collected our dataset over a period of seven days at the Ol'Pejeta Conservancy in Laikipia, Kenya, using typical field procedures in ecological data collection. The broader research goal was to collect accurate individual identifications, and therefore accurate association data, for network analysis of two different zebra populations in the area <ref type="bibr" target="#b26">[26]</ref>. We used cheap, off-the-shelf digital SLR cameras and 300mm zoom lenses. Each day, we made a semi-random circuit through the 90,000 acre nature conservancy, which contains several hundred wild Plains zebras, and fewer than 20 endangered Grevy's zebras (some of which are included in our dataset). Two people were stationed on top of the vehicle to take pictures while the driver circled around individual groups of zebras, so as to capture both flanks of the animal.</p><p>We collected as many pictures as possible of each flank of an animal in different positions in its natural walking gait. As a result, a number of pictures are quite similar. A professionally trained field assistant identified the images based on a database of prior sightings stretching back almost ten years. All but a few zebras were reliably identified. The manual identification method involves assigning each zebra an ad-hoc code based on the pattern of stripes along its shoulder. These (textual) codes are then fed into a stock photo organizing program that searches metadata for a similar code string. The final match is made by direct visual observation by a professional. <ref type="foot" target="#foot_5">6</ref> We determined after manual identification that several animals were observed on multiple days, which makes our dataset more representative of intended usage.</p><p>Figure <ref type="figure" target="#fig_6">4</ref> shows typical pictures, and manually cropped ROIs, from our dataset. In particular, they illustrate the difficulty of automatic animal segmentation and the problems associated with perspective skews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL RESULTS</head><p>We measured the accuracy of three animal recognition algorithms: Eigenface <ref type="bibr" target="#b28">[28]</ref>, the CO-1 algorithm based on multi-resolution histograms of differential image features <ref type="bibr" target="#b22">[22]</ref>, and the method we propose in this paper: StripeCodes. As the number of unique animals in the database grows, the accuracy of any algorithm is likely to suffer. We therefore chose the number of unique animals in the database as the primary independent variable for our analysis. Furthermore, analysis is restricted to animals that are already contained in the database, since it is difficult to define accuracy (and  efficacy in general) when an animal has never been observed before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Testing Methodology</head><p>Assume that the dataset consists of a total of I images of A different animals (I &gt; A). In our dataset, almost all animals have images of both their flanks, but we treat each flank as a different animal. This is because zebra stripe formation is a chaotic process which is not fully understood <ref type="bibr" target="#b13">[13]</ref>, so there is no basis for assuming symmetry. Our evaluation methodology has two independent parameters: ipa, which specifies the images per animal contained in the database, and N , the number of unique animals in the database. Keeping a fixed number of the most recent images of each animal in a production database is desirable not only for efficiency in database scans, but also as a form of temporal smoothing to account for natural changes in the animal's appearance.</p><p>For fixed values of ipa and N , the following procedure samples uniformly from all possible database and query pairs, and returns the primary evaluation measure: the rank of the correct animal.</p><p>1. Choose N ≤ A animals at random.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>For each animal a, choose ipa images randomly and add to the database.</p><p>3. From all the remaining images of the N animals, choose an image randomly as the query image.</p><p>4. Rank each animal in the database by the minimum distance of a database image to the query image. Return the rank of the correct animal.</p><p>We use three statistics over many random iterations of the loop above to evaluate algorithm performance at each value of N and ipa: the mean reciprocal rank (MRR), popular in text information retrieval <ref type="bibr" target="#b30">[30]</ref>, the median rank of the correct animal, and the average query time of our implementation. Note that this puts the Eigenface method at somewhat of a disadvantage, since we used a Matlab implementation of it, instead of the native C++ implementations of other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>We set N to be successive fifths of the dataset size, and report results at an ipa value of 1. We used 5,000 random iterations for each pair of ipa and N values, for all algorithms.</p><p>The baseline used was a random (uniform) permutation of the ranks of the animals in the database. For the CO -1 algorithm, we used histograms at 4 different scales, proceeding in half-octaves as in the original study <ref type="bibr" target="#b22">[22]</ref>, and 10 bins for each feature. All runs were performed on an AMD Athlon x2 processor with 2 GB of RAM running Ubuntu Linux.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Accuracy</head><p>Figure <ref type="figure" target="#fig_8">5</ref> shows the performance of all algorithms for ipa = 1. Note that a lower median correct rank indicates better performance, but a higher MRR is considered better. An optimal algorithm would always return the correct animal at rank 1, so its MRR would be 1, with sub-optimal algorithms having an MRR strictly less than 1. The MRR places a greater emphasis on searches where the correct animal is closer to the top of the result list. This is in contrast to, for example, the mean rank of the correct animal, which is significantly affected by outlier queries (i.e., where the correct animal is closer to the bottom of the result list). The median correct rank is more indicative of performance that might be perceived by a human.</p><p>The StripeCode algorithm, while being the simplest to implement, also outperforms all the other methods. Its median correct rank stays consistently low as the database grows. Even with 85 animals in the database, its median correct rank is less than 5. The MRR curve as the database grows is also consistently higher than the closest competitor. The poor performance of Eigenface is not surprising, given that it was originally developed for spatially aligned, exposurecontrolled images of human faces.</p><p>The actual query time of our implementation is, however, higher than competing methods because of the relatively expensive edit distance computation. Although it grows linearly, the growth is much faster than the CO-1 algorithm. This is not surprising, because a distance computation between two images in the CO-1 algorithm is reduced to (after preprocessing) computing an inner product between two relatively small numerical vectors, a highly efficient procedure on modern processors. StripeCodes are inherently slower, since they share the same foundation as sequence alignment algorithms used in bioinformatics. A number of modern technologies such as GPU computing have resulted in impressive performance gains for edit distance-like computations <ref type="bibr" target="#b16">[16]</ref>. Our implementation, in contrast, is quite plain and could be greatly improved by implementing these modern computational techniques. Furthermore, the database search itself is trivially parallelizable. We also note that the one-time feature extraction from an image is not included in Figure <ref type="figure" target="#fig_8">5</ref>. The average time to extract a StripeCode from an image was less than a second, whereas the CO-1 algorithm took an average of 8.1 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Transparency</head><p>Unlike the two other algorithms we tested, StripeCodes can supply human-interpretable visual feedback on why two images match. In a computer-assisted system, which comprises the majority of individual animal identification use cases, this is essential in helping a human operator make the final decision about a match. To visualize a match between two images, we can plot the edit paths of each pair of StripeStrings as a heat map. This is illustrated in Figure <ref type="figure">6</ref>, where a reference image is displayed side-by-side with another image of the same animal. Each color block in the reference image retains its original color if it was omitted as part of the optimal dynamic programming path. If it was not deleted, the block is colored red according to the cost incurred for the optimal path. We used k-means clustering on costs to segment them into four discrete shades of red, with brighter colors representing better matches.</p><p>To the best of our knowledge, ours is the only method where such visual feedback is available to the user. It can also be used to demonstrate the effect of the D cost on the optimal editing path, as we do in Figure <ref type="figure">6</ref>. For a low value of D = 0.1, insertions and deletions are favored over matching color blocks of different lengths. At a higher D value, insertions and deletions become more expensive, and blocks are matched even if they incur a relatively higher cost. We found values in the range 0.4 ≤ D ≤ 0.6 to be effective for our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Follow-up test</head><p>In order to account for natural aging and appearance changes in animals, we ran a follow-up test in the same area 13 months after the original dataset was collected. We tested the StripeCodes algorithm against the CO-1 algorithm on 83 new Grevy's zebra photos taken over a 3 day period while driving fixed routes. Note that the Grevy's zebra, shown in Figure <ref type="figure" target="#fig_6">4</ref>(d), has a higher stripe density than the more common Plains zebra and is therefore more susceptible to noise. Testing with an ROI located on the flank of the zebra, and using a paired t-test, we found that StripeCodes outperformed CO-1 with t = 3.85 and df = 82 for p &lt; 0.0002. The means on an ordinary t-test were 9.2 ± 1.3 (StripeCodes) and 15.3 ± 1.7 (CO-1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>We have developed a similarity algorithm for comparing animal coat markings across noisy images, designed to be a part of a computer-assisted system for individual animal identification. Our StripeCode algorithm is based on a novel feature extraction and matching method that capitalizes on the high resolution of modern digital cameras, and offers a number of benefits over other approaches:</p><p>• It offers state of the art retrieval performance, while being extremely simple to implement, and is tolerant of scale, exposure, occlusion, and mild perspective skews. Since it can be seen as a variant of sequence alignment algorithms used in bioinformatics, implementations of it can directly benefit from numerous algorithmic and hardware optimizations developed for algorithms like the Smith-Waterman algorithm <ref type="bibr" target="#b16">[16]</ref>.</p><p>• It is applicable to any animal with prominent coat markings consisting of relatively large morphological features and a small number of distinctive colors. Some examples are zebras, tigers, giraffe, and kudu.</p><p>• It offers visual feedback to a human user, essential as part of a computer-assisted system, on why two images of animal coat markings are similar.</p><p>We look forward to augmenting our open-access datasets in the future with libraries of other species, such as giraffe, as well as repeat sightings of the animals currently included. By releasing our code and data publicly, we hope to offer a common framework for the comparison of future algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Structure of the image database: contents, query, and output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 2 )</head><label>2</label><figDesc>D is a constant insertion/deletion cost, and (ca, la) and (c b , l b ) are the color blocks corresponding to a and b if neither is the empty string. Note that 0 &lt; γ(a → b) ≤ 1 if a, b = λ and ca = c b . Also note that the function is symmetric, i.e., γ(a → b) = γ(b → a), and that γ(a → a) = 0 if a, b = λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Median threshold by row (d) Difference between (a) and (c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Feature extraction process. Typical image processing errors can be seen in the top right and leftmost portions of the difference image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example of aligning two StripeStrings using dynamic programming.</figDesc><graphic coords="4,317.26,227.86,237.89,113.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Typical images from our dataset, with the cropped ROI (inset). All four images are of different animals. Image 4(d) is E. grevyi, an endangered species of zebra with higher stripe density.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Mean query time, ipa = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance of various algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>5 Figure 6 :</head><label>56</label><figDesc>Figure 6: Comparing stripes from two images of the same zebra. Red blocks in the left image are matched to blocks in the right image, with a brighter color indicating a lower cost. Black and white blocks in the left image represent insertions and deletions.</figDesc><graphic coords="7,83.26,128.50,180.29,56.69" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Although we only present results for zebra, preliminary field tests suggest that the method can successfully be applied to giraffe.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>All code and data, as well as a GUI frontend, may be downloaded from http://code.google.com/p/stripespotter/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>In our study, instructions given to the user performing the cropping, i.e., a field assistant, were to crop the image to a consistent area of the zebra's anatomy across pictures.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Note that stripe density varies dramatically between two species of zebra: Plains and Grevy's.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Using the average was found to be preferable over other summarization functions, like the minimum.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>This is only tractable manually because a trained professional can distinguish a mismatch very quickly.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>http://compbio.cs.uic.edu/∼tanya/teaching/KenyaCourse.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGEMENTS</head><p>This work is part of a project performed in the joint Princeton-UIC Computational Population Biology Course in Spring 2010 <ref type="bibr" target="#b7">7</ref> , with co-instructors Tanya Berger-Wolf (University of Illinois at Chicago), Daniel Rubenstein and Iain Couzin (Princeton University), who were instrumental in several parts of this research. We thank the Kenya Ministry of Education, Science and Technology (research permit MOST 13/001/29C 80Vol.11 to D.I. Rubenstein), the staff at Mpala Resarch Centre, Kenya and fellow graduate students at EEB-Princeton University and CS at University of Illinois at Chicago. Funding was provided by Department of Ecology and Evolutionary Biology of Princeton University, generous contributions by Bill Unger (for the UIC students in the course), UIC College of Engineering, Department of Computer Science at UIC, UIC Graduate Research and Provost's Awards (Lahiri), NSF III-CXT 0705311 (Rubenstein) and IIS-CTX-0705822 and NSF IIS-CAREER-0747369 (Berger-Wolf). We thank Anthony Roy for assistance with processing our dataset. The follow-up analysis was run by Victoria Zero and the students of Princeton's 'Natural History of Mammals' class.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A semi-automatic approach to photo identification of wild elephants</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ardovini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cinque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Della</forename><surname>Rocca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sangineto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition and Image Analysis</title>
		<imprint>
			<biblScope unit="page" from="225" to="232" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="509" to="522" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shape description using weighted symmetric axis features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="180" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Photographic identification of individual Archey&apos;s frogs, Leiopelma archeyi, from natural markings</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bradfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Doc. Science Internal Series</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<date type="published" when="2004">2004</date>
			<publisher>Dept. of Conservation</publisher>
			<pubPlace>New Zealand</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Individual animal identification using visual biometrics on deformable coat patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Burghardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Computer Vision Systems</title>
		<meeting>the 5th International Conference on Computer Vision Systems<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Use of quantitative analyses of pelage characteristics to reveal family resemblances in genetically monomorphic cheetahs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Durant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Heredity</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Color image segmentation: advances and prospects</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2259" to="2281" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The stability of centrality measures when networks are sampled</title>
		<author>
			<persName><forename type="first">E</forename><surname>Costenbader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Valente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="283" to="307" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Morphological and pelage characteristics of wild living cats in scotland: implications for defining the &apos;wildcat</title>
		<author>
			<persName><forename type="first">M</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Balharry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kitchener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aspinall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Zoology</title>
		<imprint>
			<biblScope unit="volume">244</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="247" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">In my experience: Implantable microchips for individual identification in wild and captive populations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Elbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Wildlife Society Bulletin</publisher>
			<biblScope unit="page" from="677" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Zebra fingerprints: towards a computer-aided identification system for individual zebra</title>
		<author>
			<persName><forename type="first">G</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Krijger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bangay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">African Journal of Ecology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="227" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An affine invariant curve matching method for photo-identification of marine mammals</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kehtarnavaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wursig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="132" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A unity underlying the different zebra striping patterns</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jonathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Zoology</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="539" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Computer-aided photograph matching in studies using individual identification: an example from Serengeti cheetahs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mammalogy</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="440" to="449" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Assisting manual dolphin identification by computer extraction of dorsal ratio</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kreho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kehtarnavaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Araabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wursig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="830" to="838" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">CUDA compatible GPU cards as efficient hardware accelerators for Smith-Waterman sequence alignment</title>
		<author>
			<persName><forename type="first">S</forename><surname>Manavski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Valle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">Suppl 2</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computation of normalized edit distance and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="926" to="932" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Combined morphological-spectral unsupervised image segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>O'callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Matching and retrieval of distorted and occluded shapes using dynamic programming</title>
		<author>
			<persName><forename type="first">E</forename><surname>Petrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diplaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Milios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1501" to="1516" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Statistical inference for capture-recapture experiments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pollock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brownie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wildlife Monographs</title>
		<imprint>
			<biblScope unit="page" from="3" to="97" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Run-length encoding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pountain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Byte</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="317" to="319" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On recognizing individual salamanders</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ravela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gamble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Asian Conference on Computer Vision, Ki-Sang Hong and Zhengyou Zhang</title>
		<meeting>Asian Conference on Computer Vision, Ki-Sang Hong and Zhengyou Zhang<address><addrLine>Jeju, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="742" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gaussian derivatives</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Romeny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Front-End Vision and Multi-Scale Image Analysis</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</editor>
		<meeting><address><addrLine>Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="53" to="69" />
		</imprint>
	</monogr>
	<note>Gaussian derivatives</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Necks and networks: a preliminary study of population structure in the reticulated giraffe (giraffa camelopardalis reticulata)</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shorrocks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">African Journal of Ecology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="374" to="381" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Shock graphs and shape matching</title>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shokoufandeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="32" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Network metrics reveal differences in social organization between two fission-fusion species, Grevy&apos;s zebra and onager</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sundaresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fischhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dushoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oecologia</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="140" to="149" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Non-invasive genetic sampling and individual identification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Taberlet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Luikart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Journal of the Linnean Society</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="41" to="55" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Face recognition using Eigenfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR &apos;91</title>
		<meeting>CVPR &apos;91</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast computation of normalized edit distances</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Aibar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pat. Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="899" to="902" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The TREC question answering track</title>
		<author>
			<persName><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="361" to="378" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The string-to-string correction problem</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="168" to="173" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Methods of photo-identification for small cetaceans</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wursig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jefferson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reports of the International Whaling Commission</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="43" to="52" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Hardware design experiences in ZebraNet</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Intl. Conf. on Embedded networked sensor systems</title>
		<meeting>2nd Intl. Conf. on Embedded networked sensor systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="227" to="238" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
