<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ESTIMATING HETEROGENEOUS GRAPHICAL MODELS FOR DISCRETE DATA WITH AN APPLICATION TO ROLL CALL VOTING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-09-16">16 Sep 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jian</forename><surname>Guo</surname></persName>
							<email>jguo@hsph.harvard.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Cheng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Elizaveta</forename><surname>Levina</surname></persName>
							<email>elevina@umich.edu</email>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Michailidis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ji</forename><surname>Zhu</surname></persName>
							<email>jizhu@umich.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Harvard University</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Mathematical Statistics</orgName>
								<orgName type="institution">The Annals of Applied Statistics</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Biostatistics</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<addrLine>655 Huntington Avenue Boston</addrLine>
									<postCode>02115</postCode>
									<region>Massachusetts</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">South University Ann Arbor</orgName>
								<address>
									<postCode>1085, 48109-1107</postCode>
									<region>Michigan</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ESTIMATING HETEROGENEOUS GRAPHICAL MODELS FOR DISCRETE DATA WITH AN APPLICATION TO ROLL CALL VOTING</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-09-16">16 Sep 2015</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1214/13-AOAS700</idno>
					<idno type="arXiv">arXiv:1509.04828v1[stat.AP]</idno>
					<note type="submission">Received May 2013; revised October 2013.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graphical models</term>
					<term>group penalty</term>
					<term>high-dimensional data</term>
					<term>ℓ1 penalty</term>
					<term>Markov network</term>
					<term>binary data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the problem of jointly estimating a collection of graphical models for discrete data, corresponding to several categories that share some common structure. An example for such a setting is voting records of legislators on different issues, such as defense, energy, and healthcare. We develop a Markov graphical model to characterize the heterogeneous dependence structures arising from such data. The model is fitted via a joint estimation method that preserves the underlying common graph structure, but also allows for differences between the networks. The method employs a group penalty that targets the common zero interaction effects across all the networks. We apply the method to describe the internal networks of the U.S. Senate on several important issues. Our analysis reveals individual structure for each issue, distinct from the underlying wellknown bipartisan structure common to all categories which we are able to extract separately. We also establish consistency of the proposed method both for parameter estimation and model selection, and evaluate its numerical performance on a number of simulated examples.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction.</head><p>The analysis of roll call data of legislative bodies has attracted a lot of attention both in the political science and statistical literature. For political scientists, such data allow to study broad issues such as party cohesion as well as more specific ones such as coalition formation; see, for example, the books by <ref type="bibr" target="#b9">Enelow and Hinich (1984)</ref>, <ref type="bibr">Matthews and Stimson</ref> Dimension reduction techniques such as PCA and MDS aim at constructing a "map," with the members of the legislative body positioned relative to their peers according to their voting pattern. A typical example of such a map of the U.S. Senate members in the 109th Congress <ref type="bibr">(2005)</ref><ref type="bibr">(2006)</ref> using multidimensional scaling for selected votes is shown in Figure <ref type="figure">1</ref>; for a detailed description of the data see Section 4. A clear separation between members of the two parties is seen (Republicans to the left of the map and Democrats to the right), together with some members exhibiting a voting pattern deviating from their party, for example, Nelson (Democrat of Nebraska), and Collins and Snow (Republicans of Maine), while the independent Jeffords (shown in purple) votes like a Democrat. More interestingly, the voting patterns within both parties form distinct subclusters. While the nature of this division is impossible to infer from an MDS or a PCA representation such as the one shown in Figure <ref type="figure">1</ref>, our subsequent analysis will show that this difference is driven by votes on defense/security and healthcare issues.</p><p>This finding suggests that treating all votes as homogeneous, that is, assuming that they represent the same underlying relationship between senators, may mask more subtle patterns which depend on the issues being voted upon. Therefore, treating votes as heterogeneous is more accurate and can provide further insight into the voting behavior of different groups of senators on different issues. In this paper, we focus on voting records on three types of bills: defense and national security, environment and energy, and healthcare issues. Voting on the latter category is typically more partisan than voting on defense and national security and, thus, we expect to see different connections in different categories.</p><p>The voting records of the U.S. Senate from the 109th Congress covering the period 2005-2006 were obtained directly from the Senate's website (www.senate.gov). We chose the 109th Congress because its voting patterns have been previously analyzed in the literature [see, e.g., <ref type="bibr" target="#b2">Banerjee, El Ghaoui and d'Aspremont (2008)</ref>], but as we have discovered, the version of the data previously analyzed was contaminated with voting records from the 1990s (when the set of senators would have been different). Thus, we collected the data ourselves, on all the 645 votes that the Senate deliberated and voted on during that period, which include bills, resolutions, motions, debates and roll call votes. To study the potential heterogeneity in the voting patterns, we focused on the three largest meaningful (i.e., excluding purely procedural votes) categories of votes extracted from bills, resolutions and motions: (1) defense and security issues; (2) environment and energy issues; (3) health and medical care issues. The categories were extracted by a combination of text analysis of bill names and manual labeling. A complete analysis of this data set will be presented in Section 4.</p><p>Our goal in this paper is to develop a statistical model for studying dependence patterns in such situations: there is some overall structure present J. GUO ET AL.</p><p>(party affiliation, which affects everything) and there are also distinct categories with their own individual structures. Since we are dealing with voting data, we use Markov network models to capture the dependence structure of binary or categorical random variables. Similar to Gaussian graphical models, nodes in a Markov network correspond to (categorical) variables, while edges represent dependence between nodes conditional on all other variables. Graphical models are an exploratory data analysis tool used in a number of application areas to explore the dependence structure between variables, including bioinformatics <ref type="bibr" target="#b0">[Airoldi (2007)</ref>], natural language processing <ref type="bibr" target="#b18">[Jung et al. (1996)</ref>] and image analysis <ref type="bibr" target="#b20">[Li (2001)</ref>]. In the case of Gaussian graphical models, which assumes the variables are jointly normally distributed, the structure of the underlying graph can be fully determined from the corresponding inverse covariance (precision) matrix, the off-diagonal elements of which are proportional to partial correlations between the variables. A number of methods have been recently proposed in the literature to fit sparse Gaussian graphical models [see, e.g., <ref type="bibr" target="#b23">Meinshausen and Bühlmann (2006)</ref>, <ref type="bibr" target="#b35">Yuan and Lin (2007)</ref>, <ref type="bibr" target="#b2">Banerjee, El Ghaoui and d'Aspremont (2008)</ref>, <ref type="bibr" target="#b31">Rothman et al. (2008)</ref>, <ref type="bibr">Ravikumar et al. (2011), Peng, Zhou and</ref><ref type="bibr">Zhu (2009)</ref> and references therein]. Sparse Markov networks for binary data (Ising models) have been studied by <ref type="bibr" target="#b16">Höfling and Tibshirani (2009)</ref>, <ref type="bibr" target="#b11">Guo et al. (2009)</ref>, <ref type="bibr" target="#b29">Ravikumar, Wainwright and Lafferty (2010)</ref>, <ref type="bibr" target="#b1">Anandkumar et al. (2012)</ref>, <ref type="bibr" target="#b33">Xue, Zou and Cai (2012)</ref>. These methods do not allow for different categories within the data.</p><p>To allow for heterogeneity, we develop a framework for fitting different Markov models for each category that are nevertheless linked, sharing nodes and some common edges across all categories, while other edges are uniquely associated with a particular category. This will allow us to borrow strength across categories instead of fitting them completely separately. For the Gaussian case, this type of joint graphical model was first studied by <ref type="bibr" target="#b13">Guo et al. (2011)</ref>, who proposed a joint likelihood based estimation method that borrowed strength across categories. Several other papers have proposed alternative algorithms for the Gaussian case <ref type="bibr" target="#b6">[Danaher, Wang and Witten (2011)</ref>, <ref type="bibr" target="#b34">Yang et al. (2012)</ref>, <ref type="bibr" target="#b15">Hara and Washio (2013)</ref>]. We note that a context-specific graphical model was proposed for count data in the form of contingency tables by <ref type="bibr" target="#b17">Højsgaard (2004)</ref>, but contingency tables are not suitable for highdimensional data and the context-specific model is not sparse.</p><p>The advantage of using a Markov graphical model in this context is that it quantifies the degree of conditional dependence between the senators based on their voting record, and hence the obtained network, and is directly interpretable. Techniques like multidimensional scaling and principal components analysis represent relative similarities between senators' voting records on the map and, hence, the distance between any two senators can be interpreted as a quantitative measure of similarity between their voting records.</p><p>However, unlike in a Markov network, these distances are not interpretable in the context of a generative probability model.</p><p>The remainder of the paper is organized as follows. Section 2 introduces the Markov network and addresses algorithmic issues, and Section 3 briefly illustrates the performance of the joint estimation method on simulated data. A detailed analysis of the U.S. Senate's voting record from the 109th Congress is presented in Section 4. Some concluding remarks are drawn in Section 5, and the Appendix presents results on the asymptotic properties of the method. The electronic supplementary material contains a detailed investigation of missing data imputation methods for the Senate vote data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Model and estimation algorithm.</head><p>In this section we present the Markov model for heterogeneous data, focusing on the special case of binary variables (also known as the Ising model). The extension to general categorical variables is briefly discussed in Section 5. We start by discussing estimation of separate models for each category and then develop a method for joint estimation.</p><p>The main technical challenge when estimating the likelihood of Markov graphical models is its computational intractability due to the normalizing constant. To overcome this difficulty, different methods employing computationally tractable approximations to the likelihood have been proposed in the literature; these include methods based on surrogate likelihood <ref type="bibr" target="#b2">[Banerjee, El Ghaoui and d'Aspremont (2008)</ref>, <ref type="bibr" target="#b18">Kolar and Xing (2008)</ref>] and pseudolikelihood <ref type="bibr" target="#b16">[Höfling and Tibshirani (2009)</ref>, <ref type="bibr" target="#b29">Ravikumar, Wainwright and Lafferty (2010)</ref>, <ref type="bibr" target="#b12">Guo et al. (2010)</ref>]. <ref type="bibr" target="#b16">Höfling and Tibshirani (2009)</ref> also proposed an iterative algorithm that successively approximates the original likelihood through a series of pseudo-likelihoods, while Ravikumar, <ref type="bibr" target="#b29">Wainwright and Lafferty (2010)</ref> and <ref type="bibr" target="#b12">Guo et al. (2010)</ref> established asymptotic consistency of their respective methods.</p><p>2.1. Problem setup and separate estimation. We start from setting up notation and reviewing previous work on estimating a single Ising model, which can be used to estimate the graph for each category separately. Suppose that data have been collected on p binary variables in K categories, with n k observations in the kth category, k = 1, . . . , K. Let x</p><formula xml:id="formula_0">(k) i = (x (k) i,1 , . . . , x<label>(k)</label></formula><p>i,p ) denote a p-dimensional row vector containing the data for the ith observation in the kth category and assume that it is drawn independently from an exponential family with the probability mass function</p><formula xml:id="formula_1">f k (X 1 , . . . , X p ) = 1 Z(Θ (k) ) exp p j=1 θ (k) j,j X j + 1≤j&lt;j ′ ≤p θ (k) j,j ′ X j X j ′ . (2.1) J. GUO ET AL.</formula><p>The partition function Z(Θ (k) ) = X j ∈{0,1},j exp(θ</p><formula xml:id="formula_2">(k) j,j X j + j&lt;j ′ θ (k) j,j ′ X j X j ′ )</formula><p>ensures that the probabilities in (2.1) add up to one. The parameters θ (k) j,j , 1 ≤ j ≤ p correspond to the main effect for variable X j in the kth category, and θ (k) j,j ′ is the interaction effect between variables X j and X j ′ , 1 ≤ j &lt; j ′ ≤ p. The underlying network associated with the kth category is determined by the symmetric matrix</p><formula xml:id="formula_3">Θ (k) = (θ (k) j,j ′ ) p×p . Specifically, if θ (k)</formula><p>j,j ′ = 0, then X j and X j ′ are conditionally independent in the kth category given all the remaining variables and, hence, their corresponding nodes are not connected. For each category, (2.1) is referred to as the Markov network in the machine learning literature and as the log-linear model in the statistics literature, where θ (k) j,j ′ is also interpreted as the conditional log odds ratio between X j and X j ′ given the other variables. Although general Markov networks allow higher order interactions (3-way, 4-way, etc.), <ref type="bibr" target="#b29">Ravikumar, Wainwright and Lafferty (2010)</ref> pointed out that in principle one can consider only the pairwise interaction effects without loss of generality, since higher order interactions can be converted to pairwise ones by introducing additional variables <ref type="bibr" target="#b32">[Wainwright and Jordan (2008)</ref>]. For the rest of this paper, we only consider models with pairwise interactions of the original binary variables.</p><p>The simplest way to deal with heterogenous data is to estimate K separate Markov models, one for each category. If one further assumes sparsity for the kth category, the structure of the underlying graph can be estimated by regularizing the log-likelihood using an ℓ 1 penalty: max</p><formula xml:id="formula_4">Θ (k) 1 n k n k i=1 p j=1 θ (k) j,j x (k) i,j + j&lt;j ′ θ (k) j,j ′ x (k) i,j x (k) i,j ′ (2.2) − log Z(Θ (k) ) − λ j&lt;j ′ |θ (k) j,j ′ |.</formula><p>The ℓ 1 penalty shrinks some of the interaction effects θ (k) j,j ′ to zero and λ controls the degree of sparsity. However, estimating (2.2) directly is computationally infeasible due to the nature of the partition function. A standard approach in such a situation is to replace the likelihood with a pseudolikelihood <ref type="bibr" target="#b4">[Besag (1986)</ref>], which has been shown to work well in a range of situations. Here, we use a pseudo-likelihood estimation method for Ising models <ref type="bibr" target="#b16">[Höfling and Tibshirani (2009)</ref>, <ref type="bibr" target="#b12">Guo et al. (2010)</ref>], based on max</p><formula xml:id="formula_5">Θ (k) 1 n k n k i=1 p j=1 x (k) i,j θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ − log 1 + exp θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ (2.3) − λ j&lt;j ′ |θ (k) j,j ′ |,</formula><p>where Θ (k) is restricted to be symmetric. Criterion (2.3) can be efficiently maximized using the modified coordinate descent algorithm of <ref type="bibr" target="#b16">Höfling and Tibshirani (2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Joint estimation of heterogeneous networks.</head><p>The separate estimation methods reviewed in the previous section do not take advantage of the shared nodes among the categories and potential common structure. Our goal here is to explicitly include this into the estimation procedure. We start by reparameterizing each θ</p><formula xml:id="formula_6">(k) j,j ′ as θ (k) j,j ′ = φ j,j ′ γ (k) j,j ′ , 1 ≤ j = j ′ ≤ p; 1 ≤ k ≤ K. (2.4)</formula><p>To avoid sign ambiguities between φ j,j ′ and γ</p><formula xml:id="formula_7">(k) j,j ′ , we restrict φ j,j ′ ≥ 0, 1 ≤ j &lt; j ′ ≤ p.</formula><p>To preserve the symmetry of Θ (k) , we also require φ j,j ′ = φ j ′ ,j and γ</p><formula xml:id="formula_8">(k) j,j ′ = γ (k) j ′ ,j</formula><p>, for all 1 ≤ j &lt; j ′ ≤ p and 1 ≤ k ≤ K. Moreover, for identifiability reasons, we restrict the diagonal elements φ j,j = 1 and γ</p><formula xml:id="formula_9">(k) j,j = θ (k) j,j .</formula><p>Note that φ j,j ′ is a common factor across all K categories that controls the occurrence of common links shared across categories, while γ (k) j,j ′ is an individual factor specific to the kth category. The proposed joint estimation method maximizes the following penalized criterion: max</p><formula xml:id="formula_10">{Φ (k) ,Γ (k) } K k=1 K k=1 1 n k n k i=1 p j=1 x (k) i,j θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ − log 1 + exp θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ (2.5) − η 1 j&lt;j ′ φ j,j ′ − η 2 j&lt;j ′ K k=1 |γ (k) j,j ′ |, where Φ (k) = (φ j,j ′ ) p×p and Γ (k) = (γ (k) j,j ′ ) p×p .</formula><p>The tuning parameter η 1 controls sparsity of the common structure across the K networks. Specifically, if φ j,j ′ is shrunk to zero, all θ</p><p>(1) j,j ′ , . . . , θ (K) j,j ′ are also zero and, hence, there is no link between nodes j and j ′ in any of the K graphs. Similarly, η 2 is a tuning parameter controlling sparsity of links in individual categories. Due to the nature of the ℓ 1 penalty, some of γ (k) j,j ′ 's will be shrunk to zero, resulting in a collection of graphs with individual differences. Note that this two-level penalty was originally proposed by <ref type="bibr" target="#b36">Zhou and Zhu (2007)</ref> for group variable selection in linear regression.</p><p>The criterion (2.5) achieves the stated goal of estimating common structure and hence borrows strength across the K data categories, but requires the selection of two tuning parameters. However, there is an equivalent criterion presented next that only involves a single tuning parameter, thus simplifying the estimation task max</p><formula xml:id="formula_11">{Θ (k) } K k=1 K k=1 1 n k n k i=1 p j=1 x (k) i,j θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ − log 1 + exp θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ (2.6) − λ 1≤j&lt;j ′ ≤p K k=1 |θ (k) j,j ′ |, where λ = 2 √ η 1 η 2 .</formula><p>The optimization problems given by (2.5) and (2.6) are equivalent in the sense that for each pair of (η 1 , η 2 ) there is a λ that gives the same solution and vice versa. Their equivalence can be formalized as follows (here A • B denotes the Schur-Hadamard element-wise product of two matrices): <ref type="bibr">of (2.6)</ref>. Then there exists a local maximizer of ( <ref type="formula">2</ref></p><formula xml:id="formula_12">Proposition 1. Let { Θ (k) } K k=1 be a local maximizer</formula><formula xml:id="formula_13">.5), ( Φ, { Γ (k) } K k=1 ), such that Θ (k) = Φ • Γ (k) , for all 1 ≤ k ≤ K. On the other hand, if ( Φ, { Γ (k) } K k=1</formula><p>) is a local maximizer of (2.5), then there also exists a local maximizer of ( <ref type="formula">2</ref></p><formula xml:id="formula_14">.6), { Θ (k) } K k=1 , such that Θ (k) = Φ • Γ (k) , for all 1 ≤ k ≤ K.</formula><p>The proof of this proposition is similar to the proofs of Lemma 1 and Theorem 1 in <ref type="bibr" target="#b36">Zhou and Zhu (2007)</ref> and is omitted here. Note that even though choosing a single tuning parameter λ corresponds to a particular path in the (η 1 , η 2 ) space, this restriction affects only the individual estimates φ j,j ′ and γ j,j ′ , but not their product θ j,j ′ . 2.3. Algorithm and model selection. Criterion (2.6) leads to an efficient estimation algorithm based on the local linear approximation. Specifically, letting (θ (k) j,j ′ ) [t] denote the estimates from the tth iteration, we approximate</p><formula xml:id="formula_15">K k=1 |θ (k) j,j ′ | ≈ K k=1 |θ (k) j,j ′ |/ K k=1 |(θ (k) j,j ′ ) [t] |, when θ (k) j,j ′ ≈ (θ (k)</formula><p>j,j ′ ) [t] . Thus, at the (t + 1)th iteration, problem (2.6) is decomposed into K individual optimization problems: max</p><formula xml:id="formula_16">Θ (k) 1 n k n k i=1 p j=1 x (k) i,j θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ − log 1 + exp θ (k) j,j + j ′ =j θ (k) j,j ′ x (k) i,j ′ (2.7) − λ 1≤j&lt;j ′ ≤p K k=1 |(θ (k) j,j ′ ) [t] | −1/2 |θ (k) j,j ′ |.</formula><p>Note that criterion (2.7) is a variant of criterion (2.3) with a weighted ℓ 1 penalty and hence can be solved by the algorithm of <ref type="bibr" target="#b16">Höfling and Tibshirani (2009)</ref>. For numerical stability, we threshold</p><formula xml:id="formula_17">K k=1 |(θ (k) j,j ′ ) [t]</formula><p>| at 10 −10 . The algorithm is summarized as follows:</p><p>Step 1. Initialize θ (k) j,j ′ 's (1 ≤ j, j ′ ≤ p; 1 ≤ k ≤ K) using the estimates from the separate estimation method;</p><p>Step 2. For each 1 ≤ k ≤ K, update θ (k) j,j ′ 's by solving (2.7) using the pseudo-likelihood algorithm <ref type="bibr" target="#b16">Höfling and Tibshirani (2009)</ref>, <ref type="bibr" target="#b12">Guo et al. (2010)</ref>.</p><p>Step 3. Repeat step 2 until convergence.</p><p>The tuning parameter λ in (2.6) controls the sparsity of the resulting estimator and can be selected using cross-validation. Specifically, for each 1 ≤ k ≤ K, we randomly split the data in the kth category into D subsets of similar sizes and denote the index set of the observations in the dth subset as</p><formula xml:id="formula_18">T (k) d , 1 ≤ d ≤ D. Then λ is selected by maximizing 1 D D d=1 K k=1 1 |T (k) d | i∈T (k) d p j=1 x (k) i,j ( θ (k) j,j ) [−d] (λ) + j ′ =j ( θ (k) j,j ′ ) [−d] (λ)x (k) i,j ′ (2.8) − log 1 + exp ( θ (k) j,j ) [−d] (λ) + j ′ =j ( θ (k) j,j ′ ) [−d] (λ)x (k) i,j ′ , where |T (k) d | is the cardinality of T (k) d and ( θ (k) j,j ′ ) [−d] (λ) is the joint estimate of θ (k) j,j ′ based on all observations except those in T (1) d ∪ • • • ∪ T (K) d</formula><p>, as well as the tuning parameter λ.</p><p>3. Simulation study. Before turning our attention to examining the U.S. Senate voting patterns, we evaluate the performance of the joint estimation method on three synthetic examples, each with p = 100 variables and K = 3 categories. The network structure in each example is composed of two parts: the common structure across all categories and the individual structure specific to a category. The common structures in these examples are a chain graph, a nearest neighbor graph and a scale-free graph. These graphs are generated as follows:</p><p>Example 1: Chain graph. A chain graph is generated by connecting nodes 1 to p in increasing order, as shown in Figure <ref type="figure" target="#fig_0">2(A1)</ref>.</p><p>Example 2: Nearest neighbor graph. The data generating mechanism of the nearest neighbor graph is adapted from <ref type="bibr" target="#b21">Li and Gui (2006)</ref>. Specifically, we generate p points randomly on a unit square, calculate all p(p − 1)/2 pairwise distances, and find three nearest neighbors of each point in terms of these distances. The nearest neighbor network is obtained by linking any two points that are nearest neighbors of each other. Figure <ref type="figure" target="#fig_0">2</ref>(B1) illustrates a nearest-neighbor graph.</p><p>Example 3: Scale-free graph. A scale-free graph has a power-law degree distribution and can be simulated by the Barabasi-Albert algorithm <ref type="bibr" target="#b3">[Barabási and Albert (1999)</ref>]. A realization of a scale-free network is depicted in Figure <ref type="figure" target="#fig_0">2</ref>(C1).</p><p>In each example, the network for the kth category (k = 1, . . . , K) is created by randomly adding links to the common structure. The individual links in different categories are disjoint and have the same degree of sparsity, measured by ρ, the ratio of the number of individual links to the number of common links. In particular, ρ = 0 corresponds to identical networks for all three categories. In the simulation study, we consider ρ = 0, 1/4 and 1, gradually increasing the proportion of individual links (Figure <ref type="figure" target="#fig_0">2</ref>). Given the graphs, the symmetric parameter matrix Θ (k) is generated as follows. Each θ</p><formula xml:id="formula_19">(k) j,j ′ = θ (k)</formula><p>j ′ ,j corresponding to an edge between nodes j and j ′ is uniformly drawn from [−1, −0.5] ∪ [0.5, 1], whereas all other elements are set to zero. Then we generate the data using Gibbs sampling. Specifically, suppose the ith iteration sample has been drawn and is denoted as (x (k) 1 ) [t] , . . . , (x (k) p ) [t] ; then, in the (t + 1)th iteration, we draw (x</p><formula xml:id="formula_20">(k) j ) [t+1] , 1 ≤ j ≤ p, from the Bernoulli distribution: (x (k) j ) [t+1] ∼ Bernoulli exp(θ (k) j,j + j ′ =j θ (k) j,j ′ (x (k) j ′ ) [t] ) 1 + exp(θ (k) j,j + j ′ =j θ (k) j,j ′ (x (k) j ′ ) [t] ) . (3.1)</formula><p>To ensure that the simulated observations are close to i.i.d. samples from the target distribution, the first 1,000,000 rounds are discarded (burn-in) and the data are collected every 100 iterations from the sampler. In the simulation study, we consider a balanced scenario and an unbalanced scenario. The former consists of n k = 300 observations in each category, whereas the latter has three unbalanced categories with sample sizes n 1 = 200, n 2 = 300 and n 3 = 400. We compared the structure estimation results of the joint estimation method and the separate estimation method using ROC curves, which dynamically characterize the sensitivity (proportion of correctly identified links) and the specificity (proportion of correctly excluded links) by varying the tuning parameter λ. Figure <ref type="figure" target="#fig_1">3</ref> shows the ROC curves averaged over 10 replications from the three examples in the balanced scenario, where the joint estimation method dominates separate estimation when the proportion of individual links is low. As ρ increases, the structures become more different, and the joint and separate methods move closer together. This is expected, since the joint estimation method is designed to take advantage of common structure. The results in the unbalanced scenario exhibit a similar pattern (Figure <ref type="figure" target="#fig_2">4</ref>). 4. Analysis of the U.S. Senate voting records. We applied the proposed joint estimation method to the voting records of the U.S. Senate from the 109th Congress covering the period 2005-2006. The p = 100 variables correspond to the senators. The Senate held 645 votes in that period, from which we extracted n = 222 votes in the three largest categories, namely, defense and security (141), environment and energy (34), and healthcare (47). The votes are recorded as "yes" (encoded as "1") and "no" (encoded as "0").</p><p>The assumption of our model is that bills within a category are an i.i.d. sample from the same underlying Ising model. In reality, the voting process may be more complex, with possible temporal factors and further dependencies among bills, possibly reflecting backroom deals. Neverthless, this is an improvement on previous analyses of such data, which treated all bills in all categories as i.i.d. <ref type="bibr" target="#b2">[Banerjee, El Ghaoui and d'Aspremont (2008)</ref>], and is a reasonable trade-off for an exploratory data analysis tool.</p><p>There were missing observations, as not all senators vote on all bills. The number of bills containing at least one missing vote was 98 out of 141 for defense and security, missing a total of 2.26% of all votes; 24 out of 34 for environment and energy, missing a total of 3.23% of votes; and 20 out of 47 for healthcare, missing 2.38% of all votes. While the number of bills that are missing at least one Senator's vote is relatively high, the overall proportion of missing observations is quite low and, thus, we do not expect it to create a major problem in the analysis. Nevertheless, we have investigated multiple strategies for imputing the missing data in the electronic supplement; specifically, we considered replacing the missing vote by the party's majority, by the majority vote of the five most similar Senators and, to test robustness to the imputation method, also by the opposite party's majority and at random. We found that the main conclusions of the analysis are not very sensitive to missing data imputation methods. In the subsequent analysis, we replace a missing vote for a Senator by his/her party's majority vote on the bill; for the Independent Senator Jeffords, we take the Democratic majority vote. After the imputation, the bills with a "yes/no" proportion greater than 90% or less than 10% were excluded from the analysis, as these typically correspond to procedural votes. This left 97, 29 and 40 bills in the three categories, respectively. Given that two of the sample sizes are fairly small (29 and 40), we added an ℓ 2 penalty with a small tuning parameter λ 2 = 0.01. This approach, known as the elastic net, has been shown to help avoid extremely sparse networks in such situations <ref type="bibr" target="#b37">[Zou and Hastie (2005)</ref>].</p><p>The main tuning parameter for our method was selected through crossvalidation. Following <ref type="bibr" target="#b21">Li and Gui (2006)</ref>, we used a bootstrap procedure for final edge selection, estimating the network for 100 bootstrap samples of the same size, and only retained edges that appeared more that α percent of the time. This procedure is similar to stability selection <ref type="bibr" target="#b24">[Meinshausen and Bühlmann (2010)</ref>].</p><p>The network representation, depicting both the common and the individual structures with a cutoff value for inclusion α = 0.4 and a value of λ = 0.05, is depicted in Figure <ref type="figure">5</ref>. Note that unlike techniques such as princi-Fig. <ref type="figure">5</ref>. The estimated graphical models for the three categories in the Senate voting data with an inclusion cutoff value of 0.4 and tuning parameter value of 0.5. Edges common to all three categories are shown under the heading "common structure"; all other edges are shown on category-specific graphs. The nodes represent the 100 senators, with red, blue and purple node colors corresponding to Republican, Democrat or Independent (Senator Jeffords), respectively. A solid line corresponds to a positive interaction effect and a dashed line to a negative interaction effect. The width of a link is proportional to the magnitude of the corresponding overall interaction effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J. GUO ET AL.</head><p>pal components analysis and multidimensional scaling that directly embed the senators in a two-dimensional map, the proposed method estimates the edges and constructs the adjacency matrix of the graph of Senators; subsequently, we employed a graph drawing program to visualize this graph. The common network structure estimated by the joint estimation method is shown in the top left panel of Figure <ref type="figure">5</ref>. For the individual categories, we only plot the edges associated with the category that is not part of the common network, to enhance the readability of the graphs. As expected, members of the two political parties are clearly separated. For both tuning parameter values, there are strong positive associations between senators of the same party and selected strong negative associations between senators of opposite parties. Obviously, at the higher tuning parameter value the common dependence structure becomes sparser. Of particular interest is the finding that at both tuning values there are many more associations between Democratic senators than Republican ones and this pattern holds for both the common and individual structures. One possible explanation may be that during that period the Democrats were in the minority and thus voting more frequently as a block. Further, the Independent Senator Jeffords is associated with the Democrats, while the moderate Republicans Collins, Snowe, Chafee and Specter (who switched to the Democratic party in early 2009) are not strongly associated with their Republican colleagues, thus confirming results of previous analyses by <ref type="bibr" target="#b5">Clinton, Jackman and Rivers (2004)</ref> and de Leeuw ( <ref type="formula">2006</ref>) (albeit based on data from the 105th Congress). The conservative Democrat Nelson (Nebraska) is also not closely associated with his party, as well as the very conservative Republican de Mint (South Carolina). Also, the analysis suggests that Senator Lieberman had a solid Democratic voting record before becoming an Independent in 2008.</p><p>Other interesting patterns emerging from the analysis are that the more moderate members of the two parties are located closer to the center of their respective "clouds" (e.g., Warner, Frist, Voinovich and Smith on the Republican side, and Levin, Reid, Mikulski and Rockefeller on the Democratic side), the cluster of economic conservatives on the Republican side (Mc-Connell, Domenici, Crapo, Inhofe), the close ties of the liberal Democrats Kennedy, Boxer and Nelson (Florida), the close voting records of senators from the same state (Schumer and Clinton from New York, Murkowski and Stevens from Alaska, Snowe and Collins from Maine, Cantwell and Murray from Washington). There is also a strong dependence between Durbin, Corzine, Lincoln, Harkin and Dodd on the Democratic side.</p><p>Examining the individual networks for the three categories shown in Figure <ref type="figure">5</ref>, we note that additional positive associations among Democrats emerge, primarily for defense and healthcare categories, thus indicating a stronger ideological cohesion on these issues. Further, a number of stable negative associations emerge in the environment and healthcare categories, indicating a stronger ideological divide between senators.</p><p>On defense, some additional strong ties emerge between more liberal leaning Democrats (Stabenow, Biden, Leahy, Kerry, Boxer), while a strong cluster on environmental issues arises between Republican senators from energy producing states (Murkowski and Stevens from Alaska, Thune from South Dakota, Hutchison from Texas, but also Bond from Missouri, Chambliss from Georgia, Craig from Idaho and Roberts from Kansas with their unwavering support for offshore drilling). On health and medical issues, a number of additional strong positive associations emerge among Democratic senators, possibly reflecting the fact that the 109th Congress dealt with issues ranging from veterans affairs, to medical malpractice to food safety and especially on health savings accounts legislation to reduce medical insurance costs.</p><p>Different imputation strategies for missing data were also examined and the analysis results are given in Figures <ref type="figure" target="#fig_1">1-3</ref> in the Supplement for the same values of the cutoff α and tuning parameter λ. It can be seen that similar patterns emerge, although alternative methods of imputation may lead to the emergence of a few more associations. Nevertheless, the main findings seem to be robust to the examined choices of the imputation mechanism, although at very high levels of absenteeism this may not hold <ref type="bibr" target="#b14">[Han (2007)</ref>].</p><p>For comparison purposes, separate multidimensional scaling analyses are shown in Figure <ref type="figure" target="#fig_4">6</ref> for all the votes together and for the three categories separately. MDS (or PCA or factor analysis) is one of the commonly taken approaches in social sciences when graphical modeling is not considered. Figure <ref type="figure" target="#fig_4">6</ref> suggests that the overall vote clustering in the two parties is driven to a large extent by the corresponding clustering in the defense and health categories. On the other hand, voting on environmental issues creates a clear separation between the two parties, although the moderate Republicans Chafee, Collins and Snowe are shown to have a voting record similar to the Democrats, while the Democrats Nelson (Nebraska) and Landrieu are closer to the Republicans. At a high level, MDS-based findings are similar to ours, which is a satisfactory result, but they do not provide explicit clusters or edges, nor do they provide a way to quantify the amount of dependence between individual pairs (visualized via edge thickness in Figure <ref type="figure">5</ref>).</p><p>Another relevant comparison is to fitting a separate graphical model to each of the three categories, as could have been done with any of the previously developed methods for fitting the Ising model. The results are shown in Figure <ref type="figure">7</ref>, in the same format as in Figure <ref type="figure">5</ref>, with edges common to all three categories shown under "common structure," and all other edges under their own category. We followed the same tuning procedure as we did for joint estimation, bootstrapping the data 100 times for stability selection and selecting the value of the tuning parameter on a validation data set.  Even with the cutoff set at 1 (we included only the edges appearing in all the bootstrap replications), the graphs are dense and difficult to interpret. Similar to MDS, they capture party cohesion through strong positive associations between members of the same party for all three categories and some negative associations between members of opposite parties. However, different voting patterns between categories are not clear, although the results suggest a more cohesive voting record for both parties for the defense category. Note that since this is exploratory data analysis, it is hard to verify which set of results is "better." Nevertheless, those obtained from the Fig. <ref type="figure">7</ref>. The estimated graphical models for the three categories in the Senate voting data fitted via separate estimation. Edges common to all three categories are shown under the heading "common structure"; all other edges are shown on category-specific graphs. The cutoff value is 1 (only edges appearing in all bootstrap replications are included). The nodes represent the 100 senators, with red, blue and purple node colors corresponding to Republican, Democrat or Independent (Senator Jeffords), respectively. A solid line corresponds to a positive interaction effect and a dashed line to a negative interaction effect. The width of a link is proportional to the magnitude of the corresponding overall interaction effect. joint estimation method are more nuanced and interpretable and therefore provide better insights into voting strategies of members of Congress.</p><p>5. Concluding remarks. We have proposed a joint estimation method for the analysis of heterogenous Markov networks motivated by the need to jointly estimate heterogeneous networks, such as those of the Senate vot-ing patterns. The method improves estimation of the networks' common structure by borrowing strength across categories, and allows for individual differences. Asymptotic properties of the method have been established. In particular, we show that the convergence rate is similar to the rate for Gaussian graphical models in a similar context <ref type="bibr" target="#b12">[Guo et al. (2010)</ref>]. The proposed method can be extended to deal with general categorical data with more than two levels using the strategy described in Ravikumar, <ref type="bibr" target="#b29">Wainwright and Lafferty (2010)</ref> and <ref type="bibr" target="#b12">Guo et al. (2010)</ref>. The most interesting feature emerging from the analysis of the Senate voting records is the existence of more stable associations for the Democrats, both in terms of the common structure and in the healthcare and defense categories.</p><p>There are other techniques suitable for analyzing roll call data. Dimension reduction techniques create maps, where the relative positioning of the senators allows one to infer similarity in their voting patterns. They provide a useful visual tool to capture broad patterns and relationships. On the other hand, a Markov network model aims directly at estimating the associations between the senators and thus provides an alternative view of the voting patterns, which together with the thresholding technique employed gives a measure of the stability of such associations. Further, the joint estimation method allows one to separately study the overall voting patterns and those driven by specific issues. In our view, both sets of techniques are useful, with dimension reduction providing a global perspective and the Markov model revealing more nuanced patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX: ASYMPTOTIC PROPERTIES</head><p>In this section we study the asymptotic properties of the proposed joint estimation method. Since the structure of the underlying network only depends on the interaction effects, we focus on a variant of the model without main effects. Specifically, we solve max</p><formula xml:id="formula_21">{Θ (k) } K k=1 K k=1 1 n k n k i=1 p j=1 x (k) i,j j ′ =j θ (k) j,j ′ x (k) i,j ′ − log 1 + exp j ′ =j θ (k) j,j ′ x (k) i,j ′ (A.1) − λ j&lt;j ′ K k=1 |θ (k) j,j ′ |.</formula><p>We will show that the estimator in criterion (A.1) is consistent in terms of both parameter estimation and model selection, when p and n go to infinity and the tuning parameter λ goes to zero at some appropriate rate. We note J. GUO ET AL.</p><p>on a given node, respectively. Conditions similar to (B) and (C) were also assumed by <ref type="bibr" target="#b23">Meinshausen and Bühlmann (2006)</ref>, <ref type="bibr" target="#b29">Ravikumar, Wainwright and Lafferty (2010)</ref>, <ref type="bibr" target="#b26">Peng, Zhou and Zhu (2009)</ref> and <ref type="bibr" target="#b12">Guo et al. (2010)</ref>. Our conditions are most closely related to those of <ref type="bibr" target="#b12">Guo et al. (2010)</ref>, but here they are extended to the heterogenous data setting.</p><p>Theorem 1 (Parameter estimation). Suppose all regularity conditions hold. If the tuning parameter λ = C λ (log p)/n for some constant C λ &gt; (8 − 4τ )</p><p>√ γ min /(1 − τ ) and if min{n/q 3 , n 1 /q 3 1 , . . . , n K /q 3 K } &gt; (4/C) log p for some constant C = min{τ 2 min τ 2 /288(1 − τ ) 2 , τ 2 min τ 2 /72, τ min τ /48}, then there exists a local maximizer of the criterion (A.1), { θ (k) } K k=1 , such that, with probability tending to 1,</p><formula xml:id="formula_22">K k=1 θ (k) − θ (k) 2 ≤ M q log p n , (A.4) for some constant M &gt; (2KC λ /τ min √ γ min )(3 − 2τ )/(2 − τ ).</formula><p>Theorem 2 (Structure selection). Under conditions of Theorem 1, with probability tending to 1, the maximizer { θ (k) } K k=1 from Theorem 1 satisfies θ (k) j,j ′ = 0 for all (j, j ′ ) ∈ S k , k = 1, . . . , K; θ (k) j,j ′ = 0 for all (j, j ′ ) ∈ S c k , k = 1, . . . , K.</p><p>Theorems 1 and 2 establish the consistency in terms of parameter estimation and structure selection, respectively.</p><p>The main idea of the proofs is closely related to <ref type="bibr" target="#b12">Guo et al. (2010)</ref>, and some strategies for dealing with the joint estimation are borrowed from <ref type="bibr" target="#b13">Guo et al. (2011)</ref>. We introduce notation first. For the kth category, we define the log-likelihood as</p><formula xml:id="formula_23">l(θ (k) ) = 1 n k n k i=1 p j=1 x (k) i,j j ′ =j θ (k) j,j ′ x (k) i,j ′ − log 1 + exp j ′ =j θ (k) j,j ′ x (k) i,j ′</formula><p>, whose first derivative and second derivative are denoted by ∇l(θ (k) ) and ∇ 2 l(θ (k) ), respectively. Note that ∇l(θ (k) ) is a p(p − 1)/2-dimensional vector and ∇ 2 l(θ (k) ) is a p(p−1)/2×p(p−1)/2 matrix. Then, the population Fisher information matrix of the model in (A.1) at θ can be defined as Q</p><formula xml:id="formula_24">(k) = −E[∇ 2 l(θ (k) )],</formula><p>and its sample counterpart is Q k) ). We also write</p><formula xml:id="formula_25">(k) = −∇ 2 l(θ<label>(</label></formula><formula xml:id="formula_26">U (k) = 1/n n i=1 X (k) (i) T X (k) (i)</formula><p>for the sample counterpart of U (k) . Let Proposition 2. Suppose condition (A) and the sample conditions (B ′ ) and (C ′ ) hold. If the tuning parameter λ = C λ (log p)/n for some constant C λ &gt; (8 − 4τ )</p><p>√ γ min /(1 − τ ) and q (log p)/n = o(1), then with probability tending to one, there exists a local maximizer of the restricted criterion, { θ (k) } K k=1 , satisfying:</p><formula xml:id="formula_27">(i) K k=1 θ (k) −θ (k) 2 ≤ M q(log p)/n for some constant M &gt; (2KC λ / τ min √ γ min )[(3 − 2τ )/(2 − τ )]; (ii) For each k = 1, . . . , K, θ (k) j,j ′ = 0 for all (j, j ′ ) ∈ S k and θ (k) j,j ′ = 0 for all (j, j ′ ) ∈ S c k .</formula><p>Proposition 3. Suppose the regularity conditions (B) and (C) hold, then for any ε &gt; 0, the following inequalities hold with probability tending to one for all k = 1, . . . , K:</p><formula xml:id="formula_28">(i) P{Λ min ( Q (k) S k ,S k ) ≤ τ min − ε} ≤ 2 exp{−(ε 2 /2)(n k /q 2 k ) + 2 log q k }; (ii) P{Λ max ( U (k) S k ,S k ) ≥ τ max + ε} ≤ 2 exp{−(ε 2 /2)(n k /q 2 k ) + 2 log q k }; (iii) P[ Q (k) S c k ,S k ( Q (k) S k ,S k ) −1 ∞ ≥ 1 − τ /2] ≤ 12 exp(−Cn k /q 3 k + 4 log p), for some constant C = min{τ 2 min τ 2 /288(1 − τ ) 2 , τ 2 min τ 2 /72, τ min τ /48}.</formula><p>Proposition 4. { θ} K k=1 is a local maximizer of problem (A.1) if and only if the following conditions hold for all k = 1, . . . , K:</p><formula xml:id="formula_29">∇ j,j ′ l( θ (k) ) = λ sgn( θ (k) j,j ′ ) K k=1 | θ (k) j,j ′ | 1/2 if θ (k) j,j ′ = 0; (A.8) |∇ j,j ′ l( θ (k) )| &lt; λ K k=1 | θ (k) j,j ′ | 1/2 if θ (k) j,j ′ = 0.</formula><p>Proposition 5. Under all conditions of Proposition 2, with probability tending to one, we have, for each k = 1, . . . , K,</p><formula xml:id="formula_30">∇ j,j ′ l( θ (k) ) = λ sgn( θ (k) j,j ′ ) K k=1 | θ (k) j,j ′ | 1/2</formula><p>for all (j, j ′ ) ∈ S k ;</p><p>(A.9)</p><formula xml:id="formula_31">|∇ j,j ′ l( θ (k) )| &lt; λ K k=1 | θ (k) j,j ′ | 1/2</formula><p>for all (j, j ′ ) ∈ S c k .</p><p>Proof of Theorems 1 and 2. The condition min{n/q 3 , n 1 /q 3 1 , . . . , n K / q 3 K } &gt; (4/C) log p implies that, for each k = 1, . . . , K, we have −Cn k /q 3 k + 4 log p &lt; 0 and −(ε 2 /2)(n k /q 2 k ) + 2 log q k &lt; 0 when q k is large enough. This condition also implies q (log p)/n = o(1). In addition, by Proposition 3, the sample conditions (B ′ ) and (C ′ ) hold with probability tending to one when regularity conditions (B) and (C) hold. Therefore, by Proposition 2, with probability tending to one, the solution of the restricted problem { θ (k) } K k=1 satisfies both parameter estimation consistency and structure selection consistency. On the other hand, by Proposition 5, with probability tending to one, { θ (k) } K k=1 also satisfies the KKT conditions in Proposition 4, thus, it is a local maximizer of criterion (A.1). proves Theorems 1 and 2.</p><p>Part II: Proofs of propositions. Before proving the propositions, we state a few lemmas which will be used in the proofs. These lemmas are variants of Lemmas 1, 2 and 5 in <ref type="bibr" target="#b12">Guo et al. (2010)</ref>, adapted to the settings of the heterogenous model and, thus, the proofs are omitted here. Likewise, the proof of Proposition 3 is very similar to the proof of Propositions 3 and 4 in <ref type="bibr" target="#b12">Guo et al. (2010)</ref> and is omitted.</p><p>Lemma 1. For each k = 1, . . . , K, with probability tending to 1, we have ∇l(θ</p><formula xml:id="formula_32">(k) ) ∞ ≤ C ∇ (log p)/n for some constant C ∇ &gt; 4.</formula><p>Lemma 2. If the sample dependency condition (B ′ ) holds and q (log p)/n = o(1), then for any α k ∈ [0, 1], k = 1, . . . , K, the following inequality holds with probability tending to 1:</p><formula xml:id="formula_33">− K k=1 δ (k) S k T [∇ 2 l(θ (k) + α k δ (k) )] S k ,S k δ (k) S k ≥ 1 2 τ min K k=1 δ (k) 2 2 . (A.10)</formula><p>Lemma 3. Suppose the sample dependency condition (B) holds. For any α k ∈ [0, 1], k = 1, . . . , K, the following inequality holds with probability tending to one:</p><formula xml:id="formula_34">[∇ 2 l(θ (k) + α k δ (k) ) − ∇ 2 l(θ (k) )]δ (k) ∞ ≤ τ max δ (k) 2 2 . (A.11)</formula><p>Proof of Proposition 2. The main idea of the proof was first introduced in this context in <ref type="bibr" target="#b31">Rothman et al. (2008)</ref> and has since been used by many authors. Define</p><formula xml:id="formula_35">G({δ (k) } K k=1 ) = − K k=1 [l(θ (k) + δ (k) ) − l(θ (k) )] (A.12) + λ 1≤j&lt;j ′ ≤p K k=1 |θ (k) j,j ′ + δ (k) j,j ′ | 1/2 − K k=1 |θ (k) j,j ′ | 1/2 . It can be seen from (A.5) that { δ (k) } K k=1 minimizes G({δ (k) } K k=1</formula><p>) and G({0} K k=1 ) = 0. Thus, we must have G({ δ (k) } K k=1 ) ≤ 0. If we take a closed set A which contains {0} K k=1 and show that G is strictly positive everywhere on the boundary ∂A, then it implies that G has a local minimum inside A, since G is continuous and G({0} K k=1 ) = 0. Specifically, we define A = {{δ (k) } K k=1 : K k=1 δ (k) 2 ≤ M a n }, with boundary ∂A = {{δ (k) } K k=1 :</p><p>K k=1 δ (k) 2 = M a n }, for some constant M &gt; (2KC λ /τ min √ γ min )[(3 − 2τ )/ (2 − τ )] and a n = q(log p)/n. For any {δ (k) } K k=1 ∈ ∂A, the Taylor series expansion gives G({δ (k) } K k=1 ) = I 1 + I 2 + I 3 , where</p><formula xml:id="formula_36">I 1 = − K k=1 [∇l(θ (k) )] T S k δ (k) S k , I 2 = − K k=1 δ (k) S k T [∇ 2 l(θ (k) + α k δ (k) )] S k ,S k δ (k) S k</formula><p>for some α k ∈ [0, 1], (A.13) By Lemma 1,</p><formula xml:id="formula_37">I 3 = λ</formula><formula xml:id="formula_38">|I 1 | ≤ K k=1 [∇l(θ (k) )] S k ∞ δ (k) S k 1 (A.14) ≤ [(1 − τ )C λ M γ −1/2</formula><p>min /(2 − τ )](q log p)/n. In addition, by condition q (log p)/n = o(1), Lemma 2 holds and, thus,</p><formula xml:id="formula_39">I 2 ≥ (τ min /2) K k=1 δ (k) 2</formula><p>2 ≥ [τ min /(2K)]M 2 q(log p)/n.  Proof of Proposition 5. By Proposition 2, with probability tending to one, we have θ j,j ′ = 0 for all (j, j ′ ) ∈ S k . Since { θ (k) } K k=1 is a local maximizer of the restricted problem (A.5), with probability tending to one,</p><formula xml:id="formula_40">∇ j,j ′ l( θ (k) ) = λ sgn( θ (k) j,j ′ )/( K k=1 | θ (k) j,j ′ |) 1/2</formula><p>, for all (j, j ′ ) ∈ S k . To show the second claim, we apply the mean value theorem and write k) , where r (k) = {∇ 2 l(θ k) . After some simplifications, we have  (k) )] S k } and, thus, On the other hand, λ/[ K k=1 | θ (k) j,j ′ |] 1/2 = +∞ when (j, j ′ ) ∈ S c ∪ . Otherwise, if (j, j ′ ) ∈ S ∪ \ S k , then</p><formula xml:id="formula_41">∇l( θ (k) ) = ∇l(θ (k) ) + r (k) − Q (k) δ<label>(</label></formula><formula xml:id="formula_42">(k) + α k δ (k) ) − ∇ 2 l(θ (k) )} δ<label>(</label></formula><formula xml:id="formula_43">[∇l( θ (k) )] S c k ∞ ≤ [∇l(θ (k) )] S c k ∞ + r (k) S c k ∞ + Q (k) S c k ,S k ( Q (k) S k ,S k ) −1 ∞ × { [∇l(θ (k) )] S k ∞ + r (k) S k ∞ + [∇l( θ (k) )] S k ∞ } (A.19) ≤ (2 − τ ) ∇l(θ (k) ) ∞ + (2 − τ ) r (k) ∞ + (1 − τ ) [∇l( θ (k) )]</formula><formula xml:id="formula_44">λ K k=1 | θ j,j ′ | 1/2 ≥ λ K k=1 | θ j,j ′ − θ j,j ′ | + |θ j,j ′ | 1/2 ≥ λ/ √ γ max ≥ (2 − 2τ )λ/ √ γ min .</formula><p>Thus, for any (j, j ′ ) ∈ S c k (k = 1, . . . , K), we have </p><formula xml:id="formula_45">|∇ j,j ′ l( θ (k) )| ≤ max</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The networks used in three simulated examples. The black lines represent the common structure, whereas the red, blue and green lines represent the individual links in the three categories. ρ is the ratio of the number of individual links to the number of common links.</figDesc><graphic url="image-2.png" coords="11,127.08,148.60,355.92,428.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Results for the balanced scenario (n1 = n2 = n3 = 300) and dimension p = 100. Black solid curve: joint estimation; red dashed curve: separate estimation. The ROC curves are averaged over 10 replications. ρ is the ratio between the number of individual links and the number of common links.</figDesc><graphic url="image-3.png" coords="12,127.08,148.48,355.92,426.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Results for the unbalanced scenario (n1 = 200, n2 = 300, n3 = 400) and dimension p = 100. Black solid curve: joint estimation; red dashed curve: separate estimation.The ROC curves are averaged over 10 replications. ρ is the ratio between the number of individual links and the number of common links.</figDesc><graphic url="image-4.png" coords="13,127.08,218.92,355.92,426.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Multidimensional scaling analysis for all the votes together, and the three individual categories. The nodes represent the 100 senators, with red, blue and purple node colors corresponding to Republican, Democrat or Independent (Senator Jeffords), respectively.</figDesc><graphic url="image-6.png" coords="18,126.60,148.60,356.88,368.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>.</head><label></label><figDesc>Since C λ &gt; (8 − 4τ ) √ γ min /(1 − τ ), we have [(1 − τ )/(2 − τ )]C λ / √ γ min &gt; 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>≤</head><label></label><figDesc>(M C λ γ −1/2 min ){q(log p)/n}. uses the condition M &gt; (2KC λ /τ min √ γ min )[(3 − 2τ )/(2 − τ )].Therefore, with probability tending to 1, we have K k=1 θ log p)/n, and consequently claim (i) in Proposition 2 holds.On the other hand, by the definition of θ (k) , we have θ (k) j,j ′ = 0 for all (j, j ′ ) ∈ S c k . By regularity condition (A) and Proposition 2(i), for any (j,j ′ ) ∈ S k , k = 1, . . . , K, we have | θ (k) j,j ′ | ≥ |θ (k) j,j ′ | − | θ (k) j,j ′ − θ (k)j,j ′ | ≥ γ min /2 &gt; 0, when n is large enough.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>S k ,S k ) −1 ]{[∇l(θ (k) )] S k + r (k) S k − [∇l( θ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>S k ∞ ≤ [(1 − τ )C λ / √ γ min ] (log p)/n + (2 − τ )τ max M 2 q(log p)/n + (1 − τ )λ min (j,j ′ )∈S k K k=1 | θ j,j ′ | 1/2 ≤ [2(1 − τ )/ √ γ min ]λ + o p (λ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="2,160.08,148.60,290.40,278.88" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">J. GUO ET AL.</note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Supported in part by NSF Grants DMS-01-106772 and DMS-11-59005. 2 Supported in part by NIH Grant 1RC1CA145444-0110 and NSF Grant DMS-12-28164. 3 Supported in part by NSF Grants DMS-07-05532 and DMS-07-48389.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>that our results are pointwise rather than uniform in Θ, as is standard in the literature. Some interesting implications of nonuniform bounds for sparse estimators in linear regression have recently been discussed by <ref type="bibr" target="#b19">Leeb and Pötscher (2008)</ref>, <ref type="bibr" target="#b28">Pötscher and Leeb (2009)</ref>, although their conclusions do not apply to graphical models.</p><p>Before stating the main results, we introduce necessary notation and regularity conditions. For each k = 1, . . . , K, denote θ (k) = (θ</p><p>p−1,p ) as a p(p − 1)/2-dimensional vector, recording all upper triangular elements in Θ (k) . Let θ (k) be the true value of θ (k) . Let Q (k) be the population Fisher information matrix of the model in criterion (A.1) (see the Appendix for a precise definition) and let X (k) (i) be a matrix with p rows and p(p − 1)/2 columns, whose (j, j ′ )th column is composed of zeros except for the jth (j ′ th) component being x i,j ′ (x i,j ). In addition, we define</p><p>To index the zero and nonzero elements, let</p><p>The cardinalities of S k and S ∪ are denoted by q k and q, respectively. For any matrix W and subsets of row and column indices U and V, let W U ,V be the matrix consisting of rows U and columns V in W. Finally, let Λ min (•) and Λ max (•) denote the smallest and largest eigenvalue of a matrix, respectively.</p><p>The asymptotic properties of the joint estimation method rely on the following regularity conditions:</p><p>(A) Nonzero elements bounds: There exist positive constants γ min and γ max such that:</p><p>(B) Dependency: There exist positive constants τ min and τ max such that for any k = 1, . . . , K,</p><p>Condition (A) enforces a lower bound on the magnitudes of all nonzero elements, as well as an upper bound on the magnitudes of those nonzero elements associated with individual links. Conditions (B) and (C) bound the amount of dependence and the influence that the nonneighbors can have</p><p>p−1,p ) be the same as θ (k) except that all elements in S c k are set to zero and write δ (k) = θ (k) −θ (k) and δ (k) = θ (k) −θ (k) . Finally, let W be a subset of the index set {1, 2, . . . , p(p − 1)/2}. For a p(p − 1)/2dimensional vector β, we define β W as the vector consisting of the elements of β associated with W.</p><p>Next, we introduce a variant of criterion (A.1) by restricting all true zeros in {θ (k) } K k=1 to be estimated as zero. Specifically, the restricted criterion is formulated as follows:</p><p>and its maximizer is denoted by { θ (k) } K k=1 . In addition, we consider the sample versions of regularity conditions (B) and (C): (B ′ ) Sample dependency: There exist positive constants τ min and τ max such that for any k = 1, . . . , K,</p><p>There exists a constant τ ∈ (1− γ min /4γ max , 1) such that for any k = 1, . . . , K,</p><p>For convenience of the readers, the proof of our main result is divided into two parts: Part I presents the main idea of the proof by listing the important propositions and the proofs of Theorems 1 and 2, whereas part II contains additional technical details and proofs of propositions in part I.</p><p>Part I: Propositions and proof of Theorems 1 and 2. The proof consists of the following steps. Proposition 2 shows that, under sample regularity conditions (B ′ ) and (C ′ ), the conclusions of Theorems 1 and 2 hold for the local maximizer of the restricted problem (A.5). Next, Proposition 3 proves that the population regularity conditions (B) and (C) give rise to their sample counterparts (B ′ ) and (C ′ ) with probability tending to one, hence, the conclusions of Proposition 2 also hold with the population regularity conditions. Last, we show that the local maximizer of (A.5) is also a local maximizer of the original model (A.1). This is established via Proposition 4, which sets out the Karush-Kuhn-Tucker (KKT) conditions for the local maximizer of criterion (A.1), and Proposition 5, which shows that, with probability tending to one, the local maximizer of (A.5) satisfies these KKT conditions.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Getting started in probabilistic graphical models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Airoldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">e252</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Highdimensional structure estimation in Ising models: Local separation criterion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">R3015028</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data</title>
		<author>
			<persName><forename type="first">O</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>El Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspremont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">R2417243</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page">R2091634</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the statistical analysis of dirty pictures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B Stat. Methodol</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page">R0876840</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The statistical analysis of roll call data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Clinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jackman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rivers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="355" to="370" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The joint graphical lasso for inverse covariance estimation across multiple classes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Witten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1111.0324</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Principal component analysis of senate voting patterns</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Leeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Real Data Analysis</title>
				<editor>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sawilowski</surname></persName>
		</editor>
		<meeting><address><addrLine>Charlotte, NC</addrLine></address></meeting>
		<imprint>
			<publisher>Information Age Publishing</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="405" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Horseshoes in multidimensional scaling and local kernel methods</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Holmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">R2516794</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The Spatial Theory of Voting: An Introduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Enelow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hinich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Cambridge Univ. Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Predicting legislative roll calls from text</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Gerrish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Internat. Conf. on Machine Learning (ICML-11)</title>
				<meeting>28th Internat. Conf. on Machine Learning (ICML-11)<address><addrLine>Omnipress, Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Joint structure estimation of Markov network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Michailidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Statistics, Univ. Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Joint structure estimation for categorical Markov networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Michailidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Statistics, Univ. Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint estimation of multiple graphical models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Michailidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">R2804206</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Analysing roll calls of the European Parliament: A Bayesian application</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Union Politics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="479" to="507" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning a common substructure of multiple graphical Gaussian models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Washio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="23" to="38" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Estimation of sparse binary pairwise Markov networks using pseudo-likelihoods</title>
		<author>
			<persName><forename type="first">H</forename><surname>Höfling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">R2505138</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Statistical inference in context specific interaction models for contingency tables</title>
		<author>
			<persName><forename type="first">S</forename><surname>Højsgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scand. J. Stat</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">R2042604</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Markov random field based English part-of-speech tagging system</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">;</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kolar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0811.1239</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Computational Linguistics 236-242</title>
				<meeting>the 16th Conference on Computational Linguistics 236-242<address><addrLine>Stroudsburg, PA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996">1996. 2008</date>
		</imprint>
	</monogr>
	<note>Improved estimation of high-dimensional Ising models</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sparse estimators and the oracle property, or the return of Hodges&apos; estimator</title>
		<author>
			<persName><forename type="first">H</forename><surname>Leeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Pötscher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page">R2394290</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Markov Random Field Modeling in Image Analysis</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gradient directed regularization for sparse Gaussian concentration graphs, with applications to inference of genetic networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="302" to="317" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Yeas and Nays: Normal Decision-Making in the U</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stimson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>S. House of Representatives. Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">High-dimensional graphs and variable selection with the lasso</title>
		<author>
			<persName><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">R2278363</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stability selection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B Stat. Methodol</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page">R2758523</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Methods and Models: A Guide to the Empirical Analysis of Formal Models in Political Science</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Morton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge Univ. Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Partial correlation estimation by joint sparse regression models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">R2541591</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Congress: A Political-Economic History of Roll-Call Voting</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rosenthal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Oxford Univ. Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the distribution of penalized maximum likelihood estimators: The LASSO, SCAD, and thresholding</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Pötscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leeb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Multivariate Anal</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<date type="published" when="2009">2009. 2065-2082. MR2543087</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">High-dimensional Ising model selection using ℓ1-regularized logistic regression</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">R2662343</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Highdimensional covariance estimation by minimizing ℓ1-penalized log-determinant divergence</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Raskutti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. J. Stat</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">R2836766</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sparse permutation invariant covariance estimation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Rothman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. J. Stat</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">R2417391</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graphical models, exponential families, and variational inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="305" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nonconcave penalized composite conditional likelihood estimation of sparse Ising models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">R3015030</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Fused multiple graphical lasso</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1209.2139.J.GUOETAL</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Model selection and estimation in the Gaussian graphical model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page">R2367824</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Group variable selection via a hierarchical lasso and its oracle property</title>
		<author>
			<persName><forename type="first">N</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Statistics, Univ. Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B Stat. Methodol</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">R2137327</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
