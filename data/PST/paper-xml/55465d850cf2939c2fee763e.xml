<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<address>
									<addrLine>Univer-sidade Federal do Espírito Santo</addrLine>
									<postCode>29075-91</postCode>
									<settlement>Vitória</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BA626D7B32935BCFFFB54906C050BDE2</idno>
					<idno type="DOI">10.1109/TIE.2014.2327589</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE detection of bearing faults is an important engineering task, particularly in the context of electric machines <ref type="bibr" target="#b0">[1]</ref>. A common engineering approach in model-free <ref type="bibr" target="#b1">[2]</ref> diagnosis is to define a single signal feature extraction model, together with a classifier methodology and to present cross-validation experimental results. The considered applied research in this field frequently lacks soundness in the pattern recognition part of the system. To motivate this work and to support this hypothesis, papers were analyzed that use the Case Western Reserve University (CWRU) Bearing Data [3] as a testbed.</p><p>Statistical features are exclusively used in <ref type="bibr" target="#b2">[4]</ref>- <ref type="bibr" target="#b6">[8]</ref>. The work of Sun et al. in <ref type="bibr" target="#b7">[9]</ref> and Sreejith et al. in <ref type="bibr" target="#b8">[10]</ref> use complex envelope features together with the wavelet packet analysis, which constitutes the principal feature model in the following publications: <ref type="bibr" target="#b8">[10]</ref>- <ref type="bibr" target="#b14">[16]</ref>. It is postulated here that there is no necessity to restrict the discriminatory description of a fault diagnosis system to a single feature model, thus avoiding the risk to miss important aspects of the data. It is better to produce as much information as possible about the process condition, even contaminated with noise and filter out the best features in a posterior information processing step.</p><p>Feature selection <ref type="bibr" target="#b15">[17]</ref> is such an important technique in computational intelligence. Its aim is to reduce dimensionality and eventually improve performance parameters of the system such as accuracy. No feature selection at all is used in <ref type="bibr" target="#b3">[5]</ref>, <ref type="bibr" target="#b4">[6]</ref>, <ref type="bibr" target="#b7">[9]</ref>, <ref type="bibr" target="#b8">[10]</ref>, <ref type="bibr" target="#b10">[12]</ref>- <ref type="bibr" target="#b14">[16]</ref>, <ref type="bibr" target="#b16">[18]</ref>, and <ref type="bibr" target="#b17">[19]</ref> or only univariate methods, i.e., ranking features individually, such as, e.g., <ref type="bibr" target="#b9">[11]</ref> (factor analysis) and <ref type="bibr" target="#b2">[4]</ref> (Fisher score). Here, search algorithms are applied that are multivariate, analyzing a set of candidate features, thus considerably avoiding redundancy in the final feature model. The nature of the features does not play an important role, as long as they are powerful separators of the fault classes. Therefore, a candidate pool can be assembled where features can originate from quite distinct models such as, for instance, in this work, statistical, wavelets, and envelopes.</p><p>Considering the final attribution of the vibration pattern to a machine condition, it can be observed that no classifier at all is used in <ref type="bibr" target="#b3">[5]</ref>, <ref type="bibr" target="#b10">[12]</ref>, <ref type="bibr" target="#b11">[13]</ref>, and <ref type="bibr" target="#b16">[18]</ref>; only the visual inspection of peaks in frequency graphs suggests the discriminative power of the method. In general, feedforward neural nets and support vector machines (SVMs) are the dominant techniques in contemporary work.</p><p>Training, validation, and test data splitting is very important to obtain reliable performance criteria for the fault classifier. Simple one-time train-test splitting or no information at all about the pattern division can be observed in <ref type="bibr" target="#b2">[4]</ref>, <ref type="bibr" target="#b4">[6]</ref>- <ref type="bibr" target="#b9">[11]</ref>, <ref type="bibr" target="#b12">[14]</ref>- <ref type="bibr" target="#b14">[16]</ref>, and <ref type="bibr" target="#b16">[18]</ref>. None of these papers use a statistically more significant model validation, such as leave-one-out (LOO) or K-fold cross validation (CV). Moreover, the estimated accuracy is the only performance criterion used, although other criteria are interesting, for instance, the area under the receiver operating characteristic curve (AUC-ROC) <ref type="bibr" target="#b18">[20]</ref>, particularly when the classes are considerably unbalanced with respect to the number of their training samples.</p><p>The following research on model-free bearing fault detection does not use the CWRU data but is similar to this work with respect to the objectives and methodologies. In <ref type="bibr" target="#b19">[21]</ref>, statistical features describe the bearing fault; linear discriminant analysis is used to rank the features in a preprocessing step in a univariate, bivariate, and trivariate combination; a curvilinear component analysis is used for feature extraction; and a multilayer perceptron (MLP) provides the final process condition. The faults of a wound-rotor induction machine are characterized by wavelet coefficients in <ref type="bibr" target="#b20">[22]</ref>, and a time-frequency feature model is chosen in <ref type="bibr" target="#b21">[23]</ref> by designing particular kernels for the given classification task. Moreover, sequential forward feature selection is used. The multidimensional selection criterion is the average pairwise mutual correlation among candidate features and the already selected features. He et al. in <ref type="bibr" target="#b22">[24]</ref> propose a two-stage system for bearing fault diagnosis. First, complex envelope features are used for outer race separation; then, empirical mode decomposition by the Hilbert-Huang transform generates features that are used for the remaining fault classes.</p><p>The innovative idea of this paper is to consider the final feature model as the result of an information processing sequence. It does not matter where the discriminative information comes from, as long as it improves the classification of the machine conditions. Traditional fault diagnosis systems limit the process description to a single feature model, for instance, wavelet coefficients. More than one simultaneous feature model is not considered in general.</p><p>Obviously, this approach does not work, if the good information is not filtered out by the subsequent feature selection stage. The combination of several feature models plus feature selection seems a quite obvious method to improve classification performance but is not being employed in practice.</p><p>The rest of this paper is organized in the following manner: Section II presents the proposed framework to perform the bearing fault diagnosis and describes the three feature models used in this research that are pooled into the global candidate set. In Section III, the important step of feature selection is discussed. Section IV presents the classifier models and performance estimation methods used in this work. The description of the experimental workbench in which the bearing faults are artificially created, the different machine and fault conditions that define the classes to be recognized, together with experimental results for fault diagnosis of the CWRU bearing data are presented in Section V, and finally, conclusions are drawn in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. FEATURE MODELS</head><p>The main hypothesis of this work is that higher discriminative power of the fault detection system can be achieved if as much information as possible is extracted from the signal and a subsequent feature selection reduces the final number of features to a reasonable amount. This means that various feature extraction paradigms can be combined in parallel to create a quite heterogeneous pool of candidate features from which the final set is obtained by feature selection. None of the previously analyzed publications propose a fusion of features that stem from completely different signal feature extraction methods. The experimental results suggest that this strategy of pooling, followed by selection in general, improves the performance of the fault diagnosis. Fig. <ref type="figure" target="#fig_1">1</ref> illustrates the general framework to perform the bearing fault diagnosis. The sequence of information processing steps is as follows.</p><p>1) Signal feature extraction: Use the available sensors attached to the machine to acquire the raw signal in the time domain. From the raw signal, considering a feature model, extract the feature vector within this model. Do this for all available models.</p><p>2) Feature pooling: Assemble a global feature vector that contains as much information as possible about the machine condition. Reduce the number of features by a recombination of the existing ones (extraction) or by retaining only a subset (selection), cf., the following two steps.</p><p>3) Feature extraction on the feature level: From the existing feature vector, extract new features. Usually, the dimension is considerably reduced. The new features are abstract descriptions of the machine condition. The most prominent linear method is principal component analysis (PCA). 4) Feature selection: Either discard or preserve existing features to form a subset of the existing features. The main goal is dimensionality reduction and the increase in discriminatory power of the net feature set. 5) Classification: Define a single-or a multiple-classifier model and estimate its performance. The right-hand side in Fig. <ref type="figure" target="#fig_1">1</ref> shows the specialization of the framework used in this work, the specific feature models, selection techniques, and classifiers.</p><p>The main contribution of this paper is the simultaneous use of distinct types of features and the posterior phase of feature selection. This strategy ensures that no important information is omitted during the extraction phase and that no irrelevant information from the extraction phase is preserved. Representative feature models mainly observed in the considered literature were used in this work, i.e., statistical features from the time and frequency domains, wavelet packet energy, and complex envelope magnitudes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Statistical Features</head><p>As representative sets, those features used in <ref type="bibr" target="#b9">[11]</ref> were chosen, cf., Tables <ref type="table" target="#tab_0">I</ref> and<ref type="table" target="#tab_1">II</ref>. Table <ref type="table" target="#tab_0">I</ref> presents the definition of ten statistical features in the time domain: root mean square (RMS), square root of the amplitude (SRA), kurtosis value (KV), skewness value (SV), peak-to-peak value (PPV), crest factor (CF), impulse factor (IF), margin factor (MF), shape factor (SF), and kurtosis factor (KF). Table <ref type="table" target="#tab_1">II</ref> presents the definition of three statistical features in the frequency domain: frequency center (FC), RMS frequency (RMSF), and root variance frequency (RVF). The total number of statistical features is (10 + 3) × 2 = 26, i.e., the ten statistical features of the time domain, the three of the frequency domain, taken at both the drive end (DE) and fan end (FE) of the motor housing of the CWRU testbed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Complex Envelope Analysis</head><p>There are four characteristic frequencies at which faults can occur <ref type="bibr" target="#b23">[25]</ref>. Knowing the shaft rotational frequency F S , they are the fundamental cage frequency F C (not present in the CWRU database), ball-pass inner-raceway frequency F BPI , ball-pass outer-raceway frequency F BPO , and the ball-spin frequency F B . For a detailed description of the fault frequency model, refer, e.g., to <ref type="bibr" target="#b22">[24]</ref>. A detailed description of the CWRU testbed is provided in <ref type="bibr" target="#b9">[11]</ref>.  The signal envelope can be calculated by virtue of the Hilbert transform. Given a signal h(t) in the time domain, the Hilbert transform is the convolution of h(t) with the signal 1/πt, producing a new signal in the time domain, i.e.,</p><formula xml:id="formula_0">h(t) := H{h(t)} := h(t) * 1 πt = 1 π ∞ -∞ h(t) dτ t -τ .<label>(1)</label></formula><p>The analytic signal, i.e., h a (t), which is a complex signal in the time domain, composed of the original signal h(t) and its Hilbert transform h(t) in quadrature, is defined as</p><formula xml:id="formula_1">h a (t) := h(t) + i h(t). (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>The analysis steps for the calculus of the bearing defect frequencies spectrum can be resumed as follows:</p><p>1) high-pass filtering of the raw signal to eliminate the influence of slow vibrations, producing the signal h(t); 2) calculus of the analytic signal h a (t) of the original signal h(t); 3) Fourier transform of the analytic signal F{h a (t)}; 4) analysis of its spectrum |F{h a (t)}|. For the CWRU database, the sensor at the DE, although with less confidence, can detect the faults at the FE; hence, the number of features duplicates (cross detection). For each of the characteristic fault frequencies F BPI , F BPO , F B , and up to the sixth harmonic of each of these frequencies, the 1% narrowband RMS energy (i.e., X rmsf in Table <ref type="table" target="#tab_1">II</ref>) was calculated. Hence, 2 × 3 × 2 × 6 = 72 envelope features are obtained, i.e., acquisition position (FE and DE) × characteristic frequencies × cross detection × harmonics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Wavelet Packet Analysis</head><p>Dual-domain analysis methodologies that extract features from the time-frequency domain are represented in this work by wavelets <ref type="bibr" target="#b24">[26]</ref>, more specifically by the wavelet packet analysis, which allows a more flexible decomposition guided by information theory. Work describing the CWRU data by wavelet packets is found in <ref type="bibr" target="#b9">[11]</ref>- <ref type="bibr" target="#b12">[14]</ref> and <ref type="bibr" target="#b14">[16]</ref>. Here, the procedure proposed in <ref type="bibr" target="#b9">[11]</ref> is used. The mother wavelet is Daubechies 4, and refining is done down to the fourth decomposition level. A 1-D time-domain vibration signal of S samples is considered. With a tree depth of j, 2 j final leaves W j,0 , . . . , W j,2 j -1 were obtained. Each has approximately S/2 j wavelet coefficients. 1  The features from the final 2 j leaf nodes of the tree are the respective percentages of the energy of each leaf. Let c s j,n , s = 0, . . . , S/2 j -1 be the S/2 j wavelet coefficients of leaf node n at tree depth j, n = 0, . . . , 2 j -1. The energy of the nth node is</p><formula xml:id="formula_3">E j (n) = S/2 j -1 s=0 c s j,n 2 .</formula><p>(3)</p><p>Then, the nth wavelet packet feature is</p><formula xml:id="formula_4">x n = E j (n) 2 j -1 m=0 E j (m) . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>With a tree depth of j = 4, 16 final leaves W 4,0 , . . . , W 4,15 were obtained and, consequently, 16 features {x n |n = 0, . . . , 15} with 15 n=0</p><p>x n = 1. Since calculation is done at both the DE and the FE (cross detection), this number is duplicated to 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Feature Pooling and Dimensionality Reduction</head><p>After the acquisition of the different feature models, it is possible to merge them into a common pool. The cardinality of the feature pool is 130, composed of 26 statistical features, 72 complex envelope features, and 32 wavelet packet features. The features within this global set contain redundancy and noise. A consequent step is the reduction of the dimension of the feature vector to its final value. At this point, a possible dimensionality reduction technique could be feature extraction on the feature level, e.g., PCA or key performance indicator prediction and diagnosis <ref type="bibr" target="#b25">[27]</ref>. In <ref type="bibr" target="#b26">[28]</ref>, the Tennessee Eastman chemical process simulation software <ref type="bibr" target="#b27">[29]</ref> was employed, since it provides a research testbed for reproducible and comparable experiments. This simulator was also used as a benchmark in a model-based fault diagnosis system <ref type="bibr" target="#b28">[30]</ref>. The feature extraction techniques in <ref type="bibr" target="#b26">[28]</ref> were PCA, partial least squares, independent component analysis, Fisher discriminant analysis, and subspace-aided approach. These techniques belong to the 1 Exactly, if the original signal length S were a power of two.</p><p>feature extraction on the feature-level methods in Fig. <ref type="figure" target="#fig_1">1</ref>. To distinguish the methodology of this work, a conceptual and experimental comparison with PCA as a representative is included in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. FEATURE SELECTION</head><p>A feature selection algorithm is basically composed of a selection criterion and a search strategy. A subset of d from all D available features are preserved. Excellent review papers of feature selection methodologies are <ref type="bibr" target="#b15">[17]</ref> or <ref type="bibr" target="#b29">[31]</ref>. The wrapper approach in feature selection consists in taking the estimated performance of a classifier as the proper feature selection criterion. The performance criterion in the overwhelming part of past and contemporary work is the estimated accuracy of the classifier. This means that those features during the search are labeled as good that minimize the estimated error. In the context of fault diagnosis, an alternative performance criterion, the AUC-ROC in Section IV-B, will also be motivated.</p><p>The filter approach uses different criteria to judge a feature set or judge the performance of the classifier. Usually, the benefit of a selection filter is its speed, while its drawback is a possible performance inferior compared with that of a wrapper.</p><p>Since an exhaustive search is computationally unfeasible, suboptimal search strategies are chosen. The best feature (BF) search is simply evaluating a selection criterion J({x j }) for each feature x j , j = 1, . . . , D, ordering the features in descending order relative to J and setting the selected set X d to the first d features of the ordered set. BF is fast but ignores the multidimensionality of the problem. In the considered context of the fault classification of the CWRU bearing data, Mahamad and Hiyama in <ref type="bibr" target="#b2">[4]</ref> used a univariate, distance-based selection criterion.</p><p>Sequential forward selection (SFS) <ref type="bibr" target="#b15">[17]</ref> starts with an empty set and then tests each candidate together with the alreadyselected features. The feature that performed best is included in the already-selected set. The algorithm stops when the desired number of d features is reached.</p><p>Sequential backward selection (SBS) <ref type="bibr" target="#b15">[17]</ref> starts with all D available features being selected and then discards one feature at a time, until Dd features have been deleted, i.e., d features have been retained as the selected ones. Floating techniques <ref type="bibr" target="#b30">[32]</ref> allow backtracking for an arbitrary number of times as long as the quality criterion J is improving. As representatives for a complete sequential search strategy algorithm, sequential floating forward search (SFFS) and sequential floating backward search (SFBS) are used.</p><p>Recent approaches that try to combine wrapper and filter methods are not considered, since they would deviate attention from the innovative aspects of the proposed methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CLASSIFICATION AND PERFORMANCE ESTIMATION</head><p>Frequently, in CWRU-related work, the choice of a particular classifier architecture that decides the machine condition is not sufficiently motivated or its description is incomplete, which does not permit its implementation to compare results. Moreover, the way the data are split to evaluate the performance frequently leads to overoptimistic results. To maintain scientific rigor and allow comparison, it is necessary to use statistically sound and robust methods <ref type="bibr" target="#b31">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. CV Techniques</head><p>A simple unique division of the available machine condition patterns into x% training data, and 100 -x% test data potentially introduces a considerable bias for the estimated performance. A good compromise between statistical significance and computational complexity is to use K-fold CV, where the data set is divided into K subsets; each subset is used once for test and K -1 times for training. When the training time of the classifier is not excessive, the LOO CV can be used. LOO is a special case of K-fold CV where the total data set has N patterns; hence, K = N . LOO gives a more reliable estimate than simple train-test data division, since implicitly, each available pattern is tested. In the experiments, the LOO and K-fold CV are used, depending on the training costs of the classifier architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Criteria</head><p>Two criteria, judged as most appropriate for this application, are employed, namely, accuracy and AUC-ROC. The accuracy or, equivalently, its complement, i.e., the error rate, is most easily understandable to a human being. It constitutes the vast majority among the criteria in the considered literature and is also used in this research. When only two classes (positive and negative) are considered and the classifier returns a continuous score, ideally a probability estimate of the two classes, it is possible to use the AUC-ROC <ref type="bibr" target="#b18">[20]</ref>, <ref type="bibr" target="#b31">[33]</ref> as an alternative performance criterion. It can handle unbalanced classes in which negative class examples are usually much more common than positive ones, which is a situation frequently encountered in machine fault diagnosis, where the normal operation condition is dominant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Classifier Architectures</head><p>The k-nearest neighbor classifier <ref type="bibr" target="#b32">[34]</ref> represents the category of simple nonparametric methods. As a representative classifier from the area of artificial neural networks, MLP is proposed, trained by the scaled conjugate gradient algorithm <ref type="bibr" target="#b33">[35]</ref>. The SVM <ref type="bibr" target="#b34">[36]</ref> classification architecture has been extensively used during the last decade in many distinct domains, and also in machine fault diagnosis. It is currently considered one of the most powerful methods in machine learning and, therefore, is also represented in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head><p>As a testbed, vibration signals provided and publicly available from CWRU [3] were used. This choice is motivated by the fact that a pattern database that is accessible to the research community allows a fair comparison of the performance of the proposed algorithms. The database is organized as MATLAB/Octave processable vibration signal files, with all necessary parameters attached, needed to calculate the feature models described in Section II. The machine condition differs with respect to the fault severity, bearing manufacturer, motor load, sensor position, and acquisition frequency and duration.</p><p>The main components are the motor with a maximum power of 2 hp, the torque encoder, and a dynamometer for load simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Condition Classes</head><p>Table III lists the machine condition classes defined for the experiments. Note that the number of classes is much more extensive than that found usually in work related to the CWRU data. It was tried to distinguish among the different bearing fault locations derived from the models in Section II, the severity of the fault (i.e., the diameter of the artificially drilled hole into the material) and the position of the motor bearing (DE or FE). Even the different loads for the same fault were considered as separate classes, which constitutes the most challenging classification problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Signals to Patterns</head><p>The provided descriptor for a particular machine condition is a single high-resolution digital vibration signal with a duration of approximately 10 s. For instance, the file '234.mat', describing an outer race, 0.021 in diameter, 0-hp load fault, contains n = 122 426 samples, acquired at f s = 12 kHz, resulting in a duration of 10.20 s. Since the complete signal represents several periods of a rotational process, it is justifiable to simply chop the total duration into consecutive intervals and consider these as independent patterns acquired at different time instances. Preliminary tests suggested that 15 nonoverlapping intervals is a threshold beyond which performance starts to degrade; hence, this value was fixed in all experiments. Wang in <ref type="bibr" target="#b35">[37]</ref> seems to have taken the complete signal to extract the features, obtaining only eight different patterns, Yu in <ref type="bibr" target="#b17">[19]</ref> splits  the signal into 30 parts, and Sreejith et al. in <ref type="bibr" target="#b8">[10]</ref> divides the signal into 24 parts for the f s = 12 kHz data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experiment 1: Feature Extraction</head><p>Subjecting the CWRU bearing fault data to the feature extraction models defined in Section II, explicit feature vectors for representative machine conditions are provided. Table <ref type="table" target="#tab_3">IV</ref> presents the statistical features in the time and frequency domains, defined in Tables I and II of Section II-A for selected condition classes.</p><p>The 72 features obtained as the narrowband energy of the complex envelope magnitude described in Section II-B are pointed out in Table V. As an illustrative example, consider the inner-race fault of the DE bearing (6205-2RS JEM SKF). Six harmonics are used, but only the first two are shown. Consider, for instance, the second harmonic. Since the expected frequency is 5.4152 times the running speed of the machine (30 Hz), the focus is on 2 × 5.4152 × 30 Hz, i.e., 324.91 Hz. The 1% narrow band around this frequency is then defined by the interval [321.66, 328.16 Hz], from which the energy is calculated. In fact, in case of an inner-race fault, the value of 95.183 in the third column is much higher than when the fault is not present, for instance, when a ball fault is present, the value drops to 6.413.</p><p>Considering the next feature model, in Fig. <ref type="figure" target="#fig_2">2</ref>, the resulting wavelet packet tree is illustrated for two real CWRU examples. In order not to overburden the graph, only the first 0.1 s of the two signals were processed. Each node shows the reconstructed sample, using only the wavelet packet coefficients of that node. Two signals for the same inner-race fault are compared, however with different severities (7 and 21 mils). To elevate the contrast, the 7-mils case is the one acquired without load of the motor, and the 21-mils case is the one at 3-hp load. Qualitatively, it can be observed that the node energies do differ considerably, for instance, the leaves W 4,4 and W 4,12 and, consequently, the energy percentages allow a firm distinction between two severities. In Table <ref type="table" target="#tab_5">VI</ref>, the feature values for seven representative classes are shown. Each class has two sets of values (acquisition at the DE and the FE). From the table, it can be seen that, e.g., the W 4,0 energy portion is very elevated for the 'normal' class, such that a low value suggests a fault.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experiment 2: Performance Without Feature Selection</head><p>Table VII presents the estimated performance of the 1-NN, SVM, and MLP classifiers with data sets extracted by three different feature models and the merged pool of all features, joining the three models. All 130 features were used to train the classifier and run the test, i.e., no feature selection was performed. The 1-nearest neighbor classifier always uses LOO to estimate the performance parameters. For the SVM and MLP classifiers, this method is computationally too expensive; therefore, a tenfold CV was employed. To improve the robustness of the estimation, the mean over ten different of such tenfold runs was taken.</p><p>The results of Table <ref type="table" target="#tab_6">VII</ref> give a valuable feedback considering the classification task and the feature models. The accuracy (ACC) and AUC-ROC suggest that the CWRU data set is easy to distinguish with respect to the defined classes. The statistical feature model seems to be the least discriminative. The wavelet package energy is by itself the best feature model. The complete pool is not always the best feature model.</p><p>An analysis of the results provides a principal motivation of the need for the posterior feature selection. When pooling all feature models, the classification results degrade, since some features contain more noise than information. The subsequent feature selection can improve performance and simultaneously diminish the complexity of the feature model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Experiment 3: Feature Selection</head><p>In all feature selection graphs, for the SFS and SFFS algorithms, the horizontal axis represents the number of features selected. For the SBS and SFBS algorithms, the horizontal axis represents the number of features excluded. Fig. <ref type="figure" target="#fig_3">3</ref> shows the estimated accuracy of the 1-NN classifier using LOO CV during the process of feature selection. The algorithm uses the wrapper    In general, the floating techniques seem to perform better than the sequential search in the case of the wavelet package model.</p><p>The selected subset of all feature models together enters an error-free saturation in a very early stage. The analysis of this result emphasizes the main hypothesis of this work, namely, that selected features from the global feature pool have superior performance compared with the individual feature models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Experiment 4: AUC-ROC for Different Feature Models and Number of Selected Features</head><p>As mentioned earlier, the CWRU data set is easy to classify, even with a large number of classes. This implies that the feature selection curve enters a maximum performance score saturation area in an early stage. This is most evidently seen in the first graph in Fig. <ref type="figure" target="#fig_3">3</ref> where the global feature pool is used. To produce more readable ROC curves, the difficulty in separating the classes was artificially raised.  individually. The graphs show the result for one feature, two, all, and the number with best performance. The analysis of this experimental result corroborates the main hypothesis of this work, namely, that using simultaneously more than one feature model, in conjunction with feature selection, increases performance of the fault diagnosis system.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Experiment 5: Comparison of Feature Selection and Feature Extraction by PCA</head><p>Paying tribute to a consolidated dimensionality reduction technique in fault diagnosis, see, e.g., <ref type="bibr" target="#b26">[28]</ref> and <ref type="bibr" target="#b36">[38]</ref>; a comparison of feature selection to feature extraction is done, represented by its most prominent linear method, i.e., PCA. The basic difference is that PCA produces new features as a recombination of the existing ones, whereas feature selection leaves the original features unchanged. The new PC features are ranked by their variance. Since PCA is an unsupervised method, the maximization of variance does not necessarily augment class discernability. Table <ref type="table" target="#tab_8">IX</ref> shows the performance criteria for the KNN and SVM classifiers, comparing selection (SFS) and extraction (PCA). For accuracy estimation, all classes are separately considered. For AUC-ROC estimation, all classes in Table VIII are merged, except the second one in the table, which is considered as the positive class, cf., the previous ROC experiment in Section V-G. Selection performs better in all cases. The corresponding ROC curves obtained by PCA with the global feature pool are shown in Fig. <ref type="figure">6</ref> and with only the wavelet package model as the best individual feature model in Fig. <ref type="figure" target="#fig_6">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>The three particular feature models used in this work are well known, so are the classifier architectures and performance criteria. There is, however, a novelty approach in the information processing part. The process description is taken to a higher abstraction level by characterizing the process conditions by multiple heterogeneous feature models. This approach by itself would have a low impact on the discriminative power of the diagnosis system. Only if a posterior information filter in the form of feature selection is used, the general performance can be expected to improve. A considerable amount of publications try to compensate a poor feature model by an oversophisticated classifier model. In this paper, a different approach is taken. If a good process description is available, a simple classifier is sufficient. In this case, the description appears in the form of a selection of many available features, stemming from quite distinct sources. Of course, this work cannot formally prove that the idea of this paper has general value. The experiments, however, suggest that this approach is a promising methodology, extensible to other areas of industrial applications. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Heterogeneous</head><label></label><figDesc>Feature Models and Feature Selection Applied to Bearing Fault Diagnosis Thomas W. Rauber, Member, IEEE, Francisco de Assis Boldt, and Flávio Miguel Varejão Abstract-Distinct feature extraction methods are simultaneously used to describe bearing faults. This approach produces a large number of heterogeneous features that augment discriminative information but, at the same time, create irrelevant and redundant information. A subsequent feature selection phase filters out the most discriminative features. The feature models are based on the complex envelope spectrum, statistical time-and frequency-domain parameters, and wavelet packet analysis. Feature selection is achieved by conventional search of the feature space by greedy methods. For the final fault diagnosis, the k-nearest neighbor classifier, feedforward net, and support vector machine are used. Performance criteria are the estimated error rate and the area under the receiver operating characteristic curve (AUC-ROC). Experimental results are shown for the Case Western Reserve University Bearing Data. The main contribution of this paper is the strategy to use several different feature models in a single pool, together with feature selection to optimize the fault diagnosis system. Moreover, robust performance estimation techniques usually not encountered in the context of engineering are employed. Index Terms-Case Western Reserve University (CWRU) Bearing Fault Database, fault diagnosis, feature extraction, feature selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Computational intelligence framework for bearing fault diagnosis. (a) Generic model. (b) Instantiated model.</figDesc><graphic coords="2,125.39,70.01,347.42,315.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Reconstructed signal in wavelet packet tree of depth j = 4 for two inner-race faults, varying with respect to the fault severity and work load. Only the first 0.1 s of a single sample are processed and shown in order not to overburden the graph. (a) 0.007-in 0-hp inner-race fault signal decomposition. (b) 0.021-in 3-hp inner-race fault signal decomposition.</figDesc><graphic coords="7,76.67,70.49,434.54,357.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Estimated accuracy during feature selection for all features and the wavelet package model as a representative of the individual feature models, using the 1-NN classifier. (a) Selection from global feature pool. (b) Selection of wavelet package features.</figDesc><graphic coords="8,49.91,197.33,498.38,101.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>A 12-class set was considered, varying severity and work load of the ball fault in the FE, since it showed the worst AUC-ROC in preliminary experiments. Moreover, the signal sampling resolution was reduced, by augmenting the number of patterns obtained from a single signal from 15 to 50, which makes it harder to discern the patterns. Finally, only the first 2 s were used to sample the 50 patterns, instead of the original 10-s signals. A detailed description of the classes is pointed out in Table VIII. The second one is considered as the positive class. This fault of the ball at the FE was identified as the hardest to be distinguished in preliminary tests. The remaining eleven classes are merged into the negative class. Figs. 4 and 5 show the ROC curves for the global feature pool and the wavelet package model as the best individual feature model, respectively. The AUC-ROC performance criterion increases during feature selection, and additionally, the global feature pool performs better than all the other feature models</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. SVM classifier AUC-ROC for SFS with wavelet package feature model. Number of all features is 32; best set has 13 features.</figDesc><graphic coords="9,55.67,70.37,213.74,138.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. SVM classifier AUC-ROC for PCA with wavelet package feature model. Number of all components is 32; best set has 26 principal components. Positive class is the second in Table VIII.</figDesc><graphic coords="9,317.27,69.89,216.86,140.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Thomas W. Rauber (M'09) received the Diploma degree from the Fakultät für Informatik, Universität Karlsruhe (TH), Karlsruhe, Germany, in 1989 and the Ph.D. degree in electrical engineering from the Department de Engenharia Electrotécnica, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, Lisbon, Portugal, in 1995. He conducted postdoctoral research at AG ROSY/FB Informatik/TU Kaiserslautern, Germany in 2005/2006 and at Ludwig-Maximilian Universität (LMU), Munich, Germany, in 2012. Since 1996, he has been a Professor of computer science with the Department de Informática, Universidade Federal do Espírito Santo, Vitória, Brazil. His current research interests include pattern recognition, artificial neural networks, and fault diagnosis in industrial processes. Francisco de Assis Boldt received the P.Tech. degree from Centro Universitário do Espírito Santo, Colatina, Brazil, in 1998 and the M.Sc. degree in computer science from the Universidade Federal do Espírito Santo, Vitória, Brazil, in 2008, where he is currently working toward the Ph.D. degree in computer science. His research interests include computational intelligence applied to fault diagnosis. Flávio Miguel Varejão received the B.E. degree in civil engineering from the Universidade Federal do Espírito Santo, Vitória, Brazil, in 1987 and the M.Sc. and Ph.D. degrees in computer science from the Pontifícia Universidade Católica do Rio de Janeiro, Rio de Janeiro, Brazil, in 1991 and 1999, respectively. Since 1990, he has been a Professor of computer science with the Department de Informática, Universidade Federal do Espírito Santo. His research interests include pattern recognition and data-driven fault diagnosis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I TIME</head><label>I</label><figDesc>-DOMAIN STATISTICAL FEATURE SET OF THE VIBRATION SIGNAL COMPOSED OF N ACCELERATION AMPLITUDES x i</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II FREQUENCY</head><label>II</label><figDesc></figDesc><table /><note><p>-DOMAIN STATISTICAL FEATURE SET OF THE VIBRATION SIGNAL COMPOSED OF N FREQUENCY AMPLITUDES f i</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III CLASS</head><label>III</label><figDesc>DISTRIBUTION AND DESCRIPTION, WHERE DE MEANS DRIVE END AND FE MEANS FAN END</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV STATISTICAL</head><label>IV</label><figDesc>FEATURES IN THE TIME AND FREQUENCY DOMAINS EXTRACTED FROM REPRESENTATIVE MACHINE CONDITIONS. SIGNALS WERE ACQUIRED AT THE DE OR THE FE. IR =INNER RACE, OR =OUTER RACE. PERFORATION DIAMETER OF THE HOLES DRILLED INTO THE BEARING COMPONENTS FOR ALL FAULT TYPES WAS 0.021 in</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V NARROWBAND</head><label>V</label><figDesc>ENERGY OF THE COMPLEX ENVELOPE SPECTRUM</figDesc><table /><note><p>AT THE DE. ONLY TWO OF SIX HARMONICS ARE SHOWN</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI WAVELET</head><label>VI</label><figDesc>PACKET TREE FEATURE VECTORS AS THE ENERGY PERCENTAGE OF THE LEAF NODES FOR SEVEN MACHINE CONDITIONS AT THE DE. LOWER CASE d AND f INDICATE, RESPECTIVELY, THE ACCELEROMETER POSITION (DE, FE)</figDesc><table /><note><p>approach with the performance value as the proper selection criterion, i.e., the estimated accuracy in this case. All three feature models are tested, plus the global pool. Only the wavelet package graph is shown; the statistical and envelope features exhibit a similar behavior. For the global pool, SFFS and SFBS have identical behavior as SFS and SBS, respectively.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII PERFORMANCE</head><label>VII</label><figDesc>(ACCURACY AND AUC-ROC) OF THREE CLASSIFIERS USING DATASETS WITH DIFFERENT FEATURE EXTRACTION MODELS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VIII CLASSES</head><label>VIII</label><figDesc>OF THE SPECIAL AUC-ROC DATASET, VARYING FAULT SEVERITY</figDesc><table /><note><p>AND LOAD FOR THE FAN END BALL FAULT Fig. 4. SVM classifier AUC-ROC for SFS with the global feature pool. Number of all features is 130, best set has 20 features.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE IX BALL</head><label>IX</label><figDesc>FE FAULT CLASSIFICATION PERFORMANCE. CRITERION SHOWN TOGETHER WITH OPTIMAL NUMBER OF FEATURES</figDesc><table /><note><p><p>OR PRINCIPAL COMPONENTS Fig. 6. SVM classifier AUC-ROC for PCA with the global feature pool. Number of all nonzero components is 127; best set has nine principal components. Positive class is the second in Table VIII</p>.</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meshgin-Kelk</surname></persName>
		</author>
		<title level="m">Electric Machines Modeling: Condition Monitoring and Fault Diagnosis</title>
		<meeting><address><addrLine>Boca Raton, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledge modeling-State of the art</title>
		<author>
			<persName><forename type="first">V</forename><surname>Devedzic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Integr. Comput.-Aid. Eng</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="281" />
			<date type="published" when="2001-08">Aug. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fault classification based artificial intelligent methods of induction motor bearing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mahamad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Innov. Comput., Inf. Control</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5477" to="5494" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A numerical model to predict damaged bearing vibrations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B M</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vib., Control</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1603" to="1628" />
			<date type="published" when="2007-11">Nov. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Signal analysis of vibration measurements for condition monitoring of bearings</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chebil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hrairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Abushikhah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australian J. Basic Appl. Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="78" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-scale analysis based ball bearing defect diagnostics using Mahalanobis distance and support vector machine</title>
		<author>
			<persName><forename type="first">S.-D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="416" to="433" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Kernel Fisher discriminant analysis for bearing fault diagnosis</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2005-08">Aug. 2005</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="3216" to="3220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fault diagnosis of rolling bearing based on wavelet transform and envelope spectrum correlation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Palazoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vib., Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="924" to="941" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fault diagnosis of rolling element bearing using time-domain features and neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sreejith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srividya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd IEEE ICIIS Region</title>
		<meeting>3rd IEEE ICIIS Region</meeting>
		<imprint>
			<date type="published" when="2008-12">Dec. 2008</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Spectral regression based fault feature extraction for bearing accelerometer sensor signals</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="13" to="694" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Shannon wavelet spectrum analysis on truncated vibration signals for machine incipient fault detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Meas. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">55604</biblScope>
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A kurtosis-guided adaptive demodulation technique for bearing fault detection based on tunable-Q wavelet transform</title>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Meas. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Incipient fault diagnosis of rolling element bearing based on wavelet packet transform and energy operator</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WSEAS Trans. Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="81" to="90" />
			<date type="published" when="2011-03">Mar. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rolling bearing fault diagnostics using artificial neural networks based on Laplace wavelet analysis</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Al-Raheem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Abdul-Karem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Eng., Sci. Techn</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="278" to="290" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Wavelet decomposition for the detection and diagnosis of faults in rolling element bearings</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chebil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mesbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jordan J. Mech. Ind. Eng</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="260" to="267" />
			<date type="published" when="2009-12">Dec. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An introduction to variable and feature selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1157" to="1182" />
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bearing fault diagnosis based on multiscale permutation entropy and support vector machine</title>
		<author>
			<persName><forename type="first">S.-D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1343" to="1356" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bearing performance degradation assessment using locality preserving projections</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="7440" to="7450" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An introduction to ROC analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006-06">Jun. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bearing faults detection by a novel condition monitoring scheme based on statistical-time features and neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Delgado</forename><surname>Prieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cirrincione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garcia Espinosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Henao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3398" to="3407" />
			<date type="published" when="2013-08">Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Advanced diagnosis of electrical faults in wound rotor induction machines</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gritli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4012" to="4024" />
			<date type="published" when="2013-09">Sep. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Statistical and neural-network approaches for the classification of induction machine faults using the ambiguity plane representation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Boukra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebaroud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Clerc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4034" to="4042" />
			<date type="published" when="2013-09">Sep. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Plastic bearing fault diagnosis based on a twostep data mining approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3429" to="3440" />
			<date type="published" when="2013-08">Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Mobley</surname></persName>
		</author>
		<title level="m">Root Cause Failure Analysis</title>
		<meeting><address><addrLine>Woburn, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Butterworth-Heinemann</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>Plant Engineering Maintenance Series</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Theory and Applications for Manufacturing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wavelets</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A novel scheme for key performance indicator prediction and diagnosis with application to an industrial hot strip mill</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2239" to="2247" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A comparison study of basic data-driven fault diagnosis and process monitoring methods on the benchmark Tennessee Eastman process</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Process Control</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1567" to="1581" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A plant-wide industrial process control problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Downs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Chem. Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="255" />
			<date type="published" when="1993-03">Mar. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Real-time implementation of fault-tolerant control systems with performance optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2402" to="2411" />
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Comparison of algorithms that select features for pattern classifiers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sklansky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="41" />
			<date type="published" when="2000-01">Jan. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Floating search methods in feature selection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pudil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novovičová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1119" to="1125" />
			<date type="published" when="1994-11">Nov. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Evaluating Learning Algorithms: A Classification Perspective</title>
		<author>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Cambridge Univ. Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Nearest neighbor pattern classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="1967-01">Jan. 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A scaled conjugate gradient algorithm for fast supervised learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Møller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="525" to="533" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995-09">Sep. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Classification of fault location and the degree of performance degradation of a rolling bearing based on an improved hypersphere-structured multi-class support vector machine</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Process</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="404" to="414" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A new framework of simultaneous-fault diagnosis using pairwise probabilistic multi-label classification for time-dependent patterns</title>
		<author>
			<persName><forename type="first">C.-M</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-F</forename><surname>Ip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3372" to="3385" />
			<date type="published" when="2013-08">Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
