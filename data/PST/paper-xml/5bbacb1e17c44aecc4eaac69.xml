<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph CNN for Survival Analysis on Whole Slide Pathological Images</title>
				<funder ref="#_BqgCATC #_z3vMf63 #_SkUcPUM">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_TDuDTwr #_FX2nJZH">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ruoyu</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<postCode>518057</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiawen</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<postCode>518057</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinliang</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<postCode>518057</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yeqing</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<postCode>518057</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
							<email>jzhuang@uta.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<postCode>518057</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graph CNN for Survival Analysis on Whole Slide Pathological Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1007/978-3-030-00934-2_20</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep neural networks have been used in survival prediction by providing high-quality features. However, few works have noticed the significant role of topological features of whole slide pathological images (WSI). Learning topological features on WSIs requires dense computations. Besides, the optimal topological representation of WSIs is still ambiguous. Moreover, how to fully utilize the topological features of WSI in survival prediction is an open question. Therefore, we propose to model WSI as graph and then develop a graph convolutional neural network (graph CNN) with attention learning that better serves the survival prediction by rendering the optimal graph representations of WSIs. Extensive experiments on real lung and brain carcinoma WSIs have demonstrated its effectiveness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Survival analysis is generally a set of statistical models where the output is the elapsed time until a certain event occurs. The event can range from vehicle part failure to adverse drug reaction. Clinical trials are aimed to assess different treatment regimes with the biological death as primary event of interest to observe. An accurate estimate of survival probability provides invaluable information for clinical interventions.</p><p>The Cox proportional hazards model <ref type="bibr" target="#b2">[3]</ref> is most popular in survival analysis. However, the classical Cox model and its early followers overly simplified the patient's survival probability as linear mapping from covariates. Recently, Katzman et al. designed a fully connected network (DeepSurv <ref type="bibr" target="#b8">[9]</ref>) to learn the nonlinear survival functions. Although it was showed that neural networks outperformed the linear Cox model <ref type="bibr" target="#b3">[4]</ref>, it cannot directly learn from pathological images. Along with the success of convolutional neural networks (CNNs) on generic images, pathological image, as well as CT and MRI <ref type="bibr" target="#b13">[14]</ref>, have become ideal data sources for training DL-based survival models. Among them, whole slide image (WSI) <ref type="bibr" target="#b11">[12]</ref> is one of the most valuable data formats due to the massive multi-level pathological information on nidus and its surrounding tissues.</p><p>WSISA <ref type="bibr" target="#b21">[21]</ref> was the first trial of moving survival prediction onto whole slide pathological images. To have a efficient approach on WSIs, a patch sampling on WSIs is inevitable. However, their DeepConvSurv model was trained on clustered patch samples separately. Consequently, the features extracted were overlocalized for WSIs because the receptive field is constrained within physical area corresponding to a single patch (0.063 mm 2 ). The pathological sections of nidus from patients contain more than the regions of interest (e.g tumor cells), therefore, the representations from random patch may not strongly correspond to the disease. Furthermore, it has been widely recognized that the topological properties of instances on pathological images are crucial in medical tasks, e.g. cell subtype classification and cancer classification. While, WSISA is neither able to learn global topological representations of WSIs nor to construct feature maps upon given topological structures.</p><p>Graph is widely employed to represent topological structures. However, modeling a WSI as graph is not straightforward. Cell-graph <ref type="bibr" target="#b5">[6]</ref> is infeasible for WSIs due to its huge number of cells and the many possible noisy nodes (isolated cells). The intermediate patch-wise features are a good option to construct graph with, balancing efficiency and granularity. However, applying CNNs on graphstructured data is still difficult.</p><p>In </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Graph Construction on WSI: Given a set of sampled patch images P = {P i } from WSI, we have to dump those patches from the margin areas which contains few cells, therefore, the cardinality P differs by WSI. Consequently, the graphs we construct for WSIs are of different sizes. Given patches as vertices, vertex features are generated by the VGG-16 network pre-trained on ImageNet. Due to the lack of patch labels, we cannot fine-tune the network on WSI patches. We will introduce how graph CNN model mitigates this deficiency in next section. Graph edges were constructed by thresholding the Euclidean distances between patch pairs, which were calculated using the 128 features compressed from the VGG-16 outputs with patches as input. Compressions are committed separately on train and test sets by principal component analysis (PCA). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spectral Graph Convolution. Given a graph</head><formula xml:id="formula_0">G = (V, E), its normalized graph Laplacian L = I -D -1/2 AD -1/2</formula><p>, where A is the adjacency matrix and D is the degree matrix of G. The graph on WSI is irregular with ?(G) ?(G). A spectral convolutional filter built based on spectral graph theory <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b20">20]</ref> is more applicable to irregular WSI graph. It was proved that a spectrum formed by smooth frequency components leads to a localized spatial kernel. Furthermore, <ref type="bibr" target="#b4">[5]</ref> formulated kernel as a K th order polynomial of diagonal ?, and diag(?) is the spectrum of graph Laplacian L:</p><formula xml:id="formula_1">g ? (? K ) = K-1 k=0 ? k ? k . (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>Based on theorem from <ref type="bibr" target="#b1">[2]</ref>, spectral convolution on graph G with vertex features X ? R N ?F as layer input is formulated as:</p><formula xml:id="formula_3">Y = ReLU g ? (L K )X . (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>ReLU is activation function. Output Y ? R N ?F is a graph of identical number of vertices with convolved features. The learning complexity of K-localized kernel is O(K). To have a fast filtering, <ref type="bibr" target="#b4">[5]</ref> used Chebyshev expansion as approximation of g ? (L), Recursive calculation of g ? (L K ) reduces the time cost from O(KN 2 ) to O(KS), S ( N 2 ) is the count of nonzeros in L. Sparseness of L was enforced by edge thresholding when graph construction. Initial WSI graph G was built upon compressed patch features. The VGG-16 feature network was not fine-tuned on WSI patches due to the lack of patch labels. Patient-wise censored survival label is absolutely infeasible for a patch-wise training. Therefore, the initial graph may not correctly represent the topological structures between patches on WSI.</p><p>Survival-Specific Graph. The deficiency of initial graph results from the insufficiently trained feature network. It has two problems: (1) network used irrelevant supervision (i.e ImageNet label); (2) network was not fine-tuned on pathological images. It would be better, if the patch features could be fine-tuned with survival censor labels. To achieve it, we design a separate graph G and L to describe the specific survival-related topological relationship between WSI patches <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref>. L is learned individually on each WSI. Direct learning of L is impractical because of the graph size and the uniqueness of topology on WSIs. Instead of learning and storing graph edges, we learn the Mahalanobis distance metrics M for evaluating edge connectivity. If d is the dimensionality of feature, the learning complexity is reduced from O(N 2 ) to O(d 2 ). Because there is no priors on metrics, M has to be randomly initialized. To accelerate the convergence, we keep initial graph as regularization term for survival-specific graph. The final graph Laplacian in convolution will be L(M, X) = L(M, X) + ?L. ? is trade-off coefficient. With survival-specific graph, the proposed graph convolution is formulated as:</p><formula xml:id="formula_5">Y = ReLU g ? (L(M, X) K )X . (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>Afterwards, there is a feature transform operator parameterized as W ? R Fin?Fout and bias b ? R Fout applied to output Y : Y = Y W + b. This reparameterization on activations will lead to a better imitation of CNNs, whose output features are mappings of all input feature dimensions. Model parameters {M, ?} get updated by back-propagation w.r.t. survival loss, which promises fine-tuned features and graphs optimized for survival analysis purpose.</p><p>Graph Attention Mechanism. Generally, there are merely a few local regions of interest (RoIs) on WSIs matter in survival analysis. Random sampling cannot guarantee patches are all from RoIs. Attention mechanism provides an adaptive patch selection by learning "importance" on them. In DeepGraphSurv, there is a parallel network to learn attention on nodes conditioned on node features. The network consists of two proposed GCN layers (Eq. 3). The outputs of attention network are node attention values: ? = f attn (X). Given learned attentions, the output risk R for X on graph G(V, E) is the weighted sum of Y n of each node n:</p><formula xml:id="formula_7">R = n f attn (X) n Y n , n ? {0, ? ? ? , V }. (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>As shown above, in graph gather layer (Fig. <ref type="figure" target="#fig_0">1</ref>), the learned attentions are multiplied onto the node-wise predictions when aggregating attentive graph outputs. The attention network will be trained jointly with the prediction network. Different from previous DL-based survival models that basically act as feature extractor <ref type="bibr" target="#b21">[21]</ref>, DeepGraphSurv directly generates predicted risks. We integrated regression of survival risk with graph feature learning on WSIs. The loss function is negative Cox log partial likelihood for censored survival data:</p><formula xml:id="formula_9">L(R) = i?{i:Si=1} (-R i + log j?{j:Tj &gt;=Ti} exp(R j )). (<label>5</label></formula><formula xml:id="formula_10">)</formula><p>S i , T i are respectively the censor status and the survival time of i-th patient. The fine-tuned patch features and the survival-specific graphs of WSIs are accessible at each proposed GCN layer, while the later layers offer more high-level topologyaware features of WSI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>As to the raw data source, we utilized the whole slide pathological images from a generic cancer patient dataset TCGA, publicly released by The Cancer Genome Atlas project <ref type="bibr" target="#b7">[8]</ref>. The research studied what and how errors in DNA trigger the occurrence of 33 cancer subtypes. We tested our model on two cancer subtypes from TCGA data: glioblastoma multiforme (GBM) and lung squamous cell carcinoma (LUSC). Besides, NLST (National Lung Screening Trials <ref type="bibr" target="#b9">[10]</ref>) employed 53,454 heavy smokers of age 55 to 74 with at least 30-year smoking history as high risk group for lung cancer survival analysis. We also committed an experiment on a subset of NLST database that consists of both squamous-cell carcinoma (SCC) and adenocarcinoma (ADC) patients' WSIs to evaluate the performance of our model on mixed cancer subtype dataset. Some quantitative facts of WSI used in the experiments are listed in Table <ref type="table" target="#tab_1">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">State-of-the-Art Methods</head><p>The baseline survival methods include: LASSO-Cox model <ref type="bibr" target="#b18">[18]</ref>, BoostCI <ref type="bibr" target="#b17">[17]</ref> and Multi-Task Learning model for Survival Analysis (MTLSA) <ref type="bibr" target="#b16">[16]</ref>. However, their effectiveness largely depends on the quality of hand-crafted features. Moreover, they were entirely not designed for WSI based survival analysis. For a fair comparison, we first feed those models with the features extracted by CellProfiler <ref type="bibr" target="#b10">[11]</ref>, e.g cell shape and textures, sampled and averaged over patch images. Then, we feed them with the WSI features generated by DeepGraphSurv from the same group of patient in order to demonstrate the gain of performance brought by the fine-tuned topology-aware WSI features only.</p><p>Besides classical models, we compared DeepGraphSurv with the state-of-theart deep learning based survival models on WSI. WSISA <ref type="bibr" target="#b21">[21]</ref> worked on clustered patches from WSIs, however, they simply neglected the topological relationship of the instances on WSI, which is also of great importance on survival analysis. Graph CNNs have recognized power of mining structured features on graph data. We concatenate the latest spectral GCN model <ref type="bibr" target="#b4">[5]</ref>, working on pre-trained fixed graphs, with a Cox regression as one of comparison methods in order to confirm the advantages brought by adding proposed survival-specific graphs onto GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Result and Discussion</head><p>As far as we know, DeepGraphSurv is the first survival model that used attention scheme. Figure <ref type="figure" target="#fig_1">2</ref> shows that, after 40 epoch, the regions of high attention on a WSI have correctly highlighted the most of RoIs annotated by medical experts. This interpreted part of global structural knowledge we have discovered on WSI. The concordance probability (C-index) is the fraction of all pairs of patients whose predicted survival times are correctly ordered as all censored patients that can be reasonably ordered. Forming survival order as graph G t (D, E) whose edge E i,j implies T i &lt; T j , the C-index is:</p><formula xml:id="formula_11">C(D, G t , f(x)) = 1 E Ei,j 1 f (xi)&lt;f (xj )</formula><p>, where 1 f (xi)&lt;f (xj ) is the indicator function:</p><formula xml:id="formula_12">1 a&lt;b = 1 if a &lt; b, otherwise 0. f (x i )</formula><p>is the predicted risk of x i . When a patient has multiple WSIs, the predicted risks were first averaged for the patient before calculating C-index.</p><p>The C-index results are reported in Table <ref type="table" target="#tab_2">2</ref>. Training and testing sets were randomly splitted and separately prepared. The classical survival models, e.g LASSO-Cox, cannot perform well was because they only utilize hand-crafted features. Possible issues include: (1) patches are partial representations of WSI;</p><p>(2) the data quality of patch may vary. Consequently, the features collected from random patches brought noisy and biased representations of WSI. Moreover, the features from CellProfiler are general descriptors of pathological images. After feeding them with the WSI features generated by DeepGraphSurv, the C-index were largely lifted by 0.04 on average on NLST and LUSC. This outcome showed that the features fine-tuned with survival labels are indeed better representations of WSI for survival analysis purpose.</p><p>However, we also observe that, due to the lower image quality, only using finetuned patch features cannot improve prediction on GBM data. DeepGraphSurv generates predictions by encoding patch features with their topological structure via convolution. When patch features are unreliable, topological structure of WSI instances makes more sense in recognition of survival patterns. This may explain the lift by DeepGraphSurv compared to <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">21]</ref> who learn little from topology. The previous GCN <ref type="bibr" target="#b4">[5]</ref> outperformed WSISA <ref type="bibr" target="#b21">[21]</ref> on most of datasets because it can aggregate node features as graph representation of WSI according to graph structure, while <ref type="bibr" target="#b21">[21]</ref> cannot. However, <ref type="bibr" target="#b4">[5]</ref> still worked on unsupervised graphs obtained with noisy VGG-16 features. DeepGraphSurv conducted convolution on the fine-tuned survival-specific graphs that were trained to represent the survivalrelated topological structures on each individual WSI. This improved C-index by another 0.03 on average, which again verified that the topological features trained in supervised way work better than that learned from unsupervised approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Survival prediction is a useful clinical intervention tool, although it cannot act as expected in many scenarios. Efficient mining of survival-related structured features on whole slide images is a promising solution of boosting survival analysis.</p><p>In this paper, we suggested to model WSI as graph and proposed DeepGraph-Surv to learn global topological representations of WSI. Instead of unsupervised graph, DeepGraphSurv creatively utilized a survival-specific graph trained under supervision of survival labels. The effectiveness of our model has been confirmed by improved accuracy of risk ranking on multiple cancer patient datasets across carcinoma subtypes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The architecture of DeepGraphSurv. An example of graph with 6 nodes on WSI constructed based on the 128 compressed VGG-16 features from 6 random patches. In real experiments, we sample 1000+ patches (as graph nodes) on WSI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Left: annotation of RoIs; Right: learned attention map. The yellow color marks the regions of high attention values on WSI. (Best viewed in color)</figDesc><graphic url="image-10.png" coords="6,87.48,232.31,277.84,115.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>reduces randomness of patch sampling and there- fore increases model robustness. As far as we know, DeepGraphSurv is the first GCN based survival prediction model with WSIs as input. Extensive experi- ments on cancer patient WSI datasets demonstrate that our model outperforms the state-of-the-art models by providing more accurate survival risk predictions.</head><label></label><figDesc></figDesc><table><row><cell>the paper, we propose a graph convolutional neural network (GCN) based</cell></row><row><cell>survival analysis model (DeepGraphSurv) where global topological features of</cell></row><row><cell>WSI and local patch features are naturally integrated via spectral graph con-</cell></row><row><cell>volution operators. The contributions are summarized as: (1) learn both local</cell></row><row><cell>and global representations of WSIs simultaneously: local patch features are</cell></row><row><cell>integrated with global topological structures through convolution; (2) task-</cell></row><row><cell>driven adaptive graphs induce better representations of WSI; (3) introducing</cell></row><row><cell>graph attention mechanism</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Dataset Statistics. Some patients may have multiple WSIs on record. Avg. size is the mean image size of WSI on disk.</figDesc><table><row><cell cols="6">Database Cancer Subtype No. Patient No. WSI Quality Avg. Size</cell></row><row><cell>TCGA</cell><cell>LUSC</cell><cell>463</cell><cell>535</cell><cell cols="2">Medium 0.72 GB</cell></row><row><cell>TCGA</cell><cell>GBM</cell><cell>365</cell><cell>491</cell><cell>Low</cell><cell>0.50 GB</cell></row><row><cell>NLST</cell><cell>ADC &amp; SCC</cell><cell>263</cell><cell>425</cell><cell>High</cell><cell>0.74 GB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>C-index Table.indicates that the model was trained and tested with the features generated by DeepGraphSurv.</figDesc><table><row><cell>Model</cell><cell>LUSC GBM</cell><cell>NLST</cell></row><row><cell>LASSO-Cox [18]</cell><cell cols="2">0.5280 0.5574 0.4738</cell></row><row><cell>LASSO-Cox</cell><cell cols="2">0.5663 0.5165 0.5663</cell></row><row><cell>BoostCI [17]</cell><cell cols="2">0.5633 0.5543 0.5705</cell></row><row><cell>BoostCI</cell><cell cols="2">0.5800 0.5130 0.5716</cell></row><row><cell>EnCox [19]</cell><cell cols="2">0.5216 0.5597 0.4883</cell></row><row><cell>EnCox</cell><cell cols="2">0.5740 0.5231 0.5742</cell></row><row><cell>RSF [7]</cell><cell cols="2">0.5066 0.5570 0.5964</cell></row><row><cell>RSF</cell><cell cols="2">0.5492 0.5193 0.5491</cell></row><row><cell>MTLSA [16]</cell><cell cols="2">0.5386 0.5787 0.6042</cell></row><row><cell>MTLSA</cell><cell cols="2">0.5247 0.5630 0.5573</cell></row><row><cell>WSISA [21]</cell><cell cols="2">0.6380 0.5760 0.6539</cell></row><row><cell>GCN-Cox [5]</cell><cell cols="2">0.6280 0.5901 0.6845</cell></row><row><cell cols="3">DeepGraphSurv 0.6606 0.6215 0.7066</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work was partially supported by <rs type="funder">NSF</rs> <rs type="grantNumber">IIS-1423056</rs>, <rs type="grantNumber">CMMI-1434401</rs>, <rs type="grantNumber">CNS-1405985</rs>, <rs type="grantNumber">IIS-1718853</rs> and the <rs type="funder">NSF</rs> <rs type="grantName">CAREER grant</rs> <rs type="grantNumber">IIS-1553687</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BqgCATC">
					<idno type="grant-number">IIS-1423056</idno>
				</org>
				<org type="funding" xml:id="_TDuDTwr">
					<idno type="grant-number">CMMI-1434401</idno>
				</org>
				<org type="funding" xml:id="_FX2nJZH">
					<idno type="grant-number">CNS-1405985</idno>
				</org>
				<org type="funding" xml:id="_z3vMf63">
					<idno type="grant-number">IIS-1718853</idno>
					<orgName type="grant-name">CAREER grant</orgName>
				</org>
				<org type="funding" xml:id="_SkUcPUM">
					<idno type="grant-number">IIS-1553687</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incremental eigenpair computation for graph laplacian matrices: theory and applications</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soc. Netw. Anal. Min</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Chung</surname></persName>
		</author>
		<title level="m">Spectral Graph Theory</title>
		<meeting><address><addrLine>Providence</addrLine></address></meeting>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Regression models and life-tables</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Society. Ser. B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="187" to="220" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Predicting interval time for reciprocal link creation using survival analysis</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soc. Netw. Anal. Min</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3837" to="3845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The cell graphs of cancer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gunduz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Gultekin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>suppl 1</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kalbfleisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Prentice</surname></persName>
		</author>
		<title level="m">The Statistical Analysis of Failure Time Data</title>
		<meeting><address><addrLine>Hoboken</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">360</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mutational landscape and significance across 12 major cancer types</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kandoth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">502</biblScope>
			<biblScope unit="issue">7471</biblScope>
			<biblScope unit="page" from="333" to="339" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Katzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cloninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kluger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00931</idno>
		<title level="m">Deep survival: a deep cox proportional hazards network</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lung cancer screening with low-dose helical CT: results from the national lung screening trial (NLST)</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Aberle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Prorok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Screen</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="109" to="111" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lamprecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Sabatini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cellprofiler TM : free, versatile software for automated biological image analysis</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">71</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast regions-of-interest detection in whole slide histopathology images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-28194-0_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-28194-015" />
	</analytic>
	<monogr>
		<title level="m">Patch-MI 2015</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Coup?</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Zhan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Munsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9467</biblScope>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning graph while training: an evolving graph convolutional neural network</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04675</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast preconditioning for accelerated multi-contrast MRI reconstruction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24571-3_84</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24571-384" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9350</biblScope>
			<biblScope unit="page" from="700" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03226</idno>
		<title level="m">Adaptive graph convolutional neural networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A multi-task learning formulation for survival analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1715" to="1724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Boosting the concordance index for survival data-a unified framework to derive and evaluate biomarker combinations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">84483</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The lasso method for variable selection in the cox model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Med</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="385" to="395" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A cocktail algorithm for solving the elastic net penalized cox&apos;s regression in high dimensions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Interface</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="173" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Name disambiguation in anonymized graphs using network embedding</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 26th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wsisa: making survival prediction from whole slide histopathological images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="7234" to="7242" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
