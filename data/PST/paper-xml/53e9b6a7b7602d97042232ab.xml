<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Median Filtering Forensics Using An Autoregressive Model 1</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiangui</forename><surname>Kang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anjie</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><forename type="middle">C</forename><surname>Stamm</surname></persName>
							<email>mcstamm@umd.edu</email>
						</author>
						<author>
							<persName><forename type="first">K</forename><forename type="middle">J Ray</forename><surname>Liu</surname></persName>
							<email>kjrliu@umd.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>MD20742</postCode>
									<settlement>College Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Information Sci. &amp;Tech</orgName>
								<orgName type="institution">Sun Yat-Sen University</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<region>GD</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">with Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>MD20742</postCode>
									<settlement>College Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Median Filtering Forensics Using An Autoregressive Model 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C0ECB697F507E52A32466EFF81C50904</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In order to verify the authenticity of digital images, researchers have begun developing digital forensic techniques to identify image editing. One editing operation that has recently received increased attention is median filtering. While several median filtering detection techniques have recently been developed, their performance is degraded by JPEG compression. These techniques suffer similar degradations in performance when a small window of the image is analyzed, as is done in localized filtering or cut-andpaste detection, rather than the image as a whole. In this paper, we propose a new, robust median filtering forensic technique. It operates by analyzing the statistical properties of the median filter residual (MFR), which we define as the difference between an image in question and a median filtered version of itself. To capture the statistical properties of the MFR, we fit it to an autoregressive (AR) model. We then use the AR coefficients as features for median filter detection. We test the effectiveness of our proposed median filter detection techniques through a series of experiments. These results show that our proposed forensic technique can achieve important performance gains over existing methods, particularly at low false positive rates, with very small dimension of features.</p><p>I.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Because digital images can be easily edited, it is often difficult to tell if a digital image has been manipulated. To combat this problem, researchers have developed a variety of blind forensic techniques to verify the authenticity of digital images <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>. Many of these techniques operate by searching for imperceptible traces, known as fingerprints, that are introduced into an image by editing operations. By identifying these fingerprints, a forensic investigator can determine if and how an image was manipulated. A number of forensic techniques <ref type="bibr" target="#b21">[22]</ref> currently exist to detect the use of resampling <ref type="bibr" target="#b4">[5]</ref>, contrast enhancement <ref type="bibr" target="#b5">[6]</ref>, multiple compression <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, sharpening <ref type="bibr" target="#b20">[21]</ref>, and blurring <ref type="bibr" target="#b21">[22]</ref>.</p><p>One image editing operation that has received increased attention from digital forensic researchers is median filtering <ref type="bibr" target="#b0">[1]</ref> - <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr">[25]</ref>. Median filtering is a nonlinear operation that has the useful property of preserving edges within an image. It is commonly used to perform image denoising, remove outlying pixel values, and to smooth regions of an image. Because of this, forgers may use median filtering to make their image forgeries appear more perceptually realistic.</p><p>In addition, the median filter's nonlinear properties make it useful for removing fingerprints left by other editing operations. It is has recently been incorporated into antiforensic algorithms designed to hide traces of resampling <ref type="bibr" target="#b8">[9]</ref> and evidence of compression <ref type="bibr" target="#b6">[7]</ref>. Furthermore, median filtering may affect the effectiveness of different steganalysis techniques <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p><p>While existing techniques have been developed to detect the use of median filtering <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref>, their performance is degraded in several important scenarios. This is particularly true when these detectors are held to low false positive rates. For example, the performance of existing median filtering detectors declines noticeably when testing on an image that has been JPEG compressed. This is problematic since many images are JPEG compressed during storage, capture, or transmission. Furthermore, the performance of these techniques degrades severely when small windows of an image are analyzed for evidence of localized median filtering. Additionally, existing techniques can encounter difficulties distinguishing median filtering from other editing operations at low false positive rates.</p><p>In this paper, we propose a new, robust median filtering forensic technique. It operates by analyzing the statistical properties of an image's median filter residual (MFR), which we define as the difference between an image in question and a median filtered version of itself <ref type="bibr" target="#b22">[23]</ref>. This differs from existing techniques, which extract median filtering detection features directly from an image's pixel values or the pixel difference. By analyzing an image's MFR, we are able to suppress image content which may interfere with median filtering detection. To capture the statistical properties of the MFR, we fit it to an autoregressive (AR) model. We then train a support vector machine (SVM) to use the AR coefficients as features for median filter detection.</p><p>We test the effectiveness of our proposed median filter detection techniques through a series of experiments. Our experimental results show that the MFR can be used to detect median filtering in JPEG compressed images with quality factors as low as 30and in image windows as small as 32 × 32 pixels. It is capable of differentiating 3x3 median filtering from 5×5 median filtering. Additionally, our proposed method can distinguish between median filtering and other manipulations, such as Gaussian filtering, average filtering, and rescaling. Our experimental results demonstrate that our proposed method not only achieves better performance than existing median filtering detection techniques, but it does so using a substantially smaller feature set.</p><p>The rest of this paper is organized as follows. We review existing work on median filtering detection in Section 2. In Section 3, the median filter residual is introduced and our proposed detection technique is described. In Section 4, we evaluate the performance of our proposed algorithm and compare its performance with state-of-the-art techniques <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Finally, we conclude this paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND AND PRIOR WORK</head><p>The median filter operates by replacing a pixel's value with the median value of the pixels in a small window surrounding it. The most commonly used median filter windows are squares of size 3 × 3 and 5 × 5 pixels. For the purposes of this work, we assume that median filtering is performed using a square w × w pixel window, where w is odd. Given an image, we can formally define the w × w median filter as </p><formula xml:id="formula_0">x i j x i h j v h v - - = + + ∈-<label>(1</label></formula><p>) where x(i, j) is the pixel value at point (i, j), i,j∈Z. A well known property of the median filter is that unlike linear filters, it is capable of smoothing an image while preserving its edges. As a result, the median filter is often used as a denoising filter.</p><p>Given a stochastic input to the median filter, the median filter's highly nonlinear nature makes it difficult to theoretically analyze the relationship between its input and output. Bovik was able to demonstrate that median filtering often produces constant or nearly constant regions called streaks within an image <ref type="bibr" target="#b9">[10]</ref>. Bovik analyzed this phenomenon quantitatively and obtained the probability that the median values stemming from overlapping windows are equal <ref type="bibr" target="#b9">[10]</ref>.</p><p>Early forensic work capable of detecting median filtering made use of fingerprints left by a digital camera's color filter array (CFA) pattern and interpolation coefficients. Swaminathan et al. modeled tampering operations as linear filters, then estimated the tamper filter applied to an image using blind deconvolution with the CFA pattern and interpolation coefficients as constraints <ref type="bibr" target="#b10">[11]</ref>. Chuang et al. used a similarly constrained blind deconvolution algorithm to estimate the empirical frequency response of a tampering operation <ref type="bibr" target="#b11">[12]</ref>. While these early techniques can successfully detect median filtering, they require either an accurate estimate or direct knowledge of the camera model used to capture an image. As a result, their performance is sensitive to the training data used.</p><p>Kirchner and Fridrich proposed a pair of median filter detectors inspired by the streaking artifacts discovered by Bovik <ref type="bibr" target="#b0">[1]</ref>. To identify the presence of streaking artifacts in an image x(i, j), Kirchner and Fridrich examined statistical properties of the image's first order pixel difference:</p><formula xml:id="formula_1">), ,<label>( ) , ( ) , ( ,</label></formula><formula xml:id="formula_2">l j k i x j i x e l k j i + + - =<label>(2)</label></formula><p>where (k, l)∈{(0,1),(0,-1),(1,0),(-1,0), <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b0">1)</ref>, <ref type="bibr">(1,-1)</ref>,(-1,1),(- to a decision threshold. Additionally, they proposed a more robust detector using subtractive pixel adjacency matrix (SPAM) features. The set of SPAM features are the set of distributions of a first order pixel difference conditioned on each possible value of the neighbor first order difference <ref type="bibr" target="#b14">[15]</ref>. <ref type="bibr">Kirchner and</ref> Fridrich demonstrated that SPAM features can be used to detect median filtering in high to medium quality JPEG compressed images. The detector's performance degrades, however, as the JPEG's quality factor decreases. This is particularly true at low probabilities of false positive. Additionally, since a large number of observations are required to obtain good estimates of these conditional first order difference distributions, SPAM's performance degrades as the number of pixels in an image or image window decreases which was indicated in <ref type="bibr" target="#b1">[2]</ref>. This is particularly important when performing localized median filtering detection through block-wise analysis.</p><p>Similarly, the authors of <ref type="bibr" target="#b2">[3]</ref> proposed detecting median filtering by analyzing the probability that an image's first order pixel difference will be zero in textured regions. Furthermore, they demonstrated that their technique can distinguish median filtering from rescaling, Gaussian filtering, and average filtering. While they were able to demonstrate that this technique can very effectively detect median filtering in uncompressed images, its performance degrades significantly in JPEG compressed images.</p><p>The median pixel values obtained from overlapping filter windows related to one another since overlapping windows share several pixels in common. Yuan proposed detecting median filtering by measuring the relationships among pixels within a 3 × 3 window <ref type="bibr" target="#b1">[2]</ref>. This is done by extracting a set of 44 features, known as the median filtering feature set (MFF), from an image. These sets include features such as the distribution of the block median pixel value and the distribution of the number distinct gray levels within a window. Yuan <ref type="bibr" target="#b1">[2]</ref> demonstrated that the MFF method can achieve comparable or better performance than the SPAM on both high and moderate quality JPEGs and when detecting median filtering on small image windows. However, as with the Kirchner and Fridrich's technique, the performance of Yuan's technique decreases as the JPEG quality factor is lowered or as the image size examined shrinks.</p><p>The authors in <ref type="bibr" target="#b23">[24]</ref> calculated the edge based prediction matrix (EBPM) of different kinds of image edges and obtained 72 dimensions of prediction coefficients to differentiate median filtering. They use a prediction model of the pixel values in image regions with different gradients and capture statistical relationships between nearby pixels to perform median filtering detection. In their recent work <ref type="bibr" target="#b3">[4]</ref>, they exploited cumulative distribution function of 1storder and 2nd -order image difference as fingerprints to construct the global probability feature set (GPF). They also used the local correlations between different adjacent image difference pairs to construct the local correlation feature set (LCF). They finally used GPF and LCF to construct a new feature set GLF of 56 dimensions. Their method achieved good performance for low resolution and JPEG compression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. AR MODEL OF MEDIAN FILTER RESIDUAL</head><p>Existing median filtering detectors extract their detection features directly from the pixel values or the pixel difference of the image being examined. As a result, image content such as edge or texture information and the block artifacts from JPEG compression may interfere with attempts to capture statistical traces of median filtering. Take for example the first order pixel difference used by several detectors <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>.Fig. <ref type="figure" target="#fig_0">1</ref> shows an image along with its first order pixel difference taken in the horizontal direction. We can clearly see in this figure that the first order difference contains a great deal of the image's edge content. This edge information and the block artifacts may affect the conditional first order difference distributions used by SPAM to detect median filtering. We note that while the MFF feature set does not include first order pixel differences, the MFF features are similarly affected by edge content.</p><p>To suppress both image content and block artifacts, and develop a more robust median filtering detection technique, we propose extracting detection features from the difference between a median filtered version of an image and the image itself. We refer to this difference as an image's median filter residual (MFR), which we formally define as ( , ) med ( ( , )) ( , ) ( , ) ( , )</p><formula xml:id="formula_3">w d i j y i j y i j z i j y i j = - = -<label>(3)</label></formula><p>where y(i, j) is original pixel value at point (i, j) and z(i, j) is median filtered value of y(i, j). In this work, we use w = 3 when calculating an image's MFR. We can see from Fig. <ref type="figure" target="#fig_0">1</ref>(c) that the median filter residual contains less edge information than the first order pixel difference.</p><p>To understand how the MFR can be used to detect median filtering in an image y, let us examine properties of the MFR when y is unaltered and when y has been median filtered. Median filtering detection can be framed as differentiating between the following two hypotheses:</p><p>H 0 : y is not a median filtered image, i.e. y = x, where x is an unaltered image.</p><p>H 1 : y is a median filtered image, i.e. y = med u (x).</p><p>We note that the median filter window size w used to obtain the MFR need not be the same as the median filter window size u used when altering the image.</p><p>Under hypothesis H 0 , y is equal to an unaltered image x, therefore ( , ) med ( ( , )) ( , ),</p><formula xml:id="formula_4">w d i j x i j x i j = -<label>(4) and</label></formula><p>( , ) med ( ( , ))</p><formula xml:id="formula_5">w z i j x i j = .</formula><p>(5) In this scenario, the value of z(i, j) could potentially be equal to the value of x(k, l) for any (k, l) that lies in the w × w median filter window surrounding (i, j). An example of this is shown in Fig. <ref type="figure" target="#fig_1">2(a)</ref>, where the pixel value z(i, j) (shown in red) can be equal to the value of any x(k,l) in the dashed red box. Because of this, any two distinct MFR values d(i, j) and d(i+h, j+v) could have z terms corresponding to the same x value as long as h, v&lt; w. This is illustrated in Fig. <ref type="figure" target="#fig_1">2(b)</ref>,where two w×w windows with less than w pixels displacement will overlap.</p><p>Under hypothesis H 1 , y is equal to a median filtered version ofx, i.e.</p><p>( , ) med ( ( , )).</p><formula xml:id="formula_6">u y i j x i j = (6) As a result )) , ( ( med ))) , ( ( (med med ) , ( j i x j i x j i d u u w - = (7) and ))) , ( ( (med med ) , ( j i x j i z u w = (<label>8</label></formula><p>) The value of z(i, j) can be equal to the value of y(s, t) for any (s, t) that lies in the w × w median filter window surrounding (i, j). However, the value y(s, t) can be equal to the value of x(k, l) for any (k, l) that lies in the u × u median filter window surrounding (s, t). As a result, value of z(i, j) can be equal to the value x(k, l) for any (k, l) in the (w+u-1)× (w+u-1) window surrounding (i, j). An example of this is shown in Fig. <ref type="figure" target="#fig_1">2(c</ref>). Because of this, under hypothesis H 1 any two distinct MFR values d(i, j) and d(i+h, j+v) could have z terms corresponding to the same x value as long as h, v&lt; w+u-1. This phenomenon is shown in Fig. <ref type="figure" target="#fig_1">2(d)</ref>.</p><p>Let us refer to the window over which the z term of two different d values can correspond to the same x value as the shared value window. Examining the shared value window under each hypothesis, we can observe the following: Because the size of the shared value window changes under each hypothesis, the relationship between d(i, j) and its neighbors will also change under each hypothesis.</p><formula xml:id="formula_7">H 0 : The MFR's shared value window is of size w × w.</formula><p>To capture this effect using a feature set of low dimensionality, we fit the MFR to an autoregressive (AR) model. Because an AR model essentially performs linear prediction, the values of the AR coefficients depend heavily on how the MFR values of nearby pixels relate to one another. Since the shared value window of the MFR is smaller under hypothesis H 0 than under H 1 , the coefficients of the AR model will be substantially different if the image in question has been median filtered. As a result, we use the AR coefficients of the MFR as features when performing median filtering detection.</p><p>To further reduce the dimensionality of our model, we assume that an image's statistical property is the same in the horizontal and vertical directions. Using this assumption along with the fact that median filter windows are symmetric, we fit the MFR to a one dimensional AR model in the row direction</p><formula xml:id="formula_8">( ) ( ) 1 ( , ) ( , ) ( , ), p r r k k d i j a d i j k i j ε = = - -+ ∑ (9)</formula><p>and in the column direction respectively. We then average the AR coefficients in both directions to obtain a single, one dimensional AR model. Fig. <ref type="figure" target="#fig_3">3</ref> (a) shows the first three AR coefficients (a 1 , a 2 , a 3 ) of the MFR extracted from both unaltered and median filtered versions of images in the Uncompressed Color Image Database (UCID) <ref type="bibr" target="#b17">[18]</ref>. Fig. <ref type="figure" target="#fig_3">3</ref>(b) shows the first three AR coefficients of the MFR extracted from the same images after they have undergone JPEG compression with quality factor of 70.From these figures, we can clearly see that the unaltered and median filtered images can be separated on the basis of the MFR's AR coefficients. Furthermore, these figures show that JPEG compression has little effect of the ability to separate median filtered from unaltered images on the basis of their MFR's AR coefficients. This demonstrates the robustness of the MFR's AR coefficients to JPEG compression. Fig. <ref type="figure" target="#fig_5">4</ref> shows the average value of the first 30 AR coefficients of each image in the UCID. From this figure, we can see that the AR coefficient values differ on average for roughly the first 10 AR coefficients. After this point, the AR coefficients are approximately the same regardless of whether or not an image was median filtered. Additionally, this figure shows that the largest AR coefficient occurs at different k's depending on whether or not an image was median filtered. This reinforces the notion that the AR coefficients are good features for median filtering detection.</p><formula xml:id="formula_9">( ) ( ) 1 ( , )<label>( , ) ( , ),</label></formula><p>To identify median filtering, we use a support vector machine trained on the first 10 AR coefficients of the MFR. While we have experimentally found that using 10 AR coefficients results in a desirable tradeoff between detection accuracy and the dimensionality of the feature space in the detection of both 3×3 and 5×5 median filtering, we have observed that 3×3median filtering detection can still be accurately performed using as few as 4 AR  coefficients. We note that the SPAM features proposed by Kirchner and Fridrich are 686 dimensions <ref type="bibr" target="#b0">[1]</ref>, the GLF <ref type="bibr" target="#b3">[4]</ref> features are 56 dimensions, and the MFF features proposed by Yuan <ref type="bibr" target="#b1">[2]</ref> are 44 dimensions. Since our method uses only 10 features, we are able to achieve a 1 to 2 order of magnitude reduction in the dimensions of the feature vector.</p><p>Our complete median filtering detection technique can be summarized as follows 1. Calculate an image's MFR using (3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>To evaluate the effectiveness of our proposed median filtering detector and to compare its performance to existing median filtering detection techniques, we tested our proposed technique along with several others on UCID <ref type="bibr" target="#b17">[18]</ref> and a composite image database which contains 6690 different kinds (such as raw images, rescanned images and rescaled images) of images from UCID, the BOSS RAW database (BR) [25],the BOWS2 image database (BOWS2) <ref type="bibr" target="#b24">[26]</ref>, the Dresden Image Database (DID) <ref type="bibr" target="#b25">[27]</ref> and the NRCS Photo Gallery (NRCS) <ref type="bibr" target="#b26">[28]</ref>.Each database (UCID, BR, BOWS2, DID, NRCS) contributes 1338 images with size of 512 × 384 to compose the composite image database. These databases are widely used to evaluate the performance of forensic techniques <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>, and they are described in detail in <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b3">[4]</ref>.The UCID database consists of 1338 uncompressed RGB images of size 512 × 384.The images in the other four databases (BR, BOWS2, DID, NRCS) are cropped to the size of 512 × 384from the center of its full size source images. Then all color images were first converted to gray scale images before further processing. Median filtered images were generated by performing 3 × 3 median filtering and 5 × 5 median filtering on the unaltered gray-scale images. Each unaltered and median filtered image was then saved in both its uncompressed state and JPEG compressed state using a variety of quality factors ranging between 90 and 30.</p><p>We compared our proposed AR method with the SPAM method <ref type="bibr" target="#b0">[1]</ref>,the MFF method <ref type="bibr" target="#b1">[2]</ref>, and the GLF method <ref type="bibr" target="#b3">[4]</ref>.We performed SVM training and testing for each of the four methods in the same manner. To perform classification, we used a C-SVM with a Gaussian kernel <ref type="bibr" target="#b18">[19]</ref> K (x i , x j ) = exp (-γ||x i -x j || 2 ) During cross-validation, once a training set was selected, we found the best kernel parameters for the SVM by performing an additional five-fold cross-validation in conjunction with a grid search. The grid search for the best parameters was performed on the multiplicative grid (C,γ) ∈{(2 i ,2 j ) |4 i, 4 j Ζ}. Once the best parameters were identified, we used those parameters to get the classifier model on the entire training set. We then use the trained classifier model to perform a classification on the testing set.</p><p>Experimental results were reported on the UCID database in items A)-D), and on the composite database in items E). Four-fold cross validation was used to evaluate the effectiveness of each approach when testing on the UCID database. Specifically, the images in the UCID database were randomly divided into four folds of nearly equal size. In each repetition, the training set was composed of three folds (about 1003 images), while the remaining fold was used as the testing set (about 335 images).After four-fold cross-validation testing, we can obtain the detection results and ROC curve of all 1338images in UCID database.</p><p>In real world scenarios, an investigator must often perform detection with a low probability of false positives. Because of this, each detector's performance at low false positive rate is critical. To take this into account, we report the performance of each detection technique at a low false positive rate such as 1%. Additionally, we report the minimal average decision error P e of each technique under the assumption of equal priors and equal costs, </p><p>where P fp and tp P denote the false positive (FP) and true positive rates (TP), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A) Detecting globally applied median filtering</head><p>To measure the performance of our proposed method under ideal conditions, we performed median filtering detection on the set of uncompressed images. The results of this experiment are shown in Figs. <ref type="figure" target="#fig_4">5(a</ref>) and (b)which show ROC curves obtained for each detection technique when tested against images modified using 3×3 and 5×5 median filters respectively. In Fig. <ref type="figure" target="#fig_4">5</ref>(a), "Original VS MF3" denotes that the original unmodified image set versus the 3 × 3 median filtered image set. From these results, we can see that all four methods have comparable performance and achieve perfect or nearly perfect detection.</p><p>Next, we tested each technique's ability to detect 3×3 median filtering in images that were JPEG compressed using quality factors ranging between 90 and 30. ROC curves obtained from these experiments are shown in Fig. <ref type="figure" target="#fig_7">6</ref> and significant results are listed in Table <ref type="table" target="#tab_2">I</ref>."MF3+JPEG70" denotes the composite operation of median filtering followed by JPEG compression with quality factor (QF) 70. For each JPEG quality factor test, our detector achieved a lower P e than all other three methods. Additionally, the ROC curves show that our detector achieved a higher P tp than all other detectors at all P fp Rates. This is especially true at low false positive rates. At P fp = 1%, our detector achieved a P tp = 97.5% when testing on images compressed using a quality factor of 70, while the MFF detector achieved a P tp = 56.1%, and the GLF detector achieved a P tp = 75.5%and the SPAM detector achieved a P tp = 26.9%.This corresponds to P tp improvements of 41.4%, 22.0% and 70.6% respectively. Similarly for images compressed using a quality factor of 50, our detector achieved a P tp = 93.5% at P fp = 1.0%, while the MFF, GLF and SPAM detectors achieved P tp = 38.5%, P tp = 46.4%, and P tp = 6.6% respectively. This corresponds to P tp improvements of 55%, 47.1%, and 86.9% respectively. These results demonstrate that our proposed detection method is more robust to JPEG compression than existing  <ref type="table" target="#tab_2">I</ref> and Fig. <ref type="figure" target="#fig_7">6</ref> that our detection method's advantage over the other three methods increases as the JPEG quality factor decreases. A similar improvement in performance over the state-ofthe-art MFF and GLF methods were observed when we repeated the experiment using 5 × 5 median filtering. Detailed results of this experiment are shown in Table <ref type="table" target="#tab_2">I</ref>. From Table <ref type="table" target="#tab_2">I</ref>, we can see that our proposed method achieved a larger P tp = 76.9% at P fp = 1.0% than the other three methods for images compressed with a quality factor of 30. These experimental results show that the performance of the AR classifier remains strong when the JPEG compression quality factor is as low as 30 in detection of 5× 5 median filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B) Detecting median filtering in low-resolution images and image windows</head><p>The ability to detect median filtering in low-resolution images and image windows is essential for detecting forgeries when a portion of a median filtered image is inserted into a non-median filtered image. To test each detector's performance on small image windows, we created a database to test image blocks by cropping a block of size 128 × 128, 64 × 64 and 32 × 32 from the center  an image. The state of the art median filtering detectors when operating on small image windows are the MFF method <ref type="bibr" target="#b1">[2]</ref> and the GLF method <ref type="bibr" target="#b3">[4]</ref>. For the sake of brevity, we only compared our method with both the MFF method and the GLF method on JPEG 70 compressed images. ROC curves obtained from this experiment are shown in Fig. <ref type="figure" target="#fig_9">7</ref>. From Fig. <ref type="figure" target="#fig_9">7</ref>, we can see that the performance of our proposed AR is stronger than that of the MFF and GLF detectors for blocks with sizes as low as 32 × 32. Our AR method achieved a P tp = 69.7% at P fp = 1% when testing on 128×128 pixel blocks compressed with a quality factor of 70, while the GLF and MFF methods achieved a P tp of 28.6% and 9.8% respectively at P fp = 1%. This corresponds to P tp improvements of 41.1% and 59.9% compared with GLF and MFF. For blocks of size 64 × 64, our detector achieved a P tp = 68.2% at P fp = 5%. For 32 × 32 pixel blocks, our detector achieved a P tp = 60.5% at P fp =10%. We obtained similar results when testing on blocks from images modified by 5 × 5 median filtering.</p><p>An example of a cut-and-paste image forgery and corresponding forensic detection results were shown in Fig. <ref type="figure" target="#fig_10">8</ref>. Fig. <ref type="figure" target="#fig_10">8</ref> (a) shows the 3 × 3 median filtered image from which an object (the woman on the left) was cut. Fig. <ref type="figure" target="#fig_10">8(b)</ref> shows the unaltered image into which the cut object was pasted. Fig. <ref type="figure" target="#fig_10">8</ref> (c) shows the composite image, which had been JPEG compressed using a quality factor of 70. In order to detect the forgery, the composite image was first segmented into 128×128 pixel blocks, then each block was tested for evidence of locally applied median filtering. In this example, each detection method tested was trained on 128 ×128 pixel blocks from images in UCID database that had been compressed using a quality factor of 70. Blocks corresponding to median filtering detections are boxed and outlined in red. Fig. <ref type="figure" target="#fig_10">8 (d)</ref> shows the result of blockwise detections on the composite image using our proposed AR method. In this example, each of the outlined blocks contains pixels corresponding to the inauthentic object and the pasted object can be detected correctly using our proposed AR method. Fig. <ref type="figure" target="#fig_10">8</ref> (e) shows the result of blockwise detections on the composite image using the GLF method. In this example, multiple false alarms occur and the detection rate is decreased. Fig. <ref type="figure" target="#fig_10">8</ref> (f) shows the result of blockwise detections on the composite image using the MFF method. In this case, the inauthentic object cannot be located with the MFF method correctly. This example shows that our method achieves the best performance in the cut-and-paste forgery detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C) Distinguishing median filtering from other manipulations</head><p>Identifying the particular operation used to alter an image is an important forensic problem. This can be difficult in the case of median filtering, because several other operations such as linear smoothing and resizing leave behind similar forensic traces.</p><p>We tested the ability of our proposed AR method, along with the SPAM, GLF and MFF methods, to differentiate between median filtering and other popular tools, including 3×3 Gaussian filtering with 0.5 (GAU), 3×3 average filtering (AVE), upscaling (UpRes) and downscaling (DownRes). Bilinear interpolation was used to perform both upscaling and downscaling. The upscaling factor was set to 1.1, while the downscaling factor was 0.9.</p><p>To achieve a baseline measure of the performance of each technique, we first evaluated their ability to distinguish median filtering from other operations in uncompressed images. Our experimental results show that under these ideal conditions, each technique was able to distinguish median filtering from other operations perfectly (i.e. each technique achieved a P e = 0%).</p><p>Next, we evaluated the performance of each technique on images that had been JPEG compressed using a quality factor of 70. This experiment reflects conditions more likely to be encountered by a forensic examiner in a real world scenario. ROC curves displaying the performance of method are shown in Fig. <ref type="figure" target="#fig_11">9</ref> for 3 × 3 median filtering. Additionally, detection results showing the P e and P tp at P fp = 1% are displayed in Table <ref type="table" target="#tab_3">II</ref> for both 3 × 3 and 5 × 5 median filtering.</p><p>These experimental results show that our method can discriminate between median filtering and other operations with high accuracy. As can be seen in Table <ref type="table" target="#tab_3">II</ref> , the worst P e value achieved by our detector among the four manipulations was only 2.3%. Furthermore, these results show that our method can achieve substantial performance gains over the other techniques at low false positive rates. For example, when testing against images which had been modified by Gaussian blurring and downscaling, our method achieved a P tp = 96.5% and P tp = 95.6% respectively at P fp = 1% for 3 × 3 median filtering. At the same false positive rate, the best results of other three methods were achieved by GLF and its P tp = 76.4%, 69.3% respectively.</p><p>In practical settings, it is likely that an investigator will need to distinguish between median filtering and a collection of other operations rather than a single, known operation. To evaluate our proposed forensic technique's ability to do this, we pooled all of the images used in the previous experiments that were JPEG compressed with a quality factor of 50 into two different classes. Class1 contained the 13383 × 3median filtered images, while Class2 was made up of 1338 images randomly chosen from the sets of unaltered images and images modified by average filtering, Gaussian filtering, upscaling, and downscaling. We then used the proposed AR method along with MFF, GLF and SPAM methods to distinguish between the two classes. The four-fold cross validation method was also used in this experiment. ROC curves displaying the experimental performance of each technique with different image sizes are shown in Fig. <ref type="figure" target="#fig_12">10</ref>. In Fig. <ref type="figure" target="#fig_12">10</ref>, "ALL VS MF3 + JPEG 70" denoted that the images in both Class 2 and Class 1 were JPEG compressed with a quality factor 70. These results show that our proposed AR method can distinguish between median filtering and other operations better than other three techniques, especially on small sized images. On image sizes of 128 ×128 at a false positive rate of P fp = 5%, our proposed technique achieved a P tp = 90.1%. By contrast, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D) Differentiating3×3 median filtering from 5×5 median filtering</head><p>Once a forensic investigator has identified that an image has been median filtered, they may wish to determine the window size used during median filtering. We have found that our AR method can differentiate between 3×3 and 5×5 median filtering with high accuracy. To experimentally verify this, we created 1338 3×3 and 1338 5×5 median filtered versions of each image in the UCID, and then JPEG compressed them with a quality factor of 70. Next, we used our proposed method along with the MFF, the GLF and SPAM techniques to distinguish between 3×3 and 5×5 median filtering. ROC curves showing the results of this experiment are displayed in Fig. <ref type="figure" target="#fig_13">11</ref>. From these results, we find that at a false positive rate of P fp = 1%, our AR method achieved a much higher P tp = 98.2% than other three methods. The MFF, GLF and SPAM techniques achieved P tp = 14.3%, P tp = 44.1% and P tp = 62.2% respectively. This corresponds to improvements of 83.9%, 54.1% and 36.0% respectively. These results show that our proposed technique can identify the median filter's window size more accurately than existing techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E) Detection results on a composite database</head><p>In addition, we evaluated the performance of our detector on the previously mentioned composite database consisting of 6690 images of size of 512 × 384 pixels. When testing on this database, the training set was chosen to contain 2676 images (40% of the database size) while the testing set contained the remaining 4014 images. Because the training and testing sets were sufficiently large, four-fold cross validation is not applied on the composite database. The setup is similar to Items A) -D).</p><p>First, we evaluated each technique's ability to detect 3×3 median filtering in images that were JPEG compressed using quality factor 70. The results of this experiment are shown in Fig. <ref type="figure" target="#fig_14">12(a)</ref>. From this figure, we can see that our AR method outperforms all other three methods. At a false positive rate of P fp = 5 %, the AR, GLF, SPAM and MFF methods achieved true positive rates of P tp = 83.8 %, P tp = 76.7 %, P tp = 67.2 % and P tp = 51.6 % respectively. Next, we repeated this experiment on images sized 128 × 128 pixels. These small images were cropped from the center of each full sized image in the composite database. The results of this experiment are shown in Fig. <ref type="figure" target="#fig_14">12(b</ref>). These results demonstrate that our method is able to outperform all other techniques on small images and image windows. At P fp = 5%, our method achieved a P tp = 60.6%. This corresponds to a P tp improvement of10.5% over the second best performing GLF method.</p><p>All previous experiments using JPEG compression applied JPEG post-compression, that is, JPEG compression performed after median filtering. As JPEG compression is a popular image format, we tested whether JPEG compression before median filtering affected the performance of each detection technique. In this experiment, images in the Class 1 were first JPEG compressed using a quality factor of 90, then 3 × 3 median  SPAM P e = 0.062 filtered, and finally saved in JPEG format with a quality factor of 70. Images in the Class 2were JPEG compressed using a quality factor of 70. We then used each technique to perform median filtering detection and used the results to obtain the ROC curves shown in Fig. <ref type="figure" target="#fig_14">12(c</ref>). In Fig. <ref type="figure" target="#fig_14">12(c)</ref>, Class 1 and Class 2 are denoted as "JPEG +MF3+JPEG 70" and "JPEG" respectively. From these results, we can observe that our proposed method is more robust against JPEG pre-compression and achieves best performance among all four methods. JPEG pre-compression has little effect on our proposed method in differentiating the two classes when comparing Fig. <ref type="figure" target="#fig_14">12</ref>(a) with Fig. <ref type="figure" target="#fig_14">12(c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we have proposed a new, robust median filtering detection technique. To reduce interference from an image's edge content and the block artifacts from JPEG compression, we proposed gathering detection features from an image's median filter residual. Specifically, we built a one dimensional AR model of an image's MFR and used the AR coefficients as median filtering detection features. Our AR features achieved a one to two order of magnitude reduction in the dimensionality of the detection feature space used by existing techniques such as the SPAM and MFF methods. We then used these features to train a support vector machine to perform median filtering detection.</p><p>Through a series of experiments, we have demonstrated that our proposed median filtering forensic technique outperforms existing detectors under a variety of scenarios. Our experimental results have shown that our technique can detect median filtering in images that have been JPEG compressed using quality factors as low as 30.We have demonstrated that our technique can identify median filtering in small image blocks. Using these results, we have shown that our proposed detector can be used to identify cut-and-paste forgeries. Additionally, our experimental results show that our proposed technique can more reliably distinguish between median filtering and rescaling editing operations than existing median filtering forensic techniques.</p><p>Our experimental results have shown that our detector achieves substantial performance gains over existing forensic techniques when the false positive rate is held low (e.g. P fp = 1%). Because median filtering detection must often be performed at low false positive rates, these results demonstrate that our proposed technique is better suited for use in real world scenarios than existing techniques.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1.Example showing (a) an image, (b) its first order difference, and (c) its median filter residual.</figDesc><graphic coords="2,90.30,60.96,135.00,170.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example showing (a) the w × w median filter window of the MFR of a pixel under hypothesis H 0 and (b) the overlap between of the median filter windows of the MFR (in red and blue) under hypothesis H 0 along with (c) the u × u modifying median filter window (in red) and the effective (w + u -1) × (w + u -1) median filter window of the MFR (in blue) of a pixel under hypothesis H 1 and (d) the overlap between the median filter windows of the MFR (in red and blue) under hypothesis H 1 . In this example w = 3 and u = 3.</figDesc><graphic coords="3,84.00,194.40,111.78,111.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>H 1 :</head><label>1</label><figDesc>The MFR's shared value window is of size (w+u-1) × (w+u-1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>εFig. 3 .</head><label>3</label><figDesc>Fig. 3.Plot of the first three AR coefficients of the MFR for (a) unaltered images (red) and the 3×3 median filtered images (blue); (b) JPEG 70 compressed images (red) and the 3×3 median filtered then JPEG 70 compressed image (blue) in UCID database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5.ROC curves showing 3 × 3 median filtering(a)and 5 × 5median filtering (b) detection performance on uncompressed images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4.The average AR coefficients of the MFR from unaltered images (red), the 3×3 median filtered images (blue) and the 5×5 median filtered images (green) respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2 . 3 .</head><label>23</label><figDesc>Fit the MFR to an AR model of order 10 in the row direction and in the column direction using all MFR values. Average corresponding AR coefficients across each model acquired in Step 2 to obtain a single AR model. 4. Input the AR coefficients to an SVM trained to classify between median filtered and unaltered images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6.ROC curves showing 3 × 3 median filtering detection performance on (a) JPEG 90 compressed images, (b) JPEG 70 compressed images, (c) JPEG 50 compressed images, and (d) JPEG 30 compressed images. Different scale were applied on x axis and y axis for clear demonstration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig.7.ROC curves showing 3 × 3 median filtering detection performance on JPEG compressed imagesof size 128 × 128(left), 64 × 64(middle), 32 × 32 (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8.Cut and paste forgery detection example showing (a) the median filtered image from which an object is cut, (b) the unaltered image into which the cut object is pasted, (c) the composite image which is JPEG compressed using a quality factor of 70.Blocks detected as median filtered are outlined in red boxes,(d) blockwise detections using the AR method, (e) blockwise detections using the GLF method and, (f) blockwise detections using the MFF method.</figDesc><graphic coords="8,90.24,575.40,128.88,129.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. ROC curves showing each technique's ability to discriminate 3×3 median filtering from Gaussian filtering (top left), average filtering (top right), upscaling (bottom left), and downscaling (bottom right) in JPEG compressed images using a quality factor of 70.Different scale were applied on x axis and y axis for clear demonstration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. ROC curves showing each technique's ability to discriminate median filtered images from non-median filtered images with size of 512 × 384 (left) and 128 × 128(right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11.ROC curves showing each technique's ability to discriminate 3×3 median filtering (MF3) from 5×5 median filtering (MF5) on JPEG compressed images using a quality factor of 70.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. ROC curves show each technique's performance on the composite database for 3 × 3median filtering detection on (a) images of size 512 × 384 and (b) images of size 128 × 128. Plots in (c) demonstrates each method's ability to detect 3 × 3 median filtering when images of size 512 × 384 were preprocessed by JPEG compression with QF = 90.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I P e AND P tp AT P fp = 1% FOR MEDIAN FILTERINGDETECTORS AGAINST JPEG COMPRESSION. (The best</head><label>I</label><figDesc>result for each training-testing pair is displayed with bold texts.)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>MF3</cell><cell></cell><cell></cell><cell></cell><cell>MF5</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>AR</cell><cell>MFF</cell><cell>GLF</cell><cell>SPAM</cell><cell>AR</cell><cell>MFF</cell><cell>GLF</cell><cell>SPAM</cell></row><row><cell>JPEG</cell><cell>P tp (%)</cell><cell>55. 8</cell><cell>21. 8</cell><cell>21. 7</cell><cell>4. 3</cell><cell>76. 9</cell><cell>32. 8</cell><cell>52. 5</cell><cell>56. 9</cell></row><row><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>P e (%)</cell><cell>2. 8</cell><cell>10. 0</cell><cell>7. 0</cell><cell>21. 3</cell><cell>2. 5</cell><cell>5. 2</cell><cell>3. 4</cell><cell>6. 3</cell></row><row><cell>JPEG</cell><cell>P tp (%)</cell><cell>93. 5</cell><cell>38. 5</cell><cell>46. 4</cell><cell>6. 6</cell><cell>95. 8</cell><cell>62. 4</cell><cell>85. 0</cell><cell>72. 9</cell></row><row><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>P e (%)</cell><cell>2. 2</cell><cell>7. 2</cell><cell>5. 0</cell><cell>16. 1</cell><cell>2. 1</cell><cell>4. 2</cell><cell>2. 7</cell><cell>4. 0</cell></row><row><cell>JPEG</cell><cell>P tp (%)</cell><cell>97. 5</cell><cell>56. 1</cell><cell>75. 5</cell><cell>26. 9</cell><cell>98. 8</cell><cell>70. 8</cell><cell>95. 5</cell><cell>93. 5</cell></row><row><cell>70</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>P e (%)</cell><cell>1. 3</cell><cell>4. 6</cell><cell>4. 3</cell><cell>10. 7</cell><cell>1. 0</cell><cell>3. 5</cell><cell>1. 8</cell><cell>2. 8</cell></row><row><cell>JPEG</cell><cell>P tp (%)</cell><cell>99. 5</cell><cell>95. 3</cell><cell>97. 2</cell><cell>92. 8</cell><cell>99. 7</cell><cell>96. 3</cell><cell>99. 5</cell><cell>98. 8</cell></row><row><cell>90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>P e (%)</cell><cell>0. 5</cell><cell>2. 2</cell><cell>1. 5</cell><cell>2. 5</cell><cell>0. 5</cell><cell>2. 0</cell><cell>0. 7</cell><cell>1. 0</cell></row></table><note><p>techniques. It can also be observed from Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II P e AND P tp ATP fp = 1% OF DISTINGUISHING MEDIAN FILTERING FROM OTHER MANIPULATIONS (The best</head><label>II</label><figDesc>result for each training-testing pair is displayed with bold texts.)</figDesc><table><row><cell cols="5">the SPAM, the GLF and MFF techniques achieved P tp =</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">25.6%, P tp = 72.1% and 51.1% respectively. This</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">corresponds to improvements of 64.5%, 18.0% and</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>39.0%respectively.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>MF3</cell><cell></cell><cell></cell><cell></cell><cell>MF5</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>AR</cell><cell>MFF</cell><cell>GLF</cell><cell>SPAM</cell><cell>AR</cell><cell>MFF</cell><cell>GLF</cell><cell>SPAM</cell></row><row><cell>MF VS GAU</cell><cell>P tp (%)</cell><cell>96. 5</cell><cell>44. 3</cell><cell>76. 4</cell><cell>68. 7</cell><cell>99. 1</cell><cell>66. 9</cell><cell>96. 7</cell><cell>96. 3</cell></row><row><cell></cell><cell>P e (%)</cell><cell>1. 5</cell><cell>7. 0</cell><cell>4. 4</cell><cell>6. 9</cell><cell>0. 8</cell><cell>4. 8</cell><cell>1. 7</cell><cell>1. 8</cell></row><row><cell>MF VS UpRes</cell><cell>P tp (%)</cell><cell>93. 7</cell><cell>48. 2</cell><cell>76. 8</cell><cell>29. 6</cell><cell>98. 9</cell><cell>44. 3</cell><cell>94. 8</cell><cell>90. 4</cell></row><row><cell></cell><cell>P e (%)</cell><cell>2. 3</cell><cell>6. 8</cell><cell>3. 6</cell><cell>11. 1</cell><cell>1. 0</cell><cell>4. 8</cell><cell>1. 6</cell><cell>2. 3</cell></row><row><cell cols="2">MF VS DownRes P tp (%)</cell><cell>95. 6</cell><cell>43. 9</cell><cell>69. 3</cell><cell>23. 1</cell><cell>99. 3</cell><cell>75. 0</cell><cell>95. 8</cell><cell>94. 6</cell></row><row><cell></cell><cell>P e (%)</cell><cell>1. 9</cell><cell>7. 7</cell><cell>3. 6</cell><cell>11. 3</cell><cell>0. 8</cell><cell>4. 7</cell><cell>1. 5</cell><cell>2. 4</cell></row><row><cell>MF VS AVE</cell><cell>P tp (%)</cell><cell>95. 2</cell><cell>95. 6</cell><cell>96. 6</cell><cell>51. 0</cell><cell>99. 7</cell><cell>97. 1</cell><cell>98. 0</cell><cell>93. 5</cell></row><row><cell></cell><cell>P e (%)</cell><cell>2. 1</cell><cell>2.1</cell><cell>1. 4</cell><cell>8. 2</cell><cell>0. 5</cell><cell>1. 7</cell><cell>1. 1</cell><cell>2. 4</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank H. Yuan for providing the code of MFF scheme.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b0">1</ref> <p>This work was supported by NSFC (Grant nos. 61070167, U1135001), the Research Fund for the Doctoral Program of Higher Education of China (Grant no. 20110171110042).</p><p>Xiangui Kang was with Dept. of Electrical and Computer Engineering,</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On detection of median filtering in digital images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE, Electronic Imaging, Media Forensics and Security II</title>
		<meeting>SPIE, Electronic Imaging, Media Forensics and Security II</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">7541</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Blind forensics of median filtering in digital images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1335" to="1345" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Forensic detection of median filtering in digital images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2010 IEEE Int. Conf. Multimedia and EXPO 2010</title>
		<meeting>2010 IEEE Int. Conf. Multimedia and EXPO 2010</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="89" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Blind median filteringdetection using statistics in difference domain</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of information Hiding</title>
		<meeting>of information Hiding<address><addrLine>Berkerly, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-05">2012. May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exposing digital forgeries bydetecting traces of resampling</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEETransactions on SignalProcessing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="758" to="767" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Forensic detection of image manipulation using statistical intrinsic fingerprints</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="492" to="506" />
			<date type="published" when="2010-09">Sept 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Anti-forensics of digital image compression</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1050" to="1065" />
			<date type="published" when="2011-09">Sept 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image tamper detection based on demosaicing artifacts</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Dirik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Memon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Image Processing</title>
		<meeting>International Conference on Image essing<address><addrLine>Cairo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hiding traces of resampling in digital images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Böhme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="582" to="592" />
			<date type="published" when="2008-12">Dec. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Streaking in median filtered images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="503" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Digital image forensics via intrinsic fingerprints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="117" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tampering identification using empirical frequency response</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech and Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoust., Speech and Signal essing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1517" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Steganalysis by subtractive pixel adjacencymatrix</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pevný</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="224" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Revisiting weighted stego-image stegoanalysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Ker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Böhme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SPIE, Electronic Imaging: Security, Forensics, Steganography and Watermarking of Multimedia Contents X</title>
		<meeting>of SPIE, Electronic Imaging: Security, Forensics, Steganography and Watermarking of Multimedia Contents X</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">6819</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Detection of double-compression in JPEG images for applications in steganography</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pevnỳ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="247" to="258" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">JPEG error analysis andits applications to digital image forensics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="491" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Digital Image Source Coder Forensics Via Intrinsic Fingerprints</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Tjoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="492" to="506" />
			<date type="published" when="2009-09">Sept 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">UCID-An uncompressed color image database</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SPIE, Storage and Retrieval Methods and Applications for Multimedia</title>
		<meeting>of SPIE, Storage and Retrieval Methods and Applications for Multimedia</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="472" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C. -C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C. -J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Modern spectral estimation: theory and application</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsharp masking sharpening detection via overshoot artifacts analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="603" to="606" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Image manipulation detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bayram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Avcubas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sankur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Memon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Electron. Imag</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4110201" to="4110217" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust median filtering forensics based on the autoregressive model of median filter residual</title>
		<author>
			<persName><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of APSIPA annual submit conference</title>
		<meeting>of APSIPA annual submit conference<address><addrLine>Los Angles</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12">2012. Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Median filtering detection using edge based prediction matrix</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWDW 2011</title>
		<meeting>of IWDW 2011<address><addrLine>Atlantic, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Furon</surname></persName>
		</author>
		<ptr target="http://bows2.ec-lille.fr/" />
		<title level="m">Break Our Watermarking System. 2nd Ed</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dresden Image Databasefor benchmarking digital imageforensics</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gloe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Böhme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Symposium on Applied Computing</title>
		<meeting>ACM Symposium on Applied Computing</meeting>
		<imprint>
			<date type="published" when="2010">March 22-26, 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Natural resources conservation service photo gallery</title>
		<ptr target="http://photogallery.nrcs.usda.gov" />
		<imprint>
			<publisher>United States Department of Agriculture</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
