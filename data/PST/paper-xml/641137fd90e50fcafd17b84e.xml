<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Query2doc: Query Expansion with Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-03-14">14 Mar 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<email>wangliang@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
							<email>fuwei@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Query2doc: Query Expansion with Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-03-14">14 Mar 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2303.07678v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems.</p><p>The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudodocuments. LLMs are trained on web-scale text corpora and are adept at knowledge memorization. The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning. Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-ofdomain results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information retrieval (IR) aims to locate relevant documents from a large corpus given a user issued query. It is a core component in modern search engines and researchers have invested for decades in this field. There are two mainstream paradigms for IR: lexical-based sparse retrieval, such as BM25, and embedding-based dense retrieval <ref type="bibr" target="#b29">(Xiong et al., 2021;</ref><ref type="bibr" target="#b19">Qu et al., 2021)</ref>. Although dense retrievers perform better when large amounts of labeled data are available <ref type="bibr" target="#b11">(Karpukhin et al., 2020)</ref>, BM25 remains competitive on out-ofdomain datasets <ref type="bibr" target="#b23">(Thakur et al., 2021)</ref>.</p><p>Query expansion <ref type="bibr" target="#b21">(Rocchio, 1971;</ref><ref type="bibr" target="#b12">Lavrenko and Croft, 2001</ref>) is a long-standing technique that rewrites the query based on pseudo-relevance feedback or external knowledge sources such as WordNet. For sparse retrieval, it can help bridge the lexical gap between the query and the documents. However, query expansion methods like RM3 <ref type="bibr" target="#b12">(Lavrenko and Croft, 2001;</ref><ref type="bibr" target="#b15">Lv and Zhai, 2009)</ref> have only shown limited success on popular datasets <ref type="bibr" target="#b3">(Campos et al., 2016)</ref>, and most state-ofthe-art dense retrievers do not adopt this technique. In the meantime, document expansion methods like doc2query <ref type="bibr" target="#b18">(Nogueira et al., 2019)</ref> have proven to be effective for sparse retrieval.</p><p>In this paper, we demonstrate the effectiveness of LLMs <ref type="bibr" target="#b2">(Brown et al., 2020)</ref> as query expansion models by generating pseudo-documents conditioned on few-shot prompts. Given that search queries are often short, ambiguous, or lack necessary background information, LLMs can provide relevant information to guide retrieval systems, as they memorize an enormous amount of knowledge and language patterns by pre-training on trillions of tokens.</p><p>Our proposed method, called query2doc, generates pseudo-documents by few-shot prompting LLMs and concatenates them with the original query to form a new query. This method is simple to implement and does not require any changes in training pipelines or model architectures, making it orthogonal to the progress in the field of LLMs and information retrieval. Future methods can easily build upon our query expansion framework.</p><p>For in-domain evaluation, we adopt the MS-MARCO passage ranking <ref type="bibr" target="#b3">(Campos et al., 2016)</ref>, TREC DL 2019 and 2020 datasets. Pseudodocuments are generated by prompting an improved version of GPT-3 text-davinci-003 from OpenAI <ref type="bibr" target="#b2">(Brown et al., 2020)</ref>. Results show that query2doc substantially improves the off-the-shelf BM25 algorithm without fine-tuning any model, particularly for hard queries from the TREC DL track. Strong dense retrievers, including DPR <ref type="bibr" target="#b11">(Karpukhin et al., 2020)</ref>, SimLM <ref type="bibr">(Wang et al., 2022a)</ref>, and E5 <ref type="bibr">(Wang et al., 2022b</ref>) also benefit from query2doc, although the gains tend to be diminishing when distilling from a strong crossencoder based re-ranker. Experiments in zero-shot OOD settings demonstrate that our method out-performs strong baselines on most datasets. Further analysis also reveals the importance of model scales: query2doc works best when combined with the most capable LLMs while small language models only provide marginal improvements over baselines.</p><p>To  Given a query q, we employ few-shot prompting to generate a pseudo-document d as depicted in Figure <ref type="figure" target="#fig_0">1</ref>. The prompt comprises a brief instruction "Write a passage that answers the given query:" and k labeled pairs randomly sampled from a training set. We use k = 4 throughout this paper. Subsequently, we rewrite q to a new query q + by concatenating with the pseudo-document d . There are slight differences in the concatenation operation for sparse and dense retrievers, which we elaborate on in the following section.</p><p>Sparse Retrieval Since the query q is typically much shorter than pseudo-documents, we boost the query term weights by repeating the query n times before concatenating with the pseudo-document d :</p><formula xml:id="formula_0">q + = concat({q} ? n, d ) (1)</formula><p>Here, "concat" denotes the string concatenation function. q + is used as the new query for BM25 retrieval. We find that n = 5 is a generally good value and do not tune it on a dataset basis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dense Retrieval</head><p>The new query q + is a simple concatenation of the original query q and the pseudo-document d separated by <ref type="bibr">[SEP]</ref>:</p><formula xml:id="formula_1">q + = concat(q, [SEP], d )<label>(2)</label></formula><p>For training dense retrievers, several factors can influence the final performance, such as hard negative mining <ref type="bibr" target="#b29">(Xiong et al., 2021)</ref>, intermediate pretraining <ref type="bibr" target="#b8">(Gao and Callan, 2021)</ref>, and knowledge distillation from a cross-encoder based re-ranker <ref type="bibr" target="#b19">(Qu et al., 2021)</ref>. In this paper, we investigate two settings to gain a more comprehensive understanding of our method. The first setting is training DPR <ref type="bibr" target="#b11">(Karpukhin et al., 2020)</ref> models initialized from BERT base with BM25 hard negatives only. The optimization objective is a standard contrastive loss:</p><formula xml:id="formula_2">L cont = -log e hq?h d e hq?h d + d i ?N e hq?h d i<label>(3)</label></formula><p>where h q and h d represent the embeddings for the query and document, respectively. N denotes the set of hard negatives.</p><p>The second setting is to build upon state-of-theart dense retrievers and use KL divergence to distill from a cross-encoder teacher model.</p><formula xml:id="formula_3">min D KL (p ce , p stu ) + ?L cont (4)</formula><p>p ce and p stu are the probabilities from the crossencoder and our student model, respectively. ? is a coefficient to balance the distillation loss and contrastive loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Pseudo-relevance Feedback</head><p>Our proposed method can be viewed as a variant of pseudo-relevance feedback (PRF) <ref type="bibr" target="#b12">(Lavrenko and Croft, 2001;</ref><ref type="bibr" target="#b15">Lv and Zhai, 2009)</ref>. In conventional PRF, the feedback signals for query expansion come from the top-k documents obtained in the initial retrieval step, while our method prompts LLMs to generate pseudo-documents. Our method does not rely on the quality of the initial retrieval results, which are often noisy or irrelevant. Rather, it exploits cutting-edge LLMs to generate documents that are more likely to contain relevant terms.  <ref type="bibr">(Craswell et al., 2020a)</ref> and 2020 <ref type="bibr">(Craswell et al., 2020b)</ref> datasets.</p><p>For zero-shot out-of-domain evaluation, we select five low-resource datasets from the BEIR benchmark <ref type="bibr" target="#b23">(Thakur et al., 2021)</ref>. The evaluation metrics include MRR@10, R@k (k ? {50, 1k}), and nDCG@10.</p><p>Hyperparameters For sparse retrieval including BM25 and RM3, we adopt the default implementation from Pyserini <ref type="bibr">(Lin et al., 2021)</ref>. When training dense retrievers, we use mostly the same hyperparameters as SimLM <ref type="bibr">(Wang et al., 2022a)</ref>, with the exception of increasing the maximum query length to 144 to include pseudo-documents. When prompting LLMs, we include 4 in-context examples and use the default temperature of 1 to sample at most 128 tokens. For further details, please refer to Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Main Results</head><p>In Table <ref type="table" target="#tab_1">1</ref>, we list the results on the MS-MARCO passage ranking and TREC DL datasets. For sparse retrieval, "BM25 + query2doc" beats the BM25 baseline with over 15% improvements on TREC DL 2019 and 2020 datasets. Our manual inspection reveals that most queries from the TREC DL track are long-tailed entity-centric queries, which benefit more from the exact lexical match. The traditional query expansion method RM3 only marginally improves the R@1k metric. Although the document expansion method docT5query achieves better numbers on the MS-MARCO dev set, it requires training a T5-based query generator with all the available labeled data, while "BM25 + query2doc" does not require any model fine-tuning.</p><p>For dense retrieval, the model variants that combine with query2doc also outperform the corresponding baselines on all metrics. However, the gain brought by query2doc tends to diminish when using intermediate pre-training or knowledge distillation from cross-encoder re-rankers, as shown by the "SimLM + query2doc" and "E5 + query2doc" results.</p><p>For zero-shot out-of-domain retrieval, the results are mixed as shown in Table <ref type="table">2</ref>. Entity-centric datasets like DBpedia see the largest improvements. On the NFCorpus and Scifact datasets, we observe a minor decrease in ranking quality. This is likely due to the distribution mismatch between training and evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis</head><p>Scaling up LLMs is Critical For our proposed method, a question that naturally arises is: how does the model scale affect the quality of query expansion? Table <ref type="table" target="#tab_2">3</ref> shows that the performance steadily improves as we go from the 1.3B model DBpedia NFCorpus Scifact Trec-Covid Touche2020 BM25 31.3 32.5 66.5 65.6 36.7 + query2doc 37.0 +5.7 34.9 +2.4 68.6 +2.<ref type="foot" target="#foot_0">1</ref> 72.2 +6.6 39.8 +3.1 SimLM <ref type="bibr">(Wang et al., 2022a)</ref> 34.9 32.7 62.4 55.0 18.9 + query2doc 38.3 +3.4  32.1 -0.6 59.5 -2.9 59.9 +4.9 25.6 +6.7 E5 base + KD <ref type="bibr">(Wang et al., 2022b)</ref>  to 175B models. Empirically, the texts generated by smaller language models tend to be shorter and contain more factual errors. Also, the "davinci-003" model outperforms its earlier version "davinci-001" by using better training data and improved instruction tuning. How to Use Pseudo-documents In this paper, we concatenate the original query and pseudodocuments as the new query. Alternatively, one can solely use the pseudo-documents, as done in the approach of HyDE <ref type="bibr" target="#b9">(Gao et al., 2022)</ref>. The results presented in Table <ref type="table" target="#tab_3">4</ref> demonstrate that the original query and pseudo-documents are complementary, and their combination leads to substantially better performance in sparse retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Analysis</head><p>In Table <ref type="table" target="#tab_5">5</ref>, we show two queries along with their respective pseudo-documents and groundtruth. The pseudo-documents, which are generated by LLMs, offer detailed and mostly accurate information, thereby reducing the lexical mismatch between the query and documents. In some cases, the pseudo-documents are sufficient to meet the user's information needs, rendering the retrieval step unnecessary. However, it is worth noting that the LLM generations may contain factual errors. For instance, in the second query, the theme song "It's a Jungle Out There" was used as of season two in 2003, not 2002 1 . Although such errors may appear subtle and difficult to verify, they pose a significant challenge to building trustworthy systems using LLMs.</p><p>query who killed nicholas ii of russia LLM generation Nicholas II of Russia, the last Tsar of Russia, was executed by Bolshevik revolutionaries on July 17th, 1918, along with his wife Alexandra and their five children. The execution was ordered by Vladimir Lenin, the leader of the Bolshevik Party. The actual execution was carried out by a firing squad of Bolshevik troops, and the bodies were later buried in a mass grave. . . Groundtruth   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Query Expansion and Document Expansion are two classical techniques to improve retrieval quality, particularly for sparse retrieval systems.</p><p>Both techniques aim to minimize the lexical gap between the query and the documents. Query expansion typically involves rewriting the query based on relevance feedback <ref type="bibr" target="#b12">(Lavrenko and Croft, 2001;</ref><ref type="bibr" target="#b21">Rocchio, 1971)</ref> or lexical resources such as Word-Net <ref type="bibr" target="#b16">(Miller, 1992)</ref>. In cases where labeled relevance feedback is not available, the top-k retrieved documents can serve as pseudo-relevance feedback signals <ref type="bibr" target="#b15">(Lv and Zhai, 2009)</ref>. In contrast, document expansion enriches the document representation by appending additional relevant terms. Doc2query <ref type="bibr" target="#b18">(Nogueira et al., 2019)</ref> trains a seq2seq model to predict pseudo-queries based on documents and then adds generated pseudo-queries to the document index. Learned sparse retrieval models such as SPLADE <ref type="bibr" target="#b7">(Formal et al., 2021)</ref> and uniCOIL <ref type="bibr">(Lin and Ma, 2021)</ref> also learn document term weighting in an end-toend fashion. However, most state-of-the-art dense retrievers <ref type="bibr" target="#b20">(Ren et al., 2021;</ref><ref type="bibr">Wang et al., 2022a)</ref> do not adopt any expansion techniques. Our paper demonstrates that strong dense retrievers also benefit from query expansion using LLMs. Large Language Models (LLMs) such as <ref type="bibr">GPT-3 (Brown et al., 2020)</ref>, PaLM <ref type="bibr">(Chowdhery et al., 2022)</ref>, and LLaMA <ref type="bibr">(Touvron et al., 2023)</ref> are trained on trillions of tokens with billions of parameters, exhibiting unparalleled generalization ability across various tasks. LLMs can follow instructions in a zero-shot manner or conduct in-context learning through few-shot prompting. Labeling a few high-quality examples only requires minimal human effort. In this paper, we employ few-shot prompting to generate pseudo-documents from a given query. A closely related recent work HyDE <ref type="bibr" target="#b9">(Gao et al., 2022)</ref> instead focuses on the zeroshot setting and uses embeddings of the pseudodocuments for similarity search. HyDE implicitly assumes that the groundtruth document and pseudodocuments express the same semantics in different words, which may not hold for some queries. In the field of question answering, RECITE <ref type="bibr" target="#b22">(Sun et al., 2022)</ref> and GENREAD <ref type="bibr" target="#b30">(Yu et al., 2022)</ref> demonstrate that LLMs are powerful context generators and can encode abundant factual knowledge. However, as our analysis shows, LLMs can sometimes generate false claims, hindering their practical application in critical areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper presents a simple method query2doc to leverage LLMs for query expansion. It first prompts LLMs with few-shot examples to generate pseudo-documents and then integrates with existing sparse or dense retrievers by augmenting queries with generated pseudo-documents. The underlying motivation is to distill the LLMs through prompting. Despite its simplicity, empirical evaluations demonstrate consistent improvements across various retrieval models and datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>LLM call Index search BM25 -16ms + query2doc &gt;2000ms 177ms</p><p>Table <ref type="table">6</ref>: Latency analysis for retrieval systems with our proposed query2doc. We retrieve the top 100 results for MS-MARCO dev queries with a single thread and then average over all the queries. The latency for LLM API calls depends on server load and is difficult to precisely measure.</p><p>An apparent limitation is the efficiency of retrieval. Our method requires running inference with LLMs which can be considerably slower due to the token-by-token autoregressive decoding. Moreover, with query2doc, searching the inverted index also becomes slower as the number of query terms increases after expansion. This is supported by the benchmarking results in Table <ref type="table">6</ref>. Real-world deployment of our method should take these factors into consideration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of query2doc few-shot prompting. We omit some in-context examples for space reasons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Main results on the MS-MARCO passage ranking and TREC datasets. The "Fine-tuning" column indicates whether the method requires fine-tuning model on labeled data or not. * : our reproduction.</figDesc><table><row><cell>Method</cell><cell>Fine-tuning</cell><cell cols="3">MS MARCO dev MRR@10 R@50 R@1k</cell><cell cols="2">TREC DL 19 TREC DL 20 nDCG@10 nDCG@10</cell></row><row><cell>Sparse retrieval</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BM25</cell><cell></cell><cell>18.4</cell><cell>58.5</cell><cell>85.7</cell><cell>51.2  *</cell><cell>47.7  *</cell></row><row><cell>+ query2doc</cell><cell></cell><cell>21.4 +3.0</cell><cell cols="3">65.3 +6.8 91.8 +6.1 66.2 +15.0</cell><cell>62.9 +15.2</cell></row><row><cell>BM25 + RM3</cell><cell></cell><cell>15.8</cell><cell>56.7</cell><cell>86.4</cell><cell>52.2</cell><cell>47.4</cell></row><row><cell>docT5query (Nogueira and Lin)</cell><cell></cell><cell>27.7</cell><cell>75.6</cell><cell>94.7</cell><cell>64.2</cell><cell>-</cell></row><row><cell>Dense retrieval w/o distillation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ANCE (Xiong et al., 2021)</cell><cell></cell><cell>33.0</cell><cell>-</cell><cell>95.9</cell><cell>64.5</cell><cell>64.6</cell></row><row><cell>HyDE (Gao et al., 2022)</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>61.3</cell><cell>57.9</cell></row><row><cell>DPR bert-base (our impl.)</cell><cell></cell><cell>33.7</cell><cell>80.5</cell><cell>95.9</cell><cell>64.7</cell><cell>64.1</cell></row><row><cell>+ query2doc</cell><cell></cell><cell>35.1 +1.4</cell><cell cols="3">82.6 +2.1 97.2 +1.3 68.7 +4.0</cell><cell>67.1 +3.0</cell></row><row><cell>Dense retrieval w/ distillation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RocketQAv2 (Ren et al., 2021)</cell><cell></cell><cell>38.8</cell><cell>86.2</cell><cell>98.1</cell><cell>-</cell><cell>-</cell></row><row><cell>AR2 (Zhang et al., 2021)</cell><cell></cell><cell>39.5</cell><cell>87.8</cell><cell>98.6</cell><cell>-</cell><cell>-</cell></row><row><cell>SimLM (Wang et al., 2022a)</cell><cell></cell><cell>41.1</cell><cell>87.8</cell><cell>98.7</cell><cell>71.4</cell><cell>69.7</cell></row><row><cell>+ query2doc</cell><cell></cell><cell>41.5 +0.4</cell><cell cols="3">88.0 +0.2 98.8 +0.1 72.9 +1.5</cell><cell>71.6 +1.9</cell></row><row><cell>E5 base + KD (Wang et al., 2022b)</cell><cell></cell><cell>40.7</cell><cell>87.6</cell><cell>98.6</cell><cell>74.3</cell><cell>70.7</cell></row><row><cell>+ query2doc</cell><cell></cell><cell>41.5 +0.8</cell><cell cols="3">88.1 +0.5 98.7 +0.1 74.9 +0.6</cell><cell>72.5 +1.8</cell></row><row><cell>3 Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3.1 Setup</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p>Evaluation Datasets For in-domain evaluation, we utilize the MS-MARCO passage ranking</p><ref type="bibr" target="#b3">(Campos et al., 2016)</ref></p>, TREC DL 2019</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Query expansion with different model sizes.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>40.7</cell><cell>35.0</cell><cell>70.4</cell><cell>74.1</cell><cell>30.9</cell></row><row><cell>+ query2doc</cell><cell></cell><cell></cell><cell>42.4 +1.7</cell><cell>35.2 +0.2</cell><cell>67.5 -2.9 75.1 +1.0</cell><cell>31.7 +0.8</cell></row><row><cell cols="6">Table 2: Zero-shot out-of-domain results on 5 low-resource datasets from the BEIR benchmark (Thakur et al.,</cell></row><row><cell cols="6">2021). The reported numbers are nDCG@10. For a fair comparison, the in-context examples for prompting LLMs</cell></row><row><cell cols="3">come from the MS-MARCO training set.</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3"># params TREC 19 TREC 20</cell><cell></cell></row><row><cell>BM25</cell><cell>-</cell><cell>51.2</cell><cell>47.7</cell><cell></cell></row><row><cell>w/ babbage</cell><cell>1.3B</cell><cell>52.0</cell><cell>50.2</cell><cell></cell></row><row><cell>w/ curie</cell><cell>6.7B</cell><cell>55.1</cell><cell>50.1</cell><cell></cell></row><row><cell>w/ davinci-001</cell><cell>175B</cell><cell>63.5</cell><cell>58.2</cell><cell></cell></row><row><cell>w/ davinci-003</cell><cell>175B</cell><cell>66.2</cell><cell>62.9</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Using the concatenation of the original query and the generated pseudo-documents perform substantially better.</figDesc><table><row><cell>MRR on dev set</cell><cell>26 28 30 32 34 36</cell><cell>27.3 28.5</cell><cell>31.4 32.1</cell><cell>32.8 34.1</cell><cell>33.7 35.1</cell></row><row><cell></cell><cell>20 22 24</cell><cell>1 10 21.4 22.7</cell><cell cols="3">30 % labeled data for fine-tuning 50 DPR w/o query2doc 100 DPR w/ query2doc</cell></row><row><cell cols="6">Figure 2: MRR on MS-MARCO dev set w.r.t the per-</cell></row><row><cell cols="5">centage of labeled data used for fine-tuning.</cell><cell></cell></row><row><cell cols="6">Performance Gains are Consistent across Data</cell></row><row><cell cols="6">Scales Figure 2 presents a comparison between</cell></row><row><cell cols="6">two variants of DPR models, which differ in the</cell></row><row><cell cols="6">amount of labeled data used. The results show</cell></row><row><cell cols="6">that the "DPR + query2doc" variant consistently</cell></row><row><cell cols="6">outperforms the DPR baseline by approximately</cell></row><row><cell cols="6">1%, regardless of the amount of data used for</cell></row><row><cell cols="6">fine-tuning. This observation highlights that our</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>. Nicholas II was the last emperor, or tsar, of Russia, serving from 1894 to 1917. Nicholas, his wife, and their five children were killed by the Bolsheviks, members of a revolutionary group (led by Lenin) who seized control of the government in Russia during the October Revolution (see Russian Revolution) of 1917. query who sings monk theme song LLM generation The theme song for the television show Monk is entitled "It's a Jungle Out There" and is sung by American singer-songwriter Randy Newman. The song was written specifically for the show, and it has been used as the theme song since the series premiered in 2002. It has been praised by critics and fans alike and is often regarded as one of the best theme songs in television history. Groundtruth exists and is an alternate of. The Monk theme song is It's a Jungle Out There by Randy Newman. The Monk theme song is It's a Jungle Out There by Randy Newman.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Examples from the TREC DL 2020 dataset. Bold texts are the overlapping words between groundtruth and pseudo-documents generated from LLMs. The italicized red sentence demonstrates a factual error in language model generations.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Refer to https://en.wikipedia.org/wiki/It's_a_Jungle_Out_There_(song)   </p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The key difference between HRA and HSA is that HRA is an employer funded health benefit plan that reimburses for medical expenses including personal health insurance policy premiums of employees whereas HSA is also a tax-advantaged health benefit plan exclusively available to taxpayers in the United States who are enrolled in a High-Deductible Health Plan (HDHP).</p><p>Table <ref type="table">7</ref>: More examples of LLM generations. The format is the same as in Table <ref type="table">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Implementation Details</head><p>For dense retrieval experiments in To compute the text embeddings, we utilize the [CLS] vector for SimLM and mean pooling for E5. This makes sure that the pooling mechanisms remain consistent between intermediate pre-training and fine-tuning.</p><p>When prompting LLMs, we include 4 in-context examples from the MS-MARCO training set. To increase prompt diversity, we randomly select 4 examples for each API call. A complete prompt is shown in Table <ref type="table">9</ref>.</p><p>Regarding out-of-domain evaluations on DBpedia <ref type="bibr" target="#b10">(Hasibi et al., 2017)</ref>, NFCorpus <ref type="bibr" target="#b1">(Boteva et al., 2016)</ref>, Scifact <ref type="bibr" target="#b26">(Wadden et al., 2020)</ref>, Trec-Covid <ref type="bibr" target="#b25">(Voorhees et al., 2021)</ref> For ablation experiments in Figure <ref type="figure">2</ref>, we finetune for 40 epochs or 18k steps, whichever is reached first. prompts Write a passage that answers the given query:</p><p>Query: what state is this zip code 85282 Passage: Welcome to TEMPE, AZ 85282. 85282 is a rural zip code in Tempe, Arizona. The population is primarily white, and mostly single. At $200,200 the average home value here is a bit higher than average for the Phoenix-Mesa-Scottsdale metro area, so this probably isn't the place to look for housing bargains.5282 Zip code is located in the Mountain time zone at 33 degrees latitude (Fun Fact: this is the same latitude as Damascus, Syria!) and -112 degrees longitude.</p><p>Query: why is gibbs model of reflection good Passage: In this reflection, I am going to use <ref type="bibr">Gibbs (1988)</ref> Reflective Cycle. This model is a recognised framework for my reflection. Gibbs (1988) consists of six stages to complete one cycle which is able to improve my nursing practice continuously and learning from the experience for better practice in the future.n conclusion of my reflective assignment, I mention the model that I chose, <ref type="bibr">Gibbs (1988)</ref> Reflective Cycle as my framework of my reflective. I state the reasons why I am choosing the model as well as some discussion on the important of doing reflection in nursing practice.</p><p>Query: what does a thousand pardons means Passage: Oh, that's all right, that's all right, give us a rest; never mind about the direction, hang the direction -I beg pardon, I beg a thousand pardons, I am not well to-day; pay no attention when I soliloquize, it is an old habit, an old, bad habit, and hard to get rid of when one's digestion is all disordered with eating food that was raised forever and ever before he was born; good land! a man can't keep his functions regular on spring chickens thirteen hundred years old. Table <ref type="table">9</ref>: The full prompt used for the example in Figure <ref type="figure">1</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Overview of touch? 2022: argument retrieval</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maik</forename><surname>Fr?be</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahbaz</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timon</forename><surname>Gurcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meriem</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="311" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A full-text learning to rank dataset for medical information retrieval</title>
		<author>
			<persName><forename type="first">Vera</forename><surname>Boteva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Demian</forename><surname>Gholipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="716" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mc-Candlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>NeurIPS 2020, December 6-12, 2020, virtual</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fernando Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<idno>ArXiv, abs/1611.09268</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><forename type="middle">M</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benton</forename><forename type="middle">C</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garc?a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>D?az</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><forename type="middle">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><surname>Eck</surname></persName>
		</author>
		<idno>ArXiv, abs/2204.02311</idno>
		<imprint>
			<pubPlace>Jeff Dean, Slav Petrov</pubPlace>
		</imprint>
	</monogr>
	<note>and Noah Fiedel. 2022. Palm: Scaling language modeling with pathways</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Overview of the trec 2019 deep learning track</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<idno>abs/2003.07820</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Overview of the trec 2020 deep learning track</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fernando Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<idno>ArXiv, abs/2003.07820</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Splade: Sparse lexical and expansion model for first stage ranking</title>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Formal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">St?phane</forename><surname>Clinchant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Condenser: a pretraining architecture for dense retrieval</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.75</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="981" to="993" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Precise zero-shot dense retrieval without relevance labels</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno>ArXiv, abs/2212.10496</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dbpedia-entity v2: A test collection for entity search</title>
		<author>
			<persName><forename type="first">Faegheh</forename><surname>Hasibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Nikolaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Svein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Bratsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Kotov</surname></persName>
		</author>
		<author>
			<persName><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3077136.3080751</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-08-07">2017. August 7-11, 2017</date>
			<biblScope unit="page" from="1265" to="1268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relevancebased language models</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="260" to="267" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A few brief notes on deepimpact, coil, and a conceptual framework for information retrieval techniques</title>
		<author>
			<persName><forename type="first">Jimmy</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<idno>ArXiv, abs/2106.14807</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Pyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations</title>
		<author>
			<persName><forename type="first">Jimmy</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Cheriton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comparative study of methods for estimating query language models with pseudo feedback</title>
		<author>
			<persName><forename type="first">Yuanhua</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">WordNet: A lexical database for English</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language: Proceedings of a Workshop</title>
		<meeting><address><addrLine>Harriman, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-02-23">1992. February 23-26, 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">From doc2query to doctttttquery</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno>ArXiv, abs/1904.08375</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">Yingqi</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiyang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.466</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5835" to="5847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">RocketQAv2: A joint training method for dense passage retrieval and passage re-ranking</title>
		<author>
			<persName><forename type="first">Ruiyang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqi</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoqiao</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.224</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2825" to="2835" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Relevance feedback in information retrieval</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Recitation-augmented language models</title>
		<author>
			<persName><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno>ArXiv, abs/2210.01296</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Beir: A heterogeneous benchmark for zero-shot evaluation of information retrieval models</title>
		<author>
			<persName><forename type="first">Nandan</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Abhishek Srivastava, and Iryna Gurevych. Round 2</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timoth?e</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozi?re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Aur'elien Rodriguez</surname></persName>
		</author>
		<author>
			<persName><surname>Joulin</surname></persName>
		</author>
		<idno>ArXiv, abs/2302.13971</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Trec-covid: constructing a pandemic information retrieval test collection</title>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tasmeer</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>William R Hersh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Forum</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fact or fiction: Verifying scientific claims</title>
		<author>
			<persName><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.609</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7534" to="7550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">2022a. Simlm: Pre-training with representation bottleneck for dense passage retrieval</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binxing</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno>ArXiv, abs/2207.02578</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Rangan Majumder, and Furu Wei. 2022b. Text embeddings by weakly-supervised contrastive pre-training</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binxing</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<idno>ArXiv, abs/2212.03533</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2021-05-03">2021. May 3-7, 2021</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Generate rather than retrieve: Large language models are strong context generators</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<idno>ArXiv, abs/2209.10063</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Adversarial retriever-ranker for dense text retrieval</title>
		<author>
			<persName><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancheng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/2110.03611</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
