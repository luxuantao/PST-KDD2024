<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling the Impact of Short-and Long-Term Behavior on Search Personalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
							<email>ryenw@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Chu</surname></persName>
							<email>wechu@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
							<email>sdumais@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Bailey</surname></persName>
							<email>pbailey@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fedor</forename><surname>Borisyuk</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoyuan</forename><surname>Cui</surname></persName>
							<email>xcui@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Microsoft</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Microsoft</forename><surname>Bing</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Microsoft</forename><surname>Server</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Tools</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling the Impact of Short-and Long-Term Behavior on Search Personalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">280F72E0E140FADC351063A77A26DB78</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval -search process</term>
					<term>selection process Personalization</term>
					<term>Web search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>User behavior provides many cues to improve the relevance of search results through personalization. One aspect of user behavior that provides especially strong signals for delivering better relevance is an individual's history of queries and clicked documents. Previous studies have explored how short-term behavior or long-term behavior can be predictive of relevance. Ours is the first study to assess how short-term (session) behavior and long-term (historic) behavior interact, and how each may be used in isolation or in combination to optimally contribute to gains in relevance through search personalization. Our key findings include: historic behavior provides substantial benefits at the start of a search session; short-term session behavior contributes the majority of gains in an extended search session; and the combination of session and historic behavior out-performs using either alone. We also characterize how the relative contribution of each model changes throughout the duration of a session. Our findings have implications for the design of search systems that leverage user behavior to personalize the search experience.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Search personalization improves retrieval effectiveness by tailoring the ranking of results for individual users based on models of their interests <ref type="bibr" target="#b23">[24]</ref>[28] <ref type="bibr" target="#b28">[29]</ref>. To construct the profiles necessary for search personalization, evidence of a user's interests can be mined from observed past behaviors. This behavior can be sourced from the short-term (e.g., the current search session) <ref type="bibr" target="#b33">[34]</ref> or the longterm (e.g., across many previous sessions) <ref type="bibr" target="#b24">[25]</ref>. These studies have shown that personalization is important but often care must be taken in how it is applied, e.g., we may only want to personalize queries which have high click entropy <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b29">[30]</ref>.</p><p>An important determinant of the success of personalization is the behavioral information that is used to construct user profiles. Although there has been some work examining the effect of different contextual sources for modeling user interests <ref type="bibr" target="#b21">[22]</ref> <ref type="bibr" target="#b32">[33]</ref>, another critical aspect of personalization is the timespan of the behavioral information used for profile construction. Short-term profiles capture recent interactions but lack users' long-term interests.</p><p>Long-term profiles represent long-term interests but may not adequately represent searcher needs for the current task. Earlier attempts to address this challenge leveraged different representations for each source <ref type="bibr" target="#b17">[18]</ref> or made ad hoc decisions around how to weight distant actions <ref type="bibr" target="#b26">[27]</ref>. A principled investigation of the impact of short-and long-term behavior on search personalization is lacking and we address that shortcoming with the research presented here.</p><p>In this paper, we investigate how users' long-term search activity history interacts with their short-term search session behavior. We characterize these interactions using a framework for modeling behavior from different timespans and predicting search relevance. We explore the effectiveness of user profiles developed based on different temporal views. Although each model makes use of sets of search activity gathered over different durations, the same feature set is used for each time span to remove that source of variation, and decay factors (among other things) are studied in a principled manner. We evaluate the success of these models via a large search log containing queries, results, and clicks, enabling us to compare the performance of each personalized ranker relative to that of a high quality commercial search engine in a manner similar to previous personalization research <ref type="bibr" target="#b7">[8]</ref>[25] <ref type="bibr" target="#b33">[34]</ref>. We make the following unique contributions with this research:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Propose a novel unified modeling framework that provides an integrative view of different parameters of personalization and controls key aspects such as the features generated from behavior and decay factors employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Study dynamics in the relative contribution to personalization of short-and long-term models over the course of a session. As part of our analysis, we confirm intuitions that longterm behavior is useful at the start of a session and that shortterm models yield benefit as the session proceeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Provide new findings on search personalization, such as the special properties of the first query in the session, and the strong performance of models that learn to combine shortand long-term features for each query, rather than simply aggregating all features; suggesting that individual queries differentially benefit from short-and long-term personalization.</p><p>The remainder of this paper is structured as follows. Section 2 presents related work on model-based user behavior analysis for search personalization. Section 3 describes our unified framework for combining a user's (long-term) historical behavior with their (short-term) session activity and outlines the features and model training. Section 4 describes the experiment, including the data and methodology. We present findings in Section 5, discuss them and their implications in Section 6, and conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>There is growing interest in the information retrieval (IR) community in examining how knowledge of a searcher's interests and context can be used to improve various aspects of search such as Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGIR <ref type="bibr">'12, August 12-16, 2012</ref>, Portland, Oregon, USA.</p><p>Copyright 2012 ACM 978-1-4503-1472-5/12/08...$15.00.</p><p>ranking or query suggestion. Here we review prior research that examines the use of implicit user profiles generated using a user's searching and browsing actions (queries, clicks on search results, and subsequent navigation) to personalize Web search.</p><p>Recent investigations that employ a user's search and browse actions to influence search personalization include those based on: a user's location <ref type="bibr" target="#b0">[1]</ref>, a user's history of search activity <ref type="bibr" target="#b24">[25]</ref>, the ability of a user to read at differing levels of complexity <ref type="bibr" target="#b7">[8]</ref> and patterns of re-finding the same search result <ref type="bibr" target="#b30">[31]</ref>. Others discuss how different forms of context and search activity may be used to cast search behavior as a prediction problem <ref type="bibr">[22][33]</ref>.</p><p>Several research groups have investigated personalizing search results using user profiles that comprise topical representations of users' search interests. Gauch et al. <ref type="bibr" target="#b13">[14]</ref> learned user profiles from browsing history, Speretta and Gauch <ref type="bibr" target="#b25">[26]</ref> built profiles using search history, and Chirita et al. <ref type="bibr" target="#b6">[7]</ref> and Ma et al. <ref type="bibr" target="#b18">[19]</ref> used profiles that users specified explicitly. In all cases, interest profiles were compared with those of search results and used to affect the order in which results were presented to individuals. Bennett et al.</p><p>[2] demonstrated how category features from the Open Directory Project (ODP, dmoz.org) could be used to improve search ranking in the aggregate for all users but not for individual searchers.</p><p>The context of search activities within the current session has been used to build richer models of interests and improve how the search system interprets the user's current query. Cao et al. <ref type="bibr" target="#b3">[4]</ref>[5] represented search context within a session by modeling the sequence of user queries and clicks. They learned sequential prediction models from large-scale log data, and applied the models to URL recommendation, query suggestion, and query categorization. Mihalkova and Mooney <ref type="bibr" target="#b20">[21]</ref> used similar search session features to disambiguate the current search query. White et al. <ref type="bibr" target="#b33">[34]</ref> constructed topical models of searcher's interests using the current query and recent search activities such as queries and hyperlink clicks, and used these models to predict future interests. Models of short-term interests based on search queries and result clicks have also been used to improve search quality <ref type="bibr" target="#b8">[9]</ref>[24] <ref type="bibr" target="#b35">[36]</ref>. For example, Xiang et al. <ref type="bibr" target="#b35">[36]</ref> developed heuristics to promote search results with the same topical category if successive queries in a search session were related by general similarity, and were not specializations, generalizations or reformulations.</p><p>Much of the work on search personalization focuses on longerterm models of user interests. Teevan et al. <ref type="bibr" target="#b28">[29]</ref> developed rich long-term user models based on desktop search activities to improve ranking. Matthijs and Radlinski <ref type="bibr" target="#b19">[20]</ref> developed models of users' interests using browsing behavior and evaluated their ranking improvements using an interleaving methodology (merging original and personalized rankings and observing SERP clicks). Sontag et al. <ref type="bibr" target="#b24">[25]</ref> developed generative and discriminative probabilistic models using ODP category models from historical click data. They learned parameters based on the divergence of individual user behaviors from normative behaviors to re-rank search results and found the largest gains for an ensemble of the two models. Tan et al. <ref type="bibr" target="#b27">[28]</ref> studied long-term language model-based representations of users' interests based on queries, documents and clicks. They considered different amounts of history and found that for fresh queries recent history was the most important, but for recurring queries longer-term history was more important.</p><p>Although long-term models described above include short-term information, few explicitly study it separately. Dou et al. <ref type="bibr" target="#b10">[11]</ref> learned both click-based and topic-based user models over a 12day period. Personalization was most effective for queries with high click entropy (as has also been observed by Teevan et al. <ref type="bibr" target="#b29">[30]</ref>). Topic profiles resulted in highly variable performance across queries, and personalization was more effective for users with more historical information. Li et al. <ref type="bibr" target="#b17">[18]</ref> modeled short-and long-term user activities but used different representations for each. They built long-term profiles using topics from the Google Directory of previously-clicked results and short-term models using a cache of recently-clicked results. They compared reranking based on user models with Google Directory and observed some advantages of personalization for users with varied profiles (so-called ambiguous users). However the study involved only 12 users over a ten-day period, and they were instructed to search for specific topics, hobbies and to repeat queries. Sugiyama et al. <ref type="bibr" target="#b26">[27]</ref> modeled users' interests with both ephemeral short-term preferences and persistent long-term preferences, with an exponential decay on the importance of older information. They observed small improvements for personalized methods.</p><p>The research presented in this paper differs from previous work in several important ways. First, we present a unified framework over how interests are represented (as topics or URLs) and how short-and long-term temporal dynamics are modeled. Second, we examine the effects of the query position within a session on how these behavior models change in their relative contribution. Third, we show how to learn models that effectively combine short-and long-term behavior to create improved personalization models. Finally, our evaluation is conducted on large-scale logs from a major search engine over a two-month timespan, thus addressing scale and representativeness issues inherent in smaller studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PERSONALIZATION FRAMEWORK</head><p>We can model users' preferences from different temporal views of their history of interaction with the search engine. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the relationship between each of the three temporal views that comprise the framework. The figure also shows the position of the current query which we would like to personalize. We can build a model based only on recent interactions in an attempt to capture the user's current focus. One such approach used previously, and which we adopt in this work, is to look at session interaction <ref type="bibr" target="#b33">[34]</ref>. Additionally, we consider the historic interactions that a user had with the search engine prior to the current session, potentially comprising many days or weeks of activity. This longterm information may be useful in disambiguating underspecified queries by preferring results on topics known to be historically of interest to the user <ref type="bibr" target="#b24">[25]</ref>. In addition, since information seeking tasks may extend across many sessions <ref type="bibr" target="#b16">[17]</ref> the current task (session) may relate to previous sessions. This suggests a model that aggregates all history over a shifting time window, effectively combining short-and long-term interests.</p><p>To compare the contributions of the three different temporal views, we need a framework that yields comparable features in each of them. Otherwise, the success of one view may simply be an artifact of having modeled a component in one view that is missing from the other views. To do this, we present a novel</p><p>Current query (to be personalized) framework that incorporates both functions that correspond to the temporal views depicted in Figure <ref type="figure" target="#fig_0">1</ref> and time-weighting functions. We use two representations that are commonly studied in the literature: topics and URLs <ref type="bibr" target="#b13">[14]</ref>[20] <ref type="bibr" target="#b24">[25]</ref> and show how features often studied in prior research emerge from our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Historic Session</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aggregate</head><p>We now present our framework and explain how it incorporates the following factors that are understood to affect personalization quality <ref type="bibr" target="#b27">[28]</ref>[31] <ref type="bibr" target="#b33">[34]</ref>: recency; the similarity of the current query to past user queries; the similarity of a document to be ranked for the current query to the documents previously returned to a user; and how the user interacted with those past results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Framework Overview</head><p>Within the context of personalizing search based on past behavior, we consider a number of different factors. For example, given the user has issued query q, from the temporal view on the user's past search interactions, ( ), we can consider all related queries, ( ) where is the set of the user's past issued queries, the search results, and any behavioral interactions the user had with the results. We focus on clicks but skips (explicitly ignoring a result) and misses (failing to notice a result) can also be considered. The function ( ) returns a set of queries that are related to q. For each related query, , we also model the strength of its relationship to the current query for this user, ( ) which we abbreviate as . For each related query, the search engine returns a set of results, ( ) whose elements we refer to as , the documents returned for the related query. For each we consider both its similarity, ( ) to a document, d, for the current query when determining how we should estimate the relevance of d, and we may also consider what action, denoted as ( ), the user took with respect to the document (e.g., a satisfied click serving as an indication that the document is relevant <ref type="bibr" target="#b11">[12]</ref> <ref type="bibr" target="#b12">[13]</ref>). We can write a family of features related to personalization parameterized by choices for the related query function, the relationship weight, the similarity and the action. One such simple formulation that considers all of these factors to generate a feature value from a 〈 〉 triple is:</p><formula xml:id="formula_0">( ) ∑ ( ) ( ) ∑ ( ) ( )</formula><p>Given appropriate choices for the related query function, the weighting, similarity, and action, one can derive many commonly studied features for personalization. For example, when the set of related queries comprises all queries in the user's past interaction, the relationship weight is uniformly 1, the similarity function returns 1 for identical URLs and 0 otherwise, and the action is whether or not the user clicked on the document from the related query, then the resulting feature is simply the number of times the user has clicked on d. With the same choices except where the related queries are only queries from the past interactions that are identical, then one obtains the number of previous times the user clicked on d when issuing q, a quantity highly indicative of refinding in personalization research <ref type="bibr" target="#b30">[31]</ref>.</p><p>This framework is useful for studying different temporal views because it allows us to vary the weight and related query functions to capture temporal effects while ensuring each time view has comparable features. Furthermore, it is amenable to choosing multiple types of similarity functions and yielding comparable feature families. For example, given a representation of a document, d, as a vector of topic probabilities then one reasonable similarity function would be the inner product between the current document and the document from the related query, Again assuming that all queries in a user's history are uniformly weighted and the action is a click, then the resulting feature is the inner product between the topics of results that the user has clicked on in the past and the topics of the current document.</p><p>Seeing how this amounts to the inner product over all clicked on topics and d's topics is instructive in understanding how these features could be computed efficiently in practice. For any similarity function that can be written as the inner product of two documents by using a representation of the document, ( ), such that ( ) 〈 ( ) ( )〉, we can rewrite the inner product as an inner product of d and an aggregated weight vector:</p><formula xml:id="formula_1">( ) 〈 ( ) ∑ ( ) ( ) ∑ ( ) ( ) 〉 〈 ( ) ( )〉</formula><p>where ( ) is shorthand for the weight vector derived from the sum. This new weight vector is more convenient to work with because it can be updated simply by adding in the most recent interactions for any case where the relationship weight does not change based on the overall interaction history. Even when the related queries selection is more complex such as including all queries that are a superset of the current query, this can be computed efficiently by constructing an inverted index for each user mapping query words to weight vectors, (</p><p>).</p><p>When the representation ( ) returns a document's topic vector, one obtains quantities commonly used in studying personalization by topic <ref type="bibr" target="#b24">[25]</ref>. When the representation is based on identical URLs, we capture that by defining ( ) as a sparse vector over all URLs (i.e., 1 for the argument URL and 0 elsewhere). Now that we have laid the foundations for the framework and shown that it can be used to represent several previously-proposed personalization features, we address the problems of choosing functions for related queries, relationship weight, similarity, and actions motivated by literature on personalized search. Each combination of these will yield a feature which we use as input to the machine-learned ranker examined in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Selection and Weighting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Temporal Selection</head><p>We now return to our depiction of time views of a profile in Figure <ref type="figure" target="#fig_0">1</ref> and define concretely how we represent these views. We represent the Session, Historic, and Aggregate views as choices of the ( ) function. That is, the Session view returns the queries from the current session. If the related function is "identical queries", then together with the Session view filter the sum is over "identical queries within the session." Likewise, the Historic view returns queries before the current session, and the Aggregate view returns all queries in the user's past interactions. Thus, given choices for the parameterization of weight, similarity, and action, instead of having a single feature, we now have three features: a session version, a historic version, and an aggregate version. When we turn to modeling later in the paper, we separate the features and build models using only features from each view enabling us to study each view and compare the views with the same number and types of features in each.</p><p>Note that we chose to make a session distinction since sesssions have been commonly used as a proxy to identify task boundaries <ref type="bibr" target="#b14">[15]</ref> <ref type="bibr" target="#b16">[17]</ref>. Session has been used in the context of personalization to predict short-term activity <ref type="bibr" target="#b32">[33]</ref> <ref type="bibr" target="#b33">[34]</ref>, and it is currently of broad interest to the IR community as a track in the Text Retrieval Conference <ref type="bibr" target="#b15">[16]</ref>. For our purposes a session is demarcated by 30 minutes of user inactivity as described in <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Temporal Weighting</head><p>In addition to the session boundary, we may also posit that recent interactions of a user matter more than distant ones. This has been captured in personalization by introducing a decay function on past interactions <ref type="bibr" target="#b9">[10]</ref> <ref type="bibr" target="#b22">[23]</ref>[27] <ref type="bibr" target="#b33">[34]</ref>. We introduce a similar decay into our framework by setting the relationship weighting function, , to a decay value. Let ( ) refer to the number of queries in the time view (session, historic, aggregate) by which the related query precedes the current query. Thus ( ) =1 is the most recent previous query (in session, history, and aggregate respectively). Then we choose ( ) as the decay, where c is a decay factor. Rather than emphasizing absolute time, this emphasizes recent activity. Figure <ref type="figure" target="#fig_1">2</ref> shows the weights for various decay factors over previous queries. For experiments reported in this paper, we chose =0.95 (shown as a red dotted line in the figure) because it lies between the extremes of massively emphasizing recent activity and uniformly emphasizing all actions. We also used simple uniform weighting ( =1), shown as the blue solid horizontal line at the top of Figure <ref type="figure" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Query Generalization and Specialization</head><p>Various studies have demonstrated that users interact differently with results if they have recently generalized a query (reformulated by dropping words) or specialized it (reformulated by adding words) <ref type="bibr" target="#b35">[36]</ref>. Because of this we introduce four choices for the ( ) function: <ref type="bibr" target="#b0">(1)</ref> all queries in the user's profile (generated using ( )), giving rise to features that capture the user's preference for a document independent of the current query, ; (2) all queries exactly matching in the user's profile, which captures specific interactions; (3) all queries in the profile that are (improper) subsets of , which captures behavior on generalizations of (i.e. a subset has fewer words and is therefore more general); (4) all queries in the profile that are (improper) supersets of , which captures behavior on all specializations of . The subsets and supersets were determined after stopwords were removed and had to share at least one non-stopword with (i.e., empty sets were not permitted).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">URL Representation</head><p>As noted in Section 3.1, the user's interaction with a particular document is a useful predictor for personalization as an indicator of re-finding behavior. Therefore, we use one choice of ( ) which returns a sparse vector over URLs (document IDs) that is 1 for the dimension corresponding to the URL of 's argument and 0 elsewhere. As further discussed in Section 3.1, this gives rise to a variety of useful features depending on the remaining parameter choices, e.g., the user's preference (measured as number of clicks) for a document: (1) across all queries; (2) for the current query, ;</p><p>(3) for generalizations of ; and (4) for specializations of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Topical Representation</head><p>Topical representations of documents are commonly used in personalization studies (e.g., <ref type="bibr" target="#b13">[14]</ref>[25] <ref type="bibr" target="#b33">[34]</ref>). To obtain such a topic representation for this study, we labeled each document with a vector of probabilities of categories from the top two levels of the ODP hierarchy using a text-based classifier. Each document's vector was restricted to the three most probable classes. The classifier has a micro-averaged F1 value of 0.60 and is described more fully in <ref type="bibr" target="#b1">[2]</ref>. As mentioned in Section 3.1, given appropriate choices for the remaining parameters, this representation will yield features that capture the user's preference for the topics of : (1) across all queries; (2) for the current query, ; (3) for generalizations of ; and (4) for specializations of . To measure the similarity between the document's topical representation and ( ) resulting from the topic parameterization we use the cosine similarity, which is commonly used in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Search Actions</head><p>While a variety of behavioral signals have been studied in the literature, we restrict our choice for the ( ) function to satisfied (SAT) clicks on the search engine result page. A SAT click involves a user dwelling on the result for at least 30 seconds or one which terminates the search session <ref type="bibr" target="#b11">[12]</ref> <ref type="bibr" target="#b12">[13]</ref>. We focus on SAT clicks since research indicates that dwell time is indicative of relevance and that clicks with short dwell times ("quick backs") are unlikely to be relevant <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Profile Information Measures</head><p>Personalization studies have also commonly introduced features that measure the amount of information known about the user or the appropriateness of personalizing for a query <ref type="bibr" target="#b0">[1]</ref>[8][30] <ref type="bibr" target="#b33">[34]</ref>. Similar notions also emerge from our framework. When the choice of relationship weight, the representation, and action are all non-negative, then ( ) can be treated as describing a probability space over the representation space, ( ) by normalizing across the feature dimensions. In fact, if we further summed across all users when the relationship is exact query match, with the URL representation, and click actions, then the entropy of the resulting vector is QueryClickEntropy, commonly referred to as click entropy in earlier personalization research <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b29">[30]</ref>. To simplify the personalized versions because tracking all URLs for a user can be costly, we make a simplifying assumption and compute this entropy over (clicked) rank positions instead of URLs. If the same query always returns the same search results in the same rank order, then the personalized click entropy for a query (UserQueryPositionEntropy) is the same as a personalized computation for standard click entropy.</p><p>Likewise, we use the topical representation and compute entropy of the resulting (</p><p>). In which case if we sum across users, we obtain QueryTopicEntropy (used to identify ambiguous queries for personalization in <ref type="bibr" target="#b24">[25]</ref>), conditional on the user across all queries we obtain UserTopicEntropy, conditional on user and query we obtain UserQueryTopicEntropy, and similarly for subset and superset. Because these entropy-based features derive from the appropriate parameterization of ( ), they can depend on each time view and use decay or uniform weighting.  We also introduce simple features that measure the number of queries or sessions containing the query in each view. We use these features in our model and describe them in detail in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Additional Features and Summary</head><p>In addition to the features listed thus far, we also have a number of other non-personalized features of the query and the search results that we use in our models. These include the query click entropy and query class entropy (whose relationship to the framework is described in Section 3.6), which measures the diversity of clicks across users, and the diversity of topics in the search results for the current query, both derived from historic log data.</p><p>Other features such as the length of the query and the rank position of each of the result URLs, as determined by the baseline ranker, are also included. A full description with additional motivation of each of these additional features, as well as all features described in text above, is provided in Table <ref type="table" target="#tab_0">1</ref>.</p><p>In summary, we consider several features, 3 temporal views and 2 weights. There are 14 rows in the table that depend both on temporal selection and weight accounting for 14×3×2=84 features.</p><p>There are four features that depend only on temporal selection accounting for 4×3=12 features, and there are 6 features that have no temporal selection or weight -resulting in 102 features total.</p><p>Restricting the set of features used to a single temporal view yields 14×2+4+6=38 features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL METHODOLOGY</head><p>Using the models described in the previous section, we aim to answer questions about the relative performance of each of the temporal views. In this section we describe the method that we followed for our experiments. We begin by describing the set of research questions that we answer in our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Research Questions</head><p>The study investigates the following conditions, each specifying the amount and type of search history used for personalization: Adding the Union condition allows the ranker to determine how much weight to put on each of the three possible time views.</p><p>Using these four conditions, we train models that re-rank the top Web search results provided by a large commercial search engine. The baseline used for our experiments is the original ranking of the top ten results provided by the engine. Note that this baseline is highly competitive and outperforming it is very challenging.</p><p>We address the following three research questions:</p><p>1. Do short-and long-term models both provide evidence for improved personalization? (Session, Historic vs. baseline)</p><p> Which one provides more? (Session vs. Historic)  Do they provide additive information? (Union vs. the best- performing model of Session and Historic)</p><p>2. Does aggregating all activity (with or without a decay factor emphasizing recent activity) capture the full interaction of short-and long-term models? (Aggregate vs. Union)</p><p>3. Do some features act differently in short-versus long-term models? (Can the performance of Union be explained by any of Session, Historic, or Aggregate?)</p><p>Answers to these questions provide valuable insight about the relative utility of the time views and help inform decisions about when and how to use these views for search personalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Set and Evaluation Methodology</head><p>The primary source of data for this study is a proprietary data set comprising anonymized logs of users of the Microsoft Bing search engine. The logs contained a unique user identifier, a search session identifier, the query, the top-10 URLs returned by the search engine for that query, and clicks on the results. We used eight weeks of log data gathered from July and August 2011 to train and evaluate our different models. Logs were collected from flights where other personalization support was disabled, so as to not bias our results with other personalization signals.</p><p>For evaluation, we need a personalized relevance judgment for each result. Obtaining many explicit relevance judgments from real users is impractical, and there is no known approach to train expert judges to provide reliable judgments that reflect real user preferences. Hence we obtained these judgments using a logbased methodology inspired by <ref type="bibr" target="#b11">[12]</ref> and similar to that used in <ref type="bibr">[2][8]</ref>. Specifically, we assign a positive judgment to one of the top 10 URLs if it is a satisfied result click (SAT click). We define a SAT click in a similar way to previous work <ref type="bibr" target="#b11">[12]</ref> as either a click followed by no further clicks for 30 seconds or more, or the last result click in the session. We also assign a positive judgment to a URL if it is a SAT click in one of the following two queries in the session --as long as all queries up to the SAT click share at least one URL in the top 10 with the original query. The remaining top-ranked URLs receive a negative judgment. This gives us a positive or negative judgment for each of the top-10 URLs for each query. The rank positions of the positive judgments are used to evaluate retrieval performance before and after re-ranking. Specifically, we measure our performance using the mean average precision (MAP) of the re-ranked lists. This is the mean of the average precision attained for each of the queries across the top-10 results retrieved before re-ranking (for the baseline) and after re-ranking (for each of the views of interest). Queries for which we cannot assign a positive judgment to any top-10 URL are excluded from the dataset.</p><p>We used a modified form of five-fold cross validation by user for training and testing, splitting based on user identifier. This is modified in the sense that during each fold 80% of the users were used for training and 20% of the users were held out for testing, but all of the test data came from the week after the training data. Split-  ting on user meant that there are no overlapping users between training and test. We did this because we wanted to ensure that the predictive patterns we learned also apply to users not seen during model training (as would be the case when deploying such models in practice). Figure <ref type="figure" target="#fig_3">3</ref> demonstrates how we extracted training and test data from the logs. Both training (week 7) and testing (week 8) data use the six weeks immediately prior to each to ensure feature distributions between train and test are based on the same amount of profile information. For each query in week seven, the historic features are computed based on actions from up to six weeks before that query (weeks 16). For users in the test fold (week 8), we used data from weeks 2-7 to build the profiles. Because we aim to compare the contributions of both historic and recent activity, if users lack search activity in a timespan then reliably comparing our experimental outcomes becomes challenging. We leave studying how this tradeoff changes with the amount of available history from a user as future work. Therefore, we restricted users to those with at least one SAT click in each of the six weeks before the week of interest (note this only uses weeks 17 and does not use knowledge of week 8 when selecting users). Over the 8 week period, the selection process resulted in around 155K user profiles over 10.4M sessions with an average of 174.40 (σ=181.49) queries/user and 2.61 queries/session (σ=3.36). All MAP results are means of performance across the five folds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments</head><p>Using the described dataset, we train a ranking model using the LambdaMART learning algorithm <ref type="bibr" target="#b34">[35]</ref> for re-ranking the top ten results of the query. LambdaMART is an extension of Lamb-daRank <ref type="bibr" target="#b2">[3]</ref> based on boosted decision trees. LambdaMART has been shown to be one of the best algorithms for learning to rank. Indeed, an ensemble model in which LambdaMART rankers were the key component won Track 1 of the 2010 Yahoo! Learning to Rank Challenge <ref type="bibr" target="#b5">[6]</ref>. However, we note the choice of learning algorithm is not central to this work, and any reasonable learning to rank algorithm would likely provide similar results.</p><p>We use LambdaMART with 500 decision trees. We did a grid search using cross-validation by user over a 5 percent sample of the training set using the Union feature set. We used a range of number of leaves {35, 70, 140, 280, 560}, minimum instances in a leaf node {200, 400, 800, 1600, 2000}, learning rate {0.075, 0.15, 0.30, 0.60}, and number of trees in the ensemble {50, 100, 200, 400}. There was relative insensitivity in the area where number of leaves ≤ 100, learning rate ≤ 0.3, minimum instances in a leaf node ≤ 2000, and number of trees <ref type="bibr">[50,</ref><ref type="bibr">200]</ref>. We broke ties arbitrarily and used number of leaves = 70, minimum instances in a leaf node = 2000, learning rate = 0.3, and number of trees = 50. After sweeping to determine parameters, we used the same parameters for all other models. We did this because we wish to understand how each model/feature set behaves in combination with the other parameters. For each fold, 10% of the training set is used as validation for model selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS</head><p>In this section we present the findings of our analysis. We focus on comparing the performance of the models constructed using the four conditions listed in Section 4.1. We begin by describing the overall performance of the models across all queries, then focus only on queries for which there is a measurable difference in search performance (e.g., where MAP changes) since those more clearly illustrate performance differences (although mask coverage effects, which we also explore). We report the change in performance from the baseline ranking -a highly competitive top Web search engine. We also conducted paired -tests to compare the performance of the models with each other and the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Performance</head><p>We begin by analyzing the overall performance of the models over the baseline. We measured the change (difference) in MAP from the baseline non-personalized search engine ranking's MAP across all queries for each of the four experimental conditions. For proprietary reasons, we only report the change from the baseline's MAP, rather than reporting absolute performance.  As seen in Figure <ref type="figure" target="#fig_4">4</ref>, all methods improve over the baseline (i.e., all reported changes are positive). All gains over the baseline and differences between methods are significant with paired t-tests at p &lt; .01. The figure shows increasing amounts of profiling information leads to greater improvements in retrieval performance. Interestingly using all sets of features (Union) and allowing the ranker to learn how the time views should be used for each query leads to the largest improvements over the baseline. This suggests that how personalization should be applied may be more nuanced than simple aggregation can capture (e.g., there may be times when we want to ignore historic data for personalization if the task is atypical of the user). We emphasize that while greater profiling information leads to better performance, this is not a foregone conclusion. For example, if every session was a new task unlike anything a user has previously done, then we would expect Session to outperform Historic. Likewise, if simple combinations of long-and short-term data could fully summarize the information available, then Union would not outperform Aggregate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Performance on All Queries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Effect of Query Position in Session</head><p>During search sessions, searchers reformulate their queries and adapt their information needs based upon exposure to information. We wanted to study whether this had an effect on the performance of the models. Figure <ref type="figure" target="#fig_6">5</ref> shows the average change in MAP from the baseline, broken out by the query position in the session, from the first to the fifth query and all remaining queries thereafter. From Figure <ref type="figure" target="#fig_6">5</ref>, we see the Session-based personalization steadily increases its gains as more session information becomes available and seems to stabilize around 0.55 gain in MAP. On the other hand, Historic quickly decreases its gains as the information from the current session is not captured and the searcher's immediate interests may not be reflected in their long-term interests. It is interesting to note that by the fifth query, the session information accounts for half the gains in personalization (Aggregate vs. Historic). Looking at Union we can see that allowing the ranker to learn how to combine short-and long-term history leads to the best gains versus simple aggregation of the two profile sources. Note that the gains of Union over the other models are significant at p &lt; .01 across all queries in the session except the first. For the first query in a session, the three models incorporating historic information have access to the same information, and as expected, their performance is nearly statistically identical. Overall this implies that re-finding and personalization are likely qualitatively different in the short term versus long term -otherwise simple aggregation would likely capture the behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance When Measurably Different</head><p>Until now, we have focused on the effect on overall retrieval performance. However, since personalization may only be appropriate for a subset of queries, a more sensitive measure of the relative performance of the temporal views is to consider only performance on queries where personalization resulted in a different MAP score (i.e., non-zero difference) than the baseline -which we call measurably different queries for brevity. This provides important insight into the relative precision that each personalization method has independent of the fraction of queries that they affect. We present results from that analysis in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">All Measurably Different Queries</head><p>We begin by examining the change in MAP for the measurably different queries. Figure <ref type="figure" target="#fig_7">6</ref> shows the average change for each of the four profiling methods. The figure shows that the gains are much larger when we focus on the measurably different queries (e.g., for Session, the MAP gain is more than 4 vs. 0.2 in Figure <ref type="figure" target="#fig_4">4</ref>). The relative ordering of the sources is the same as presented in Figure <ref type="figure" target="#fig_4">4</ref>, although the performance of the three models which incorporate historic information are more similar between themselves and more noticeably different from Session than when looking at changes in overall MAP. Differences are significant with paired -tests at p &lt; .01 for all comparisons apart from the Aggregate versus Union comparison, which is significant at p &lt; .10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Effect of Query Position in Session</head><p>In a similar way to earlier, we also study the effect of query position in session on the change in MAP for the measurably different queries. Figure <ref type="figure" target="#fig_8">7</ref> shows the gain over the baseline as the session proceeds. We see the gains per query are quite large, ranging from 3 points to 13 points of MAP. Several observations can be made from these differences. Again we see that the gain from Session increases then plateaus and that the gain from Historic decreases as the session progresses. Differences between Session and Historic are significant at p &lt; .01 apart from at queries 3 and 4 where the gains in MAP that they offer cross. Next, we see that the gains of Aggregate and Union over measurably different queries are comparable in all positions (Union is better but generally not significant, other than at queries 3 and 5 (p &lt; .05)). Since Union outperforms Aggregate overall (see Section 5.1.1) this implies the query volume impacted is the key difference (also see Figure <ref type="figure" target="#fig_10">9</ref>) and suggests that being able to differentially weight short-term and long-term behavior can personalize different sets (i.e., it is not simply a gain in precision over the same queries).</p><p>Finally, the large increase in MAP in the first position for the methods using long-term information suggests that more ambiguous queries, which personalization most benefits <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b29">[30]</ref>, may be more likely to happen as the first query in the session. This intuitively makes sense since much session behavior is captured by refinement and reformulation after the first query. 1 In Figure <ref type="figure" target="#fig_9">8</ref> we examine several important properties of the queries in each position in the session to help us interpret such differences. We report Z-scores to highlight how the queries in each position differ from the mean of all positions.  From Figure <ref type="figure" target="#fig_9">8</ref>, we see the first position consists of very short queries that are frequent and have lower than average click entropy with higher than average topic ambiguity. Perhaps this is the reason why long-term profiles are so successful in the first position since they can frequently provide disambiguation. The most clear trend observable in the graph is for query length. Typically short queries start a session but the query length increases dramatically later in the session. While the low click entropy at the first position may seem contradictory to having ambiguous queries at the start of a session, this is an effect of the frequency of short sessions containing primarily navigational intents. For example, if we focus simply on sessions of length five or more, the z-score of the click entropy in the first position of such long sessions is 0.04 -well above the average. The decrease in ambiguity and increase in complexity (length) later in the session may explain why observed gains in MAP across the impacted queries are lower as we extend further into the session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Query Volume Impacted by Personalization</head><p>Since personalization is not applied to all queries, it is important to understand the fraction of queries that can be affected by each of the time views. Overall the query volume impacted (percentage of measurably different queries) for the methods ranges from 5.42% (Session) to 9.05% (Union). However, there are some interesting effects when we consider the position of the query in the session. Figure <ref type="figure" target="#fig_10">9</ref> presents the fraction of queries with impacted performance at different query positions in the session. In examining the impact percentages reported in Figure <ref type="figure" target="#fig_10">9</ref>, we see that all of the methods personalize more often later in the session. This rate of impact rises most rapidly for the Session personalization as more information becomes available to it. Interestingly, impact rate also rises for the Historic method even though that method does not incorporate information from the current session. This suggests that long sessions may be a priori more likely to come from a user's prototypical interests although this observation requires further study. Changes in impact rate as the session proceeds may indeed be related to changes in query properties such as query length and popularity as the session proceeds and searchers' needs become more narrowly focused. As we saw in Figure <ref type="figure" target="#fig_9">8</ref>, properties of the queries change over the course of the search session, and these changes may affect the percentage of queries that are amenable to personalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effects of Other Conditions</head><p>As well as measuring the effect of time view on the performance of the model, we also explored the effects of other conditions mentioned in Section 3. Given the representation, one possibility is that the uniform weight or the decay weighting is crucial. For all of the features that use a weight we ran an ablation study that only used uniform weighted features, decay-weighted, or both and we observed no significant differences (not shown for space).</p><p>It is also interesting to consider whether these temporal aspects that happen using all features (All) are due only to topical effects (Topic) or to URL effects (URL). We summarize these conditions in Figure <ref type="figure" target="#fig_11">10</ref>, normalizing each of them by the maximum performance within condition to focus on the temporal trend within condition. We see the same trends observed overall also hold within each of these conditions. This implies that the tradeoffs between shortand long-term aspects are not simply due to effects seen under one representation but are more general across representation choices.</p><p>Both for space and because our emphasis here is on temporal aspects, we do not focus on comparing performance across conditions and address that in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DISCUSSION AND IMPLICATIONS</head><p>We have studied how short-term (session) behavior and long-term (historic) behavior interact, and how each may be used in isolation or in combination to optimally contribute to gains in relevance through search personalization. Through a large-scale analysis of search logs, we have shown: that historic behavior provides substantial benefits at the start of a search session; that short-term session behavior contributes the majority of gains in an extended search session; and that the combination of session and historic behavior outperforms either using just session behavior alone or using simple aggregations. Importantly, we also showed that by learning a combination of the three views, the model can determine which should be weighted most highly given the current query and prior behavior. These results have important implications for search personalization, which has typically only studied short-or long-term behaviors independently. We show there is value from carefully considering interactions between them.</p><p>We observe that over the course of a search session there are variations in query properties such as query length and query ambiguity. These query changes may also affect the potential for personalization. As the session proceeds, we observe that more queries can be impacted by personalization since there may be more evidence of searcher interests resulting in increasing overall utility, but smaller gains in retrieval effectiveness for queries that do change, perhaps because the queries are more difficult.</p><p>Our research improves the understanding of how short-and longterm behaviors can be used by search engine designers to improve the performance of search personalization. For example, based on the position of the current query in a session, the search engine could use a particular source (e.g., historic data early in the session, session data as the session proceeds). However, we have also shown we can learn a model that can outperform any source in isolation and appropriately choose behaviors from each time view to attain better retrieval performance. Future work will extend this research, including actions beyond clicks (e.g., skips) and other query similarity measures. We will also quantify the impact of short-term modeling for the cold-start problem of providing personalization to users with no previously observed interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>Previous work in search personalization has leveraged short-term or long-term behaviors to construct models of searcher interests. However, little is known about how these behaviors interact and when we should be leveraging them separately or in combination.</p><p>In this paper we investigated the interaction between short-and long-term interests, and how this information can be combined to learn performant search personalization models. We demonstrated the benefits of historic behavior: at the outset of a session, shortterm models yield benefit as the session proceeds; and allowing the ranker to learn weights for short-term features, long-term features, and their combination models searcher interests more effectively. This work makes an important step toward unifying prior work on personalization. Future work will explore further aspects of the interaction between different feature durations as well as other conditions from the framework that we only touched on briefly here (e.g., topic vs. URL), all focusing on how best to improve search performance through personalization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. An illustration of how we create profiles from recent (Session), past (Historic), or a combination (Aggregate).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Query decay weights given various decay factors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Illustration of our usage of data to profiles relative to the training and testing sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4</head><label>4</label><figDesc>Figure 4 presents the change in overall MAP for each model from the baseline. Error bars denote standard error of the mean in this chart and all other charts in the remainder of the paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Average change in MAP from baseline ranker MAP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Avg. change in MAP by position of query in session.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Average change in MAP given measurably different.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Average change in MAP on measurably different queries for each temporal view vs. position of query in session.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Mean of query properties for queries in a position normalized by their overall mean and standard deviation. Below/above zero is below/above average. Y-axis units are standard deviations (represented as the Z-score).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Percentage of queries with performance different than baseline vs. position of query in session.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Changes in performance for other model conditions relative to the best performing time view and condition pair.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Summary of Features. For each parameterized feature, the feature type ( ) = SAT click. When a row has the "Temporal Selection" box checked then a version is instantiated for each value of ( ) When a row has the weight box checked then a version is instantiated for each value of uniform, decay. Thus rows with both tem- poral selection and temporal decay correspond to 3 views × 2 weight = 6 features.</head><label>1</label><figDesc></figDesc><table><row><cell>Temporal Selection</cell><cell cols="2">Weight Feature</cell><cell></cell><cell></cell><cell></cell><cell>Description</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Query-Doc-User Features</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">( ) ( DocTopicCosineUserTopicProfile : cosine of ) with ( )=all, ( )</cell><cell>Topic similarity of overall user's history to this URL</cell></row><row><cell>×</cell><cell>×</cell><cell cols="4">( ) ( UserClicksOnUrl : inner prod. of ) with (</cell><cell>)=all, ( )</cell><cell>Click count of overall user's history to this URL</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">( ) ( DocTopicCosineUserTopicProfileForQuery : cosine of ) with ( )=q, ( )</cell><cell>Class similarity of selected user history (exact query) to this URL</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">( ) ( UserClicksOnUrlForQuery : inner prod. of ) with ( )=q, ( )</cell><cell>Click count of selected user history (exact query) to this URL</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">DocTopicCosineUserTopicProfileForSubsetQuery : cosine of ( ) ( ) with ( )=subset q, ( )</cell><cell>Class similarity of selected user history (subset of query after stopword removal) to this URL</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">UserClicksOnUrlForSubsetQuery : inner prod. of ( ) ( ) with ( )=subset q, ( )</cell><cell>Click count of selected user history (subset of query after stop-word removal) to this URL</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">DocTopicCosineUserTopicProfileForSupersetQuery : cosine of ( ) ( ) with ( )=superset q, ( )</cell><cell>Class similarity of selected user history (superset of query after stopword removal) to this URL</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">UserClicksOnUrlForSupersetQuery : inner prod. of ( ) ( ) with ( )=superset q, ( )</cell><cell>Click count of selected user history (superset of query after stop-word removal) to this URL</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Query Features</cell></row><row><cell cols="4">Query Ambiguity Measures</cell><cell></cell><cell></cell></row><row><cell cols="3">Query Difficulty Measures</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">PositionInSession</cell><cell></cell><cell></cell><cell>Easy queries come early in a session with reformulations later</cell></row><row><cell></cell><cell></cell><cell cols="2">QueryLength</cell><cell></cell><cell></cell><cell>Query length has been shown to be predictive of query difficulty</cell></row><row><cell></cell><cell></cell><cell cols="2">QueryFrequency</cell><cell></cell><cell></cell><cell>More frequent queries often have more click information</cell></row><row><cell cols="2">Query-Doc</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Rank</cell><cell></cell><cell></cell><cell></cell><cell>Rank of base ranker -non-personalized estimate of relevance</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Query-History Features</cell></row><row><cell cols="7">Query Number Features in Profile (not quite analogs)</cell></row><row><cell>×</cell><cell></cell><cell cols="2">NumberOfQueries</cell><cell></cell><cell></cell><cell>Number of distinct queries in interaction view</cell></row><row><cell>×</cell><cell></cell><cell cols="3">NumberOfSessionsWithQuery</cell><cell></cell><cell>Number of sessions in view containing this query</cell></row><row><cell>×</cell><cell></cell><cell cols="2">NumberOfSubsetQueries</cell><cell></cell><cell></cell><cell>Number of distinct queries in view matching subset relation</cell></row><row><cell>×</cell><cell></cell><cell cols="3">NumberOfSupersetQueries</cell><cell></cell><cell>Number of distinct queries in view matching superset relation</cell></row><row><cell cols="3">Focus of User Profile</cell><cell></cell><cell></cell><cell></cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">( UserTopicEntropy: entropy of normalized ) with ( )=all, ( )</cell><cell>Measures diversity of the user's observed needs</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">UserQueryTopicEntropy: entropy of normalized ( ) with ( )=q, ( )</cell><cell>Measure of diversity of topics that have satisfied the user's need for this exact query in the past</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">UserSubsetQueryTopicEntropy: entropy of normalized ( ) with ( )=subset q, ( )</cell><cell>Measures diversity of topics that have satisfied the user's need for the selected (subset) history</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">UserSupersetQueryTopicEntropy: entropy of normalized ( ) with ( )=superset q, ( )</cell><cell>Measure of diversity of topics that have satisfied the user's need for the selected (super) history</cell></row><row><cell>×</cell><cell>×</cell><cell cols="5">UserPositionEntropy: entropy of normalized ( ) with ( )=all, ( )</cell><cell>Higher positional entropy means that the user is not always satis-fied by results in the top position</cell></row><row><cell></cell><cell></cell><cell cols="5">UserQueryPositionEntropy: entropy of normalized</cell></row><row><cell>×</cell><cell>×</cell><cell>(</cell><cell>) with</cell><cell>(</cell><cell cols="2">)=q, ( )</cell></row></table><note><p><p><p>QueryClickEntropy (commonly called click entropy in the literature)</p>Measures the diversity of clicks across users. Higher entropy indicates queries with more intents QueryTopicEntropy Higher entropy indicates topically ambiguous.</p>Higher positional entropy means that the user is not always satisfied by results in the top position for this query. If the results for a query are always stable, this is personalized click entropy</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Combines the sets of features associated with each of the three other views. The full set of features in Table1instantiated for the each of the Session, Historic, and Aggregate views yielding 102 features (32 temporal selection features × 3 + the 6 additional features).</figDesc><table /><note><p>1. Session: All previous actions in current search session. The full set of features in Table 1 instantiated for the Session view yielding 38 features. 2. Historic: All previous actions apart from those in the current session. The full set of features in Table 1 instantiated for the Historic view yielding 38 features. 3. Aggregate: All previous actions before the current query. The full set of features in Table 1 instantiated for the Aggregate view yielding 38 features. 4. Union of Session, Historic, and Aggregate:</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGMENTS</head><p>We would like to thank Dan Schwartz, Sebastian de la Chica, and Yi Mao for contributing to early prototypes of the research here. We would also like to thank Filip Radlinski for discussions around the implications for session-based personalization.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inferring and using location metadata to personalize web search</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="135" to="144" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Classificationenhanced ranking</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to rank with non-smooth cost functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ragno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="page" from="193" to="200" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Context-aware query suggestion by mining clickthrough and session data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="875" to="883" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Context-aware query classification. SIGIR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://learningtorankchallenge.yahoo.com" />
		<title level="m">The Yahoo! learning to rank challenge</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using ODP metadata to personalize search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chirita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kohlschutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="178" to="185" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>De La Chica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<title level="m">Personalizing web search results by reading level. CIKM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A session based personalized search using an ontological user profile</title>
		<author>
			<persName><forename type="first">L</forename><surname>Daoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tamine-Lechani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chebaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SOC</title>
		<imprint>
			<biblScope unit="page" from="1732" to="1736" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Understanding the relationship between searchers&apos; queries and information goals</title>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liebling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>CIKM</publisher>
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A large-scale evaluation and analysis of personalized search strategies</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-R</forename><surname>Wen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="581" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Evaluating implicit measures to improve Web search</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kuldeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mydland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="168" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Smoothing clickthrough data for web search ranking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="355" to="362" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ontologybased user profiles for search and browsing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaffee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pretschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WIAS</title>
		<imprint>
			<biblScope unit="page" from="219" to="234" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Beyond the session timeout: automatic hierarchical segmentation of search topics in query logs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Klinkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CIKM</title>
		<imprint>
			<biblScope unit="page" from="699" to="708" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Session track overview</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Modeling and analysis of cross-session search tasks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kotov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="5" to="14" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dynamic adaptation strategies for long-term and short-term user profile to personalize search</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kitsuregawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">APWeb/WAIM</title>
		<imprint>
			<biblScope unit="page" from="228" to="240" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interest-based personalized search</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Personalizing web search using long term browsing history</title>
		<author>
			<persName><forename type="first">N</forename><surname>Matthijs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>WSDM</publisher>
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to disambiguate search queries from short sessions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mihalkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECML</title>
		<imprint>
			<biblScope unit="page" from="111" to="127" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Predictive user click models based on click-through history</title>
		<author>
			<persName><forename type="first">B</forename><surname>Piwowarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>CIKM</publisher>
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Analysis of topic dynamics in Web search</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="1102" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Context-sensitive information retrieval using implicit feedback</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Probabilistic models for personalizing web search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Billerbeck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>WSDM</publisher>
			<biblScope unit="page" from="433" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Speretta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gauch</surname></persName>
		</author>
		<title level="m">Personalizing search based on user search histories. WI</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="622" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Adaptive web search based on user profile constructed without any effort from users</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hatano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yoshikawa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mining long-term search history to improve search accuracy</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="718" to="723" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Personalizing search via automated analysis of interests and activities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="449" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">To personalize or not to personalize: modeling queries with variation in user intent</title>
		<author>
			<persName><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Liebling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="163" to="170" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Understanding and prediction personal navigation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liebling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Geetha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>WSDM</publisher>
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Investigating behavioral variability in Web search</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Predicting user interests from contextual information. SIGIR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Predicting short-term interests using activity-based search context</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="middle">S T</forename><surname>Dumais</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>CIKM</publisher>
			<biblScope unit="page" from="1009" to="1018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Ranking, boosting, and model adaptation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno>MSR-TR-2008-10</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="report_type">Microsoft Research Technical Report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Context-aware ranking in Web search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="451" to="458" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Incorporating post-click behaviors into a click model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<biblScope unit="page" from="355" to="362" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
