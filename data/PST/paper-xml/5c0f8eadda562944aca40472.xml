<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
							<idno type="ORCID">0000-0003-3264-3265</idno>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Wu</surname></persName>
							<email>jia.wu@mq.edu.au</email>
						</author>
						<author>
							<persName><forename type="first">Ji</forename><surname>Zhao</surname></persName>
							<email>zhaoji84@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Junjun</forename><surname>Jiang</surname></persName>
							<email>jiangjunjun@hit.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Huabing</forename><surname>Zhou</surname></persName>
							<email>zhouhuabing@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Quan</forename><forename type="middle">Z</forename><surname>Sheng</surname></persName>
							<idno type="ORCID">0000-0002-3326-4147</idno>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Electronic Information School</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<postCode>430072</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Beijing Advanced Innovation Center for Intelligent Robots and Systems</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<postCode>10081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Faculty of Science and Engineer-ing</orgName>
								<orgName type="department" key="dep2">Department of Computing</orgName>
								<orgName type="institution">Macquarie University</orgName>
								<address>
									<postCode>2109</postCode>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">ReadSense Ltd</orgName>
								<address>
									<postCode>200040</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
								<address>
									<postCode>518055</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">School of Computer Science and Engineer-ing</orgName>
								<orgName type="institution">Wuhan Institute of Technology</orgName>
								<address>
									<postCode>430073</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F7E0ADF327CB9D14AC85BBF5C5B2C093</idno>
					<idno type="DOI">10.1109/TNNLS.2018.2872528</idno>
					<note type="submission">received November 16, 2017; revised April 8, 2018, August 1, 2018, and September 4, 2018; accepted September 25, 2018.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Manifold regularization</term>
					<term>nonrigid</term>
					<term>point set registration</term>
					<term>robust estimation</term>
					<term>visual homing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper solves the problem of nonrigid point set registration by designing a robust transformation learning scheme. The principle is to iteratively establish point correspondences and learn the nonrigid transformation between two given sets of points. In particular, the local feature descriptors are used to search the correspondences and some unknown outliers will be inevitably introduced. To precisely learn the underlying transformation from noisy correspondences, we cast the point set registration into a semisupervised learning problem, where a set of indicator variables is adopted to help distinguish outliers in a mixture model. To exploit the intrinsic structure of a point set, we constrain the transformation with manifold regularization which plays a role of prior knowledge. Moreover, the transformation is modeled in the reproducing kernel Hilbert space, and a sparsity-induced approximation is utilized to boost efficiency. We apply the proposed method to learning motion flows between image pairs of similar scenes for visual homing, which is a specific type of mobile robot navigation. Extensive experiments on several publicly available data sets reveal the superiority of the proposed method over state-of-the-art competitors, particularly in the context of the degenerated data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>as structure from motion, panorama mosaic, image fusion, object detection and retrieval, visual homing, to name just a few. One of the reasons these tasks could be commonly casted into solving a point set registration problem is that the point is a simple and generic way of representing objects of interest. In this context, points usually represent the spatial locations of interest points extracted from an image, a shape contour, or an object surface, and the registration problem accordingly reduces to two subproblems, i.e., determining the correct correspondence between two given point sets and learning the underlying spatial transformation.</p><p>According to the characteristics of the data in specific applications, point set registration can be categorized into rigid or nonrigid registration. The former, which involves only a few transformation parameters, is relatively easy to handle (see <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b5">[6]</ref> for a literature survey). By contrast, the latter is challenging because the underlying nonrigid transformations usually cannot be modeled in a simple parametric manner <ref type="bibr" target="#b6">[7]</ref>. Despite these challenges, nonrigid registration remains desirable in quite a significant number of applications, such as handwritten character recognition, deformable image registration, visual homing, and so forth <ref type="bibr" target="#b7">[8]</ref>. In this paper, we focus on the problem of nonrigid point set registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Prior Work</head><p>The iterated closest point (ICP) approach <ref type="bibr" target="#b1">[2]</ref> is arguably one of the most classic approaches for point set registration, which assigns a certain pair of points, a binary indicator based on its nearest neighbors and utilizes the estimated correspondences to refine the transformation. The "hard" binary assignment of ICP can be replaced by soft ones, where a structured correspondence matrix is sought with consideration of parametric or nonparametric constraints <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Ma et al. <ref type="bibr" target="#b9">[10]</ref> introduced a nonrigid registration approach based on Gaussian fields, which was subsequently improved in <ref type="bibr" target="#b10">[11]</ref> by using the inner distance shape context (SC) <ref type="bibr" target="#b11">[12]</ref> rather than the original SC <ref type="bibr" target="#b12">[13]</ref> to construct initial correspondences. More recently, some probabilistic methods <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b17">[18]</ref> have been developed to accomplish the task. The kernel correlation-based method <ref type="bibr" target="#b13">[14]</ref> assumes that the two-point sets can be modeled as two probability distributions, and their dissimilarity is measured based on kernel density estimates. Then, the work <ref type="bibr" target="#b14">[15]</ref> representing the point sets using Gaussian mixture models (GMMs) further improves the scheme proposed in <ref type="bibr" target="#b13">[14]</ref>. In <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b17">[18]</ref>, GMM is utilized to assign the point correspondence by estimating the parameters of a mixture via the maximum likelihood and expectation maximization (EM) algorithms. Specifically, a method based on coherent point drift (CPD) <ref type="bibr" target="#b15">[16]</ref>, referred to as global-local topology preservation (GLTP) <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, is customized to cope with highly articulated deformations. The above-mentioned methods have achieved great success in handling both rigid and nonrigid registration. However, they ignore the local structure information among point sets that can be incorporated into feature descriptors. Thus, their performance degrades in complicated registration problems.</p><p>Another technical line of point set registration involves two stages: 1) correspondences are first built based on the similarity of local feature descriptors and 2) spatial transformation is then estimated according to the global geometric constraints. Representatives of this strategy include the SC <ref type="bibr" target="#b12">[13]</ref> for 2-D cases, fast point feature histograms (FPFHs) for 3-D cases <ref type="bibr" target="#b20">[21]</ref>, and analogous variants <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. These methods perform reasonably well when the spatial transformation is not complex. However, they have exposed their limitations if there are errors in the correspondences which frequently occurs in real-world tasks, especially if the transformation is complex and/or the input data are contaminated by outliers (e.g., points in one set do not have corresponding points in the other set).</p><p>To address this problem, Ma et al. <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> introduced the two choices for achieving a robust estimation in the transformation. The first one, i.e., vector field consensus (VFC) <ref type="bibr" target="#b23">[24]</ref>, builds a complex model with extra (hidden) variables, thereby enabling the identification and rejection of outliers. The second one, i.e., L 2 estimator (L 2 E) <ref type="bibr" target="#b24">[25]</ref>, uses an estimator that is less sensitive to outliers instead of the maximum likelihood estimator, which can be severely biased by outliers. These methods can properly manage complex nonrigid deformations. However, they calculate transformations solely based on the matched putative correspondences instead of fully utilizing the entire input data, which may produce an unsatisfying result if the data degradation is large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Motivations and Contributions</head><p>As mentioned earlier, nonrigid registration requires solving the correspondence and transformation between two given point sets. Solving for the two variables simultaneously is difficult. An effective scheme is to solve one variable if the value of the other is given, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b12">[13]</ref>, that is, iteratively use the estimation of correspondence to improve the learning of transformation, and vice versa, until convergence. This paper mainly focuses on how to robustly learn transformation from a putative correspondence in such an iterative procedure.</p><p>In the past decades, various methods have been developed to address the problem of robust transformation learning from a given set of initial point correspondences <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>; however, such problem remains a challenging task due to several aspects. First, putative correspondences are likely inaccurate because they are usually established upon local feature descriptors, which are inherently sensitive to noise, occlusion, and similar visual patterns in practice, leading to false correspondences (commonly known as outliers). In such a case, an outlier removal procedure is required to purify the initial correspondences. Second, a certain portion of input points may be excluded from the putative correspondence set due to the similarity constraints imposed on the establishment of correspondences. In fact, these unmatched points may carry useful information about the intrinsic structures of the input data, thereby facilitating transformation learning. Therefore, a desirable way is to involve the entire input point set in the modeling. Third, computational efficiency is a key concern in many scenarios that involve large-scale point sets (e.g., point clouds with tens of thousands of points).</p><p>In dealing with these concerns, the matching problem is cast into a mixture model under semisupervised learning. The model brings latent/hidden variables for all matches in the putative set to screen out the outliers, and employs a prior, say a nonparametric constraint to advocate the geometric smoothness on the spatial transformation via manifold regularization on the entire given data <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b26">[27]</ref>. On the one hand, such manifold regularization controls the complexity of the transformation. On the other hand, it can discover the underlying structure of the input data. The maximum a posteriori (MAP) estimation technique is a typical option for solving the problem with manifold regularizers, which easily get stuck into bad local points. As a solution, the EM algorithm <ref type="bibr" target="#b27">[28]</ref> is adopted to update the variance of position disturbance and distinguish the false correspondences simultaneously, providing a large initial variance. Moreover, a sparsity-induced approximation that is similar to the subset of regressors method <ref type="bibr" target="#b28">[29]</ref> is introduced for computational efficiency.</p><p>The contributions of this paper include the following four aspects. First, manifold regularization is introduced to the point set registration problem, thereby capturing the intrinsic structure of the given data and helping to learn the transformation. Second, according to the manifold regularization, a novel approach for robust transformation learning, which can learn transformation from point correspondences contaminated by outliers, is proposed. Third, fast implementation is provided for the proposed method using a sparse approximation, which enables the handling of large-scale data, e.g., 3-D point clouds. Fourth, our proposed method is generalized to solve the visual homing problem, which can learn accurate motion flows between image pairs and help improve homing performance significantly.</p><p>A preliminary version of this paper appeared in <ref type="bibr" target="#b29">[30]</ref>. The primary new contributions include that the model design and the solver are presented in more theoretical details, a more in-depth analysis of the properties and potentials of the proposed method are provided and further generalized to solve a real-word task in the field of mobile robotics, such as visual homing. Extensive experimental comparisons are conducted to verify the advances of our method. The code is released at https://sites.google.com/site/jiayima2013/home to allow comparisons from the community and encourage future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Organization of This Paper</head><p>The remainder of this paper is organized as follows.</p><p>Section II formalizes the foundational definitions and setup of the point set registration problem, including correspondence estimation and transformation learning. Section III presents the proposed robust transformation learning algorithm under manifold regularization and its fast implementation, along with some implementation details. Section IV applies the proposed method to solve the visual homing problem. Section V illustrates the use of the proposed method in 2-D shape matching, 3-D point cloud registration, and visual homing on publicly available data sets, with comparisons to other state-of-the-art methods. Section VI summarizes the concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM STATEMENT</head><p>Point set registration aims to determine the correct correspondences and seek the spatial transformation between two given point sets (e.g., a model point set {x i } M i=1 and a target point set {y j } N j =1 , where x i and y j ∈ IR D are the point positions (usually D = 2 or 3), M and N are, respectively, the numbers of points contained in the two sets) <ref type="bibr" target="#b24">[25]</ref>. To solve this problem, an iterative strategy between correspondence construction and transformation learning is considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Correspondence Construction</head><p>A specific shape or object should have a relatively fixed geometric structure at its local parts. Therefore, two-point sets that are generated from two samples of the same shape will generally have similar local geometric structures. By using a shape feature descriptor to incorporate such information (e.g., neighborhood structures), the correspondence can be constructed based on the similarity of corresponding descriptors. For example, two points should be matched only if their descriptors are sufficiently similar. Several well-designed feature descriptors can efficiently establish reliable correspondences between point sets in 2-D and 3-D cases <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b30">[31]</ref>.</p><p>For the 2-D case, the SC <ref type="bibr" target="#b12">[13]</ref> is used to construct descriptor. For two given points (i.e., x i and y j ), their corresponding SCs are histograms { p i (k)} H k=1 and {q j (k)} H k=1 , which characterize the distributions of their neighborhood points. Specifically, for a point x i from {x i } M i=1 , p i is computed according to the relative spatial positions of the remaining M -1 points</p><formula xml:id="formula_0">p i (k) = #{x j = x i : (x j -x i ) ∈ bin(k)}. (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>The bins are uniform in the log-polar space. Consequently, the nearby sample points play more important roles than the points that are farther away. The original SC is not rotation invariant, and a rotation invariant SC could be considered if necessary by using a mass center to compute the positive x-axis for the local coordinate system <ref type="bibr" target="#b21">[22]</ref>. After obtaining p i and q j , their difference is frequently measured via the χ 2 distance as follows:</p><formula xml:id="formula_2">C i j = C(x i , y j ) = 1 2 H k=1 [ p i (k) -q j (k)] 2 p i (k) + q j (k) . (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>After all the pairwise distances (i.e., {C(x i , y j ), i = 1, . . . , M, j = 1, . . . , N}) are obtained, the Hungarian method <ref type="bibr" target="#b31">[32]</ref> is applied to determine the correspondences between {x i } M i=1 and {y j } N j =1 .</p><p>For the 3-D case, the FPFH <ref type="bibr" target="#b20">[21]</ref> is considered as the feature descriptor. It is a fast implementation of PFH that captures the underlying surface model properties (e.g., the local geometry, including point coordinates, surface normals, curvatures, and moment invariants) around the k-nearest neighbors of each point. The computational complexity of FPFH is linear with respect to the number of neighbors for each point, and hence beneficial for dealing with large-scale 3-D point clouds. To establish correspondences between two point clouds efficiently, a sample consensus initial alignment method is implemented instead of the original greedy initial alignment in PFH, which tries to preserve the same local geometries of putative correspondences without having to try all possible correspondence pairs.</p><p>After using local feature descriptors to establish correspondence, a putative set S = {(x i , y i )} L i=1 is obtained with L ≤ min{M, N} being the amount of correspondences. In addition, we make an assumption that {x i } L i=1 and {y j } L j =1</p><p>in the putative set S correspond to the first L elements of the original point sets {x i } M i=1 and {y j } N j =1 , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Transformation Learning</head><p>A putative correspondence set, S = {(x i , y i )} L i=1 , is established from two point sets (i.e., {x i } M i=1 and {y j } N j =1 ) involving nonrigid deformation. Each input-output pair (x i , y i ) can be considered a random sample drawn from the underlying spatial transformation between the two point sets. This paper aims to learn the transformation T [e.g., y i = T (x i ) for any (x i , y i ) in S]. However, for a nonrigid T , its solution will be not unique if no additional constraint is imposed on T . The regularization technique, which usually operates in a reproducing kernel Hilbert space (RKHS) <ref type="bibr" target="#b32">[33]</ref> (associated with a particular kernel), can be used to obtain a meaningful solution. In particular, the Tikhonov regularization <ref type="bibr" target="#b33">[34]</ref> in the RKHS H minimizes a regularized risk functional as follows:</p><formula xml:id="formula_4">T * = min T ∈H L i=1 y i -T (x i ) 2 + λ T 2 H (3)</formula><p>where the first term fitting the input data is the data-fidelity term, or empirical error (risk); the second term is a regularization term, which plays a role of stabilizer and enforces smoothness to the spatial transformation T ; λ &gt; 0 controls the tradeoff; • H represents the functional norm of H (their definitions will be discussed in the Appendix).</p><p>The transformation learning here focuses on how to utilize the global geometric constraint on the point sets to obtain a smooth transformation without consideration of the intrinsic geometry involved in a specific shape or object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head><p>This section presents the proposed manifold regularization under semisupervised learning for transformation estimation and shows its capability of capturing the underlying intrinsic structure of a point set. Then, a formulation for robust transformation learning from putative correspondences using the global geometric constraints of manifold regularization is proposed, followed by its fast implementation based on sparsityinduced approximation and some implementation details of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Manifold Regularization</head><p>The problem of manifold regularization is tied to semisupervised learning. It is a generalization of supervised learning in which regularization is imposed on the labeled and unlabeled data <ref type="bibr" target="#b26">[27]</ref>. Manifold learning methods have received considerable research interest in the areas of pattern recognition and machine learning <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref> since the introduction of two pioneering methods, namely, ISOMAP <ref type="bibr" target="#b37">[38]</ref> and locally linear embedding method <ref type="bibr" target="#b38">[39]</ref>. These methods usually assume that a low-dimensional representation can be used to characterize the underlying intrinsic structure embedded in the high-dimensional data. Based on this assumption, a graph is constructed, and the graph Laplacian matrix is calculated to capture the manifold structure, which is further utilized to conduct various learning tasks, including clustering, dimensionality reduction, and semisupervised learning <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>.</p><p>Recently, manifold regularization has been widely used in computer vision <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>. Xu et al. <ref type="bibr" target="#b43">[44]</ref> applied manifold regularization to solve the feature selection problem under a semisupervised learning setting to determine more discriminative features. Zhao et al. <ref type="bibr" target="#b44">[45]</ref> introduced a compact graph to grasp the geometric structure of a data set and utilized it for manifold ranking in image retrieval. Xiang et al. <ref type="bibr" target="#b45">[46]</ref> presented a local regression and global alignment approach for graph construction and applied it to image segmentation. A recent work <ref type="bibr" target="#b40">[41]</ref> used manifold regularization to manage image classification and visualization and preserve manifold information together with local and global discriminative information. In this paper, manifold regularization is introduced to the point matching problem to utilize the intrinsic geometry of the given point sets supported on a low-dimensional manifold. The proposed method can fully utilize the entire input data, thereby enhancing registration accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Transformation Learning With Manifold Regularization</head><p>In the matching problem, the matched points are usually a part of the entire point set (i.e., L ≤ M) because of the existence of noise, outliers, and occlusions. That is, only L points x 1 , . . . , x L are given labels y 1 , . . . , y L undergoing transformation T , respectively. However, the input data in a point set registration task are typically sampled a specific object that possesses certain "intrinsic geometry." For example, the spatial positions of points comprising a specific shape are not arbitrary and often obey a specific distribution. Thus, the remaining M -L points without labels may contain extra geometric structure information about the input data. Manifold regularization is considered to fully utilize such additional information <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b46">[47]</ref>. It defines an extra regularization term T 2</p><p>I on the entire input data {x i } M i=1 to constrain T in a low-dimensional manifold. Thus, the objective function in <ref type="bibr" target="#b2">(3)</ref> becomes</p><formula xml:id="formula_5">T * = min T ∈H L i=1 y i -T (x i ) 2 + λ 1 T 2 H + λ 2 T 2 I (4)</formula><p>where the first regularization term controls the complexity of T , and the second regularization term exploits the intrinsic geometry of the input data. As a manifold is typically located in a subspace, the first regularization term is then necessary.</p><p>In particular, for those T ∈ H providing the same value on a manifold, the solution that is smoother in the input space is preferred and expected to have better generalization capacity. The graph Laplacian, which is a discrete analog of the manifold Laplacian, is used to define the manifold regularization term <ref type="bibr" target="#b26">[27]</ref>. Suppose the input samples are drawn i.i.d. from a manifold, the graph Laplacian then models the manifold according to a weighted neighborhood graph, G. Specifically, G is obtained by constructing the vertex set V = {x 1 , . . . , x M } (the matched and unmatched points) with edges (x i , x j ) if and only if x ix j 2 ≤ . The following weight is assigned to edge (x i , x j ):</p><formula xml:id="formula_6">W i j = e -1 x i -x j 2 .</formula><p>(</p><formula xml:id="formula_7">)<label>5</label></formula><p>According to W , a matrix A is constructed with each element expressed as follows:</p><formula xml:id="formula_8">A i j = D i j -W i j (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where D = diag( M j =1 W i j ) M i=1 (i.e., the diagonal matrix whose i th entry is the sum of the weights of edges leaving x i ). Denote t = (T (x 1 ), . . . , T (x M )) T . The manifold regularization term is defined as follows:</p><formula xml:id="formula_10">T 2 I = M i=1 M j =1 W i j (t i -t j ) 2 = tr(t T At)<label>(7)</label></formula><p>where tr(•) indicates the trace of a matrix. Thus, the objective function (4) becomes</p><formula xml:id="formula_11">T * = min T ∈H L i=1 y i -T (x i ) 2 + λ 1 T 2 H + λ 2 tr(t T At).<label>(8)</label></formula><p>Its solution will be discussed subsequently in Section III-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Robust Transformation Learning</head><p>The transformation can be learned by minimizing the objective function in <ref type="bibr" target="#b3">(4)</ref>. Nevertheless, the putative set S = {(x i , y i )} L i=1 usually involves several unknown false correspondences because it is constructed based on only local neighborhood structures. Therefore, the transformation learning procedure should be resistant to outliers. Next, we introduce an approach for achieving such robust learning based on manifold regularization.</p><p>For the inliers, the noise on the components of point positions is assumed to be isotropic Gaussian, i.e., N (0, σ 2 I). While for the outliers, the corresponding point could appear anywhere in the output space, leading to a uniform distribution 1/a, with a denoting the volume of the bounded output space <ref type="bibr" target="#b23">[24]</ref>. Then, the i th correspondence is associated with a latent variable z i ∈ {0, 1}, where z i = 1 and z i = 0 indicate Gaussian and uniform distributions, respectively. Let X = (x 1 , . . . , x L ) T and Y = (y 1 , . . . , y L ) T ∈ IR L×D be the two point sets in the putative set. Thus, the likelihood of matching correctness is a mixture model expressed as follows:</p><formula xml:id="formula_12">p(Y|X, θ) = L i=1 z i p(y i , z i |x i , θ ) = L i=1 γ (2πσ 2 ) D/2 e - y i -T (x i ) 2 2σ 2 + 1 -γ a (<label>9</label></formula><formula xml:id="formula_13">)</formula><p>where θ = {T , σ 2 , γ } contains the variables to be solved, in which γ specifies the marginal distribution of hidden variable z i (i.e., ∀z i , p(z i = 1) = γ ). The nonrigid transformation T is assumed to lie within the RKHS and simultaneously captures the intrinsic geometry of the input data. These properties can be incorporated into a prior on T as:</p><formula xml:id="formula_14">p(T ) ∝ e -(1/2)(λ 1 T 2 H +λ 2 T 2 I )</formula><p>. The MAP solution of θ is estimated via the Bayes rule as follows:</p><formula xml:id="formula_15">θ * = arg max θ p(θ |X, Y) = arg max θ p(Y|X, θ) p(T ). (10)</formula><p>The EM algorithm, which is a common technique for addressing the appearance of hidden variables, is considered to optimize the objective function. This paper follows standard notations <ref type="bibr" target="#b47">[48]</ref> and omits several terms that are independent of θ . Considering the posterior function in 10, its complete-data log posterior is expressed as follows:</p><formula xml:id="formula_16">Q(θ, θ old ) = - 1 2σ 2 L i=1 p i y i -T (x i ) 2 - DL p 2 ln σ 2 + L p ln γ + (L -L p ) ln(1 -γ ) - λ 1 2 T 2 H - λ 2 2 T 2 I (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>where p i = P(z i = 1|x i , y i , θ old ), L p = L i=1 p i . The EM approach iterates between an E-step and an M-step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E-</head><p>Step: This step focuses on computing the posterior distribution of hidden variables (i.e., p i ) according to the current newest parameter value (i.e., θ old ). Let P = diag( p 1 , . . . , p L ) denote a diagonal matrix, and it is obtained by using the Bayes rule as follows:</p><formula xml:id="formula_18">p i = γ e - y i -T (x i ) 2 2σ 2 γ e - y i -f(x i ) 2 2σ 2 + (1 -γ ) (2πσ 2 ) D/2 a . (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>The value of p i ranging from 0 to 1 characterizes the degree of consistency that correspondence (x i , y i ) satisfies the current newest transformation T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M-</head><p>Step: This step focuses on determining the updated parameter as θ new = arg max θ Q(θ , θ old ). Let T (X) = (T (x 1 ), . . . , T (x L )) T . As P is a diagonal matrix, we take the derivatives of Q(θ ) with respect to σ 2 and γ and set them to zero, the following closed-form solutions are obtained:</p><formula xml:id="formula_20">σ 2 = tr((Y -T (X)) T P(Y -T (X))) DL p (13) γ = tr(P)/L. (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>Then, the terms of Q(θ ) related to T are considered, and the following manifold regularized risk functional is obtained <ref type="bibr" target="#b48">[49]</ref>:</p><formula xml:id="formula_22">E(T ) = 1 2σ 2 L i=1 p i y i -T (x i ) 2 + λ 1 2 T 2 H + λ 2 2 T 2 I . (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>The transformation T is modeled in the RKHS H, which is defined uniquely by a matrix-valued kernel : IR D × IR D → IR D×D . For the point set registration problem, a diagonal decomposable kernel is often sufficiently accurate to capture the spatial transformation <ref type="bibr" target="#b23">[24]</ref>, for example, (x, x ) = κ(x, x ) • I with κ(x, x ) = e -β x-x 2 being a scalar Gaussian kernel, where β determines the range of interactions between different points. Thus, the representer theorem is derived as follows <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b46">[47]</ref> (the proof is provided in the Appendix).</p><p>Theorem 1: The optimal solution of the manifold regularized risk functional ( <ref type="formula" target="#formula_22">15</ref>) is expressed as follows:</p><formula xml:id="formula_24">T * (x) = M i=1 (x, x i )c i (<label>16</label></formula><formula xml:id="formula_25">)</formula><p>with the coefficient set {c i } M i=1 determined by the following linear system:</p><formula xml:id="formula_26">(J T PJ + λ 1 σ 2 I + λ 2 σ 2 A )C = J T PY<label>(17)</label></formula><p>where ∈ IR M×M is the Gram matrix and i j = κ(x i , x j ), J = (I L×L , 0 L×(M-L) ) with I being an identity matrix and 0 being a matrix of all zeros, C = (c 1 , . . . , c M ) T ∈ IR M×D is the matrix of coefficients.</p><p>Convergence Analysis: Note that the objective function ( <ref type="formula">10</ref>) is nonconvex in nature. Although global optimality is difficult to be warranted by existing optimization techniques, a stable local optimum, which is usually sufficient for solving realworld tasks, can be obtained. To this end, the variance σ 2 is initialized with a relatively large value, e.g., obtained by using <ref type="bibr" target="#b12">(13)</ref> with P = I and T (X) = X. The reason for doing so is that for a large value of σ 2 , the objective function should be convex in a large range, thereby filtering out many noisy local optimum. The EM algorithm is employed to approach the desired minimum gradually. The objective function changes smoothly as σ 2 decreases; thus, using the minimum from the previous iteration as the initialization for the next round is beneficial to achieving a new better optimum. In other words, as the procedure iterates, a satisfying local optimum can be finally reached. This concept is associated with deterministic annealing <ref type="bibr" target="#b6">[7]</ref>, which adopts the solution of a relatively easy problem to provide the initializations recursively to increasingly difficult problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Fast Implementation</head><p>In our proposed method, we need to solve transformation T in <ref type="bibr" target="#b16">(17)</ref>, which is the most time-consuming procedure. Its time complexity is cubic O(M 3 ), which is problematic when dealing with large-scale problems. Even when the proposed method is implementable, an alternative which produces suboptimal solutions but is more efficient may be preferred. Next, we give such an approximate and fast solution by using the idea similar to a subset of regressors <ref type="bibr" target="#b28">[29]</ref>.</p><p>Instead of seeking the optimal solution in H M , a sparsity-induced approximation, which is defined as</p><formula xml:id="formula_27">H K = { K i=1 (•, x i )c i }</formula><p>, is adopted to optimize the problem in a space with less basis functions. In this paper, K M and the point set { x i : i ∈ II N K } are composed of an arbitrary subset of {x i : i ∈ II N M }. This is inspired by Rifkin et al. <ref type="bibr" target="#b49">[50]</ref> and Ma et al. <ref type="bibr" target="#b50">[51]</ref> who found that such a simple random selection performs as well as those sophisticated and timeconsuming methods. The manifold regularized risk functional over all samples is then minimized. According to sparse approximation, the solution forms the following shape:</p><formula xml:id="formula_28">T (x) = K i=1 (x, x i )c i (<label>18</label></formula><formula xml:id="formula_29">)</formula><p>with the coefficient {c i } K i=1 determined by the following linear system:</p><formula xml:id="formula_30">(U T PU + λ 1 σ 2 s + λ 2 σ 2 V T AV)C = U T PY<label>(19)</label></formula><p>where s ∈ IR K ×K and s,i j = κ( x i , x j ), U ∈ IR L×K and U i j = κ(x i , x j ), V ∈ IR M×K and V i j = κ(x i , x j ). Note that U equals to the first L rows of V. The details of the derivation of <ref type="bibr" target="#b18">(19)</ref>, which are similar to that of Theorem 1, are omitted. Unlike the optimal solution of taking the form of a linear combination of the basis functions { (•, x i ) : i ∈ II N M }, by the representer theorem, the solution based on our sparse approximation only involves K basis functions. In general, this procedure significantly speeds up the processing with a trivial loss in accuracy. Compared with the original algorithm, the fast implementation solves the linear system in <ref type="bibr" target="#b18">(19)</ref> rather than that in <ref type="bibr" target="#b16">(17)</ref>.</p><p>Computational Complexity: For the linear system (17), the size of the coefficient matrix J T PJ + λ 1 σ 2 I + λ 2 σ 2 A is M × M, and thus the time complexity for solving T is O(M 3 ). In contrast, the size of the coefficient matrix U T PU+λ 1 σ 2 s + λ 2 σ 2 V T AV in the linear system <ref type="bibr" target="#b18">(19)</ref> is only K × K , and thus, the time complexity for solving the transformation T is reduced to O(K 3 ). Nevertheless, the time complexity of computing the coefficient matrix,</p><formula xml:id="formula_31">U T PU + λ 1 σ 2 s + λ 2 σ 2 V T AV, is O(K M 2 )</formula><p>due to the multiplication operation on the M × M graph Laplacian matrix A. Given that K is a constant and independent of M and K M, the total time complexity of solving transformation T in fast implementation can be written as O(M 2 ). The space complexity of the proposed method scales as O(M 2 ) because of the memory requirements for storing the graph Laplacian matrix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Summarization and Implementation Details</head><p>To produce reliable registration results, we iteratively construct the correspondences and learn the transformation. The number of iterations is fixed in this paper (i.e., usually 10 but more when the noise level is high or when the original point sets contain a large percentage of outliers). The proposed robust point matching approach is based on manifold regularization and is thus called robust point matching using manifold regularization (MR-RPM). The MR-MPM method is summarized in Algorithm 1. The performance of point set registration is influenced by the coordinate system that expresses the data. To relieve such influence, we normalize the coordinates of the point sets. In particular, we adopt a linear scaling on the coordinates, so that the means of coordinates in the two point sets are both 0 and the variances are both 1. Rather than directly solving transformation T , a displacement function f: T (x) = x +f(x), which is achieved straightforward by replacing the output with y -x, is solved. Compared with the original position mapping, the use of the motion field achieves high robustness <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b23">[24]</ref>.</p><p>Parameter Settings: The MR-RPM algorithm has four main parameters, namely, , β, λ 1 , and λ 2 . Parameter is used to establish the graph Laplacian and compute the weight of its edges. Parameter β characterizes the Gaussian window of the kernel function and determines the range of interactions between different points. The tradeoff between fitting the data and ensuring stability on the transformation is controlled by the two other parameters. In particular, λ 1 regularizes with respect to the entire input space, and λ 2 constrain the transformation to exploit the intrinsic geometry. Generally, the proposed method is robust to parameter changes. The following settings are used throughout this paper: = 0.05, β = 0.1, λ 1 = 3, λ 2 = 0.1, K = 15, which are selected by the exhaustive grid search on one data set and kept unchanged in all the experiments. In addition, as described in Line 8 in Algorithm 1, we should make an initial assumption on the inlier ratio γ , which is fixed as 0.9. The constant a for outlier distribution is assigned to the volume of output space after normalization of the point coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. APPLICATION TO VISUAL HOMING</head><p>In this section, we apply our method to the visual homing problem. Specifically, the MR-RPM is used for robust feature matching and dense motion flow learning between two images. The focus-of-contraction (FOC) and focus-of-expansion (FOE) are derived accordingly to determine the homing directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Background</head><p>Visual homing, which aims to navigate a robot to a goal or home position from arbitrary starting positions solely based on visual information, has received increasing attention and plays an important role in many applications in the mobile robotics community <ref type="bibr" target="#b2">[3]</ref>. The visual homing problem is usually solved based on sparse feature matching. Specifically, it initially matches local features in the two images and subsequently transforms the correspondences into motion flows, which are finally used to determine the homing vector <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>.</p><p>In early homing methods, the positions and correspondences of landmarks are assumed to be known in advance. Such methods usually demand special settings to achieve a reliable performance, such as placing artificial landmarks in the work environment. This restriction limits its applications in practical visual homing problems. To address this issue, recent correspondence methods use feature points that are automatically extracted from images as landmarks, and the correspondences are built using the descriptors associated with them <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b51">[52]</ref>. For example, in <ref type="bibr" target="#b53">[54]</ref>, a biologically inspired method, such as average landmark vector, was combined with the feature points detected in panoramic images for visual homing and showed promising results. However, the feature correspondences in these methods are usually established based on only local descriptor information, and hence some unknown false matches will be introduced which degrade the homing performance. The robustness of visual homing methods has been verified to be dominated by the presence and amount of false correspondences <ref type="bibr" target="#b54">[55]</ref>. Several heuristic methods are usually adopted to remove false correspondences to remedy the degradation caused by mismatches. In <ref type="bibr" target="#b51">[52]</ref>, features are assumed to be distributed approximately uniformly, and mismatch removal is not performed. Mismatch removal is explicitly conducted for visual homing using an effective random sample consensus (RANSAC)-like method in <ref type="bibr" target="#b2">[3]</ref>, but it relies on a parametric model. Usually, the spatial transformation of a panoramic pair cannot be modeled exactly by a parametric model <ref type="bibr" target="#b55">[56]</ref>. The current study applies the proposed MR-RPM to establish accurate feature correspondences and learn accurate motion flows to enhance homing performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Motion Flow Learning</head><p>The dense motion flow between an image pair of the same or similar scenes is learned based on sparse feature matching. To this end, a set of putative matches S = {(x i , y i )} L i=1 is constructed by considering all possible matches between two feature sets (i.e., {x i } M i=1 and {y j } N j =1 ) and filtering out matches whose feature descriptors are sufficiently different, which can be fulfiled by several existing welldesigned local image feature descriptors (e.g., scale invariant feature transform (SIFT) <ref type="bibr" target="#b56">[57]</ref>). The putative match (x i , y i ) can be further converted to a motion flow sample by a transformation (x i , y i ) → (u i , v i ), where u i = x i and v i = y ix i denote the position and displacement, respectively. Therefore, this paper aims to learn a dense motion flow f : v i = f(u i ) from a set of sparse motion flow samples contaminated by several unknown outliers. Clearly, MR-RPM can be used to achieve this goal.</p><p>In the visual homing problem, the panoramic image usually achieves a 360 • field-of-view horizontally, which is usually called "360 cylindrical panorama." The image plane of this type of image can be considered a cylinder unrolled along with a certain vertical cutting line. Therefore, calculating the displacements between feature matches on the image plane by directly using the Euclidean distance is inappropriate, because the displacement will depend on the cutting line in this case. For example, two nearby matched features on the cylinder will have a large displacement on the image plane if they are located on the two sides of the cutting line. To address this issue, the motion flow vector is defined according to the cylinder distance as follows:</p><formula xml:id="formula_32">u i = x i (<label>20</label></formula><formula xml:id="formula_33">)</formula><formula xml:id="formula_34">v i = y h i -x h i + αx h max , y v i -x v i (<label>21</label></formula><formula xml:id="formula_35">)</formula><p>where x h and x v denote the horizontal and vertical coordinates of a feature point x, respectively; x h max is the horizontal width of the image plane; and parameter α ∈ {0, ±1} is used to wrap the horizontal displacement to</p><formula xml:id="formula_36">[-x h max /2, x h max /2]. After the motion flow sample set S = {(u i , v i )} L</formula><p>i=1 is obtained, the motion flow f can be learned according to Lines 5-15 in Algorithm 1 under manifold regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Visual Homing Using Singularities of Motion Flow</head><p>Previous work shows that the motion flow of a panoramic image pair has two singularities <ref type="bibr" target="#b57">[58]</ref> corresponding to the FOC and FOE. These two singularities are separated by a half horizontal width of the panoramic image. The FOC and FOE have been used in many applications, including 3-D environment reconstruction and estimation of time-to-contact in visual navigation. Specifically, in the visual homing literature, the FOC and FOE have been used to determine the homing direction <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>. A heuristic strategy has been proposed by detecting whether the SIFT features have grown or shrunk with respect to their sizes in the reference home image to localize the two singularities <ref type="bibr" target="#b51">[52]</ref>.</p><p>In our previous work <ref type="bibr" target="#b58">[59]</ref>, we have introduced a method that uses the dense motion flow to determine the FOC and FOE. Here, we briefly review this method. Generally, the FOC and FOE should lie on the horizontal line u v = u v max /2 and are separated by u h max /2.<ref type="foot" target="#foot_0">1</ref> Therefore, no significant differences in the estimation of these two singularities are observed. The subsequent paragraphs will only focus on the estimation of FOC because the generalization of FOE is straightforward.</p><p>After obtaining the motion flow f(u), deriving the analytical solution of its singularities is impossible or difficult. Instead, several numerical methods can be adopted to derive an approximate solution. Formally, given that FOC lies on the horizontal line u v = u v max /2, the following 1-D function can be defined:</p><formula xml:id="formula_37">g(u h ) f u h , u v max 2 . (<label>22</label></formula><formula xml:id="formula_38">)</formula><p>Clearly, g(θ ) is continuous and differentiable, and the singularities correspond to the points whose left and right local neighborhoods have different signs. The formal definition of FOC is as follows.</p><p>Definition (FOC): FOC u h FOC is the point that satisfies 1) g(u h FOC ) = 0 and 2) ∃ &gt; 0 that satisfy g(u h ) &gt; 0 for any u h in the left -neighborhood of u h FOC and g(u h ) &lt; 0 for any u h in the right -neighborhood of u h FOC . A coarse-to-fine grid search strategy is used to find the optimal solution of FOC, which can achieve arbitrary precision. In the visual homing literature, all panoramic images usually have identical compass orientations by preprocessing. By converting the coordinate to the angle, the homing direction can be obtained as follows:</p><formula xml:id="formula_39">θ homing = θ FOC = 2π • u h FOC u h max . (<label>23</label></formula><formula xml:id="formula_40">)</formula><p>With this homing direction, the visual homing task can be accomplished, and a robot can be navigated back to its reference home position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head><p>Experiments on 2-D shape contours and 3-D point clouds are conducted to demonstrate the effectiveness of the proposed MR-RPM. The experimental environment is a laptop which has a 3.0-GHz Intel Core CPU and an 8-GB memory, and the algorithm is implemented with MATLAB code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Results on 2-D Shape Contour</head><p>For the registration of the 2-D shape contour, two publicly available shape models (i.e., a fish pattern and a Chinese character pattern) are used to test the performance of different methods. Following <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b21">[22]</ref>, these two patterns are artificially added with different types of degenerations, such as deformation, noise, outlier, rotation, and occlusion. There are five or six levels of degeneration (each level involves 100 samples) for every degeneration type. Note that the degeneration of outlier is to some extent analogous to the degeneration of occlusion, because in both cases there are some elements only included in one of the two point sets. However, for real-world tasks, the degeneration of occlusion is more common given that the uncommon points originate from an object contour. By contrast, for the degeneration of outlier, the uncommon points are generated randomly on the two patterns in our testing data sets. Moreover, the degeneration of rotation can be easily addressed in our method by adopting a feature descriptor that is rotation invariant. Thus, the proposed method is tested on only three types of degenerations, namely, deformation, noise, and occlusion.</p><p>The goal of point set registration is to align two point sets together, such as the model point set marked by " " and the target point set marked by " ." Fig. <ref type="figure">1</ref> schematically illustrates the registration evolution in the fish case. Different columns correspond to different stages of registration, while each row is polluted by a different type of degradation. From the results, Fig. <ref type="figure">1</ref>. the registration process of our MR-RPM for registration. We aim to align the model sets (" ") onto the target sets (" "). Input data suffer from deformation, noise, and occlusion (from top to bottom). we can observe that the MR-RPM registration is accurate and robust, and usually converges within 10 iterations.</p><p>More qualitative results of MR-RPM are offered in Fig. <ref type="figure" target="#fig_0">2</ref>. For each group of results, the top figures depict the model (" ") and the target points (" "), while the bottom ones present the registration results. The results reflect that MR-RPM is capable to handle all of the different degradations. The registration performance declines gradually as the level of degradation goes up. However, even in the case of high degradation, particularly for deformation and occlusion, the results produced by the proposed method are still remarkable. The average elapsed time of our MR-RPM on these two patterns with approximately 100 points is approximately 0.5 s.</p><p>The results of seven methods (i.e., SC <ref type="bibr" target="#b12">[13]</ref>, robust point matching using thin plate spline (TPS-RPM) <ref type="bibr" target="#b6">[7]</ref>, robust point matching by preserving local neighborhood structures (RPM-LNS) <ref type="bibr" target="#b21">[22]</ref>, GMM-based registra-  tion (GMMREG) <ref type="bibr" target="#b14">[15]</ref>, CPD <ref type="bibr" target="#b15">[16]</ref>, GLTP <ref type="bibr" target="#b18">[19]</ref>, and VFC <ref type="bibr" target="#b23">[24]</ref>) are reported to provide a quantitative comparison with stateof-the-art methods, as shown in Fig. <ref type="figure" target="#fig_1">3</ref>. We implement the seven comparison methods based on publicly available codes and use their default parameter settings because these methods were evaluated on the same data set as that used in this paper.</p><p>To characterize the registration error, we compute the average Euclidean distance between the warped model points and their ground truth corresponding target points in each pattern pair. Subsequently, to make a quantitative comparison of different methods, we calculate the mean and standard deviation of the registration error on all the 100 samples for each level of degradation in each type of degradation.</p><p>The results in Fig. <ref type="figure" target="#fig_1">3</ref> show that SC, GMMRGE, and GLTP are sensitive to noise, whereas TPS-RPM is poorly degraded when the occlusion ratio is high. The alignment performance of RPM-LNS and CPD is relatively good, which declines smoothly when the level of degradation goes up. By contrast, in most cases, the VFC and MR-RPM can achieve the best performance, except in high noise level. MR-RPM almost consistently outperforms VFC for different degradation types and degradation levels on all of the data sets, especially when the data are degraded by a large degree of deformation. Note that the key difference of our MR-RPM and the compared iterative algorithms, especially VFC, is that our MR-RPM adopts an extra manifold regularization term to regularize the transformation. Consistently better results illustrate that manifold regularization does play an important role in improving transformation learning.</p><p>We next validate the effectiveness of our sparse approximation and test the accuracy and efficiency of our method with and without sparse approximation on the two shape patterns with occlusion degeneration. The results are reported in Table <ref type="table" target="#tab_1">I</ref>. We see that the average registration errors of MR-RPM and MR-RPM-S are quite close and that MR-RPM-S even improves the registration performance in some cases. This result may be because the sparse approximation solution with less basis functions in <ref type="bibr" target="#b17">(18)</ref> is "simpler" than the original optimal solution in <ref type="bibr" target="#b15">(16)</ref> and it is easier to solve in the context of nonconvex optimization. For the average runtime, we only report in Table <ref type="table" target="#tab_1">I</ref>, the time cost of transformation estimation (i.e., without the time cost of correspondence construction), which can directly highlight the advantage of sparse approximation. The results show that sparse approximation can greatly improve registration efficiency, and this advantage is further magnified when the size of the point set goes up, especially in case of 3-D point registration.  The influence of the parameter settings is also investigated. Specifically, we change the value of one parameter and fix the values of the other four parameters and test the average registration errors on the 100 fish pattern pairs, with the occlusion ratio at 0.3 (refer to the bottom right figure in Fig. <ref type="figure" target="#fig_1">3</ref>). The results are reported below in Fig. <ref type="figure" target="#fig_2">4</ref>. We see that the best performance can be achieved at = 0.05, β = 0.1, λ 1 = 3, and λ 2 = 0.1. For parameter K , i.e., the number of bases used for sparse approximation, the performance generally improves as K increases. However, the performance is already sufficiently good at K = 15. For the sake of efficiency, we set the default value to K = 15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results on 3-D Point Cloud</head><p>To test the registration performance of the proposed MR-RPM on 3-D point clouds, we use a public wolf shape pattern with approximately 5000 points in different poses for the evaluation <ref type="bibr" target="#b59">[60]</ref>. In Fig. <ref type="figure" target="#fig_3">5</ref>, the first two columns show the results of the test on nonrigid deformation, and the other two columns show the results of the test on occlusion. Under both conditions, the proposed method consistently produces superior results. An average run time of approximately 47 s is required for this data set.</p><p>A quantitative comparison of two typical state-of-the-art methods, namely, CPD and VFC, is conducted. The average alignment errors on the nonrigid deformation and occlusion cases shown in Fig. <ref type="figure" target="#fig_3">5</ref> are 0.82 and 0.72 for CPD, 1.15 and 1.01 for VFC, and 0.78 and 0.53 for MR-RPM, respectively. Clearly, the proposed method exhibits the best results, which indicates that MR-RPM is effective for registration of both the 2-D and 3-D data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results on Visual Homing</head><p>MR-RPM is evaluated using a widely used panoramic image database 2 in the visual homing literature <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b52">[53]</ref>.</p><p>2 http://www.ti.uni-bielefeld.de/html/research/avardy/index.html</p><p>The panoramic image database contains a collection of omnidirectional and unwrapped images in an indoor environment, together with ground truth for positions where the images were collected. The database includes several scenes, and the sizes of the collected images are 561 × 81, 583 × 81, or 295 × 41. The actual intervals between two nearest positions for image collection are 30 cm. Given that the image resolution is relatively low, the default parameter of SIFT is modified to generate more features. Specifically, the number of layers in each octave is increased from default 3 to 6.</p><p>Three types of methods for quantitative comparison, namely, homing in scale space (HiSS) <ref type="bibr" target="#b51">[52]</ref>, visual servoing-based methods <ref type="bibr" target="#b2">[3]</ref>, and motion flow interpolation by smoothness prior (MFI-SP) <ref type="bibr" target="#b52">[53]</ref>, are used to validate the effectiveness of MR-RPM in visual homing. Note that in <ref type="bibr" target="#b2">[3]</ref>, four variants of homing methods are introduced: 1) bearing-only visual servoing; 2) scale-only visual servoing; 3) scale and bearing visual servoing, and 4) simplified scale-based visual servoing (SSVS). For these four variants, only the results of SSVS are reported because of its superior performance and efficiency compared with the other three methods. Moreover, SSVS is the first choice of the original authors according to their comprehensive evaluation. <ref type="foot" target="#foot_1">3</ref> We implement all the comparison methods and tune all the parameters according to the original papers to find the optimal settings. As in <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b51">[52]</ref>, the total average angular error (TAAE), minimal error (Min), maximal error (Max), and standard variation of error (StdVar) are used to evaluate the homing performance. For all the metrics, small values indicate good results.</p><p>1) Sparse Feature Matching on Panoramic Images: The method for sparse feature matching on panoramic images is tested. The ground truth is established by the manual  checking of each putative match in each image pair, and only 23 image pairs with large viewpoint changes are selected for quantitative evaluation. This method not only makes the test data challenging but also simplifies the construction of the ground truth. Four state-of-the-art feature matching algorithms, namely, RANSAC <ref type="bibr" target="#b55">[56]</ref>, identifying correspondence function (ICF) <ref type="bibr" target="#b60">[61]</ref>, graph shift (GS) <ref type="bibr" target="#b61">[62]</ref>, and VFC <ref type="bibr" target="#b23">[24]</ref>, are adopted for quantitative comparison.</p><p>The matching results of different approaches are reported in Fig. <ref type="figure" target="#fig_4">6</ref>. The average inlier ratio in the putative sets is approximately 76.53%, and the average number of putative matches is approximately 125.2. The results show that MR-RPM clearly has the best precision and recall tradeoff. RANSAC has the best precision but the worst recall because the panoramic pair does not satisfy a parametric model exactly; thus, only a part of the true matches can be identified. The missing matches will inevitably affect the subsequent dense motion field interpolation. GS and ICF have similar performances but have middle-rank precisions and recalls. VFC has slightly better precisions than MR-RPM; however, the recalls of the proposed method are better, which is important for learning accurate dense motion flow in areas with few sparse feature matches. The runtime statistics of the different methods are also provided on the rightmost figure in Fig. <ref type="figure" target="#fig_4">6</ref>. The average run time of MR-RPM is approximately 59 ms, which ranks in the middle among run times of the other methods.</p><p>2) Visual Homing on Panoramic Images: The method for visual homing is further tested. Fig. <ref type="figure" target="#fig_5">7</ref> provides several intuitive results of the different methods on homing performance. Position (5, 8) of the A1originalH data set is considered as the reference home position, and the homing vectors calculated from other images using the four methods are shown in Fig. <ref type="figure" target="#fig_5">7</ref>  The statistics of the homing vector errors of all methods on the test database are reported in Table <ref type="table" target="#tab_2">II</ref>. In general, MR-RPM can produce results that are better than or comparable to the results of other competitors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>This paper proposes a novel approach named MR-RPM for the nonrigid registration of 2-D shape patterns and 3-D point clouds. Our approach uses manifold regularization to exploit the intrinsic geometrical structures of the given data, resulting in a reliable estimate of the underlying transformation. Fast implementation has also been provided to reduce algorithm complexity from cubic to quadratic. This enhances the suitability of the proposed method for the large-scale data (particularly 3-D point cloud). The superiority of MR-RPM over state-ofthe-art alternatives is demonstrated on public 2-D and 3-D data sets qualitatively and quantitatively, particularly in the context of significant nonrigid deformations and/or occlusions. Moreover, the proposed method is applied to a real-world task, that is, visual homing, and it realizes a more advanced performance compared with other state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX PROOF OF THEOREM 1</head><p>For any given reproducing kernel , a unique RKHS H M can be defined by considering the completion of the space as follows:</p><formula xml:id="formula_41">H M = M i=1 (•, x i )c i : c i ∈ Y (<label>24</label></formula><formula xml:id="formula_42">)</formula><p>and its norm is induced by the following inner product:</p><formula xml:id="formula_43">f, g H = M i, j =1 (x j , x i )c i , d j ∀f, g ∈ H M (<label>25</label></formula><formula xml:id="formula_44">)</formula><p>where f = M i=1 (•, x i )c i and g = M j =1 (•, x j )d j . Let H ⊥ M stand for a subspace of H, and it has the form</p><formula xml:id="formula_45">H ⊥ M = {T ∈ H : T (x i ) = 0, n ∈ II N M }.<label>(26)</label></formula><p>Considering the reproducing property <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b48">[49]</ref>, ∀T ∈ H ⊥ M , we have the inner product</p><formula xml:id="formula_46">T , M i=1 (•, x i )c i H = M i=1 T (x i ), c i = 0. (<label>27</label></formula><formula xml:id="formula_47">)</formula><p>That is to say, the two spaces H ⊥ M and H M are orthogonal, and each T ∈ H can be decomposed into two orthogonal components: </p><formula xml:id="formula_48">T = T M + T ⊥ M ,</formula><formula xml:id="formula_49">E(T ) = 1 2σ 2 L i=1 p i y i -T (x i ) 2 + λ 1 2 T M + T ⊥ M 2 H + λ 2 2 tr(t T At) ≥ 1 2σ 2 L i=1 p i y i -T M (x i ) 2 + λ 1 2 T M 2 H + λ 2 2 tr t T M At M . (<label>28</label></formula><formula xml:id="formula_50">)</formula><p>Thus, the optimal solution of the objective function ( <ref type="formula" target="#formula_22">15</ref>) is derived from the space H M and hence can be expressed as <ref type="bibr" target="#b15">(16)</ref>. By defining the functional f H as f H = ( f, f H ) 1/2 and considering the inner product in <ref type="bibr" target="#b24">(25)</ref>, the manifold regularized risk functional is then converted into the matrix form as follows:</p><formula xml:id="formula_51">E(T ) = 1 2σ 2 P 1/2 (Y -J C) 2 F + λ 1 2 tr(C T C) + λ 2 2 tr(C T A C)<label>(29)</label></formula><p>where is an M × M matrix and i j = κ(x i , x j ), J = (I L×L , 0 L×(M-L) ), and C = (c 1 , . . . , c M ) T is the M × D coefficient matrix. The linear system in (17) can be obtained by considering the derivative of ( <ref type="formula" target="#formula_51">29</ref>) with respect to C and setting it to zero. Therefore, the coefficient set {c i } M i=1 of the optimal solution T is determined using the linear system <ref type="bibr" target="#b16">(17)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Qualitative illustration of the MR-RPM on the fish (a)-(c) and Chinese character (d)-(f) patterns. For each group of results, the top plots are the input data, whereas the bottom plots are the alignment results, with the level of degradation increasing from left to right. Input data suffer from deformation, noise, and occlusion (from top to bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Comparison of MR-RPM with SC, TPS-RPM, RPM-LNS, GMMREG, CPD, GLTP, and VFC on the fish (top) and Chinese character (bottom). Error bars: registration error means and standard deviations over 100 trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.<ref type="bibr" target="#b3">4</ref>. Illustration of the influence of parameter settings. The testing data are the 100 fish pattern pairs with occlusion ratio at 0.3, and we compute the average registration error to characterize the registration performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Qualitative illustration of our MR-RPM on 3-D point clouds (wolf ) undergoing nonrigid deformation (left two plots) and occlusion (right two plots).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Precisions (left), recalls (middle), and run times (right) of RANSAC, ICF, GS, VFC, and MR-RPM on a panoramic data set [3].</figDesc><graphic coords="11,312.47,215.45,248.18,80.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Homing vectors and error analysis referring to grid position (5, 8) in data set A1originalH. (a)-(d) Homing vectors. The solid circle in each figure is the homing position. (e)-(h) Angular errors for each position (unit: degree).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Schematic of the feature matching and dense motion flow estimation results of MR-RPM. The feature matching result, where the blue and black lines indicate the preserved inliers and removed outliers (top). The corresponding sparse motion flow samples (middle). Dense motion flow estimated based on the preserved matches by MR-RPM, where the black dots indicate the localized FOC and FOE (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(a)-(d). The corresponding average angular errors for each position of the data set are shown in Fig. 7(e)-(h). The results show that MR-RPM can provide more accurate homing results.The feature matching result and estimated dense motion flow on a typical image pair are schematically shown in Fig.8. Clearly, all the inliers and outliers in the putative set are correctly distinguished. The estimated dense motion flow, FOC, and FOE are also consistent with the real motion flow. In this example, the FOC and FOE are approximately (440, 41) and (133, 41), respectively. The proposed method usually takes approximately 9 ms to localize the FOE/FOC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 H = T M 2 H + T ⊥ M 2 H</head><label>222</label><figDesc>whereT M ∈ H M and T ⊥ M ∈ H ⊥ M . Moreover, t M = (T M (x 1 ), . . . , T M (x M )) T .Based on the orthogonality T M + T ⊥ M and the reproducing property T (x i ) = T M (x i ), the regularized risk functional satisfies the following expression:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Model point set {x i } M i=1 , target point set {y j } N j =1 , parameters , β, λ 1 , λ 2 , K Output: Aligned model point set {x i } M i=1 1 Construct descriptors for target point set {y j } N j =1 ; 2 Calculate the volume of output space and assign it to a;</figDesc><table><row><cell cols="2">Algorithm 1 MR-RPM Algorithm</cell></row><row><cell cols="2">Input: 3 repeat</cell></row><row><cell>4 5</cell><cell>Construct descriptors for model point set {x i } M i=1 ; Construct S = {(x i , y i )} L i=1 using descriptors;</cell></row><row><cell>6</cell><cell>Compute matrix A using Eqs. (5) and (6);</cell></row><row><cell>7</cell><cell>Compute based on the definition of ;</cell></row><row><cell>9</cell><cell>repeat</cell></row><row><cell>10</cell><cell>E-step:</cell></row><row><cell>12</cell><cell>M-step:</cell></row><row><cell>13</cell><cell>Compute σ 2 and γ using Eqs. (13) and (14);</cell></row></table><note><p><p><p><p>8</p>Initialize P = I, γ , T (x i ) = x i , and σ 2 by Eq. (</p>13</p>); 11 Compute P = diag( p 1 , . . . , p L ) using Eq. (12); 14 Compute C by solving Eq. (19); 15 until Q converges; 16 Transform model set {x i } M i=1 ← {T (x i )} M i=1 ; 17 until achieve the maximum number of iterations; 18 Output {x i } M i=1 as {T (x i )} M i=1 in the last iteration.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I STATISTICS</head><label>I</label><figDesc>OF THE AVERAGE ERRORS AND RUNTIME (UNIT: SECOND) OF MR-RPM AND ITS SPARSE APPROXIMATION (I.E., MR-RPM-S) ON THE TESTING DATA SETS WITH DEGENERATION OF OCCLUSION. BOLD: BETTER PERFORMANCE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II STATISTICS</head><label>II</label><figDesc>OF VISUAL HOMING ERROR BY USING DIFFERENT METHODS (UNIT: DEGREE)</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The definitions of u h , u v , and u h max are the same as x h , x v , and x h max , respectively, and u v max is the vertical width of the image plane.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Among the different feature extraction methods used in this paper, the performances of HiSS<ref type="bibr" target="#b51">[52]</ref> and SSVS<ref type="bibr" target="#b2">[3]</ref> are not the same as those reported in previous studies. The reimplemented SSVS method in this paper does not contain the mismatch removal introduced in<ref type="bibr" target="#b2">[3]</ref>.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 61773295, Grant 61503288, Grant 61501413, and Grant 41501505, in part by the Beijing Advanced Innovation Center for Intelligent Robots and Systems under Grant 2016IRS15, in part by the MQNS under Grant 9201701203, in part by MQ EPS under Grant 9201701455, and in part by the 2018 Collaborative Research Project between Macquarie University and Data61 under Grant 92307766.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey of image registration techniques</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="376" />
			<date type="published" when="1992-12">Dec. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A method for registration of 3-D shapes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Mckay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="1992-02">Feb. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual homing from scale with an uncalibrated omnidirectional camera</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pradalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1353" to="1365" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Guided locality preserving feature matching for remote sensing image registration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4435" to="4447" />
			<date type="published" when="2018-08">Aug. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Infrared and visible image fusion methods and applications: A survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="153" to="178" />
			<date type="published" when="2019-01">Jan. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust registration of 2D and 3D point sets</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1145" to="1153" />
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A new point matching algorithm for nonrigid registration</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understand</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="114" to="141" />
			<date type="published" when="2003-02">Feb. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Feature guided Gaussian mixture model with semi-supervised EM and local geometric constraint for retinal image registration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">417</biblScope>
			<biblScope unit="page" from="128" to="142" />
			<date type="published" when="2017-11">Nov. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The softassign procrustes matching algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Bookstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Non-rigid visible and infrared face registration via regularized Gaussian fields criterion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="772" to="784" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Context-aware Gaussian fields for non-rigid point set registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
			<biblScope unit="page" from="5811" to="5819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Shape classification using the inner-distance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="286" to="299" />
			<date type="published" when="2007-02">Feb. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="522" />
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A correlation-based approach to robust point set registration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="page" from="558" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Robust point set registration using Gaussian mixture models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1633" to="1645" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Point set registration: Coherent point drift</title>
		<author>
			<persName><forename type="first">A</forename><surname>Myronenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2262" to="2275" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rigid and articulated point registration with expectation conditional maximization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yguel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dewaele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="587" to="602" />
			<date type="published" when="2011-03">Mar. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Non-rigid point set registration by preserving global and local structures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="64" />
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Non-rigid point set registration with global-local topology preservation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis</title>
		<meeting>IEEE Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2014-06">Jun. 2014</date>
			<biblScope unit="page" from="245" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Articulated non-rigid point set registration for human pose estimation from 3D sensors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="15218" to="15245" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast point feature histograms (FPFH) for 3D registration</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th IEEE</title>
		<meeting>26th IEEE</meeting>
		<imprint>
			<date type="published" when="2009-05">May 2009</date>
			<biblScope unit="page" from="3212" to="3217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust point matching for nonrigid shapes by preserving local neighborhood structures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="643" to="649" />
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A fast and robust local descriptor for 3D point cloud registration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="page" from="163" to="179" />
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust point matching via vector field consensus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1706" to="1721" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robust L 2 E estimation of transformation for non-rigid registration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1115" to="1129" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A robust non-rigid point set registration method based on asymmetric Gaussian representation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understand</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="67" to="80" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. B, Methodol</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Networks for approximation and learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Girosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990-09">Sep. 1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1481" to="1497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Non-rigid point set registration with robust transformation estimation under manifold regularization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf. Artif. Intell</title>
		<meeting>AAAI Conf. Artif. Intell</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4218" to="4224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Surface feature detection and description with applications to mesh matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zaharescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Varanasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="373" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Combinatorial Optimization: Algorithms and Complexity</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Steiglitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<pubPlace>Chelmsford, MA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Courier Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Theory of reproducing kernels</title>
		<author>
			<persName><forename type="first">N</forename><surname>Aronszajn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Amer. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="337" to="404" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Solutions of Ill-Posed Problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Arsenin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>Winston</publisher>
			<pubPlace>Washington, DC, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Face recognition using Laplacianfaces</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="340" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph embedding and extensions: A general framework for dimensionality reduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Trace ratio criterion based generalized discriminative learning for semi-supervised dimensionality reduction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W S</forename><surname>Chow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1482" to="1499" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning from normalized local and global discriminative information for semisupervised regression and dimensionality reduction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W S</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="286" to="309" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multiview vectorvalued manifold regularization for multilabel image classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="709" to="722" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Descriptor learning via supervised manifold regularization for multioutput regression</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhaduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2035" to="2047" />
			<date type="published" when="2017-09">Sep. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Discriminative semisupervised feature selection via manifold regularization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-T</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1033" to="1047" />
			<date type="published" when="2010-07">Jul. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Automatic image annotation via compact graph based semi-supervised learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W S</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="148" to="165" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Turbopixel segmentation using Eigen-images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3024" to="3034" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Vector-valued manifold regularization</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Q</forename><surname>Minh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On learning vector-valued functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="204" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Regularized least-squares classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rifkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Learning Theory: Methods, Model and Applications</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Regularized vector field learning with sparse approximation for mismatch removal</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3519" to="3532" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An orientation invariant visual homing algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Churchill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="29" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Visual homing by robust interpolation for sparse motion flow</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots Syst</meeting>
		<imprint>
			<date type="published" when="2017-09">Sep. 2017</date>
			<biblScope unit="page" from="1282" to="1288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Combining invariant features and the ALV homing method for autonomous robot navigation based on panoramas</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramisa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldhoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aldavert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>De Mantaras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="625" to="649" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On the robustness of visual homing under landmark uncertainty</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schroeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Autonomous Systems</title>
		<meeting><address><addrLine>Clifton, VA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="278" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Local visual homing by matched-filter descent in image distances</title>
		<author>
			<persName><forename type="first">R</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="413" to="430" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Visual homing via guided locality preserving matching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Autom</title>
		<meeting>IEEE Int. Conf. Robot. Autom</meeting>
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
			<biblScope unit="page" from="7254" to="7261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Blended intrinsic maps</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Rejecting mismatches by correspondence function</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Common visual pattern discovery via spatially coherent correspondences</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis</title>
		<meeting>IEEE Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="1609" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
