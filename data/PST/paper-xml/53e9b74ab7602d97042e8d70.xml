<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DAISY: Dynamic Compilation for 100% Architectural Compatibility</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kemal</forename><surname>Ebciofjlu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Erik</forename><forename type="middle">R</forename><surname>Altman</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IBM Thomas J. Watson Research Center Yorktown Heights</orgName>
								<address>
									<postCode>10598</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">ISCA &apos;97</orgName>
								<address>
									<settlement>Denver</settlement>
									<region>CO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DAISY: Dynamic Compilation for 100% Architectural Compatibility</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F0D5E886201476C174526E67477A8455</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>INSTRUCTION-LEVEL PARALLELISM</term>
					<term>OBJECT CODECOMPATIBLE VLIW</term>
					<term>DYNAMICCOMPILATION</term>
					<term>B~NARY TRANSLATION</term>
					<term>~UPERSCALAR</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although VLIW architectures offer the advantages of simplicity of design and high issue rates, a major impedimegt to their use is that they are not compatible with the existing software base. We describe new simple hardware features for a VLIW machine we call DAISY (Dynamically Architected Instruction Set from Yorlrtown). DAISY is specifically intended to emulate existing architectures, so that all existing software for an old architecture (including operating system kernel code) runs without changes on the VLIW. Each time a new fragment of code is executed for the first time, the code is translated to VLIW primitives, parallelized and saved in a portion of main memory not visible to the old architecture, by a Ertual Machine Monitor (software) residing in read only memory. Subsequent executions of the same fragment do not require a translation (unless cast out). We discuss the architectural requirements for such a VLIW, to deal with issues including self-modifying code, precise exceptions, and aggressive reordering of memory references in the presence of strong MP consistency and memory mapped I/O. We have implemented the dynamic parallelization algorithms for the PowerPC architecture. The initial results show high degrees of instruction level parallelism with reasonable translation overhead and memory usage.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Background and Motivation</head><p>Very Long Instruction Word (VLIW) architectures offer the advantages of design simplicity, a potentially short clock period, and high issue rates. Unfortunately, high performance is not sufficient for success. One of the major impediments to using a VLIW (or any new ILP machine architecture) has been its inability to run existing binaries of estabIished architectures. It was argued (and not face-tiously) in a recent keynote speech <ref type="bibr">[I 11</ref>, that architectures which do not run Intel x86 code may well be doomed for failure, regardless of their speed! To solve the compatibility problem efficiently, there have been several proposals beyond plain or caching interprctcrs <ref type="bibr">[lo]</ref>. One has been the object code translation approach (c,g, <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>), where a software program takes as input an executable module generated for the old machine, and profile directed feedback information from past emulations, if available. It then generates a new executable module that can run on thenew architecture (resorting to interpretation in some difficult cases), and that gives the same results that plain interpretationwould. Although many of the nasty challenges to static object code translation (programs printing their own checksum, shared variables, self modifying code, generating a random number and using it as a branch target address, and so on) have been addressed, the static object code translation solution still has some problems.</p><p>If object code trtislation is used to emulate applications written for one existing machine on another ( <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>), then many primitives may need to be generated to emulate one old architecture instruction, or unsafe simplifying assumptions may need to be made (e.g. about ordering of shared variable accesses, or the number of bits in the floating point representation) to get more performance, in which cast full compatibility is sacrificed. This is typicaIly because hardware features to help compatibility with an "important" old architecture were not designed into the new fast machine; compatibility was just not emphasized, or came as an aftcrthought. For example, the set of condition codes maintained is often quite different in different architectures. This object code translation approach does allow the convenicncc of running many important applications of the old architccturc on the new machine, but does not provide a replacement for the old machine in terms of speed and range of applications, If thenew architecture is fully binary compatible with the old one by hardware design, but does not run with the best performance on old binaries, ( <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>), and the new features of the new architecture that improve performance can bc utilized only by object code translation, or recompilation, the solution is still not perfect. Rapid adoption of new architcctural features for higher performance may be possible under certain circumstances; scientific and technical computing is an example. But computer designers often underestimate the strong inertia of the user community and software vendors at large, and their resistance to change.</p><p>Another approach is to translate the old architecture instructions to a new internal representation (e.g. VLIW) at Icache miss time, by hardware <ref type="bibr">[9, 14, 191.</ref> This approach is robust in the sense that it implements the old architecture completely. But the optimizations that can be performed by the hardware are limited, compared to software opportunities. Also the conversion from the old architecture representation in memory to the internal Icache representation is complex (especially if one attempts to do re-ordering) and can require substantial hardware design investment, and VLSI real estate.</p><p>As an alternative we present DAISY (D~~~amicaZ~ Axhitected Instruction Set front Yorktown). DAISY employs software translation, which is attractive because it dispenses with the need for complex hardware whose sole purpose is to achieve compatibility with (possibly ugly) old architecture(s). Given the appropriate superset of features in the new architecture (e.g. condition codes inx86, PowerPC, and S/390 format), DAISY can be dynamically architected by software to efficiently emulate any of the old architectures. Assuming that we can begin with a clean slate for both hardware and emulation software, and adopt a simple design philosophy, what architectural features and compilation techniques are required to make software translation efficient and 100% compatible with existing software? We attack this problem in the current paper.</p><p>While DAISY and this paper focus mainly on a VLIW as the new architecture, the same ideas can be applied any new superscalar design, and potentially to other new LP architectures that break binary compatibility as well. Current compiler techniques for attaining high ILP are unacceptably slow for dynamic parallelization, which requires real-time performance from a compiler, in order to make the overhead imperceptible to the user. To this end, we describe a new, significantly faster parallelization technique. We have implemented this technique for the PowerPC and we report the initial encouraging EP results. Another feature of the new compilation technique is the ability to maintain precise exceptions, so the original instruction responsible for an exception can be identified, whenever an exception occurs. While out-of-order superscalars use elaborate hardware mechanisms to maintain precise exceptions, in our case this is done by soflware alone.</p><p>The paper is organized as follows: We first give an example illustrating the new fast dynamic compilation algorithm used by DAISY. Next, various architectural features to support high performance translation are described. We then describe the dynamic translation mechanism whereby DAISY runs the old software with minimal hardware support. Next we discuss the mapping mechanisms from the old code to VLJW code and back. We then provide some experimental results and conclude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Compilation Algorithm</head><p>In this paper, we call the original, old architecture that we are trying to emulate, the base architecture. The VLIW which emulates the old architecture we called the migrant architecture, following the terminology of <ref type="bibr" target="#b19">[20]</ref>. The base architecture could be any architecture, but we will be giving examples mostly from the IBM PowerPC.</p><p>Traditional caching emulators may spend under 100 instructions to translate a typical base architecture instruction (depending on the architectural mismatch and complexity of the emulated machine). So caching emulators are very fast, but do not do much optimization nor ILP extraction. Traditional VLJW compiler techniques, on the other hand, extract considerable ILP at the cost of much more overhead.</p><p>The goal in DAISY is to obtain significant levels of ILP while keeping compilation overhead to a minimum, to meet the severe time constraints of a virtual machine implementation. Unlike traditional VLIW scheduling, DAISY examines each operation in the order it occurs in the original binary code, converting each into RISC primitives (if a CISCy operation). As each RISC primitive is generated, DAISY immediately finds a VLJW instruction in which it can be placed, while still doing VLJW global scheduling on multiple paths and across loop iterations and while maintaining precise exceptions.</p><p>Figure <ref type="figure" target="#fig_2">1</ref> shows an example of PowerPC code and its conversion to VLJW code l. This conversion uses the algorithm described in <ref type="bibr" target="#b5">[6]</ref>. However, the discussion below should make the main points clear. We begin with four major points: . l Operations are always added to the end of the last VLJW on the current path. If input data for an operation are available prior to the end of the last VLIW, then the operation is performed as early as possible with the result placed in a renamed register (that is not architected in the original architecture). The renamed register is then copied to the original (architected) register at the end of the last VLIW. This is illustrated by the xor instruction in step 4, whose result is renamed to r63 in VLIWl, then copied to the original destination r4 in VLIW2. By having the result available early in r63, later instructions can be moved up. For example, the cntl z in step 11 can use the result in r63 before it has been copied to r4. (Note that we use parallel semantics here in which all operations in a VLIW read their inputs before any outputs from the current VLIW are written.)  <ref type="figure">-----------</ref> non-renameable destinations are placed at the end of the last VLIW on the current path. In this way, precise exceptions can be maintained. For example, assume an external interrupt occurs immediately after VLIWl finishes executing, and prior to the start of VLIW~. The interrupt handler is just an incrementally compiled version of the standard Pow-erPC interrupt handler. Hence it looks only at Pow-erPC architected registers. These registers appear as if instruction 2, bc has just completed execution and control is about to pass to instruction 3, sli.</p><p>(The instruction address register is even set to the proper PowerPC address of the sli, as will be described in Section 3.3.) Since VLIW~ expects the value of the speculatively executed xor to be in non-architcctcd register r63, it is not a valid entry point for the intcrrupt handler to return to: the value of r63 is not saved by the PowerPC interrupt handler, and hence its value may be corrupted upon return from the interrupt. Thus the VMM must either (1) interpret PowerPC instructions starting from instruction 3, sli., until reaching a valid entry into VLIW code (which depends only on values in PowerPC architected registers), or (2) it must compile a new group of VLIW's starting from instruction 3, so as to create a valid entry point.</p><p>. VLIW instructions are trees of operations with multiple conditional branches allowed in each VLIW <ref type="bibr" target="#b4">[5]</ref>. All the branch conditions are evaluated prior to execution of the VLIW, and ALU/Memory operations from the resulting path in the VLIW are executed in parallel, Note that this approach works even if data is misinterpreted as code and aggressively scheduled. As we discuss more in Section 2.1, no side effects to architected resources occur until the point in the original program at which they would occur. However, we can and do limit scheduling of data by halting translation at unconditional branches. If the address following such a branch is indeed code, it must be reachable in one or more of the following ways: (1) by some other path on the page, (2) some branch from another page, or (3) by an indirect jump. In case <ref type="bibr">(l)</ref>, the address will be properly translated when encountered on the other path, For cases (2) and (3), the address will be translated when the executing program actually attempts to branch to that address. In Section 3.2, we discuss VLIW branch instructions which facilitate cases (2) and (3).</p><p>As this example suggests, the instruction set of the tnigrant K!JW architecture should be a superset of the base architecture for efficient execution. 2 This example also raises several questions. How is an OFFPAGE branch handled? How and why is it different than an ONPAGE branch7 How are indirect branches handled? These questions arc addressed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Essential Architectural Features for Aggressive Reordering</head><p>The VLIW must have the usual support for speculative execution and for moving loads above stores optimistically, even when there is a chance of overlap, as discussed in (c.g. <ref type="bibr">[13,</ref><ref type="bibr">12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8]</ref>). Furthermore, dataintermingledwith code, and (unknowingly) scheduled as code must not cause errant execution. In order to keep the paper self contained, WC briefly mention here how we address these problems.</p><p>Each register of the VLIW has an additional exception tag bit, indicating that the register contains the result of an operationthat caused an error. Each opcode has a speculative version (in the present implementation, operations that set a aComplex and/or infrequent instructions such as Load M~lllple Reglsters or Decimal Divide can be decomposed into simpler primitives, non-architected register such as r63 will be speculative). A speculative operation that causes an error does not cause an exception, it just sets the exception tag bit of its result register. The exception tag may propagate through other speculative operations. When a register with the exception tag is used by a non-speculative commit operation, or any non-speculative operation, an exception occurs. This is illustrated below:</p><formula xml:id="formula_0">ORIGIBAL CODE VLIY CODE load x63&lt;-[Addr] bc Ll bc Ll load r3&lt;-[Addr] copy r3&lt;-r63</formula><p>Register r63 is not architected in the base architecture.</p><p>Hence when it is loaded, no exception occurs, even if this load would normally cause a page fault or segmentation violation. Instead the exception tag bit of r63 is set. If the bc falls through, the attempt to copy r63 to r3 will result in an exception since r3 is architected in the base a&amp;itecture. However, if bc is taken, then execution continues apace and no exception is ever taken. This mechanism allows the VMM to move loads aggressively above conditional branches without changing the exception behavior of the original program.</p><p>As discussed above, loads may be moved above stores that cannot be proven not to store into the same location. If there does turn out to be aliasing between a speculative load and a store it passed, or some other processor changed the memory location, the code must be retranslated starting at the load. This allows both the optimistic execution of loads on a single program, and also strong multiprocessor consistency (assuming the memory interface supports strongly consistent shared memory).</p><p>It is not always possible to distinguish at dynamic compile time which loads refer to I/O space (I/O references shouldnot be executed out of order). A speculative memory mapped I/O space load, will be treated as a no-op, but the exception tag of the result register of the load operation will be set. When the load is committed, an exception will occur and the load will be re-executed -non-speculatively this time. Note that neither exception tags nor the nonarchitected registers are part of the base architecture state; they are invisible to the base architecture operating system, which does not need to be modified in any way. With the precise exception mechanism, there is no need to save or restore non-architected registers at context switch time.</p><p>Finally, for this paper, we assume that the base architecture machine is a "standard" register oriented machine with sequential semantics. This need not be the case. For example, <ref type="bibr" target="#b6">[7]</ref> outlines how the DAISY approach could be implemented for a Java stack machine. If the base architectule is a VLIW with parallel semantics, where x = y; y = x; means exchange x and y, the code must first be converted to sequential code by introducing temporaries. The exchange then becomes the sequential code, t = x;</p><p>x = y; y = t;.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Page and Address Mapping Mechanisms</head><p>In this section, we describe the address space layout of the VLIW or migrant architecture and how it compares to that of the base architecture. We then describe why this layout allows a translation mechanism whereby the migrant architecture runs the old base architecture software with minimal hardware support. We also discuss why with this layout, a page is a useful unit of translation for dynamic translation. Finally we describe why DAISY is robust in the presence of self-modifying or self-referential code and why all possible entry points to a page need not be known when translating from a particular entry point to that page.</p><p>The VLIW (migrant architecture) has a virtual memory that is divided into 3 sections, as illustrated in Figure <ref type="figure" target="#fig_4">2</ref>. The low portion, starting from address 0, is mapped with the identity mapping, where VLIW virtual address = VLIW real address, and is identical to the base architecture5 physical address space. (i.e., "real memory" for PowerPC, "absolute memory" for S/390, "'physical memory" for x86). In Figure <ref type="figure" target="#fig_4">2</ref>, for example the base architecture virtual page at virtual address 0x3 0 0 0 0 is mapped to the base architecture physical page at physical address 0x2 0 0 0 (which is the same as VLIW virtual address 0x2 0 0 0 in the low portion of the VLIW virtual memory), through the normal virtual memory mechanism of the base architecture.</p><p>The next, middle portion of the VLIW virtual memory address space, comprises of (1) a read only store (ROM), which contains the Virtual Machine Monitor (VMM) software (that accomplishes the dynamic translation between base architecture code and VLIW code), (2) a read/write area to store various data structures needed by the VMM, and (3) a nonexistent memory area (a hole in VLIW virtual address space). The middle section (where present) is also mapped with the identity mapping, VLIW virtual = VLIW real.</p><p>The third and top section is the translated code area, and starts at a large power of 2 address called VLIW-BASE (e.g.Ox8 00 00000). There are at least two ways in which this section can be mapped:</p><p>l For each page in the physical memory of the base machine, (= the low portion of VLIW virtual memory) there is an N times larger page in the translated code area of the VLIW virtual address space. To achieve an efficient mapping between the base architecture code and VLIW code, N should be a power of 2, so N = 4 seems a reasonable value for PowerPC, S/390 or x86. (The actual code expansion can be larger or smaller, as described in later sections.) The translation of a page at physical address n in the base architecture physical memory, is at VLIW virtual address n x N + VLIW-BASE. The translated code area is not mapped VLIW virtual = VLIWreal (since that would require a VI&amp;V real memory area N times larger than the base architecture memory). Instead, the VMM translates pages when the first execution attempt occurs, and maps it to a real VLIW page frame from a pool of page frames in the upper part of VLIW real storage (discarding the least recently used ones in the pool if no more page frames are available).</p><p>l An alternative is to maintain the top section of memory as a hash table of translated entries. The hash table is indexed by the base architecture physical address and contains the real address of translated VLIW code. This hash table is maintained by the VMM, which adds entries to the hash table as page entry points are translated, and removes them as translations of new pages need the space. This approach has the advantages (1) that code for a translated page can be contiguous, (2) that code need never be moved when a new entry point is discovered, and (3) that there is less wastage -no portion of a VLIW real memory page need be wasted if the actual translation requires less than an NX expansion. However, this second mapping is more complicated than the first approach, and hence slower.</p><p>For simplicity, we shall discuss only the mechanisms first mapping in the Sections below. However, the second approach can be extended in a straightforward manner to accomplish the actions described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Creation of a Page Translation</head><p>Suppose a program running on the base architecture branches offpage to a base architecture instruction, whose physical address is n. In the translated version of the same program running on the VLIW, this branch will be executed bybranchingintoVLIWvirtualaddressnxN+VLIW-BASE in upper area of the VLIW virtual address space. Assume the beginning physical address of this 4K byte base architecture physical page was ng =(&amp;OxfffffOOO)(inCnotation). If this base architecture page has never been executed before, then the corresponding NX 4K byte page at VLIW virtual address (no x N + VLIW-BASE) is not mapped, and therefore a "VLIW translation missing" exception occurs, which is handled by the VMM. The VMM creates a translation for the base arclzitecfure physical page at physical address no, and makes the corresponding translated code area page map to some NX 4K byte page frame in the upper area of VLIW real memory. Then the interrupted translated program will be resumed to redo the branch to address (nx N+VLI W-BASE), which will now succeed. When that fist page of the base architecture program branches to a physical address TZ' in a second, different base architecture physical page that has not yet been executed, that page will in turn be translated and mapped in the same manner.</p><p>As a concrete example, as shown in Figure <ref type="figure" target="#fig_4">2</ref>, suppose the base architecture program begins when the operating system branches to base architecture virtual address 0x3 0 10 0 (part ofthe4Kpageat Ox30000 -Ox3Offf). . The base architecture virtual address 0x3 0100 has been mapped (via base architecture page tables) to base architecture physical address 0x2 10 0 (part of the 4K pageframe 0x2000 -Ox2fff).</p><p>. The VLIW transIation of 0x2 100 is at VLIW virtual address 4 x 0x2100 + VLIW-BASE = 0x80008400 (part of the 16K page 0x80008000 -Ox8000bf f f).</p><p>l In the translated code, the branch to base arclzitecfurr virtual address 0x3 0 10 0 is really executed as a branch toVLIWvirtualaddress 0x800084 00, which belongs to a 16K VLIW virtual page that is not yet mapped. So this branch initially causes a translation missing intcrrupt to the VMM. The VMM creates the translation of the base architecture 4K physical page frame 0x2 0 0 0 -Ox2f f f and writes it into the VLIW 16K page frame at (say) VLIW real address 0x02000000 -0x02003fff, *Finally the VMM maps the VLIW 16K virtual page 0x80008000 -Ox8000bfff to this page frame at 0x02000000 -Ox02003fff.</p><p>The interrupted translated program is then restarted, and now the branch to VLIW virtual address 0x8 0 0 0 84 0 0 succeeds without an interrupt, and starts executing the translated VLIW code for the first page.</p><p>We emphasize that the contents of the upper portion of the VLIW Real Memory are managed by the VMM and arc not paged. When room is needed for newly translated code, theVMM discards the least recently used translation to make space. At some point it may be desirable to page translations to disk so as to save them for later use, but initially WC wish to develop an architecture that requires no base software or system changes.</p><p>All exceptions are fielded by the VMM. When an exccption occurs, the VLIW branches to a fixed offset (based on the type of exception) in the VMM area. So far WC havo described the VLlW translation not present and cocle NIO&amp; zjkation interrupts, that are handled directly by the VMM. Another type of exception occurs when the translated code is executing, such as a page fault or external interrupt. In such cases, the VMM first determines the base arc~zitecfure instruction that was executing when the exception occurred, (The translation is done maintaining precise interrupts as was described in Section 2, so this is possible.) The VMM then performs intenupt actions required by the base arclzitectzrre, such as putting the address of the interrupted base archi tee ture instruction in a specific register. Finally the VMM branches to the translation of the base operating system code that would handle the exception. When the baso operating system is done processing the interrupt, it executes a return-from-interrupt instruction which rcsumcs execution of the interrupted code at the translation of the interrupted instruction.</p><p>We still need to address the problem of how to handlc an offpage branch in the base architecture to an address q on the same 4K page as n, but where q was not identified as a possible entry point during the translation starting from n. This problem is addressed in Section 3.2. Another concern is self-referential code such as code that takes the checksum of itself or code with floating point constants interrnixcd with real code or even PC-relative branches. These arc all transparently handled by the fact that all registers architectcd in the base architecture -including theprogram counter or instruction address register-contain the values they would  The only means for code to refer to itself is through these registers, hence self-referential code is trivially handled.</p><p>A final major concern is selfmodifying code. Each "unit" of base architecture physical memory (low section of VLIW virtual memory) has a new read-only bit, not known to the base architecture. (The unit size is 4K for PowerPC, 2 2 bytes for S/390, 2 1 byte for x86 -perhaps 8 for both.) Whenever the VMM translates any code in a memory unit, it sets its read only bit to a 1. Whenever a store occurs to a memory unit that is marked as read-only (by this or another processor, or I/O) an interrupt occurs to the VMM, which invalidates the translation of the page containing the unit. The exception is precise, so the base architecture machine state at the time of the interrupt corresponds to the point just after completing the base architecture instruction that modified the code (in case the code modification was done by the program). After invalidating the appropriate translation, the program is restarted by branching to the translation of the base architecture instruction following the one that modified the code. If the page currently executing was modified, then retranslation of the page will occur before the program can be restarted.</p><p>The above paragraphs describe the logical behavior of the address mappings. In the actual implementation, these multiple levels of address mapping are collapsed to one level, so cross-page branches can execute very efficiently, as will be seen in section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">VLJW Branch Instructions</head><p>We described in Section 3.1 how one could find the translation of a base architecture instruction at physical address n, by branching to VLJW virtual address n x N + VLIW-BASE. So, if an instruction is at offset nin the basearchitecture page, its translation is at offset n x N in the VLIW translated code page. In reality, not all entry points are valid all the time in the VLIW page, a fact with which cross-page branches must deal. There are multiple ways of implementing cross-page branches, and we first describe a high-performance altemative. We then describe two lower performance and cheaper alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High Performance Branches</head><p>The VLIW primitive to perform a cross-page branch is:</p><p>(G~~.~R~SS-PAGE reg offset) The off set is added to the register reg to obtain an effective address of the base architecture. That effective address is first translated to a physical address of the base architecture; then it is multiplied by N and VLIWBASE is added to it; then it is translated to a VLIW real address, which is finally the address of the branch target VLIW. If the base architecture physical address is not available, a base architecture instructionpagefault exception occurs (to a handler in the VMM -all exceptions are fielded by the VMMJ If the translated VLIW code for this page is not available, a translation missing exception occurs. If the target VLIW is not marked as a valid entry, an invalid entry exception occurs. Otherwise execution proceeds with the target VLlW instruction.</p><p>Theabovedescriptionmay give the impression ofa daunting CISC instruction, but here is how it can be implcmentcd: Assume the VLIW Instruction Translation Lookaside Buffer (ITLB) maps the base architecture 4K virtual page numbers directly into VLIW Nx 4K real page frame numbers that contain the translated code. The software could guarantee that the low order 12 bits of reg is 0, or the off set is 0, so the low order 12 bits of the effective address reg+of f set: is immediately available. The low order 12 bits of the effcctive address are shifted left by logz(N) bits, and applied to the Icache (14 bits allows a 64K cache, if 4 way associative). At the same time the upper bits of the effective address arc sent to the ITLB. If a VLIW real address that comes out of the Icache directory matches the VLIW real address that comes out of the ITLB, no miss occurs. The target VLIW is then checked for an valid entry marker on the next cycle, while optimistically executing the target VLIW as if it were a valid entry (and recovering before any side effects occur, and causing an exception, in case the target VLIW is an invalid entry).</p><p>If only an Icache miss occurs, hardware handles it. One could handle an ITLB miss by hardware sequencers, but using a yet lower level of software to implement a "microinterrupt" ITLB miss handler is simpler, and more in lint with the philosophy of the present design. (Note that all software in a VLIW is like horizontal microcode, so no part of the VLIW software is necessarily slower than horizontal microcode.)</p><p>Other types of branches are: . (GOTO off set 1 just branches to the VLIW at off set in the current page (no check for a valid cntry). Ordinary intra-page branches between VLIW's use this branch.</p><p>l (GOT0 lr) , (GOTO long-offset) branch to the VLIW at the real address given by a link rcgister, lr or the long-off set, There is no check for a valid entry, and the ITLB is bypassed. Branches to an overflow area may use these primitives. The cross-page branch, ITLB, and valid entries mcchanism described above are intended for reducing the latency of a cross-page branch. If we give up the simultaneous ITLB lookup, we could first do the address translation in a prior VLIW, and then send a VLIW real address to the Icache, which has some advantages in Icache design.</p><p>; reg + offset is translated to physicaladdross n, ; The VLIY real address for VLIU virtual addroan ; n*B + VLIU-BASE is then placed in lrl. (LBA reg offset (lrl))</p><p>; Goto VLIU real addr in lrl. Check if valid ontry (GO~ACROSS~PAGElrl)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simpler Cross Page Branches</head><p>As noted earlier, we can also give up the valid entry point approach. Let the translated code page for a base anditecture page consist of a vector of pointers. For a base instruction at offset n in the base architecture page, vector element vz will contain the real address of the VLIW code, or in case the entry at offset n has not yet been created for this page, the real address of a translator routine, that will create the corresponding VLIW code. This costs another level of indirection, but is simpler to manage.</p><p>; Put translated reg + offset in tl ==&gt; tl contains ; real address of ptr to VLIU code for this entry. For additional simplicity, we could even give up the ITLB and simulate a big direct mapped ITLB in VLIWreal memory by software. In many cases the operations for doing the crosspage branch may be moved up into previous VLIW's, and their latencies hidden.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Finding Exception-Causing Instruction in Base Architecture</head><p>As we mentioned in Section 3.1, when an exception occurs in VLIW code, the VMM should be able to find the base anzhitecture instruction responsible for the interrupt, and the register and memory state just before executing that instruction.</p><p>A Virtual Page Address (WA) register is maintained. The VPA contains the address of the current page in the original code, and is updated in the translated code whenever a cross-page branch is executed. The simplest way to identify the original instruction that caused an exception is to place the offset of the base instruction corresponding to the beginning of a VLIW as a no -op inside that VLJW, or as part of a table that relates VLIW instructions and base instructions, associated with the translation of a page. For example, the offset within a page could be kept in a IO-bit field in each VLIW instruction. (10 bits assumes a 4096 byte page aligned on a I-byte boundary.)</p><p>If the VLIW has an exception semantics where the entire VLIW appears not to have executed, whenever an error condition is detected in any of its parcels, then the offset identifies where to continue from in the base code. Interpreting a few base instructions may be needed before identifying the interrupting base instruction and the register and memory state just before it.</p><p>If the VLIW has a sequential semantics (like an in-order superscalar, where independently executable operations have been grouped together in "VLIW's") so that all parcels that logically preceded the exception causing one have executed when an exception is detected, the identification of the original base instruction does not require interpretation. Assuming the base architecture code page offset corresponding to the beginning of the VLIW is available, the original base instruction responsible for the exception can be found by matching the assignments to architected resources from the beginning of the VLIW instruction, to those assignments in the base code, starting at the given base code offset.</p><p>One way to avoid extra fields, tables, and pointers to the original base architecture instructions altogether is as follows: Let us assume the VLIW has sequential semantics, and exceptions occur at a parcel of VLIW, (as opposed to a VLIW boundary). In this scheme there are no offsets in the VLIW code that relate it to the base architecture, nor any tables. This scheme relies on the fact that the entry point of the group of VLIW's, is known to have an exact correspondence with a base architecture instruction. (If the beginning of the group is at offset N x TZ in the translation page, the original base instruction must be at offset n in the base architecture page).</p><p>We describe the scheme with the help of the example in Figure <ref type="figure" target="#fig_8">3</ref>. Assume that the load at address 0x8 causes a page fault. To determine the base architecture address of the exception-causing instruction, the VMM finds the backward path from the exception causing parcel to the entry point of the group of VLIW's. The exception is registered in VLIW~ in the copy r5=r5 ' instruction, when the exception bits associated with r5 ' are acted upon. Thus the VMM traces from this parcel to the start of VLIWl. the entry point of this group of VLIW's. If VLIW's are laid out in a topological order from the entry point, a backward scan in the binary code from the interrupting parcel to the nearest entry point should be able to rapidly identify the path from the entry point to the interrupting parcel.</p><p>As the backward path isscanned, {copy, bc, VLIW2, b VLIW2, load, cmpi , VLIWl}, the VMM remembers the branch directions taken by conditional branches, in this case the fact that bc cr0 . eq is not taken. Upon reaching the top of the backwards path, the base architecture address corresponding to VLIWl is calculated: VPA + VLIWlo~set/4, ifthe code has 4x expansion. In this case the calculation yields address 0 in the base architecture. Now the same path is followed in forward order, {VLIWl, cmpi, load, b VLIWZ, VLIW~, bc, copy}. There has to be a one to onecorrespondence between assignments to architected registers, conditional branches and stores in the VLIW code path, and assignments to architected registers, conditional branches and stores in the base code path. Thus the cmpi assignment to cr0 is matched first. The load to r5' is passed over sincer5' isnotarchitectedinthebase architecture. The next correspondence is the bc at address 0x4 in the base architecture. The VMM recorded that this branch was not taken, so the VMM moves to instruction at 0x8 in the base architecture. The load to r5 in the base architecture is matched to the copy to r5 in the VLIW. Since the VMiM recorded that this copy caused the exception, it determines that the load at 0x8 is the offending instruction. The VMM then puts 0x8 in the register used by the base architecture to identify the exception, and branches to the VLIW translation of the exception handler. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We have implemented the incremental compilation technique for the Rs/6000, which is essentially the same as Pow-erPC for our purposes. The present version of the incremental compiler is incomplete in anumber ofways. For example, the "combining" optimization includes only a small subset of all combining possibilities, and software pipelining is not implemented. Nevertheless, we provide here some preliminary results on the SPECint95 benchmarks, as well as a few AIX utilities, and an Erastothenes' Sieve program for finding prime numbers (a Stanford integer benchmark).</p><p>Since our implementation of DAISY runs on RS/6000 machines, a set of RS/6000 simulation instructions (in direct binary form) is also generated for each VLIW. These RS/6000 instructions emulate the actions of each VLIW. In effect we use a compiled simulation method similar to Shade <ref type="bibr" target="#b2">[3]</ref> for simulating our VLIW machine on theRS/6000. During transitions between VLIW's, a counter is incremented for each VLIW flowgraph edge. From the edge counts and from information about the static properties of each edge, ALU usage histograms and other statistical data can be obtained at the end of the run. A call to a kernel routine is translated to a real call, so kernel routines are not simulated in the current implementation. But since many applications that spend most of their time in user and library code, we can learn significantly about available ILP, and tradeoffs in compiler techniques, from the current implementation.</p><p>Table <ref type="table" target="#tab_0">1</ref> contains the pathlength reductions achieved on the SPECint95 benchmarks for an 8-issue machine. These numbers were obtained by executing the benchmarks with the full SPECint95 reference inputs, with a resulting execution of more than 500 billion PowerPC operations, or about 200 billion VLIW instructions, as can be discerned from the mean infinite cache pathlength reduction of 2.5. (The pathlength reduction is equal to the number of operations in the RS/6000 execution trace divided by the number of VLIW instructions in the VLIW execution trace.) The pathlength reduction can be viewed as an abstract measure of the infinite cache instruction level parallelism for the program.</p><p>The VLIW machine has primitives similar to the Pow-   erPC, but with 64 integer and floating point registers, rathor than 32 in PowerPC. Operation latencies are the same as in the PowerPC-604. A total of 8 operations (out ofwhich 4 can be memory accesses), and a total of 3 conditional branches (4-way branching) can be executed in each VLJW, which follows the tree instructionmodel. Efficient hardware implcmentations of the tree VLIW have been described elscwhcro (e.g. <ref type="bibr" target="#b4">[5]</ref>). The implemented incremental compilation algorithm is similar to the one discussed in this paper, although instead of generating binary VLIW code, an assembly level listing is produced. DAISY's performance was achieved at quite low cost, In the current experiments, DAISY required an average of 43 15 X/6000 instructions to compile each PowerPCinstruction. Furthermore, we found that DAISY comes within 20% of a more traditional static VLIW compiler [ 161 which implements a large number of sophisticated optimizations and takes approximately 100,000 instructions to compile each instruction. By way of comparison, the gee compiler cxccutes an average of 65,000 RS/6000 instructions to gencratc each machine instruction in its output. Finally, our implementation is a research prototype intended for flexible cxperimentation. We expect to reduce our translation overhead significantly with straightforward tuning, and further with an eventual rewrite of the incremental compiler, when the de- Code explosion statistics for the benchmarks are also in Table <ref type="table" target="#tab_0">1</ref>. The average code expansion per actually translated page is 16W4K = 4x (this is just the VLJW code size; empty wasted space on pages due to the 4x fixed expansion may lead to additional overhead, unless used for something else). We have placed little emphasis in our implementation on controlling code explosion and expect to reduce the explosion in future implementations. Notice that only the actually executed pages get translated, so code explosionmay be less than that of a static VLJW compiler that translates all pages of the executable.</p><p>Figure <ref type="figure" target="#fig_9">4</ref> indicates, for several small utilities 3, how the pathlength reduction changes with the number of resources available in the migrant VLJW machine. These benchmarks all achieved ILP around 2 for the most primitive machine, withcwide VLIW instructions, 2 ofwhose ops may be ALU operations, and 2 of which may be memory ops, with only 1 branch allowed per cycle. Performance diverges for a 24wide high end machine, with ILP of close to 5 achieved for f grep.</p><p>Another measure of interest is the number of crosspage branches executed. As discussed in Section 3.2 crosspage branches can be expensive, particularly in low-end imple-'Time constraintsdid not permit us to obtain the correspondingnumbers for SPECint95. . Notice that there is wide variety among the different benchmarks as to the fraction of instructions which are crosspage branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of Compiler Overhead</head><p>Table <ref type="table" target="#tab_1">3</ref> indicates the extra runtime of a two second program, due to dynamic compilation, assuming a VLIW machine running at 1 GHz and assuming that both the incremental compiler and the program have an average ILP of 4 instructions per cycle. Table <ref type="table" target="#tab_1">3</ref> was devised using a rough formula for relating the amount of reuse needed of each page (or instruction) in order to make a VLIW with an incremental compiler faster than the base architecture in executing a particular program. <ref type="bibr" target="#b5">[6]</ref>. By reuse, we mean the number of times each translated instruction executes.</p><p>Table <ref type="table">4</ref> gives an idea of the reuse factor for large programs such as those in the SPEC95 benchmark suite. Table <ref type="table">4</ref> indicates that they have very high reuse factors with a mean of over 500,000. The static code sizes were obtained on an RX/6000 using the installed C compiler. * .</p><p>A final example further supports the fact that dynamic compilation can be practical. Consider a worst case program that jumps from page to page, never repeating code. If the number of unique code pages executed is reasonable (say 200), the large percentage increase in time is probably imperceptible, as we expect only a millisecond will be required to translate each page. If the number of unique code pages is large, the overhead is likely to be dominated by the base architecture OS paging activity. Of course, thrashing due to a translated code area that is not large enough, will lead to extreme slowdown, and must be prevented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Previous Work</head><p>Virtual machine concepts have been used for many years, for example in IBM's VM operating systems <ref type="bibr" target="#b1">[2]</ref>, but virtual machines have so far implemented a virtual architecture on almost the same architecture (e.g. S/360 on S/370,8086 on 486, whereas in DAISY we support a very different virtual   <ref type="table">4</ref>: Reuse factors for SPEC95 benchmarks architecture on a VLIW. Caching emulators are commonly used for speeding up emulation. For example, each instruction is individually translated and the translation is cached for re-use when the instructionis emulated again <ref type="bibr">[lo]</ref>. However, in this approach, there is no sophisticated reordering, and thus no consequent difficult issues to deal with, for maintaining precise exceptions. We are also inspired by VLIW compiler research (e.g. the Moon-Ebcioglu compiler techniques [ 151 and Rau's work [ 1 S]), but in this paper we have proposed a new dynamic compilation algorithm that is much faster than existing VLIW compilation techniques, and which achieves good run-time performance.</p><p>Our initial page-based translation ideas were inspired by the workof Conte and Sathaye <ref type="bibr" target="#b3">[4]</ref> who proposed a translation at page fault time. However, their approach is intended for achieving object code compatibility between different gcnerations of the same family of VLIW machines, and is not intended for emulating an existing architecture. Contc and Sathaye's approach has a clever encoding which guarantees that the size of the code does not change during translation. However this guarantee does not hold for general virtual machine implementations. Dynamic translation by hardware to an internal VLIW-like representation at Icache miss time <ref type="bibr" target="#b8">[9,</ref><ref type="bibr">14,</ref><ref type="bibr">19</ref>, 171 achieves a similar purpose, but requires complex Icache miss processing hardware and more hardware design investment, and does not allow sophisticated compiler techniques that can be implemented in software, Static translation of executable modules such as FXl32, ws done in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr">231</ref>. However, static translation does not address the problem of achieving 100% compatibility with the old architecture, including operating system code, dcbuggers, device drivers, etc.. So, although there arc many influences to our line of thought, we believe that the combination of the ideas presented here constitute a new solution for an important compatibility problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have described DAISY, an approach for making VLI-W's and other novel architectures fully compatible with cxisting software for base architecture(s). DAISY achieves this without any special hardware for emulation. Our approach could be important in the future for making an ultimate open system, where a single hardware chip can run multiple operating systems and base architectures. It is only nccessaty that the chip be constructed with an appropriate supersct of the primitive operations of the multiple base arckitectures, e.g. x86, PowerPC, and S/390. A similar technique can be applied to aid migration to other new ILP architectures, that would otherwise break binary compatibility.</p><p>Although space constraints do not permit us to elaborate here, anovelty ofDAISY is that it affords a practical means to achieve oracle parallelism (at high compilation cost): the first time an entry point to a page is encountered, the instructions in the page starting at the entry point are interpreted and tho execution path revealed by the interpretation (say path A) is compiled into VLIW's, until a stopping point is encountered on path A. If the group is entered again, and it takes the same path A, performance will be high since it executes VLIW code solely. Further details may be found in <ref type="bibr" target="#b5">[6]</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>l</head><label></label><figDesc>Operations l-1 1 of the original PowerPC code are scheduled in sequence into VLIW's. It turns out that two VLIW's sufiIce for these 11 instructions, yielding an ILP of 4, 4, and 3.5 on the three possible paths through the code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>l</head><label></label><figDesc>The renaming scheme just described places results in the architected registers of the base architecture in original program order. Stores and other operations with ~__~U--..l.--~_^-------</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of conversion from PowerPC code to VLIW tree instructions. non-renameable destinations are placed at the end of the last VLIW on the current path. In this way, precise exceptions can be maintained. For example, assume an external interrupt occurs immediately after VLIWl finishes executing, and prior to the start of VLIW~. The interrupt handler is just an incrementally compiled version of the standard Pow-erPC interrupt handler. Hence it looks only at Pow-erPC architected registers. These registers appear as if instruction 2, bc has just completed execution and control is about to pass to instruction 3, sli. (The instruction address register is even set to the proper</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: VLIW Address Space Layout</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>LRA reg offset (tl)) ; Load ptr to real addr of VLIU code into lrl. (LOAD-REAL tl 0 (irl)) ; Goto VLIY code. Hake no valid entry CM (GOTO lrl)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Finding the base architecture instruction responsible for an exception</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Pathlengthreductions for Different Machine Configurations sign matures. As a rough guess, under 1000 base instructions per base instruction seems achievable for implementing our aggressive compiler techniques.Code explosion statistics for the benchmarks are also in Table1. The average code expansion per actually translated page is 16W4K = 4x (this is just the VLJW code size; empty wasted space on pages due to the 4x fixed expansion may lead to additional overhead, unless used for something else). We have placed little emphasis in our implementation on controlling code explosion and expect to reduce the explosion in future implementations. Notice that only the actually executed pages get translated, so code explosionmay be less than that of a static VLJW compiler that translates all pages of the executable.Figure4indicates, for several small utilities 3, how the pathlength reduction changes with the number of resources available in the migrant VLJW machine. These benchmarks all achieved ILP around 2 for the most primitive machine, withcwide VLIW instructions, 2 ofwhose ops may be ALU operations, and 2 of which may be memory ops, with only 1 branch allowed per cycle. Performance diverges for a 24wide high end machine, with ILP of close to 5 achieved for f grep.Another measure of interest is the number of crosspage branches executed. As discussed in Section 3.2 crosspage branches can be expensive, particularly in low-end imple-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Pathlength reductions and code explosion moving from PowerPC to VLJW.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Overhead of Dynamic Compilation mentations of the VLJW. Table 2 breaks down the number of crosspage branches in the seven benchmarks. PowerPC has 3 distinct types of crosspage branches: (1) direct branches, (2) branches via the Link Register, and (3) branches via the Counter Register</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Number of crosspage branches in different benchmarks.</figDesc><table><row><cell></cell><cell>Program k compress ?P go I= Wg ii</cell><cell cols="2">Branch Type Linkreg via k via 1149M 620M 949M 179M 31M 1072M 376M 1515M k II Counter (I Total ] Total Crosspage 1 Total VLIW's Exec / 1605M 1461M 2273M 416M 57M 3065M 840M 3603M</cell></row><row><cell>INTEGER go</cell><cell cols="2">T L 1 80.8 billion 1 135.852 1 1</cell><cell>594.764 ]</cell></row><row><cell cols="2">m88ksim I 74.3 billion 1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>84.520 I 879.081 1</head><label></label><figDesc></figDesc><table><row><cell>C' cl</cell><cell>34.1 billion</cell><cell>357,166</cell><cell>95,474</cell></row><row><cell>compress</cell><cell>46.4 billion</cell><cell>52,172</cell><cell>889,366</cell></row><row><cell>li</cell><cell>66.7 hillion</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>We thank Mark Charney, Tom Puzak, and Ravi Nair for these numbers and constructing the tools with which to obtain them.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We wish to thank the anonymous referees for their many useful suggestions. We also wish to thank Jaime Moreno, Mayan Moudgill, Arkady Polyak, and many of our other colleagues at IBM for their observations and discussion about this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Auslander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Philipose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename></persName>
		</author>
		<title level="m">Effective Dynamic Compilation, PLDI &apos;96</title>
		<meeting><address><addrLine>Bershad, Fast</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Evolution ofKrtual Machine Architecture National Computer Conference</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Buzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">O</forename><surname>Gagliardi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="291" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Shade: A Fast Instruction-Set Simulator for Execution P@iIing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Cmelik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keppel</surname></persName>
		</author>
		<idno>UWCSE 93-06-06</idno>
		<ptr target="http://s~.cs.nashington.edu/research/compiler/papers.d/shade.html" />
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>University of Washington Computer Science and Engineering Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename></persName>
		</author>
		<title level="m">Sathaye Dynamic Rescheduling: A Tecltnique for Object Code Compatibility in VLIW A&amp;itectures Proc. MICRO-28</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="208" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Some Design Ideas for a VLZWArchitecture for Sequential-Natured Software</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
		<ptr target="http://www.research.ibm.com/vliw" />
	</analytic>
	<monogr>
		<title level="m">Parallel Processing (Proceedings of IFIP WG 10.3 Working Conference on Parallel Processing</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Cosnard</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="3" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">DAISY: Compilation for 100% Architectural Compatibility</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Altman</surname></persName>
		</author>
		<idno>No. RC 20538</idno>
		<ptr target="http://www.watson.ibm.com" />
	</analytic>
	<monogr>
		<title level="j">IBM</title>
		<imprint>
			<biblScope unit="page">8080</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A JAVA ILP Machine Based on Fast Dynamic Compilation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hokenek</surname></persName>
		</author>
		<ptr target="http://www.watson.ibm.com" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of (IEEE MASCOTS) Intemational Workshop on Security and Efficiency Aspects of Java</title>
		<meeting>(IEEE MASCOTS) Intemational Workshop on Security and Efficiency Aspects of Java<address><addrLine>Eilat, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">January 9-10, 1997</date>
			<biblScope unit="page">8080</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Some Global Compiler Optimizations and Architectural Features for Improving the Pegormance of Superscalars</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Groves</surname></persName>
		</author>
		<idno>No. RC 16145</idno>
		<ptr target="http://www.research.ibm.com/vliw" />
	</analytic>
	<monogr>
		<title level="j">IBM</title>
		<imprint/>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smotherman</surname></persName>
		</author>
		<title level="m">A Fill-unit Approach to Multiple Instruction Issue Proc. MICRO-27</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Emulation: RISC&apos;S Secret Weapon BYTE</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Halfhill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-04">April 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">HWU VLIK Is It For Real This i&apos;?me? Keynote Speech in MICRO-27</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename></persName>
		</author>
		<ptr target="http://american.cs.ucdavis.edu/Micro27" />
	</analytic>
	<monogr>
		<title level="m">The foils are currently in</title>
		<imprint>
			<date type="published" when="1994-11">November 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">HPL PlayDoh Architecture Specification &amp;rsion 1.0</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kathail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlansker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Rau</surname></persName>
		</author>
		<idno>HPL-93-80</idno>
		<imprint>
			<date type="published" when="1994-02">Feb. 1994</date>
			<publisher>Technical Publications Department, 1501 Page Mill Road</publisher>
			<biblScope unit="volume">94304</biblScope>
			<pubPlace>Hewlett-Packard Laboratories; Palo Alto, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Mei</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Ramakrishna</forename><surname>Rau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micheal</forename><forename type="middle">S</forename><surname>Schlansker</surname></persName>
		</author>
		<title level="m">Sentinel Schedulingfor YZIW and Superscalar Processors, Proceedings of the Fifth Int&apos;l Conference on Architecture Support for Programming Languages and Operating Systems (ASPLOS-V)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-12-15">Oct. 12-15, 1992</date>
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hardware Support for Large Atomic Units in Dynamically Scheduled Machines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Melvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shebanow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2 1st Annual International Symposium on Microarchitecture</title>
		<meeting>the 2 1st Annual International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1988-12">December 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An E_fcient Resource-Constrained Global Scheduling Technique for Superscalar and VLZWProcessors</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICRO-25</title>
		<meeting>MICRO-25</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1992-12">December 1992</date>
			<biblScope unit="page" from="55" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Compiler/Architecture Interaction in a Tree-Based VLIWProcessor</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moudgill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polyak</surname></persName>
		</author>
		<ptr target="http://www.watson.ibm.com" />
		<imprint>
			<biblScope unit="page">8080</biblScope>
		</imprint>
	</monogr>
	<note>Report No. RC 20694, IBM</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ExpZoiting Instruction Level Parallelism in Processors by Caching Scheduled Groups</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hopkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual ACM/IEEE International Symposium on Computer Architecture</title>
		<meeting>the 24th Annual ACM/IEEE International Symposium on Computer Architecture<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">June 2-4, 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dynamically Scheduled VLZW Processors</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Rau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICRO-26</title>
		<meeting>MICRO-26</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1993-12">December 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Trace Cache: A Low Latency Approach to High Bandwidth Instruction Fetching</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Microarchitecture</title>
		<meeting>the 29th Annual International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1996-11">November 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Architectural Framework for Supporting Heterogeneous Instruction-Set Architectures</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Silbennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="39" to="56" />
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An Architectural Frameworkfor Migrationfrom CISC to Higher Pegormance Platforms</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1992 International Conference on Supercomputing</title>
		<meeting>1992 International Conference on Supercomputing</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="198" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Sites</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Binary Translation, CACM</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="69" to="81" />
			<date type="published" when="1993-02">Feb. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">ThompsonAn Alpha in PC ClothingBYTE</title>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1996-02">February 1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
