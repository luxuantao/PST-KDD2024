<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reporting Guidelines for Controlled Experiments in Software Engineering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Jedlitschka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Fraunhofer Institute for Experimental Software</orgName>
								<address>
									<addrLine>Engineering Fraunhofer-Platz 1</addrLine>
									<postCode>67663</postCode>
									<settlement>Kaiserslautern</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Dietmar</forename><surname>Pfahl</surname></persName>
							<email>dpfahl@ucalgary.ca</email>
							<affiliation key="aff1">
								<orgName type="department">Schulich School of Engineering ICT 540</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<addrLine>2500 University Dr. N.W</addrLine>
									<postCode>T2N 1N4</postCode>
									<settlement>Calgary, Alberta</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reporting Guidelines for Controlled Experiments in Software Engineering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C41D376C1C4C8D9ABAD621F5A008C6AD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>One major problem for integrating study results into a common body of knowledge is the heterogeneity of reporting styles: (1) It is difficult to locate relevant information and (2) important information is often missing. Reporting guidelines are expected to support a systematic, standardized presentation of empirical research, thus improving reporting in order to support readers in (1) finding the information they are looking for, (2) understanding how an experiment is conducted, and (3) assessing the validity of its results. The objective of this paper is to survey the most prominent published proposals for reporting guidelines, and to derive a unified standard that which can serve as a starting point for further discussion. We provide detailed guidance on the expected content of the sections and subsections for reporting a specific type of empirical studies, i.e., controlled experiments. Before the guidelines can be evaluated, feedback from the research community is required. For this purpose, we propose to adapt guideline development processes from other disciplines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In today's software development organizations, methods and tools are employed that frequently lack sufficient evidence regarding their suitability, limits, qualities, costs, and associated risks. In Communications of the ACM, Robert L. Glass <ref type="bibr" target="#b0">[1]</ref>, taking the standpoint of practitioners, asks for help from research: "Here's a message from software practitioners to software researchers: We (practitioners) need your help. We need some better advice on how and when to use methodologies." Therefore, he demands: • a taxonomy of available methodologies, based upon their strengths and weaknesses; • a taxonomy of the spectrum of problem domains, in terms of what practitioners need;</p><p>• a mapping of the first taxonomy to the second (or the second to the first). The evidence-based software engineering (EBSE) paradigm <ref type="bibr" target="#b1">[2]</ref> promises to solve parts of these issues by providing a framework for goal-oriented research, leading to a common body of knowledge (BoK) and, based on that, comprehensive problem-oriented decision support regarding SE technology selection.</p><p>One major problem for integrating study results into a common BoK is the heterogeneity of study reporting <ref type="bibr" target="#b3">[3]</ref>: <ref type="bibr" target="#b0">(1)</ref> It is difficult to find relevant information because the same type of information is located in different sections of different study reports; (2) important information is often missing -for example, context information is reported differently and without taking into account further generalizability.</p><p>One way to avoid heterogeneity is to introduce and establish reporting guidelines. More generally speaking, reporting guidelines are expected to support a systematic, standardized description of empirical research, thus improving reporting in order to support readers in <ref type="bibr" target="#b0">(1)</ref> finding the information they are looking for, <ref type="bibr" target="#b1">(2)</ref> understanding how an experiment is conducted, and (3) assessing the validity of its results. This claim is supported by the CONSORT statement <ref type="bibr" target="#b4">[4]</ref>.</p><p>As already identified by Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref>, reporting guidelines are necessary for all relevant kinds of empirical work, and they have to address the needs of different stakeholders (i.e., researchers and practitioners). The specific need for standardized reporting of controlled experiments has been mentioned by different authors, e.g., <ref type="bibr" target="#b3">[3]</ref>, <ref type="bibr" target="#b6">[6]</ref>, <ref type="bibr" target="#b7">[7]</ref>, <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr" target="#b9">[9]</ref>, <ref type="bibr" target="#b10">[10]</ref>, <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref>. At the same time, several reporting guidelines have been proposed, e.g., <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b5">[5]</ref>. Even though each of these proposals has its merits, none of these proposals has yet been accepted as a de-facto standard. Moreover, most of the existing guidelines are not explicitly tailored to the specific needs of certain types of empirical studies, e.g., controlled experiments (a comprehensive classification of empirical studies is given by Zelkowitz et al. <ref type="bibr" target="#b14">[14]</ref>). 0-7803-9508-5/05/$20.00 ©2005 IEEE.</p><p>The goal of this paper is to survey the most prominent published proposals for reporting guidelines, and to derive a unified and -where necessary -enhanced standard, which can serve as a starting point for further discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Empirical software engineering research is not the first area encountering problems with regard to extracting crucial information from empirical research and to insufficient reporting. Other disciplines, such as medicine and psychology, have experienced similar problems before and have achieved various improvements by standardizing and instantiating reporting guidelines, e.g., for randomized controlled trials in biomedical research <ref type="bibr" target="#b4">[4]</ref>, <ref type="bibr" target="#b15">[15]</ref>, clinical practice guidelines <ref type="bibr" target="#b16">[16]</ref>, and empirical results from psychological research <ref type="bibr" target="#b17">[17]</ref>.</p><p>In the field of software engineering (SE) research, in 1999, Singer <ref type="bibr" target="#b13">[13]</ref> described how to use the "American Psychological Association (APA) Styleguide" <ref type="bibr" target="#b17">[17]</ref> for publishing experimental results in SE. In 2001, Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref> provided initial guidelines on how to perform, report, and collate results of empirical studies in SE based on medical guidelines as well as on the personal experience of the authors. In 2003, Shaw <ref type="bibr" target="#b18">[18]</ref> provided a tutorial on how to write scientific papers, including the presentation of empirical research as a special case. Additionally, standard text books on empirical SE, such as Wohlin et al. <ref type="bibr" target="#b19">[19]</ref> and Juristo et al. <ref type="bibr" target="#b20">[20]</ref>, address the issue of reporting guidelines. Wohlin et al. suggest an outline for reporting the results of empirical work. Juristo et al. provide a list of "most important points to be documented for each phase" in the form of "questions to be answered by the experimental documentation".</p><p>Table <ref type="table" target="#tab_0">1</ref> gives a characterization of the existing proposals for guidelines on reporting empirical work in SE. The first row of the table lists the proposals, arranged with regard to their publication date. The last column of the table contains our proposal of a unifying and enhanced reporting guideline. The second row of the Otherwise, the specific type is explicitly mentioned, e.g., "Controlled Experiment" or "Systematic Review". The third row describes the phases of an experiment covered by the guideline. The entry "All" indicates that the guideline covers all phases of the type of study in focus.</p><p>The remaining rows list the structuring elements as they are mentioned in the proposed guidelines and map them to the structure of our proposal (last column). Elements of existing proposals occurring twice in a column indicate that disjoint parts of these elements can be mapped to two different elements of our new proposal. An asterix (*) indicates that the authors do not explicitly mention or describe details for this element, but it is assumed that the elements are implicitly required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Guideline for Controlled Experiments</head><p>Our work started with the collection and integration of existing guidelines. As indicated in Table </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Structured Abstract</head><p>The need for an abstract is beyond any question. It is an important source of information for any reader, as it briefly summarizes the main points of the study and, moreover, often is the only part of a publication that is freely accessible <ref type="bibr" target="#b21">[21]</ref>. The exact form of the abstract needs more discussion. For example, Shaw found that there is a common structure for the clearest abstracts consisting of the following elements: (a) the current state of the art, identifying a particular problem, (b) the contribution to improving the situation, (c) the specific result and the main idea behind it, and (d) how the result is demonstrated or defended <ref type="bibr" target="#b18">[18]</ref>. In other disciplines, e.g., medicine and psychology, a special form of the abstract, the so-called structured abstract <ref type="bibr" target="#b27">[27]</ref>, has been imposed on authors by a huge number of journals in order to improve the clarity of abstracts. The most common elements of structured abstracts are Background or Context, Objective or Aim, Method, Results, and Conclusion.</p><p>Inspired by the lessons learned from medicine, we suggest using a structured abstract consisting of the elements listed below: Background: Give a brief introducing notice about the motivation for conducting the study. Example: "Software developers have a plethora of development technologies from which to choose, but often little guidance for making the decision" <ref type="bibr" target="#b16">[16]</ref>.</p><p>Objective: Describe the aim of the study, including the object under examination, the focus, and the perspective. Example: "We examined &lt;technique1&gt; vs. &lt;technique2&gt; with regard to fault detection rates from the viewpoint of a quality engineer".</p><p>Method: Describe which research method was used to examine the object (e.g., experimental design, number and kind of participants, selection criteria, data collection and analysis procedures). Example: "We used a 2x2 factorial design with 24 randomly assigned undergraduate students participating. The data were collected with the help of questionnaires and analyzed using ANOVA".</p><p>Results: Describe the main findings. Example: "&lt;technique1&gt; was significantly more effective than &lt;technique2&gt; at an alpha level of 0.05".</p><p>Limitations: Describe the principal limitations of the research. Example: "Generalization of results is limited due to the fact that undergraduate students participated in the study".</p><p>Conclusion: Describe the impact of the results. Example: "The result reinforced existing evidence regarding the superiority of &lt;technique1&gt; over &lt;technique2&gt;".</p><p>The inclusion of the element Limitations follows a suggestion made in <ref type="bibr" target="#b23">[23]</ref>, since every piece of evidence has its limitations. This additional information will help readers judge transferability of the results to their own context. It will also help to prevent uncritical acceptance by the reader <ref type="bibr" target="#b23">[23]</ref>.</p><p>It is important to use only a few sentences for each structuring element of the abstract. Hartley <ref type="bibr" target="#b24">[24]</ref> found that the number of words will increase by about 30%. But he claims that these "extra costs" will pay back because, with the additional, valuable information given in the abstract, a wider readership might be encouraged and increasing citation rates will improve (journal) impact factors. Several researchers who compared structured abstracts with traditional ones found advantages with regard to the information, but no real disadvantages <ref type="bibr" target="#b25">[25]</ref>, <ref type="bibr" target="#b21">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Motivation</head><p>The purpose of the motivation section is to set the scope of the work and to give the potential reader good reasons for reading the remainder of the publication. The survey of existing guidelines shows variations with regard to the content of this section. In most cases, this section starts with a broader introduction to the research area <ref type="bibr" target="#b19">[19]</ref>.</p><p>We suggest subsections for the Problem Statement, the Research Objectives, and the description of the Context of the research.</p><p>With the exception of Wohlin et al. <ref type="bibr" target="#b19">[19]</ref>, who demand a special section to describe the problem under study, most of the proposed guidelines include the description of the problem within a more comprehensive section, often labeled "Introduction". Our proposal tries to capitalize on the advantages of these alternatives. On the one hand, we recognize the importance of the problem statement by highlighting the topic by means of an explicit subsection. On the other hand, by including the problem statement in the motivation section, fast readers will not risk missing this important information.</p><p>Following the suggestions of Wohlin et al. <ref type="bibr" target="#b19">[19]</ref> and Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref>, we suggest to explicitly describe the context of the study. While Wohlin et al. describe the context as part of the experimental planning, we decided to encapsulate this topic in a separate subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Problem Statement</head><p>The problem statement is important because it supports the readers in comparing their problems with the problem investigated in the reported experiment. In addition, this section helps to judge the relevance of the research. In general, we would expect answers to the questions: What is the problem? Where does it occur? Who has observed it? Why is it important to be solved? The problem statement should end with a brief description of the solution idea and the (expected) benefits of this solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Research Objectives</head><p>With regard to the research objective, or, as Wohlin et al. called it, the "Definition of the Experiment", the description should follow the goal template of the Goal/Question/Metric (GQM) method <ref type="bibr" target="#b18">[18]</ref>:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyze &lt;Object(s) of study&gt; for the purpose of &lt;purpose&gt; with respect to their &lt;Quality Focus&gt; from the point of view of the &lt;Perspective&gt; in the context of &lt;context&gt;.</head><p>For examples of the use of the goal definition template, see <ref type="bibr" target="#b28">[28]</ref> or <ref type="bibr" target="#b19">[19]</ref>. The common use of this formalized format would increase the comparability of research objectives, e.g., for the purpose of systematic reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Context</head><p>Similar to the CONSORT Statement <ref type="bibr" target="#b0">[1]</ref>, our Context subsection requests that the setting and locations of a study have to be described. The author should provide information that will help the readers understand whether the research relates to their specific situations. After having executed the experiment, the context is needed to evaluate external validity, i.e., transferability of results from one context to another. The context consists of all particular factors (e.g., application domain, type of company, experience of the participants, time constraints, process, tools, and size of project) that might affect the generality and utility of the conclusions.</p><p>It is sufficient to describe the context factors informally within the Context subsection. A precise (formal) definition will be given later on in the section Experimental Design (cf. Section 3.4.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Related Work</head><p>Published guidelines state the importance of clarifying how the work to be reported relates to existing work. Researchers as well as practitioners need to get fast access to related work, because it facilitates drawing a landscape of alternative approaches and relations between different experiments <ref type="bibr" target="#b6">[6]</ref>.</p><p>There is no common consensus on where this section fits best. In contrast to Singer <ref type="bibr" target="#b13">[13]</ref>, Juristo et al. <ref type="bibr" target="#b20">[20]</ref>, Wohlin et al. <ref type="bibr" target="#b19">[19]</ref>, and Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref>, we suggest presenting related work as a special section. This section should consist of: Description of the Investigated Technology (or tool, method), Description of Alternative Solutions, and Related Experiments.</p><p>In most cases the technology and the alternatives to be described here will be the levels in the experiment. For example, if one intends to compare two reading techniques, descriptions would have to be provided with regard to the research objectives. The detail of the description depends on the availability of earlier publications. With regard to the content of the description, it is most important that all identifying characteristics are provided; for example, for each level used in the study (e.g., reading techniques in inspection experiments), a description of the pre-and postconditions for the application is needed. Pre-conditions describe what is necessary to apply the technique, whereas post-conditions describe the (expected) effects. Shaw <ref type="bibr" target="#b18">[18]</ref> demands that the related work should not only be a simple list of experiments but an objective description of the main findings relevant to the work at hand.</p><p>Especially in the case of an experiment that compares different approaches, it is crucial to objectively describe the alternative approaches. Additionally, other alternatives might be mentioned. If available, existing evidence, in the form of earlier experiments, should be described. The relation to alternative approaches and other experiments (existing evidence) in the field will help to arrange this work in a larger context and supports reuse of this study for replication or systematic review, improving the value of the research and providing a sound basis for this work.</p><p>In case the reported study is a replication, the parental study and its findings also have to be described. This will help the reader follow the comparison of the findings. Appropriate citation is absolutely mandatory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experimental Design</head><p>This section should describe the outcome of the experiment planning phase. It is important because, as Singer stated, this section is the "receipt for the experiment" <ref type="bibr" target="#b13">[13]</ref>. It should provide all information that is necessary to replicate the study or to integrate it in the BoK. In addition, it allows readers to evaluate the internal validity of the study, which is an important selection criterion for systematic review or meta-analysis <ref type="bibr" target="#b21">[21]</ref>, <ref type="bibr" target="#b5">[5]</ref>.</p><p>We suggest subsections for the formulation of the Goals, Hypotheses, Parameters, and Variables, the Design, the Subjects, the Objects, the Instrumentation, the Data Collection Procedure, the Analysis Procedure, as well as the subsection Evaluation of the Validity. The format of the Experimental Design section is inspired by the structure of the "Experiment Planning" phase suggested by Wohlin et al. <ref type="bibr" target="#b19">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Goals, Hypotheses, Parameters, and Variables</head><p>In this subsection the research objective should be refined, e.g., with regard to the facets of the quality focus, if different aspects of the quality focus are of interest ([28] can serve as an example). Regarding the naming of the types of variables, we follow Juristo et al. <ref type="bibr" target="#b20">[20]</ref>.</p><p>For each goal the null hypotheses, denoted H 0ij , and its corresponding alternative hypotheses, denoted H 1ij , need to be derived, where i corresponds to the goal identifier, and j is a counter in the case that more than one hypothesis is formulated per goal. The description of both null and alternative hypotheses should be as formal as possible.</p><p>The context of an experiment needs to be described by listing parameters that represent characteristics that are invariable throughout the conduct of experiment and do not influence the results of the experiment. A precise description of the context via measurable parameters is essential, because the results yielded by the experiment will be true locally for the conditions reflected in the parameters.</p><p>There are two types of variables that need to be described: response variables (aka. dependent variables) and factors (aka. independent variables or predictor variables). Response variables should be defined and related measures should be justified in terms of their relevance to the goals listed in the section Research Objectives. For each factor, its corresponding levels (aka. alternatives, treatments) have to be specified in measurable form.</p><p>For the definition of measures, we follow Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref> who suggest using as many standard measures as possible. Besides approaches to obtain the respective measures such as GQM <ref type="bibr" target="#b18">[18]</ref> and a conceptual Entity-Relationship model proposed by Kitchenham et al. <ref type="bibr" target="#b29">[29]</ref>, no common taxonomy for measures is available yet, although the need has been reported by different authors. A first set of candidate attributes and metrics is presented in Juristo et al. <ref type="bibr" target="#b20">[20]</ref>. More specialized sets are available for the field of defect reduction <ref type="bibr" target="#b6">[6]</ref>, <ref type="bibr" target="#b9">[9]</ref>, <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref> and maintenance <ref type="bibr" target="#b30">[30]</ref>.</p><p>Nevertheless, experimenters should be aware of the measurement issue and define their measures carefully. In particular, if a standardized set of metrics is available, authors have to explain which of them are used, not used, or why new ones have been introduced. If existing measures are tailored, the need for the tailoring and the tailored variable have to be described. Based on Juristo et al. <ref type="bibr" target="#b20">[20]</ref>, Wohlin et al. <ref type="bibr" target="#b19">[19]</ref>, and Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref>, Table <ref type="table" target="#tab_2">2</ref> gives a schema for the description of variables.</p><p>For subjective measures Kitchenham et al. request that a measure of inter-rater agreements is presented, such as the kappa statistics or the intra-class correlation coefficient for continuous measure <ref type="bibr" target="#b5">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Experiment Design</head><p>The hypothesis and the variables influence the choice of the experimental design. In the Experiment Design subsection the selection of the specific design has to be described. This selection is supported by further selection criteria (e.g., randomization, blocking, and balancing). Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref> propose selecting a design that has been fully analyzed in the literature. If such a design is not appropriate, authors are recommended to consult a statistician. In this case, more details about the background of the design are needed. Descriptions of design types can be obtained from Wohlin et al. <ref type="bibr" target="#b19">[19]</ref> and Juristo et al. <ref type="bibr" target="#b20">[20]</ref>.</p><p>Wohlin et al. stress that "it is important to try to use a simple design and try to make the best possible use of the Type of attribute (internal, external) <ref type="bibr" target="#b19">[19]</ref>, <ref type="bibr" target="#b20">[20]</ref> Scale type (nominal, ordinal …) <ref type="bibr" target="#b29">[29]</ref> Unit <ref type="bibr" target="#b29">[29]</ref> Range or, for nominal and restricted ordinal scales, the definition of each scale point. <ref type="bibr" target="#b29">[29]</ref> Counting rule in the context of the entity <ref type="bibr" target="#b29">[29]</ref> available subjects". This point is also referred by Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref>, who point out that in many SE experiments, the selected design is complex, and the analysis method is inappropriate for coping with it. Moreover, authors should describe how the subjects and objects are assigned to levels (treatments) in an unbiased manner <ref type="bibr" target="#b5">[5]</ref>. If any kind of blinding has been used, the details need to be provided; this applies to the execution and the analysis. In case the experiment is a replication, the adjustments and their rationales need to be discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Subjects</head><p>In this subsection, information on the sampling strategy (how the sample will be selected), on the population from which the sample is drawn, and on the planned sample size should be provided. As Singer states, all important subject-related characteristics have to be provided <ref type="bibr" target="#b13">[13]</ref>. These characteristics can be understood as restrictions to the sample. For instance, if a certain level of experience is required, the sample might be drawn from fourth-term computer science students. A description of the motivation for the subjects to participate is mandatory. For instance, it should be stated whether the participants will be paid for taking part in the experiment, or whether they will earn educational credits.</p><p>In empirical SE, many experiments are performed involving human subjects. If this is the case, it is more convenient to talk about participants <ref type="bibr" target="#b13">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4">Objects</head><p>In this subsection, the objects used in the experiment, for example the document used for the application of the reading technique (length, complexity …), and faults (number, type, interactions …) should be presented. As stated above, all characteristics that might have an impact on the results should be mentioned here as formally as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.5">Instrumentation</head><p>In this subsection, information about the instrumentation that might have an impact on the results should be provided. There are two types of instruments: guidelines and measurement instruments (e.g., questionnaires, data collection tools). It is also important to describe which kind of training, if any, the participants will get.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.6">Data Collection Procedure</head><p>In this subsection, the schedule of the experiment as well as the timing for each run of the experiment has to be provided. Furthermore, details of the collection method have to be described. Examples vary from manual collection by the participants to automatic collection by tools. It is important to describe where (e.g., in which phase of the process) the data will be collected, by whom, and with what kind of support (e.g., tool). This is also in accordance with Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref>, who state that the data collection process describes the "who?", the "when?", and the "how?" of any data collection activity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.7">Analysis Procedure</head><p>Since the analysis depends on the design, the mathematical analysis model should be presented in this subsection. If different goals are investigated, information for each goal needs to be provided separately. If any additional influences are expected, their analysis needs to be described, too (e.g., see Ciolkowski et al. <ref type="bibr" target="#b28">[28]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.8">Validity Evaluation</head><p>In this subsection it has to be described whether any particular steps will be taken to increase the reliability of the measurements, meaning that the data is reasonable and that complete and appropriate (correct) collection of data is ensured <ref type="bibr" target="#b5">[5]</ref>, <ref type="bibr" target="#b19">[19]</ref>. Actions that could be taken in advance could be, for instance, specific training, double checks, and automatic measurements; if any actions are planned, they have to be described, too.</p><p>A description of the validity of the materials used during the study and the conformance of the participants, e.g., how it is ensured that the participants will follow the guidelines <ref type="bibr" target="#b20">[20]</ref>, is necessary. In addition, actions established to improve the reliability and validity of data collection methods or tools have to be described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Execution</head><p>According to Singer <ref type="bibr" target="#b13">[13]</ref>, the purpose of this section is to describe "each step in the production of the research". From our perspective, execution describes how the experimental plan (design) was enacted. So, besides the who and the when, the specific instantiations of the sampling, randomization, instrumentation, apparatus, execution, data collection, and validation have to be described. The most important point is to describe whether any deviations from the plan occurred and how they were treated.</p><p>We suggest structuring the Execution section into the following subsections: Sample, Preparation, Data Collection Performed, and Validity Procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Sample</head><p>In this subsection, the instantiation of the sampling strategy and the resulting sample needs to be described, including number of participants, kind of participants (e.g., computer science students), and all characteristics that might have an effect on the results, e.g., experience (with regard to the techniques to be applied) and educational level. Additionally, the answers to the following questions are of interest <ref type="bibr" target="#b19">[19]</ref>: How the participants committed? How was consent obtained? How was confidentiality assured? How was participation motivated (induced)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Preparation</head><p>In this subsection, it has to be described how the experimental groups were formed, how the randomization was performed, what kind of training, if any, was provided to the participants, and how long the training took.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.3">Data Collection Performed</head><p>The purpose of this subsection is to describe how the collection process was followed and, if any deviations occurred, how they were solved. The general schedule of the experiment needs to be described as well as how much time the participants were given to run the experiment. Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref> demand information about subjects who drop out from the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.4">Validity Procedure</head><p>The purpose of this subsection is to describe how the validity process was followed and, if any deviations occurred, how they were solved. A description of what kind of actions were taken and what their effect was is necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Analysis</head><p>According to Singer <ref type="bibr" target="#b13">[13]</ref>, the Analysis section summarizes the data collected and the treatment of the data. The most important points for this section are: (1) It is not allowed to interpret the results <ref type="bibr" target="#b13">[13]</ref> and (2) data should be analyzed in accordance with the design <ref type="bibr" target="#b5">[5]</ref>. If multiple goals were investigated, separate analysis subsections and an overlap analysis are required. Since the analysis procedures are already described in the design section, the purpose of this section is to describe the application of the analysis methods to the data collection. If any deviations from the plan occur, they have to be discussed here, e.g., in case no statistically significant results were found, it is necessary to describe what was done to cope with this circumstance.</p><p>We suggest structuring the Analysis section into the following subsections: Descriptive Statistics, Data Set Reduction, and Hypothesis Testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1">Descriptive Statistics</head><p>The purpose of this subsection is to present the collected data with the help of appropriate descriptive statistics, including number of observations, measures for central tendency, and dispersion. Mean, median, and mode are example measures for central tendency. Standard deviation, variance, and range, as well as interval of variation and frequency are example measures for dispersion. To facilitate meta-analysis, it is highly recommended to provide raw data in the appendices (cf. Section 3.11).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2">Data Set Reduction</head><p>In this subsection the reduction of the data set as a consequence of the descriptive statistics should be discussed, i.e., the removal of outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.3">Hypothesis Testing</head><p>In this subsection, it has to be described how the data was evaluated and how the analysis model was validated. Special emphasis should be placed on constraints that would hinder the application of a planned analysis method (e.g., normality, independence, and residuals). Any resulting deviations with regard to the hypothesis test from the original plan (e.g., a different test was used because of data set constraints) should be described. Moreover, it has to be described which methods were used to determine statistical significance.</p><p>To understand the interpretation and conclusion based on the analysis, it is important to present inferential statistics. Singer <ref type="bibr" target="#b13">[13]</ref> demands that "inferential statistics are reported with the value of the test, the probability level, the degrees of freedom, the direction of effect", and the power of the test. More precisely, the p-value, alphavalue, and confidence interval for each finding has to be presented. For each hypothesis, quantitative results should be presented. If a null hypothesis is rejected, it has to be described on which significance level. Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref> present a checklist for reporting inferential results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Interpretation</head><p>The purpose of this section is to interpret the findings from the analysis presented in the previous section. This includes an overview of the results, threats to validity, generalization (where are the results applicable?), as well as the (potential) impact on cost, time, and quality. We suggest structuring the Interpretation section into the following subsections: Evaluation of Results and Implications, Limitations of the Study, Inferences, and Lessons Learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.1">Evaluation of Results and Implications</head><p>In this subsection, the results should be explained. In case it was not possible to reject the null hypotheses, assumptions about the reasons why this happened should be given. Also, any other unexpected result should be described in this subsection. Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref> point out that it is important to distinguish between statistical significance and practical importance. The theoretical implications of the findings should be described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.2">Limitations of the Study</head><p>As already mentioned in the Experimental Design section, all threats that might have an impact on the validity of the results as such (threats to internal validity, e.g., confounding variables, bias), and, furthermore, on the extent to which the hypothesis captures the objectives and the generalizability of the findings (threats to external validity, e.g., participants, materials) have to be discussed in this subsection. According to Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref>, it is not enough to mention that a threat exists; it also has to be discussed what the implications are. A classification of threats to validity is given, e.g., in Wohlin et al. <ref type="bibr" target="#b19">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.3">Inferences</head><p>The purpose of this subsection is to describe inferences drawn from the data to more general conditions. This has to be done carefully, based on the findings and the limitations. This care includes the definition of the population to which inferential statistics and predictive models apply. This subsection is also the place to describe how and where the results can be used (generalization).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.4">Lessons Learned</head><p>In this subsection, it has to be described which experience was collected during the course of the experiment, i.e., during design, execution analysis. The purpose is to describe what went well and what did not. If the reasons for interesting observations are known, they can be described in this subsection, too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Conclusions and Future Work</head><p>This section presents a summary of the study. We suggest structuring the Conclusion and Future Work section into the following subsections: Relation to Existing Evidence, Impact, Limitations, and Future Work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.1">Relation to Existing Evidence</head><p>This subsection is the place where the relation of the results to earlier experiments, especially those mentioned in the Related Work section, has to be provided. The contribution of the study should be discussed here. Kitchenham et al. <ref type="bibr" target="#b5">[5]</ref> point out that it is important to (1) ensure that conclusions follow from the results and (2) differentiate between the results of the analysis and the conclusions drawn by the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.2">Impact</head><p>To enable readers to get the most important findings, we emphasize a description of the impact on cost, time, and quality.</p><p>Impact on Cost: What effort was necessary to introduce and perform the technique (e.g., what are the costs of detecting a defect of a certain type with this technique? Is there any impact on the cost of other steps of the development process, positive or negative ones (e.g., reduced cost for rework)?)</p><p>Impact on Time: Is there any positive or negative impact on the time of other steps of the development process?</p><p>Impact on Quality: Is there any impact on the quality of the product and the products of other steps?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.3">Limitations</head><p>In this subsection, principal limitations of the approach have to be described, i.e., circumstances under which the approach presumably will not yield the expected benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.4">Future Work</head><p>In this subsection, it has to be described what other experiments could be run to further investigate the results yielded or evolve the BoK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9">Acknowledgements</head><p>In this section sponsors, participants, and contributors who do not fulfill the requirements for authorship should be mentioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.10">References</head><p>In this section, all cited literature has to be presented in the format requested by the publisher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.11">Appendices</head><p>In this section, material, raw data, and detailed analyses that might be helpful for others to build upon the reported work should be provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion and Future Work</head><p>The contribution of this paper is a (preliminary) proposal of a standardized reporting guideline that unifies the most prominent existing guidelines published by various authors (cf. Table <ref type="table" target="#tab_0">1</ref>). In addition to providing a uniform structure of a reporting template, we have tried to provide detailed guidance on how to fill in the various sections and subsections of this template for a specific type of empirical studies, i.e., controlled experiments. In some places, for instance for the definition of variables, we suggest a prescriptive formalization schema.</p><p>Our proposal has not yet been evaluated, e.g., through a peer review by stakeholders, or by applying it to a significant number of controlled experiments to check its usability. In order to assess the benefits and challenges of the proposed guidelines, it is necessary to use them in two ways: <ref type="bibr" target="#b0">(1)</ref> to describe new experiments and (2) to rewrite already published experiments. The first approach, preferably performed by different research groups to reduce expectation bias, leads to feedback with regard to the applicability that will be based on the experience of the very authors. The second approach can be used to compare the availability and accessibility of information between the two descriptions. The prerequisite is the general availability of information with regard to the specific experiment. We are aware that this proposal can only be a first step towards a standardized reporting guideline.</p><p>The experience of the last 6 years, since the first publication of a reporting guideline for empirical SE research by Singer in 1999 <ref type="bibr" target="#b13">[13]</ref>, leads us to conclude that significant effort needs to be invested to make sure that guidelines are widely accepted. This is also what other communities have already learned <ref type="bibr" target="#b14">[14]</ref>. We propose adopting some of their measures to enact reporting guidelines within the SE community. For example, we believe the SE community needs an organization that is able to achieve sufficient consent on the guidelines and that is able to establish the guidelines in review boards for journals, conferences, etc.</p><p>At this point in time, the discussion with regard to reporting guidelines has just started. The involvement of different stakeholders is crucial for success. To address this aim, we have set up an initial working group, consisting of eight researchers from five countries, who have committed themselves to the task of defining and disseminating guidelines. The first step on that path was to identify which types of guidelines are needed, and to define the goal for each type of guideline. As the main objective we have identified the further use of empirical reports, namely the aggregation of empirical results from single studies. This objective is supported by different authors who have tried to aggregate single findings into more generic knowledge, e.g., <ref type="bibr" target="#b3">[3]</ref>, <ref type="bibr" target="#b9">[9]</ref>, <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref>.</p><p>The working group collected a set of existing guidelines, including those from other disciplines. The authors have committed to refining guidelines for controlled experiments.</p><p>One important issue related to defining guidelines is to evaluate and ensure the quality of the proposed guidelines as well as to further evolve them. This will be done by reporting studies, preferably performed by different research groups to reduce bias (to overcome expectation biases, it is important in this phase that the guidelines are used by volunteering authors who were not involved in the definition), following the guidelines and trials to perform a systematic review <ref type="bibr" target="#b21">[21]</ref> (as a specific form of aggregation). The systematic reviews should be done by groups of experts in the specific field. We will then qualitatively compare the ease of extracting relevant information from the report following the guidelines with the attempts we made before with study reports that do not follow the guideline. Further needs that might not be foreseen today may require evolution of the guidelines.</p><p>An important issue related to the dissemination task is to ensure that the guidelines are used in research practice. One possibility to enforce the usage of reporting guidelines could be that program committees of SE workshops and conferences as well as editorial boards of SE journals make the application of a standard reporting scheme mandatory.</p><p>To facilitate the adoption of the guidelines, it would help to stress that a researcher can benefit from applying them. For example, one benefit could be that the integration into the BoK will be easier if studies are reported using the guidelines. We also assume that, generally, the SE publication process will become more efficient, since crucial information will be found by reviewers (and other researchers) in the same place every time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Characterization of different Guidelines for empirical SE</head><label>1</label><figDesc></figDesc><table><row><cell>Singer [13]</cell><cell cols="3">Wohlin et al. [19] Kitchenham et al.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>[5]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Introduction Experiment</cell><cell>and</cell><cell>Execution Experiment</cell><cell>Excluded Studies Included</cell><cell>and</cell><cell>Execution</cell></row><row><cell></cell><cell></cell><cell>Data Collection</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Results</cell><cell>Data Analysis</cell><cell>Analysis</cell><cell></cell><cell>Experimental</cell><cell>Results</cell><cell></cell><cell>Analysis</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Analysis</cell><cell></cell><cell></cell></row><row><cell>Discussion</cell><cell>Interpretation of</cell><cell>Interpretation</cell><cell>of</cell><cell>Experimental</cell><cell>Discussion</cell><cell></cell><cell>Interpretation</cell></row><row><cell></cell><cell>Results</cell><cell>Results</cell><cell></cell><cell>Analysis</cell><cell></cell><cell></cell></row><row><cell>Discussion</cell><cell>Discussion and</cell><cell>*</cell><cell></cell><cell>Experimental</cell><cell>Conclusion</cell><cell></cell><cell>Discussion</cell><cell>and</cell></row><row><cell></cell><cell>Conclusion</cell><cell></cell><cell></cell><cell>Analysis</cell><cell></cell><cell></cell><cell>Conclusions</cell></row><row><cell></cell><cell>Discussion and</cell><cell>*</cell><cell></cell><cell>Experimental</cell><cell></cell><cell></cell><cell>Future Work</cell></row><row><cell></cell><cell>Conclusion</cell><cell></cell><cell></cell><cell>Analysis</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 . Schema for the description of variables</head><label>2</label><figDesc></figDesc><table><row><cell>Name of</cell><cell>Abbreviation Class (product,</cell><cell>Entity</cell></row><row><cell>the</cell><cell>process,</cell><cell>(instance</cell></row><row><cell>variable</cell><cell>resource,</cell><cell>of the</cell></row><row><cell></cell><cell>method)</cell><cell>class)</cell></row><row><cell></cell><cell>[19],[20]</cell><cell>[20]</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Conflict of Interest Acknowledgements References References * * References References Structure Appendices Appendix</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Marcus Ciolkowski, Reidar Conradi, Tore Dybå, Natalia Juristo, Barbara Kitchenham, Dieter Rombach, Janice Singer, Sira Vegas, Claes Wohlin, and many others for fruitful discussions, and the anonymous reviewers for giving valuable feedback, thus helping to improve the paper. Furthermore, we are grateful to Sonnhild Namingha from the Fraunhofer Institute for Experimental Software Engineering for reviewing a previous version of this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices Appendices</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Matching Methodology to Problem Domain</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Column Practical Programmer in Communications of the ACM</title>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="19" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evidencebased Software Engineering</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dybå</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jørgensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 26th Intern. Conf. on Software Engineering (ICSE&apos;04)</title>
		<meeting>of 26th Intern. Conf. on Software Engineering (ICSE&apos;04)</meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Scotland</forename><surname>Edinburgh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">United</forename><surname>Kingdom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="273" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards Evidence in Software Engineering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jedlitschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ciolkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/IEEE Intern. Symposium on Software Engineering 2004 (ISESE2004)</title>
		<meeting>of ACM/IEEE Intern. Symposium on Software Engineering 2004 (ISESE2004)<address><addrLine>Redondo Beach, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">August 2004. 2004</date>
			<biblScope unit="page" from="261" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Davidoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Elbourne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Gøtzsche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><surname>Group</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Revised CONSORT Statement for Reporting Randomized Trials: Explanation and Elaboration</title>
		<imprint>
			<date type="published" when="2001-04">April 2001</date>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="663" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Preliminary guidelines for empirical research in software engineering</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Pfleeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Pickard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Hoaglin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>El Emam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="721" to="734" />
			<date type="published" when="2002-08">Aug 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards a Comprehensive Summarization of Empirical Studies in Defect Reduction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jedlitschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ciolkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Posters and Fast Abstract Sessions</title>
		<meeting><address><addrLine>Redondo Beach, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">2004. August 2004</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="5" to="6" />
		</imprint>
	</monogr>
	<note>Proc. of ISESE</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Repeatable software engineering experiments for comparing defect-detection techniques</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Rombach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="241" to="277" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining empirical results in software engineering</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Pickard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="811" to="821" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Prospects and Limitations for Cross-Study Analyses -A Study on an Experiment Series</title>
		<author>
			<persName><forename type="first">P</forename><surname>Runeson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Future of Empirical Studies in Software Engineering, Proc. of 2nd Int. Workshop on Empirical Software Engineering, WSESE 2003</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Jedlitschka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ciolkowski</surname></persName>
		</editor>
		<meeting><address><addrLine>Roman Castles, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Fraunhofer IRB Verlag</publisher>
			<date type="published" when="2003">Sept. 2003. 2004</date>
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Shull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Travassos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Maldonado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Conradi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Basili</surname></persName>
		</author>
		<title level="m">Replicated Studies: Building a Body of Knowledge about Software Reading Techniques</title>
		<imprint>
			<biblScope unit="page" from="39" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Process for Identifying Relevant Information for a Repository: A Case Study for Testing Techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Juristo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Managing Software Engineering Knowledge</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Aurum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Jeffery</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Handzic</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="199" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Combining Data from reading Experiments in Software Inspections</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aurum</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="85" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using the American Psychological Association (APA) Style Guidelines to Report Experimental Results</title>
		<author>
			<persName><forename type="first">J</forename><surname>Singer</surname></persName>
		</author>
		<ptr target="dec.bmth.ac.uk/ESERG/WESS99/singer.ps" />
	</analytic>
	<monogr>
		<title level="m">Proc. of Workshop on Empirical Studies in Software Maintenance</title>
		<meeting>of Workshop on Empirical Studies in Software Maintenance<address><addrLine>Oxford, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="71" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Experimental Validation of New Software Technology</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Zelkowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Binkley</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="229" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">for the CONSORT Group; The CONSORT Statement: Revised Recommendations for Improving the Quality of Reports of Parallel-Group Randomized Trials</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1987" to="1991" />
			<date type="published" when="2001-04-18">April 18, 2001</date>
		</imprint>
	</monogr>
	<note>JAMA</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Standardized Reporting of Clinical Practice Guidelines: A Proposal from the Conference on Guideline Standardization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Shiffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shekelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Overhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Slutsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grimshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Deshpande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="493" to="498" />
			<date type="published" when="2003-09">September 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Publication Manual of the</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>American Psychological Association</publisher>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
	<note>th ed.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Writing Good Software Engineering Research Papers -Minitutorial</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th Intern. Conf. on Software Engineering (ICSE&apos;03)</title>
		<meeting>of the 25th Intern. Conf. on Software Engineering (ICSE&apos;03)<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="726" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Experimentation in Software Engineering -An Introduction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wohlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Runeson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Höst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Ohlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Regnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wesslén</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Basics of Software Engineering Experimentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Juristo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moreno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Procedures for Performing Systematic Reviews</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<idno>0400011T.1</idno>
	</analytic>
	<monogr>
		<title level="m">and National ICT Australia Ltd</title>
		<imprint>
			<date type="published" when="2004-07">July, 2004</date>
		</imprint>
		<respStmt>
			<orgName>Keele University Joint</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">NICTA Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">More Informative Abstracts of Articles Describing Clinical Practice Guidelines</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S A</forename><surname>Hayward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Tunis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Bass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Haynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="731" to="737" />
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Addressing the Limitations of Structured Abstracts (Editorial)</title>
	</analytic>
	<monogr>
		<title level="j">Annals of Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2004-03">March 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving the Clarity of Journal Abstracts in Psychology: The Case for Structure</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Science Communication</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="366" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Current findings from research on structured abstracts</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Medical Library Association</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="368" to="371" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Goal Question Metric Paradigm</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Caldiera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Rombach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Software Engineering</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Marciniak</surname></persName>
		</editor>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="528" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Structured Abstract: An Essential Tool for Researchers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bayley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eldredge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Library Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2003">2003</date>
			<pubPlace>Spring</pubPlace>
		</imprint>
	</monogr>
	<note>In Hypothesis: The Journal of the Research Section of the. 4 pages</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Empirical Investigation of Perspective-based Reading: A Replicated Experiment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ciolkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Differding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Laitenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Münch</surname></persName>
		</author>
		<idno>ISERN-97-13</idno>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Fraunhofer Institute for Experimental Software Engineering</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling Software Measurement</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Linkman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="788" to="804" />
			<date type="published" when="2001-09">September 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Towards an Ontology of Software Maintenance</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Travassos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Von Mayrhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Niessink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vehvilainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Software Maintenance: Research &amp; Practice</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="365" to="389" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m">Lecture Notes on Empirical Software Engineering</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Juristo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Moreno</surname></persName>
		</editor>
		<meeting><address><addrLine>Ed. River Edge, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>World Scientific Publishing</publisher>
			<date type="published" when="2003-10">October 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
