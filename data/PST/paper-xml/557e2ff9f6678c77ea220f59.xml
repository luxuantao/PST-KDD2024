<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Universal Analytical Forms for Modeling Image Probabilities</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anuj</forename><surname>Srivastava</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Florida State University</orgName>
								<address>
									<postCode>32306</postCode>
									<settlement>Tallahassee</settlement>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiuwen</forename><surname>Liu</surname></persName>
							<email>liux@cs.fsu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Florida State University</orgName>
								<address>
									<postCode>32306</postCode>
									<settlement>Tallahassee</settlement>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ulf</forename><surname>Grenander</surname></persName>
							<email>ulf-grenander@home.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Florida State University</orgName>
								<address>
									<postCode>32306</postCode>
									<settlement>Tallahassee</settlement>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="middle">A</forename><surname>Srivastava</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Florida State University</orgName>
								<address>
									<postCode>32306</postCode>
									<settlement>Tallahassee</settlement>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="middle">X</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Division of Applied Mathematics</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<postCode>02912</postCode>
									<settlement>Providence</settlement>
									<region>RI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Universal Analytical Forms for Modeling Image Probabilities</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0228C9A6613B74E9B81E1F9532804C2D</idno>
					<note type="submission">received 9 Nov. 2001; accepted 10 Feb. 2002. Recommended for acceptance by D. Forsyth.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index TermsÐImage probabilities</term>
					<term>spectral analysis</term>
					<term>Bessel K forms</term>
					<term>clutter classification</term>
					<term>target recognition</term>
					<term>Gabor filters</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>AbstractÐSeeking probability models for images, we employ a spectral approach where the images are decomposed using bandpass filters and probability models are imposed on the filter outputs (also called spectral components). We employ a (two-parameter) family of probability densities, introduced in [11] and called Bessel K forms, for modeling the marginal densities of the spectral components, and demonstrate their fit to the observed histograms for video, infrared, and range images. Motivated by object-based models for image analysis, a relationship between the Bessel parameters and the imaged objects is established. Using L P Emetri on the set of Bessel K forms, we propose a pseudometric on the image space for quantifying image similarities/differences. Some applications, including clutter classification and pruning of hypotheses for target recognition, are presented.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>S TATISTICAL techniques for image analysis and understand- ing require efficient and tractable probability models for analyzing the observed images. Given the tremendous variability associated with the imaged objects, detailed (e.g., 3D deformable templates) models are not feasible for ªall possible objects.º Therefore, one seeks a balance by designing low-level, coarse representations that are tractable and yet capture significant image variation. Here, we study a family of tractable, coarse probability models that can form building blocks of a larger image understanding system. Since the image space is very high-dimensional, a direct modeling of the joint probabilities is not possible, even if a large number of observations are provided, and some method for reducing dimensions is required. There are two general reductionist approaches adopted in the literature: 1) parameterize the probability densities using certain (low-dimensional) physical parameters (relating to the imaged objects) or 2) perform dimension reduction via purely numerical, nonphysical approaches.</p><p>In the first approach related to high-level vision, images are parameterized by the physical characteristics of the objects (such as shapes, textures, reflectance, illumination, and motion). These quantities are modeled mathematically, within some acceptable approximation and the resulting physical variables are used to analyze images. Probability models on images now consist of: 1) probability models on these physical variables and 2) the sensing models. An example of this idea is the deformable template theory <ref type="bibr" target="#b8">[9]</ref> where images are studied through the transformations that match the physical templates to the observations. These models are detailed and capture sufficient variability to discriminate well even in challenging situations (cluttered scenes, low SNR, distant images, etc.). One drawback is that they are computationally expensive to implement, since they require synthesis of hypothesized images for comparison with the observed images. The second idea relates to low-level vision and involves one of many techniques that reduce dimensions using purely numerical considerations. That is, by not involving any physical consideration on the imaged objects, or any contextual knowledge, the images are treated as elements of a vector space and one seeks a low-dimensional subspace that best represents those numbers (under some chosen criterion). Principal components <ref type="bibr" target="#b15">[16]</ref>, independent components <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b2">[3]</ref>, sparse coding <ref type="bibr" target="#b20">[21]</ref>, Fisher's discriminant <ref type="bibr" target="#b1">[2]</ref>, local linear embedding <ref type="bibr" target="#b23">[24]</ref>, and many other statistical learning algorithms are all instances of this idea. The main advantage here is the computational efficiency and the main drawback is knowledge deficiency. Lack of physical or contextual information leads to a limited performance, especially in challenging situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Models for Image Analysis</head><p>An important idea is to develop an adaptive strategy that balances these two levels of inferences. In this paper, we study a framework that provides some interaction between the pixel-based and the template-based inferences and is capable of shifting between the two depending on the available resources, both computational and informational. Consider a deformable template representation of the imaged objects, as laid out in <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b25">[26]</ref>. The basic idea is that images are made up of (images of) objects and their variability can be represented by physical variables. Using 3D models of objects (including polygonated surfaces, textures, and reflectance functions), all occurrences of these objects can be generated by applying similarity transformations. 3D scenes containing these transformed objects lead to 2D images via occlusion and projection. What probability models on image can result from this model? As stated earlier, there are two possibilities:</p><p>1. The template approach where the set of possible objects is small and the 3D models are available for all objects. Also, the tools for synthesizing images of these objects under all transformations of pose and illumination are assumed available. Under these assumptions, a probability distribution on images can be written explicitly in terms of a joint probability on the transformation space and the set of objects.</p><p>Object recognition is now solved on the product space <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Inference procedures are laid out in the papers <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b18">[19]</ref>. 2. For general problems in image understanding, 3D models cannot be prestored for all objects, and furthermore, the transformations may not be identifiable in all conditions. Therefore, the representations tend to be less explicit and the image probability is motivated through empirical studies <ref type="bibr" target="#b19">[20]</ref> and not via the physical parameters. In this paper, we seek general models that retain some physical considerations, although not as explicitly as the template approach. Pursuing the second case, we replace 3D templates by their 2D profiles (call them generators) and denote them as gs. gs are the views (appearances, signatures, profiles) of randomly chosen objects, taken from random poses. Let q be the space of all possible generators associated with all objects, imaged from all angles. Random translations of 3D objects in a scene will be modeled by random placements and scalings of gs in an image.</p><p>Let I X IR P U 3IR be the image map. Then, each object (with generator g i ) present in the scene contributes to the pixel value Iz according to a i g i I i z À z i . Here, z P W H; L Â H; L is a variable for pixel location, g i X W U 3IR is a generator of a randomly chosen object, i P H; L is a random scale, and a i P IR is the random weight associated with g i . g i s are assumed to be drawn from q according to some probability dG. Although the physics of imaging dictates using occlusion models, we simplify the image formation by using the equation: </p><formula xml:id="formula_0">Iz n i a i g i I i z À</formula><p>and 4. a i s, g i s, z i s, and i s are all assumed independent of each other. Since g i s are assumed unknown, the related variables n, i s, and z i s become indeterminable. However, we aim to derive probability models on I by implicitly incorporating their variability.</p><p>Motivated by a growing understanding of early human vision, a popular strategy has been to decompose images into their spectral components using a family of bandpass filters. Following that idea, our definition of a probability model on images is through its spectral representation. If certain lowdimensional statistics of these filtered components are found sufficient, then a significant reduction is achieved. Zhu et al. <ref type="bibr" target="#b29">[30]</ref> have shown that the marginal distributions of spectral components, obtained using a collection of filters, sufficiently characterize homogeneous textures. The choice of histograms as sufficient statistics implies that only the frequencies of occurrences of (pixel) values in the filtered images are relevant and the location information is discarded <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Chubb et al. <ref type="bibr" target="#b3">[4]</ref> also advocate the use of a histogram in texture representation. The main focus in these papers has been to model homogeneous textures, but we will apply spectral analysis to a general setting of image understanding. Portilla and Simoncelli <ref type="bibr" target="#b22">[23]</ref> have suggested using the lower order statistics (mean, variance, skewness, kurtosis) to specify the marginal densities of the wavelet coefficients of the images. Wainwright et al. <ref type="bibr" target="#b27">[28]</ref> have studied a family of Gaussian mixtures, resulting from different mixing densities, for modeling the observed histograms. Lee et al. <ref type="bibr" target="#b16">[17]</ref>. have presented a synthesis model for capturing the statistics in the images of leaves. Donoho and Flesia <ref type="bibr" target="#b6">[7]</ref> and Donoho and Huo <ref type="bibr" target="#b5">[6]</ref> have proposed edge-based transforms to account for the patterns in the observed histograms.</p><p>Using a physical model for image formation, we have proposed a family of two-parameter probability densities <ref type="bibr" target="#b10">[11]</ref>, called Bessel K forms, to model the horizontal and the vertical derivatives of images. In this paper, we extend this model to a full spectrum of bandpass filters and arbitrary images. The two parameters associated with this family will form a sufficient statistic for a spectral component, denoting a significant reduction in the representation. The parameters can be directly estimated from the variance and the kurtosis of the filtered image pixels, thereby implying a simple estimation procedure. The main results presented here are: 1) demonstration of the success of Bessel K forms in modeling the spectral components for video, infrared, and range images of natural and artificial scenes, 2) derivation of an analytical expression for computing the L P Emetri, on the Bessel family, that leads to a pseudometric on image space, and 3) use the Bessel K forms (and the pseudometric) as a tool for clutter classification and for pruning possible hypothesis set for recognition of objects from their images. The last claim is based on: 1) motivating the model in <ref type="bibr" target="#b0">(1)</ref> by relating it to the 3D deformable template representation, 2) relating Bessel parameters to certain physical characteristics of the imaged objects, and 3) an example of pruning hypothesis using the COIL database. In addition, we will present an asymptotic approximation of the Bessel K form that can potentially simplify future inference procedures.</p><p>This paper is organized as follows: Section 2 applies Bessel K forms to model spectral components of images and associates the estimated Bessel K parameters with the observed shapes. Section 3 derives an L P Emetri on the Bessel K forms and on the image space, while Section 4 applies this metric to clutter classification and target recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBABILITY MODELS FOR IMAGE SPECTRA</head><p>We start with some notation. Given an image I and a bank of filters fF j ; j I; P; F F F ; Kg, we compute for each filter F j a filtered image I j I Ã F j , where Ã denotes the 2D convolution operation. As an example, a Gabor filter is a bandpass filter with a Gaussian kernel centered around a specific wavenumber (see <ref type="bibr" target="#b13">[14]</ref> for details). For a rotation P H; P, a Gabor filter is given by: F z exp À I P P z I P z P P exp Àj Pz I ;</p><p>where denotes the resolution associated with the filter and z os Àsin sin os</p><formula xml:id="formula_1">! z I z P ! P IR P :</formula><p>Another filter suggested by Marr <ref type="bibr" target="#b17">[18]</ref> to model early vision is the Laplacian of Gaussian filter whose operation on I is given by G Ã ÁI, where G is a Gaussian kernel and Á is the Laplacian operator. In addition to these filters, one can utilize a wide variety of filters: neighborhood operators, steerable filters, interpolation filters, etc. Each filter selects and isolates certain features present in the original image. In this paper, we do not address the issue of selecting filters to best accomplish a specific task. Instead, we will assume an arbitrary choice of filters as long as the resulting spectral components have marginals that are: 1) unimodal, 2) symmetric around the mode, and 3) are leptokurtic, i.e., their kurtosis are more than that of a Gaussian random variable with the same variance. Additionally, we want the filters such that the resulting representation is computationally efficient which holds for filters with smaller bandwidths.</p><p>Remark 1. In this paper, we force the mode to be at zero by setting I j I j À EI j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Analytical Models</head><p>Applying 2D convolution to both sides of (1), we obtain a spectral component</p><formula xml:id="formula_2">I j z I Ã F j z i a i g j i I i z À z i ; where g j i F j Ã g i :</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P</head><p>The conditional density of I j z, given the Poisson points fz i g, the scales f i g, and the profiles fg i g, is normal with mean zero and variance u, where</p><formula xml:id="formula_3">u i g j i I i z À z i P :</formula><p>One departure here, from the model used in <ref type="bibr" target="#b10">[11]</ref>, is that the generators are now randomly selected and are included at random scales i s in <ref type="bibr" target="#b1">(2)</ref>. Under this model and assuming u to be a scaled-Gamma random variable, the density function of the random variable I j z has been shown to be <ref type="bibr" target="#b10">[11]</ref> </p><formula xml:id="formula_4">P c r jx À j<label>2 3</label></formula><p>; x P IR:</p><p>As stated earlier, in this paper, we restrict to only two parameters by setting H.</p><p>Let h be the space of all such densities:</p><formula xml:id="formula_5">h ffxY p; cjp &gt; H; c &gt; Hg:</formula><p>We refer to the elements of h as the Bessel K forms and the parameters p; c as the Bessel parameters. The elements of h have the following properties:</p><p>1. They are symmetric and unimodal with the mode at zero. For p I, fxY p; c is the density of a double exponential. In general, it is the pth convolution power (for any p &gt; H) of a double exponential density. Therefore, it is unimodal with the mode at x H. For the same reason, it is symmetric around zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The kurtosis of a Bessel K form relates to the term</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q vru</head><p>Eu P :</p><p>Hence, the Bessel K forms are leptokurtic (the tails are heavier as compared to a normal curve with the same variance). 3. A Bessel K form is a specific kind of normal variance-mean mixture where the mixing variable is a scaled Gamma with parameters p and c. It becomes a special case of a larger family of selfreciprocal normal variance mixtures as described by Barndorff-Nielson et al. <ref type="bibr" target="#b0">[1]</ref>. This connection opens the possibility of a larger family, namely, the generalized hyperbolic distributions, to be used in modeling image spectra, if needed. In addition to the shape and the scale, this family allows for a location parameter, skewness, and different rates (of exponential decay) on the two tails. The significance here for image analysis is that more filters, beyond the ones that lead to symmetric histograms, can also be included in the analysis. This property is due to the choice of Gamma density for u and it limits our later derivation of L P Emetri to the Bessel K forms with pEvlues larger than H:PS. How does one estimate the Bessel K parameters for a given filtered image? p and c can be estimated using the equations:</p><formula xml:id="formula_6">p Q u I j ÀQ ; c I j À Á p ; R</formula><p>where SK is the sample kurtosis and SV is the sample variance of the pixel values in I j . A derivation of these estimators is omitted here as a similar result is presented in <ref type="bibr" target="#b10">[11]</ref>. The computational task of estimating the marginal density is that of computing the second and the fourth moments of the filtered image. We illustrate some estimation results for a variety of images.</p><p>. Shown in the top panels of Fig. <ref type="figure" target="#fig_0">1</ref> are some images taken from the van Hateren <ref type="bibr" target="#b26">[27]</ref> database. The middle panels display their specific filtered forms (or spectral components) for Gabor filters at arbitrarily chosen orientations and scales, and the bottom panels plot the marginal densities. On a log scale, the observed densities (histograms) are plotted in the marked (knotted) lines and the estimated Bessel K forms (fxY p; c) are plotted in the solid lines.</p><p>. For the image shown in the top panel of Fig. <ref type="figure">2</ref>, we have estimated Bessel K forms for many Gabor filters. The middle panels show the marginals for different filter orientations ( QH; WH; IPH, and ISH degrees), while keeping the scale fixed at R:H and the bottom panels are for different filter scales ( R; T; V, and IH) keeping the orientation fixed at ISH degrees. . Fig. <ref type="figure">3</ref> shows examples of estimation when the images are filtered by Laplacian of Gaussian filters. The top panels show some natural images from the van Hataren database <ref type="bibr" target="#b26">[27]</ref> and the bottom panels show the corresponding estimated Bessel K forms. . Fig. <ref type="figure">4</ref> shows estimation results for three infrared face images when filtered by Gabor filters. These results suggest the role of Bessel K forms in modeling images beyond the visual spectrum. For an application of Bessel K forms in infrared face recognition, please refer to the article <ref type="bibr" target="#b24">[25]</ref>. . Shown in Fig. <ref type="figure">5</ref> are some examples of estimating marginal densities for the case of outdoor range images taken from the Brown range database of Lee and Huang. The three images shown in top panels are filtered using Gabor filters and the resulting densities are plotted in the bottom panels. Instead of estimating Bessel parameters using moments, it may be preferable to use some robust estimation technique to account for the outliers. A simple idea is to consider a fraction (say one percent) of the tail as outlier and discard it in parameter estimation. Using this idea, we have found an improvement in estimation performance for the cases where p is quite small (p &lt; H:I). Other possibilities include maximumlikelihood estimation of p; c, or a robust estimation technique based on relating quartiles to p and c. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Performance Analysis of Bessel K Forms</head><p>To quantify the performance in modeling observed histograms by estimated Bessel K forms, a number of quantities can be used and we choose the Kullback-Leibler (KL) divergence.</p><p>For any two density functions f I and f P , the KL divergence is defined as the quantity:</p><formula xml:id="formula_7">KLf I ; f P I R log f I x f P x f I xdx:</formula><p>We have computed it by discretizing at the center points of the histogram bins. To illustrate KL divergence values for our applications, we start with some examples. Shown in Fig. <ref type="figure">6</ref> are six plots, each containing a pair of densities: one observed (marked line) and one estimated (solid line), and the KL divergence between them is listed on the top. These six cases show a decreasing match, in going from top left to bottom right. The KL divergence, in that order, is found to be 0.0008, 0.0058, 0.0105, 0.00591, 0.247, and 0.3341, respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relating the Shape Parameter to the Imaged Objects</head><p>Before we present some applications of these Bessel K forms, we first deal with an interesting question. How do the Bessel K parameters p and c, estimated for a spectral component of an image, relate to the objects that are present in that image?</p><p>The physical characteristics of the imaged objects and the filter used in generating a spectral component, should dictate the resulting Bessel K form. Since c is essentially a scale parameter relating to the range of pixel values in I, its role is not as important as p. Here, we derive a relationship between the imaged generators and the estimated shape parameter. We will perform the analysis for the pixel Iz as composed of the generators fg i I i z À z i g (1), although the analysis remains the same for any spectral component I j z composed of the generators fg j i I i z À z i g (2). Let the characteristic function of the random variable a i be given by !. (Later, we assume a specific by choosing a i s to be standard normal.) The conditional characteristic function of I j z, given the Poisson points fz i gs, the scales f i gs, and the generators fg i gs, is:</p><formula xml:id="formula_8">É I !jfz i g; f i g; fg i g n iI !g i I i z À z i ;</formula><p>using the i.i.d. nature of a i s. Integrating out the uniform, independent placement of z i s, for a given n, we obtain the conditional characteristic function:</p><formula xml:id="formula_9">É I !jn; fg i g; f i g G n iI W !g i I i z À z i dz i :</formula><p>Similarly, integrating out the scales, we get: Now, integrate out the random selection of the generators g i s.</p><formula xml:id="formula_10">É I !jn; fg i g G n iI W L H !g i I i z À z i d i dz i :</formula><p>Recall that each g i is drawn independently from the generator space q according to some measure dG. This gives,</p><formula xml:id="formula_11">É I !jn G q W L H !g I I I z À z I d I dz I dG I n :</formula><p>The last step is to integrate with respect to n. For the image defined over the set W , n is a Poisson random variable with mean jW j. To simplify notation, we use to denote jW j in the following:</p><formula xml:id="formula_12">É I ! G I nH 2 expÀ n n3 q W L H !g I I I z À z I d I dz I dG I n 3 exp 2 q W L H !g I I I z À z I d I dz I dG I À I 3 :</formula><p>Without loss of generality, we can substitute z H. To simplify, assume that the generators g P q are all even functions. Then,</p><formula xml:id="formula_13">É I ! G exp q W L H !g I z I I d I dz I dG I À I : S</formula><p>To find the cumulants of I, we use the relation:</p><formula xml:id="formula_14">k d k logÉ I ! d! k j !H :</formula><p>The two cumulants that we need are:</p><formula xml:id="formula_15">P HH H q W L H g I z I I P d I dz I dG I<label>2 3</label></formula><p>;</p><formula xml:id="formula_16">R iv H q W L H g I z I I R d I dz I dG I<label>2 3</label></formula><p>:</p><p>The kurtosis of Iz, according to this model, is given by: This equation provides an important relationship between a generator g and the parameter p. According to (6), p &lt; I occurs when &lt; T . If the generator g has sharp, distinct boundaries (i.e., is larger), then the p value is small unless the frequency of occurrence () is large. Specifically, if a filter F j is used to extract a particular feature (e.g., oriented edges, junctions, bands, etc.) from the image I, then the value of p is dictated by the distinctness () and the frequency of occurrence () of that feature in the image. For example, shown in Fig. <ref type="figure" target="#fig_6">8</ref> is a variation of p value when the images are filtered for extracting vertical edges ( WH). The top row shows images with increasing frequency of vertical edges in going from left to right. Correspondingly, the estimated p value shows an increase (H:IHP, H:SRI, I:RUQ, and V:VQ). Summarizing the relation between p and , we have:</p><formula xml:id="formula_17">kurtosisI R P P iv H q W L H g I z I I R d I dz I dG I HH H q W L</formula><formula xml:id="formula_18">sf H &lt; &lt; =T then p &lt; I =T &lt; &lt; =Q then p &gt; I : &amp; 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Asymptotic Approximation of Bessel K Forms</head><p>Although the proposed Bessel K forms model the observed histograms very well, their functional form is not easy to work with. Following the discussion in <ref type="bibr" target="#b0">[1]</ref>, it is possible to approximate the tails of Bessel K forms using a gamma density as follows: For large values of x, the modified Bessel function K x can be approximated by the function Px p expÀx uniformly over compact sets of . Since small values of imply a large tail, this approximation holds well for a large part of the domain whenever p is small. The tails of a Bessel K form with the parameters p and c can be approximated well by the function: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PSEUDOMETRICS FOR COMPARING IMAGES</head><p>We have chosen to represent images via the Bessel parameters of their spectral components. One distinct advantage, of having such analytical forms for the marginals of the spectral components, is the resulting theoretical framework for image analysis. For instance, we would like to be able to compare images by directly comparing their respective Bessel parameters. An analytical form is very useful in the sense that we do not need to estimate the densities for this comparison.</p><p>To quantify the distance between two Bessel K forms, we have chosen the L P Emetri on h. It is possible that other metrics, such as the Kullback-Leibler divergence, Renyi's Edivergene, or even the L I metric, may prove more useful in certain situations. Since we are restricting ourselves to only h, and not the full set of pdfs, we suggest that many of these choices will provide similar results, especially if the task is classification or hypothesis pruning. The main drawback of choosing L P is that Bessel K forms are not in L P for p &lt; H:PS. In the case of natural images, the pEvlues are mostly larger than H:PS, while, for images of objects with sharp, well-defined edges, p can sometimes be below H:PS. Remark 4. In cases where an image-filter combination leads to p &lt; H:PS, we can choose one of following: 1) drop that filter, 2) replace p by H:PS , and then compute the L P Emetri, or 3) compute the L P Emetri numerically using the quadrature integration at a certain resolution.  Theorem 1 provides a metric between two Bessel K forms or between two spectral marginals. It can be extended to a pseudometric on the image space as follows: For any two images, I I and I P , and for a given bank of filters, F I ; F F F ; F K , let the Bessel parameter values be given by: p j I ; c j I and p j P ; c j P , respectively, for j I; P; F F F ; K. Then, the L P Edistne, between the spectral representations of the two images, is defined as: , may be pursued. Since the Gabor filters are sensitive to the image orientations, the resulting metric also depends upon the orientations. To enforce rotational invariance, one can define a metric which selects the supremum over all possible image orientations. The other choice is to restrict to filters that are rotationally invariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPLICATION OF BESSEL K REPRESENTATIONS</head><p>Now, we present some examples of applying Bessel K formulations and the metric d I to image understanding problems. We have selected examples from: 1) clutter classification, 2) target recognition, and 3) texture synthesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Clutter Classification</head><p>An important application of this Bessel K representation is in the classification of clutter for ATR (automated target recognition) scenarios. In particular, given an observed image of a target imaged in a cluttered environment, one would like to characterize the clutter to the extent that it improves the ATR performance. Some knowledge of the clutter type, whether it is grass, buildings, trees, or roads, can help improve the target recognition performance. In this section, we will utilize Bessel K forms to represent the image spectra, and will employ d I as defined in <ref type="bibr" target="#b8">(9)</ref> to classify the clutter types from their images. To illustrate the idea, we will use d I to cluster some images of natural clutter shown in Fig. <ref type="figure" target="#fig_0">11</ref>. For a simple illustration, let the images in the top row be the training images that are already classified, and the bottom row be images that are to be classified. Using 27 small-scale Gabor filters (K PU, for nine orientations at three scales each), we have computed the pairwise distances d I s.</p><p>Using the nearest-neighbor approach and the metric d I , one can perform clutter classification. To illustrate a classification of clutter types, we have plotted a clustering chart in the left panel of Fig. <ref type="figure" target="#fig_0">12</ref> using the dendrogram function in matlab. This function generates a clustering tree for points in a high-dimensional space when their pairwise distances are given. The clustering of I I with I P , I Q with I R , etc., demonstrates the success of this representation and the metric chosen. For comparison, we ran the same clustering Shown in Fig. <ref type="figure" target="#fig_11">13</ref> is another example of image clustering using d I .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pruning Hypotheses for Recognition</head><p>Recognition of objects from their observed images corresponds to the selection of hypothesis in presence of the nuisance parameters <ref type="bibr" target="#b11">[12]</ref>. As stated under Case 1 in Section 1.1, this hypothesis selection is often performed using detailed models involving physical shapes, texture, pose, and motion <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Such methods are based on low-and high-dimensional deformations of targets' templates in order to match their synthesized images with the observed images. The deformations capture the variability in pose, motion, illumination, etc., and form the set of nuisance parameters, call it S, for hypothesis selection; they typically are computationally expensive to implement. Given an image, the task of searching over all possible templates is demanding and can benefit from a pruning that places significant probability only on a small subset of possible hypotheses.</p><p>Let e be the set of all possible objects. Define a probability mass function on e according to: for P e, ;s ; c j ;s are the estimated parameters for the filter F j and the target rendered at the nuisance variable s P S. Note that p j ;s ; c j ;s can be precomputed offline for all P e, s P S, and j P fI; P; F F F ; Kg.</p><p>To illustrate this idea, consider the following experiment. Shown in Fig. <ref type="figure" target="#fig_0">14</ref> are some sample images of objects from the Columbia object image library (COIL) <ref type="bibr" target="#b21">[22]</ref>. This database consists of 72 images each of a total of 100 objects, taken at five degree separation in azimuth, and has been widely used in testing object recognition algorithms. In this experiment, we divided 7,200 images into nonoverlapping training and test sets. Some of the images are used as training and the remaining for testing, similar to the work presented in <ref type="bibr" target="#b21">[22]</ref>.</p><p>We have used a bank of K QW filters, consisting of gradient filters, Laplacian of Gaussian filters, and Gabor filters. For each image of the object at the pose s in the training set, we estimate p j ;s ; c j ;s , for each filter F j . Then, given a test  image I, the estimated parameters p j obs ; c j obs are used to compute the probability P jI according to <ref type="bibr" target="#b9">(10)</ref>. Shown in Fig. <ref type="figure" target="#fig_0">15</ref> are six plots of P jI versus (at T H:S) for six different test images I in the COIL database. All the objects with probabilities larger than some threshold, say H:HI, can be shortlisted for detailed hypothesis testing. As an example, the plot in top left shows P jI for an image I of the first object. In short-listing by thresholding, we are left with only 14 possible hypotheses, a significant reduction from 100. The bottom middle plot displays the worst case of the whole experiment and still shortlists 35 objects.</p><p>To support the use of Bessel K models in hypothesis pruning, we have actually used P jI for object recognition and have compared results with some other recently proposed procedures: principal component analysis (PCA), independent component analysis (ICA), support vector machines (SVM), and SNoW. Pontil and Verri <ref type="bibr" target="#b21">[22]</ref> have applied SVM (Support Vector Machines) method to 3D object recognition and have tested it on a subset of the COIL-100 data set with half for training and the other half for testing. As pointed out by Yang et al. <ref type="bibr" target="#b28">[29]</ref>, this dense sampling of training views simplifies the recognition problem. Hence, we have presented recognition results for different training to test ratios in splitting the COIL database. The number of components selected is such that complexity remains similar to that of Bessel representations. Table <ref type="table" target="#tab_4">1</ref> summarizes that Bessel representations, in addition to being analytic and parametric, generally outperform these other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Texture Synthesis</head><p>To further illustrate the strength of Bessel representations, we present some examples of texture synthesis. For homogeneous textures, it is possible to sufficiently characterize them using their spectral responses. As described in <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b29">[30]</ref>, choosing the filtered marginals for several filters as sufficient statistics leads to a Gibbs' distribution on the image space. This points to a natural Gibbs' type MCMC sampling method to generate high probability images from the probability model. Using the same sampling scheme, except the observed marginals are now replaced by the estimated Bessel K forms, we have generated high probability samples on the image space. The Gibbs' distribution on the image is space is given by:</p><formula xml:id="formula_19">f I I I Z exp À K jI kH I j À f xY p j ; c j k P =T<label>2 3</label></formula><p>; where H denotes the observed histogram and Z is the normalizing constant involved. Shown in the top panels of Fig. <ref type="figure" target="#fig_13">16</ref> are real texture images used to estimate the Bessel K parameters (for QW filters) and shown in the bottom panels are the corresponding samples from a distribution based on the estimated parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We have applied Bessel K forms to model the probability densities of the filtered marginals. The estimated parametric  forms are shown to match well with the observed histograms for a variety of images: video, infrared, and range, for gradient, Gabor, and Laplacian of Gaussian filters. Given the assumptions behind this construction, we expect this model to perform well in other imaging modalities such as MRI, PET, and radar imaging. Bessel parameter p is related to the distinctness and the frequency of occurrence of the filtered characteristics of imaged objects. We have used L P metric on the set of Bessel forms (restricted to p &gt; H:PS) to derive a pseudometric on the image space. This metric can be used for, among other things, clutter classification and target recognition. Although the performance of Bessel representations in challenging object recognition situations remains to be tested, their ability to prune possible hypotheses and feed to a more detailed recognition model seems promising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A.1 Bessel Function</head><p>The modified Bessel function used in this paper is defined as: IP where `a b &gt; H, ` &lt; I À j`j À j`j. F is the hypergeometric function; it is an infinite series in its last argument.</p><p>To derive the L P Emetri, we start with its square: using the integral formula <ref type="bibr" target="#b11">(12)</ref> Combining these three terms, the result in <ref type="bibr" target="#b7">(8)</ref> follows: It should be noted that the metric is symmetric in the parameters p I ; c I and p P ; c P , even though it does not appear that way from the expression in <ref type="bibr" target="#b7">(8)</ref>. The condition associated with the formula <ref type="bibr" target="#b11">(12)</ref> implies that p I and p P must be greater than 0.25.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Images (top panels), their Gabor components (middle panels), and the marginal densities (bottom panels). The observed densities are drawn in marked lines and the estimated Bessel K forms are drawn in solid lines.</figDesc><graphic coords="4,31.12,69.17,504.17,270.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Plots of observed and estimated marginals (on a log scale) of the spectral components of a given image (top panel). Middle panels depict the marginals for different filter orientations while the bottom panels are for different filter scales.</figDesc><graphic coords="5,31.12,69.17,504.17,310.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Observed and estimated marginal densities (bottom panels) for the IR face images (top panels) and arbitrary Gabor filters.</figDesc><graphic coords="6,40.14,69.17,486.14,255.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Examples of Kullback-Leibler divergence: The divergence values for the six plots are listed on the top.</figDesc><graphic coords="7,95.75,69.17,375.06,206.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>This result is useful as it provides a simpler expression although only in an asymptotic setting. Since for p &gt; I, the maxima of fxY p; c are attained at the points x AEp À I P c p and not at x H, this approximation is valid only for p &lt;&lt; I:H. To illustrate this approximation on the filtered marginals, three example are shown in Fig.9. The top panels show original images and the bottom panels show the log densities for arbitrary Gabor filters. The observed histograms are plotted in solid lines, the Bessel K forms fxY ; p; c are plotted in lines with + signs (-+ -), and the asymptotic approximations fxY p; c are plotted in lines with * (-*-).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Asymptotic approximations of Bessel forms: For the images shown in top panels, the bottom panels plot the observed histogram (solid), Bessel K form (-+-), and the approximation (-*-).</figDesc><graphic coords="9,78.35,539.15,409.83,196.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .:</head><label>8</label><figDesc>Fig. 8. Variation of pEvlues for extracting vertical edges ( WH). Top panels are the original images, middle panels are filtered images, and the bottom panels are the densities (log-scale). The estimated pEvlues are: H:IHP, H:SRI, I:RUQ, and V:V, respectively.</figDesc><graphic coords="9,31.12,69.17,504.17,260.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Note that d I is not a proper metric on the image space because two different images can have d I H between them. Also, d I is dependent upon the choice of filters. It has been established in the literature that different spectral components of the same image are often correlated and, therefore, this Euclidean form may not be appropriate. In such cases, another choice such as the max of all components, d I I I ; I P mx j dp j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Examples of the L P Emetri on h: (a) p P H:S, c P PH, d H:HTQ, (b) p P H:US, c P IH, d H:IIR, (c) p P I:H, c P I:H, d H:IPS, (d) p P P:S, c P P:H, d H:ITI. p I H:S and c I IH:H are held constant.</figDesc><graphic coords="10,30.84,69.17,504.91,118.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>our confidence (analogous to the temperature in Gibbs' energies) in this probability. Here, p j obs ; c j obs are the estimated parameters for the image I and filter F j , and p j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .Fig. 12 .</head><label>1112</label><figDesc>Fig. 11. Ten natural images from the van Hateren database: top row consists of the training images and bottom row consists of the test images.</figDesc><graphic coords="11,60.21,69.51,446.06,153.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. For the images shown in left, a dendrogram clustering plot using Bessel K forms is shown in the right panel.</figDesc><graphic coords="12,55.16,320.37,456.15,76.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 .Fig. 15 .</head><label>1415</label><figDesc>Fig. 14. Sample images of objects from COIL image database.</figDesc><graphic coords="12,44.56,420.32,477.52,256.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 16 .</head><label>16</label><figDesc>Fig.<ref type="bibr" target="#b15">16</ref>. Top row: observed images of the textures. Bottom row: synthesized images using the Bessel K densities.</figDesc><graphic coords="13,115.43,549.07,335.62,195.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>z</head><label></label><figDesc>P y P H:S dz; II for ` &gt; ÀH:S, x &gt; H, and jargyj &lt; P .A.2 Proof of Theorem 1To establish the theorem, we will need the integral formula ([8, p. 676, (4)]:I H x À K axK bxdx P ÀPÀ a ÀÀI b ÀI À</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>dp I ; c I ; p P ; c P P x fxY p I ; c I P dx x fxY p P ; c P P dx À P x fxY p I ; c I fxY p P ; c P dx: Consider these terms one by one, starting with the first term: I Zp I ; c I P x x PpIÀI K pIÀH:S P c I r x K pIÀH:S P c I r x dx I Zp I ; c I P P ÀQ Pc I p I ÀPp I À H:S ÀPp I Àp I P ÀH:S P p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Remark 2. If EI j is not equal to zero then we can account for it by defining a three-parameter family:</figDesc><table><row><cell>fxY p; c</cell><cell cols="2">I Zp; c</cell><cell cols="3">jxj pÀH:S K pÀH:S</cell><cell>2</cell><cell>r P c</cell><cell>3 jxj ; x P IR;</cell><cell>Q</cell></row><row><cell cols="8">where K is the modified Bessel function (see (11) in</cell></row><row><cell cols="8">Appendix A.1) and Z is the normalizing constant given by</cell></row><row><cell></cell><cell cols="3">Zp; c</cell><cell>p</cell><cell cols="3">ÀpPc H:SpH:PS :</cell></row><row><cell>fxY ; p; c</cell><cell>I Zp; c</cell><cell cols="6">jx À j pÀH:S K pÀH:S</cell></row></table><note><p>: for p &gt; H, c &gt; H,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 1 Correct</head><label>1</label><figDesc>Recognition Rate for the Full COIL-100 Data Set Using PCA, ICA, and Bessel Forms</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Substituting for the integral in the cross term gives:IZp I ; c I Zp P ; c P Zp I ; c I Zp P ; c P P ÀQ P p I c pP Àp I p P À H:S Àp I p P Àp I Àp P ÀH:S F p I p P À H:S; p P Y p I p P Y I À</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>. Similarly, the second term</cell></row><row><cell cols="2">becomes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">P p R</cell><cell cols="3">ÀH:S</cell><cell cols="2">I c P p</cell><cell>ÀPp P À H:S ÀPp P</cell><cell>:</cell></row><row><cell>x</cell><cell cols="4">x pIpPÀI K pIÀH:S I</cell><cell>r</cell><cell>P c I</cell><cell>x</cell><cell cols="2">K pPÀH:S P r r Àp I H:S P x dx c P</cell><cell>r</cell><cell>P</cell><cell>p P ÀH:S</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">I</cell><cell>c I</cell><cell>c P</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>c I</cell></row><row><cell></cell><cell>P p R</cell><cell>ÀH:S</cell><cell cols="2">I c I p</cell><cell cols="2">c I c P</cell><cell></cell><cell></cell><cell>c P</cell></row></table><note><p>pP Àp I p P À H:S Àp I p P p :</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by the grants Army Research Office DAAD19-99-1-0267, NMA 201-01-2010, and US National Science Foundation DMS-0101429. The images used in the experiments are taken from the Groningen image database, the COIL database, Brown range database, and the Florida State University infrared face database. The authors are grateful to the producers of these databases for making them public. The authors also thank Professor J. Sethuraman for some useful discussions on this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. For more information on this or any other computing topic, please visit our Digital Library at http://computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ªNormal Variance-Mean Mixtures and z Distributions,º Int</title>
		<author>
			<persName><forename type="first">O</forename><surname>Barndorff-Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">l Statistical Rev</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="145" to="159" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ªEigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hepanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="711" to="720" />
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ªThe ªIndependent Componentsº of Natural Scenes are Edge Filters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3327" to="3338" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ªHistogram Contrast Analysis and the Visual Segregation of iid Textures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Econopouly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Landy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. Am. A</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2350" to="2374" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
		<title level="m">ªIndependent Component Analysis, a New Concept?º Signal Processing</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ªCan Recent Innovations in Harmonic Analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Flesia</surname></persName>
		</author>
		<ptr target="http://www-stat.stanford.edu/donoho/Reports" />
	</analytic>
	<monogr>
		<title level="j">Explain&apos; Key Findings in Natural Image Statistics</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huo</surname></persName>
		</author>
		<ptr target="http://www-stat.stanford.edu/donoho/Reports" />
		<title level="m">ªBeamlets and Multiscale Image Analysis</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Gradshteyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Ryzhik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Table of Integral Series and Products</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Jeffrey</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<title level="m">General Pattern Theory</title>
		<imprint>
			<publisher>Oxford Univ. Press</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ªHilbert-Schmidt Lower Bounds for Estimators on Matrix Lie Groups for ATR</title>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="790" to="802" />
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ªProbability Models for Clutter in Natural Images</title>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="424" to="429" />
			<date type="published" when="2001-04">Apr. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ªAsymptotic Performance Analysis of Bayesian Object</title>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Recognitionº IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1658" to="1666" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
		<title level="m">ªPyramid-Based Texture Analysis,º Proc. SIGGRAPH</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="229" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Jahne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Haubecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Geibler</surname></persName>
		</author>
		<title level="m">Handbook of Computer Vision and Applications</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ªA Theory of Preattentive Texture Discrimination Based on First-Order Statistics of Textons</title>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="131" to="138" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ªApplication of the Karhunen-Loeve Procedure for the Characterization of Human Faces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sirovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="108" />
			<date type="published" when="1990-01">Jan. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªOcclusion Models for Natural Images: A Statistical Study of Scale-Invariant Dead Leaves Model</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">41</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">VISION: A Computational Investigation into the Human Representation and Processing of Visual Information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>W.H. Freeman and Company</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ªConditional-Expectation Estimation via Jump-Diffusion Processes in Multiple Target Tracking/Recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2678" to="2690" />
			<date type="published" when="1995-11">Nov. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<title level="m">ªEmpirical Investigations into the Statistics of Clutter and the Mathematical Models It Leads To,º Lecture for the Review of ARO Metric Pattern Theory Collaborative</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<title level="m">ªSparse Coding with an Over-Complete Basis Set: A Strategy Employed by V1?º Vision Research</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="3311" to="3325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ªSupport Vector Machines for 3D Object Recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Verri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="637" to="646" />
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ªA Parametric Texture Model Based on Join Statistics of Complex Wavelet Coeeficients,º Int</title>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="70" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
		<title level="m">ªNonlinear Dimensionality Reduction by Locally Linear Embedding,º Science</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesher</surname></persName>
		</author>
		<title level="m">ªSpectral Probability Models for Infrared Images and Their Applications to IR Face Recognition,º Proc. Workshop Computer Vision Beyond Visual Spectrum</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Grenander</surname></persName>
		</author>
		<title level="m">ªBayesian Automated Target Recognition,º Handbook of Image and Video Processing</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="869" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hateren</surname></persName>
		</author>
		<ptr target="http://hlab.phys.rug.nl" />
		<title level="m">ªNatural Stimuli Collection: A Public Database of Natural Images</title>
		<imprint>
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªRandom Cascades on Wavelet Trees and Their Use in Analyzing and Modeling Natural Images</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="89" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<title level="m">ªLearning to Recognize 3D Objects with SNoW,º Proc. Sixth European Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="439" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<title level="m">ªStatistics Matching and Model Pursuit by Efficient MCMC,º IEEE Trans. Pattern Recognition and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="554" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªMinimax Entropy Principles and Its Application to Texture Modeling</title>
		<imprint>
			<date type="published" when="1997-11">Nov. 1997</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1627" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
