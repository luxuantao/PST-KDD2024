<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Model Simplification Through Refinement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dmitry</forename><surname>Brodsky</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Watson</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Model Simplification Through Refinement</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A68EF6D00CB1AA3D79B8B14C4B5EBCF5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As modeling and visualization applications proliferate, there arises a need to simplify large polygonal models at interactive rates. Unfortunately existing polygon mesh simplification algorithms are not well suited for this task because they are either too slow (requiring the simplified model to be pre-computed) or produce models that are too poor in quality. These shortcomings become particularly acute when models are extremely large.</p><p>We present an algorithm suitable for simplification of large models at interactive speeds. The algorithm is fast and can guarantee displayable results within a given time limit. Results also have good quality. Inspired by splitting algorithms from vector quantization literature, we simplify models in reverse, beginning with an extremely coarse approximation and refining it. Approximations of surface curvature guide the simplification process. Previously produced simplifications can be further refined by using them as input to the algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many of today's applications require simplification of polygonal models at interactive speeds. Modeling applications must simplify and display extremely large models at interactive rates. In visualization applications isosurfaces from high dimensional data sets must be computed, simplified, and rendered in close to real-time. In dynamically modifiable virtual environments, newly generated surfaces are typically over-tessellated and must be simplified for display at interactive speeds. As the size of polygonal models balloons simplification algorithms have to scale gracefully to handle these extremely large models.</p><p>An ideal simplification algorithm for these applications would possess several characteristics. Most importantly, the algorithm must guarantee displayable results within a specified time limit. Second, the algorithm must provide good control of output model size if results are to be displayable. It is also very important that the output model quality remains reasonable, despite stringent time constraints. If time demands require the output of a crude simplification, then the algorithm should allow for later refinement of that output. Finally, for interactive display it would be useful if the algorithm produced a continuous level of detail hierarchy instead of several discrete levels of detail.</p><p>Most existing simplification algorithms are far too slow to be used in interactive applications. Some vertex clustering algorithms <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18]</ref> are very fast, but control of output quality and size is quite poor. Moreover this output is difficult to refine and to organize into a continuous level of detail hierarchy.</p><p>Our algorithm, R-Simp, was inspired by splitting algorithms from the vector quantization literature <ref type="bibr" target="#b5">[6]</ref>. The algorithm simplifies in reverse from coarse to fine, allowing us to guarantee a displayable result within a specified time limit. At every iteration of the algorithm, the number of vertices in the simplified model is known, enabling control of output model size. We use curvature to guide the simplification process, permitting preservation of important model features, and thus a reasonable level of output model quality. Performing simplification in a reverse direction makes it possible to refine intermediate output as long as some state information is saved. Finally with its divide and conquer approach, R-Simp can easily be extended to create continuous level of detail hierarchies. R-Simp's complexity is O(n i log n o ), where n i is the size of the input model and n o is the size of the output model. This enables R-Simp to scale linearly with respect to input size for a given output size. With all these traits, R-Simp is well suited for simplification of large models in interactive environments.</p><p>We also look to vector quantization to form a taxonomy of existing simplification algorithms. In sections 2, 3 and 4 we review vector quantization, related research, and curvature. The details of the algorithm are discussed in section 5. In section 6 we examine the performance of the algorithm and compare it to QSlim <ref type="bibr" target="#b4">[5]</ref> and a vertex clustering algorithm <ref type="bibr" target="#b17">[18]</ref>. Sections 7 and 8 present other possible applications of R-Simp and conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Vector quantization</head><p>Vector quantization (VQ) is the process of mapping a vector in a large set S ⊂ R n into a smaller set C ⊂ R n . More precisely, a quantizer is a function</p><formula xml:id="formula_0">Q : R n → C where C = { v i ∈ R n |1 ≤ i ≤ N }. C is called the codebook.</formula><p>The challenge is finding C such that it optimally represents all vectors in S ⊂ R n . The codebook C partitions the set S, since each v i represents multiple vectors from S. A single partition of S is called a cell and v i is the centroid of the cell. The difference between a vector v i and an input vector u is called distortion. When the distortion for an input vector u is minimal for all u ∈ S then the codebook is called optimal.</p><p>In <ref type="bibr" target="#b5">[6]</ref>, Gersho and Gray present four basic types of VQ algorithms. Using these four types we will create a taxonomy of existing simplification algorithms.</p><p>Product code algorithms use scalar quantizers that are independently applied to each input vector element.</p><p>In pruning algorithms, the codebook initially contains all the vectors in the input set S. The codebook entry that increases distortion least is removed; removals continue until the desired codebook size is reached. Alternatively, the codebook is initially empty, and each of the input vectors is considered in succession. If representing any vector with the current codebook would result in distortion over a given threshold, the vector is added to the codebook.</p><p>Pairwise nearest neighbor algorithms also set the initial codebook to contain all the vectors in S. All possible cell pairs are considered and the pair that introduces the least distortion is merged. Merging continues until the desired codebook size or distortion tolerance is reached.</p><p>In Splitting algorithms, the codebook initially contains a single cell. The cell with the most distortion is located and then split. Splitting continues until the required distortion or codebook size is reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Vector Quantization and Simplification</head><p>Simplification relates to quantization as follows: a centroid equates to a primitive (vertex, line, or polygon) or a set of primitives in the simplified model. For most vertex merge algorithms, the centroid is a single vertex and associated faces. A cell equates to a set or cluster of faces in the original model. There are a few ways in which model simplification differs from vector quantization. For example in model simplification, two disjoint faces do not make up an ideal cluster, while in image quantization a cluster with two separate pixels is perfectly acceptable. We cannot review every known simplification algorithm; a fairly comprehensive survey is available from Garland and Heckbert <ref type="bibr" target="#b7">[8]</ref>.</p><p>Rossignac and Borrel <ref type="bibr" target="#b17">[18]</ref> proposed an algorithm that applies a product codes technique to the model vertices. Cells are formed with a uniform voxelization; the centroid is usually chosen as the mean of the vertices in each cell (weighted averages or maxima are common alternatives). Only a linear pass through the vertices is required to simplify the surface. The result is an extremely fast algorithm that produces poor simplifications. He et al <ref type="bibr" target="#b6">[7]</ref> proposed a similar and slower algorithm that makes use of a low pass three dimensional filter. Low and Tan <ref type="bibr" target="#b14">[15]</ref> developed a vertex clustering algorithm that nonuniformly subdivided the model's volume. Cells are centred on the most important vertices in the model.</p><p>The simplification algorithms taking the pruning approach are generally not as fast as the product code algorithms, but they produce better simplifications. Two such algorithms <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13]</ref> work by growing coplanar patches. When a face cannot be added to a patch without violating a co-planarity threshold, it is re-triangulated with fewer polygons and added to the codebook. Other algorithms <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> work by removing or pruning away single vertices. The algorithm described in <ref type="bibr" target="#b19">[20]</ref> simply removes a vertex whose surrounding faces are relatively coplanar and re-triangulates the created hole, while the algorithm described in <ref type="bibr" target="#b20">[21]</ref> adds a completely new set of vertices and tries to prune away as many of the old vertices as possible.</p><p>There are many algorithms, commonly called vertex merge or edge collapse algorithms, that use the pairwise nearest neighbour approach <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref>. These algorithms tend to produce the best simplification results but are often quite slow. The algorithms assign weights to each vertex merge and use a priority queue to locate the merge with minimum cost. They merge the vertices (merge the cells), recompute the affected vertex pairs, and iterate. The algorithms continue until the required model size or error tolerance is reached. The algorithms differ in how they assign weights to a vertex merge and how they determine the location of merged vertices (calculate centroids).</p><p>To our knowledge R-Simp is the only simplification algorithm based on the splitting technique. In R-Simp we treat simplification as quantization of face normals as opposed to colour (x, y, z instead of R, G, B). Our goal when splitting is to create cells containing the most planar surface possible (the variation in face normals is small). Thus, cells that contain little curvature are split less than cells that contain more curvature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Curvature</head><p>One common measure of surface curvature is called normal curvature <ref type="bibr" target="#b15">[16]</ref>. Normal curvature is the rate of change of the normal vector field U on a surface S in direction u, where u is a unit vector tangent to the surface S at point p. There are two important normal curvature extrema called principle curvatures, these are the maximum (k 1 ) and minimum (k 2 ) values of normal curvature. The directions corresponding to these principle curvatures are called principle directions.</p><p>Since these curvature measures are defined for infinitely small patches, they provide a good description of the local surface around a point. However, they do not work well for larger surface patches with multiple scales of curvature. (e.g. asphalt looks flat from a distance but can feel quite rough close up). R-Simp requires measures of orientation change, curvature, for large patches. We will use the term normal variation to refer to orientation change in large patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The R-Simp algorithm</head><p>Unlike other algorithms, R-Simp starts with a coarse approximation of the model and refines it until the desired model complexity is reached. The algorithm begins with the triangulated model in a single cluster (a cluster is a collection of faces from the original model). The initial cluster is then divided into eight sub-clusters. These eight sub-clusters are then iteratively divided until the required number of clusters (vertices) is reached. Clusters are chosen for division based on the amount of normal variation on the surface in the cluster.</p><p>The R-Simp algorithm can be broken down into three stages.</p><p>• Initialization: In this stage we create global face (gfl) and vertex (gvl) lists, as well as vertexvertex and vertex-face adjacency lists. We also create the eight initial clusters.</p><p>• Simplification: In this stage the model is simplified. The simplification consists of four steps:</p><p>1. Choose the cluster that has the most face normal variation.</p><p>2. Partition (split) the cluster based on the amount and direction of the face normal variation.</p><p>3. Compute the amount of face normal variation in each of the sub-clusters.</p><p>4. Iterate until the required number of clusters (vertices) is reached.</p><p>• Post Processing: For each cluster that is left, compute a representative vertex (centroid). Retriangulate the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data structures</head><p>The principle data structure in this algorithm is the Cluster. It stores all the information necessary to determine face normal variation and to compute the representative vertex. It contains two arrays of indices, for vertices (vl) and faces (fl), that index into two global lists of the vertices and faces from the original model (gfl and gvl). The Cluster also contains the mean normal ( mn) that is the area-weighted mean of all the face normals in the cluster and is computed by Equation <ref type="formula">1</ref>.</p><formula xml:id="formula_1">mn = N i n i a i (1)</formula><p>where N is the number of faces in the cluster, n i is the normal of face i, and a i is the area of face i. The Cluster also holds the mean vertex (mv) for the cluster, the amount of normal variation (nv), and the total area of the faces in the cluster. Two other important data structures are the Face and the Vertex data structures which make up gfl and gvl respectively. The Face contains a list of vertices that make up the face, its normal, the face area, and its midpoint. The Vertex contains adjacency information for all the vertices and faces adjacent to it.</p><p>The vertices in the Face data structure are indices into gvl. The adjacency lists for the faces and the vertices in the Vertex data structure are also indices into gfl and gvl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Initialization</head><p>During the initialization stage gfl and gvl are constructed and the initial eight clusters are created. The initial clusters are created by partitioning the model using three axis aligned planes that are positioned in the middle of the model's bounding box. We then compute the amount of face normal variation in each of these clusters (see Section 5.3). These eight clusters are then inserted into a priority queue sorted by the amount of face normal variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Choosing the cluster to partition</head><p>In the simplification stage of our algorithm the first step is to choose a cluster in which the face normals vary the most (the cluster at the head of the queue). We compute the amount of face normal variation using the areaweighted mean ( mn) of the face normals.</p><p>The flatter the surface, the larger the magnitude of mn. If all the faces are coplanar, the magnitude of mn will equal the area of the surface in the cluster. We define this component cp of our face normal variation measure as follows:</p><formula xml:id="formula_2">cp = mn N i a i<label>(2)</label></formula><p>Even if the surface in a cluster is extremely small it can contain a large amount of curvature. In order to prevent small, highly curved details (e.g. a small spring in an engine) from dominating the simplification we must make our normal variation measure (nv ) sensitive to size. To do this, we scale cp by the ratio of the surface area in the cluster to the model surface area:</p><formula xml:id="formula_3">nv = N i a i M i a i (1 -cp)<label>(3)</label></formula><p>where M is the number of faces in the model. We complement cp so that nv increases as face normal variation increases. In the remainder of this paper the term "normal variation" refers to variation of face normals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Describing the pattern of normal variation</head><p>The next step is to describe normal variation in the chosen cluster. We follow Gersho and Gray <ref type="bibr" target="#b5">[6]</ref> who suggest principle component analysis (PCA) <ref type="bibr" target="#b11">[12]</ref> as a way of determining how to split cells when using a splitting algorithm. In PCA a covariance matrix is formed from the data set of interest. The eigenvectors of this matrix are aligned according to the pattern of variation in the data set. Garland <ref type="bibr" target="#b3">[4]</ref> showed that if the covariance matrix is formed with normal vectors, the eigenvectors are generally related to the principal directions of normal curvature. Specifically, the largest eigenvalue and corresponding eigenvector represent the mean normal of the surface.</p><p>Usually the second and third largest eigenvalues and corresponding eigenvectors represent the directions of maximum and minimum curvature. The covariance matrix A around the mean [0, 0, 0] is defined by:</p><formula xml:id="formula_4">A = N i n i n T i (4)</formula><p>We compute the eigenvalues and eigenvectors using the Jacobi method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Partitioning the cluster</head><p>Partitioning the cluster consists of four steps. First, we must determine how many planes to use to partition the cluster. Second, we must orient the planes. Finally, we must position the planes and create new sub-clusters.</p><p>A cluster is partitioned into two, four, or eight subclusters depending on the amount of curvature. Let c mn , c M and c m equal the eigenvalues in descending order (the second and third largest eigenvalues relate to k 1 and k 2 , the magnitudes of principle curvature). Let c M and c m represent the corresponding eigenvectors (these are related to the directions of maximum and minimum curvature).</p><p>If all eigenvalues are of similar magnitude the pattern of normal variation is unclear. We test for this by comparing the eigenvalues as follows: both c M &lt; 2c m and c mn &lt; 2c M must be true. In this case we partition the cluster into eight sub-clusters. One partitioning plane is perpendicular to c M , the second plane is perpendicular to c m , and the third plane is perpendicular to mn.</p><p>Otherwise, if c M cm &lt;= 4 then the surface is most likely hemispherical since there is significant curvature in both the minimum and maximum directions of curvature. In this case we partition the cluster into four sub-clusters. One partitioning plane is perpendicular to c M and the other plane is perpendicular to c m .</p><p>In all remaining cases c M cm &gt; 4 and the surface is most likely cylindrical since most of the curvature is in one direction. In this case we partition the cluster into two sub-clusters. The partitioning plane is perpendicular to c M .</p><p>We must now position the partitioning planes in the cluster. Ideally the surface should be partitioned along any ridges or through any elliptical bumps. However, locating such features is difficult, instead we do the following: first we compute the vector c M ⊥ , which is the projection of c M onto P mn , the plane defined by mn and the cluster's mean vertex (mv). We then project the midpoint of all the faces in the cluster onto P mn and find the mean of all projected midpoints that fall within 2.5 degrees of c M ⊥ . The resulting point is the position for the partitioning plane(s).</p><p>Sub-clusters are created by partitioning the vertices in a cluster. The membership of a vertex depends on which side of the partitioning plane(s) it falls on. The faces follow the vertices to the sub-clusters. A face may belong to two or three clusters if the vertices of the face fall into different sub-clusters.</p><p>Even if the entire model is topologically connected, a given cluster may contain two or more disconnected components. Approximating these components with a single vertex can introduce severe distortion. We have found it useful to perform a topology check to determine if a new cluster contains topologically disjoint components.</p><p>The topology check is a breadth first search on the vertices and edges contained in a cluster. We use a bit array to record the vertices visited during the search, making it linear in complexity. If the cluster contains disjoint components, each component is placed into a separate cluster. Although this topology check increases the overall simplification time, the resulting increase in quality of the simplification is considerable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Post processing</head><p>Once the simplification stage is finished two tasks remain. The first is to compute the location of the representative vertex (v) for each cluster. The second is to re-triangulate the output surface.</p><p>To represent a cluster's faces as accurately as possible, v should be as close as possible to all the faces. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref> all minimize the summed distance from the planes con-taining the cluster's faces. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14]</ref> minimize the squared distance:</p><formula xml:id="formula_5">Q(v) = v T Av + 2 b T v + c<label>(5)</label></formula><p>Where n i + d i = 0 is the plane equation for face i, A is as previously defined, b</p><formula xml:id="formula_6">= N i d i n i , and c = N i d 2 i . Since Q is a quadratic then Q(v)</formula><p>is minimum when its partial derivatives equal zero. This occurs when:</p><formula xml:id="formula_7">v min = -A -1 b T (6)</formula><p>We re-triangulate using a method similar to that used by <ref type="bibr" target="#b17">[18]</ref>. After v j is computed for each cluster, the v j s are output to a simplified vertex list svl. In gvl, all vertex references contained in (vl) of cluster j are pointed at the new entry in svl. We then traverse the global face list gfl. Any face referencing three different vertices in svl is retained and output to the simplified face list sfl. All other faces have degenerated into lines or points and are discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Simplification algorithms are usually judged by two criteria. The first criterion is speed, the time required to simplify a model. The second and more difficult to measure criterion is quality. Intuitively speaking, quality of a simplification is its appearance or its geometric accuracy.</p><p>In the following subsection we present execution times for two different input models. We also present quality results, including images allowing for comparison of appearance and geometric accuracy measured with the Metro [2] tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Performance</head><p>Five different models were used in our comparisons. All models were simplified on a 195 MHz R10000 SGI Onyx2 with 512 MB of main memory.</p><p>We compared R-Simp to two other simplification algorithms. We chose the fastest vertex clustering algorithm and the fastest vertex merge algorithm. The first is Rossignac and Borrel's <ref type="bibr" target="#b17">[18]</ref> vertex clustering algorithm (with unweighted centroid calculations). The second, QSlim <ref type="bibr" target="#b4">[5]</ref>, is one of the fastest vertex merge algorithms.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> compares the performance of R-Simp to QSlim and vertex clustering with the Stanford bunny. R-Simp is considerably faster than QSlim; it is able to produce a simplified model of up to 20000 polygons before QSlim removes a single face. R-Simp's complexity is O(n i log n o ) where n i is the input model size and n o is the output model size. Thus R-Simp is linear for a fixed output size. The speed of vertex clustering is not related to output size.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows how the size of the input model affects simplification time. The dragon was initially simplified using QSlim to various sizes. These models were then simplified by R-Simp, QSlim, and vertex clustering to 2100 polygons. As the graph shows, the larger the input model, the longer it takes to simplify. However, QSlim's curve is significantly steeper than R-Simp's. Vertex clustering is fastest but is affected by input size.</p><p>To compare model quality we took seven models and simplified them. Table <ref type="table" target="#tab_0">1</ref> summarizes the results. The table shows the mean Hausdorff distance between the original and the simplified surface as a percentage of the diagonal of the bounding box of the original surface <ref type="bibr" target="#b1">[2]</ref>.</p><p>Figures <ref type="figure" target="#fig_3">3a-h</ref> show the original bunny and dragon models and the corresponding simplifications produced by all three algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Discussion</head><p>As we noted earlier, in applications where the model is created in response to user input pre-computation is not possible. Models must be simplified at interactive rates. Applications that deal with extremely large models must ensure that the simplification algorithm is able to produce simplifications in reasonable time.</p><p>Algorithms useful for such applications should possess several characteristics:</p><p>• Interactive response: Most importantly, algorithms should be able to guarantee displayable results within a specified time limit. R-Simp's speed and coarse to fine pattern of simplification make it ideal for this application. Vertex clustering is even faster although precise control of execution time is difficult. Because QSlim is slower and simplifies from fine to coarse it cannot make any time guarantees.  • Control of output model size: Control of output model size is important if results are to be displayable. R-Simp and QSlim provide a straight forward way to control the output model size but most vertex clustering algorithms do not. In these algorithms one can only specify the number of voxels; the number of vertices and faces will typically be much smaller. Thus, if displayability is to be guaranteed, quality suffers.</p><p>• High output quality: Algorithms should output models of the best possible quality despite time constraints. QSlim clearly generates the best quality models. R-Simp's output quality is not as good, vertex clustering is worst.</p><p>• Iterative improvement: When time constraints require the output of a crude simplification, it should be possible to refine the result after the time demands have been met. R-Simp's coarse to fine pattern of simplification makes this fairly simple; one must only save the priority queue of clusters. With QSlim there is no need for refinement, the more important question is whether the time constraints could be met. Vertex clustering uses a one pass, one resolution approach and thus refinement is not possible.</p><p>• Continuous level of detail: Many interactive applications require level of detail hierarchies. Both R-Simp and QSlim are able to produce hierarchies but much of the hierarchy initially output by QSlim will not be displayable in interactive settings. Vertex clustering cannot produce hierarchies without fundamental changes to the algorithm.</p><p>• Scalability: Simplification algorithms need to scale gracefully so that they are able to handle extremely large models. QSlim's complexity is O(n log n) in input while R-Simp's is linear for a fixed output size.</p><p>To summarize, QSlim generates the best quality models but it is not suitable for interactive applications because it is too slow and cannot guarantee displayable results in a fixed time. Vertex clustering algorithms are extremely fast but generate poor quality models and do not provide an easy way to control output model size. We believe R-Simp's time guarantees and quality/speed tradeoff make it ideal for use in interactive applications. R-Simp can simplify any model, regardless of topology or manifold characteristics. In output it can simplify topology and thus does not guarantee topology preservation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future work and other applications</head><p>The quality of R-Simp's simplifications might be improved by adding a look-ahead feature, comparing the normal variation before and after the cluster split. It should also be possible to modify R-Simp to consider boundaries as well as face and vertex attributes (e.g. colour) during simplification. For large environments consisting of many objects, it should be possible to add a distance threshold to the topology check, so that disjoint but neighbouring objects remain in the same cluster and are merged.</p><p>To enable management of the quality/speed tradeoff, R-Simp might be used as part of a two stage simplification process. If speed is particularly important, vertex clustering could be used to simplify the model to a medium level of complexity and the result input to R-Simp. If quality is important, the output of R-Simp could be input to QSlim.</p><p>We have already discussed the use of R-Simp for level of detail hierarchies. The bounding box around the clusters in these hierarchies can be used to speed up collision detection. We have experimented with such bounding boxes as an error measure during simplification and found no loss in quality or speed. For view based level of detail control, the error measure should limit the distance between the simplified and original surfaces.</p><p>Since R-Simp simplifies in a coarse to fine direction, it should be well suited for application in progressive transmission of 3D models. Approximations of previously uncompressed models could be transmitted quickly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We presented R-Simp, an algorithm that simplifies 3D models in reverse and is well suited for interactive applications such as generation of iso-surfaces. Given a limited amount of time most other algorithms cannot guarantee displayable results or results of reasonable quality. R-Simp also allows iterative improvements, precise control of output size, and construction of level of detail hierarchies.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The effect of output model size on simplification time for the Stanford bunny.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The effect of input model size on simplification time. Output model size is 2100 polygons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visual results of the three simplification algorithms. (a) Original bunny 69451 faces. (b) Original dragon 871306 faces. (c)(e)(g) are 1900 faces. (d)(f)(h) are 2500 faces.</figDesc><graphic coords="8,345.24,536.43,133.93,110.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Simplification error and time of R-Simp, QSlim, and vertex clustering. The error is the mean surface deviation between two surfaces measured as a percentage of the sampling bounding box diagonal<ref type="bibr" target="#b1">[2]</ref>.</figDesc><table><row><cell>Model</cell><cell>Input</cell><cell>Output</cell><cell cols="2">Vertex Clustering</cell><cell></cell><cell>R-Simp</cell><cell>QSlim</cell></row><row><cell></cell><cell cols="3"># Faces # Faces Error</cell><cell cols="2">Time (s) Error</cell><cell>Time (s) Error</cell><cell>Time (s)</cell></row><row><cell>Bunny</cell><cell>69451</cell><cell>1600</cell><cell cols="2">0.302% 0.09</cell><cell cols="2">0.155% 1.58</cell><cell>0.071% 7.85</cell></row><row><cell>Cow</cell><cell>5782</cell><cell>1600</cell><cell cols="2">0.256% 0.03</cell><cell cols="2">0.118% 0.12</cell><cell>0.060% 0.45</cell></row><row><cell cols="3">Dragon 871306 2100</cell><cell cols="2">0.428% 0.29</cell><cell cols="2">0.241% 18.9</cell><cell>0.175% 129</cell></row><row><cell>Horse</cell><cell>96966</cell><cell>1600</cell><cell cols="2">0.266% 0.05</cell><cell cols="2">0.147% 2.29</cell><cell>0.052% 11.5</cell></row><row><cell>Chair</cell><cell>2481</cell><cell>800</cell><cell cols="2">0.658% 0.00</cell><cell cols="2">0.215% 0.05</cell><cell>0.019% 0.17</cell></row><row><cell>Torus</cell><cell>20000</cell><cell>400</cell><cell cols="2">0.460% 0.05</cell><cell cols="2">0.265% 0.32</cell><cell>0.160% 1.74</cell></row><row><cell>Spring</cell><cell>9386</cell><cell>800</cell><cell cols="2">1.012% N/A</cell><cell cols="2">0.594% 0.13</cell><cell>0.295% 0.75</cell></row><row><cell>Mean</cell><cell></cell><cell></cell><cell cols="2">0.483% 0.09</cell><cell cols="2">0.242% 3.34</cell><cell>0.119% 21.6</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Oleg Verevka for suggesting the comparison of quantization to model simplification and Carolina Diaz-Goano for her mathematical assistance. We are grateful to Alex Brodsky for all his helpful and insightful comments and to Greg Turk for his comments, geometry filters, and models. This research was supported by an NSERC grant: RGPIN203262-98.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mesh simplification</title>
		<author>
			<persName><forename type="first">Maria-Elena</forename><surname>Algorri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Schmitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="77" to="C86" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metro: measuring error on simplified surfaces</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cignoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rocchini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scopigno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Istituto per l&apos;Elaborazione dell&apos;Infomazione -Consiglio Nazionale delle Ricerche</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simplifying polygonal models using successive mappings</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinesh</forename><surname>Manocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Olano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization&apos;97</title>
		<meeting>IEEE Visualization&apos;97</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="395" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Quadric-Based Polygonal Surface Simplification</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Garland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Surface simplification using quadric error metrics</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Heckbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 97 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Vector Quantization and Signal Compression</title>
		<author>
			<persName><forename type="first">Allen</forename><surname>Gersho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Voxel-based object simplification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Taosong He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization&apos;95</title>
		<meeting>IEEE Visualization&apos;95</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="296" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Survey of polygonal surface simplification algorithms</title>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Heckbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Garland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Draft Version</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Geometric optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hinker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization&apos;93</title>
		<meeting>IEEE Visualization&apos;93</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="189" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Progressive meshes</title>
		<author>
			<persName><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 96 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mesh optimization</title>
		<author>
			<persName><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Duchamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mc-Donald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werner</forename><surname>Stuetzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIG-GRAPH 93 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<title level="m">Principle Component Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Superfaces: Polygonal mesh simplification with bounded error</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">D</forename><surname>Kalvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><forename type="middle">H</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and memory efficient polygonal simplification</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lindstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization&apos;98</title>
		<meeting>IEEE Visualization&apos;98</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Model simplification using vertex-clustering</title>
		<author>
			<persName><forename type="first">Kok-Lim</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiow-Seng</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1997 Symposium on Interactive 3D Graphics</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="75" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">O'</forename><surname>Barret</surname></persName>
		</author>
		<author>
			<persName><surname>Neill</surname></persName>
		</author>
		<title level="m">Elementary Differential Geometry</title>
		<meeting><address><addrLine>New York, New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press Inc</publisher>
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Full-range approximation of triangulated polyhedra</title>
		<author>
			<persName><forename type="first">Remi</forename><surname>Ronfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarek</forename><surname>Rossignac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="67" to="C76" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>C</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-resolution 3D approximations for rendering complex scenes</title>
		<author>
			<persName><forename type="first">Jarek</forename><surname>Rossignac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Borrel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modeling in Computer Graphics: Methods and Applications</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lodestar: An octree-based level of detail generator for VRML</title>
		<author>
			<persName><forename type="first">Dieter</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VRML 97: Second Symposium on the Virtual Reality Modeling Language</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Decimation of triangle meshes</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">A</forename><surname>Zarge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Re-tiling polygonal surfaces</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="55" to="64" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
