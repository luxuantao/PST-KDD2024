<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding WeChat User Preferences and &quot;Wow&quot; Diffusion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xueyi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai</forename><surname>Zhuang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leyu</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Santa</forename><surname>Claus</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Victoria</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abby</forename><surname>Sunny</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Yanyan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Health Everyday Mingming</orgName>
								<address>
									<addrLine>Haoran Wang</addrLine>
									<settlement>Zihan, Aliya, Shine, Wei Zhang</settlement>
									<region>Victoria, Sunny</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding WeChat User Preferences and &quot;Wow&quot; Diffusion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Social Networks</term>
					<term>Social Influence</term>
					<term>Information Diffusion</term>
					<term>User Behavior</term>
					<term>User Modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>WeChat is the largest social instant messaging platform in China, with 1.1 billion monthly active users. "Top Stories" is a novel friend-enhanced recommendation engine in WeChat, in which users can read articles based on preferences of both their own and their friends. Specifically, when a user reads an article by opening it, the "click" behavior is private. Moreover, if the user clicks the "wow" button, (only) her/his direct connections will be aware of this action/preference. Based on the unique WeChat data, we aim to understand user preferences and "wow" diffusion in Top Stories at different levels. We have made some interesting discoveries. For instance, the "wow" probability of one user is negatively correlated with the number of connected components that are formed by her/his active friends, but the click probability is the opposite. We further study to what extent users' "wow" and click behavior can be predicted from their social connections. To address this problem, we present a hierarchical graph representation learning based model DiffuseGNN, which is capable of capturing the structure-based social observations discovered above. Our experiments show that the proposed method can significantly improve the prediction performance compared with alternative methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>I NFORMATION diffusion [33] has increasingly changed from offline to online these years. There emerge many popular social applications, such as "News Feed" in Facebook and "Top Stories" in WeChat, which facilitate information diffusion greatly. Central to information diffusion are the user trait and the social influence between users, which have attracted many researchers working on it <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b45">[46]</ref>. Despite popular applications and extensive studies of information diffusion algorithms, it is still unclear about the inherent factors that result in different types of user feedback. First, how can user attributes, the correlations between users, and the local network structure influence user behavior? Second, what are the differences between various kinds of user feedback (such as "click", "like", and "share") w.r.t. the above factors? Such problems are still largely unexplored and far from understood. If she/he also "wow"s one article, it will be displayed to (only) her/his friends, which forms a diffusion process. Here "active friends" means friends who "wow"ed the corresponding articles.</p><p>In this work, we study the "Top Stories" service in WeChat -the largest social instant messaging platform in China -to understand user behavior in the specific social context. In Top Stories, a user can see the articles "wow"ed by her friends, which can be regarded as share plus like, and she can perform a "wow" or click action on each article as well. An illustrative example of WeChat's Top Stories service is shown in Figure <ref type="figure" target="#fig_0">1</ref>, in which each user is shown articles that her friends "wow"ed as well as those friends' names, and she can click on the articles or also "wow" them. Herein, we aim at understanding users' "wow" and click behavior from different aspects, including user demographics, dyadic and triadic correlations, and users' ego network structures.</p><p>The problem in this paper is related to social influence locality <ref type="bibr" target="#b49">[50]</ref>, which targets quantifying how user behavior is influenced by other users in ego networks, and is more broadly related to social influence <ref type="bibr" target="#b37">[38]</ref> and information diffusion <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b33">[34]</ref>. Most methods address the social influence locality problem by using hand-crafted user features and network features to predict user behaviors <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b49">[50]</ref>. Recently, Qiu et al. <ref type="bibr" target="#b30">[31]</ref> propose to use graph attention networks (GAT) to learn user proximity in ego networks. Wang et al. <ref type="bibr" target="#b43">[44]</ref> further consider topological features via the Weisfeiler-Lehman (WL) algorithm <ref type="bibr" target="#b6">[7]</ref> to predict user behavior for in-feed advertising. However, they haven't dug into studying potential factors in different granularities, such as user demographics and ego network properties, based on which better prediction models can be designed.</p><p>Through the study, we first reveal several intriguing discoveries that impact user behavior at different levels. Based on these discoveries, we develop a unified framework to predict users' "wow" and click behavior by modeling user attributes, dyadic correlations, and ego network structures together.</p><p>To highlight several of our key findings, for user demographics, we find that users' "wow" and click behavior vary by gender and age, and the patterns become complicated when cross-attribute factors are considered. For dyadic correlations, users are likely to behave differently when their active friends are structural holes and opinion leaders. Considering ego network properties, both "wow" probability and click probability are strongly correlated with the number of connected components formed by users' active friends, but they have the opposite patterns. This correlation becomes stronger when the ego network is cleaned.</p><p>Based on these interesting discoveries, we further study to what extent users' behavior can be predicted from their social connections and attributes. To this end, we propose a hierarchical graph representation learning based model called DiffuseGNN. Our model is closely related to and motivated by the insights from data, which is different from many neural network based methods. Specifically, first, to model cross-attribute factors for users' different attributes as the analysis in Section 3.1 (such as user embeddings and demographics), we adopt the factorization machine technique to generate second-order features to model feature interactions for each individual. Second, to remove noise in the ego networks as shown in the Section 3.3 analysis, Dif-fuseGNN propagates initial user features in the modulated spectral domain, to generate user embeddings based on cleaned ego networks. Third, to model dyadic correlations as the analysis in Section 3.2 shows, we adopt a new graph attention mechanism to model feature interactions between neighbors. Fourth, to model the connected componentsthe hierarchical structure of the ego networks as in the Section 3.3 analysis, we generate hierarchical representations of ego networks by clustering nodes together and learning on the coarsened graphs iteratively. We evaluate the proposed method on a WeChat Top Stories dataset and a public Weibo dataset. Our experiments show that the proposed solution can consistently outperform alternative methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND -TOP STORIES DATASET</head><p>Different from other news feed systems, Top Stories in WeChat recommend to a user articles favored ("wow"ed) by her/his friends. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, the articles recommended to the current user are two articles favored by her active friends. The user can choose to click the "wow" button so that her friends will also be informed of her choice. In this way, the "wow" essentially plays an implicit diffusion role. On the other hand, the user can also click to view the full content of the article, or simply ignore it. The dataset used in this paper is a subset of data sampled randomly from Top Stories. The approval from users were developed prior to the start of data collection. It consists of three parts: 1) a social network G = {U, E}, where U is a set of users, and E represents a set of edges recording friendships between users; 2) user attributes C including users' gender, age, regions, and so on; and 3) the interaction between users and articles L = {(u, d, ts, is_like, is_click, af (u, d, ts))|u ∈ U, d ∈ D}, where u is the ego user, d is a displayed article in article set D, ts is the timestamp, is_like and is_click are whether u "wow"s and clicks d, af (u, d, ts) is u's active friends who "wow"ed d before timestamp ts. Note that an interaction can be represented by a triplet (u, d, ts). To avoid overfitting, we further select a subset of the data by first extracting users who performed at least ten interactions ("wow" or click), and then extracting these users' friendship networks and their attributes. The final dataset contains 48,084,772 users, 61,252,317 articles, and 7,459,660,092 interactions. All data are preprocessed via data masking to protect user privacy.</p><p>To start with our analysis, we first introduce several definitions which will be used later. Definition 2.1. Connected Components (CC) 1 . In graph theory, a connected component of an undirected graph G is an induced subgraph in which any two vertices are connected to each other by paths, and which is connected to no additional vertices in the rest of the graph. We let CC denote the acronym of connected components and #CC denote the number of connected components in a graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.2. Structural Hole (SH) [2].</head><p>A "structural hole" is a term for recognizing a missing bridge in a graph. Wherever two or more groups fail to connect, one can argue that there is a structural hole, a gap waiting to be filled. We let SH denote the acronym of structural hole. Definition 2.3. Ego network and τ -ego network. Ego network G u = {U u , E u } is a subgraph of a static social network G centered at the focal node ("ego"), where U u is the node set consisting of the ego and its first-order neighbors, E u is the edge set containing edges between nodes in U u in the original graph G. τ -ego network G τ u = {V τ u , E τ u } is a subgraph induced by u and u's τ -degree friends, V τ u is the node set of the subgraph G τ u and E τ u is the edge set of G τ u .</p><p>1. https://en.wikipedia.org/wiki/Component_(graph_theory) Definition 2.4. Active Friends. In this article, we define active friends as the friends who performed "wow" action on an article. In WeChat Top Stories, if a user "wow"ed an article, his/her friends will be informed about it. However, users' click behavior will not be shown directly to friends. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, the names shown below the articles are the friends who performed a "wow" action. Definition 2.5. Active Rate. We define "active rate" to refer to both "wow" probability and click probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ANALYSIS AND DISCOVERIES</head><p>Based on abundant user behavior data in Top Stories, we investigate how users' "wow" and click behavior correlates with three aspects: (1) user demographics, (2) dyadic and triadic correlations, and (3) ego network properties. Next, we present these analysis results one by one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">User Demographics</head><p>Table <ref type="table" target="#tab_0">1</ref>, Figure <ref type="figure">2</ref>, and Figure <ref type="figure">3</ref> show the probability that people of different gender and age "wow" or click articles in Top Stories. From Table <ref type="table" target="#tab_0">1</ref>, we observe that males' click probability is clearly higher than females', while females' "wow" probability is a little bit higher than males'. The reason might be that males tend to consume content, but females are more active in social circles. Regarding age, the patterns are very interesting. According to our intuition, young generations (users in their 20s and 30s) are the most active users in our online social circles. However, in Figure <ref type="figure">2</ref>, the "wow" and click probability of the 20s and 30s is the lowest among all ages. We infer that young people might be too busy to look at the articles in detail, or their "reverse psychology" reacts to the recommended articles.</p><p>Moreover, when we consider both gender and age attributes, the patterns become different again. In Figure <ref type="figure">3</ref>, we find that for people younger than 20, males are more active than females. However, there is a reversion for both "wow" and click behavior, but at different split points (the 40s for "wow" and the 60s for click), indicating that older female users are more active than older male users. The  result demonstrates that the cross-attribute factor is more complicated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dyadic and Triadic Correlations</head><p>In this subsection, we consider dyadic and triadic correlation factors. To eliminate other influence factors, we consider interactions with only one friend who "wow"ed the article for dyadic correlations, and exactly two active friends for triadic correlations. We analyze these correlations from two views: demographic attributes and social roles.</p><p>Dyadic Correlations w.r.t. Demographic Attributes. Table <ref type="table">2</ref> shows the users' active rate concerning dyadic correlations between ego users' gender and friends' gender. We observe that for click behavior, when friends' gender is the same as ego users', the ego users' click probability is higher, which can be explained by the homophily of their interests. However, for "wow" behavior, users are more likely to "wow" an article when their active friends are females. In view of ages, Figure <ref type="figure">4</ref> visualizes users' "wow" probability w.r.t. dyadic correlations between users' ages and friends' ages. We have several interesting discoveries. First, when users are young (&lt; 40 years old), they are more influenced by their older friends than friends of the same age group. Second, older users are highly influenced by their friends of the same age group. Meanwhile, they also care about what young generations "wow"ed, which shows cross-generation care, such as parents to children, managers to subordinates, etc. The pattern of click behavior is omitted here since it is similar to that of "wow" behavior.</p><p>Talking about the region, we also consider the distance between users and their friends (incorporating users' re-  gions). Table <ref type="table" target="#tab_2">3</ref> shows the users' active rate w.r.t. the distance between the user and the active friend. We see that when the geographic distance between the ego user and the friend is closer, the "wow" probability and click probability of the ego user is higher, which shows the existence of interest homophily w.r.t. user region.</p><p>Dyadic Correlations w.r.t. Social Roles. We also study dyadic correlations between users' social roles and friends' social roles. Here social roles refer to users' roles in the social network or "wow" diffusion network. Table <ref type="table" target="#tab_3">4</ref> shows the users' active rate w.r.t. dyadic correlations of different social roles: opinion leaders (OL) and ordinary users (OU). We find opinion leaders in social networks by running the PageRank algorithm <ref type="bibr" target="#b27">[28]</ref> on the user diffusion network and then regard users with top 1% PageRank scores as opinion leaders. Surprisingly, we find users' "wow" and click probability is higher when their active friends are not opinion leaders. For "wow" behavior, the reasons might be that if an opinion leader has "wow"ed one article, the ego user is less willing to publicize it because many users connected to opinion leaders probably have already known it. For click behavior, we think perhaps users browse Top Stories mainly for recreation, as WeChat is a social instant messaging platform for friends and acquaintances. Therefore, users might care more about what similar friends are interested in, rather than what opinion leaders pay attention to. Table <ref type="table" target="#tab_4">5</ref> also shows the users' active rate w.r.t. dyadic correlations of different social roles: structural holes (SH) and ordinary users (OU). Here we find cut points in the users' friendship network using the Tarjan <ref type="bibr" target="#b40">[41]</ref> algorithm to approximate structural hole users. Clearly, users' "wow" behavior is highly influenced when their friends are structural  holes, which demonstrates that structural holes are critical in the information diffusion process. Also, the "wow" and click probability of ordinary users is higher if their active friends are structural holes. For users who are structural holes, their click probability is higher when their friends are not structural holes, but the difference is not very significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Triadic Correlations w.r.t. Demographic Attributes.</head><p>Here we study how triadic correlations -more complex factors -would influence ego users' behavior. For triadic correlations, we consider interactions with exactly two friends who "wow"ed the article. We analyze the demographics (gender, age, and region) of ego users and their friends.</p><p>Figure <ref type="figure" target="#fig_2">5</ref> shows the users' active rate with respect to the triadic correlations between the ego user's gender and his/her two friends' gender. From the figure, we observe consistent patterns of "wow" and click behaviors. If the two friends' gender is the same as the ego user's gender, the ego users' active rate is the highest. Again, this implies a high degree of gender homophily.</p><p>Furthermore, Figure <ref type="figure">6</ref> shows the users' active rate w.r.t. the difference between the ego user's age and the two friends' ages. We discover that if one friend is of the same age group and the other friend is younger than the ego user, the active rate of the ego user is high. Furthermore, the color in the left top is darker than that of the right bottom, which demonstrates that old users pay more attention to young users compared with young users attending to old users.</p><p>Additionally, Figure <ref type="figure">7</ref> shows the users' active rate w.r.t. the distance between the ego user and the two active friends. Our intuition is that if the distance between the ego user and her two friends is closer, the ego users' active rate can be higher. However, actually, if one friend is nearby, and the other friend is more distant from the ego user, the ego user will be more active. This kind of "attribute diversity" may provide evidence that the "wow"ed articles are acknowledged by various users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ego Network Properties</head><p>In this subsection, we study the correlation between users' activity and their ego network properties. To be precise, the ego network is defined as the induced subgraph of users' active friends. We find that users' online behaviors (click and "wow") are strongly influenced by their friend circles (users in their ego networks). We study ego network properties from three aspects: the number of friends in the ego network, the number of connected components (#CC) in the ego network, #CC in the cleaned ego network (k-core subgraph).</p><p>The Number of Friends in the Ego Networks. Figure <ref type="figure" target="#fig_5">8</ref> shows how a user's "wow" and click probability on an article changes when the number of active friends increases. We define the ratio of active friends by dividing a predefined maximum number of friends into the actual number of friends. It demonstrates two very different patterns w.r.t. the two behaviors. For "wow" behavior, with the number of active friends increasing, the probability that the user "wow"s an article also increases roughly linearly, while for click behavior, the probability first fluctuates a little, and then decreases clearly after the ratio of one's active friends increases to 0.4. The phenomenon could be explained by  information overload -when the number of one's active friends is large, the user may have many other channels from these friends to learn about the information, such as "Moments" or "Subscriptions" (the first is reading articles posted by friends and the other is reading articles of subscribed accounts), resulting in loss of interest in clicking it <ref type="bibr" target="#b8">[9]</ref>. For "wow" behavior, the pattern is consistent with our intuition that people may continue to share the hot spots to let more and more people care about them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Number of Connected Components (#CC) in the Ego</head><p>Network. Following the above, we conduct another deep analysis, named structural diversity <ref type="bibr" target="#b41">[42]</ref>, to study how the topological structure of one's active friends would influence the user's behavior. Figure <ref type="figure">9</ref>(a) plots the probability of a user's behavior w.r.t. the number of connected components (#CC) of her/his active friends. Here, each connected component can be viewed as a specific group of friends (connected by friendships among them). The pattern is very interesting. When the total number of active friends on an article increases, users are more likely to spread the article (see Figure <ref type="figure" target="#fig_5">8</ref>). However, when fixing the number of active friends, ranging from 2 to 7, the probability decreases with the increase of the number of connected components (#CC) (see Figure <ref type="figure">9(a)</ref>). This confirms the structural diversity analysis in sociology <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b49">[50]</ref>, which suggests that the user's interest in sharing a piece of information will decrease when she/he notices that the information has already been shared by multiple different groups of friends, since there isn't much benefit for growing the user's influence when many people have shared it. For click, it is totally different -when a user notices that multiple different groups of his/her friends have read an article, her/his probability of reading the articles will quickly increase. If many friends from different circles have "wow"ed one article, the article is probably of high quality and has a broad audience, so the user is attracted to read it.</p><p>#CC in the Cleaned Ego Network. Although one can have many active friends who "wow"ed an article, different friends may influence the ego user to a different extent. For example, it is possible that friend O and the ego user became friends by chance, but they are not familiar with each other. Thus, O is an outlier in the ego network who doesn't connect to other friends of the ego user. In this case, including friend O in the ego network may introduce noise. Thus, we want to first obtain the cleaned ego network, and then analyze the correlation between its structure and the ego user's activity. To obtain the cleaned ego network, we  <ref type="figure">9</ref>. Social influence analysis: the probability that the user "wow"s or clicks an article conditioned on the number of connected components of (cleaned) ego networks formed by active friends.</p><p>extract the 1-core subgraph of the ego network formed by active friends, where 1-core means the node in the subgraph needs to have at least one edge with other nodes. In this way, outliers are removed from the ego networks. Figure <ref type="figure">9</ref>(b) plots the probability of a user's behavior w.r.t. #CC of one's 1-core subgraph of the ego network formed by active friends. Note that 1-core ensures the connectivity of nodes in the subgraph, so some combinations of (#Friends, #CC) pairs don't exist, such as 7 friends with 7 CC. Comparing Figure <ref type="figure">9</ref>(b) with Figure <ref type="figure">9</ref>(a), we can see that when fixing the number of active friends (such as 7), the speed of increase or decrease of "wow"/click probability w.r.t. #CC in Figure <ref type="figure">9</ref>(b) is obviously faster. Such a difference shows that the structural topology of cleaned ego networks probably gives a better discriminative ability to predict ego users' activity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Summaries</head><p>From the above analysis, we have the following discoveries:</p><p>• Males are more likely to click but less likely to "wow" articles than females. Counterintuitively, the young generations (people in their 20s and 30s) have the lowest active rate in Top Stories. • For dyadic or triadic correlations, there exists interest homophily between users and friends (such as about gender), but attribute diversity (such as region) also positively correlates with users' activity when there is more than one active friend. • According to ego network topology, the patterns of "wow" and click behavior are very different. For instance, when fixing the number of active friends, users' "wow" probability is negatively correlated to #CC formed by active friends, but for click behavior, it is the opposite. The patterns can be more significant when the ego network is cleaned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PREDICTIVE MODEL</head><p>Can we leverage the discovered patterns to predict users' online behaviors? In this section, we first briefly formulate the problem and then present our prediction framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Problem Formulation</head><p>Let G τ u = {V τ u , E τ u } be user u' s τ -ego network where τ -ego network is a subgraph induced by u and u's τdegree friends, V τ u is the node set of the subgraph G τ u and E τ u is the edge set of G τ u . The attribute matrix of users in</p><formula xml:id="formula_0">V τ u is denoted as C τ u .</formula><p>When user u is displayed with an article d "wow"ed (shared) by some friends at timestamp ts, we denote an action status of user u's ego-network as S (u,d,ts) = {s (v,d,ts) ∈ {0, 1}|v ∈ V τ u \ {u}}, where s (v,d,ts) is the action status of user v w.r.t. article d before timestamp ts, here 0 means inactive and 1 means active (both denoting "wow" behavior). Our goal is to quantify the "wow" and click probability of ego user u after timestamp ts:</p><formula xml:id="formula_1">P (s (u,d,&gt;ts) |G τ u , S (u,d,ts) , C τ u )<label>(1)</label></formula><p>Since we analyze two different behaviors (click and "wow") of users, a straightforward idea is to leverage the correlation between click and "wow" to design a joint prediction model (like multi-task learning). However, there is no evident correlation between click and "wow" in our training set. According to our statistics, P (is_click u = 1) ≈ P (is_click u = 1|is_wow u = 1), which means that the two behaviors are almost independent. Thus, we choose to learn independent models for predicting the two behaviors. In the following, we will illustrate our model framework in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The DiffuseGNN Framework</head><p>In this subsection, we present our proposed model framework DiffuseGNN as illustrated in Figure <ref type="figure" target="#fig_7">10</ref>. The core model components and the basic idea are as follows: (1) For input user features, we consider various user features such as user demographics (gender and age) and pre-trained user embeddings, and try to model feature interactions as the analysis in Section 3.1. (2) We then learn user embeddings by propagating initial features in a trainable modulated spectral domain, by which the learned user embeddings can capture useful information in ego networks and filter out noise, which is motivated by the analysis in Section 3.   Preprocessing Ego Networks. As the τ -ego network can be very large in such a dense social network, especially for users with large degrees, we adopt a sampling strategy to sample a subset of users from one's ego-network. In this work, we use Breadth-First Search (BFS) to generate a fixed-size ego network for each user/interaction due to its effectiveness and efficiency. In detail, we first add the ego user and active friends into the ego network in order. The added order of active friends is determined by their active ("wow") timestamp. Then the friends of users in the current ego networks are added by performing BFS iteratively. Note that Qiu et al. <ref type="bibr" target="#b30">[31]</ref> use Random Walk with Restart (RWR) <ref type="bibr" target="#b13">[14]</ref> to generate sampled ego networks. However, information diffusion in WeChat is very localized (users can only see articles their friends "wow"ed); thus, BFS is more suitable than RWR in this case. Finally, we perform BFS in users' 2-ego networks (τ = 2). We set the number of nodes in each sampled ego network to m. The adjacency matrix of the generated ego network for each instance is denoted as A (u,d,ts) (here an instance refers to an interaction between user u and article d before timestamp ts). We omit subscripts (u, d, ts) in the following description if there is no ambiguity.</p><p>Input Layer. We consider various types of input features for each user, as listed in Table <ref type="table" target="#tab_6">6</ref>. First, the input layer covers customized user features, such as demographic and social role features. Second, we also consider two-dimensional contextual features for each user to indicate active status and positions in the ego network, in which one is whether the user "wow"ed the corresponding article, and the other is whether the user is an ego user <ref type="bibr" target="#b30">[31]</ref>. Third, we consider pre-trained user embeddings. Although we study user behavior prediction in the ego network, it would be beneficial to capture user structure information in the global social network. Thus, we first pre-train user embeddings in the friendship network. Many network representation learning methods have been proposed to learn node representations in a graph <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b48">[49]</ref>. We adopt ProNE <ref type="bibr" target="#b48">[49]</ref> to pretrain user embeddings in the friendship network, due to its high efficiency and effectiveness, which could take a relatively short time to generate node embeddings of billionscale graphs, and is effective in capturing global information by propagating embeddings in the spectrally modulated domain.</p><p>The above mentioned features can be regarded as firstorder user features. Motivated by the analysis in Subsection 3.1, the cross-attribute factor might also take effect. Thus, we adopt the factorization machine technique to model feature interactions. We generate second-order features by first mapping different features into the same space, and then calculate the second-order feature interactions as follows:</p><formula xml:id="formula_2">X 2nd = 1 2 (( F i=1 W i x (i) ) 2 − F i=1 (W i x (i) ) 2 )<label>(2)</label></formula><p>where x (i) is i-th user feature, W i is the feature projection matrix of feature x (i) and F is the number of different features. Here the cross-terms indicate the interactions between different features. Finally, we concatenate all the first-order features {x (i) } F i=1 and the second-order feature X 2nd to form input feature X.</p><p>Feature Smoothing Layer. Pre-trained user embeddings only capture the global network structure. Users residing in different ego networks may play different roles. Thus, they should have different representations in different ego networks. We propose a feature smoothing method via graph filters, which can fine-tune user embeddings X via cleaned ego network structures. The output of this step is X l0 by propagating X in the modulated spectral domain of ego networks.</p><p>In graph theory, the random walk normalized graph Laplacian is defined as L = I m − D −1 A, where A is the adjacency matrix of the ego network, m is the size of each ego network, I m is the identity matrix, and D = j A ij . The normalized Laplacian can be decomposed as L = U ΛU , where Λ = diag[λ 1 , λ 2 , ...λ m ]. In spectral graph theory, small (large) eigenvalues in a graph Laplacian control the network's global clustering (local smoothing) effect, which motivates us to capture useful information of ego networks in the spectral domain. The global clustering (local smoothing) effect means how well a graph can be partitioned into a small (large) number of clusters, so that nodes in different clusters are less connected, while nodes in the same clusters are densely connected. The smaller the j-th eigenvalue λ j is, the better partition effect it would achieve for dividing into j clusters <ref type="bibr" target="#b48">[49]</ref>. Thus we employ a graph filter g to adjust the eigenvalues of the Laplacian.</p><formula xml:id="formula_3">L = U diag([g(λ 1 ), g(λ 2 ), ..., g(λ m )])U (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where L is the modulated Laplacian and g is the spectral modulator. We propagate the initial node embeddings in the spectral domain via modulated Laplacian as follows:</p><formula xml:id="formula_5">X l0 = D −1 A(I m − L)X (4)</formula><p>where X l0 is the user embedding matrix modulated in the spectral domain. Here I m − L is the spectral modulator of the normalized adjacency matrix D −1 A. In this paper, we adopt the graph filter as follows:</p><formula xml:id="formula_6">g(λ) = e − 1 2 [(λ−µ) 2 −1]θ<label>(5)</label></formula><p>where g can be considered an adjustable band-pass filter kernel (see Figure <ref type="figure" target="#fig_7">10</ref>) with µ ∈ [0, 2]. It passes or enlarges eigenvalues within a certain range and filters out other values, thus reducing the noise or redundant information.</p><p>To avoid explicit eigendecomposition and Fourier transform, we use the same trick as in <ref type="bibr" target="#b48">[49]</ref> to approximate g with a Chebyshev expansion and Bessel function <ref type="bibr" target="#b0">[1]</ref>. In our model, we set µ as a trainable parameter. Thus it can be adaptively learned for different datasets.</p><p>Hierarchical Graph Representation Learning. As we analyze above, the ego user's activity is strongly correlated to the number of connected components of her ego-network formed by active friends (neighbors). Our idea here is to design a hierarchical representation learning method to encode the substructures of ego networks. Substructures, such as connected components, can be regarded as high-level structural patterns, which motivates us to cluster similar nodes iteratively to encode these substructures. The goal of this step is to generate high-level ego network representation Z l k at iteration k. We employ graph neural networks (GNN) <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b46">[47]</ref> as basic modules to learn graph representation.</p><p>In detail, we first generate node embeddings of the entire ego networks via a GNN <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b42">[43]</ref> module. The input user embeddings are from the learned user embeddings via graph filters described above.</p><formula xml:id="formula_7">Z l1 = GNN 0,embed (A l0 , X l0 ) (6)</formula><p>where Z l k is the hidden node embedding of layer l k , A l0 is the adjacency matrix of ego networks, and X l0 is the input node features. In order to generate coarsened graphs to represent graph substructures, following DIFFPOOL <ref type="bibr" target="#b46">[47]</ref>,</p><p>we learn an assignment matrix B l k+1 via another GNN,</p><formula xml:id="formula_8">B l k+1 = softmax(GNN k,pool (A l k , X l k ))<label>(7)</label></formula><p>where</p><formula xml:id="formula_9">B l k+1 ∈ R m k ×m k+1 (m k+1 &lt; m k , m 0 = m) and b l k+1 ij</formula><p>represents the probability of assigning node i to j-th clusters in (k + 1)-th assignment layer . With assignment matrix B l k , an ego network can be transformed into a smaller graph iteratively, in which each node represents a "cluster".</p><formula xml:id="formula_10">X l k = B l k Z l k ∈ R m k ×h k (8) A l k = B l k A l k−1 B l k ∈ R m k ×m k (9)</formula><p>where X l k is the cluster embeddings, and A l k is the coarsened adjacency matrix which denotes the connectivity strength between pairwise clusters. Based on the coarsened graph, the coarse-level node embeddings can be generated by</p><formula xml:id="formula_11">Z l k+1 = GNN k,embed (A l k , X l k ) (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>We generate different levels of (sub)graph embeddings by pooling operations on node embedding matrices, and then concatenate them to form the final representations of ego networks,</p><formula xml:id="formula_13">Z graph = L k=1 σ(Z l k )<label>(11)</label></formula><p>We set σ in Eq. 11 as a dimension-wise max-pooling operation or sum-pooling to transform node embedding matrix into graph embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic GNN modules.</head><p>As for GNN modules in Eq. 6, Eq. 7 and Eq. 11, we argue that GAT <ref type="bibr" target="#b42">[43]</ref> is suitable, since it can learn the attention weights of neighboring nodes with their node features. GAT learns the attention weight between node i and node j as follows:</p><formula xml:id="formula_14">α AA ij = exp(act(a src W p x i + a dst W p x j )) t∈Ni exp(act(a src W p x i + a dst W p x t ))<label>(12)</label></formula><p>where N i is the neighbors of node i, x i is the hidden embedding of node i, W p is the feature projection matrix, a src and a dst are attention parameter, and act is the LeakyReLU activation function. As shown in Eq. 12, GAT uses additive attention (AA). However, the attention mechanism used in GAT doesn't consider feature interactions between neighboring nodes. Thus, we employ a simple modification over Eq. 12:</p><formula xml:id="formula_15">α DA ij = exp(act((a src W p x i + b src ) • (a dst W p x j + b dst ))) t∈Ni exp(act((a src W p x i + b src ) • (a dst W p x t + b dst )))<label>(13)</label></formula><p>where b src and b dst are bias terms. We term this attention Dot attention (DA). As shown in Eq. 13, the cross terms model feature interactions of neighboring nodes. We denote our model using GAT modules as DiffuseGNN AA and the model using dot attention as DiffuseGNN DA .</p><p>Output Layer. Finally, we let the ego network embedding Z graph pass into fully connected layers to generate the prediction scores, which are used to compare with the groundtruth "wow"/click labels. We use the cross-entropy loss as our objective function. The prediction function at the output layer and the loss function are described in Eq. 14 and Eq. 15, respectively, where f c pred represents the fully-connected layers, y i pred denotes the action probability of instance i, and y i is the ground-truth of instance i.</p><formula xml:id="formula_16">y pred = f c pred (Z graph )<label>(14)</label></formula><formula xml:id="formula_17">L = − N i=1 (y i × log(y i pred ) + (1 − y i ) × (1 − log(y i pred )))<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>When users' click and "wow" behaviors are concerned, it is natural to take into account the article content. If we further consider articles, the problem is highly related to social recommendation. However, the main focus of this article is user behavior prediction based on user demographics, correlations between users, and ego network properties, which is related to the problem of social influence locality, so we exclude article information to make the problem clear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We present the effectiveness of our model on users' "wow" and click behavior prediction of WeChat Top Stories, and also a publicly available Weibo dataset. The codes are publicly available. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setup</head><p>Datasets. We mainly evaluate our model on the collected WeChat Top Stories dataset. further verify the generalization ability of our method, we also choose a publicly available Weibo dataset for evaluation. For WeChat Top Stories dataset, we randomly sample a subset of data to evaluate our proposed method. To effectively model the influence of users' friend circles on users' online behaviors, we only consider interactions with at least five friends having "wow"ed the articles. After filtering out data, we select all positive instances, in which there are 3,163,171 "wow" instances, 2,181,279 click instances, which result in 5,121,571 positive instances in total. We also sample a subset of negative instances randomly to keep the ratio between positive and negative instances relatively balanced. We divide training/validation/testing sets according the timestamps of the interactions. That is to say, data from the earlier time are used for training/validation and others for testing. We keep the ratio between positive and negative instances at about 1.5 : 1 and 1 : 1 for "wow" and click datasets respectively.</p><p>Another dataset is a Weibo dataset 3 . Weibo 4 is the most popular microblogging system in China. The original dataset consists of direct user following networks and tweet 2. https://github.com/zfjsail/wechat-wow-analysis 3. http://aminer.org/Influencelocality 4. https://weibo.com logs in 2012. The goal is to predict users' retweet behavior based on their local neighbors. We follow the same setup as in <ref type="bibr" target="#b30">[31]</ref>. Finally, we obtain 779,164 data instances, in which 50% are used for training, 25% for validation, and 25% for testing.</p><p>Comparison Methods. We compare our proposed model with the following methods.</p><p>• Random. We generate like/click probability uniformly in the range [0, 1) for prediction. • Logistic Regression (LR). We use logistic regression <ref type="bibr">(LR)</ref> to train a classification model. We define three categories of features: (1) ego users' features, including user gender, age, region, social roles (whether one is an opinion leader or a structural hole) (2) ego network features, including the number of active friends, the number of connected components (#CC), and the local clustering coefficient of the ego graph formed by active friends; (3) correlation features of ego users and friends: average and sum of the common friends' ratio between the ego user and each active friend. • Random Forest (RF) <ref type="bibr" target="#b21">[22]</ref>. We use Random Forest to train a classification model due to its effectiveness in selecting relevant features and instances. The features used are the same as Logistic Regression.</p><p>• xDeepFM <ref type="bibr" target="#b20">[21]</ref>. xDeepFM is a framework based on the Factorization Machine (FM). It learns high-order feature interaction with FM modules and also has DNN (feed forward networks) modules to model feature interactions implicitly. The input features are the same as LR and RF.</p><p>• DeepInf <ref type="bibr" target="#b30">[31]</ref>. DeepInf is a framework to learn users' latent representation for predicting social influence. It takes users' ego networks as input, and uses the graph neural network to learn user representation. Here we adopt GAT to learn user embedding due to its superiority for influence prediction in the paper <ref type="bibr" target="#b30">[31]</ref>. • Wang et al. <ref type="bibr" target="#b43">[44]</ref>. This method models the topological influence structure based on the Weisfeiler-Lehman (WL) algorithm, and learns the influence dynamics for the ego user by leveraging GAT, too. The different parts of features are concatenated to make predictions. • SAGPool <ref type="bibr" target="#b18">[19]</ref>. SAGPool is a graph pooling method that uses self-attention to distinguish between nodes that should be dropped and the nodes that should be retained. The predictions are made on smaller graphs.</p><p>• ASAP <ref type="bibr" target="#b31">[32]</ref>. ASAP utilizes a novel self-attention network to cluster similar nodes together in a graph. Then, the most important clusters are selected and included in the pooled graph. After each pooling step, the graph is summarized using a readout function.  Parameter Settings. For the WeChat dataset, we set the maximum number of users/nodes in the sampled ego network to 32. For pre-trained user embeddings, we generate 64-dim embeddings using ProNE <ref type="bibr" target="#b48">[49]</ref>. In the user feature smoothing method via graph filter, we choose the parameters in the graph filter as follows: µ = 0.4, θ = 7. For hierarchical graph representation learning, the number of graph coarsening steps is set to 2. In GAT encoders of hierarchical graph representation learning, we set the head number to 8 and hidden vector dimension for each head to 16. When training, the learning rate is 0.01 for "wow" prediction and 0.1 for click prediction. The L2 regularization weight is 0.0005. Adagrad <ref type="bibr" target="#b7">[8]</ref> is chosen as the optimizer.</p><p>As for the Weibo dataset, there are several differences as follows. Following <ref type="bibr" target="#b30">[31]</ref>, we adopt random walk with restart (RWR) to generate the sampled ego networks. The number of graph coarsening steps is 1 and the learning rate is 0.05. For traditional classifiers, it can not achieve better prediction performance than other methods, although it leverages hand-craft user features, correlation features, and network features. xDeepFM, a factorization-machine based neural network model, achieves better performance than LR and RF on WeChat dataset, which might imply that the correlation between user features is an inherent factor that impacts users' "wow" and click behaviors, such as the correlation between users' gender and age.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Overall Results</head><p>DeepInf and Wang et al. could both achieve good prediction performance on three datasets. It demonstrates that modeling dyadic correlations via graph attention is effective. However, the prediction performance of Wang et al. is inferior to DeepInf, which might indicate that sometimes local topological features could result in a negative impact on user behavior prediction.</p><p>For hierarchical graph representation learning methods, SAGPool outperforms most of the baselines, though still weakly than DiffuseGNN. This indicates that dropping nodes via self-attention on graphs is another effective solution to graph coarsening. Moreover, ASAP performs better than SAGPool on the Weibo dataset, which might imply that Weibo and WeChat datasets have different characteristics for user behavior modeling. As for StructPool, we infer that modeling cluster assignment as a structured prediction problem via conditional random fields is ineffective for our problem, due to its inferior performance.</p><p>For our proposed model, its superiority is mainly due to the hierarchical structure embedding of ego networks and the feature smoothing effect. Moreover, compared with baselines using various hand-crafted features, our method only uses user features as input. Thus, our method can model dyadic correlations and ego network structures better than hand-crafted features. Furthermore, we observe that DiffuseGNN DA achieves similar performance as DiffuseGNN AA and DiffuseGNN DA sometimes outperforms DiffuseGNN AA slightly. Here we argue that AUC is more important than F1 metric, since F1 depends on a good threshold for classification. Thus, modeling feature interactions between neighboring nodes takes effect at times.</p><p>In addition, for the WeChat Top Stories dataset, we find that the performance differences between different methods for click prediction are smaller than those of "wow" prediction. Another observation is that, in general, the click prediction performance is much lower than "wow" prediction performance. This phenomenon is probably because users' click (or reading) behavior is more correlated to the articles 7KHQXPEHURIFRDUVHQLQJVWHSV themselves, while their "wow" behavior is more relevant to the social influence around them.</p><formula xml:id="formula_18">$8&amp; ) $8&amp; ) (a) WeChat "Wow" 7KHQXPEHURIFRDUVHQLQJVWHSV $8&amp; ) $8&amp; ) (b) WeChat Click 7KHQXPEHURIFRDUVHQLQJVWHSV $8&amp; ) $8&amp; ) (c) Weibo</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study</head><p>We study the effects of different model components for user behavior prediction.</p><p>• w/o pre-train: Remove the pre-trained ProNE user embedding in the input features. Note that the second-order features also lack this part. • w/o node feature: Remove the demographic and social role features in the input features. Note that the secondorder features also lack this part. • w/o 2nd feature: Remove the second-order feature interactions of different user features in the input features. • w/o smoothing: Remove the feature smoothing step via the graph filter. In Table <ref type="table" target="#tab_8">7</ref>, the bottom part summarizes the results of the ablation study. We observe that all studied components contribute to the effectiveness of our model to some degree. Among all the components, removing pre-trained embeddings and removing feature smoothing steps cause larger performance drops compared to other components on the WeChat dataset. In contrast, adding second-order features contributes a little to predict user behavior in WeChat Top Stories, but contributes more to the Weibo dataset. Meanwhile, our model performs well, even without hand-crafted user features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Parameter Analysis</head><p>The Number of Coarsening Steps in Hierarchical Graph Representation Learning. In the hierarchical graph representation step, each coarsening step transforms the ego network to smaller graphs iteratively by clustering similar "nodes" together. We study whether the number of coarsening steps influences the prediction performance. Figure <ref type="figure" target="#fig_8">11</ref> shows the prediction performance w.r.t. the number of coarsening steps. In the experiment, we set in each iteration, the number of "nodes" becomes half of that of the last iteration. We see that hierarchical graph representation clearly better than "flat" representation (0 pooling layer) on WeChat "Wow" and Weibo dataset. The prediction performance changes little in terms of the number of coarsening steps for click behavior prediction. When there are 2 coarsening steps, test AUC and F1 for click prediction are the highest. 1 pooling layer is the best for the Weibo dataset and WeChat "wow". Perhaps although we set the coarsening ratio to 50%, GNN can automatically learn the node proximity and the appropriate number of meaningful clusters <ref type="bibr" target="#b46">[47]</ref>.</p><p>Parameters in the graph filter. We analyze how the parameters θ in the graph filter g(λ) = e − 1 2 [(λ−µ) 2 −1]θ can affect the prediction performance. Here µ is trainable and we set its initial value to 0.4. Figure <ref type="figure" target="#fig_0">12</ref> shows the performance variations (AUC and F1) w.r.t. θ on test data. Parameter θ in g affects the peak value of modulated eigenvalue λ. We observe that when θ = 7 or θ = 9, AUC is higher for "wow" and click prediction than other tested configurations. However, for the Weibo dataset, when θ varies from 1 to 9, test performance increases first, then decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Visualization of Hierarchical Graph Representation Learning</head><p>We visualize the hierarchical graph representation learning process to understand how it assigns nodes into different clusters and performs predictions. Figure <ref type="figure" target="#fig_9">13</ref>(a) and 13(b) show two case studies for "wow" prediction, where Figure <ref type="figure" target="#fig_9">13</ref>(a) is a positive "wow" instance and Figure <ref type="figure" target="#fig_9">13</ref>(b) is a negative "wow" instance. The two subfigures both visualize the first coarsening step. We observe that, although the coarsening ratio is set to 50%, which means the nodes in one ego network can be assigned to at most 16 clusters, the two examples both assign nodes into only three clusters. It shows that the learning algorithm can automatically learn the appropriate number of clusters. Moreover, for the positive "wow" instance in Figure <ref type="figure" target="#fig_9">13</ref>(a), all active friends (who "wow"ed the article) are assigned to blue clusters, which may correspond to the conformity phenomenon. As for the negative "wow" instance in Figure <ref type="figure" target="#fig_9">13</ref>(b), active friends are assigned to different clusters (nodes with different colors all have nodes with "*" within). The inactivity of the ego user perhaps can be explained by the negative correlation between ego users' "wow" probability and structural diversity (referring to Sec. 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Social Influence Analysis</head><p>Social influence has been studied and modeled widely from different viewpoints. At the macro level, the problem of influence maximization in social networks has been studied in <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b16">[17]</ref>. Xin et al. <ref type="bibr" target="#b34">[35]</ref> study the indirect influence on Twitter. Micro influence, like pairwise influence, has been studied in <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b49">[50]</ref>. Liu et al. <ref type="bibr" target="#b23">[24]</ref> study the micro mechanism of influence diffusion in heterogeneous social networks and propose a probabilistic generative model. Tang et al. <ref type="bibr" target="#b37">[38]</ref> propose Topical Affinity Propagation (TAP) to model influence on different topics in the academic network <ref type="bibr" target="#b38">[39]</ref> and the heterogeneous network. More recently, deep learning models have been proposed to model social influence. Qiu et al. <ref type="bibr" target="#b30">[31]</ref> use Graph Attention Networks (GAT) to model social influence locality. Feng et al. <ref type="bibr" target="#b9">[10]</ref> propose a skip-gram architecture to learn user embeddings that reflect social influence. In this work, we first analyze microlevel social influence (e.g., dyadic and triadic correlations) and local network structure, based on which we propose an effective method to model social influence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">User Feedback in Recommender Systems</head><p>Generally, user feedback in the recommender system falls into two categories: explicit feedback and implicit feedback. Implicit feedback includes click, mouse movement, etc., and explicit feedback includes retweets, ratings, and so on. Jawaheer et al. <ref type="bibr" target="#b15">[16]</ref> propose a classification framework for explicit and implicit feedback based on several properties, including Cognitive Effort, User Model, Scale of Measurement, and Domain Relevance. They also compare different user feedback types in detail in an online music recommendation service <ref type="bibr" target="#b14">[15]</ref>. Many recommender systems try to combine different kinds of user feedback to improve recommendation performance. Liu et al. <ref type="bibr" target="#b24">[25]</ref> unify explicit and implicit feedback in a matrix-factorization framework. However, Tang et al. <ref type="bibr" target="#b39">[40]</ref> find that it is better to train different models separately for each feedback type and then combine them. In this work, we analyze both "wow" and click user feedback, and discover some interesting differences between them. Then we train separate models for each feedback type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Network Representation Learning</head><p>Recently, network representation learning at the node level and graph level has become a research hotspot. Generally, node-level representation learning approaches can be broadly categorized as (1) factorization-based approaches such as GraRep <ref type="bibr" target="#b3">[4]</ref>, NetMF <ref type="bibr" target="#b29">[30]</ref>, (2) shallow embedding approaches such as DeepWalk <ref type="bibr" target="#b28">[29]</ref>, LINE <ref type="bibr" target="#b36">[37]</ref>, HARP <ref type="bibr" target="#b4">[5]</ref>, and (3) neural network approaches <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b19">[20]</ref>. Recently, graph convolutional network (GCN) <ref type="bibr" target="#b17">[18]</ref> and its multiple variants, such as GAT <ref type="bibr" target="#b42">[43]</ref>, GIN <ref type="bibr" target="#b44">[45]</ref>, have become the dominant approaches for network representation learning, thanks to the use of graph convolution that effectively fuses graph topology and node features. Furthermore, there are also some works using graph convolution architectures for graphlevel representation learning, such as <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b46">[47]</ref>. In order to generate graph representations, most works employ graph convolution encoders to generate node embeddings first, and then use some pooling or READOUT functions, such as hierarchical pooling <ref type="bibr" target="#b46">[47]</ref> and sum operations <ref type="bibr" target="#b35">[36]</ref>.</p><p>Among hierarchical pooling methods, some <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b31">[32]</ref> use self-attention to select important nodes in the graph or cluster similar nodes together. Yuan et al. <ref type="bibr" target="#b47">[48]</ref> regard the node clustering problem as a structured prediction problem via conditional random fields. In this work, based on users' ego networks, we first learn user/node embeddings by modulating the spectral domain of the ego networks. Then, a hierarchical graph representation method is utilized to generate graph-level embeddings. Our method is motivated by and consistent with our statistical analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this work, we use the WeChat Top Stories data to understand user preferences and "wow" diffusion. Our study reveals several interesting phenomena: 1) Males' click probability is higher than females', while females' "wow" probability is higher than males'.</p><p>2) The active rate of young generations (users in their 20s) is the lowest. 3) Given the fixed number of friends who "wow"ed an article, the larger #CC (the number of connected components formed by active friends), the lower the "wow" probability of ego users is, but the higher the click probability is.</p><p>Based on these important discoveries, we also develop a unified model DiffuseGNN to predict users' behaviors. We evaluate it on the real sizable social networks, and results show that the proposed model can achieve significantly better performance over several state-of-the-arts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•Fig. 1 .</head><label>1</label><figDesc>Fig.1. "Top Stories" in WeChat. Each user can view what friends "wow"ed. If she/he also "wow"s one article, it will be displayed to (only) her/his friends, which forms a diffusion process. Here "active friends" means friends who "wow"ed the corresponding articles.</figDesc><graphic url="image-1.png" coords="1,375.92,343.74,140.27,197.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Users' "wow" and click probability w.r.t. user's gender and friends' gender. M: Male, F: Female.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>[- 35 ,Fig. 6 .Fig. 7 .</head><label>3567</label><figDesc>Fig.6. User "wow" and click probability w.r.t. the differences between user age and friend age. Here the difference is calculated by "the age of the friend minus the age of the ego user".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. User "wow" and click probability vs. the ratio of active friends</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>3 . ( 3 )</head><label>33</label><figDesc>Next, we further feed the learned intermediate representations to a hierarchical graph representation model. This model can learn subgraph embeddings by clustering nodes iteratively (here subgraphs can be considered to correspond to connected components analyzed in Sec. 3.3). (4) Also, we try to model the interactions between users' features and friends' features with a new attention model as the analysis in Section 3.2. The proposed DiffuseGNN framework consists of five steps: Preprocessing ego networks, Input layer, Feature smoothing layer, Hierarchical graph representation learning and Output layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Model Framework: (a) A sketch map of the processed ego network; (b) The input layer, in which each user's pretrained embedding is concatenated with handcrafted features and her influence feature, which indicates her active status and whether she is an ego user; (c) The feature smoothing layer, in which each user's concatenated input features are filtered by a band-pass filter in the spectral domain; (d) Each ego network's features are passed into a hierarchical graph representation learning model; (e) The output layer, where MLP layers are employed to predict user behaviors based on graph representations.</figDesc><graphic url="image-24.png" coords="7,82.83,92.06,70.91,71.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>"Wow" and click performance (AUC) on test dataset w.r.t. the number of pooling layers in hierarchical graph representation learning Fig.12. Prediction performance (AUC and F1) on test dataset w.r.t. θ in the graph filter of the feature smoothing step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Visualization of cluster assignment of hierarchical graph representation learning for "wow" behavior prediction. (a) Positive sample: the ego user "wow"ed the article. (b) Negative sample: the ego user didn't "wow" the article. Here different colors represent different cluster assignments. The largest node in each ego network is the ego user.Nodes with "*" inside mean that these users "wow"ed the article.</figDesc><graphic url="image-27.png" coords="12,53.71,49.54,113.39,102.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1</head><label>1</label><figDesc>User activity w.r.t. gender.</figDesc><table><row><cell cols="2">Gender</cell><cell cols="4">"Wow" prob.</cell><cell cols="2">Click prob.</cell></row><row><cell></cell><cell>Male</cell><cell></cell><cell>1.17%</cell><cell></cell><cell></cell><cell cols="2">10.62%</cell></row><row><cell></cell><cell>Female</cell><cell></cell><cell cols="2">1.19%</cell><cell></cell><cell cols="2">9.86%</cell></row><row><cell></cell><cell>0.14</cell><cell>Wow</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>User active probability</cell><cell>0.04 0.06 0.08 0.10 0.12</cell><cell>Click</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>Age</cell><cell>50</cell><cell>60</cell><cell>70</cell></row><row><cell cols="7">Fig. 2. "Wow" and click probability w.r.t. user age.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3</head><label>3</label><figDesc>Dyadic correlations w.r.t. the distance between the user and the friend.</figDesc><table><row><cell>User</cell><cell>"Wow" prob.</cell><cell>Click prob.</cell></row><row><cell>All</cell><cell>1.01%</cell><cell>10.24%</cell></row><row><cell>Same province</cell><cell>1.05%</cell><cell>10.65%</cell></row><row><cell>Same city</cell><cell>1.08%</cell><cell>10.85%</cell></row><row><cell>Same district</cell><cell>1.19%</cell><cell>11.27%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 4</head><label>4</label><figDesc>Dyadic correlations w.r.t. users' and friends' social roles. OU: ordinary user; OL: opinion leader.</figDesc><table><row><cell>User</cell><cell>Friend</cell><cell>"Wow" prob.</cell><cell>Click prob.</cell></row><row><cell>OU</cell><cell>OU</cell><cell>1.06%</cell><cell>10.65%</cell></row><row><cell>OU</cell><cell>OL</cell><cell>0.66%</cell><cell>8.11%</cell></row><row><cell>OL</cell><cell>OU</cell><cell>0.92%</cell><cell>8.57%</cell></row><row><cell>OL</cell><cell>OL</cell><cell>0.64%</cell><cell>7.49%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 5 Dyadic</head><label>5</label><figDesc></figDesc><table><row><cell>User</cell><cell>Friend</cell><cell>"Wow" prob.</cell><cell>Click prob.</cell></row><row><cell>OU</cell><cell>OU</cell><cell>0.99%</cell><cell>10.26%</cell></row><row><cell>OU</cell><cell>SH</cell><cell>1.38%</cell><cell>12.43%</cell></row><row><cell>SH</cell><cell>OU</cell><cell>2.34%</cell><cell>10.28%</cell></row><row><cell>SH</cell><cell>SH</cell><cell>3.58%</cell><cell>10.16%</cell></row></table><note>correlations w.r.t. users' and friends' social roles. OU: ordinary user; SH: structural hole.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 6</head><label>6</label><figDesc>List of input features of DiffuseGNN. (*x) indicates the dimension of the feature. OL: opinion leader. SH: structural hole.</figDesc><table><row><cell>Type</cell><cell>Description</cell><cell>Feature Definition</cell></row><row><cell></cell><cell>Gender</cell><cell>(*1) 0: unknown, 1: male, 2: female</cell></row><row><cell>Demographics</cell><cell>Age</cell><cell>(*1) Age number</cell></row><row><cell></cell><cell>Region</cell><cell>(*10) Encoding via region partition</cell></row><row><cell>Social Roles</cell><cell>OL SH</cell><cell>(*1) PageRank score (*1) Cut point or not</cell></row><row><cell>Context</cell><cell>Ego Action</cell><cell>(*1) Ego user or not (*1) "wow" or not</cell></row><row><cell>Embedding</cell><cell>Pre-train</cell><cell>ProNE embedding</cell></row><row><cell>Cross Feature</cell><cell>2nd feature</cell><cell>FM w.r.t. various features</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 7</head><label>7</label><figDesc>Results of User Behavior Prediction.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">WeChat "Wow"</cell><cell></cell><cell cols="2">WeChat Click</cell><cell></cell><cell cols="2">Weibo</cell><cell></cell></row><row><cell>Method</cell><cell>Prec</cell><cell>Rec</cell><cell>F1</cell><cell>AUC Prec</cell><cell>Rec</cell><cell>F1</cell><cell>AUC Prec</cell><cell>Rec</cell><cell>F1</cell><cell>AUC</cell></row><row><cell>Random</cell><cell cols="10">47.84 50.06 48.92 50.05 28.64 50.13 36.45 50.02 25.12 50.48 33.55 50.15</cell></row><row><cell>LR</cell><cell cols="10">68.08 70.08 69.06 76.73 41.71 67.01 51.41 70.07 42.97 71.37 53.64 76.38</cell></row><row><cell>RF [22]</cell><cell cols="10">69.20 65.17 67.12 76.69 39.52 74.69 51.69 70.12 40.03 73.66 51.87 75.14</cell></row><row><cell>xDeepFM [21]</cell><cell cols="10">66.23 80.96 72.85 78.25 40.88 75.09 52.94 71.61 30.20 73.90 42.88 64.38</cell></row><row><cell>DeepInf [31]</cell><cell cols="10">70.28 81.46 75.46 83.06 43.88 76.03 55.65 74.50 48.09 71.67 57.56 81.46</cell></row><row><cell>Wang et al. [44]</cell><cell cols="10">69.76 79.40 74.27 81.91 41.91 75.07 53.79 72.31 45.58 74.63 56.59 80.26</cell></row><row><cell>SAGPool [19]</cell><cell cols="10">81.74 75.43 78.46 86.18 46.58 79.19 58.66 77.37 43.79 73.81 54.97 78.89</cell></row><row><cell>ASAP [32]</cell><cell cols="10">71.13 79.81 75.22 83.28 44.92 76.57 56.62 75.48 46.55 70.64 56.12 79.87</cell></row><row><cell>StructPool [48]</cell><cell cols="10">67.56 79.21 72.92 79.46 40.20 78.55 53.19 71.54 30.47 72.87 42.98 61.83</cell></row><row><cell>DiffuseGNN AA</cell><cell cols="10">84.95 76.81 80.67 87.64 46.63 82.01 59.46 78.05 50.09 72.87 59.37 83.08</cell></row><row><cell>DiffuseGNN DA</cell><cell cols="10">85.46 76.30 80.62 87.69 46.45 82.81 59.52 78.27 48.70 74.88 59.01 82.76</cell></row><row><cell>w/o pre-train</cell><cell cols="10">74.96 78.42 76.65 84.91 45.68 75.77 57.00 76.09 47.33 74.15 57.78 81.51</cell></row><row><cell cols="11">w/o node feature 85.01 75.69 80.08 87.10 45.64 82.26 58.71 77.64 46.34 74.46 57.13 81.10</cell></row><row><cell>w/o 2nd feature</cell><cell cols="10">86.40 76.16 80.16 87.50 46.66 81.66 59.39 78.16 46.12 75.02 57.12 81.03</cell></row><row><cell>w/o smoothing</cell><cell cols="10">79.23 77.57 78.39 86.04 46.26 78.38 58.18 76.89 48.95 72.20 58.35 82.13</cell></row><row><cell cols="5">using additive attention in the basic GNN modules, and</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">use DiffuseGNN DA to denote using dot attention in the</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>basic GNN modules.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>summarizes the results of user behavior predic-</cell></row><row><cell>tion. The comparison methods can be roughly divided into</cell></row><row><cell>several categories: (1) traditional classifiers: LR and RF, (2)</cell></row><row><cell>deep learning method by modeling feature interactions:</cell></row><row><cell>xDeepFM, (3) the state-of-the-art user behavior prediction</cell></row><row><cell>methods based on ego networks: DeepInf and Wang et al.</cell></row><row><cell>and (4) hierarchical graph representation learning methods:</cell></row><row><cell>SAGPool, ASAP and StructPool. (3) and (4) are both GNN-</cell></row><row><cell>based methods. Generally, we observe that our model Dif-</cell></row><row><cell>fuseGNN consistently outperforms baseline methods.</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is supported by a research fund of Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology, the National Key R&amp;D Program of China (2018YFB1402600), NSFC for Distinguished Young Scholar (61825602), NSFC (61836013), NSFC (61672313), and NSF under grants III-1763325, III-1909323, and SaTC-1930941.   </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Special functions of mathematics for engineers</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Andrews</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Spie Press</publisher>
			<biblScope unit="volume">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Structural holes and good ideas</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Burt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of sociology</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="349" to="399" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep neural networks for learning graph representations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;16</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Grarep: Learning graph representations with global structural information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;15</title>
				<imprint>
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Harp: Hierarchical representation learning for networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;18</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mining the network value of customers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;01</title>
				<imprint>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Douglas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1101.5211</idno>
		<title level="m">The weisfeiler-lehman method and graph isomorphism testing</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Competing for attention in social media under information overload conditions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Havlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Braunstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inf2vec: Latent representation model for social influence embedding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Chee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE&apos;18</title>
				<imprint>
			<biblScope unit="page" from="941" to="952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Talk of the network: A complex systems look at the underlying process of word-ofmouth</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Libai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing letters</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="223" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning influence probabilities in social networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Lakshmanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM&apos;10</title>
				<imprint>
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Threshold models of collective behavior</title>
		<author>
			<persName><forename type="first">M</forename><surname>Granovetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of sociology</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1420" to="1443" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Topic-sensitive pagerank: A context-sensitive ranking algorithm for web search</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="784" to="796" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparison of implicit and explicit feedback from an online music recommendation service</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jawaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szomszor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kostkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international workshop on information heterogeneity and fusion in recommender systems</title>
				<meeting>the 1st international workshop on information heterogeneity and fusion in recommender systems</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="47" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modeling user preferences in recommender systems: A classification framework for explicit and implicit user feedback</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jawaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kostkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Interactive Intelligent Systems (TiiS)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Maximizing the spread of influence through a social network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;03</title>
				<imprint>
			<biblScope unit="page" from="137" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>ICLR&apos;17</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-attention graph pooling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">36th International Conference on Machine Learning, ICML 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6661" to="6670" />
		</imprint>
	</monogr>
	<note>International Machine Learning Society (IMLS)</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adaptive graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In AAAI&apos;18</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">xdeepfm: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Classification and regression by randomforest</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiener</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="18" to="22" />
		</imprint>
	</monogr>
	<note>R news</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detecting stress based on social interactions in social networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1820" to="1833" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning influence from heterogeneous social networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unifying explicit and implicit feedback for collaborative filtering</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;10</title>
				<imprint>
			<biblScope unit="page" from="1445" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rise and fall patterns of information diffusion: model and implications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsubara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;12</title>
				<imprint>
			<biblScope unit="page" from="6" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;16</title>
				<imprint>
			<biblScope unit="page" from="2014" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The pagerank citation ranking: Bringing order to the web</title>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Stanford InfoLab</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;14</title>
				<imprint>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM&apos;18</title>
				<imprint>
			<biblScope unit="page" from="459" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deepinf: Social influence prediction with deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
				<imprint>
			<biblScope unit="page" from="2110" to="2119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Asap: Adaptive structure aware pooling for learning hierarchical graph representations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5470" to="5477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Diffusion of innovations</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Rogers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Simon and Schuster</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Prediction of information diffusion probabilities for independent cascade model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KES&apos;08</title>
				<imprint>
			<biblScope unit="page" from="67" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Modeling indirect influence on twitter</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Semantic Web and Information Systems (IJSWIS)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="20" to="36" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization</title>
		<author>
			<persName><forename type="first">F.-Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno>ICLR&apos;20</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;15</title>
				<imprint>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Social influence analysis in large-scale networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;09</title>
				<imprint>
			<biblScope unit="page" from="807" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Arnetminer: extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;08</title>
				<imprint>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An empirical study on recommendation with multiple types of feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;16</title>
				<imprint>
			<biblScope unit="page" from="283" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Depth-first search and linear graph algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="146" to="160" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Structural diversity in social contagion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ugander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PNAS</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="5962" to="5966" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>ICLR&apos;18</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Social influence does matter: User action prediction for in-feed advertising</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In ICLR&apos;19</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Rain: Social role-aware information diffusion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS&apos;18</title>
				<imprint>
			<biblScope unit="page" from="4800" to="4810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Structpool: Structured graph pooling via conditional random fields</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Prone: fast and scalable network representation learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI&apos;19</title>
				<imprint>
			<biblScope unit="page" from="4278" to="4284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Social influence locality for modeling retweeting behaviors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI&apos;13</title>
				<imprint>
			<biblScope unit="page" from="2761" to="2767" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
