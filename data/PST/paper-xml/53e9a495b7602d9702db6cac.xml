<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Anonymity in Location-based Services: Towards a General Framework *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Claudio</forename><surname>Bettini</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Milan</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sergio</forename><forename type="middle">Mascetti</forename><surname>Dico</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Milan</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">X</forename><forename type="middle">Sean</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Dept of CS</orgName>
								<orgName type="department" key="dep2">VT Sushil Jajodia CSIS</orgName>
								<orgName type="institution" key="instit1">University of Vermont</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<address>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Anonymity in Location-based Services: Towards a General Framework *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">17A1808492C12FE476295345DE494322</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A general consensus is that the proliferation of locationaware devices will result in a diffusion of location-based services. Privacy preservation is a challenging research issue for this kind of service. A possible solution consists of ensuring users' anonymity, i.e., ensuring that the user issuing a request is indistinguishable, among a group of users, by any attacker who has access to the service requests.</p><p>In this paper we propose a formal framework to model the problem of guaranteeing anonymity when requiring location-based services. The proposed framework extends existing approaches by allowing to model different kinds of knowledge that may be available to the attacker. We show application examples of our framework, modeling both known scenarios and new ones. From a practical point of view, the framework makes it possible to define anonymity-preserving techniques that best suite the system assumptions as derived from the applicative context, and the level of privacy protection defined by the user.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Location-based services (LBS) have been recently attracting a lot of interest both from industry and research. Currently, the most popular commercial service is probably car navigation, but many other services are being offered and more are being experimented, as less expensive location aware devices are reaching the market. Consciously or unconsciously, many users are ready to give up one more piece of their private information in order to access the new services. On the contrary, many others are concerned with releasing their exact location as part of the service request or with releasing the information of having used a particular service. More generally, the association between the real identity of the user issuing an LBS request and the request itself as it reaches the service provider (SP) can be considered a privacy threat.</p><p>An obvious defense against this threat is to eliminate from the request any data that can directly reveal the issuer's identity, possibly using a pseudonym whenever this is required (e.g., for billing through a third party).</p><p>Unfortunately, simply dropping the issuer's personal identification data may not be sufficient to anonymize the request. For example, the location and time information contained in the request may be used, with the help of external knowledge, to restrict the group of possible issuers. This problem is well-known for the release of data in databases tables <ref type="bibr" target="#b10">[11]</ref>. In that case, the problem is to protect the association between the identity of an individual and a tuple containing her sensitive data; the attributes whose values could possibly be used to restrict the candidate identities for a given tuple are called quasi-identifiers <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>Most research efforts in LBS privacy have considered the problem of location and time acting as quasi-identifiers. More specifically, Gruteser et Al. <ref type="bibr" target="#b5">[6]</ref> were the first to propose spatio-temporal generalization to obtain a property analogous to k-anonymity <ref type="bibr" target="#b10">[11]</ref>. Gedik and Liu <ref type="bibr" target="#b4">[5]</ref> followed this direction and proposed new generalization algorithms that allow each user to specify the minimum level of anonymity and the maximum tolerated spatio-temporal generalization. Mokbel et Al. <ref type="bibr" target="#b9">[10]</ref> proposed a solution that also allows the user to specify the smallest area that should be forwarded to the SP. Kalnis et Al. <ref type="bibr" target="#b7">[8]</ref> pointed out a possible problem with the generalization proposed in <ref type="bibr" target="#b5">[6]</ref> and presented a solution. Other researchers <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref> have considered the possibility for an attacker to recognize sets of requests issued by the same (anonymous) users and to exploit this information in an attack. We call this technique linking. In <ref type="bibr" target="#b1">[2]</ref> the notion of Historical k-anonymity has been defined considering spatio-temporal traces obtained by linking requests. A different problem was addressed by Kido et al. <ref type="bibr" target="#b8">[9]</ref> that consider location and time as sensitive information. The solution proposed to prevent the attacker from understanding user's location, consists in generating fake requests 1-4244-1241-2/07/$25.00 ©2007 IEEE that contains false location information each time a user issues a request.</p><p>While all these contributions to LBS privacy preservation are very interesting and promising, we identify two main issues: a) Current contributions are focused on location and time acting as quasi-identifiers; are these really the only quasi-identifiers in an LBS request? b) Current contributions are mostly based on example scenarios, and the assumptions made in each scenario about the knowledge available to the attacker, are not always clear. Consequently, the characterization of the attacks is not formally defined and the proposed defense techniques are easily attackable by counterexamples assuming new knowledge. Moreover, for some services it may be interesting to study defense techniques based on less conservative assumptions. For example, it is sometimes unreasonable to assume that the attacker knows the identity of all individuals in any given place (e.g., a crowded square). How can we devise defense techniques based on different assumptions?</p><p>This paper reports preliminary results of our effort to address these issues. While our global goal is to extend the framework to model also attacks based on request linking, for lack of space and for clarity of presentation we limit the results presented in this paper to the case in which linking is not considered. After briefly describing our reference scenario in Section 2, we present in Section 3 a formal framework that precisely defines the notions of attack, safe request, and defense function, based on the specific knowledge assumed to be possibly reachable by an attacker (not limited to location information). In Section 4 we investigate the framework expressiveness, showing that it can formally characterize known attacks as well as new attacks. Moreover, we model attacks in which service parameters other than location and time can be used as quasi-identifiers. In Section 5, we show how the formal framework can be useful to define a defense function against a given attack. In particular we devise an algorithm that provides a generalization proved to be safe against attacks assuming knowledge about location of individuals, services they are entitled to use, as well as knowledge about the generalization function itself. Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Scenario</head><p>Figure <ref type="figure">1</ref> shows our reference scenario that involves three entities:</p><p>• The User invokes or subscribes to location-based remote services that are going to be provided to her mobile device.</p><p>• The Location-aware Trusted Server (LTS) stores precise location data of all its users, using data directly provided by users' devices and/or acquired from the infrastructure. It also has the ability to efficiently perform spatio-temporal queries to determine, for example, which or how many users are in a certain region.</p><p>• The Service Provider (SP) fulfills user requests and communicates with the user through the LTS. Both pull and push communication service models are possible; We concentrate on the former but the framework we present can be easily extended to deal with the latter too.</p><p>Most of the approaches proposed in the literature <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10]</ref> to protect LBS privacy consider scenarios that can be easily mapped to the one depicted in Figure <ref type="figure">1</ref>. Actually, scenarios where no location-aware intermediate entity is present have also been considered. For example, in <ref type="bibr" target="#b8">[9]</ref> a direct communication between the user and the service provider is assumed, and the defense function is computed on the client system. Clearly in this model it is not possible to assume that the client has any awareness of the exact location of other clients; hence the generalization techniques proposed in this and in other papers would not be applicable. We believe that the current business models of mobile operators naturally support the existence and functionality of an entity like the LTS. Indeed, mobile users implicitly trust the operator infrastructure even if they know that very accurate information about their location and service requests is stored. Moreover, in most countries each operator has a very large number of custumers, and hence a collection of data that may be more than sufficient to implement some of the defense techniques we are proposing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. A general reference scenario</head><p>The format of a request is represented by the following triple:</p><p>IdData, ST Data, SSData</p><p>• IdData contains the exact user identity in the original request; when the request is generalized it is either empty or it contains a pseudo-id.</p><p>• STData contains spatio-temporal information about the location of the user performing the requests, and the time the request was issued. For the sake of simplicity, we assume that this information is a point in 3-dimensional space (with time being the third dimension) for the original request, and a region in the same space for the generalized request.</p><p>• SSData contains parameters characterizing the required service and service provider.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A formal model for anonymity in LBS</head><p>In this section we provide a formal framework to define attack and defense techniques. The set R contains all the possible original requests issued by the users to the LTS and all the possible generalized requests that the LTS would forward to the SP. We also indicate with I the set of all users' identities and with issuer(r) the identity of the user that issued the request r. A generalization function is used by the LTS to transform an original request into a generalized one to be forwarded to the SP. Definition 1 Given a set R of requests, we say that g : R → R is a generalization function.</p><p>In the following, we often use r to denote an original request r, and r = g(r) to denote the generalization of r that is forwarded to the SP. The generalization function is not necessarily a total function; if it happens to be undefined for some original request r, then the LTS simply suppresses r.</p><p>Most approaches to anonymity are based on generalization and/or suppression. The main idea is to generalize the data that could be used, possibly joined with external knowledge, to re-identify individuals. The generalization should ensure that the re-identification process does not associate a request to an individual user with high enough probability. In the context of LBS requests, what can be generalized is IDData, which is usually suppressed or changed into pseudonames, ST Data, which is usually generalized to coarser spatio-temporal regions, and, in principle, also SSData that specifies the desired service. However, how much should we generalize these values in order to be safe? As observed in the introduction, most current approaches focus on STData and devise a generalization function that is intended to provide safety even in the worst case scenario of an attacker having acquired external knowledge about the identities of individuals in the spatio-temporal region specified in the request. This is a very conservative assumption. Nevertheless, we will show that the generalization function based on it, is not sufficient if we consider, for example, that also SSData can act as quasi-identifier, or if we assume that the generalization function is known.</p><p>We claim that the safety of a generalization function can only be formally evaluated if it is clearly identified which part of the request can act as a quasi-identifier, and which knowledge is assumed to be possibly reachable by an attacker. We use Γ to denote this knowledge, that can contain public information (e.g., a voter list) and confidential information (e.g., the identity of a user in a given location). Clearly, Γ changes depending on the applicative context and on the level of conservativeness of the chosen model. In Sections 4 we show different scenarios, including the ones addressed in the literature, each one modeling different assumptions for the content of Γ.</p><p>The attacker's aim is to infer, from a generalized request, based on the knowledge Γ, the identity of the user that issued it. We model a specific attack as the likelihood of associating a specific identity to a generalized request. Definition 2 formally states what is an attack by normalizing to one all the likelihood values for a given generalized request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2 An attack based on knowledge Γ is a function</head><formula xml:id="formula_0">Att Γ : R×I → [0, 1] such that for each generalized request r , i∈I Att Γ (r , i) = 1<label>(1)</label></formula><p>By definition 2, attacks can be specified in which, given a request r , the candidate individuals have different probabilities of being the issuer of r , as shown in Example 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 1 Consider a location based yellow pages service and the following knowledge Γ that the attacker could acquire:</head><p>• the location of each user;</p><p>• the users' profiles (possibly obtained during the registration phase);</p><p>• the fact that the ST Data field of the requests forwarded by the LTS always contains the location of the issuer of the original request.</p><p>Suppose that Alice issues a request asking for the closest shop where she can find classical music. The LTS receives the request and deletes the information that could directly lead to Alice's identity (her name, for example). Moreover, the exact location of Alice is generalized into an area. Then, the resulting generalized request r is forwarded to the SP.</p><p>If an attacker obtains r , he first uses the location knowledge to restrict the set of possible issuers to the users whose location is in the region specified in r . Suppose this set is composed by three users: Alice, Bob and Carl. Then, he uses the knowledge of the users' profiles, to discover that Alice's musical interests are closer to the classical genre than those of Bob and Carl. Hence, this attack is characterized by a higher likelihood for Alice being the issuer of r , than Bob or Carl.</p><p>A special case of this general definition is the one in which the attacker can identify a set of candidate issuers, each one having the same probability of being the real issuer. In this case, for each generalized request r , we call anonymity set based on knowledge Γ (we indicate it with Anon Γ (r )) the set of candidate issuers of r obtained using knowledge Γ. Once the anonymity set is specified, it is possible to derive the corresponding uniform attack: Definition 3 Given the external knowledge Γ and the complete function Anon Γ : R → 2 I , we say that Att Γ is the uniform attack based on anonymity set Anon Γ if, for each generalized request r ∈ R and for each i ∈ I:</p><formula xml:id="formula_1">Att Γ (r , i) = 0 if i ∈ Anon Γ (r ) 1 |AnonΓ(r )| otherwise</formula><p>Clearly, an attack Att Γ depends on the external knowledge Γ: the more information the attacker has available, the higher the probability of identifying the issuer.</p><p>Given the definition of attack, we define when a generalized request r can lead the attacker to infer the correct identity of the issuer of r . The idea of Definition 4 is that a request is safe if the attack associates it to the correct identity with a likelihood smaller than a threshold value h. Definition 4 Let Att Γ be an attack, h a value in [0, 1) and r a generalized request. We say that r is a safe request against Att Γ with threshold h if, given i = issuer(r), Att Γ (r , i) ≤ h.</p><p>If a request is not safe, we say that it is unsafe.</p><p>The task of the LTS is to avoid to generalize a request into a unsafe one. We call defense function a generalization function that generates only requests that are safe against a given attack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 5 Let Att Γ be an attack and h a value in [0, 1).</head><p>A generalization function g : R → R is a defense function against Att Γ with threshold h if for each original request r ∈ R such that g(r) is defined, g(r) is a safe request against Att Γ with threshold h.</p><p>In this paper, we use the following notation:</p><p>• r.ST Data and r.SSData represent the STData field, and the SSData field of the request r, respectively;</p><p>• loc i is the location of user i;</p><p>• given a generalized request r , loc i ∈ r .ST Data indicates that loc i is within the region r .ST Data;</p><p>• given an original request r and a generalized request r , r.ST Data ∈ r .ST Data indicates that the point r.ST Data is within the region r .ST Data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Expressiveness of the formal model</head><p>In this section we show how the formal framework defined in Section 3 can be used to model both well known anonymization problems and new ones. In particular, different assumptions of the knowledge Γ make it possible to define different attacks, each one requiring a specific defense technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Modeling spatio-temporal anonymity</head><p>Several anonymization techniques proposed in the literature <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8]</ref> address the problem first presented in <ref type="bibr" target="#b5">[6]</ref>; in the following we refer to this anonymization model as the Spatio Temporal Anonymization (STA) problem. In this section we characterize this approach with the formal framework presented in Section 3.</p><p>As briefly explained in the introduction, the idea of the STA problem is that users can be identified through their location, and therefore user's privacy is endangered if a generalized request contains precise information about user's location. For example, an attacker can understand user's identity from user's location through the physical observation of the user, or because the user is the only one that can be in that location (a suburban house, for instance).</p><p>Existing approaches to the STA problem <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8]</ref> propose techniques that are safe also in the case in which the attacker acquires the knowledge about the exact location of each user. In this section we consider this conservative case, while in Section 4.2 we relax this assumption. In STA, the attacker is also assumed to know that the generalization function used by the LTS preserves the location, i.e., the region g(r).ST Data always includes the point r.ST Data.</p><p>Most of the solutions to the STA problem provide privacy protection if the external knowledge the attacker can acquire is limited to the location of the users and to the fact that the generalization function preserves the location.</p><p>Since the STA problem refers to a scenario analogous to the one described in Section 2, three dimensional regions are considered in generalized requests. For the sake of simplicity, in the following of this paper we concentrate on two dimensions only, disregarding time; However, our work can be easily extended to support also the temporal dimension.</p><p>The uniform attack considered in the STA problem is based on the anonymity set of users who are located within the area specified in the generalized request. Definition 6 Let Γ ST be the knowledge :</p><p>1. for each original request r, r.ST Data ∈ g(r).ST Data;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">∀i ∈ I, loc i .</head><p>For each request r , the anonymity set considered in STA is:</p><formula xml:id="formula_2">Anon ΓST (r ) = {i ∈ I|loc i ∈ r .ST Data}</formula><p>The idea is that the more users are located inside r .ST Data, the more anonymous is the issuer of r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 7</head><p>In the STA problem, a generalized request r is said to be k-anonymous if |Anon ΓST (r )| ≥ k.</p><p>The solutions to the STA problem provided in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b5">6]</ref> guarantee anonymity by generalizing the STData field of the incoming request and forwarding to the SP only requests r such that r .ST Data specifies an area that contains at least the location of k users.</p><p>Theorem 1 shows that, considering knowledge Γ ST , a generalization function that generates k-anonymous requests is a defense function, and that the parameter k is the inverse of h.</p><p>Theorem 1 Let k be an integer and g() a generalization function such that, for each original request r, g(r) is kanonymous. Then, g() is a defense function against the uniform attack based on anonymity set Anon ΓST with threshold 1/k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Modeling STA when only some users' locations are known to the attacker</head><p>In this section we consider the STA problem and we extend it to the case in which only some locations can be used to derive user's identity.</p><p>To model this situation, we partition the geographical area covered by the LS in two parts: A v and A h . A v represents the area where users are "visible" and can be identified, while A h includes all the location where users are "hidden" and hence cannot be identified.</p><p>Therefore, in this case, we consider a knowledge Γ P L ("PL" stands for "Partial Location") that includes the identities of the users whose locations are inside A v and the fact that the generalization function preserves the location.</p><p>Based on knowledge Γ P L , we propose the following definition of anonymity set Anon ΓPL : if the region specified in r .ST Data is completely included in A v , then all the candidate issuers are potentially visible to the attacker, and therefore Anon ΓP L contains the users whose location is within r .ST Data. On the contrary, if r .ST Data overlaps with A h , then the attacker cannot know which users are in the area r .ST Data ∩ A h and therefore Anon ΓPL also contains all the users whose location is in A h . Formally, given I r = {i ∈ I|loc i ∈ r .ST Data} and</p><formula xml:id="formula_3">I h = {i ∈ I|loc i ∈ A h }, Anon ΓP L (r ) = I r if r .ST Data ⊆ A v I r ∪ I h otherwise</formula><p>Note that this definition of anonymity set is a proper extension of Anon ΓST . Indeed, if we consider A h = ∅, then, for each generalized request r , Anon ΓP L (r ) = Anon ΓST (r ).</p><p>A further extension of the scenario based on knowledge Γ P L can consider the case in which the attacker has access to users' locations with different precision in different areas. In this case, the geographical region covered by the service provider is partitioned into (possibly non-contiguous) areas. In each of them, the attacker's knowledge about user's location can rely on different sources, each one having a different precision of the locations' information. The precision can range from the exact user's location to the only information that a user is located in one of the areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Modeling STA when the generalization function is known to the attacker</head><p>In this section we give a formal explanation to the counterattacks illustrated in the literature to the defense techniques first proposed for STA. Indeed, the attacks implicitly consider the generalization function as publicly known, while the defense technique assumed otherwise.</p><p>If the generalization function, as well as the parameters on which it is based (e.g., the threshold k) are known, it can be inverted, hence allowing an attacker to infer, from a generalized request r , the set of possible issuers. If this set is sufficiently small, the attacker can be able to identify, with high probability, the issuer of the original request r.</p><p>Figure <ref type="figure">2</ref> shows the application of the generalization function g() to a request r; the result is a request r . The inverse function g -1 () maps r to a set of three possible original requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Representation of the generalization function and its inverse.</head><p>The attacker's knowledge Γ IST that we model in this section is given by the union of Γ ST , as defined in Sec-tion 4.1, with the knowledge of the function g(). Since g : R → R is known, the function g -1 : R → 2 R can be derived as: g -1 (r ) = {r ∈ R|g(r) = r }.</p><p>Knowing Γ IST , a possible uniform attack can be based on the following definition of anonymity set: Definition 8 Let Γ IST be the union of the knowledge Γ ST and the following knowledge: {∀r ∈ R, g(r)}.</p><p>For each generalized request r , we define the anonymity set: Anon ΓIST (r ) = {i ∈ I|∃r ∈ R s.t. issuer(r) = i and g(r) = r } Theorem 2 shows that, if the generalization function is known, then an effective technique to de-anonymize a generalized request consists of inverting g().</p><p>Theorem 2 For each generalized request r , Anon ΓIST (r ) ⊆ Anon ΓST (r ).</p><p>Intuitively, Theorem 2 states that, given a generalized request r = g(r), the set of possible issuer of r computed inverting the function g() is a subset of the set of users whose location is within r .ST Data. This implies that, if g() is known to the attacker, if a request is k-anonymous according to Definition 7, it may nevertheless be associated to a particular user with likelihood greater than 1/k. Theorem 3 Let r be a generalized request. The kanonymity of r is a necessary but not sufficient condition for r to be a safe request against the uniform attack based on anonymity set Anon ΓIST (r ) with threshold 1/k.</p><p>Theorem 3 shows that the notion of k-anonymity of a request is not sufficient in order to guarantee user's privacy when the generalization function is known to the attacker. In Example 2 we show, in terms of our framework, why the generalization function proposed in <ref type="bibr" target="#b5">[6]</ref> is not a defense function against Att ΓIST with threshold 1/k. Example 2 Figure <ref type="figure" target="#fig_0">3</ref> shows four user locations. Users u 1 , u 2 and u 3 are close to each other, while u 4 is far away. Consider a generalization function g() that enlarges the area of a request until it includes the location of k users. In our example, a request issued by u 1 , u 2 or u 3 is generalized into a request that has A 2 as STData while a request issued by u 4 is generalized into a request that has A 1 as STData.</p><p>As we proved in Theorem 1, g() is a defense function against the uniform attack based on Anon ΓST with threshold 1/3. On the contrary, if we assume that the attacker knows the generalization function and hence has knowledge Γ IST , then g() is not a defense function against the uniform attack based on Anon ΓIST for any threshold in [0, 1). Indeed, let r be a request issued by u 4 and r the generalization of r such that r .ST Data = A 1 . If we invert g(), we obtain g -1 (r ) = {r}, since any request issued by u 1 , u 2 or u 3 would be generalized into a request different from r . Therefore, the only possible issuer of r is u 4 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Modeling STA when SSData can be used to identify users</head><p>Location and time are not the only parameters of a request that can be used as quasi-identifiers.</p><p>In this section we model the case in which the attacker can increase the probability of identifying the issuer of a request r through the information contained in g(r).SSData, as illustrated in Example 3.</p><p>Example 3 Assume that the attacker obtains a generalized request r that has been forwarded to the SP by generalizing r.ST Data. Assume also that, based on r .ST Data, Alice, Bob and Carl are identified as the potential issuers. Since r .SSData contains the parameters to access a specific LBS news service that requires registration, if the attacker gains access to the list of registered users, he may discover that Bob is the only one among the three to be registered. In this case Bob would be re-identified as the issuer of r.</p><p>In order to formally model this situation, we consider knowledge Γ IST EU = Γ IST ∪ Γ EU where Γ EU is the knowledge, for each service, of the users who are eligible to use that service.</p><p>A possible uniform attack can be based on the anonymity set Anon ΓIST EU (r ) = EU r ∩ Anon ΓIST (r ) where EU r is the set of users eligible to use the service specified in r .SSData. Clearly, any defense function devised against this attack must assume the set of eligible users to be known by the LTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Devising a defense function</head><p>In this section we show how the formal framework defined in Section 3 can be useful to define a defense function against a given attack. As an example, we consider the uniform attack based on Anon ΓIST EU , as defined in Section 4.4, and we show how to define an algorithm to compute a defense function.</p><p>For the sake of simplicity, our defense function will be based on the generalization of STData only. Since Γ IST EU subsumes Γ IST which in turn subsumes Γ ST , the defense function against the uniform attack Anon ΓIST EU should also provide protection against the uniform attacks Anon ΓIST and Anon ΓST . This consideration suggests us a three steps procedure to define the algorithm that computes the defense function against Anon ΓIST EU :</p><p>1. define algorithm Gen ST that provides protection against Anon ΓST ;</p><p>2. alter Gen ST to obtain Gen IST that provides protection against Anon ΓIST ;</p><p>3. alter Gen IST to obtained Gen IST EU that provides protection against Anon ΓIST EU .</p><p>We define algorithm Gen ST inspired by the Interval-Cloaking generalization algorithm <ref type="bibr" target="#b5">[6]</ref>. The idea is to iteratively restrict a set I of users that is initialized to I. At each iteration I is partitioned. If the block b that contains the issuer contains at least k users, then I is set to b and the iteration continues. Otherwise, it returns the MBR (Minimum Bounding Rectangle) of the locations of the users in I . Gen ST does not provide protection against Anon ΓIST due to the problem described in Example 2. A solution consists in: i) imposing the partitioning function to be independent from the issuer and ii) modifying the termination condition of Gen ST so that the algorithm terminates if any of the blocks in which I is partitioned contains less than k users. The resulting algorithm is Gen IST . Then, algorithm Gen IST can be modified to provide protection against Anon ΓIST EU by changing the termination condition so that the algorithm terminates if any of the blocks in which I is partitioned contains less than k users eligible to use the service specified in the request. In the following, given a set I of identities, we denote with el r (I ) the set of users in I that are eligible to access the service required in r.</p><p>The resulting Algorithm 1 first checks if there are at least k users who are eligible to access the service required in the original request r. If not, null is returned. Otherwise, the algorithm iteratively restricts the set I of candidate identities by successively partitioning it. The iteration terminates when a further partitioning would contain at least one block with less than k users who are eligible to use the service. Then, the algorithm returns the MBR of the locations of the users in the current set.</p><p>Assuming that partitioning is performed independently from r, the correctness of Algorithm 1 is given by the fact that the area returned by Gen IST EU (Γ IST EU , k, I, r) contains a set of at least k users who are eligible to require</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Gen IST EU</head><p>• Input: knowledge Γ IST EU , an integer value k, the set I of user identities, and an original request r.</p><p>• Output: null if |el r (I)| &lt; k; the MBR of loc issuer(r) and of the locations of other k -1 users in el r (I) otherwise.</p><p>• Method: end if 10: end while the service specified in r.SSData, and such that, if any of them issues a request r 1 requiring the same service, the result of Gen IST EU (Γ IST EU , k, I, r 1 ) would be the same as Gen IST EU (Γ IST EU , k, I, r). Theorem 4 formalizes this idea and proves the correctness of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4 Let Gen IST EU (Γ IST EU , k, I, r) be an execution of Algorithm 1 that returns a non-null result A.</head><p>There exists a set I ⊆ I such that: <ref type="bibr" target="#b0">(1)</ref> for each i ∈ I , loc i ∈ A, (2) issuer(r) ∈ I , (3) |I | ≥ k, (4) each user in I is eligible to access the service required in r and ( <ref type="formula">5</ref>) for each user i ∈ I there exists r 1 ∈ R in which the same service as r is specified such that issuer(r 1 ) = i and Gen IST EU (Γ IST EU , k, I, r 1 ) = A.</p><p>In <ref type="bibr" target="#b7">[8]</ref> the hilbASR algorithm is presented; it computes a defense function against the uniform attack based on Anon IST . hilbASR can be seen as a non-iterative version of Algorithm 1 in which the partitioning is obtained by transforming the two dimensional space into a monodimensional space using the Hilbert space filling function. The transformation into a mono-dimensional space makes it possible to define a total order among users' locations; using this order it becomes easy to partition the set of users into blocks of cardinality k.</p><p>We believe that our general algorithm can be used to define other techniques to compute defense functions for this kind of attacks. Our aim is to further reduce the dimension of the ST Data field of the generalized requests. In particular, the current implementation of our algorithm exploits the internal structure of R-trees to perform the partitioning. Indeed, we can think of a R-tree node N as the container of the set of spatial objects (users' locations, in this case), that are stored in the subtree that has N as root. According to this view, the set of locations contained in a non-leaf node N is partitioned by the children of N . Then, an implementation of Algorithm 1 simply has to traverse the R-tree starting from the root, until a node is reached that has at least one child containing less than k users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we propose a formal framework to model the problem of protecting anonymity of users who access location based services. Differently from previous approaches, our formalism explicitly models the knowledge that is assumed to be possibly reachable by an attacker and provides defense techniques that are specific for that knowledge. A general problem faced by these privacy preservation techniques is the identification of the knowledge that may be actually available to the attacker. While there is no way to precisely obtain this information, a practical approach may be the identification of classes of potential attackers with each class being characterized by the minimum knowledge that subsumes the one of the attackers in that class. Similarly to the qualitative level of protection that a user can set on her browser when accessing online resources, more or less conservative defense techniques may be required for LBS, depending on the above mentioned classes of possible attackers. How exactly to do this is an interesting research direction.</p><p>We are currently working towards the extension of the framework to model also attacks based on traces of multiple requests. A formal understanding of all the subtleties involved in this kind of attacks, will be the basis for the classification of known solutions and for devising new defense techniques. Regarding the defense functions presented in this paper, we are investigating and experimenting new partitioning techniques that preserve privacy but minimize the spatio-temporal generalization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Example of attack when the generalization function is known to the attacker.</figDesc><graphic coords="6,332.53,72.30,188.74,115.72" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* This work was partially supported by the US NSF grants IIS-0430402 &amp; IIS-0430165. The work of Bettini and Mascetti was partially supported by the Italian MIUR InterLink project N.II04C0EC1D.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mix zones: User privacy in location-aware services</title>
		<author>
			<persName><forename type="first">Alastair</forename><forename type="middle">R</forename><surname>Beresford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Stajano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PerCom Workshops</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="127" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Protecting privacy against location-based personal identification</title>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Bettini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sushil</forename><surname>Jajodia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2nd workshop on Secure Data Management (SDM)</title>
		<meeting>of the 2nd workshop on Secure Data Management (SDM)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3674</biblScope>
			<biblScope unit="page" from="185" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The role of quasi-identifiers in k-anonymity revisited</title>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Bettini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sushil</forename><surname>Jajodia</surname></persName>
		</author>
		<idno>RT-11-06</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>DICo, University of Milan</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finding a needle in a haystack -or identifying anonymous census record</title>
		<author>
			<persName><forename type="first">Tore</forename><surname>Dalenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Official Statistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="336" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Location privacy in mobile systems: A personalized anonymization model</title>
		<author>
			<persName><forename type="first">Bugra</forename><surname>Gedik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th International Conference on Distributed Computing Systems (ICDCS)</title>
		<meeting>of the 25th International Conference on Distributed Computing Systems (ICDCS)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="620" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Anonymous usage of location-based services through spatial and temporal cloaking</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gruteser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1st International Conference on Mobile Systems, Applications and Services (MobiSys). The USENIX Association</title>
		<meeting>of the 1st International Conference on Mobile Systems, Applications and Services (MobiSys). The USENIX Association</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Protecting location privacy through path confusion</title>
		<author>
			<persName><forename type="first">Baik</forename><surname>Hoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gruteser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the First International Conference on Security and Privacy for Emerging Areas in Communications Networks (Se-cureComm)</title>
		<meeting>of the First International Conference on Security and Privacy for Emerging Areas in Communications Networks (Se-cureComm)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="194" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Preserving anonymity in location based services</title>
		<author>
			<persName><forename type="first">Panos</forename><surname>Kalnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Ghinta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyriakos</forename><surname>Mouratidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitri</forename><surname>Papadias</surname></persName>
		</author>
		<idno>B6/06</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>National University of Singapore</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An anonymous communication technique using dummies for location-based services</title>
		<author>
			<persName><forename type="first">Hidetoshi</forename><surname>Kido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Yanagisawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tetsuji</forename><surname>Satoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Pervasive Services (ICPS)</title>
		<meeting>of the International Conference on Pervasive Services (ICPS)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="88" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The new casper: query processing for location services without compromising privacy</title>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">F</forename><surname>Mokbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Yin</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walid</forename><forename type="middle">G</forename><surname>Aref</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 32nd International Conference on Very Large Data Bases (VLDB)</title>
		<meeting>of the 32nd International Conference on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="763" to="774" />
		</imprint>
		<respStmt>
			<orgName>VLDB Endowment</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Protecting respondents&apos; identities in microdata release</title>
		<author>
			<persName><forename type="first">Pierangela</forename><surname>Samarati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1010" to="1027" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
