<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FA035244FAA63EE1AFDD66DBC9303144</idno>
					<idno type="DOI">10.1109/TMI.2006.880587</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalized Overlap Measures for Evaluation and Validation in Medical Image Analysis</head><p>William R. Crum*, Oscar Camara, and Derek L. G. Hill, Member, IEEE Abstract-Measures of overlap of labelled regions of images, such as the Dice and Tanimoto coefficients, have been extensively used to evaluate image registration and segmentation algorithms. Modern studies can include multiple labels defined on multiple images yet most evaluation schemes report one overlap per labelled region, simply averaged over multiple images. In this paper, common overlap measures are generalized to measure the total overlap of ensembles of labels defined on multiple test images and account for fractional labels using fuzzy set theory. This framework allows a single "figure-of-merit" to be reported which summarises the results of a complex experiment by image pair, by label or overall. A complementary measure of error, the overlap distance, is defined which captures the spatial extent of the nonoverlapping part and is related to the Hausdorff distance computed on grey level images. The generalized overlap measures are validated on synthetic images for which the overlap can be computed analytically and used as similarity measures in nonrigid registration of three-dimensional magnetic resonance imaging (MRI) brain images. Finally, a pragmatic segmentation ground truth is constructed by registering a magnetic resonance atlas brain to 20 individual scans, and used with the overlap measures to evaluate publicly available brain segmentation algorithms.</p><p>Index Terms-Fuzzy sets, Hausdorff distance, morphological operations, registration, segmentation, validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>O BJECTIVE evaluation of image analysis methods is both vital and generally difficult in medical applications. Two of the most common and important classes of image analysis algorithm with medical applications are image registration and image segmentation. Registration refers to a set of techniques with the shared goal of establishing anatomical or functional correspondence between images acquired at different times, of different subjects, or with different modalities <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Segmentation aims to decompose an image into a number of labelled regions maximising a measure of homogeneity within labels and a measure of heterogeneity between labels. Classically, these homogeneity and heterogeneity measures were based solely on the intensity characteristics of the voxels in the image <ref type="bibr" target="#b2">[3]</ref>. However, in medical applications, image acquisition can affect local intensity characteristics, important biological structures may be Manuscript received <ref type="bibr">April 27, 2006</ref>; revised <ref type="bibr">June 20, 2006</ref>. This work was supported in part by the Medical Images and Signals IRC (EPSRC GR/N14248/01 and UK Medical Research Council Grant D2025/31) and in part by the Modelling, Understanding and Predicting Structural Brain Change Project (EPSRC GR/S48844/01). Asterisk indicates corresponding author. *W. R. Crum is with the Center for Medical Image Computing, University College London, London WC1E 6BT, U.K. (e-mail: b.crum@ucl.ac.uk).</p><p>O. Camara and D. L. G. Hill are with the Center for Medical Image Computing, University College London, London WC1E 6BT, U.K. (e-mail: o.camara-rey@ucl.ac.uk; derek.hill@ucl.ac.uk).</p><p>Digital Object Identifier 10.1109/TMI.2006.880587 composed of more than one tissue type, and boundaries between different tissue classes within single voxels result in intensities that are not characteristic of either tissue. For example, the hippocampus is a structure of considerable importance in volumetric and morphometric studies of ageing and dementia <ref type="bibr" target="#b3">[4]</ref>, but it cannot be separated from surrounding structures in magnetic resonance (MR) images by intensity alone because it is composed of grey and white matter and suffers partial volume effects on its boundaries. Therefore, prior knowledge and modelling of image acquisition and/or variation in appearance under imaging is often necessary to obtain biologically meaningful delineations.</p><p>The goal of most current work in medical image segmentation is to reduce or remove the need for manual intervention. Evaluation is generally difficult as, although it is possible to image phantom objects with known "tissue" properties, in applications of interest the underlying tissue classification is unknown. Haralick <ref type="bibr" target="#b4">[5]</ref> notes, "Measuring how well an algorithm does on perfect data is not interesting. Performance characterisation has to do with establishing the correspondence of the random variations and imperfections which the algorithm produces on the output data caused by the random variations and the imperfections on the input data." Therefore, expert manual segmentation of real images (i.e., by delineating the external contour of a region) is regarded as a practical gold standard against which new segmentation algorithms can be compared. Another approach to evaluation is to use synthetic data where images are constructed from a model where the true structure boundaries are known. Synthetic data rarely captures the rich variety of structure and artifact seen in real images but is often used, especially in early testing. One of the most used synthetic data sets is the MNI BrainWeb digital phantom <ref type="bibr" target="#b5">[6]</ref>, constructed from multiple scans of a single individual, which does allow some imaging artifact to be simulated. Where tissue is subject to mechanical deformation, applications can be validated using biomechanical modelling approaches (e.g., <ref type="bibr" target="#b6">[7]</ref>).</p><p>Image registration can also be evaluated using a segmentation approach. Corresponding regions are segmented on two images that are then registered using an image-driven approach (i.e., without knowledge of the segmentation). The segmentations before and after registration can be compared to assess how well the registration brings them into alignment. <ref type="foot" target="#foot_0">1</ref> Therefore, both registration and segmentation can be evaluated quantitatively if suitable measures of region agreement are available. There have been many attempts to quantify region agreement (or disagreement) including the Hausdorff distance <ref type="bibr" target="#b7">[8]</ref>, the Modified Williams Index <ref type="bibr" target="#b8">[9]</ref> and measures based on information theory <ref type="bibr" target="#b9">[10]</ref>; some of these quantities can be computed using the Valmet software described in <ref type="bibr" target="#b10">[11]</ref>. The two most common measures of region overlap are the Dice Similarity Coefficient (DSC) <ref type="bibr" target="#b11">[12]</ref> and the Tannimoto Coefficient (TC) <ref type="bibr" target="#b12">[13]</ref> (alternatively known as the Jaccard Similarity <ref type="bibr" target="#b13">[14]</ref>) which although often treated separately are related by DSC TC TC <ref type="bibr" target="#b14">[15]</ref> so that they are equal at the extrema {0, 1} and DSC TC between those limits.</p><p>This work is motivated by three observations. The first is that it is increasingly common for automated segmentation algorithms to provide a so-called "partial volume" estimate i.e., rather than each voxel being labelled as belonging or not belonging to a region there is a notion of partial belonging. Where a binary voxel labelling is characterized by the values {0, 1} a partial volume labelling takes values in the continuous range [0, 1] at each voxel. Examples include the use of multi-spectral analysis <ref type="bibr" target="#b15">[16]</ref> and statistical models of partial volume estimation <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b21">[22]</ref>. This situation also occurs in registration when a label is interpolated as it is transformed from one image space to another. The overlap measures commonly used do not explicitly account for this fractional labelling. Some researchers have tried to account for fractional labels by applying thresholds to the continuous distribution of label membership values. For instance, Shattuck et al. <ref type="bibr" target="#b14">[15]</ref> compared a partial volume brain classification with a binary one using the TC by simply labelling each voxel with the pure tissue class having the largest fractional membership. Ashburner and Friston <ref type="bibr" target="#b22">[23]</ref> take a similar thresholding approach. Zou et al. <ref type="bibr" target="#b23">[24]</ref> threshold the fractional membership and integrate the DSC over all possible thresholds and Anbeek et al. <ref type="bibr" target="#b20">[21]</ref> take the maximum value of DSC over all possible thresholds. However, a more powerful approach is to accept that labels that reflect the proportion of tissue in a voxel are inherently nonbinary and apply an evaluation framework that exploits this property. The second observation is that evaluation studies are becoming larger and more complicated. For segmentation algorithms, this means evaluation on many different data sets, possibly acquired at different times, different sites or under different conditions. For registration algorithms, this means evaluation on multiple image-pairs, again possibly acquired under different conditions and also using multiple different labels to assess correspondence of many different important structures or tissue classes. Recent progress in registration has made evaluation even harder with the emergence of groupwise/target-less schemes (e.g., <ref type="bibr" target="#b24">[25]</ref>) where multiple registrations are performed simultaneously either to a known reference space or to one which is determined dynamically from the images as the registration proceeds. In all of these cases, it would be desirable to compute a single "figure of merit," based on overlaps, which describes the overall effectiveness of the segmentation or registration algorithm. Such a figure of merit should accumulate results from multiple subjects and labels and cope with fractional labels in a natural way. The third observation is that overlap measures do not indicate the scale of the region mismatch, only the proportion of the region match. A measure of the scale of mismatch complementary to the overlap measure would provide a more complete summary of an evaluation study.</p><p>This paper expands on the initial work in <ref type="bibr" target="#b25">[26]</ref> to present a generalized framework for overlaps that achieves these goals by defining partial-volume, multilabel overlap measures with an associated error measure. The new overlap measures are first validated on synthetic data which models partial volume effects and for which an analytic result for the overlap is known. The potential of the overlap measure to drive nonrigid registration in conjunction with image data is tested, as it is thought that labels can help resolve ambiguities in image registration. Finally, they are applied to evaluate three of the most widely used brain tissue segmentation algorithms, those found in SPM2 <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, SPM5 <ref type="bibr" target="#b22">[23]</ref>, and FAST <ref type="bibr" target="#b21">[22]</ref> using a segmentation ground truth constructed from real data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. THEORY</head><p>For two overlapping regions, and , the TC is defined as the ratio of the number of voxels in their intersection to that in the union and the DSC is defined as the ratio of the number in the intersection to the mean label volume. In (1), () indicates the number of voxels in the enclosed set <ref type="bibr" target="#b0">(1)</ref> In this section, we first develop fuzzy overlap measures that can summarize the overlap of multiple labels, then discuss different ways to weight the contribution of different labels, and show how a distance parameter can be used to measure the scale of labelling error. We work exclusively with the TC but the development could equally be applied to the DSC and the two are intimately related, as discussed in Section I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiple Fractional Labels</head><p>First, the TC is redefined for fractional labels. To do this, we use established results from fuzzy set theory for the intersection and union of fuzzy sets (e.g., <ref type="bibr" target="#b28">[29]</ref>). The amount of labels and at a voxel , is written as . Then, the fuzzy intersection is the amount of label in common at each voxel and is therefore equal to . Similarly the fuzzy union is the total label at each voxel (counting the shared component only once), and is, therefore, equal to . Therefore, (1) can be rewritten to give the simple fuzzy overlap of a pair of fuzzy labels</p><p>(2)</p><p>The numerator and denominator of (2) can both be accumulated across multiple labels to compute a single overlap figure, , which describes the total overlap of a set of fuzzy labels defined on a single image pair. This overlap is the ratio of the total fuzzy intersection to the total fuzzy union of all labels <ref type="bibr" target="#b2">(3)</ref> In <ref type="bibr" target="#b2">(3)</ref>, is a label-specific weighting factor that affects how much each label contributes to the overlap accumulated over all labels. We defer a discussion of the possible values of to Section II-B. Note that this accumulation preserves the individual contributions of the labels to the total overlap and is not the same as calculating the overlap of a single large label equal to the union of the smaller ones. A further accumulation over all pairs of images gives , describing the total fuzzy overlap of a set of labels defined over an ensemble of image pairs <ref type="bibr" target="#b3">(4)</ref> In ( <ref type="formula">4</ref>), is a pair-specific weighting factor that affects the relative contribution of each image pair to the overlap accumulated over all labels and pairs of images. We again defer a discussion of the possible values of to Section II-B. Equation ( <ref type="formula">4</ref>) allows each pairwise comparison to contribute according to the weighting factors. The overlaps defined in ( <ref type="formula">2</ref>)-( <ref type="formula">4</ref>) ( , ,</p><p>) will be referred to collectively as generalized Tanimoto coefficients (GTC) in the remainder of the paper. We will also make use of label-specific overlaps accumulated over all voxels and subjects denoted and obtained by evaluating (4) with a fixed label index, l.</p><p>An alternative formulation for some applications (e.g., where each pairwise comparison is in the same reference space) would be to compute the ratio of the joint intersection, (JI) and the joint union (JU) at each voxel over all image pairs directly, where and . This would result in a very conservative estimate of the overlap as the smallest label intensity will dominate the JI and the largest label intensity will dominate the JU at each voxel. Therefore, we will not consider this formulation further in this paper.</p><p>From a registration perspective, (4) corresponds to an experiment where multiple pairwise registrations are performed. For targetless registration applications, a reference image is defined dynamically and pairwise comparisons are not appropriate. Therefore we also propose a groupwise overlap measure constructed by considering all overlaps of pairwise permutations of images and applying (4). The number of permutations rapidly becomes very large with increasing and the direct computation of ( <ref type="formula">4</ref>) is slow. Groupwise evaluation can be made more practicable by considering all permutations of a label voxel in images together. Define the label intensity of this voxel in the images as , An and sort by label intensity (so that ). Then expanding the MAX() terms in (4) gives the groupwise union at the voxel as and expanding the MIN() terms gives the groupwise intersection as Therefore, for the groupwise case, the intersection and union are weighted sums of the individual voxel label contributions. Assuming that sorting is an process <ref type="bibr" target="#b29">[30]</ref>, then for images with labels and voxels per image, direct evaluation of (4) carries a computational cost compared with by applying the sorting approach outlined above. For direct evaluation requires a factor 5 more operations than the sorting approach and for direct evaluation requires a factor 25 more operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Label Weightings and Error Estimation</head><p>In ( <ref type="formula">3</ref>) and ( <ref type="formula">4</ref>), weights and , respectively, define the relative contribution of labels (l) and pairs ( ) to the GTC. With , labels are implicitly weighted by their volume so large labels contribute most to the overlap. This may not be desirable as the overlap of smaller labels representing a greater registration or segmentation challenge will not strongly affect the overall overlap. Some alternative choices of are detailed in Table <ref type="table" target="#tab_0">I</ref> and allow all labels to be contribute equally to the overall overlap or to contribute with a volume or complexity dependent weighting. By direct substitution in (3), it can be shown that setting equal to the inverse union of each label pair gives a GTC equal to the mean of the individual TCs computed for each label pair. This confirms that simple averaging of TCs is a special case of the GTC. The complexity measure used here (mean absolute label intensity gradient across nonzero label voxels) will be high for labels with large surface areas and/or voxels with large intensity gradients as might be found in well-defined labels of complicated structures. Low complexity values will be associated with labels with small surface areas and/or voxels with small intensity gradients as might be found in labels of approximately spherical structures, or labels with many partial-volume voxels. The second parameter is used to weight images (or combinations of images) in different ways. It can be used to down-weight labels defined on poor quality images or, where labels have been obtained from different sources such as two manual segmentors, weight them according to reproducibility and accuracy. In the experiments reported in this paper, we have set . When the overlap is accumulated over multiple labels on a pair of images it becomes a measure of the agreement of two partitionings of that image space. When the overlap is accumulated over multiple labels on multiple images, it can be considered as a measure of the agreement of two partitionings of a "super-space" composed of the individual image spaces. Different choices of and change the relative importance of various pairings and labelings within the space.</p><p>There are two standard overlap results reported in this paper: 1) the overlap for a specific label accumulated over multiple image pairs, and 2) the overlap accumulated over a set of labels and image pairs as in (4). For case 1) we assume that each pairwise label overlap is an independent measurement drawn from a normal distribution. Therefore, the associated variance can be computed in the standard way. For case 2), we assume that each overlap accumulated over all labels in each pair of images is an independent measurement drawn from a normal distribution. Again the associated variance can be computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Tolerance and the Scale of Nonoverlap</head><p>Simple label overlaps do not provide any information about the nonoverlapping label portions such as the scale of mismatch. Pichon et al. <ref type="bibr" target="#b30">[31]</ref> noted some previously proposed estimates of distance error, which are functions of the distance of each missegmented voxel to the ground truth, and then introduced a more symmetric error distance and defined some statistical quantities related to the misclassification probability and the mean and worst-case distance error. Although shown to be related, at least in part, to the DSC these measures are not a natural extension of overlap measures and have not been defined for fractional labels. Another previously proposed method of learning about the error scale directly through the overlap is to apply a spatial tolerance to the label intersection <ref type="bibr" target="#b31">[32]</ref>. The standard GTC is, by definition, since pairs of label voxels have to occupy the same space to be considered overlapping. However, allows label voxels to be considered overlapping if they lie within millimeters of each other. In the overlap measures considered here, the relative overlap is defined by the label intersection (numerator) which is then divided by the union (Tanimoto) or mean volume (Dice) to give the normalized overlap. Therefore relaxing the criterion for overlap can be implemented, in both cases, by relaxing the criterion for label intersection. This can be incorporated into the existing framework by applying a morphological dilation operator, , to each label in turn. The fuzzy dilation operator is a generalization of the familiar binary morphological operator.</p><p>is represented as a voxel mask of dilation coefficients centered on the voxel of interest with representing the extent of the operator. In one-dimension (1-D), where the voxel dimension is 1 mm for example, , , , etc. When considering fractional tolerances then , , etc., where . Then the fuzzy dilation applied at a single voxel in 1-D is where and ; this is consistent with the definition of <ref type="bibr" target="#b32">[33]</ref>. A graphical example of fuzzy dilation is shown in Table <ref type="table" target="#tab_1">II</ref> where dilation kernels for are applied to an example 1-D array of image pixels. Starting from the definition of overlap for fractional labels TC (2) we define fuzzy overlap to a noninteger tolerance in a symmetrical way, as shown in <ref type="bibr" target="#b4">(5)</ref>  In <ref type="bibr" target="#b4">(5)</ref>, it can be seen that the normalizing denominator (union term) is unchanged but the numerator (intersection term) takes the maximum value at each voxel of the intersection of with dilated and with dilated . The maximum possible overlap given by ( <ref type="formula">5</ref>) can be established by assuming that and are fractional labels in the range [0, 1] with both having at least one label voxel equal to 1. Then, when the summand in the numerator reduces to since for large ) and the maximum overlap is 1 as expected. Note that is an increasing function of for . In cases where the maximum label voxel is 1 but identical for and the above argument holds. For cases where and have different maxima then both can be upper thresholded at MIN(MAX( ), MAX( )) and the argument above will hold but may be underestimated.</p><p>The smallest value of for which the overlap is 1 can be used as a measure of the scale of the nonoverlapping region. We define this as the overlap distance (OD) where . This quantity is related to a classical measure of distance between sets, the Hausdorff distance (HD). For overlapping binary sets, the HD can be obtained by generating, for each set in turn, the set of distances from each point in one set to the nearest point in the other set, and then taking the largest of all these distances <ref type="bibr" target="#b7">[8]</ref>. There have been a number of attempts to define the HD for fuzzy-sets or for grey-level images; see <ref type="bibr" target="#b33">[34]</ref> for a review. In <ref type="bibr" target="#b34">[35]</ref>, the HD is defined in terms of dilation operators as where and are nonempty compact overlapping sets and ( , ) returns the smallest value of a dilation parameter for such that . This is a more conservative definition than we have used in <ref type="bibr" target="#b4">(5)</ref>. In our nomenclature, the definition of an overlap incorporating the HD as a tolerance parameter according to <ref type="bibr" target="#b34">[35]</ref> is shown in (6) at the bottom of the page. In <ref type="bibr" target="#b5">(6)</ref>, the intersection is computed for all voxels in each image being dilated in turn and then the largest of the resulting intersections is chosen. In our definition of the OD, the maximum intersection at each voxel in turn is chosen. Therefore, the OD is less sensitive to outliers and smaller than the HD since the maximum overlap will be achieved for . This is easily seen by comparing ( <ref type="formula">5</ref>) and ( <ref type="formula">6</ref>) and noting that for two real sets, and</p><p>Now consider a pair of misregistered images where every voxel is independently labeled and the same set of labels exists in each image but are not necessarily coincident. Then the overlap of any pair of labels (voxels) can be computed as described above. For each labeled voxel in the target image, the OD can be computed. Then the map of OD for all voxels is a map of target registration error. For labels spanning multiple voxels, the OD gives an estimate of residual displacement between corresponding labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS</head><p>Experiments were performed to validate the theory and implementation of the GTC, use it as a similarity measure to register sets of labels and to evaluate three publicly available brain tissue classification algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Validation of the GTC Using Synthetic "Petal" Data</head><p>To validate the theory and software implementation of the fuzzy overlap calculation, we used a synthetic test object designed to be simple enough that an analytic expression for the overlap could be obtained, but to also feature a nontrivial border which would exhibit partial volume effects in an image of the object. A "petal" object meets these criteria and can be described in two-dimensional (2-D) polar coordinates by ( <ref type="formula">8</ref>) where and a are constant lengths , is the number of wavelengths (petals) and is an angular offset . By varying , a set of pairs of images with varying overlap can be created. The other panels in Fig. <ref type="figure">1</ref> show subtraction images of pairs of petal object of increasingly different angular offset . We evaluated the overlap between such pairs of images in two ways 1) analytically using (8) and 2) by measurement from images of the objects. For details of the analytic computation and the generation of partial volume images of these shapes, see the Appendix.</p><p>For the same pairs of shapes, we computed the HD numerically by exhaustive sampling of points on the external contour of both shapes, and compared this with the OD computed from the corresponding image pairs using (5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Application of the GTC to Image and Label Registration</head><p>The use of the GTC to act as a similarity measure for nonrigid registration was evaluated using 9 of the 18 publicly available three-dimensional (3-D) T1-weighted labelled MR-brain images from the Internet Brain Segmentation Repository. <ref type="foot" target="#foot_1">2</ref> The images used (numbers 02, 04, 06, 07, 08, 10, 11, 12, and 16) were qualitatively assessed to have the best contrast and least artifact to minimise associated labelling errors. Each image had voxels of either or and had ten binary anatomical labels, one for each of the following structures: amygdala, caudate, cerebellum, cortex, hippocampus, lateral ventricle, pallidum, putamen, thalamus, and white matter. A tenth image (09) with the same labels was chosen as a reference. Each image was registered to the reference using a fluid registration algorithm <ref type="bibr" target="#b6">[7]</ref> with two resolution levels (half and full resolution). The registration was performed in three different ways: 1) the grey-level image data was registered by maximizing the intensity cross correlation; 2) images containing the label-sets defined above were registered by maximizing the GTC computed over all labels; 3) grey-level image and label image pairs were registered by maximizing the sum of the intensity cross correlation and total overlap. To do this, the GTC was implemented as a voxel-wise force to drive the fluid registration. For the specific case here, where the target image labels are binary, each fluid force component at voxels with nonzero labels in the target image, is proportional to the difference in label intensities between source voxels neighboring the corresponding target voxel i.e., a centered difference scheme that strives to match the intensity of corresponding source and target label voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Application of the GTC to Segmentation Evaluation</head><p>The final experiment applies the GTC to evaluate three widely used brain tissue segmentation algorithms SPM2,<ref type="foot" target="#foot_2">3</ref> SPM5<ref type="foot" target="#foot_3">4</ref> and FAST.<ref type="foot" target="#foot_4">5</ref> SPM2 employs a modified mixture model cluster analysis technique <ref type="bibr" target="#b26">[27]</ref> including a correction for image intensity nonuniformity <ref type="bibr" target="#b27">[28]</ref>. SPM5 again uses Gaussian mixture model techniques but treats tissue segmentation as one part of an integrated spatial normalization process that includes estimation of nonuniformity correction and warping parameters. FAST uses a hidden Markov Random Field model to explicitly incorporate spatial information into the process <ref type="bibr" target="#b21">[22]</ref>. A data set with known tissue class segmentation was constructed for the evaluation. 35 flip angle. Each reconstructed scan consisted of 124 1.5 mm slices with 256 256 voxels of size 0.9375 0.9375 mm in-plane. The MNI BrainWeb T1-weighted brain <ref type="bibr" target="#b5">[6]</ref> was then fluidly registered at half resolution to each brain in turn <ref type="bibr" target="#b6">[7]</ref>. The resulting warp-fields were used to transform both the MNI BrainWeb T1-weighted noise-free brain image, and its associated partial volume labels for grey-matter, white-matter and CSF into the space of each subject in turn using trilinear interpolation. The 20 transformed BrainWeb images with added Rician noise (2% of maximum intensity on two independent Gaussian channels) formed the test-set for the segmentation evaluation. Fig. <ref type="figure" target="#fig_2">2</ref> shows example axial and coronal slices from four of the transformed images showing the range of appearance despite all images being derived from the same reference scan. To check the consistency of the registration, the CSF, grey matter and white matter volumes were computed from the warped tissue maps for each image and compared for time-point 1 and time-point 2 in each case under the assumption that as the subjects were normal controls, no volume change should have occurred. The mean (sd) of the absolute difference in tissue volume between time points as a percentage of the mean tissue volume was CSF: 2.0% (2.2%), grey matter: 1.0% (1.1%), white matter 0.7% (0.9%). These figures should be compared with the percent standard deviations in each tissue volume for the ten time-point one scans which were: CSF: 10.4%; grey matter: 7.1%; white matter: 7.1%. The results indicate that tissue class warping is consistent to 1% by volume in grey-matter and white matter with approximately twice that variation in CSF. The transformed BrainWeb tissue labels were used as the gold-standard segmentation results. This experiment does not depend on perfect inter-subject brain registration since the evaluation is done purely on transformed BrainWeb images.</p><p>To perform the evaluation, each segmentation algorithm was applied to the 20 test images in turn to produce partial volume estimates of the three tissue classes. Each algorithm was applied "out of the box" in that all default parameter settings were used. In the case of FAST, the Brain Extraction Tool (BET) was used to presegment brain from nonbrain as this is the recommended use. One case was subsequently removed from the study as BET failed to achieve a good brain extraction.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Validation of the GTC Using Synthetic "Petal" Data</head><p>Fig. <ref type="figure" target="#fig_3">3(a)</ref> shows excellent agreement between the overlap computed analytically and that measured experimentally from the partial-volume images for a range of offset values. This confirms that the software implementation of the overlap measure is correct and that the overlap of structures with ill-defined borders can be recovered using partial volume assumptions. The percentage fractional error of the experimental result compared with the theoretical result is shown in Fig. <ref type="figure" target="#fig_3">3(b</ref>) for two cases: 1) with the fuzzy label voxels described above and 2) where each fuzzy label voxel was thresholded at the 50% intensity level to create a binary label voxel equivalent. The fuzzy case has mean (standard deviation) error 0.06% (0.02%) whereas the binary case has mean (s.d.) 0.16% (0.06%). In this simple experiment the error as a fraction of measured overlap is low in both cases but the fuzzy measurement slightly overestimates the computed overlap suggesting an effect of the discretization of the petal shape. Fig. <ref type="figure" target="#fig_4">4</ref> shows the relationship between the OD and the HD, again as a function of the angular offset. As predicted with the difference becoming larger for larger angular offsets and smaller overlaps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Application of the GTC to Image and Label Registration</head><p>Fig. <ref type="figure">5</ref> shows the relationship between the intensity cross correlation (voxel similarity) and the GTC (label similarity) Fig. <ref type="figure">5</ref>. Relationship between the mean image similarity measure and the GTC computed over all labels and subjects for the unregistered, image-registered, label-registered and image+label-registered cases. Image similarity was computed over the entire image volume in each case.</p><p>for the unregistered, image-registered, label-registered, and image label-registered experiments. As expected, the unregistered data has the lowest image similarity and label overlap. The image-registered data has the largest image-similarity and also improves the label overlap. The label-registered data has a significantly larger label overlap and an improved image similarity over the unregistered data. The key result is that the image label registered data has an image similarity larger than the label-registered case-which we would expect-and a label overlap larger than the label registration case-which we might not expect. Therefore, the image and label information used together for registration is resulting in high image similarity and high label overlap representing a compromise between image and label features. labels contain a relatively sparse set of information for registration compared with the original image data raising the possibility of local minima during the optimization procedure. The results here suggest that the additional voxel intensity information used in the image label registration experiment has a beneficial effect in avoiding such minima. Fig. <ref type="figure" target="#fig_5">6</ref> shows the breakdown of the results of Fig. <ref type="figure">5</ref> for each label. The significance of the difference of label overlaps between each pair of registration experiments was assessed using the paired, two-tailed student -test and found to be significant in all cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Application of the GTC to Segmentation Evaluation</head><p>We applied the three segmentation procedures to the test images to produce fuzzy tissue maps for grey matter, white matter, and CSF. These were compared against the transformed MNI tissue maps. Fig. <ref type="figure" target="#fig_6">7</ref> shows the GTC over all subjects and labels for the three methods compared with the known segmentations. Results are presented for the four different label weightings discussed in Section II-B. The performance of FAST and SPM5 are comparable for the equal-weighting case with SPM5 significantly better for the inverse volume weighting case and FAST significantly better for the volume weighting case. SPM2 has significantly poorer performance than the other two methods.   These results can be broken down further by examining the overlaps for each tissue class [Fig. <ref type="figure" target="#fig_7">8(a)</ref>]; again the results were comparable for SPM5 and FAST for each tissue class with the overall results for CSF worse than GM and WM. Visual examination of the CSF tissue labels showed that both SPM (both versions) and FAST are overestimating the cortical CSF compared with the gold standard; this tissue class is the most challenging to classify due to the poorly defined boundary in MR between cortical CSF and the meninges. To assess the effect of misclassification outside the brain the GTCs were recomputed  after the application of a brain mask derived from the known GM, WM, and CSF maps for each subject. The results for GM and WM were unchanged but there was significant improvement in the results for CSF in all three cases and SPM5 improved the most [Fig. <ref type="figure" target="#fig_7">8(b)</ref>]. These results confirm that all three algorithms tended to misclassify (or over-classify) extra-cortical voxels as CSF. Fig. <ref type="figure" target="#fig_8">9</ref> shows how the unmasked overlap varies with the tolerance overall and for each tissue class. For grey matter and white matter in all cases, a large increase in overlap is achieved for a tolerance of 1 mm indicating that the tissue boundary determined by these algorithms is spatially close to the gold-standard. For tolerances 0.0 mm, FAST is consistently superior for CSF segmentation and this effect is large enough to result in a similar trend in the total overlap. Fig. <ref type="figure" target="#fig_9">10</ref> shows the relationship between GTC and OD for each tissue class in each segmentation. In terms of OD, the average performance of the three techniques is similar, giving OD 2.0 mm for white matter and 3.0 mm for grey matter. The OD is larger and exhibits more variation for CSF consistent with the overlap results in Figs. <ref type="figure" target="#fig_6">7</ref> and<ref type="figure" target="#fig_7">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSION AND CONCLUSTION</head><p>There is a need for better evaluation techniques for image segmentation and registration algorithms. One of the biggest problems in medical image analysis remains the lack of gold standards for many segmentation applications. Time-consuming manual segmentation with its inherent variability remains necessary but is often limited by resource and expertise. As recently as 2005, a comparative study of brain segmentation methods used expert manual segmentation of just two slices from just one normal MR brain study as a ground truth <ref type="bibr" target="#b35">[36]</ref>.</p><p>One alternative strategy is to use the segmentation estimates themselves to produce a plausible ground truth. <ref type="bibr">Warfield et al.</ref> have recently introduced the STAPLE (Simultaneous Truth and Performance Level Estimation) algorithm for validation of image segmentation that estimates the "true" segmentation from a set of input segmentation estimates <ref type="bibr" target="#b36">[37]</ref>. The ground truth estimate will depend strongly on the input data (since STAPLE does not perform segmentation using image data) and the assumptions inherent in STAPLE (see later). An objective ground-truth that can be generated without excessive manual intervention remains a desirable goal. Our approach in this paper was to use a standard template for brain anatomy but to warp it to resemble volunteer brains. This is clearly only a partial solution, not least due to the assumption that the effects of interpolation are consistent between the grey-level image and the tissue maps. The other limitation is that there is nonrigid variation in the gross neuroanatomy but essentially the same cortical structure in our test images. It is possible in principle to use the transformed tissue templates to simulate new more realistic MR volumes but this does not avoid the fact that there would still be little variation in the geometry of the cortex. More sophisticated methods of simulating variation in neuroanatomy <ref type="bibr" target="#b37">[38]</ref> may result in improved evaluation data becoming available.</p><p>The results of the segmentation evaluation (Section IV-C) provide some evidence for convergence in the performance of contemporary brain tissue classification algorithms; it is worth noting that we did not try to optimize the performance of any of the algorithms by preprocessing the data or by using nondefault parameter settings. SPM5 was previously evaluated in <ref type="bibr" target="#b22">[23]</ref> (Table <ref type="table" target="#tab_0">I</ref>) where the DSC was computed for grey matter and white matter after thresholding a fuzzy segmentation of the T1-weighted BrainWeb brain to give Dice overlaps of 0.93 (grey matter) and 0.96 (white). Converting our GTC to a GDSC (generalized Dice Similarity Coefficient) gives GDSC overlaps of 0.88 (grey matter) and 0.92 (white matter), which are lower by approximately 5% but have the same trend. Of future interest is how the increasingly subtle differences in performance between automated brain classification algorithms affect clinical research studies.</p><p>To be useful in large-scale studies, measures of segmentation quality must be amenable to statistical analysis. The relationship of the DSC to the Kappa statistic <ref type="bibr" target="#b38">[39]</ref> is often mentioned in the literature on segmentation evaluation but rarely explicitly exploited. Similarly it is also often reported that a value for the indicates "excellent agreement" between data under consideration but the relevance of this to segmentation evaluation is questionable and as noted in <ref type="bibr" target="#b38">[39]</ref>, "most of its merit lies in the fact that it provides a value that can be used to compare the similarities between measurement pairs." Zou et al. <ref type="bibr" target="#b23">[24]</ref> suggest a fuller statistical framework for the DSC.</p><p>One key step in their formulation is to apply the logit transform to transform the domain of the DSC from [0, 1] to . We note in passing that effectively this means a different overlap measure is being analyzed, defined as the ratio of the (Dice) overlap to the nonoverlap. A similar analysis could be applied to the measures in this work; to date we have compared total overlaps using associated variances in a very simple way.</p><p>Ultimately, definitive validation requires a number of approaches that will be dictated by the application at hand. The STAPLE approach is potentially very powerful, especially for comparison of trained manual segmentors, but does come with assumptions. From <ref type="bibr" target="#b36">[37]</ref>, "Implicit in this model is the notion that experts have been trained to interpret the images in a similar way, the segmentation decisions may differ due to random or systematic rater differences ". It is not clear how far these assumptions will apply to automated segmentation techniques. Of particular relevance to this work is the assumption of STAPLE that the ground truth at each voxel is a single binary label. In addition the ability of STAPLE to establish a ground-truth from a number of segmentation estimates should improve given more segmentation estimates but also weaken given fewer. As the estimate of the ground truth becomes worse, so does the ability to compare raters. Simple overlap measures like the ones described in this paper remain of value for these reasons. Indeed in <ref type="bibr" target="#b39">[40]</ref>, where a comparative study of STAPLE and the Williams index for brain tissue classification was performed, it was concluded that "When no ground truth is required, we recommend the use of Williams index as it is easy and fast to compute." Pairwise generalized overlap measures are also relatively fast to compute requiring minutes on contemporary desk-top processors for the entire sets of images and labels used in this paper. However, at present the computation of the OD is costly because fuzzy dilation is relatively slow to compute (several minutes per label per pair) and an optimization over several fuzzy dilations is required. Measures related to the HD are typically difficult to compute efficiently, however our implementation of this calculation is currently far from optimal so there is potential for significant improvement.</p><p>In addition to validation applications, the generalized overlaps can be used to drive registration using label information. Registration of labels has previously been reported by D'Agostino et al. <ref type="bibr" target="#b40">[41]</ref> who used the Kullback-Leibler distance between an ideal joint tissue class probability distribution and one evaluated during fluid registration as a similarity measure. Camara et al. <ref type="bibr" target="#b41">[42]</ref> used the root mean square difference of voxel label intensities to register thoracic/abdominal structures in positron emission tomography (PET) and computerized tomography (CT) images. Frangi et al. <ref type="bibr" target="#b42">[43]</ref> used the label consistency measure, which is essentially a TC, and a Kappa statistic measure that is related to the DSC, for Free Form Deformation registration of labelled MR cardiac images and found no significant difference between them. Even earlier, Christensen et al. <ref type="bibr" target="#b43">[44]</ref> used segmentation of key structures in pelvic CT scans to drive fluid registration of serial CT scans of subjects undergoing intracavitary brachytherapy. The GTC combines the advantages of the previous work, specifically, that multiple fractional labels can be registered together by maximizing a global similarity measure which incorporates partial volume labelling effects. Using labels simplifies the correspondence problem and can mask confounding image information, where there are large differences between images. We also reported one way of combining image and label information-by summing image and label voxel forces in fluid registration-that in our experiment slightly improved the overall label match. In general, the purpose of combining label and image information is to make the registration robust away from the labels and guarantee known correspondence in the vicinity of the labels. The registration transformation could be initialized using the difference in position of centres of mass of corresponding labels but we have not attempted this here.</p><p>In future work, we hope to explore the relationship between the OD and the GTC more fully and develop a statistical framework for the analysis of overlap computed over different subsets of the images and labels under consideration. We plan to explore the potential for a small number of labels to resolve problems in contemporary nonrigid registration problems. In summary, we have presented a flexible framework for computing generalized label overlaps which offers a natural way to summarize the results of complex registration and segmentation studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>To compute the overlap analytically, we consider a pair of images described by <ref type="bibr" target="#b7">(8)</ref>, one with and the other with so that and (Fig. <ref type="figure" target="#fig_10">11</ref>). Then the areas of intersection and union of the overlapping pair are given by (9) <ref type="bibr" target="#b8">(9)</ref> In <ref type="bibr" target="#b8">(9)</ref>, corresponds to the outline of the intersection of the objects and corresponds to the outline of the union of the objects. To compute these integrals, we observe that (Fig. <ref type="figure" target="#fig_10">11</ref>), the external contours of the pair of images defined above intersect at angles given by (i.e., when ) and that there are two such crossings and in each wavelength. Therefore, the integrals in ( <ref type="formula">9</ref>) can be split into three segments , , and where MIN( 1, 2) or MAX( 1, 2) in the expressions for and consistently returns or for the whole of the segment. Expressions for the area of intersection and union are then obtained by expanding the squared terms in (9) and using elementary methods to evaluate each segment separately. For the validation experiments, we generated voxelated partial volume image pairs representing the same shapes. First an empty image was defined and then, all voxels outside the maximum extent of the shape were set to zero and all voxels within of the centre of the shape to 255. Then each voxel in the "petal" region was set to zero and subdivided into a grid of . Each point on the grid was identified as being inside or outside the shape by computing its 2-D radial polar coordinates and using <ref type="bibr" target="#b8">(9)</ref>. Then the intensity was set to 255.number_points_inside/total_number_of_points to represent partial volume effects at each voxel.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 6 )Fig. 1 .</head><label>61</label><figDesc>Fig. 1. Basic petal object with zero offset and subtraction of a pair of petal objects with increasing angular offset with respect to each other.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 8 )Fig. 1 (</head><label>81</label><figDesc>Fig. 1 (left panel) shows the object described by (8) with , , and. By varying , a set of pairs of images with varying overlap can be created. The other panels in Fig.1show subtraction images of pairs of petal object of increasingly different angular offset . We evaluated the overlap between such pairs of images in two ways 1) analytically using (8) and 2) by measurement from images of the objects. For details of the analytic computation and the generation of partial volume images of these shapes, see the Appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples slices from four of the test images used for the segmentation evaluation. Coronal and axial slices were selected visually to show the same anatomy. Images were obtained by warping the MNI BrainWeb noise-free T1-weighted image onto normal control images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Left graph compares the analytical result for the overlap of a pair of petal objects with varying relative angular offset with that measured from generated images incorporating partial volume effects. Graph shows the percentage fractional overlap error for the fuzzy petal labels and where each fuzzy petal label voxel has been thresholded at the 50% level.</figDesc><graphic coords="6,305.16,66.70,246.00,71.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison of the HD computed for pairs of the petal object with different relative angular offsets with the OD computed from the corresponding image pairs. Theory predicts that the OD HD. See text for further details.</figDesc><graphic coords="6,305.16,206.26,246.00,176.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Breakdown of the results in Fig.5for the individual labels. Image similarity was computed over the voxels comprising each label in the target space.</figDesc><graphic coords="7,321.36,66.78,210.00,207.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The GTC computed over all labels and subjects for the segmentation evaluation experiment. Groupings on the x axis correspond to different label weightings in the overall overlap. See text for full details.</figDesc><graphic coords="7,303.66,315.40,246.00,128.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. (a) GTC computed over all subjects for each label in the segmentation evaluation experiment. Across subjects, each label was weighted equally. (b) GTC for CSF after application of a brain mask.</figDesc><graphic coords="7,303.66,494.14,246.00,92.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Relationship between overlap and overlap tolerance for grey matter, white matter and CSF and overall for the three segmentation algorithms. Standard errors are not shown for clarity but are 0.01 for = 0:0 falling to 0.001 for = 5:0.</figDesc><graphic coords="8,43.14,311.86,243.00,95.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Relationship between the generalized Tanimoto Coefficient and the OD for CSF, GM, and WM for three segmentation methods. Note that the OD was limited to a maximum of 10.0 mm in the calculation; in the case of the CSF calculation for SPM2 all ODs were limited resulting in an apparent standard deviation of 0.0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Radial profiles of the petal object over the angular range spanning one petal (n = 6) (a) the radius of two petal objects with an angular offset (b) the MIN and MAX of the profiles in (a) corresponding with the intersection and union object.</figDesc><graphic coords="9,303.66,66.58,246.00,77.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I WEIGHTINGS</head><label>I</label><figDesc></figDesc><table /><note><p>USED BETWEEN DIFFERENT LABELS</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II SCHEMATIC</head><label>II</label><figDesc>OF THE EFFECT OF FUZZY DILATION IN 1-D</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The segmentation must be of high quality to avoid the propagation of segmentation errors into the registration evaluation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.cma.mgh.harvard.edu/ibsr.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://www.fil.ion.ucl.ac.uk/spm/software/spm2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>http://www.fil.ion.ucl.ac.uk/spm.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>http://www.fmrib.ox.ac.uk/analysis/research/fast.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Prof. N. Fox of the Dementia Research Centre, Institute of Neurology, University College London, for the MR brain data used to construct the segmentation gold standard. This paper benefited and stemmed from discussions within the Integrated Brain Image Modelling project (EPSRC GR/S82503/01). The authors would also like to thank two anonymous reviewers for constructive comments that have improved this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image registration methods: A survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zitova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Flusser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="977" to="1000" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Non-rigid image registration: Theory and practice</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Crum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hartkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L G</forename><surname>Hill</surname></persName>
		</author>
		<idno>140-S153</idno>
	</analytic>
	<monogr>
		<title level="j">Br. J. Radiol</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on evaluation methods for image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1335" to="1346" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Presymptomatic hippocampal atrophy in Alzheimer&apos;s disease-A longitudinal MRI study</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Warrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Freeborough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hartikainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Rossor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2001" to="2007" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Performance characterization in computer vision</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP: Image Understanding</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="249" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MRI simulation-based evaluation of image-processing and classification methods</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>-S. Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Pike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1085" to="1097" />
			<date type="published" when="1999-11">Nov. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Anisotropic multi-scale fluid registration: Evaluation in magnetic resonance breast imaging</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Crum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="5153" to="5174" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparing images using the Hausdorff distance</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Klanderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Rucklidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="850" to="863" />
			<date type="published" when="1993-09">Sep. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A methodology for evaluation of boundary detection algorithms on medical images</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chalana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="642" to="652" />
			<date type="published" when="1997-05">May 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Measuring global and local spatial correspondence using information theory</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C F</forename><surname>Colchester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1496</biblScope>
			<biblScope unit="page" from="964" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Valmet: A new validation tool for assessing and improving 3-D object segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jomier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="516" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Measures of the amount of ecologic association between species</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Dice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="297" to="302" />
			<date type="published" when="1945">1945</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<title level="m">Pattern Classification and Scene Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nouvelles recherches sur la distribution florale</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jaccard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin de la Societe Vaudoise des Sciences Naturelles</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="223" to="270" />
			<date type="published" when="1908">1908</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Magnetic resonance image tissue classification using a partial volume model</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Shattuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Sandor-Leahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Schaper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Rottenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Leahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="856" to="876" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving tissue classification in MRI: A three-dimensional multispectral discriminant analysis method with automated training class selection</title>
		<author>
			<persName><forename type="first">G</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Andreasen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cizadlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Bockholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Magnotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Assist. Tomogr</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="144" to="154" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast and robust parameter estimation for statistical partial volume models in brain MRI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tohka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zijdenbos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neu-roImage</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimation of the partial volume effect in MRI</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A G</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="389" to="405" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Validation of partial tissue segmentation of single-channel magnetic resonance images of the brain</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Grabowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Szumski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Damasio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="640" to="656" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A unifying framework for partial volume segmentation of brain MR images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Van Leemput</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="119" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probabilistic segmentation of brain tissue in MR imaging</title>
		<author>
			<persName><forename type="first">P</forename><surname>Anbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Vincken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Van Bochove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J P</forename><surname>Van Osch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Der Grond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="795" to="804" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="57" />
			<date type="published" when="2001-01">Jan. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unified segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="839" to="851" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Statistical validation of image segmentation quality based on a spatial overlap index</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bharatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M C</forename><surname>Tempany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Kaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Haker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Jolesz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academic Radiol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="178" to="189" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A template free approach to volumetric spatial normalization of brain anatomy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Studholme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cardenas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1191" to="1202" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">generalized overlap measures for assessment of pairwise and groupwise image registration and segmentation</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Crum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Camara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L G</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3749</biblScope>
			<biblScope unit="page" from="99" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multimodal image coregistration and partitioning-A unified framework</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="209" to="217" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Voxel-based morphometry-The methods</title>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="805" to="821" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prade</surname></persName>
		</author>
		<title level="m">Fundamentals of Fuzzy Sets</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Vetterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Flannery</surname></persName>
		</author>
		<title level="m">Numerical Recipes in C++: The Art of Scientific Computing</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A statistically based flow for image segmentation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pichon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tannenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="274" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Zen and the art of medical image registration: Correspondence, homology and quality</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Crum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L G</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1425" to="1437" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fuzzy spatial relationships for image processing and interpretation: A review</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="89" to="110" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fuzzy mathematical morphologies-A comparative-study</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Maitre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1341" to="1387" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On distances between fuzzy points and their use for plausible reasoning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Syst. Man Cybernetics</title>
		<meeting>Int. Conf. Syst. Man Cybernetics</meeting>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="300" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Comparison and validation of tissue modelization and statistical classification methods in T1-weighted MR brain images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bach Cuadra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cammoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Butz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cuisenaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Thiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1548" to="1565" />
			<date type="published" when="2005-12">Dec. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Simultaneous truth and performance level estimation (STAPLE): An algorithm for the validation of image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="903" to="921" />
			<date type="published" when="2004-07">Jul. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Statistical representation and simulation of high-dimensional deformations: Application to synthesizing brain deformations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Karacali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Med. Image Comput. Computer-Assisted Intervention</title>
		<imprint>
			<biblScope unit="volume">3749</biblScope>
			<biblScope unit="page" from="500" to="508" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Morphometric analysis of white matter lesions in MR images: methods and validation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Zijdbenos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Dawant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Margolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="716" to="724" />
			<date type="published" when="1994-04">Apr. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Two methods for validating brain tissue classifiers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Martin-Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bouix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Mccarley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Shenton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3749</biblScope>
			<biblScope unit="page" from="515" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An information theoretic approach for non-rigid image registration using voxel class probabilities</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agostino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Med. Image Computing Computer Assisted Intervention</title>
		<imprint>
			<biblScope unit="volume">2879</biblScope>
			<biblScope unit="page" from="812" to="820" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Free form deformations guided by gradient vector flow: A surface registration method in thoracic and abdominal PET-CT applications</title>
		<author>
			<persName><forename type="first">O</forename><surname>Camara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Delso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Biomed. Registration</title>
		<meeting>Workshop Biomed. Registration</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2717</biblScope>
			<biblScope unit="page" from="224" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Automatic construction of multiple-object three-dimensional statistical shape models: application to cardiac modelling</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Niessen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1151" to="1166" />
			<date type="published" when="2002-09">Sep. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Image-based dose planning of intracavitary brachytherapy: Registration of serial-imaging studies using deformable anatomic templates</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S C</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Grigsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Radiat. Oncol. Biol. Phys</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="227" to="243" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
