<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Effective Strong Dimension, Algorithmic Information, and Computational Complexity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Krishna</forename><forename type="middle">B</forename><surname>Athreya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Operations Research and Industrial Engineering</orgName>
								<orgName type="department" key="dep2">Departments of Mathematics and Statistics</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>14853</postCode>
									<settlement>Ithaca</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Iowa State University</orgName>
								<address>
									<postCode>50011</postCode>
									<settlement>Ames</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Hitchcock</surname></persName>
							<email>jhitchco@cs.iastate.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Iowa State University</orgName>
								<address>
									<postCode>50011</postCode>
									<settlement>Ames</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jack</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
							<email>lutz@cs.iastate.edu</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Iowa State University</orgName>
								<address>
									<postCode>50011</postCode>
									<settlement>Ames</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elvira</forename><surname>Mayordomo</surname></persName>
							<email>elvira@posta.unizar.es</email>
							<affiliation key="aff4">
								<orgName type="department">Departamento de Informática e Ingeniería de Sistemas</orgName>
								<orgName type="institution">Universidad de Zaragoza</orgName>
								<address>
									<postCode>50015</postCode>
									<settlement>Zaragoza</settlement>
									<country key="ES">SPAIN</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Effective Strong Dimension, Algorithmic Information, and Computational Complexity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DED62D19C454E87B7173B3BAA3F4BB8C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The two most important notions of fractal dimension are Hausdorff dimension, developed by <ref type="bibr" target="#b11">Hausdorff (1919)</ref>, and packing dimension, developed independently by <ref type="bibr" target="#b41">Tricot (1982)</ref> and <ref type="bibr" target="#b39">Sullivan (1984)</ref>. Both dimensions have the mathematical advantage of being defined from measures, and both have yielded extensive applications in fractal geometry and dynamical systems. <ref type="bibr" target="#b3">Lutz (2000)</ref> has recently proven a simple characterization of Hausdorff dimension in terms of gales, which are betting strategies that generalize martingales. Imposing various computability and complexity constraints on these gales produces a spectrum of effective versions of Hausdorff dimension, including constructive, computable, polynomial-space, polynomial-time, and finite-state dimensions. Work by several investigators has already used these effective dimensions to shed significant new light on a variety of topics in theoretical computer science.</p><p>In this paper we show that packing dimension can also be characterized in terms of gales. Moreover, even though the usual definition of packing dimension is considerably more complex than that of Hausdorff dimension, our gale characterization of packing dimension is an exact dual of -and every bit as simple as -the gale characterization of Hausdorff dimension.</p><p>Effectivizing our gale characterization of packing dimension produces a variety of effective strong dimensions, which are exact duals of the effective dimensions mentioned above. In general (and in analogy with the classical fractal dimensions), the effective strong dimension of a set or sequence is at least as great as its effective dimension, with equality for sets or sequences that are sufficiently regular.</p><p>We develop the basic properties of effective strong dimensions and prove a number of results relating them to fundamental aspects of randomness, Kolmogorov complexity, prediction, Boolean circuit-size complexity, polynomial-time degrees, and data compression. Aside from the above characterization of packing dimension, our two main theorems are the following.</p><p>1. If β = (β 0 , β 1 , . . .) is a computable sequence of biases that are bounded away from 0 and R is random with respect to β, then the dimension and strong dimension of R are the lower and upper average entropies, respectively, of β.</p><p>2. For each pair of ∆ 0 2 -computable real numbers 0 ≤ α ≤ β ≤ 1, there exists A ∈ E such that the polynomial-time many-one degree of A has dimension α in E and strong dimension β in E.</p><p>Our proofs of these theorems use a new large deviation theorem for self-information with respect to a bias sequence β.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Hausdorff dimension -a powerful tool of fractal geometry developed by Hausdorff <ref type="bibr" target="#b11">[12]</ref> in 1919 -was effectivized in 2000 by Lutz <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. This has led to a spectrum of effective versions of Hausdorff dimension, including constructive, computable, polynomial-space, polynomial-time, and finite-state dimensions. Work by several investigators has already used these effective dimensions to illuminate a variety of topics in algorithmic information theory and computational complexity <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b9">10]</ref>. (See <ref type="bibr" target="#b25">[26]</ref> for a survey of some of these results.) This work has also underscored and renewed the importance of earlier work by Ryabko <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>, Staiger <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>, and Cai and Hartmanis <ref type="bibr" target="#b4">[5]</ref> relating Kolmogorov complexity to classical Hausdorff dimension. (See Section 6 of <ref type="bibr" target="#b20">[21]</ref> for a discussion of this work.)</p><p>The key to all these effective dimensions is a simple characterization of classical Hausdorff dimension in terms of gales, which are betting strategies that generalize martingales. (Martingales, introduced by Lévy <ref type="bibr" target="#b17">[18]</ref> and Ville <ref type="bibr" target="#b44">[45]</ref> have been used extensively by Schnorr <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref> and others in the investigation of randomness and by Lutz <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> and others in the development of resourcebounded measure.) Given this characterization, it is a simple matter to impose computability and complexity constraints on the gales to produce the above-mentioned spectrum of effective dimensions.</p><p>In the 1980s, a new concept of fractal dimension, called the packing dimension, was introduced independently by Tricot <ref type="bibr" target="#b41">[42]</ref> and Sullivan <ref type="bibr" target="#b39">[40]</ref>. Packing dimension shares with Hausdorff dimension the mathematical advantage of being based on a measure. Over the past two decades, despite its greater complexity (requiring an extra optimization over all countable decompositions of a set in its definition), packing dimension has become, next to Hausdorff dimension, the most important notion of fractal dimension, yielding extensive applications in fractal geometry and dynamical systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>The main result of this paper is a proof that packing dimension can also be characterized in terms of gales. Moreover, notwithstanding the greater complexity of packing dimension's definition (and the greater complexity of its behavior on compact sets, as established by Mattila and Mauldin <ref type="bibr" target="#b24">[25]</ref>), our gale characterization of packing dimension is an exact dual of -and every bit as simple as -the gale characterization of Hausdorff dimension. (This duality and simplicity are in the statement of our gale characterization; its proof is perforce more involved than its counterpart for Hausdorff dimension.)</p><p>Effectivizing our gale characterization of packing dimension produces for each of the effective dimensions above an effective strong dimension that is its exact dual. Just as the Hausdorff dimension of a set is bounded above by its packing dimension, the effective dimension of a set is bounded above by its effective strong dimension. Moreover, just as in the classical case, the effective dimension coincides with the strong effective dimension for sets that are sufficiently regular.</p><p>After proving our gale characterization and developing the effective strong dimensions and some of their basic properties, we prove a number of results relating them to fundamental aspects of randomness, Kolmogorov complexity, prediction, Boolean circuit-size complexity, polynomial-time degrees, and data compression. Our two main theorems along these lines are the following.</p><p>1. If δ &gt; 0 and β = (β 0 , β 1 , . . .) is a computable sequence of biases with each β i ∈ [δ, 1  2 ], then every sequence R that is random with respect to β has dimension dim(R) = lim inf where H(β i ) is the Shannon entropy of β i .</p><p>2. For every pair of ∆ 0 2 -computable real numbers 0 ≤ α ≤ β ≤ 1 there is a decision problem A ∈ E such that the polynomial-time many-one degree of A has dimension α in E and strong dimension β in E.</p><p>In order to prove these theorems, we prove a new large deviation theorem for the self-information log 1</p><formula xml:id="formula_0">µ β (w)</formula><p>, where β is as in 1 above.</p><p>A corollary of theorem 1 above is that, if the average entropies 1 n n-1 i=0 H(β i ) converge to a limit H( β) as n → ∞, then dim(R) = Dim(R) = H( β). Since the convergence of these average entropies is a much weaker condition than the convergence of the biases β n as n → ∞, this corollary substantially strengthens Theorem 7.7 of <ref type="bibr" target="#b20">[21]</ref>.</p><p>Our remaining results are much easier to prove, but their breadth makes a strong prima facie case for the utility of effective strong dimension. They in some cases explain dual concepts that had been curiously neglected in earlier work, and they are likely to be useful in future applications. It is to be hoped that we are on the verge of seeing the full force of fractal geometry applied fruitfully to difficult problems in the theory of computing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>We use the set Z of integers, the set Z + of (strictly) positive integers, the set N of natural numbers (i.e., nonnegative integers), the set Q of rational numbers, the set R of real numbers, and the set [0, ∞) of nonnegative reals. All logarithms in this paper are base 2. We use the slow-growing function log * n = min{j ∈ N | t j ≥ n}, where t 0 = 0 and t j+1 = 2 t j , and Shannon's binary entropy function H : [0, 1] → [0, 1] defined by</p><formula xml:id="formula_1">H(β) = β log 1 β + (1 -β) log 1 1 -β ,</formula><p>where 0 log 1 0 = 0. A language, or decision problem, is a set A ⊆ {0, 1} * . We usually identify a language A with it characteristic sequence χ A ∈ C defined by χ A [n] = if s n ∈ A then 1 else 0, where s 0 = λ, s 1 = 0, s 2 = 1, s 3 = 00, . . . is the standard enumeration of {0, 1} * . That is, we usually (but not always) use A to denote both the set A ⊆ {0, 1} * and the sequence</p><formula xml:id="formula_2">A = χ A ∈ C.</formula><p>A string is a finite, binary string w ∈ {0, 1} * . We write |w| for the length of a string w and λ for the empty string. For i, j ∈ {0, . . . , |w| -1}, we write w[i..j] for the string consisting of the i th through the j th bits of w and w[i] for w[i..i], the i th bit of w. Note that the 0 th bit w[0] is the leftmost bit of w and that w[i..j] = λ if i &gt; j. A sequence is an infinite, binary sequence. If S is a sequence and i, j ∈ N, then the notations S[i..j] and S[i] are defined exactly as for strings. We work in the Cantor space C consisting of all sequences. A string w ∈ {0, 1} * is a prefix of a sequence S ∈ C, and we write w ⊑ S, if S[0..|w| -1] = w. The cylinder generated by a string w ∈ {0, 1} * is</p><formula xml:id="formula_3">C w = {S ∈ C|w ⊑ S}. Note that C λ = C.</formula><p>Given a set A ⊆ {0, 1} * and n ∈ N, we use the abbreviations A =n = A ∩ {0, 1} n and A ≤n = A ∩ {0, 1} ≤n . A prefix set is a set A ⊆ {0, 1} * such that no element of A is a prefix of another element of A.</p><p>For each i ∈ N we define a class G i of functions from N into N as follows.</p><formula xml:id="formula_4">G 0 = {f | (∃k)(∀ ∞ n)f (n) ≤ kn} G i+1 = 2 G i (log n) = {f | (∃g ∈ G i )(∀ ∞ n)f (n) ≤ 2 g(log n) }</formula><p>We also define the functions ĝi ∈ G i by ĝ0 (n) = 2n, ĝi+1 (n) = 2 ĝi (log n) . We regard the functions in these classes as growth rates. In particular, G 0 contains the linearly bounded growth rates and G 1 contains the polynomially bounded growth rates. It is easy to show that each</p><formula xml:id="formula_5">G i is closed under composition, that each f ∈ G i is o(ĝ i+1</formula><p>), and that each ĝi is o(2 n ). Thus G i contains superpolynomial growth rates for all i &gt; 1, but all growth rates in the G i -hierarchy are subexponential.</p><p>Let CE be the class of computably enumerable languages. Within the class DEC of all decidable languages, we are interested in the exponential complexity classes E i = DTIME(2 G i-1 ) and</p><formula xml:id="formula_6">E i SPACE = DSPACE(2 G i-1 ) for i ≥ 1. The much-studied classes E = E 1 = DTIME(2 linear ), E 2 = DTIME(2 polynomial</formula><p>), and ESPACE = E 1 SPACE = DSPACE(2 linear ) are of particular interest.</p><p>We use the following classes of functions.</p><formula xml:id="formula_7">all = {f | f : {0, 1} * → {0, 1} * } comp = {f ∈ all | f is computable} p i = {f ∈ all | f is computable in G i time} (i ≥ 1) p i space = {f ∈ all | f is computable in G i space} (i ≥ 1)</formula><p>(The length of the output is included as part of the space used in computing f .) We write p for p 1 and pspace for p 1 space.</p><p>A constructor is a function δ : {0, 1} * → {0, 1} * that satisfies x = δ(x) for all x. The result of a constructor δ (i.e., the language constructed by δ) is the unique language R(δ) such that δ n (λ) ⊑ R(δ) for all n ∈ N. Intuitively, δ constructs R(δ) by starting with λ and then iteratively generating successively longer prefixes of R(δ). We write R(∆) for the set of languages R(δ) such that δ is a constructor in ∆. The following facts are the reason for our interest in the above-defined classes of functions.</p><formula xml:id="formula_8">R(all) = C. R(comp) = DEC. For i ≥ 1, R(p i )=E i . For i ≥ 1, R(p i space) = E i SPACE. If D is a discrete domain (such as N, {0, 1} * , N × {0, 1} * , etc.), then a function f : D -→ [0, ∞) is ∆-computable if there is a function f : N × D -→ Q ∩ [0, ∞) such that | f (r, x) -f (x)| ≤ 2 -r</formula><p>for all r ∈ N and x ∈ D and f ∈ ∆ (with r coded in unary and the output coded in binary). We say that f is exactly</p><formula xml:id="formula_9">∆-computable if f : D -→ Q ∩ [0, ∞) and f ∈ ∆. We say that f is lower semicomputable if there is a computable function f : D × N → Q such that (a) for all (x, t) ∈ D × N, f (x, t) ≤ f (x, t + 1) &lt; f (x), and (b) for all x ∈ D, lim t→∞ f (x, t) = f (x).</formula><p>Finally, we say that f is ∆ 0 2 -computable if f is computable (i.e., comp-computable) relative to the halting oracle.</p><formula xml:id="formula_10">A real number α ∈ [0, ∞) is computable (respectively, ∆ 0 2 -computable) if the function f : {0} → [0, ∞) defined by f (0) = α is computable (respectively, ∆ 0 2 -computable). Let k be a positive integer. A k-account finite-state gambler (k-account FSG) is a tuple G = (Q, δ, β, q 0 , c 0 ) where • Q is a nonempty, finite set of states, • δ : Q × {0, 1} → Q is the transition function, • β : {1, . . . , k} × Q × {0, 1} → Q ∩ [0, 1] is the betting function,</formula><p>• q 0 ∈ Q is the initial state, and • c 0 is the initial capital vector, a sequence of k nonnegative rational numbers.</p><p>The betting function satisfies β(i, q, 0) + β(i, q, 1) = 1 for each q ∈ Q and 1 ≤ i ≤ k. We use the standard extension δ * : Σ * → Q of δ defined recursively by δ * (λ) = q 0 and δ * (wb) = δ(δ * (w), b) for all w ∈ {0, 1} * and b ∈ {0, 1}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Fractal Dimensions</head><p>In this section we briefly review the classical definitions of some fractal dimensions and the relationships among them. Since we are primarily interested in binary sequences and (equivalently) decision problems, we focus on fractal dimension in the Cantor space C.</p><p>For each k ∈ N, we let A k be the collection of all prefix sets A such that A &lt;k = ∅. For each X ⊆ C, we then define the families</p><formula xml:id="formula_11">A k (X) = A ∈ A k X ⊆ w∈A C w , B k (X) = {A ∈ A k |(∀w ∈ A)C w ∩ X = ∅ } .</formula><p>If A ∈ A k (X), then we say that the prefix set A covers the set X. If A ∈ B k (X), then we call the prefix set A a packing of X. For X ∈ C, s ∈ [0, ∞), and k ∈ N, we then define</p><formula xml:id="formula_12">H s k (X) = inf A∈A k (X) w∈A 2 -s|w| , P s k (X) = sup A∈B k (X) w∈A 2 -s|w| .</formula><p>Since H s k (X) and P s k (X) are monotone in k, the limits</p><formula xml:id="formula_13">H s (X) = lim k→∞ H s k (X), P s ∞ (X) = lim k→∞ P s k (X)</formula><p>exist, though they may be infinite. We then define</p><formula xml:id="formula_14">P s (X) = inf ∞ i=0 P s ∞ (X i ) X ⊆ ∞ i=0 X i .<label>(3.1)</label></formula><p>The set functions H s and P s have the technical properties of an outer measure <ref type="bibr" target="#b7">[8]</ref>, and the (possibly infinite) quantities H s (X) and P s (X) are thus known as the s-dimensional Hausdorff (outer) cylinder measure of X and the s-dimensional packing (outer) cylinder measure of X, respectively. The set function P s ∞ is not an outer measure; this is the reason for the extra optimization (3.1) in the definition of the packing measure.</p><formula xml:id="formula_15">Definition. Let X ⊆ C. 1. The Hausdorff dimension of X is dim H (X) = inf{s ∈ [0, ∞)|H s (X) = 0}. 2. The packing dimension of X is dim P (X) = inf{s ∈ [0, ∞)|P s (X) = 0}.</formula><p>The proof of our main result uses a well-known characterization of packing dimension as a modified box dimension. For each X ⊆ C and n ∈ N, let</p><formula xml:id="formula_16">N n (X) = {w ∈ {0, 1} n |(∃S ∈ X)w ⊑ S} . Then the upper box dimension of X is dim B (X) = lim sup n→∞ log N n (X) n .<label>(3.2)</label></formula><p>The lower box dimension dim B (X), which we do not use here, is obtained by using a limit inferior in place of the limit superior in (3.2). When dim B (X) = dim B (X), this quantity, written dim B (X), is called the box dimension of X.</p><p>Box dimensions are over 60 years old, have been re-invented many times, and have been named many things, including Minkowski dimension, Kolmogorov entropy, Kolmogorov dimension, topological entropy, metric dimension, logarithmic density, and information dimension. Box dimensions are often used in practical applications of fractal geometry because they are easy to estimate, but they are not well-behaved mathematically. The modified upper box dimension</p><formula xml:id="formula_17">dim MB (X) = inf sup i dim B (X i ) X ⊆ ∞ i=0 X i (3.3)</formula><p>is much better behaved. (Note that (3.3), like (3.1), is an optimization over all countable decompositions of X.) In fact, the following relations are well-known <ref type="bibr" target="#b7">[8]</ref>.</p><formula xml:id="formula_18">Theorem 3.1. For all X ⊆ C, 0 ≤ dim H (X) ≤ dim MB (X) = dim P (X) ≤ dim B (X) ≤ 1.</formula><p>The above dimensions are monotone, i.e., X ⊆ Y implies dim(X) ≤ dim(Y ), and stable, i.e., dim(X ∪ Y ) = max{dim(X), dim(Y )}. The Hausdorff and packing dimensions are also countably stable, i.e., dim(∪ ∞ i=0 X i ) = sup{dim(X i )|i ∈ N}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Gale Characterizations</head><p>In this section we review the gale characterization of Hausdorff dimension and prove our main theorem, which is the dual gale characterization of packing dimension.</p><formula xml:id="formula_19">Definition. Let s ∈ [0, ∞). 1. An s-supergale is a function d : {0, 1} * -→ [0, ∞) that satisfies the condition d(w) ≥ 2 -s [d(w0) + d(w1)] (4.1)</formula><p>for all w ∈ {0, 1} * .</p><p>2. An s-gale is an s-supergale that satisfies (4.1) with equality for all w ∈ {0, 1} * .</p><p>3. A supermartingale is a 1-supergale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>A martingale is a 1-gale.</p><p>Intuitively, we regard a supergale d as a strategy for betting on the successive bits of a sequence S ∈ C. More specifically d(w) is the amount of capital that d has after betting on the prefix w of S. If s = 1, then the right-hand side of (4.1) is the conditional expectation of d(wb) given that w has occurred (when b is a uniformly distributed binary random variable). Thus a martingale models a gambler's capital when the payoffs are fair. (The expected capital after the bet is the actual capital before the bet.) In the case of an s-gale, if s &lt; 1, the payoffs are less than fair; if s &gt; 1, the payoffs are more than fair.</p><p>We use the following known generalization of the Kraft inequality. We now define two criteria for the success of a gale or supergale.</p><p>Definition. Let d be an s-supergale, where s ∈ [0, ∞).</p><p>1. We say that d succeeds on a sequence S ∈ C if</p><formula xml:id="formula_20">lim sup n→∞ d(S[0..n -1]) = ∞. (4.2)</formula><p>The success set of d is S ∞ [d] = {S ∈ C|d succeeds on S}.</p><p>2. We say that d succeeds strongly on a sequence S ∈ C if</p><formula xml:id="formula_21">lim inf n→∞ d(S[0..n -1]) = ∞. (4.3)</formula><p>The strong success set of d is S ∞ str [d] = {S ∈ C|d succeeds strongly on S}.</p><p>We have written conditions (4.2) and (4.3) in a fashion that emphasizes their duality. Condition (4.2) says simply that the set of values d(S[0..n -1]) is unbounded, while condition (4.3) says that</p><formula xml:id="formula_22">d(S[0..n -1]) → ∞ as n → ∞. Notation. Let X ⊆ C. 1. G(X) is the set of all s ∈ [0, ∞) for which there exists an s-gale d such that X ⊆ S ∞ [d].</formula><p>2. G str (X) is the set of all s ∈ [0, ∞) for which there exists an s-gale d such that X ⊆ S ∞ str [d].</p><p>3. G(X) is the set of all s ∈ [0, ∞) for which there exists an s-supergale d such that X ⊆ S ∞ [d].</p><p>4. G str (X) is the set of all s ∈ [0, ∞) for which there exists an s-supergale d such that X ⊆ S ∞ str [d].</p><p>Note that s ′ ≥ s ∈ G(X) implies that s ′ ∈ G(X), and similarly for the classes G str (X), G(X), and G str (X). The following fact is also clear.</p><formula xml:id="formula_23">Observation 4.2. For all X ⊆ C, G(X) = G(X) and G str (X) = G str (X).</formula><p>For Hausdorff dimension, we have the following known fact.</p><formula xml:id="formula_24">Theorem 4.3. (Gale Characterization of Hausdorff Dimension -Lutz [20]) For all X ⊆ C, dim H (X) = inf G(X).</formula><p>Our main result is the following dual of Theorem 4.3.</p><formula xml:id="formula_25">Theorem 4.4. (Gale Characterization of Packing Dimension) For all X ⊆ C, dim P (X) = inf G str (X).</formula><p>By Observation 4.2, we could equivalently use G(X) and G str (X) in Theorems 4.3 and 4.4, respectively. We will use the following lemma to prove Theorem 4.4.</p><p>Lemma 4.5. For each family of sets</p><formula xml:id="formula_26">{X k ⊆ C |k ∈ N }, inf G str ( k X k ) = sup k inf G str (X k ). Proof. The inequality inf G str ( k X k ) ≥ sup k inf G str (X k ) holds trivially. To prove that inf G str ( k X k ) ≤ sup k inf G str (X k ), let s &gt; sup k inf G str (X k ). Then for each k ∈ N there is an s-gale d k such that X k ⊆ S ∞ str [d k ]</formula><p>. We define an s-gale d by</p><formula xml:id="formula_27">d(w) = k∈AE 2 -k d k (λ) • d k (w)</formula><p>for all w ∈ {0, 1} * . Then for each k, for any S ∈ X k , we have</p><formula xml:id="formula_28">d(S[0..n -1]) ≥ 2 -k d k (λ) • d k (S[0..n -1]) for all n, so S ∈ S ∞ str [d]. Therefore k X k ⊆ S ∞ str [d]</formula><p>and the lemma follows.</p><formula xml:id="formula_29">Proof of Theorem 4.4. Let X ⊆ C. By Theorem 3.1, it suffices to show that dim MB (X) = inf G str (X). To see that dim MB (X) ≤ inf G str (X), let s &gt; inf G str (X). It suffices to show that dim MB (X) ≤ s.</formula><p>By our choice of s, there is an</p><formula xml:id="formula_30">s-gale d such that X ⊆ S ∞ str [d]. For each n ∈ N, let B n = {w ∈ {0, 1} n |d(w) &gt; d(λ)} and Y n = {S ∈ C|S[0..n -1] ∈ B n }.</formula><p>For each i ∈ N, let</p><formula xml:id="formula_31">X i = ∞ n=i Y n ,</formula><p>and note that</p><formula xml:id="formula_32">X ⊆ ∞ i=0 X i .<label>(4.4)</label></formula><p>For all n ≥ i ∈ N, we have X i ⊆ Y n , whence the generalized Kraft inequality (Lemma 4.1) tells us that</p><formula xml:id="formula_33">N n (X i ) ≤ N n (Y n ) = |B n | &lt; 2 sn .</formula><p>It follows that, for all i ∈ N,</p><formula xml:id="formula_34">dim B (X i ) = lim sup n→∞ log N n (X i ) n ≤ s, whence by (4.4), dim MB (X) ≤ sup i∈AE dim B (X i ) ≤ s. To see that inf G str (X) ≤ dim MB (X), let s &gt; s ′ &gt; s ′′ &gt; dim MB (X). It suffices to show that inf G str (X) ≤ s. Since s ′′ &gt; dim MB (X), there exist sets X 0 , X 1 , . . . ⊆ C such that X = ∞ i=0 X i and dim B (X i ) &lt; s ′′ for all i ∈ N. By Lemma 4.5, it suffices to show that s ∈ G str (X i ) for all i ∈ N. Fix i ∈ N. Since dim B (X i ) &lt; s ′′ , there exists n 0 ∈ N such that, for all n ≥ n 0 , log Nn(X i ) n &lt; s ′′ , i.e., N n (X i ) &lt; 2 s ′′ n . For each n ≥ n 0 , let A n = {S[0..n -1]|S ∈ X i } (noting that |A n | = N n (X i )), and define d n : {0, 1} * → [0, ∞) by d n (w) =      2 (s-s ′ )|w| u wu∈An 2 -s ′ |u| if |w| ≤ n 2 (s-1)(|w|-n) d n (w[0..n -1]) if |w| &gt; n.</formula><p>It is routine to verify that d n is an s-gale for each n ≥ n 0 . Note also that d n (w) = 2 (s-s ′ )n for all n ≥ n 0 and w</p><formula xml:id="formula_35">∈ A n . Let d = ∞ n=n 0 d n . Then d(λ) = ∞ n=n 0 d n (λ) = ∞ n=n 0 |A n |2 -s ′ n = ∞ n=n 0 N n (X i )2 -s ′ n &lt; ∞ n=n 0 2 (s ′′ -s ′ )n &lt; ∞, so d is an s-gale by linearity. Let S ∈ X i . Then, for all n ≥ n 0 , S[0..n -1] ∈ A n , so d(S[0..n -1]) ≥ d n (S[0..n -1]) ≥ 2 (s-s ′ )n . Thus S ∈ S ∞ str [d]. This shows that X i ⊆ S ∞ str [d], whence s ∈ G str (X i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Effective Strong Dimensions</head><p>Theorem 4.3 has been used to effectivize Hausdorff dimension at a variety of levels. In this section we review these effective dimensions while using Theorem 4.4 to develop the dual effective strong dimensions.</p><p>We define a gale or supergale to be constructive if it is lower semicomputable. For any s ∈ [0, ∞) and any k-account FSG G an s-gale d</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(s)</head><p>G is defined as follows <ref type="bibr" target="#b6">[7]</ref>. (Recall that finite-state gamblers were defined in Section 2.) For each 1 ≤ i ≤ k we define an s-gale d</p><formula xml:id="formula_36">(s) G,i by the recursion d (s) G,i (λ) = c 0,i d (s) G,i (wb) = 2 s d (s) G,i (w)β(i, δ * (w), b) for all w ∈ {0, 1} * and b ∈ {0, 1}. Then d (s) G = k i=1 d (s) G,i .</formula><p>We define an s-gale d to be finite-state if there is a finite-state gambler (FSG) G such that d</p><formula xml:id="formula_37">(s) G = d.</formula><p>For the rest of this paper, ∆ denotes one of the classes all, comp, p, pspace, p 2 , p 2 space, etc. defined in Section 2.</p><p>For each Γ ∈ {constr, ∆, FS} and X ⊆ C, we define the sets G Γ (X), G str Γ (X), G Γ (X), and G str Γ (X) just as the classes G(X), G str (X), G(X), and G str (X) were defined in Section 4, but with the following modifications.</p><formula xml:id="formula_38">(i) If Γ = constr, then d is required to be constructive. (ii) If Γ = ∆, then d is required to be ∆-computable.</formula><p>(iii) In G FS (X) and G str FS (X), d is required to be finite-state.</p><p>(iv) G FS (X) and G str FS (X) are not defined. The following effectivizations of Hausdorff and packing dimension are motivated by Theorems 4.3 and 4.4.</p><formula xml:id="formula_39">Definition. Let X ⊆ C and S ∈ C. 1. [21] The constructive dimension of X is cdim(X) = inf G constr (X). 2. The constructive strong dimension of X is cDim(X) = inf G str constr (X).</formula><p>3. <ref type="bibr" target="#b20">[21]</ref> The dimension of S is dim(S) = cdim({S}).</p><p>4. The strong dimension of S is Dim(S) = cDim({S}).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">[20] The</head><formula xml:id="formula_40">∆-dimension of X is dim ∆ (X) = inf G ∆ (X). 6. The ∆-strong dimension of X is Dim ∆ (X) = inf G str ∆ (X). 7. [20] The dimension of X in R(∆) is dim(X|R(∆)) = dim ∆ (X ∩ R(∆)). 8. The strong dimension of X in R(∆) is Dim(X|R(∆)) = Dim ∆ (X ∩ R(∆)).</formula><p>9. <ref type="bibr" target="#b6">[7]</ref> The finite-state dimension of X is dim FS (X) = inf G FS (X).</p><p>10. The finite-state strong dimension of X is Dim FS (X) = inf G str FS (X).</p><p>11. <ref type="bibr" target="#b6">[7]</ref> The finite-state dimension of S is dim FS (S) = dim FS ({S}).</p><p>12. The finite-state strong dimension of S is Dim FS (S) = Dim FS ({S}).</p><p>In parts 1,2,5, and 6 of the above definition, we could equivalently use the "hatted" sets G constr (X), G str constr (X), G ∆ (X), and G str ∆ (X) in place of their unhatted counterparts. In the case of parts 5 and 6, this follows from Lemma 4.7 of <ref type="bibr" target="#b19">[20]</ref>. In the case of parts 1 and 2, it follows from the main theorem in <ref type="bibr" target="#b13">[14]</ref> (which answered an open question in <ref type="bibr" target="#b20">[21]</ref>, where G constr (X) was in fact used in defining cdim(X)).</p><p>The polynomial-time dimensions dim p (X) and Dim p (X) are also called the feasible dimension and the feasible strong dimension, respectively. The notation dim p (X) for the p-dimension is all too similar to the notation dim P (X) for the classical packing dimension, but confusion is unlikely because these dimensions typically arise in quite different contexts.</p><p>Note that the classical Hausdorff and packing dimensions can each now be written in three different ways, i.e., dim H (X) = dim all (X) = dim(X|C) and dim P (X) = Dim all (X) = Dim(X|C).</p><p>Observations 5.1.</p><p>1. Each of the dimensions that we have defined is monotone (e.g., X ⊆ Y implies cdim(X) ≤ cdim(Y )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Each of the effective strong dimensions is bounded below by the corresponding effective dimen-</head><p>sion (e.g., cdim(X) ≤ cDim(X)).</p><p>3. Each of the dimensions that we have defined is nonincreasing as the effectivity constraint is relaxed (e.g., dim H (X) ≤ cdim(X) ≤ dim pspace (X) ≤ dim FS (X)).</p><p>4. Each of the dimensions that we have defined is nonnegative and assigns C the dimension 1.</p><p>Lemma 5.2. The finite-state dimensions are stable, i.e., for all X, Y ⊆ C,</p><formula xml:id="formula_41">dim FS (X ∪ Y ) = max{dim FS (X), dim FS (Y )} and Dim FS (X ∪ Y ) = max{Dim FS (X), Dim FS (Y )}.</formula><p>Proof. The stability of finite-state dimension was proved in <ref type="bibr" target="#b6">[7]</ref>. The same arguments establish stability for finite-state strong dimension.</p><formula xml:id="formula_42">Definition. Let X, X 0 , X 1 , X 2 , . . . ⊆ C. 1. We say that X is a ∆-union of the ∆-dimensioned sets {X k |k ∈ N} if X = ∞ k=0 X k and for each s &gt; sup k∈AE dim ∆ (X k ) with 2 s rational, there is a function d : N × {0, 1} * → [0, ∞) with the following three properties. (i) d is ∆-computable. (ii) For each k ∈ N, if we write d k (w) = d(k, w), then the function d k is an s-gale. (iii) For each k ∈ N, X k ⊆ S ∞ [d k ].</formula><p>Analogously, X is a ∆-union of the ∆-strong dimensioned sets {X k |k ∈ N} if there is a d with the above properties that also satisfies</p><formula xml:id="formula_43">(iv) For each k ∈ N, X k ⊆ S ∞ str [d k ].</formula><p>2. We say that X is a ∆-union of the sets</p><formula xml:id="formula_44">{X k |k ∈ N} dimensioned in R(∆) if X = ∞ k=0 X k and X ∩ R(∆) is an ∆-union of the ∆-dimensioned sets {X k ∩ R(∆)|k ∈ N}. Analogously, X is ∆-union of the sets {X k |k ∈ N} strong dimensioned in R(∆) if X = ∞ k=0 X k and X ∩ R(∆) is an ∆-union of the ∆-strong dimensioned sets {X k ∩ R(∆)|k ∈ N}. Lemma 5.3. The dimensions defined from ∆ are ∆-countably stable, i.e., if X is a ∆-union of the ∆-dimensioned sets X 0 , X 1 , X 2 , . . . , then dim ∆ (X) = sup k∈AE dim ∆ (X k ),</formula><formula xml:id="formula_45">and if X is a ∆-union of the ∆-strong dimensioned sets X 0 , X 1 , X 2 , . . ., then Dim ∆ (X) = sup k∈AE Dim ∆ (X k ),</formula><p>and similarly for dimension and strong dimension in R(∆).</p><p>Proof. The stability of dim ∆ over ∆-unions was proved in <ref type="bibr" target="#b19">[20]</ref>. The proof for strong dimension is analogous. Proof. The absolute stability of constructive dimension was proved in <ref type="bibr" target="#b20">[21]</ref> using optimal constructive supergales. The same argument works for constructive strong dimension.</p><p>In the following two sections, we use Martin-Löf's definition of randomness <ref type="bibr" target="#b23">[24]</ref> as reformulated in terms of martingales by Schnorr <ref type="bibr" target="#b31">[32]</ref> as follows.</p><p>A probability measure on C is a function ν : {0, 1} * → [0, ∞) such that ν(λ) = 1 and ν(w) = ν(w0) + ν(w1) for all w ∈ {0, 1} * . (Intuitively, ν(w) is the probability that w ⊑ S when the sequence S is "chosen according to ν.")</p><p>A bias is a real number β ∈ [0, 1]. Intuitively, if we toss a 0/1-valued coin with bias β, then β is the probability of the outcome 1. A bias sequence is a sequence β = (β 0 , β 1 , β 2 , . . .) of biases. If β is a bias sequence, then the β-coin-toss probability measure is the probability µ β on C defined by</p><formula xml:id="formula_46">µ β (w) = |w|-1 i=0 β i (w),<label>(5.1)</label></formula><p>where</p><formula xml:id="formula_47">β i (w) = (2β i -1)w[i] + (1 -β i ), i.e., β i (w) = if w[i] then β i else 1 -β i .</formula><p>That is, µ β is the probability that S ∈ C w when S ∈ C is chosen according to a random experiment in which for each i, independently of all other j, the i th bit of S is decided by tossing a 0/1-valued coin whose probability of 1 is β i . In the case where the biases β i are all the same, i.e., β = (β, β, β, . . .) for some β ∈ [0, 1], we write µ β for µ β , and (5.1) simplifies to</p><formula xml:id="formula_48">µ β (w) = (1 -β) #(0,w) β #(1,w) ,<label>(5.2)</label></formula><p>where #(b, w) is the number of times the bit b appears in the string w. The uniform probability measure on C is the probability measure µ = µ 1 2 , for which (5.2) simplifies to</p><formula xml:id="formula_49">µ(w) = 2 -|w|</formula><p>for all w ∈ {0, 1} * .</p><p>Definition. Let ν be a probability measure on C.</p><formula xml:id="formula_50">1. A ν-martingale is a function d : {0, 1} * → [0, ∞) that satisfies the condition d(w)ν(w) = d(w0)ν(w0) + d(w1)ν(w1)</formula><p>for all w ∈ {0, 1} * .</p><p>2. A ν-martingale is constructive if it is lower semicomputable.</p><p>Note that a µ-martingale is a martingale. If β is a bias sequence, then we call a µ β -martingale simply a β-martingale.</p><p>Definition. Let ν be a probability measure on C, and let X ⊆ C.</p><p>1. X has constructive ν-measure 0, and we write ν constr (X) = 0, if there is a constructive</p><formula xml:id="formula_51">ν-martingale d such that X ⊆ S ∞ [d].</formula><p>2. X has constructive ν-measure 1, and we write ν constr (X) = 1, if ν constr (C -X) = 0.</p><p>Definition. If ν is a probability measure on C, then a sequence R ∈ C is ν-random, and we write R ∈ RAND ν , if the singleton set {R} does not have constructive ν-measure 0 (i.e., there is no constructive ν-martingale that succeeds on R).</p><p>It is well-known (and easy to see) that ν constr (RAND ν ) = 1.</p><p>We write RAND β for RAND µ β and RAND for RAND µ . We also use resource-bounded notions of randomness that have been investigated by Schnorr <ref type="bibr" target="#b32">[33]</ref>, Lutz <ref type="bibr" target="#b21">[22]</ref>, Ambos-Spies, Terwijn, and Zheng <ref type="bibr" target="#b1">[2]</ref>, and others.</p><p>Definition. Let ν be a probability measure on C, and let t : N → N.</p><p>1. A sequence R ∈ C is ∆-ν-random, and we write R ∈ RAND ν (∆), if there is no ∆-computable ν-martingale that succeeds on R.</p><formula xml:id="formula_52">2. A sequence R ∈ C is t(n)-ν-random, and we write R ∈ RAND ν (t(n)), if there is no O(t(n))- time-computable ν-martingale that succeeds on R.</formula><p>We write RAND β (t(n)) for RAND µ β (t(n)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Algorithmic Information</head><p>In this section we present a variety of results and observations in which constructive and computable strong dimensions illuminate or clarify various aspects of algorithmic information theory. Included is our second main theorem, which says that every sequence that is random with respect to a computable sequence of biases β i ∈ [δ, 1/2] has the lower and upper average entropies of (β 0 , β 1 , . . .) as its dimension and strong dimension, respectively. We also present a result in which finite-state strong dimension clarifies an issue in data compression.</p><p>Mayordomo <ref type="bibr" target="#b26">[27]</ref> proved that for all S ∈ C,</p><formula xml:id="formula_53">dim(S) = lim inf n→∞ K(S[0..n -1]) n ,<label>(6.1)</label></formula><p>where K(w) is the Kolmogorov complexity of w <ref type="bibr" target="#b18">[19]</ref>. Subsequently, Lutz <ref type="bibr" target="#b20">[21]</ref> used termgales to define the dimension dim(w) of each (finite!) string w ∈ {0, 1} * and proved that</p><formula xml:id="formula_54">dim(S) = lim inf n→∞ dim(S[0..n -1]) (6.2)</formula><p>for all S ∈ C and</p><formula xml:id="formula_55">K(w) = |w|dim(w) ± O(1)<label>(6.3)</label></formula><p>for all w ∈ {0, 1} * , thereby giving a second proof of (6.1). The following theorem is a dual of (6.2) that yields a dual of (6.1) as a corollary. Proof. This proof is analogous to the one for the dual statement (6.2) given in <ref type="bibr" target="#b20">[21]</ref>.</p><p>Corollary 6.2. For all S ∈ C,</p><formula xml:id="formula_56">Dim(S) = lim sup n→∞ K(S[0..n -1]) n .</formula><p>By Corollary 6.2, the "upper algorithmic dimension" defined by Tadaki <ref type="bibr" target="#b40">[41]</ref> is precisely the constructive strong dimension.</p><p>The rate at which a gambler can increase its capital when betting in a given situation is a fundamental concern of classical and algorithmic information and computational learning theories. In the setting of constructive gamblers, the following quantities are of particular relevance. 5. The lower Lyapunov exponent of X is λ(X) = inf S∈X λ(S).</p><p>6. The upper Lyapunov exponent of X is Λ(X) = inf S∈X Λ(S).</p><p>Lyapunov exponents such as these were investigated by Schnorr <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b34">35]</ref>, Ryabko <ref type="bibr" target="#b30">[31]</ref>, and Staiger <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref> (using slightly different notations) prior to the effectivization of Hausdorff dimension. The quantities λ d (S) and Λ d (S) are also called "exponents of increase" of d on S. It is implicit in Staiger's paper <ref type="bibr" target="#b37">[38]</ref> that</p><formula xml:id="formula_57">Λ comp (S) = 1 -dim comp (S)</formula><p>for all S ∈ C, where Λ comp (S) is defined like Λ(S) above, but with d required to be a computable martingale. Similar reasoning leads to the following characterizations of the Lyapunov exponents.</p><formula xml:id="formula_58">Theorem 6.3. Let S ∈ C and X ⊆ C. Then Λ(S) = 1 -dim(S), λ(S) = 1 -Dim(S), Λ(X) = 1 -cdim(X), and λ(X) = 1 -cDim(X).</formula><p>Proof. We show that Λ(S) = 1dim(S). A similar argument shows that λ(S) = 1 -Dim(S). By Lemma 5.4, Λ(X) = 1cdim(X) and λ(X) = 1 -cDim(X) follow from the statements about sequences. Let t &lt; s &lt; Λ(S) with t computable, and let d be a constructive martingale for which λ d (S) &gt; s. Then for infinitely many n, d(S[0..n -1]) &gt; 2 sn . Define a constructive (1t)-gale d ′ by d ′ (w) = 2 -t|w| d(w) for all w ∈ {0, 1} * . Then for infinitely many n, we have</p><formula xml:id="formula_59">d ′ (S[0..n -1]) = 2 -tn d(S[0..n -1]) &gt; 2 (s-t)n , so S ∈ S ∞ [d]. Therefore dim(S) &lt; 1 -t.</formula><p>This holds for all computable t &lt; Λ(S), so dim(S) ≤ 1 -Λ(S).</p><p>Let s &gt; dim(S) be computable, and let d be a constructive s-gale with S ∈ S ∞ </p><formula xml:id="formula_60">..n -1]) &gt; 2 (1-s)n . Therefore Λ d ′ (S) ≥ 1 -s, so Λ(S) ≥ 1 -s.</formula><p>This holds for all s &gt; dim(S), so Λ(S) ≥ 1dim(S).</p><p>Constructive strong dimension can also be used to characterize entropy rates of the type investigated by Staiger <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> and Hitchcock <ref type="bibr" target="#b14">[15]</ref>.</p><formula xml:id="formula_61">Definition. Let A ⊆ {0, 1} * . 1. The entropy rate of A ⊆ {0, 1} * is H A = lim sup n→∞ log |A=n| n .</formula><p>2. We define the sets of sequences</p><formula xml:id="formula_62">A i.o. = {S ∈ C|(∃ ∞ n)S[0..n -1] ∈ A} and A a.e. = {S ∈ C|(∀ ∞ n)S[0..n -1] ∈ A}. Definition. Let X ⊆ C. The constructive entropy rate of X is H CE (X) = inf{H A |X ⊆ A i.o. and A ∈ CE}</formula><p>and the constructive strong entropy rate of X is</p><formula xml:id="formula_63">H str CE (X) = inf{H A |X ⊆ A a.</formula><p>e. and A ∈ CE}.</p><p>Hitchcock <ref type="bibr" target="#b14">[15]</ref> proved that H CE (X) = cdim(X) (6.4) for all X ⊆ C. We have the following dual of (6.4).</p><p>Theorem 6.4. For any X ⊆ C, H str CE (X) = cDim(X).</p><p>Proof. This proof is analogous to the proof of (6.4) given in <ref type="bibr" target="#b14">[15]</ref>.</p><p>In the classical case, Tricot <ref type="bibr" target="#b41">[42]</ref> has defined a set to be regular if its Hausdorff and packing dimensions coincide, and defined its irregularity to be the difference between these two fractal dimensions. Analogously, we define the c-irregularity (i.e., constructive irregularity) of a sequence S ∈ C to be Dim(S)dim(S), and we define the c-irregularity of a set X ⊆ C to be cDim(X)cdim(X). We define a sequence or set to be c-regular (i.e., constructively regular) if its c-irregularity is 0.</p><p>As the following result shows, the c-irregularity of a sequence may be any real number in [0, 1].</p><p>Theorem 6.5. For any two real numbers 0 ≤ α ≤ β ≤ 1, there is a sequence S ∈ C such that dim(S) = α and Dim(S) = β.</p><p>Proof. Let R be a random sequence. It is well-known that</p><formula xml:id="formula_64">K(R[0..n -1]) ≥ n -O(1). (6.5) Write R = r 1 r 2 r 3 . . . where |r n | = 2n -1 for all n. Note that |r 1 • • • r n | = n 2 .</formula><p>For each n, define</p><formula xml:id="formula_65">γ n = 1-α α if log * n is odd 1-β β if log * n is even,</formula><p>and let k n = ⌈|r n |γ n ⌉ .</p><p>We now define S ∈ C as</p><formula xml:id="formula_66">S = r 1 0 k 1 r 2 0 k 2 • • • r n 0 kn • • • .</formula><p>Note that for all n,</p><formula xml:id="formula_67">|r n 0 kn | = ⌈|r n |(1 + γ n )⌉ = 1 α |r n | if log * n is odd 1 β |r n | if log * n is even.</formula><p>Let w ⊑ S. Then for some n,</p><formula xml:id="formula_68">w = r 1 0 k 1 • • • r n-1 0 k n-1 r ′ n 0 j</formula><p>where r ′ n ⊑ r n and 0 ≤ j ≤ k n . We have</p><formula xml:id="formula_69">K(w) ≤ K(r 1 • • • r n-1 r ′ n ) + K(k 1 ) + • • • K(k n-1 ) + K(j) + O(1) ≤ |r 1 • • • r n-1 r ′ n | + O(n log n) ≤ (n -1) 2 + O(n log n). (6.6) Also, K(r 1 • • • r n-1 r ′ n ) ≤ K(w) + K(k 1 ) + • • • + K(k n-1 ) + K(j) + O(1) ≤ K(w) + O(n log n),</formula><p>so by (6.5),</p><formula xml:id="formula_70">K(w) ≥ K(r 1 • • • r n-1 r ′ n ) -O(n log n) ≥ |r 1 • • • r n-1 r ′ n | -O(n log n) ≥ (n -1) 2 -O(n log n). (6.7)</formula><p>We bound the length of w in terms of n as</p><formula xml:id="formula_71">|w| ≥ |r 1 |(1 + γ 1 ) + • • • + |r n-1 |(1 + γ n-1 ) + |r ′ n | ≥ |r 1 • • • r n-1 | β = 1 β (n -1) 2 (6.8) and |w| ≤ |r 1 |(1 + γ 1 ) + • • • + |r n-1 |(1 + γ n-1 ) + |r n |(1 + γ n ) + n ≤ |r 1 • • • r n-1 r n | α + n ≤ 1 α (n + 1) 2 .</formula><p>(6.9)</p><p>From (6.6) and (6.8), we have</p><formula xml:id="formula_72">lim sup m→∞ K(S[0..m -1]) m ≤ lim sup n→∞ (n -1) 2 + O(n log n) 1 β (n -1) 2 = β,<label>(6.10)</label></formula><p>and (6.7) and (6.9) yield</p><formula xml:id="formula_73">lim inf m→∞ K(S[0..m -1]) m ≥ lim inf n→∞ (n -1) 2 -O(n log n) 1 α (n + 1) 2 = α. (6.11)</formula><p>For each n, let</p><formula xml:id="formula_74">w n = r 1 0 k 1 • • • r n 0 kn .</formula><p>Recall the sequence of towers defined by t j by t 0 = 1 and t j+1 = 2 t j . If j is even, then for all t j-1 &lt; i ≤ t j , γ i = 1-β β . Then</p><formula xml:id="formula_75">|w t j | ≤ t j + t j i=1 |r i |(1 + γ i ) = t j + t j-1 i=1 |r i |(1 + γ i ) + 1 β t j i=t j-1 +1 |r i | ≤ t j + 1 α t 2 j-1 + 1 β (t 2 j -t 2 j-1 ) ≤ 1 β t 2 j + t j + O((log t j ) 2 ). (6.12)</formula><p>Similarly, if j is odd, we have We now come to the main theorem of this section. The following notation simplifies its statement and proof.</p><formula xml:id="formula_76">|w t j | ≥ t j i=1 |r i |(1 + γ i ) = t j-1 i=1 |r i |(1 + γ i ) + 1 α t j i=t j-1 +1 |r i | ≥ 1 β t j-1 2 + 1 α (t 2 j -t 2 j-1 ) ≥ 1 α t 2 j -O((log t j ) 2 ). (<label>6</label></formula><p>Notation. Given a bias sequence β = (β 0 , β 1 , . . .), n ∈ N, and S ∈ C, let</p><formula xml:id="formula_77">H n ( β) = 1 n n-1 i=0 H(β i ), H -( β) = lim inf n→∞ H n ( β), H + ( β) = lim sup n→∞ H n ( β).</formula><p>We call H -( β) and H + ( β) the lower and upper average entropies, respectively, of β.</p><p>Theorem 6.6. If δ ∈ (0, 1  2 ] and β is a computable bias sequence with each</p><formula xml:id="formula_78">β i ∈ [δ, 1 2 ], then for every sequence R ∈ RAND β , dim(R) = H -( β) and Dim(R) = H + ( β).</formula><p>Theorem 6.6 says that every sequence that is random with respect to a suitable bias sequence β has the lower and upper average entropies of β as its dimension and strong dimension, respectively. Since there exist β-random sequences in ∆ 0 2 when β is computable, this gives a powerful and flexible method for constructing ∆ 0 2 sequences with given (∆ 0 2 -computable) dimensions and strong dimensions.</p><p>Note that Theorem 6.6 also gives an alternative, though less constructive, proof of Theorem 6.5.</p><p>We now develop a sequence of results that are used in our proof of Theorem 6.6.</p><p>Lemma 6.7. Assume that δ &gt; 0, ǫ &gt; 0, and that, for each β ∈ [δ, 1δ], η β is a bounded random variable such that Eη β ≤ -ǫ and Ee tη β is a continuous function of β for each t &gt; 0. Then there exists θ &gt; 0 such that, for all β ∈ [δ, 1δ] and t ∈ (0, θ],</p><formula xml:id="formula_79">Ee tη β &lt; 1 - tǫ 2 .</formula><p>Proof. Assume the hypothesis. Then the Dominated Convergence Theorem <ref type="bibr" target="#b2">[3]</ref> tells us that, for all</p><formula xml:id="formula_80">β ∈ [δ, 1 -δ], lim t→0 + Ee tη β -1 t = lim t→0 + E e tη β -1 t = E lim t→0 + e tη β -1 t = E η β lim t→0 + e tη β -1 tη β = Eη β ≤ -ǫ.</formula><p>Hence, for each β ∈ [δ, 1δ], there exists t β &gt; 0 such that, for all t ∈ (0, t β ],</p><formula xml:id="formula_81">Ee tη β -1 t &lt; - 3ǫ 4 .</formula><p>It follows by our continuity hypothesis that, for each</p><formula xml:id="formula_82">β ∈ [δ, 1 -δ],</formula><p>there is an open neighborhood N β of β such that, for all t ∈ (0, t β ] and γ</p><formula xml:id="formula_83">∈ N β ∩ [δ, 1 -δ], Ee tηγ -1 t &lt; - ǫ 2 .</formula><p>The family</p><formula xml:id="formula_84">G = {N β | β ∈ [δ, 1 -δ]} is an open cover of the compact set [δ, 1 -δ], so there is a finite set B ⊆ [δ, 1 -δ] such that the subcollection G ′ = {N β | β ∈ B} is also a cover of [δ, 1 -δ]. Let θ = min{t β | β ∈ B}.</formula><p>Then θ &gt; 0 and, for all β ∈ [δ, 1δ] and t ∈ (0, θ],</p><formula xml:id="formula_85">Ee tη β -1 t &lt; - ǫ 2 , whence Ee tη β &lt; 1 - tǫ 2 .</formula><p>Corollary 6.8. For each δ &gt; 0 and ǫ &gt; 0, there exists θ &gt; 0 such that, for all β ∈ [δ, 1δ], if we choose a ∈ {0, 1} with Prob[a = 1] = β, and if</p><formula xml:id="formula_86">η = ξ -H(β) -ǫ or η = H(β) -ξ -ǫ, where ξ = (1 -a) log 1 1 -β + a log 1 β , then Ee θη &lt; 1 - θǫ 2 .</formula><p>Proof. The random variables</p><formula xml:id="formula_87">η 1,β = ξ -H(β) -ǫ, η 2,β = H(β) -ξ -ǫ</formula><p>satisfy the hypothesis of Lemma 6.7 with Eη 1,β = Eη 2,β = -ǫ, so we can choose θ 1 &gt; 0 for η 1,β and θ 2 &gt; 0 for η 2,β as in that lemma. Letting θ = min{θ 1 , θ 2 } establishes the corollary.</p><p>Notation. Given a bias sequence β = (β 0 , β 1 , . . .), n ∈ N, and S ∈ C, let</p><formula xml:id="formula_88">L n ( β)(S) = log 1 µ β (S[0..n -1]) = n-1 i=0 ξ i (S),</formula><p>where</p><formula xml:id="formula_89">ξ i (S) = (1 -S[i]) log 1 1 -β i + S[i] log 1 β i for 0 ≤ i &lt; n.</formula><p>Note that L n ( β), ξ 0 , . . . , ξ n-1 are random variables with</p><formula xml:id="formula_90">EL n ( β) = n-1 i=0 Eξ i = n-1 i=0 H(β i ) = nH n ( β).</formula><p>The following large deviation theorem tells us that L n ( β) is very unlikely to deviate significantly from this expected value. Theorem 6.9. For each δ &gt; 0 and ǫ &gt; 0, there exists α ∈ (0, 1) such that, for all bias sequences β = (β 0 , β 1 , . . .) with each β i ∈ [δ, 1δ] and all n ∈ Z + , if L n ( β) and H n ( β) are defined as above, then</p><formula xml:id="formula_91">P |L n ( β) -nH n ( β)| ≥ ǫn &lt; 2α n ,</formula><p>where the probability is computed according to µ β .</p><p>Proof. Let δ &gt; 0 and ǫ &gt; 0, and choose θ &gt; 0 as in Corollary 6.8. Let α = 1 -θǫ 2 , noting that α ∈ (0, 1). Let β be as given, and let n ∈ Z + . Let L = L n ( β), H = H n ( β), and ξ 0 , ξ 1 , . . . be as above. The proof is in two parts.</p><p>1. For each i ∈ N, let η i = ξ i -H(β i )-ǫ. Then Markov's inequality, independence, and Corollary 6.8 tell us that</p><formula xml:id="formula_92">P[L -nH ≥ ǫn] = P [e θ(L-nH) ≥ e θǫn ] ≤ e -θǫn Ee θ(L-nH) = Ee θ(L-nH)-ǫθn = Ee θ È n-1 i=0 η i = E n-1 i=0 e θη i = n-1 i=0 Ee θη i &lt; α n .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Arguing as in part 1 with</head><formula xml:id="formula_93">η i = H(β i ) -ξ i -ǫ shows that P[nH -L ≥ ǫn] &lt; α n .</formula><p>By parts 1 and 2 of this proof, we now have</p><formula xml:id="formula_94">P[|L -nH| ≥ ǫn] &lt; 2α n .</formula><p>Some of our arguments are simplified by the following constructive version of a classical theorem of Kakutani <ref type="bibr" target="#b16">[17]</ref>. Say that two bias sequences β and β ′ are square-summably equivalent, and write</p><formula xml:id="formula_95">β ≈ 2 β ′ , if ∞ i=0 (β i -β ′ i ) 2 &lt; ∞.</formula><p>Theorem 6.10. (van Lambalgen <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>, Vovk <ref type="bibr" target="#b45">[46]</ref>) Let δ &gt; 0, and let β and β ′ be computable bias sequences with</p><formula xml:id="formula_96">β i , β ′ i ∈ [δ, 1 -δ] for all i ∈ N. 1. If β ≈ 2 β ′ , then RAND β = RAND β ′ . 2. If β ≈ 2 β ′ , then RAND β RAND β ′ = ∅.</formula><p>Corollary 6.11. If δ &gt; 0 and β is a computable bias sequence with each β i ∈ [δ, 1δ], then there is an exactly computable bias sequence β ′ with each</p><formula xml:id="formula_97">β ′ i ∈ [ δ 2 , β i ] satisfying RAND β ′ = RAND β . Proof. Assume the hypothesis. Then there is a computable function g : N × N → Q such that |g(i, r) -β i | ≤ 2 -r for all i, r ∈ N. Let m = 2 + log 1</formula><p>δ , and let</p><formula xml:id="formula_98">β ′ i = g(i, m + i) -2 -(m+i)</formula><p>for all i ∈ N. It is easily verified that β ′ is exactly computable, each</p><formula xml:id="formula_99">β ′ i ∈ [ δ 2 , β i ],</formula><p>and β ′ ≈ 2 β, whence Theorem 6.10 tells us that RAND β ′ = RAND β . Lemma 6.12. If δ &gt; 0 and β is a computable bias sequence with each</p><formula xml:id="formula_100">β i ∈ [δ, 1 -δ], then every sequence R ∈ RAND β satisfies L n ( β)(R) = nH n ( β) + o(n) as n → ∞. 1. If s &lt; H -( β), then S ∞ [d] RAND β = ∅. 2. If s &lt; H + ( β), then S ∞ str [d] RAND β = ∅.</formula><p>Proof. Assume the hypothesis. Define</p><formula xml:id="formula_101">d ′ : {0, 1} * → [0, ∞) by d ′ (w) = d(w) 2 s|w| µ β (w)</formula><p>for all w ∈ {0, 1} * . Then d ′ is a β-martingale, and d ′ is clearly constructive. Let R ∈ RAND β . Then d ′ does not succeed on R, so there is a constant c &gt; 0 such that, for all n ∈ N, if we write</p><formula xml:id="formula_102">z n = R[0..n -1], then d ′ (z n ) ≤ 2 c , whence log d(z n ) ≤ c + sn + log µ β (z n ).</formula><p>It follows by Lemma 6.12 that</p><formula xml:id="formula_103">log d(z n ) ≤ c + n[s -H n ( β)] + o(n)</formula><p>as n → ∞. Hence, for any ǫ &gt; 0, if we let</p><formula xml:id="formula_104">I ǫ = {n ∈ Z + | s &lt; H n ( β) -ǫ},</formula><p>then log d(z n ) &lt; c for all sufficiently large n ∈ I ǫ . We now verify the two parts of the lemma.</p><formula xml:id="formula_105">1. If s &lt; H -( β), let ǫ = H -( β)-s 2 . Then I ǫ is cofinite, so log d(z n ) &lt; c for all sufficiently large n ∈ Z + , so R ∈ S ∞ [d]. 2. If s &lt; H + ( β), let ǫ = H + ( β)-s 2 . Then I ǫ is infinite, so log d(z n ) &lt; c for infinitely many n ∈ Z + , so R ∈ S ∞ str [d].</formula><p>We now have all we need to prove the main theorem of this section.</p><p>Proof of Theorem 6.6. Assume the hypothesis, and let R ∈ RAND β . By Lemma 6.13, dim(R) ≤</p><formula xml:id="formula_106">H -( β) and Dim(R) ≤ H + ( β). To see that dim(R) ≥ H -( β) and Dim(R) ≥ H + ( β), let s, t ∈ [0, ∞) be computable with s &lt; H -( β) and t &lt; H + ( β), let d -be a constructive s-gale, and let d + be a constructive t-gale. It suffices to show that R ∈ S ∞ [d -] and R ∈ S ∞ str [d + ]</formula><p>. But these follow immediately from Lemma 6.14 and the β-randomness of R. Corollary 6.15. If β is a computable sequence of coin-toss biases such that</p><formula xml:id="formula_107">H( β) = lim n→∞ H n ( β) ∈ (0, 1), then every sequence R ∈ C that is random with respect to β is c-regular, with dim(R) = Dim(R) = H( β).</formula><p>Note that Corollary 6.15 strengthens Theorem 7.6 of <ref type="bibr" target="#b20">[21]</ref> because the convergence of H n ( β) is a weaker hypothesis than the convergence of β.</p><p>Generalizing the construction of Chaitin's random real number Ω <ref type="bibr" target="#b5">[6]</ref>, Mayordomo <ref type="bibr" target="#b26">[27]</ref> and, independently, Tadaki <ref type="bibr" target="#b40">[41]</ref> defined for each s ∈ (0, 1] and each infinite, computably enumerable set A ⊆ {0, 1} * , the real number</p><formula xml:id="formula_108">θ s A = 2 |π| s π ∈ {0, 1} * and U (π) ∈ A ,</formula><p>where U is a universal self-delimiting Turing machine. Given (6.1) and Corollary 6.2 above, the following fact is implicit in Tadaki's paper.</p><p>Theorem 6.16. (Tadaki <ref type="bibr" target="#b40">[41]</ref>) For each s ∈ (0, 1] and each infinite, computably enumerable set A ⊆ {0, 1} * , the (binary expansion of the) real number θ s A is c-regular with dim(θ s A ) = Dim(θ s A ) = s. We define a set X ⊆ C to be self-similar if it has the form</p><formula xml:id="formula_109">X = A ∞ = {S ∈ C|S = w 0 w 1 w 2 . . . for some w 0 , w 1 , w 2 , . . . ∈ A}</formula><p>where is A ⊆ {0, 1} * is a finite prefix set. Self-similar sets are examples of c-regular sets. Theorem 6.17. Let X = A ∞ be self-similar where A is a finite prefix set. Then X is c-regular, with cdim(X) = cDim(X) = inf{s| w∈A 2 -s|w| ≤ 1}.</p><p>Proof. We say that a string w is composite if there are strings w 1 , . . . , w k ∈ A such that w = w 1 • • • w k . Let s be computable such that w∈A 2 -s|w| ≤ 1. For any computable ǫ &gt; 0 we define a constructive (s + ǫ)-supergale d as follows. Let w ∈ {0, 1} * , and let v be the maximal composite proper prefix of w. Then d(w) = u∈A:w⊑vu</p><formula xml:id="formula_110">2 ǫ|w| 2 -s(|vu|-|w|) .</formula><p>For all composite strings w, we have d(w) = 2 ǫ|w| . It follows that A ∞ ⊆ S ∞ str [d], and therefore cDim(A ∞ ) ≤ s + ǫ.</p><p>Let s such that w∈A 2 -s|w| &gt; 1 and let d be a s-gale. To show that cdim(A ∞ ) &gt; s, it suffices to construct a sequence S ∈ A ∞ -S ∞ [d]. Initially, we let w 0 = λ. Assume that w n has been defined, and let u ∈ A such that d(w n u) ≤ d(w n ). We know that such a u exists because of our choice of s. Then we let w n+1 = w n u. Our sequence S is the unique one that has w n ⊑ S for all n.</p><p>Dai, Lathrop, Lutz, and Mayordomo <ref type="bibr" target="#b6">[7]</ref> investigated the finite-state compression ration ρ FS (S), defined for each sequence S ∈ C to be the infimum, taken over all information-lossless finite-state compressors C (a model defined in Shannon's 1948 paper <ref type="bibr" target="#b35">[36]</ref>) of the (lower) compression ratio</p><formula xml:id="formula_111">ρ C (S) = lim inf n→∞ |C(S[0..n -1])| n .</formula><p>They proved that ρ FS (S) = dim FS (S) (6.17) for all S ∈ C. However, it has been pointed out that the compression ratio ρ FS (S) differs from the one investigated by Ziv <ref type="bibr" target="#b46">[47]</ref>. Ziv was instead concerned with the ratio R FS (S) defined by</p><formula xml:id="formula_112">R FS (S) = inf k∈AE lim sup n→∞ inf C∈C k |C(S[0..n -1])| n ,</formula><p>where C k is the set of all k-state information-lossless finite-state compressors. The following result, together with (6.17), clarifies the relationship between ρ FS (S) and R FS (S).</p><p>Theorem 6.18. For all S ∈ C, R FS (S) = Dim FS (S).</p><p>The proof of Theorem 6.18 is based on the following lemma.</p><p>Lemma 6.19. Let C be the set of all finite-state compressors. For all S ∈ C,</p><formula xml:id="formula_113">R FS (S) = inf C∈C lim sup n→∞ |C(S[0..n -1])| n . Proof. Let R ′ FS (S) = inf C∈C lim sup n→∞ |C(S[0..n -1])| n .</formula><p>The inequality R FS (S) ≤ R ′ FS (S) is trivial. We use several results from <ref type="bibr" target="#b6">[7]</ref> to obtain for each k ∈ N and ǫ &gt; 0 a finite-state compressor C k,ǫ that is nearly optimal for all compressors in C k . From Lemma 7.7 in <ref type="bibr" target="#b6">[7]</ref> we obtain a finite-state gambler for each C ∈ C k . By Lemma 3.7 in <ref type="bibr" target="#b6">[7]</ref>, we can combine these gamblers into a single finite-state gambler. Theorem 4.5 and Lemma 3.11 in <ref type="bibr" target="#b6">[7]</ref> convert this single gambler into a 1-account nonvanishing finite-state gambler and finally Lemma 7.10 converts this to the finite-state compressor C k,ǫ . Combining the five cited constructions in <ref type="bibr" target="#b6">[7]</ref> we obtain that there is a constant c k,ǫ such that for all w ∈ {0, 1} * and</p><formula xml:id="formula_114">C ∈ C k , |C k,ǫ (w)| ≤ |C(w)| + ǫ|w| + c k,ǫ .</formula><p>Then for all k ∈ N and ǫ &gt; 0,</p><formula xml:id="formula_115">R ′ FS (S) ≤ lim sup n→∞ |C k,ǫ (S[0..n -1])| n ≤ lim sup n→∞ inf C∈C k |C(S[0..n -1])| n + ǫ, so R ′ FS (S) ≤ R FS (S).</formula><p>Proof of Theorem 6.18. The equality</p><formula xml:id="formula_116">Dim FS (S) = inf C∈C lim sup n→∞ |C(S[0..n -1])| n</formula><p>has a proof analogous to that of (6.17) given in <ref type="bibr" target="#b6">[7]</ref>. Together with Lemma 6.19, this implies that R FS (S) = Dim FS (S).</p><p>Thus, mathematically, the compression ratios ρ FS (S) and R FS (S) are both natural: they are the finite-state effectivizations of the Hausdorff and packing dimensions, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Computational Complexity</head><p>In this section we prove our third main theorem, which says that the dimensions and strong dimensions of polynomial-time many-one degrees in exponential time are essentially unrestricted. Our proof of this result uses convenient characterizations of p-dimension and strong p-dimension in terms of feasible unpredictability.</p><p>Definition. A predictor is a function π : {0, 1} * × {0, 1} → [0, 1] such that for all w ∈ {0, 1} * , π(w, 0) + π(w, 1) = 1.</p><p>We interpret π(w, b) as the predictor's estimate of the probability that the bit b will occur next given that w has occurred. We write Π(p) for the class of all feasible predictors. Definition. Let w ∈ {0, 1} * , S ∈ C, and X ⊆ C.</p><p>1. The cumulative log-loss of π on w is</p><formula xml:id="formula_117">L log (π, w) = |w|-1 i=0 log 1 π(w[0..i -1], w[i])</formula><p>.</p><p>2. The log-loss rate of π on S is</p><formula xml:id="formula_118">L log (π, S) = lim inf n→∞ L log (π, S[0..n -1]) n .</formula><p>3. The strong log-loss rate of π on S is</p><formula xml:id="formula_119">L log str (π, S) = lim sup n→∞ L log (π, S[0..n -1]) n .</formula><p>4. The (worst-case) log-loss of π on X is</p><formula xml:id="formula_120">L log (π, X) = sup S∈X L log (π, S).</formula><p>5. The (worst-case) strong log-loss of π on X is L log str (π, X) = sup S∈X L log str (π, S).</p><p>6. The feasible log-loss unpredictability of X is</p><formula xml:id="formula_121">unpred log p (X) = inf π∈Π(p)</formula><p>L log (π, X).</p><p>7. The feasible strong log-loss unpredictability of X is</p><formula xml:id="formula_122">Unpred log p (X) = inf π∈Π(p)</formula><p>L log str (π, X).</p><p>Hitchcock <ref type="bibr" target="#b12">[13]</ref> showed that feasible dimension exactly characterizes feasible log-loss unpredictability, that is, unpred log p (X) = dim p (X) <ref type="bibr">(7.1)</ref> for all X ⊆ C. The same argument proves the following dual result for strong dimension.</p><p>Theorem 7.1. For all X ⊆ C, Unpred log p (X) = Dim p (X).</p><p>The following theorem is the main result of this section. Most of this section is devoted to proving Theorem 7.2. Our proof is motivated by analogous, but simpler, arguments by Ambos-Spies, Merkle, Reimann and Stephan <ref type="bibr" target="#b0">[1]</ref>. Like most dimension calculations, our proof consists of separate lower and upper bound arguments. The results from here through Lemma 7.7 are used for the lower bound. Lemma 7.8 uses Theorem 7.1 to establish the upper bound. The proof of Theorem 7.2 follows Lemma 7.8.</p><p>The first part of the following theorem is due to Ambos-Spies, Merkle, Reimann and Stephan <ref type="bibr" target="#b0">[1]</ref>. The second part is an exact dual of the first part.   The following lemma is a time-bounded version of Lemma 6.14.</p><p>Lemma 7.4. Assume that k, l ∈ Z + , δ &gt; 0, β is an exactly n l -time-computable bias sequence with each <ref type="bibr">)</ref>, and d is an n k -time-computable s-gale.</p><formula xml:id="formula_123">β i ∈ Q ∩ [δ, 1 -δ], s ∈ Q ∩ [0, ∞</formula><formula xml:id="formula_124">1. If s &lt; H -( β), then S ∞ [d] RAND β (n k+2l+1 ) = ∅. 2. If s &lt; H + ( β), then S ∞ str [d] RAND β (n k+2l+1 ) = ∅.</formula><p>Proof. We proceed exactly as in the proof of Lemma 6.14, noting that our present hypothesis implies that the β-martingale d ′ is O(n k+2l+1 )-time-computable.</p><p>Our proof of Theorem 7.2 also uses the martingale dilation technique, which was introduced by Ambos-Spies, Terwijn, and Zheng <ref type="bibr" target="#b1">[2]</ref> and extended by Breutzmann and Lutz <ref type="bibr" target="#b3">[4]</ref>.</p><p>Definition. The restriction of a string w ∈ {0, 1} * to a language A ⊆ {0, 1} * is the string w ↾ A defined by the following recursion.</p><formula xml:id="formula_125">1. λ ↾ A = λ. 2. For w ∈ {0, 1} * and b ∈ {0, 1}, (wb) ↾ A = (w ↾ A)b if s |w| ∈ A, w ↾ A if s |w| ∈ A.</formula><p>(That is, w ↾ A is the concatenation of the successive bits w[i] for which s i ∈ A.)</p><formula xml:id="formula_126">Definition. A function f : {0, 1} * -→ {0, 1} * is strictly increasing if, for all x, y ∈ {0, 1} * , x &lt; y =⇒ f (x) &lt; f (y),</formula><p>where &lt; is the standard ordering of {0, 1} * .</p><p>Notation. If f : {0, 1} * -→ {0, 1} * , then for each n ∈ N, let n f be the unique integer such that f (s n ) = s n f .</p><p>Definition. If f : {0, 1} * -→ {0, 1} * is strictly increasing and β is a bias sequence, then the f -dilation of β is the bias sequence β f given by β f n = β n f for all n ∈ N.</p><p>Observation 7.5. If f : {0, 1} * -→ {0, 1} * is strictly increasing and A ⊆ {0, 1} * , then for all n ∈ N,</p><formula xml:id="formula_127">χ f -1 (A) [0..n -1] = χ A [0..n f -1] ↾ range(f ).</formula><p>Definition. If f : {0, 1} * -→ {0, 1} * is strictly increasing and d is a martingale, then then the f -dilation of d is the function fˆd : {0, 1} * -→ [0, ∞),</p><formula xml:id="formula_128">fˆd(w) = d(w ↾ range(f )).</formula><p>Intuitively, the f -dilation of d is a strategy for betting on a language A, assuming that d itself is a good betting strategy for betting on the language f -1 (A). Given an opportunity to bet on the membership of a string y = f (x) in A, fˆd bets exactly as d would bet on the membership or nonmembership of x in f -1 (A).</p><p>The following result is a special case of Theorem 6.3 in <ref type="bibr" target="#b3">[4]</ref>.</p><p>Theorem 7.6. (Martingale Dilation Theorem -Breutzmann and Lutz <ref type="bibr" target="#b3">[4]</ref>) Assume that β is a bias sequence with each β i ∈ (0, 1), f : {0, 1} * -→ {0, 1} * is strictly increasing, and d is a β f -martingale.</p><p>Then fˆd is a β-martingale and, for every language A ⊆ {0, 1} * , if d succeeds on f -1 (A), then fˆd succeeds on A.</p><p>Notation. For each k ∈ Z + , define g k : {0, 1} * -→ {0, 1} * by g k (x) = 0 |x| k 1x. Note that each g k is strictly increasing and computable in polynomial time.</p><p>Lemma 7.7. Assume that β is a bias sequence with each β i ∈ (0, 1), and R ∈ RAND β (n 2 ). Then, for each k ≥ 2, g -1 k (R) ∈ RAND α (n k ), where α = β g k .</p><p>Proof. Let β, k, and α be as given, and assume that g -1 k (R) ∈ RAND α (n k ). Then there is an n k -time-computable α-martingale d that succeeds on g -1 k (R). It follows by Theorem 7.6 that g k ˆd is a β-martingale that succeeds on R </p><formula xml:id="formula_129">k + |x| + 1 ≤ |s |w| | = ⌊log(1 + |w|)⌋, so |w ′ | ≤ 2 1+log(1+|w|) 1 k , so the time required to compute g k ˆd(w) is O(|w| 2 + 2 k 2 k(log(1+|w|)) 1 k ) = O(|w| 2 ) steps. Thus g k ˆd(w) is is an n 2 -time computable β-martingale, so R ∈ RAND β (n 2 ).</formula><p>Notation. From here through the proof of Theorem 7.2, we assume that α and β are ∆ 0 2computable real numbers with 0 ≤ α ≤ β ≤ 1/2. It is well-known that a real number is ∆ 0 2computable if and only if there is a computable sequence of rationals that converge to it. Slowing down this construction gives polynomial-time functions α, β : N → Q such that lim n→∞ α(n) = α and lim n→∞ β(n) = β. We also assume that 1 n ≤ α(n) ≤ β(n) for all n. For each n, we let</p><formula xml:id="formula_130">κ(n) = α(n) if n is even β(n) if n is odd</formula><p>and define a special-purpose bias sequence γ by</p><formula xml:id="formula_131">γ n = κ(log * n). Note that γ is O(n)-time-computable, 1 log * n ≤ γ n for all n, H -( γ) = H(α), and H + ( γ) = H(β).</formula><p>We now use the unpredictability characterizations from the beginning of this section to establish upper bounds on the dimensions and strong dimensions of lower spans of sequences random relative to γ. Proof. For now, fix a polynomial-time function f : {0, 1} * → {0, 1} * . The collision set of f is</p><formula xml:id="formula_132">C f = {j | (∃i &lt; j)f (s i ) = f (s j )}. For each n ∈ N, let #C f (n) = |C f ∩ {0, . . . , n -1}|.</formula><p>We use f to define the predictors</p><formula xml:id="formula_133">π f 0 (w, b) = 1 2 if |w| ∈ C f w[i] b (1 -w[i]) 1-b if |w| ∈ C f and i = min{j | f (s j ) = f (s |w| )} and π f 1 (w, b) = (γ f |w| ) b (1 -γ f |w| ) 1-b if |w| ∈ C f w[i] b (1 -w[i]) 1-b if |w| ∈ C f and i = min{j | f (s j ) = f (s |w| )}</formula><p>for all w ∈ {0, 1} * and b ∈ {0, 1}.</p><p>For each S ∈ C, we now define several objects to facilitate the proof. First, we let</p><formula xml:id="formula_134">A f (S) = f -1 (S);</formula><p>that is, A f (S) is the language ≤ p m -reduced to S by f . Observe that for all w ⊑ A f (S),</p><formula xml:id="formula_135">L log (π f 0 , w) = |w| -#C f (|w|). (7.2)</formula><p>Recall the sequence of towers defined by t j by t 0 = 1 and t j+1 = 2 t j . For any j ∈ N and t j &lt; n ≤ t j+1 , define the entropy quantity</p><formula xml:id="formula_136">H f n = i&lt;n i ∈C f and i f &gt;t j-1 H(γ f n )</formula><p>and the random variable</p><formula xml:id="formula_137">L f n (S) = i&lt;n i ∈C f and i f &gt;t j-1 log 1 π f 1 (A f (S)[0..i -1], A f (S)[i])</formula><p>.</p><p>(Recall that i f is the unique number such that f (s i ) = s i f .) We have</p><formula xml:id="formula_138">L log (π f 1 , A f (S)[0..n -1]) = i&lt;n log 1 π f 1 (A f (S)[0..i -1], A f (S)[i]) = i&lt;n i ∈C f log 1 π f 1 (A f (S)[0..i -1], A f (S)[i]) = L f n (S) + i&lt;n i ∈C f and i f ≤t j-1 log 1 π f 1 (A f (S)[0..i -1], A f (S)[i]) ≤ L f n (S) + i&lt;n i ∈C f and i f ≤t j-1 log log * i f ≤ L f n (S) + (t j-1 + 1) log(j -1) ≤ L f n (S) + (1 + log n) log * n,<label>(7.3)</label></formula><p>for all n. (Here we used the fact that γ i ≥ 1 log * i for all i.) Finally, for any ǫ &gt; 0 and θ ∈ (0, 1), define the set</p><formula xml:id="formula_139">J f θ,ǫ (S) = {n | #C f (n) &lt; (1 -θ)n and L f n (S) ≥ H f n + ǫn} of natural numbers.</formula><p>Claim. For any rational θ ∈ (0, 1) and ǫ &gt; 0,</p><formula xml:id="formula_140">µ γ n 5 {S | J f θ,ǫ (S) is finite} = 1.</formula><p>Proof of Claim. The argument is similar to the proof of Lemma 6.12. For each n ∈ N, define the set</p><formula xml:id="formula_141">Y n = ∅ if #C f (n) ≥ (1 -θ)n {S | L f n (S) ≥ H f n + ǫn} otherwise, and let X ǫ = {S ∈ C|(∃ ∞ n)S ∈ Y n }.</formula><p>To prove the claim, we will show that µ γ n 5 (X ǫ ) = 0.</p><p>For each n ∈ N and w ∈ {0, 1} * , let</p><formula xml:id="formula_142">d n (w) = µ γ (Y n |C w ) if |w| ≤ n d n (w[0..n -1]) if |w| &gt; n.</formula><p>It is clear that each d n is a γ-martingale and that Y n ⊆ S 1 [d n ] for all n ∈ N.</p><p>Let S ∈ C. For each n, j ∈ N, let</p><formula xml:id="formula_143">I n j = {i f | i &lt; n, i ∈ C f , and log * i f = j}. Also, define S + = {i | S[i] = 1} and S -= {i | S[i] = 0}.</formula><p>Then, if n is large enough to ensure that log * i f ≤ 1 + log * n for all i &lt; n, we have</p><formula xml:id="formula_144">L f n (S) = (log * n)+1 k=(log * n)-1 I n k ∩ S + log 1 κ(k) + I n k ∩ S -log 1 1 -κ(k) .</formula><p>For any n and k, write i(n, k) = |I n k |. Let T n be the set of all tuples (l -1 , l 0 , l 1 ) satisfying 0 ≤ l r ≤ i(n, j + r) for -1 ≤ r ≤ 1 and</p><formula xml:id="formula_145">1 r=-1 l r log 1 κ(j + r) + (i(n, j + r) -l r ) log 1 1 -κ(j + r) ≥ H f n + ǫn,</formula><p>where j = log * n. Then we have</p><formula xml:id="formula_146">µ γ (Y n ) = (l -1 ,l 0 ,l 1 )∈Tn 1 r=-1</formula><p>i(n, j + r) l r κ(j + r) lr (1κ(j + r)) i(n,j+r)-lr .</p><p>We can write a similar formula for µ γ (Y n |C w ) when w = λ. From this it follows that the mapping (n, w) → d n (w) is exactly computable in O(n 3 ) time. By Theorem 6.9, there exists δ ∈ (0, 1) such that for all n ∈ N with Y n = ∅, we have</p><formula xml:id="formula_147">µ γ (Y n ) &lt; 2δ n-#C f (n) &lt; 2δ θn .</formula><p>It follows that the series ∞ n=0 d n (λ) is p-convergent, so a the polynomial-time first Borel-Cantelli Lemma <ref type="bibr" target="#b21">[22]</ref> (extended to γ as indicated in <ref type="bibr" target="#b3">[4]</ref>) tells us that µ γ n 5 (X ǫ ) = 0. Claim. Let R ∈ RAND γ (n 5 ). Let ǫ &gt; 0 and θ &lt; H(α) be rational. Then by the above claim, J f θ,ǫ (R) is finite. That is, for all but finitely many n, We now verify (7.9). For each n, let m(n) = t 2 n . Then for sufficiently large n, we have i f &lt; t n+1 for all i &lt; m(n). Using the sets I k n from the proof of the claim, we then have For each polynomial-time reduction f , we have defined and analyzed two predictors π f 0 and π f 1 . We now show how to combine all these predictors into a single predictor that will establish the lemma.</p><formula xml:id="formula_148">#C f (n) ≥ (1 -θ)n or L f n (R) &lt; H f n + ǫn. (<label>7</label></formula><formula xml:id="formula_149">H f m(n) = I m(n)</formula><p>Let {f j | j ∈ N} be a uniform enumeration of all polynomial-time functions f j : {0, 1} * → {0, 1} * such that f j (x) is computable in O(2 |x| + j) steps. For any predictor ρ, define a probability measure As π is (exactly) polynomial-time computable, this establishes that P m (R) = {A f j (R) | j ∈ N} has p-dimension at most H(α) + ǫ by (7.1) and strong p-dimension at most H(β) + ǫ by Theorem 7.1. As ǫ &gt; 0 was arbitrary, the lemma follows.</p><p>We now have the machinery we need to prove the main result of this section.</p><p>Proof of Theorem 7.2. Let x and y be ∆ 0 2 -computable real numbers with 0 ≤ x ≤ y ≤ 1. Then there exist ∆ 0 2 -computable real numbers α and β with 0 ≤ α ≤ β ≤ 1 2 , H(α) = x, and H(β) = y. Let γ be the bias sequence defined from α and β above (just prior to Lemma 7.8). It is well-known <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b1">2]</ref> that almost every language in E is n 5 -γ-random. In particular, there exists a language A ∈ RAND β (n 5 ) ∩ E. By Theorem 7. In light of Theorem 7.2, the following question concerning the relativized feasible dimension of NP is natural. Open Question 7.9. For which pairs of real numbers α, β ∈ [0, 1] does there exist an oracle A such that dim p A (NP A ) = α and Dim p A (NP A ) = β?</p><p>We conclude this section with two brief observations. Fortnow and Lutz <ref type="bibr" target="#b10">[11]</ref> have recently established a tight quantitative relationship between pdimension and feasible predictability. Specifically, for each X ⊆ C, they investigated the quantity Pred p (X) which is the supremum, for all feasible predictors π, of the (worst-case, upper) success rate π + (S) = inf is the expected number of correct predictions that π will make on w. They proved that Pred p (X) is related to the p-dimension of X by 2(1 -Pred p (X)) ≤ dim p (X) ≤ H(Pred p (X)) <ref type="bibr">(7.16)</ref> (where H(α) is the Shannon entropy of α) and that these bounds are tight. If we call Pred p (X) the upper feasible predictability of X and define the lower feasible predictability of X, pred p (X), in the same fashion, but with the limit superior in (7.15) replaced by a limit inferior, then we have the following dual of (7.16).</p><p>Theorem 7.10. For all X ⊆ C, 2(1pred p (X)) ≤ Dim p (X) ≤ H(pred p (X)).</p><p>For each s : N → N, let SIZE(s(n)) be the class of all (characteristic sequences of) languages A ⊆ {0, 1} * such that, for each n ∈ N, A =n is decided by a Boolean circuit consisting of at most s(n) gates.</p><p>Theorem 7.11. For each α ∈ [0, 1], the class X α = SIZE(α• 2 n n ) is pspace-regular, with dim pspace (X α ) = Dim pspace (X α ) = dim(X α |ESPACE) = Dim(X α |ESPACE) = α.</p><p>Proof. It was shown in <ref type="bibr" target="#b19">[20]</ref> that dim pspace (X α ) = dim(X α |ESPACE) = α. This proof also shows that the strong dimensions are α.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Lemma 4 . 1 .</head><label>41</label><figDesc>(Lutz [20]) Let s ∈ [0, ∞). If d is an s-supergale and B ⊆ {0, 1} * is a prefix set, then for all w ∈ {0, 1} * , u∈B 2 -s|u| d(wu) ≤ d(w).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Lemma 5 . 4 .</head><label>54</label><figDesc>The constructive dimensions are absolutely stable, i.e., for all X ⊆ C, cdim(X) = sup S∈X dim(S) and cDim(X) = sup S∈X Dim(S).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Theorem 6 . 1 .</head><label>61</label><figDesc>For all S ∈ C, Dim(S) = lim sup n→∞ dim(S[0..n -1]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Definition.. 2 .. 3 .</head><label>23</label><figDesc>Let d be a supermartingale, let S ∈ C, and let X ⊆ C. 1. The lower d-Lyapunov exponent of S is λ d (S) = lim inf n→∞ log d(S[0..n-1]) n The upper d-Lyapunov exponent of S is Λ d (S) = lim sup n→∞ log d(S[0..n-1]) n The lower Lyapunov exponent of S is λ(S) = sup{λ d (S)|d is a constructive supermartingale}. 4. The upper Lyapunov exponent of S is Λ(S) = sup{Λ d (S)|d is a constructive supermartingale}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>[d]. Define a constructive martingale d ′ by d ′ (w) = 2 (1-s)|w| d(w) for all w ∈ {0, 1} * . For infinitely many n, we have d(S[0..n -1]) &gt; 1, and for each of these n, d ′ (S[0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Theorem 7 . 2 .</head><label>72</label><figDesc>For every pair of ∆ 0 2 -computable real numbers x, y with 0 ≤ x ≤ y ≤ 1, there exists A ∈ E such that dim p (deg p m (A)) = dim(deg p m (A)|E) = x and Dim p (deg p m (A)) = Dim(deg p m (A)|E) = y.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Theorem 7 . 3 .</head><label>73</label><figDesc>Let A ∈ E.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1 .</head><label>1</label><figDesc>dim p (deg p m (A)) = dim p (P m (A)) and dim(deg p m (A)|E) = dim(P m (A)|E).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>2 .</head><label>2</label><figDesc>Dim p (deg p m (A)) = Dim p (P m (A)) and Dim(deg p m (A)|E) = Dim(P m (A)|E).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>.</head><label></label><figDesc>The time required to compute g k ˆd(w) is O(|w| 2 + |w ′ | k ) steps, where w ′ = w ↾ range(g k ). (This allows O(|w| 2 ) steps to compute w ′ and then O(|w| k steps to compute d(w ′ ).) Now |w ′ | is bounded above by the number of strings x such that |x|</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Lemma 7 . 8 .</head><label>78</label><figDesc>For each R ∈ RAND γ (n 5 ), dim p (P m (R)) ≤ H(α)and Dim p (P m (R)) ≤ H(β).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>nH</head><label></label><figDesc>(κ(n)) + I m(n) n+1 H(κ(n + 1)) ≤ (t n + 1)H(κ(n)) + m(n)H(κ(n + 1)).As t n = o(m(n)) and κ(2n) → α as n → ∞,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>[0..i -1], w[i]) for all w ∈ {0, 1} * . For each m ∈ N and w ∈ {0, 1} m , let µ m (w) = 2 -(2m+1) +</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>3, it suffices to prove that dim p (P m (A)) = dim(P m (A)|E) = H(α) and Dim p (P m (A)) = Dim(P m (A)|E) = H(β). By Lemma 7.8, then, it suffices to prove that dim(P m (A)|E) ≥ H(α) (7.11) and Dim(P m (A)|E) ≥ H(β). (7.12) Note that (7.11) is trivial if α = 0, and (7.12) is trivial if β = 0. If α &gt; 0, let s ∈ [0, H(α)) ∩ Q, and let d -be an n k -time computable s-gale. Similarly, if β &gt; 0, let t ∈ [0, H(β)) ∩ Q, and let d + be an n k -time computable t-gale. It suffices to show thatα &gt; 0 ⇒ P m (A) ∩ E ⊆ S ∞ [d -] (7.13) and β &gt; 0 ⇒ P m (A) ∩ E ⊆ S ∞ str [d + ]. (7.14) Let B = g -1 k+3 (A). It is clear that B ∈ P m (A) ∩ E. Also, by Lemma 7.7, B ∈ RAND γ ′ (n k ), where γ ′ = γ g k+3 . Since s &lt; H(α) = H -( γ) = H -( γ ′ ), t &lt; H(β) = H + ( γ) = H + ( γ ′ ),and γ ′ is O(n)-time-computable, Lemma 7.4 tells us that α &gt; 0 ⇒ B ∈ S ∞ [d -] and β &gt; 0 ⇒ B ∈ S ∞ str [d + ]. Thus (7.13) and (7.14) hold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>[0..i -1], w[i])</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.4) Writing w n = A f (R)[0..n -1],(7.4) combined with (7.2) and (7.3) implies that L</figDesc><table><row><cell>As</cell><cell></cell><cell>lim sup n→∞</cell><cell>H f n n</cell><cell>≤ H(β),</cell></row><row><cell>it follows that</cell><cell>lim sup n→∞</cell><cell cols="3">min{L log (π f 0 , w n ), L log (π f 1 , w n )} n</cell><cell>≤ H(β) + ǫ.</cell><cell>(7.7)</cell></row><row><cell cols="3">If (7.5) holds for infinitely many n, then</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">L log (π f 0 , A f (R)) ≤ H(α).</cell><cell>(7.8)</cell></row><row><cell cols="4">Otherwise, (7.6) holds for almost all n. Assuming</cell><cell></cell></row><row><cell></cell><cell></cell><cell>lim inf n→∞</cell><cell>H f n n</cell><cell>≤ H(α),</cell><cell>(7.9)</cell></row><row><cell>in this case we have</cell><cell></cell><cell>L log (π f 1 , A</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(7.6)</cell></row></table><note><p><p><p>log (π f 0 , w n ) ≤ θn &lt; H(α)n (7.5) or L log (π f 1 , w n ) &lt; H f n + ǫn + (1 + log n) log * n. f (R)) ≤ H(α) + ǫ. (</p>7</p>.10)    </p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment. The third author thanks Dan Mauldin for extremely useful discussions.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This research was supported in part by Air Force Office of Scientific Research Grant ITSI F 49620-01-1-0076. . This research was supported in part by National Science Foundation Grant 9988483. . This research was supported in part by National Science Foundation Grant 9988483. . This research was supported in part by Spanish Government MEC project PB98-0937-C04-02 and by National Science Foundation Grant 9988483. It was done while visiting Iowa State University.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof. Assume the hypothesis. By Corollary 6.11, we can assume that β is exactly computable. Let ǫ &gt; 0. For each n ∈ N, define the set</p><p>and let</p><p>It suffices to show that µ β comp (X ǫ ) = 0. For each n ∈ N and w ∈ {0, 1} * , let</p><p>It is easily verified that each d n is a β-martingale and that the function (n, w)</p><p>for all n ∈ N. Finally, by Theorem 6.9, the series</p><p>is computably convergent, so the computable first Borel-Cantelli Lemma <ref type="bibr" target="#b21">[22]</ref> (extended to β as indicated in <ref type="bibr" target="#b3">[4]</ref>) tells us that µ β comp (X ǫ ) = 0. Lemma 6.13. If δ &gt; 0 and β is a computable bias sequence with each</p><p>Proof. Assume the hypothesis. By Corollary 6.11, we can assume that β is exactly computable. Let s ∈ [0, ∞) be computable.</p><p>Define</p><p>for all w ∈ {0, 1} * . Then d is a constructive (in fact, computable) s-gale. For each R ∈ C and n ∈ N, if we write</p><p>for all n. In particular, if R ∈ RAND β , if follows by Lemma 6.12 that</p><p>as n → ∞. We now verify the two parts of the lemma. For both parts, we let</p><p>To see that cdim(RAND</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>. Then the set I ǫ is infinite, so (6.16) tells us that RAND β ⊆ S ∞ [d], whence cdim(RAND β ) ≤ s.</p><p>To see that cDim(RAND β ) ≤ H + ( β), let s &gt; H + ( β), and let ǫ = s-H + ( β)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>. Then the set I ǫ is cofinite, so (6.16) tells us that RAND β ⊆ S ∞ str [d], whence cDim(RAND β ) ≤ s.</p><p>Lemma 6.14. Assume that δ &gt; 0, β is a computable bias sequence with each</p><p>s ∈ [0, ∞) is computable, and d is a constructive s-gale.</p><p>Then</p><p>&lt; µ m (w). For all w ∈ {0, 1} * , k ∈ {0, 1}, and j &lt; |w|, we have</p><p>For any j ∈ N, it follows that L log str (π, A f j (R)) ≤ H(β) + ǫ by using f = f j in (7.7). Also, since either (7.8) or (7.10) holds for f = f j , we have L log (π, A f j (R)) ≤ H(α) + ǫ.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hausdorff dimension in exponential time</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ambos-Spies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Stephan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th IEEE Conference on Computational Complexity</title>
		<meeting>the 16th IEEE Conference on Computational Complexity</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="210" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Resource bounded randomness and weakly complete problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ambos-Spies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Terwijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="195" to="207" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Probability and Measure</title>
		<author>
			<persName><forename type="first">P</forename><surname>Billingsley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>John Wiley and Sons</publisher>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
	<note>third edition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Equivalence of measures of complexity classes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Breutzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="302" to="326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On Hausdorff and topological dimensions of the Kolmogorov complexity of the real line</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hartmanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and Systems Sciences</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="605" to="619" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A theory of program size formally identical to information theory</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Chaitin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Computing Machinery</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="329" to="340" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Finite-state dimension. Theoretical Computer Science</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mayordomo</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Falconer</surname></persName>
		</author>
		<title level="m">Fractal Geometry: Mathematical Foundations and Applications</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Falconer</surname></persName>
		</author>
		<title level="m">Techniques in Fractal Geometry</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gales and supergales are equivalent for defining constructive Hausdorff dimension</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fenner</surname></persName>
		</author>
		<idno>cs.CC/0208044</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Prediction and dimension</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fortnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Conference on Computational Learning Theory</title>
		<meeting>the 15th Annual Conference on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="380" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Hausdorff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dimension und äusseres Mass. Mathematische Annalen</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="157" to="179" />
			<date type="published" when="1919">1919</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fractal dimension and logarithmic loss unpredictability. Theoretical Computer Science</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hitchcock</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gales suffice for constructive dimension</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hitchcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint/>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Correspondence principles for effective dimensions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hitchcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Colloquium on Automata, Languages, and Programming</title>
		<meeting>the 29th International Colloquium on Automata, Languages, and Programming</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="561" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MAX3SAT is exponentially hard to approximate if NP has positive dimension</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hitchcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">289</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="861" to="869" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the equivalence of infinite product measures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kakutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="214" to="224" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Théorie de l&apos;Addition des Variables Aleatoires</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lévy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1937">1937</date>
			<publisher>Gauthier-Villars</publisher>
		</imprint>
	</monogr>
	<note>second edition 1954</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">An Introduction to Kolmogorov Complexity and its Applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitányi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dimension in complexity classes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
		</author>
		<idno>cs.CC/0203016</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>SIAM Journal on Computing</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The dimensions of individual strings and sequences. Information and Computation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
		</author>
		<idno>cs.CC/0203017</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>To appear. Available as</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Almost everywhere high nonuniform complexity</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="220" to="258" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Resource-bounded measure</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th IEEE Conference on Computational Complexity</title>
		<meeting>the 13th IEEE Conference on Computational Complexity</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="236" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The definition of random sequences</title>
		<author>
			<persName><forename type="first">P</forename><surname>Martin-Löf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="602" to="619" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Measure and dimension functions: measurability and densities</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mattila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mauldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Proceedings of the Cambridge Philosophical Society</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="81" to="100" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Effective Hausdorff dimension</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mayordomo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Foundations of the Formal Sciences III</title>
		<meeting>Foundations of the Formal Sciences III</meeting>
		<imprint>
			<publisher>Kluwer Academic Press</publisher>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Kolmogorov complexity characterization of constructive Hausdorff dimension</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mayordomo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Coding of combinatorial sources and Hausdorff dimension</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ya</surname></persName>
		</author>
		<author>
			<persName><surname>Ryabko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Mathematics Doklady</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="219" to="222" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Noiseless coding of combinatorial sources. Problems of Information Transmission</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ya</surname></persName>
		</author>
		<author>
			<persName><surname>Ryabko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="170" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Algorithmic approach to the prediction problem</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ya</surname></persName>
		</author>
		<author>
			<persName><surname>Ryabko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Problems of Information Transmission</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="186" to="193" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The complexity and effectiveness of prediction problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ya</surname></persName>
		</author>
		<author>
			<persName><surname>Ryabko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Complexity</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A unified approach to the definition of random sequences</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Schnorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Systems Theory</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="246" to="258" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Schnorr</surname></persName>
		</author>
		<author>
			<persName><surname>Zufälligkeit</surname></persName>
		</author>
		<author>
			<persName><surname>Wahrscheinlichkeit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Mathematics</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Process complexity and effective random tests</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Schnorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="376" to="388" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A survey of the theory of random sequences</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Schnorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Basic Problems in Methodology and Linguistics</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Butts</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hintikka</surname></persName>
		</editor>
		<imprint>
			<publisher>D. Reidel</publisher>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="193" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="623" to="656" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Kolmogorov complexity and Hausdorff dimension</title>
		<author>
			<persName><forename type="first">L</forename><surname>Staiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Computation</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="159" to="194" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A tight upper bound on Kolmogorov complexity and uniformly optimal prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Staiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory of Computing Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="215" to="229" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">How much can you win when your adversary is handicapped?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Staiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Numbers, Information and Complexity</title>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Hausdorff measures old and new, and limit sets of geometrically finite Kleinian groups</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><surname>Entropy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Mathematica</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page" from="259" to="277" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A generalization of Chaitin&apos;s halting probability ω and halting self-similar sets</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tadaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hokkaido Mathematical Journal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="219" to="253" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Two definitions of fractional dimension</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tricot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Proceedings of the Cambridge Philosophical Society</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="57" to="74" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Van Lambalgen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics, University of Amsterdam</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
	<note>Random Sequences</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Von Mises&apos; definition of random sequences reconsidered</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Lambalgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Symbolic Logic</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="725" to="755" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Étude Critique de la Notion de Collectif</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1939">1939</date>
			<publisher>Gauthier-Villars</publisher>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On a randomness criterion</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Vovk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Mathematics Doklady</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="656" to="660" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Coding theorems for individual sequences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ziv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="405" to="412" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
