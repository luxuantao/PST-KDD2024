<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases</title>
				<funder ref="#_KWcXHpQ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-08-17">17 Aug 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xintao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qianwen</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yongting</forename><surname>Qiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiaqing</forename><surname>Liang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qianyu</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhouhong</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yanghua</forename><surname>Xiao</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
							<email>weiwang1@m.fudan.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Leonardo</forename><surname>Dicaprio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kate</forename><surname>Winslet</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Catch ? starring Leonardo DiCaprio and Tom Hanks with Christopher Walken</orgName>
								<address>
									<addrLine>Nathalie Baye</addrLine>
									<settlement>Martin Sheen, Amy Adams</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-08-17">17 Aug 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2308.11761v1[cs.CL]</idno>
					<note type="submission">Revolutionary Road comes close but falls short of</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Catch Me If You Can: [(&apos;starring&apos;</term>
					<term>&apos;Leonardo DiCaprio&apos;)</term>
					<term>(&apos;starring&apos;</term>
					<term>&apos;Tom Hanks&apos;)] Revolutionary Road: [(&apos;stars&apos;</term>
					<term>&apos;Leonardo DiCaprio&apos;)</term>
					<term>(&apos;stars&apos;</term>
					<term>&apos;Kate Winslet&apos;)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) have demonstrated impressive impact in the field of natural language processing, but they still struggle with several issues regarding, such as completeness, timeliness, faithfulness and adaptability. While recent efforts have focuses on connecting LLMs with external knowledge sources, the integration of knowledge bases (KBs) remains understudied and faces several challenges. In this paper, we introduce Knowl-edGPT, a comprehensive framework to bridge LLMs with various knowledge bases, facilitating both the retrieval and storage of knowledge. The retrieval process employs the program of thought prompting, which generates search language for KBs in code format with pre-defined functions for KB operations. Besides retrieval, KnowledGPT offers the capability to store knowledge in a personalized KB, catering to individual user demands. With extensive experiments, we show that by integrating LLMs with KBs, KnowledGPT properly answers a broader range of questions requiring world knowledge compared with vanilla LLMs, utilizing both knowledge existing in widelyknown KBs and extracted into personalized KBs. Query Who starred in both Catch Me If You Can and Revolutionary Road? BM25 Embedding Similarity Knowledge Base Memory</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large Language Models (LLMs) (OpenAI, 2023) <ref type="bibr" target="#b8">(Chiang et al., 2023)</ref>  <ref type="bibr" target="#b31">(Taori et al., 2023)</ref> have achieved substantial impact across a variety of natural language processing (NLP) tasks like translation <ref type="bibr" target="#b34">(Wang et al., 2023)</ref>, summarization <ref type="bibr" target="#b43">(Zhang et al., 2023)</ref> and question answering <ref type="bibr" target="#b33">(van Sonsbeek et al., 2023)</ref>, alongside with all kinds of requests from real-world users. Their remarkable capabilities stem from the ever-increasing number of parameters and training data, which expands in correlation with their massive knowledge and emergent abilities like chain-of-thought reasoning <ref type="bibr" target="#b16">(Kojima et al., 2022)</ref> and in-context learning <ref type="bibr" target="#b4">(Brown et al., 2020)</ref>.  In this case, no document retrieved from the corpus provides enough knowledge for the query, while from the knowledge base sufficient related knowledge can be retrieved.</p><p>However, LLMs still struggle with factual knowledge considering issues like completeness, timeliness, faithfulness and adaptability (OpenAI, 2023) <ref type="bibr" target="#b15">(Kandpal et al., 2023)</ref>. Firstly, LLMs demonstrate limitations in terms of timely updates and expertise in specific domains. Secondly, these models can generate unfaithful or "hallucinated" knowledge, posing both reliability and ethical concerns. Thirdly, due to constraints like costs and accessibility, LLMs can hardly incorporate new knowledge via continued training, which hampers the ability to tailor these models to accommodate specific knowledge demands. Therefore, these knowledge demands encourage comprehensive research efforts towards integrating LLMs with external sources of knowledge.</p><p>Towards this issue, some recent efforts have been made to enable LLMs to access plug-andplay knowledge sources like knowledge bases (KBs) <ref type="bibr">(Modarressi et al., 2023)</ref>, search engines <ref type="bibr" target="#b27">(Schick et al., 2023)</ref>, document memories <ref type="bibr" target="#b22">(Liu, 2022)</ref>, and databases <ref type="bibr" target="#b13">(Hu et al., 2023)</ref> to provide LLMs with world knowledge, generally via LLM-generated API calls. In this paper, we focus on knowledge bases (KBs), a unique form of knowledge source featuring entity-centric knowl-edge like relational triples and entity descriptions. On one hand, various KBs have been constructed for their practical effectiveness for applications, and the conciseness, expressiveness, interpretability and visibility of their representation. On the other hand, previous approaches have largely focused on document corpus, which reveals several deficiency when applied to KGs, as shown in Fig 1 . 
Therefore, connecting LLMs with KBs is of significant importance, yet still remains underexplored.</p><p>Recently, several works have attempted to connect LLMs to KBs. Toolformer <ref type="bibr" target="#b27">(Schick et al., 2023)</ref> queries Wikipedia for descriptions of interested entities to answer related questions. Graph-Toolformer <ref type="bibr" target="#b40">(Zhang, 2023)</ref> and ToolkenGPT <ref type="bibr" target="#b12">(Hao et al., 2023)</ref> make LLMs reason over knowledge graphs like Freebase. <ref type="bibr">RET-LLM (Modarressi et al., 2023)</ref> builds personalized KG memory with relational triples extracted from past conversations for future use, in parallel with practical efforts of KG Index in LangChain <ref type="bibr" target="#b6">(Chase, 2022)</ref> and Llama Index <ref type="bibr" target="#b22">(Liu, 2022)</ref>.</p><p>However, there are still many challenges in this direction, as shown in Figure <ref type="figure" target="#fig_3">2</ref>. Firstly, the process by which LLMs navigate through knowledge bases for intricate and varied questions remains a problem, especially for multi-hop questions which requires information across multiple and nested entries in KBs. Secondly, aligning entities and relations in knowledge bases with their text mentions is a challenging task, as they need to map to a wide spectrum of natural language expressions and account for severe ambiguation in the knowledge bases. Thirdly, while the triple-based representation in KGs is neat and interpretable, it only covers limited information compared with natural language, which suggests the need for new representation form in KBs for LLMs.</p><p>In this paper, we propose a comprehensive framework, KnowledGPT, to connect LLMs to various knowledge bases effectively, with an improved capability in dealing with complex questions, ambiguation and knowledge representation. Knowl-edGPT implements a unified accessor interface for operations on different KBs, including widelyused public KBs and personalized KB memories. KnowledGPT accesses entity-oriented knowledge, including both entity descriptions and relational triples. For a given query, KnowledGPT searches KBs with three steps: search code generation, search execution, and answer generation. Inspired by <ref type="bibr" target="#b7">(Chen et al., 2022)</ref>, KnowledGPT adopts program of thoughts (PoT) prompting, interacting with KBs by generating Python code which delegates searching steps and executing it. This code encapsulates functions for assessing KBs such as entity_linking. Afterwards, KnowledGPT integrates the retrieved knowledge to generate the response. If KnowledGPT judges that the question does not necessitate knowledge from KBs, or if the retrieved knowledge is inadequate or absent, the question will be directly answered by the LLM. Besides, KnowledGPT can also extract knowledge from unstructured texts represented in various forms to enrich the personalized KB.</p><p>Overall, our contributions are summarized as follows:</p><p>1. We propose KnowledGPT, a comprehensive framework to enable LLMs to retrieve knowledge from knowledge bases. It significantly advances the collaboration between LLMs and KBs towards vital practical challenges like complex searching and ambiguation.</p><p>2. We propose the use of personalized knowledge bases as symbolic memory for LLMs, encapsulating entity-oriented knowledge in three forms of representations. This expands the scope of knowledge in symbolic memories compared with triples-only KBs.</p><p>3. We demonstrate the efficacy of our proposed methods with experiments. The results underscore the utility and potential of using KBs as symbolic memory for LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>External Knowledge and Memory for LLMs Large language models (LLMs), such as <ref type="bibr">GPT-4 (OpenAI, 2023)</ref> and LLaMA <ref type="bibr" target="#b32">(Touvron et al., 2023)</ref>, have demonstrated impressive performance across various applications. However, they still struggle with knowledge considering completeness, timeliness, faithfulness and adaptability. Hence, many recent efforts have been devoted to equipping LLMs with external knowledge. Internetaugmented language models <ref type="bibr" target="#b17">(Komeili et al., 2022</ref>) <ref type="bibr" target="#b19">(Lazaridou et al., 2022)</ref>, as well as New Bing and ChatGPT "Browse with Bing" plugin, allow LLMs to access up-to-date information with search engines or web browsers. Retrievalaugmented methods like REALM <ref type="bibr">(Guu et al.</ref>,  2020), RAG <ref type="bibr" target="#b20">(Lewis et al., 2020)</ref>, augment LLMs with document corpus, which have also been increasingly adopted by recent popular LLMs like ChatGPT as the memory unit <ref type="bibr" target="#b22">(Liu, 2022)</ref>  <ref type="bibr" target="#b6">(Chase, 2022)</ref>. ChatDB <ref type="bibr" target="#b13">(Hu et al., 2023)</ref> augments LLMs with databases as symbolic memory.</p><p>Knowledge Bases for LLMs Some recent works have studied to augment LLMs with knowledge from external KBs or use KBs as symbolic memories, usually by making LLMs generate API calls for KB operations. Toolformer <ref type="bibr" target="#b27">(Schick et al., 2023)</ref> trains LLMs to search Wikipedia for texts of entities. Graph-Toolformer <ref type="bibr" target="#b40">(Zhang, 2023)</ref> empowers LLMs to reason over knowledge graphs. However, it skips the entity linking step, so it requires entity id like /m/053yx as input, instead of their names. ToolkenGPT <ref type="bibr" target="#b12">(Hao et al., 2023)</ref> keeps the LLMs frozen and trains tool embeddings for relations in KBs to support relational queries. <ref type="bibr">RET-LLM (Modarressi et al., 2023)</ref>, similar to the KG memory of LangChain <ref type="bibr" target="#b6">(Chase, 2022)</ref> and Llama-Index <ref type="bibr" target="#b22">(Liu, 2022)</ref>, extracts relational triples from user inputs and store them in a symbolic KG memory. Compared with previous efforts, KnowledGPT supports various knowledge representations and both public and private KBs, as shown in Table <ref type="table" target="#tab_1">1</ref>.</p><p>Knowledge-based Question Answering (KBQA) is to search for answer entities or relations given natural language queries specific to certain KGs. Existing KBQA systems are mainly based on semantic parsing <ref type="bibr" target="#b2">(Berant et al., 2013)</ref> or information extraction <ref type="bibr" target="#b38">(Yao and Van Durme, 2014)</ref>, where language models are increasingly involved. Semantic parsing methods <ref type="bibr" target="#b39">(Yu et al., 2023;</ref><ref type="bibr" target="#b5">Cao et al., 2022;</ref><ref type="bibr">Zhang et al., 2022b;</ref><ref type="bibr" target="#b0">Abdelaziz et al., 2021;</ref><ref type="bibr" target="#b18">Lai et al., 2016)</ref> leverage semantic parser to convert natural language queries into intermediate logic forms such as SPARQL (Prud'hommeaux, 2011) and program <ref type="bibr" target="#b21">(Liang et al., 2016)</ref>, which are executed on KBs to obtain the answers. However, the generated logic forms are usually non-executable, thus failing to arrive at the correct answer <ref type="bibr" target="#b30">(Sun et al., 2020)</ref>. Pangu <ref type="bibr" target="#b10">(Gu et al., 2022)</ref> trains a language model discriminator to evaluate probability of candidate plans.</p><p>Information extraction methods usually combines retrieval and reasoning <ref type="bibr">(Zhang et al., 2022a;</ref><ref type="bibr" target="#b28">Shi et al., 2021;</ref><ref type="bibr" target="#b29">Sun et al., 2019;</ref><ref type="bibr" target="#b14">Jiang et al., 2023;</ref><ref type="bibr" target="#b1">Baek et al., 2023)</ref>. These methods show effectiveness in handling single-hop retrieval. However, they encounter challenges with multi-hop retrieval concerning storage and computation costs, where the number of relations expands exponentially with each added hop.</p><p>KnowledGPT differs from KBQA methods in two aspects. First, many KBQA methods are designed for special queries about relational triples in KGs, while KnowledGPT augments LLMs to respond to various user queries with knowledge in various forms from KBs. Second, KBQA methods are typically trained on specific datasets and KGs, whereas KnowledGPT requires no training and can easily accommodate different LLMs and KBs.  </p><formula xml:id="formula_0">? ? ? ? ? ? ? ? ToolkenGPT ? ? ? ? ? ? ? ? Graph-Toolformer ? ? ? ? ? ? ? ? RET-LLM ? ? ? ? ? ? ? ? LangChain KG Memory ? ? ? ? ? ? ? ? Llama-Index KG Index ? ? ? ? ? ? ? ? KnowledGPT ? ? ? ? ? ? ? ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>In this section, we introduce KnowledGPT, a comprehensive framework to integrate LLMs with KBs.</p><p>We first provide the definition of two tasks of KnowledGPT, knowledge retrieval and knowledge storage (Sec 3.1). Then, we elaborate the details in the retrieval (Sec 3.2) and storage (Sec 3.3) process of KnowledGPT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>KnowledGPT supplements LLMs with external knowledge from various knowledge bases (KBs), including a personalized KB (PKB) as an writable symbolic memory. Given a user input in natural language, KnowledGPT undertakes two primary tasks, namely knowledge retrieval and knowledge storage. In the knowledge retrieval task, the model searches through provided KBs to retrieve relevant knowledge to answer the user query. In the knowledge storage task, the model extracts knowledge from the user input and inserts it into the PKB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Knowledge Retrieval</head><p>KnowledGPT follows a three-step process to answer user queries with knowledge from KBs, as shown in Fig 3 . First, it generates a piece of search code as a logical form for query-specific KB access. Then, the search code is executed to retrieve related knowledge. Finally, KnowledGPT reads the retrieved knowledge and answers the query. We utilize the program of thought (PoT) prompting approach <ref type="bibr" target="#b7">(Chen et al., 2022)</ref> , which adopts Python code as the search language generated by LLMs. In this paper, we use <ref type="bibr">GPT-4 (OpenAI, 2023)</ref> as the LLM. The code is encapsulated in a search function, as is shown in the yellow part of Fig 3 , which includes built-in Python functions and three custom KB functions designed to facilitate the interaction of LLMs with KBs:</p><p>1. get_entity_info, which accepts an entity as input and returns its encyclopedic description.</p><p>2. find_entity_or_value, which accepts a query consisting of an entity and a relation as input, and outputs a list of the corresponding entity or value.</p><p>3. find_relationship, which accepts two entities as input, and returns a list of their relationship.</p><p>Specially, each entity or relation is represented as a list of candidate aliases, rather than a single name, to effectively handle synonyms. Besides the outputs stated above, these KB functions also return a message which logs the function call and result. Then, the overall output of the search function is obtained by concatenating the messages from individual KB function calls. The prompt is shown in 7.</p><p>The search function is then executed to retrieve the expected knowledge from KBs. The code would be decorated before execution, e.g. with a try-except statement and KB-specific accessor object, as is elaborated in Sec 3.2.1. The search function is executed for each KB respectively in parallel, and their results are concatenated.</p><p>Finally, the retrieved knowledge is provided to LLMs, and LLMs are tasked with responding to the user's query, supported by the retrieved knowledge. The prompt is shown in Sec 7. LLMs will ignore the retrieved information and address the user query independently in scenarios where LLMs judge the question does not require external knowledge or the retrieved knowledge is not enough for the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Code Implementation</head><p>Next, we introduce the implementation of the KB functions to execute the generated code. We implement the functions at two levels: a unified level and a KB-specific level.</p><p>Functions at the unified level provide a unified interface for operations over different KBs. These include the three KB functions (get_entity_info, find_entity_or_value, find_relationship) generated  directly by LLMs, and an entity_linking function to align entity aliases generated by LLMs with entities in KBs.</p><p>Functions at the KB-specific level implement operations on each specific KB by calling corresponding APIs. Basically, we only need to implement three functions for each KB: _get_entity_info, _en-tity_linking, _get_entity_triples. We denote these functions with an underscore in front in this paper.</p><p>Prior to execution, we decorate the generated code. We wrap the code with a try-except statement, so that if the code breaks down in subsequent steps, the search function still returns valuable results from successful steps. Also, we pass the user query into the search function as a global variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Entity Linking</head><p>Entity linking, which aligns entity mentions in natural language with entities in a KB, is an indispensable step towards the integration of LLMs with KBs. It is essential because an entity can be referred to by various mentions (e.g. Donald Trump and President Trump), and a noun phrase can also refer to different entities (e.g. the fruit apple and to gather information about the candidates. Each piece of entity information will be truncated to a maximum length. Finally, we provide LLMs with the function input (including the query, aliases of entity and relation) and the candidate entities along with their information, and make LLMs determine the most appropriate entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Get Entity Information</head><p>The get_entity_info function retrieves information about a specific entity. It first employs the entity_linking function to link entity aliases to an entity in the KB. Subsequently, it invokes the KB-specific _get_entity_info function, which returns information of the given entity in KB, including its entity description and triple information. The _get_en-tity_triples function is called to collect its triples. The KB-specific _get_entity_info function is nested in the entity_linking function, which makes it an integral part of all KB functions at the unified level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Find Entity or Value</head><p>Given a query composed of an entity and a relation, the find_entity_or_value function is designed to retrieve the corresponding entity or attribute value. This function undergoes several steps, as is presented in Algorithm 1. Still, it starts by invoking the entity_linking function to associate entity aliases with a corresponding entity in the KB. Then, it calls the internal _find_entity_or_value function, which includes a KB-specific _get_entity_triples functions that retrieve all triples related to the entity. Subsequently, the relations in these triples are sorted based on their similarity with the input relation aliases. Here we employ cosine similarity of sentence embeddings, rather than symbolic metrics, which considers synonyms of relations. Afterwards, we select the relation with highest similarity score, and return entities or attribute values from all corresponding triples. To improve the robustness of our method, we will conduct a further search within the entity description for the relation if no triples are found. If the relation is present in the description, we return the corresponding sentence. Otherwise, we return the whole description, which may still offer relevant details for LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Find Relationship</head><p>Given a query composed of two entities, the find_relationship function is designed to retrieve their relationship. This functions is similar to find_en-tity_or_value. The difference is that, upon retrieving triples or entity information for the first entity, the find_relationship function proceeds to search for the second entity, instead of the relation. If this initial search fails, the function swaps the first entity and second entity and searches again. Different from relation similarity, we measure entity similar-ity by Levenshitein distance d. The entity similarity is calculated as 100 -d if two entity names have word overlap, and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Knowledge Storage</head><p>While public KBs provide abundant world knowledge, they are still unable to cover all knowledge that users are interested in. To meet users' personal knowledge demands, KnowledGPT introduces a personalized KB (PKB) that acts as LLMs' symbolic memory, granting users the capability to store and access specialized knowledge. The PKB is populated by knowledge extracted from user-provided documents. When users intend to add knowledge into the PKB we prompt LLMs to extract knowledge from their provided documents, with the prompt shown in Sec A.</p><p>We consider knowledge represented in three forms, including entity description, relational triples, and entity-aspect information, as is shown in Fig 2, which is different from RET-LLM <ref type="bibr">(Modarressi et al., 2023)</ref> or the KG-Index of LangChain <ref type="bibr" target="#b6">(Chase, 2022)</ref> and Llama Index <ref type="bibr" target="#b22">(Liu, 2022)</ref> that extract only triples, While entity description and relational triples have been widely adopted in knowledge bases like Wikipedia and Wikidata, they only represents a limited portion of knowledge, as is shown by experiments in Sec 4.4. For example, when we want to know the experience of Socrates as a soldier, most content in Socrates' wikipedia page would be hardly helpful, and it can also hardly be represented as a triple. Therefore, we propose an additional knowledge representation, termed as entity-aspect information, for symbolic memory of LLMs. It is a variation of triple where the object is a long piece of text which describes and can be retrieved by an entity and an aspect, For instance, a record might be indexed by ("Socrates", "Military Service") and correspond to the description "Socrates served as a Greek hoplite or heavy infantryman...". Knowledge represented in this form will also be retrieved also by the get_entity_-or_value function.</p><p>Given the tiny scale of PKBs in comparison to public KBs, we consider a different strategy for entity linking on PKBs. The difference is mainly three-fold. First, we define the entity searching API for PKB based on exact match and embedding similarity. Embedding similarity aids in recognizing widely-known entity aliases, such as Chanelle Scott Calica and Shystie. Second, during extraction, an extracted entity mention is not aligned to entities existing in the PKB. Therefore, an entity may be extracted as distinct mentions in different documents. Hence, for entity linking, KnowledGPT returns multiple matched entities. Third, an entity would be extracted with an aliases list, which would be provided to LLMs for entity linking.</p><p>For the get_entity_or_value function, since a relation can also be extracted as different expressions, we opt to retrieve relations with similarity score over a threshold, instead of a top-scored relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we experiment KnowledGPT on various settings, including manually crafted diverse queries on popular KBs (Sec 4.2), knowledgebased question answering (Sec 4.3), and personalize KBs as memory for LLMs (Sec 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setups</head><p>Knowledge Bases. KnowledGPT can access various KBs with its unified interface for KB operation. In this paper, we primarily consider the following KBs:</p><p>1. Wikipedia In practical scenarios, we initiate the process by determining the language of the user query. For English queries, Wikipedia and Wikidata, as well as the personalized KB are employed. For Chinese queries, we utilize CN-DBPedia in conjunction with the personalized KB. Our methods can also be easily extended to more languages with KBs in corresponding languages.</p><p>Language Models. In this paper, we employ the powerful LLM GPT-4 by default, which is accessed by the OpenAI API<ref type="foot" target="#foot_4">5</ref> . We prompt LLMs with instructions, requirements, and in-context examples, and require LLMs to output in json format. The detailed prompts are shown in Sec A. For sentence embeddings, we employ GPT text-embedding-ada-002 model from OpenAI.  For code generation, it is considered successful if the code is supposed to be able to retrieve all the necessary knowledge related.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Queries on Popular KBs</head><p>To evaluate KnowledGPT in terms of diversified queries of real users requiring external knowledge, we craft 11 questions about knowledge from CN-DBPedia<ref type="foot" target="#foot_5">6</ref> . These questions span a variety of types, including single-hop and multi-hop relational queries, relation prediction, diversified instructions, mixed queries, and value comparison. These questions concern both popular entities and long-tail entities. The detailed examples are shown in Sec B. We experiment on KnowledGPT with GPT-4 and ChatGPT as the base LLMs, and measure the rate of successful generation in terms of direct answers without KBs, code generation, entity linking, and KnowledGPT answers.</p><p>The results are shown in Table <ref type="table" target="#tab_4">2</ref>. For detailed generations, please refer to Sec B. We observe that:</p><p>(1) GPT-4 and ChatGPT themselves are proficient at addressing queries about well-known entities, but they also hallucinate frequently about the unpopular entities. (2) KnowledGPT with GPT-4 excellently accomplish tasks like code generation and entity linking, and eventually answers user queries with correct knowledge, representing a marked improvement over the vanilla responses from GPT-4.</p><p>(3) However, for ChatGPT, the success rate of intermediate steps remains to be improved, which constrains the overall efficacy of KnowledGPT. In the code generation step, ChatGPT sometimes generates poor relation aliases, such as who is the father, especially for diverse or intricate queries. This comparison suggests that GPT-4 significantly outperforms ChatGPT in aspects like complex instruction understanding, task decomposition and code generation. While we also experimented with smaller open-source LLMs like Llama-2-Chat-13B, they struggle to provide accurate answers directly and also fail to generate well-formatted code and respond in the JSON format as is required by the KnowledGPT framework.</p><p>Case Studies. Fig 3 illustrates a complete process of employing KnowledGPT to answer the question "What are the titles of the poet who wrote Quiet Night Thoughts (Jing Ye Si) ?", which requires multi-hop knowledge retrieval and reasoning. The original answer from GPT-4 contains untruthful information, which shows the need to augment LLMs with precise external knowledge. Knowl-edGPT generates an excellent piece of code, which first looks for the author of the poem Quiet Night Thoughts, and then searches for the author's titles. This demonstrates the effectiveness of solving multi-hop knowledge retrieval with code. Upon execution, the code efficiently retrieves relevant information. Finally, KnowledGPT integrates the retrieved knowledge to answer the query correctly. Despite potential noise in the intermediate steps, KnowledGPT well filters the noise and answers properly. The examples clearly indicate that the original candidate entities, returned from the entity linking and searching api of external KBs, are not well-ordered and might not even include the correct entity. Hence, simply selecting the top entity could introduce severe noise. We apply GPT-4 to select from the candidate entities provided with their information. The results indicate that GPT-4 proficiently identifies the correct entity for the query, and is also capable of rejecting all options when none is fit. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Knowledge-Based Question Answering</head><p>We evaluate KnowledGPT on zero-shot knowledge-based question answering (KBQA). KBQA is an extensively researched domain that seeks to answer natural language questions specific to certain relational triples in KBs. For example, to answer the question "Who is the author of the Republic", a KBQA model is expected to retrieve the triple (the Republic, written by, Plato) and answer Plato.</p><p>Given the expenses of invoking OpenAI APIs, we have compiled two compact datasets, namely NLPCC-100 for single-hop queries and NLPCC-MH-59 for multi-hop queries. NLPCC-100 is com-posed of 100 samples from the test set of NLPCC 2016 KBQA dataset <ref type="bibr" target="#b9">(Duan, 2016)</ref>, while NLPCC-MH-59 consists of 59 samples from the test set of NLPCC-MH <ref type="bibr" target="#b35">(Wang and Zhang, 2019)</ref>, a multi-hop KBQA dataset. NLPCC-MH is automatically constructed by expanding the NLPCC 2016 dataset, which leads to certain inherent noise. From the NLPCC-MH dataset, we manually select 59 samples, ensuring their quality and the presence of supporting fact chains in the KB. Furthermore, we rectify any noise present in these samples. For both NLPCC-100 and NLPCC-MH-59, we use exclusively the full NLPCC 2016 KBQA Knowledge Base in this experiment.</p><p>We make several modification to KnowledGPT towards this dataset and KB. First, in the provided KB, the tail entities of triples may contain multiple entities separated by special symbols, so we adjust the prompt for search code generation to request LLMs to include a splitting mechanism in the generated code. Second, for better entity linking, as the provided KB does not contain entity description, we modify the implementation of _get_entity_information to return 10 triples related to the entity, sorted by the jaccard similarity between the query relation and the relation in triples. Third, we also modify the entity linking prompt, requiring LLMs to also adjust the query relation alias to better align with relations in the KB.</p><p>We compare KnowledGPT with the following baseline methods :</p><p>1. Retrieval via embedding similarity. Each triple is treated as a document and embedded using the CoSENT model <ref type="bibr" target="#b23">(Ming, 2022)</ref>. A single document is retrieved based on embedding similarity for each search. For multi-hop questions, the result from the first retrieval is added to the query to facilitate the second retrieval.</p><p>2. Retrieval via BM25 <ref type="bibr" target="#b26">(Robertson et al., 1995)</ref>.</p><p>For each entity, we group all its triples as a document. The most relevant document is retrieved using the BM25 algorithm for each search query, with stop words removed. We regard it as successful if the retrieved document contains the corresponding triple. For multihop queries, we pick a triple from the initial retrieval's document based on the jaccard similarity between relations, and integrate this triple into the subsequent retrieval's query.</p><p>3. SPE <ref type="bibr" target="#b18">(Lai et al., 2016)</ref>. SPE extracts subjectpredicate pairs from simple questions using embedding similarity. It obtaied the first place in the contest of NLPCC 2016 KBQA task.</p><p>We report averaged F1 on NLPCC-100 and NLPCC-MH-59. Averaged F1 is a widely adopted metric for KBQA, designed for tasks with multiple golden answers and predictions. However, since in our dataset there is only one answer and one prediction for each sample, so the averaged F1 actually is equivalent to accuracy.</p><p>The results are shown in Table <ref type="table" target="#tab_6">3</ref>, from which we have the following observation: (1) For single-hop queries, KnowledGPT significantly outperforms retrieval methods via BM25 and embedding similarity, which shows the effectiveness of retrieval from symbolic KBs compared with document corpus, for questions related to knowledge in KBs. (2) Zeroshot KnowledGPT outperforms the SPE method trained on the full training set of NLPCC-2016 KBQA dataset (0.92 vs 0.85), which shows the strong zero-shot performance of KnowledGPT. (3) For multi-hop queries, KnowledGPT also achieves excellent performance, while the performance of retrieval methods based on BM25 and embedding similarity drops significantly.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">KB as Memory</head><p>We conduct experiments to study the effectiveness of KnowledGPT when paired with a modifiable personalized KB. KnowledGPT is tasked with building the PKB by extracting knowledge from provided documents, and study whether KnowledGPT answer corresponding questions properly with the PKB. Fig <ref type="figure" target="#fig_10">6</ref> shows an example where text about Socrates is provided. KnowledGPT extracts knowledge from the text, and answers related questions by retrieving the extracted knowledge. We further apply KnowledGPT to Hot-potQA <ref type="bibr" target="#b37">(Yang et al., 2018)</ref>, a multi-hop question answering dataset with provided documents. We select 25 questions from HotpotQA dev set (distractor), including 5 comparison questions like "Which is a shrub, Mimosa or Cryptocoryne?" and 20 bridge questions like "When was Erik Watts' father Input Text: Socrates (470-399 BC) was a Greek philosopher from Athens who is credited as the founder of Western philosophy and among the first moral philosophers of the ethical tradition of thought. An enigmatic figure, Socrates authored no texts and is known mainly through the posthumous accounts of classical writers, particularly his students Plato and Xenophon...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query: Why was Socrates accused ?</head><p>Answer with Retrieved Knowledge: Socrates was accused of impiety and corrupting the youth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieved Knowledge from KBs: [FROM Memory][find_entity_or_value(entity_aliases = ['Socrates'],</head><p>relation_aliases = ['accused for', 'charged with', 'accusation']) -&gt; ] Socrates, accused of: impiety and corrupting the youth Extracted Knowledge: Entity Description: { "Socrates": "Socrates (c. 470-399 BC) was a Greek philosopher from Athens who is credited as the founder of Western philosophy and among the first moral philosophers of the ethical tradition of thought ?" } Relation Triples: { "Socrates": [ ("Socrates", "was a", "Greek philosopher"), ("Socrates", "credited as", "founder of Western philosophy"), ("Socrates", "accused of", "impiety and corrupting the youth"), ("Socrates", "known for", "proclaiming his total ignorance") ? ]} Entity Aspect Information: { "Socrates": [ ("Socrates", "philosophy", "?Socrates is known for proclaiming his total ignorance; he used to say that the only thing he was aware of was his ignorance?"), ("Socrates", "trial and death", "In 399 BC, he was accused of impiety and corrupting the youth. After a trial that lasted a day, he was sentenced to death. He spent his last day in prison, refusing offers to help him escape. "), ("Socrates", "influence", "Socrates exerted a strong influence on philosophers in later antiquity and has continued to do so in the modern era? "), ? ]} born?". Each question is paired with 10 documents, and KnowledGPT extracts knowledge from these documents to build the PKB.</p><p>The results are shown in Table <ref type="table" target="#tab_7">4</ref>. KnowledGPT successfully answer all comparison questions, and 15 out of 20 bridge questions. Among the failed cases, two bridge questions failed to extract the knowledge needed to answer the question and one bridge question failed in the entity linking stage. Overall, this experiment suggests the promising future of utilizing PKBs as symbolic memory of LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison Bridge</head><p>All KnowledGPT 5/5 15/20 20/25 We further investigate the knowledge extraction coverage of KnowledGPT on 100 documents from HotpotQA <ref type="bibr" target="#b37">(Yang et al., 2018)</ref>, considering various LLMs and diverse combination of applied knowledge representations. To quantify the coverage, we employ the word recall rate, calculated as</p><formula xml:id="formula_1">|W extracted ? W doc | |W doc | ,<label>(1)</label></formula><p>where | ? | indicates the cardinality of a set. W extracted and W doc denote the set of words in the extracted knowledge and the document respectively, after preprocessing including the removal of stop words and lemmatization, utilizing the NLTK toolkit <ref type="bibr" target="#b3">(Bird and Klein, 2009)</ref>.</p><p>The results are shown in Table <ref type="table">5</ref>, from which we have the following observations: (1) When restricting knowledge representation solely to triples, the extraction coverage stands at 0.53, which indicates that only a limited portion of knowledge can be represented as triples. Therefore, a PKB supporting triples alone falls short of adequately encompassing the knowledge provided by real users.</p><p>(2) With additional knowledge representations, i.e., entity description and entity-aspect information, we observe a marked improvement in knowledge extraction coverage, suggesting that incorporating entity description and entity-aspect information enables KnowledGPT to populate the PKB with a broader spectrum of knowledge. (3) ChatGPT and GPT-4 achieve similar proficiency for knowledge extraction. GPT-4 outperforms ChatGPT only when entity-aspect info is included, which probably is attributed to GPT-4's enhanced capability at following complex instructions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Limitations</head><p>While KnowledGPT enables LLMs to effectively perform KB operations on external knowledge bases, there remain several limitations in its current form. First, the retrieval process entails a singleround of code generation and execution for efficiency concerns. However, a multi-round mecha-nism may better allow LLMs to autonomously explore KBs. As LLMs are not aware of the contents within KBs, they might generate search that appear logical but yield no results. For example, a query like "Who is the voice actor for the heroine in ..." may require a two-hop searching for the relations heroine and voice actor subsequently in certain KBs, or just a single relation main voice actor in others. In these scenarios, a multi-round mechanism empowers LLMs to probe and revisit the KBs autonomously, which might yield better results but with increased costs. Second, we experiment with KnowledGPT on representative yet small datasets, constrained by the expenses of accessing GPT-4 via API. While the results validate the effectiveness of KnowledGPT, more comprehensive evaluations on full benchmarks are expected to better compare KnowledGPT to related methods. We plan to study fine-tuning LLMs like Llama for KnowledGPT in our future work to improve the efficiency and conduct more thorough experiments. Finally, it remains a practical issue when LLMs need to access external KGs, rather than solving problems independently. In this work, we simply let LLMs make this decision, while better approaches remain to be explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduce KnowledGPT, a comprehensive framework to integrate LLMs with external knowledge bases, facilitating LLMs' retrieval and storage on KBs. For retrieval, KnowledGPT adopts "program of thought" prompting, which retrieves knowledge via code generation and execution. For storage, KnowledGPT extracts various forms of knowledge from user provided texts, and populate the personalized KB with the extracted knowledge. KnowledGPT tackles several challenges inherent in integrating LLMs with KBs, including complex question answering, ambiguation in entity linking, and limited forms of knowledge representations. We show with extensive experiments that Knowl-edGPT effectively provides LLMs with the capability to operate on external KBs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Prompts</head><p>The prompts are shown in We request LLMs to output in JSON format, and in the same language as the query. The prompts emphasize the LLMs should finish special tasks, instead of directly answering the input questions. They are mostly written in English, with some in-context examples in Chinese to better support queries in Chinese. To ease understanding, these examples are translated into English in these figures.</p><p>Prompt for search code generation first asks LLMs to judge whether the query need knowledge from external KBs. If so, it continues to generate the search code. It pre-defines three functions that LLMs can generate to access KBs. It asks LLMs to generate a list of entity aliases or relation synonyms as input to these functions.</p><p>Prompt for entity linking directs LLMs to select from multiple candidate entities for the input query and target entity, provided with information of the candidate entities. While LLMs have the option to output [NONE] if none seems related, they are advised to use this option cautiously.</p><p>Prompt for question answering first guides LLMs to assess if the provided knowledge adequately supports answering this question. If so, it asks LLMs to answer the query with the retrieved knowledge. Otherwise, we let LLMs answer this question independently.</p><p>Prompt for knowledge extraction prompts LLMs to extract knowledge from the provided text. For long texts, LLMs tend to overlook many pieces of information during the extraction proceess. We find that emphasizing "Do not miss any knowledge points." largely improves the knowledge extraction coverage. Additionally, the prompt encourages LLMs to present knowledge in the form of relational triples and entity-aspect information when possible, instead of entity description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Detailed Results of Queries on Popular KBs</head><p>In this section, we elaborate the detailed results of the manualy crafted examples mentioned in Sec 4.2. The examples are mainly in Chinese, including their queries, retrieval results, and answers. We translate them into English to ease understanding. We color incorrectly generated content that in red, including false facts or illogical code. We also color unhelpful answers in brown, where GPT-4 and ChatGPT admit their ignorance. In the two cases about value comparison, GPT-4 attempts to conduct value comparison in the code, which seems logical. However, it actually performs string comparison, which makes the results unreliable without improved value comparing functions that can take into account units and unit conversion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt for Search Code Generation:</head><p>You are an awesome knowledge graph accessing agent that helps to RETRIEVE related knowledge about user queries via writing python codes to access external knowledge sources. Your python codes should implement a search function using exclusively built-in python functions and the provided functions listed below. ===PROVIDED FUNCTIONS=== 1. get_entity_info: obtain encyclopedic information about an entity from external sources, which is used to answer general queries like "Who is Steve Jobs". Args: "entity_aliases": a list of the entity's aliases, e.g. ['American', 'United States', 'U.S.'] for the entity 'American'. Return: two strings, 'result' and 'message'. 'result' is the encyclopedic information about the entity if retrieved, None otherwise. 'message' states this function call and its result. 2. find_entity_or_value: access knowledge graphs to answer factual queries like "Who is the founder of Microsoft?". Args: "entity_aliases": a list of the entity's aliases, "relation_aliases": a list of the relation's aliases. Return: two variables, 'result' and 'message'. 'result' is a list of entity names or attribute value to this query if retrieved, None otherwise. 'message' is a string states this function call and its result.</p><p>3. find_relationship: access knowledge graphs to predict the relationship between two entities, where the input query is like "What's the relationship between Steve Jobs and Apple Inc?". Args: "entity1_aliases": a list of entity1's aliases, "entity2_aliases": a list of entity2's aliases. Return: two strings, 'result' and 'message'. 'result' is the relationship between entity1 and entity2 if retrieved, None otherwise. 'message' states this function call and its result. ===REQUIREMENTS=== 1.</p><p>[IMPORTANT] Always remember that your task is to retrieve related knowledge instead of answering the queries directly. Never try to directly answer user input in any form. Do not include your answer in your generated 'thought' and 'code'.</p><p>2. Exclusively use built-in python functions and the provided functions. 3. To better retrieve the intended knowledge, you should make necessary paraphrase and list several candidate aliases for entities and relations when calling the provided functions, sorted by the frequency of the alias. E.g., "Where is Donald Trump born" should be paraphrased as find_entity_or_value(["Donald Trump", "President Trump"], ["place of birth", "is born in"]). Avoid entity alias that may refer to other entities, such as 'Trump' for 'Donald Trump'. 4. When using find_entity_or_value, make sure the relation is a clear relation. Avoid vague and broad relation aliases like "information". Otherwise, use get_entity_info instead. For example, for the question 'Who is related to the Battle of Waterloo?', you should use get_entity_info(entity_aliases = ['the Battle of Waterloo']) instead of find_entity_or_value(entity_aliases = ['the Battle of Waterloo'], relation_aliases = ['related to']) since 'related to' is too vague to be searched. 5. The input can be in both English and Chinese. If the input language is NOT English, make sure the args of get_entity_info, find_entity_or_value and find_relationship is in the input language. 6. The queries may need multiple or nested searching. Use smart python codes to deal with them. Note that find_entity_or_value will return a list of results. 7. Think step by step. Firstly, you should determine whether the user input is a query that "need knowledge". If no, simply generate "no" and stop. Otherwise, generate "yes", and go through the following steps: First, Come up with a "thought" about how to find the knowledge related to the query step by step. Make sure your "thought" covers all the entities mentioned in the input. Then, implement your "thought" into "code", which is a python function with return. After that, make an "introspection" whether your "code" is problematic, including whether it can solve the query, can be executed, and whether it contradicts the requirements (especially whether it sticks to the RETRIEVE task or mistakenly tries to answer the question). Make sure "thought" and "introspection" are also in the same language as the query. Finally, set "ok" as "yes" if no problem exists, and "no" if your "introspection" shows there is any problem. 8. For every call of get_entity_info, find_entity_or_value and find_relationship, the return 'message' are recorded into a string named 'messages', which is the return value of search(). 9. Add necessary explanation to the 'messages' variable after running certain built-in python codes, such as, messages += f'{top_teacher} is the teacher with most citations'. 10. When the user query contains constraints like "first", "highest" or mathmatical operations like "average", "sum", handle them with built-in functions. 11. Response in json format. ===OUTPUT FORMAT=== { "need_knowledge": "&lt;yes or no. If no, stop generating the following.&gt;" "thought": "&lt;Your thought here. Think how to find the answer to the query step by step. List possible aliases of entities and relations.&gt;", "code": "def search():\\n\\tmessages = ''\\n\\t&lt;Your code here. Implement your thought.&gt;\\n\\treturn messages\\n", "introspection": "&lt;Your introspection here.&gt;", "ok": "&lt;yes or no&gt;" } ===EXAMPLES=== 1. Input: "Who are you?" Output: { "need_knowledge": "no" } 2. Input: "Who proposed the theory of evolution?" Output: { "need_knowledge": "yes", "thought": "The question is asking who proposed the theory of evolution. I need to search for the proponent of the theory of evolution. The possible expressions for the 'proponent' relationship include 'proposed', 'proponent', and 'discovered'.", "code": "def search():\\n\\tmessages = ''\\n\\tproposer, msg = find_entity_or_value(entity_aliases = ['theory of evolution'], relation_aliases = ['propose', 'proponent', 'discover'])\\n\\tmessages += msg\\n\\treturn messages\\n", "introspection": "The generated code meets the requirements.", "ok": "yes" } 3. Input: "what is one of the stars of 'The Newcomers' known for?" Output:{ "need_knowledge": "yes", "thought": "To answer this question, firstly we need to find the stars of 'The Newcomers'. The relation can be paraphrased as 'star in', 'act in' or 'cast in'. Then, we should select one of them. Finally, we should retrieve its encyclopedic information to know what he or she is known for. We should not treat 'known for' as a relation because its too vague.", "code": "def search():\\n\\tmessages = ''\\n\\tstars, msg = find_entity_or_value(entity_aliases = ['The Newcomers'], relation_aliases = ['star in', 'act in', 'cast in'])\\n\\tmessages += msg\\n\\tstar = random.choice(stars)\\n\\tstar_info, msg = get_entity_info(entity_aliases = [star])\\n\\tmessages += msg\\n\\treturn messages\\n" "introspection": "The generated code is executable and matches user input. It adheres to the requirements. It finishes the retrieve task instead of answering the question directly.", "ok": "yes" } Prompt for Entity Linking: You are an awesome knowledge graph accessing agent. There are many entities with similar names that exist in knowledge graphs which cause ambiguity, such as the fruit 'apple' and the company 'Apple'. Given the user input, and the interested entity mention in it, you are provided with some candidate entities and their information. Now, your task is to consider carefully which of the candidate entities matches the entity mention in user input. ===NOTICE=== 1. The user input and entity information can be in English or Chinese. 2. If all the candidate entities are irrelavant to the input entity mention, reply <ref type="bibr">[None]</ref>. However, you should not reply <ref type="bibr">[None]</ref> simply because the provided entity information do not directly answer the question. If the entity mention clearly matches a candidate entity, you should definitely return it. 3. If multiple candidates are possible, just choose one that you think is most possible. 4. When the user input is an assumption or question, do not think entities are irrelavant to the input simply because their information cannot cover the assumption or question. Use your imagination how the assumption or question can be related with the candidate entities. 5. [IMPORTANT] Always remember that your task is to select the correct entity instead of answering the questions. Never try to directly answer user input in any form.  Prompt for Question Answering: You are an helpful and knowledgable AI assistant. The user has issued a query, and you are provided with some related knowledge. Now, you need to think step by step to answer the user input with the related knowledge. ===REQUIREMENTS=== 1. You should think step by step. First, think carefully whether you can answer this query without the provided knowledge. Second, consider how to use the related knowledge to answer the query. Then, tell me whether this query can be answered with your own knowledge and the provided knowledge. If so, answer this question. However, if the query involves a command or an assumption, you should always regard it as answerable. 2. When you are thinking, you can use and cite the provided knowledge. However, when you are generating the answer, you should pretend that you came up with the knowledge yourself, so you should not say things like "according to the provided knowledge from ..." in the "answer" part. 3. The user query and provided knowledge can be in both Chinese and English. your "thought" and "answer" in the same language as the input. 4. Response in json format, use double quotes. ===INPUT FORMAT=== { "query": "&lt;the user query that you need to answer&gt;", "knowledge": "&lt;the background knowledge that you are provided with&gt;" } ===OUTPUT FORMAT=== { "thought": "&lt;Your thought here. Think step by step as is required.&gt;", "answerable": "&lt;yes or no. Whether you can answer this question with your knowledge and the provided knowledge. If the query involves a command or an assumption, say 'yes'.&gt;", "answer": "&lt;Your answer here, if the query is answerable.&gt;" } ===EXAMPLES=== Input:{ "query": "What is the motto of the school where Xia Mingyou graduated?", "knowledge": "[FROM CNDBPedia][find_entity_or_value(entity_aliases = ['Xia Mingyou'], relation_aliases = ['graduated from', 'school']) -&gt; ] Xia Mingyou, school: Fudan University[find_entity_or_value(entity_aliases = ['Fudan University'], relation_aliases = ['motto']) -&gt; ] Fudan University, motto: Rich in Knowledge and Tenacious of Purpose; Inquiring with Earnestness and Reflecting with Self-practice" } Output:{ "thought": "Based on the background knowledge from CNDBPedia, Xia Mingyou graduated from Fudan University, and the motto of Fudan University is ' Rich in Knowledge and Tenacious of Purpose; Inquiring with Earnestness and Reflecting with Self-practice '. So the answer is ' Rich in Knowledge and Tenacious of Purpose; Inquiring with Earnestness and Reflecting with Self-practice '. This question can be answered based on the provided knowledge.", "answerable": "yes", "answer": " Rich in Knowledge and Tenacious of Purpose; Inquiring with Earnestness and Reflecting with Self-practice " } 'What is Liang Jiaqing's weapon?' Input:{ "query": "What is Liang Jiaqing's weapon?", "knowledge": "[FROM CNDBPEDIA] Liang Jiaqing: Liang Jiaqing, also known as Lu Yuan. A member of the Chinese Communist Party, born after the 1960s, with a university education. Specially appointed writer for 'Chinese Writers' magazine and 'Chinese Reportage Literature' magazine. Attributes: Author -&gt; The Loyal Life of a Criminal Police Captain." } Output:{ "thought": "According to the knowledge provided by CNDBPedia, Liang Jiaqing is an author. The provided knowledge does not mention anything about Liang Jiaqing's weapon, and authors generally do not have weapons. The question cannot be answered based on the provided knowledge or my knowledge.", "answerable": "no" } </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt for Knowledge Extraction:</head><p>You are an awesome information extraction agent and your task is to extract important pieces of information (knowledge) in a structured form from unstructured text, which will be stored to build a knowledge base memory. You should extract the following three types of knowledge: 1. Entity description: Format: {"&lt;entity&gt;": "&lt;entity description in the encyclopedic style&gt;"} You should extract entity description, which is the most critical information about an entity, as concise as possible, and in the encyclopedic style. For example, { "Elon Reeve Musk": "Elon Reeve Musk (born June 28, 1971) is a business magnate and investor..."} 2. Relational triple: Format: ["&lt;subject&gt;", "&lt;predict&gt;", "&lt;object&gt;"] You should extract relational triples (a.k.a factual triples), a common type of knowledge widely used to build knowledge graphs. The &lt;subject&gt; must be an entity in natural language, e.g. "United States". The &lt;predict&gt; is an attribute or a relationship, e.g. "population" or "located in". Attributes mainly refer to the possible attributes, features, characteristics, and parameters of an entity. Relationships connect two entities and characterize their relationships. The &lt;object&gt; is an attribute value or another entity, such as "over 333 million" in ["United States", "population", "over 333 million"], or "North America" in ["United States", "located in", "North America"], respectively. 3. Entity-Aspect-Content: Format: ["&lt;entity&gt;", "&lt;aspect&gt;", "&lt;content&gt;", "&lt;question&gt;"] You should also extract textual information that describes an entity in a certain aspect. This differs from relational triple in that the &lt;content&gt; is a longer piece of text of an entity instead of a concise value or entity. It also differs from entity description in that the &lt;content&gt; describes an entity in a certain aspect. Besides, generate a &lt;question&gt; about the &lt;aspect&gt; of the &lt;entity&gt;. For example, you should extract ["Elon Reeve Musk", "biography", "Musk was born in Pretoria, South Africa, and briefly attended the University of Pretoria before moving to Canada at age 18, acquiring citizenship through his Canadian-born mother."] to describe "Elon Reeve Musk" in terms of his "biography". The generated question can be "What is Elon Reeve Musk's biography?". ===REQUIREMENTS=== 1.</p><p>[IMPORTANT] Always remember that your task is to extract information from a given corpus. Never try to answer a query or a command. More importantly, only extract information from the given text, and never generate things not mentioned in the text. 2. There can be overlapped information among the three types of extracted knowledge. The same piece of information can be appropriately organized into two or more formats. For example, the corpus "Elon Reeve Musk is born on June 28, 1971." can be organized into an entity encyclopedic description like {"Elon Reeve Musk": "Elon Reeve Musk is born on June 28, 1971."}, and meanwhile, the corpus can also be organized into a relational triple like ["Elon Reeve Musk", "born on", "June 28, 1971"]. 3. The extracted entity description should be the most critical information about the entity, in the encyclopedic style. 4. When extracting knowledge in the relational triple format of ["&lt;subject&gt;", "&lt;predict&gt;", "&lt;object&gt;"], make sure the &lt;predict&gt; is a clear attribute or relation. Avoid vague and broad predicts like "information", "related to". Instead, put the information into the entity description format if it's a piece of encyclopedia-like information about the entity, or put the information into the entity-aspect-content format if you can summarize a specific aspect for this piece of information. 5. The input can be in both English and Chinese. If most of the input is written in English, make sure the output is in English. If most of the input is written in Chinese, make sure the output is in Chinese. 7. Think step by step. Firstly, you need to understand what the given corpus is mainly about and then decide on the core entities you plan to extract from this corpus. Next, iterate through each core entity, coming up with a "thought" about how to extract information about this core entity and according to the generated "thought", extracting "entity_description", "relational_triple", "entity_aspect_content" for each entity in turn. Specifically, the "thought" field should give details on how to find all relevant information about the core entity from the corpus, and how to choose the appropriate formats to organize these pieces of information according to their characteristics. Make sure your "thought" covers all the relevant entities mentioned in the input. Make "thought" in the same language as the input corpus. 8. The entity names should be concise, yet accurately refer to the entity. 9. Extract as many relational triples as possible from input text. 10. Response in json format. ===OUTPUT FORMAT=== Format description: The output format is a nested json object. The top-level json object has two fields named "thought" and "knowledge" respectively. The content of the "thought" is a string; the content of the "knowledge" is another json object whose keys are core entities. Y o u can extract one or more core entities from the corpus, e.g. &lt;core entity 1&gt;, &lt;core entity 2&gt;, etc. The value of the &lt;core entity 1&gt; is another json object, whose keys are "entity_description", "relational_triple", "entity_aspect_content". The value of "entity_description" is a piece of encyclopedic text. The value of "relational_triple" is a list of relational triples whose &lt;subject&gt; or &lt;object&gt; is the &lt;core entity 1&gt;. The value of "entity_aspect_content" is a list of ["&lt;entity&gt;", "&lt;aspect&gt;", "&lt;content&gt;", "&lt;question&gt;"] quaternions whose &lt;entity&gt; is the &lt;core entity 1&gt;. Format: { "thought": "&lt;Your thought here. Determine the language of the input text and output in that language. Understand what the given corpus is mainly about and then decide on the core entities you plan to extract from this corpus. For each core entity, find all relevant information about the core entity and choose the appropriate formats to organize these pieces of information according to their characteristics.&gt;", "knowledge": { "&lt;core entity 1&gt;": { "entity_description": "&lt; entity description in the encyclopedic style&gt;", "relational_triple": [["&lt;core entity 1&gt;", "&lt;predict 1&gt;", "&lt;object 1&gt;"], ["&lt;subject 2&gt;", "&lt;predict 2&gt;", "&lt;core entity 1&gt;"], ?], "entity_aspect_content": [["&lt;core entity 1&gt;", "&lt;aspect 1&gt;", "&lt;long text 1&gt;", "&lt;question 1&gt;"], ["&lt;core entity 1&gt;", "&lt;aspect 2&gt;", "&lt;long text 2&gt;", "&lt;question 2&gt;"], ?]}, "&lt;core entity 2&gt;": { "entity_description": "&lt; entity description in the encyclopedic style&gt;", "relational_triple": [["&lt;core entity 2&gt;", "&lt;predict 1&gt;", "&lt;object 1&gt;"], ["&lt;subject 2&gt;", "&lt;predict 2&gt;", "&lt;core entity 2&gt;"], ?], "entity_aspect_content": [["&lt;core entity 2&gt;", "&lt;aspect 1&gt;", "&lt;long text 1&gt;", "&lt;question 1&gt;"], ["&lt;core entity 2&gt;", "&lt;aspect 2&gt;", "&lt;long text 2&gt;", "&lt;question 2&gt;"], ?]}, }} ===EXAMPLES=== 1. Input: "The Orenda OE600 is a 600 hp-class liquid-cooled 8-cylinder V-block ?." Output: { "thought": "The text is written in English, so I output it in English. The text is about the Orenda OE600, an aircraft engine designed by ?", "knowledge": { "Orenda OE600": { "entity_description": "The Orenda OE600 is a 600 hp-class liquid-cooled 8-cylinder V-block aircraft engine intended to re-introduce ...", "relational_triple": [["Orenda OE600", "type", "600 hp-class liquid-cooled 8-cylinder V-block aircraft engine"], ["Orenda OE600", "intended for", "aircraft normally powered by the Pratt &amp; Whitney Canada PT6 turboprop"], ["Orenda OE600", "offers", "better fuel economy"]],</p><p>"entity_aspect_content": [["Orenda OE600", "design purpose", "The Orenda OE600 is intended to re-introduce piston power to aircraft normally powered by the famous Pratt &amp; Whitney Canada PT6 turboprop.", "What is the design purpose of Orenda OE600?"], ["Orenda OE600", "features", "The Orenda OE600 is a 600 hp-class liquid-cooled 8-cylinder V-block aircraft engine that offers much better fuel economy.", "What are the features of Orenda OE600?"] ? ]}, "Orenda Aerospace": {?} }} 2. ? </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Document</head><label></label><figDesc>Revolutionary Road is a 2008 romantic drama film directed by ? ? ??Only docs about Catch Me If You Can ??Only docs about Revolutionary Road KB Memory ??Related knowledge</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Comparison between retrieval results from document corpus and knowledge bases. In this case, no document retrieved from the corpus provides enough knowledge for the query, while from the knowledge base sufficient related knowledge can be retrieved.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison between KnowledGPT and previous methods towards several challenges in bridging LLMs with KBs. KnowledGPT handles complex questions through multi-hop searching and processing based on code, tackles entity ambiguation with LLM-based entity linking (middle), and provides extended forms of knowledge representations to encapsulate a broader range of knowledge from the provided text.</figDesc><graphic url="image-25.png" coords="3,219.53,171.65,149.55,65.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Query:</head><label></label><figDesc>What are the titles of the poet writing Quiet Night Thoughts (Jing Ye Si) ? Code for Knowledge Retrieval: def search(): messages = '' author, msg = find_entity_or_value(entity_aliases = ['Quiet Night Thoughts '], relation_aliases = ['author', 'creator', 'writor']) messages += msg if author: titles, msg = find_entity_or_value(entity_aliases = author, relation_aliases = ['title', 'also known as', 'appellation']) messages += msg return messages Original Answer from GPT-4: The poet of Quiet Night Thoughts is Li Bai from the Tang Dynasty. He has multiple titles, including 'The Immortal Poet', 'The Wandering Poet', and 'The Wine Immortal'. His poetic talent was outstanding, his works are widely circulated, and he has been revered as 'the God in Poetry' by later generations. Answer with Retrieved Knowledge: The poet Li Bai, who wrote 'Quiet Night Thoughts', has the titles 'Blue Lotus Hermit' and 'Exiled Immortal'. Retrieved Knowledge from KBs: [FROM CNDBPedia] [find_entity_or_value(entity_aliases = ['Quiet Night Thoughts'], relation_aliases = ['author', 'creator', 'writer']) -&gt; ] 'Quiet Night Thoughts' (a poem by Li Bai), Author: Li Bai, The Orderer of Heaven's Mandate [find_entity_or_value(entity_aliases = ['Li Bai', 'The Orderer of Heaven's Mandate'], relation_aliases = ['title', also known as', 'appellation']) -&gt; ] Li Bai (famous Tang Dynasty poet), Title: Blue Lotus Hermit, Exiled Immortal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The detailed process of KnowledGPT's retrieval steps for the given example. It shows the generated code for retrieval, the retrieval results, and the knowledge-enhanced response for the query, along with the original answer from LLMs. Texts highlighted in red indicates inaccuracies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Query:Figure 4 :</head><label>4</label><figDesc>Figure 4: The detailed process of KnowledGPT's entity linking steps for the given example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Algorithm 1: find_entity_or_value Input: query q, alias list of entity E, alias list of relation R. Output: a list of target entities or attribute values T . 1 Function EMBSIM(str r, list[str] R): 12 r = N U LL 13 sr = -1 14 for triple ? triples do 15 ri = triple.rel 16 si = EMBSIM(ri, R) 17 if si &gt; sr then 18 sr = si 19 r = ri 20 if r == N U LL then 21 return N U LL 22 triplesr = triples with relation r 23 R = target entities or attribute values in triplesr 24 return R</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig 5</head><label>5</label><figDesc>Fig 5 illustrates three instances of the entity linking step in KnowledGPT.The examples clearly indicate that the original candidate entities, returned from the entity linking and searching api of external KBs, are not well-ordered and might not even include the correct entity. Hence, simply selecting the top entity could introduce severe noise. We apply GPT-4 to select from the candidate entities provided with their information. The results indicate that GPT-4 proficiently identifies the correct entity for the query, and is also capable of rejecting all options when none is fit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Query:Figure 5 :</head><label>5</label><figDesc>Figure 5: Case studies of KnowledGPT's entity linking process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: An example showing knowledge extraction and retrieval of KnowledGPT on the personalized KB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig 7 ,</head><label>7</label><figDesc>Fig 8, Fig 9, Fig 10. These prompts primarily consist of task introductions, requirements, the format of input and output, and in-context examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Prompt for search code generation. The second example is in Chinese and translated into English.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Prompt for entity linking. The second example is in Chinese and translated into English.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Prompt for question answering. The examples are in Chinese and translated into English.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Prompt for knowledge extraction. Certain contents about entity descriptions and in-context examples are omitted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>MethodEnt Desc Triples Ent Aspect Info Multi-Hop Search Zero-Shot Ent Linking External KBs Private KB Toolformer</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison between KnowledGPT and existing KB-augmented methods. Ent, Rel, and Desc are abbreviations for entity, relation and description, respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Number of successful answers on the selected samples. The results are evaluated by human annotators.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Averaged F1 of different methods on NLPCC-100 and NLPCC-MH-59.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note><p>Number of successful answers on 25 questions selected from HotPotQA. The results are evaluated by human annotators.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Always reply [ENT 1], [ENT 2] ... [ENT n] or [NONE]. 6. Try your best to ensure the entity you choose is equivalent to the input target entity. They should belong to the same type. For example, if the input target entity is William "William Shakespeare", you shouldn't choose "William Shakespeare's plays" as your answer, since the former is a person while the later are works. ===INPUT FORMAT=== You are provided with the [USER INPUT], the [TARGET ENTITY] of the target entity mention, and several candidate entities like [ENT 1], [ENT 2] ... [ENT n]. ===OUTPUT FORMAT=== In order to find the correct entity, you should think step by step, and output in json format. First, you should generate your 'thought' considering the user input, the target entity mention, and all the candidate entities. Do not directly answer user query in your thought. Then, output your 'choice', which is the entity that matches the entity mention like [ENT 1], [ENT 2] ... [ENT n], or[NONE]  if there is none. Liang Jiaqing: Liang Jiaqing, also known as Lu Yuan, is a member of the Chinese Communist Party. He was born after the 1960s and has a university education. He is a specially appointed writer for "Chinese Writers" magazine and "Chinese Reportage Literature" magazine. Attributes: Category -&gt; Cultural figure, Author -&gt; The Loyal Life of a Criminal Police Captain.[ENT 2]: Liang Jiaqing (Scholar at Fudan University): Liang Jiaqing graduated from the School of Computer Science at Fudan University and holds a Ph.D. degree. He is a well-known scholar in the field of knowledge graph and natural language processing. Attributes: Graduated from -&gt; Fudan University.</figDesc><table><row><cell>===EXAMPLES===</cell></row><row><cell>1.</cell></row><row><cell>Input:</cell></row><row><cell>[USER INPUT]: Which Nobel laureate in Literature is best known for 'Blowing in the Wind'?</cell></row><row><cell>[TARGET ENTITY]: Blowing in the Wind</cell></row><row><cell>[ENT 1]: Blowing in the Wind (Q4928603): album by Lou Donaldson.</cell></row><row><cell>[ENT 2]: Blowing in the Wind (Q15921392): television series.</cell></row><row><cell>[ENT 3]: Blowing in the wind (Q59044759): scientific article published in Nature.</cell></row><row><cell>Output:</cell></row><row><cell>{</cell></row><row><cell>"thought": "None of the album, tv series and scientific article seems related with Nobel Prize in Literature.",</cell></row><row><cell>"choice": "[None]"</cell></row><row><cell>}</cell></row><row><cell>2.</cell></row><row><cell>Input:</cell></row><row><cell>[USER INPUT]: Please introduce the academic achievements of Liang Jiaqing.</cell></row><row><cell>[TARGET ENTITY]: Liang Jiaqing</cell></row><row><cell>[ENT 1]: Output:</cell></row><row><cell>{</cell></row><row><cell>"thought": "The user wants to know about the academic achievements of Liang Jiaqing, so here Liang Jiaqing refers to a scholar, matching with [ENT</cell></row><row><cell>2].",</cell></row><row><cell>"choice": "[ENT 2]"</cell></row><row><cell>}</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://en.wikipedia.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://wikidata.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://zh.wikipedia.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://baike.baidu.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://platform.openai.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>As CN-DBPedia is a Chinese KB, the queries and generations are also in Chinese. We translate them into English to ease understanding.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>Hanks collaborated ? on five films: <rs type="person">? Catch Me If You Can</rs> (<rs type="grantNumber">2002</rs>), The Terminal (2004), Bridge of Spies (2015), and The Post (2017), as well as Later in 2008, DiCaprio collaborated with <rs type="person">Kate Winslet</rs> for the drama <rs type="person">Revolutionary Road</rs>, directed by her then-husband Sam Mendes. Extract triples: ('<rs type="institution">U.S. Bancorp', 'based in', 'Minnesota') 'U.S. Bancorp': 'U.S. Bancorp</rs>, a bank holding company based in Minneapolis, <rs type="institution">Minnesota ? ('U.S.Bancorp', 'scope of business'</rs>, 'The company provides banking, investment, mortgage, trust, and payment services products to individuals ? ')</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KWcXHpQ">
					<idno type="grant-number">2002</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A semantic parsing and reasoning-based approach to knowledge base question answering</title>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><surname>Ravishankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavan</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v35i18.17988</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="15985" to="15987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Knowledge-augmented language model prompting for zero-shot knowledge graph question answering</title>
		<author>
			<persName><forename type="first">Jinheon</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Saffari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.04136</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bird</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<title level="m">Natural language processing with python</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<idno>CoRR, abs/2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Program transfer for answering complex questions over knowledge bases</title>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jifan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghui</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Chase</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>LangChain</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks</title>
		<author>
			<persName><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.12588</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Vicuna: An opensource chatbot impressing gpt-4</title>
		<author>
			<persName><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>with 90%* chatgpt quality</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of the nlpcc-iccpol 2016 shared task: Open domain chinese question answering</title>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Understanding and Intelligent Applications</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="942" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Don&apos;t generate, discriminate: A proposal for grounding language models to real-world environments</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09736</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Retrieval augmented language model pre-training</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
	<note>Panupong Pasupat, and Mingwei Chang</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Shibo</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11554</idno>
		<title level="m">Toolkengpt: Augmenting frozen language models with massive tools via tool embeddings</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Chenxu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenzhuang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.03901</idno>
		<title level="m">Chatdb: Augmenting llms with databases as their symbolic memory</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Unikgqa: Unified retrieval and reasoning for solving multi-hop question answering over knowledge graph</title>
		<author>
			<persName><forename type="first">Jinhao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large language models struggle to learn long-tail knowledge</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Kandpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haikang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="15696" to="15707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Internet-augmented dialogue generation</title>
		<author>
			<persName><forename type="first">Mojtaba</forename><surname>Komeili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.579</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8460" to="8478" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Open domain question answering system based on knowledge base</title>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Understanding and Intelligent Applications: 5th CCF Conference on Natural Language Processing and Chinese Computing, NLPCC 2016, and 24th International Conference on Computer Processing of Oriental Languages, ICCPOL 2016, Kunming</title>
		<meeting><address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-12-02">2016. December 2-6, 2016</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="722" to="733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Internetaugmented language models through few-shot prompting for open-domain question answering</title>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Stokowiec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolai</forename><surname>Grigorev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.05115</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9459" to="9474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">D</forename><surname>Forbus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00020</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.1234</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>LlamaIndex</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Ming</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14322</idno>
		<title level="m">A tool for text to vector. Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, and Hinrich Sch?tze. 2023. Ret-llm: Towards a general read-write memory for large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<title level="m">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Eric Prud&apos;hommeaux</title>
	</analytic>
	<monogr>
		<title level="m">Sparql query language for rdf</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Okapi at trec-3</title>
		<author>
			<persName><forename type="first">S</forename><surname>Stephen Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Overview of the Third Text REtrieval Conference (TREC-3)</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Dess?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberta</forename><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Cancedda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Scialom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04761</idno>
		<title level="m">Toolformer: Language models can teach themselves to use tools</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Transfernet: An effective and transparent framework for multi-hop question answering over relation graph</title>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text</title>
		<author>
			<persName><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Sparqa: Skeleton-based semantic parsing for complex questions over knowledge bases</title>
		<author>
			<persName><forename type="first">Yawei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingling</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori B</forename><surname>Hashimoto</surname></persName>
		</author>
		<ptr target="https://crfm.stanford.edu/2023/03/13/alpaca.html" />
		<title level="m">Alpaca: A strong, replicable instruction-following model. Stanford Center for Research on Foundation Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timoth?e</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozi?re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelien</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<title level="m">Llama: Open and efficient foundation language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Open-ended medical visual question answering through prefix tuning of language models</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Tom Van Sonsbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivona</forename><surname>Mahdi Derakhshani</surname></persName>
		</author>
		<author>
			<persName><surname>Najdenkoska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Cees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><surname>Worring</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.05977</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Longyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbo</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhirui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02210</idno>
		<title level="m">Document-level machine translation with large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A dynamic programming-based approach to knowledge-basd question answering</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Zhengzhou University (Science Edition)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="37" to="42" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cndbpedia: A never-ending chinese knowledge extraction system</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqing</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanyun</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghua</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="428" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd annual meeting of the association for computational linguistics</title>
		<meeting>the 52nd annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="956" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Decaf: Joint decoding of answers and logical forms for question answering over knowledge bases</title>
		<author>
			<persName><forename type="first">Donghan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">Hanbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11116</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">2022a. Subgraph retrieval enhanced model for multi-hop knowledge base question answering</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaokang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jifan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.396</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of th Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of th Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers). Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">2022b. Crake: Causal-enhanced table-filler for question answering over large scale knowledge base</title>
		<author>
			<persName><forename type="first">Minhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanzeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zou</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esin</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori B</forename><surname>Hashimoto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13848</idno>
		<title level="m">Benchmarking large language models for news summarization</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
