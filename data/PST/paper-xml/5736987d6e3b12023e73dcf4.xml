<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast and General Distributed Transactions using RDMA and HTM</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yanzhe</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Scalable Computing and Systems Institute of Parallel and Distributed Systems</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xingda</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Scalable Computing and Systems Institute of Parallel and Distributed Systems</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Scalable Computing and Systems Institute of Parallel and Distributed Systems</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rong</forename><surname>Chen</surname></persName>
							<email>rongchen@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Scalable Computing and Systems Institute of Parallel and Distributed Systems</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haibo</forename><surname>Chen</surname></persName>
							<email>haibochen@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Key Laboratory of Scalable Computing and Systems Institute of Parallel and Distributed Systems</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fast and General Distributed Transactions using RDMA and HTM</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">40240C721A2218B55EC4F0AC334FBB69</idno>
					<idno type="DOI">10.1145/2901318.2901349</idno>
					<note type="submission">Silo [49, 60] DBX [52] Calvin [48] FaRM [16, 17] DrTM [54] DrTM+R Performance High High Low High Very High Very High Scale-out No No Yes Yes Yes Yes</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent transaction processing systems attempt to leverage advanced hardware features like RDMA and HTM to significantly boost performance, which, however, pose several limitations like requiring priori knowledge of read/write sets of transactions and providing no availability support. In this paper, we present DrTM+R, a fast in-memory transaction processing system that retains the performance benefit from advanced hardware features, while supporting general transactional workloads and high availability through replication. DrTM+R addresses the generality issue by designing a hybrid OCC and locking scheme, which leverages the strong atomicity of HTM and the strong consistency of RDMA to preserve strict serializability with high performance. To resolve the race condition between the immediate visibility of records updated by HTM transactions and the unready replication of such records, DrTM+R leverages an optimistic replication scheme that uses seqlock-like versioning to distinguish the visibility of tuples and the readiness of record replication. Evaluation using typical OLTP workloads like TPC-C and SmallBank shows that DrTM+R scales well on a 6-node cluster and achieves over 5.69 and 94 million transactions per second without replication for TPC-C and Small-Bank respectively. Enabling 3-way replication on DrTM+R only incurs at most 41% overhead before reaching network bottleneck, and is still an order-of-magnitude faster than a state-of-the-art distributed transaction system (Calvin).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Transaction <ref type="bibr" target="#b17">[18]</ref> is a very powerful abstraction that simplifies the processing of relational data. With the increase of data volume and concurrency level, many systems like Web Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org or Publications Dept., ACM, Inc., fax +1 (212) 869-0481.</p><p>EuroSys <ref type="bibr">'16, April 18-21, 2016</ref>, London, United Kingdom Copyright c 2016 ACM 978-1-4503-4240-7/16/04. . . $15.00 DOI: http://dx.doi.org/10.1145/2901318.2901349 service, stock exchange, and e-commerce demand the support of low-latency and high-throughput transaction processing systems. However, traditional systems are usually with low efficiency such that only a small portion of the wallclock time is spent on useful data processing <ref type="bibr" target="#b43">[44]</ref>.</p><p>Recent advanced hardware features like large (nonvolatile) memory, hardware transactional memory (HTM) and fast interconnect with RDMA pose new opportunities for fast transaction processing: large memory volume enables a new paradigm of in-memory transactions, which significantly reduces buffering and I/O overhead; the hardware support for atomicity, consistency, and isolation (ACI) properties makes it very promising to offload concurrency control to CPU <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b51">52]</ref>; and the RDMA feature further enables fast distributed transactions within a local cluster <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b53">54]</ref>. However, while prior systems have demonstrated the feasibility of combining such advanced hardware features for fast distributed transactions, they fall short in several aspects. They either leverage only parts of the features <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b51">52]</ref>, or place several restrictions on transaction such as knowing read/write sets in advance and providing no availability support <ref type="bibr" target="#b53">[54]</ref>, or both. This paper presents DrTM+R, a fast and general distributed transaction processing system. Like prior systems, DrTM+R supports in-memory transactions by leveraging battery-backed memory as the main storage for database records and combines HTM and RDMA for fast distributed transactions. Unlike prior systems <ref type="bibr" target="#b53">[54]</ref>, DrTM+R places no restrictions on transactional workloads and provides full replication support for high availability.</p><p>To address the generality issue, DrTM+R leverages an opportunistic concurrency control (OCC) design <ref type="bibr" target="#b51">[52]</ref> for local transactions, while leveraging HTM to protect the validation and write phases. To glue together distributed transactions across machines, DrTM+R leverages the strong consistency of RDMA to detect the conflict between a remote (distributed) transaction from local transactions. To prevent a remote transaction from updating a record in the read set of a local transaction, DrTM+R additionally introduces a remote locking phase before the validation phase and the write phase of OCC. As DrTM+R knows all read and write sets of a transaction after the execution phase, DrTM+R does not require priori knowledge of read/write sets before transaction execution.</p><p>There is a challenge in providing replication for DrTM+R, due to the fact that no I/O operations such as RDMA operations are allowed within an HTM transaction. Hence, DrTM+R cannot replicate local updates within a transaction to a remote machine, while replicating updates outside the HTM transaction would cause a race condition that a transaction is considered as committed but not replicated. DrTM+R addresses this issue by leveraging an optimistic replication scheme that decouples local commit from replication (i.e., full commit). Specifically, it assigns a version number to each record and uses a seqlock <ref type="foot" target="#foot_0">1</ref> -like versioning scheme. DrTM+R increases the version number into "odd" within the HTM transaction, indicating that the records are committed but not replicated. It then increases the records again to "even" after replication outside the HTM transaction to indicate that the records have been replicated. An inflight transaction is allowed to read an unreplicated record but cannot commit until the records have been replicated.</p><p>We have implemented DrTM+R, which extends a prior OCC-based multicore database design <ref type="bibr" target="#b51">[52]</ref> with the support for distributed transactions. To demonstrate the efficiency of DrTM+R, we have conducted a set of evaluations of DrTM+R's performance using a 6-node cluster connected by InfiniBand NICs with the RDMA feature. Each machine of the cluster has two 10-core RTM-enabled Intel Xeon processors. Using popular OLTP workloads like TPC-C <ref type="bibr" target="#b45">[46]</ref> and SmallBank <ref type="bibr" target="#b44">[45]</ref>, we show that DrTM+R can perform over 5.69 and 94 million transactions per second without replication for TPC-C and SmallBank respectively. A simulation of running multiple logical nodes over each machine shows that DrTM+R may be able to scale out to a larger cluster with tens of nodes. A comparison with a state-of-the-art distributed transaction system (i.e., Calvin without replication) shows that DrTM+R is at least 26.8X faster for TPC-C. We further show that enabling 3-way replication on DrTM+R only incurs at most 41% overhead before reaching network bottleneck.</p><p>In summary, the contributions of this paper are:</p><p>• The design and implementation of a distributed transaction processing system with the combination of HTM and RDMA ( §3), yet without restrictions in prior work like knowing read/write sets of transactions in advance.</p><p>• An HTM/RDMA friendly concurrency control scheme using OCC and remote locking to glue together multiple concurrent transactions across machines ( §4).</p><p>• An efficient optimistic replication scheme that provides durability and high availability while retaining the benefits of combining RDMA and HTM ( §5).</p><p>• A set of evaluations that confirm extremely high performance and high availability of DrTM+R with strict serializability ( §7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Motivation</head><p>2.1 Advanced Hardware Features HTM and Strong Atomicity. Hardware transactional memory (HTM) has recently been commercially available in the form of Intel's restricted transactional memory (RTM). The goal of HTM is to be an alternative of locking, by providing the simplicity of coarse-grained locking yet having the performance of fine-grained locking. By enclosing a set of operations (including memory operations) as a hardware transaction<ref type="foot" target="#foot_1">2</ref> , the CPU ensures that a set of operations execute with the properties of atomicity, consistency and isolation (ACI). Some recent hardware proposals even further propose adding durability to HTM <ref type="bibr" target="#b52">[53]</ref>. Intel RTM provides a set of interfaces including XBEGIN, XEND, and XABORT, which will begin, end, and abort an RTM transaction accordingly.</p><p>As a hardware supported one, Intel's RTM provides strong atomicity <ref type="bibr" target="#b6">[7]</ref> within a single machine. This means that a non-transactional operation will unconditionally abort an HTM transaction when their accesses conflict. To simplify hardware implementation, RTM uses the first-level cache to track the write set and an implementation-specific structure (e.g., a bloom filter) to track the read set. It relies on the cache coherence protocol to detect conflicts, upon which at least one transaction will be aborted.</p><p>There are also several limitations with Intel's RTM <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>, which prevents a direct use of RTM to protect database transactions. The first limitation is that an RTM transaction can only track limited read/write sets. Consequently, the abort rate of an RTM transaction will increase significantly with the increase of working set size. Thus, running a program with a number of memory operations will cause high abort rate or even no forward progress. The second limitation is that no I/O operations are allowed within an RTM transaction. This prevents us from running RDMA operations within an RTM transaction for remote memory operations. Last but not least, RTM is only a compelling hardware feature for single machine platform but provides no support across machines.</p><p>RDMA and Strong Consistency.  <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>. One interesting feature of RDMA operations is its strong consistency with respect to the memory operations in the target CPU: an RDMA operation is cache coherent with the memory operations <ref type="bibr" target="#b53">[54]</ref>. Thus, when combining with the strong consistency of HTM, an RDMA operation will unconditionally abort a conflicting HTM transaction in the target machine. However, while powerful, one-sided RDMA operation only provides limited interfaces: read, write, and two atomic operations (fetch-and-add and compare-and-swap).</p><p>Non-volatile Memory: Some data-centers provide an interesting feature called distributed UPS that allows flushing data from volatile memory to persistent storage (like SSD) <ref type="bibr" target="#b32">[33]</ref>. Besides, NVDIMM <ref type="bibr" target="#b42">[43]</ref> has been commercially available by major memory vendors like Micron, Viking, JEDEC, and Fusion-IO. Finally, 3DXpoint <ref type="bibr" target="#b49">[50]</ref>, a new nonvolatile memory technology from Intel and Micron, has been predicted to be available to the market soon. With logging to disk accounting for a large portion of transaction execution, these non-volatile memory devices can largely mitigate the logging overhead of transactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Issues with Prior Systems</head><p>While HTM and RDMA are promising hardware features to boost transaction executions, prior systems either only leverage one of them, or fall short in only providing limited transaction features. Table <ref type="table" target="#tab_0">1</ref> illustrates a comparison of recent designs with DrTM+R.</p><p>General designs: Silo <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b59">60]</ref> is a fast in-memory transaction for multicore. It adopts fine-grained locking with scalable transaction ID to provide scalable transaction processing in a single machine. However, it is not designed to be scale-out to multiple machines. Calvin <ref type="bibr" target="#b47">[48]</ref> leverages deterministic execution for scalable distributed transaction processing. Yet, its performance is at least an order of magnitude less than that of DrTM+R, due to not exploiting advanced hardware features like HTM and RDMA. Besides, Calvin requires priori knowledge of remote read and write sets, which would limit its applicability to various types of transactions.</p><p>RDMA-only designs: FaRM <ref type="bibr" target="#b15">[16]</ref> and its successor <ref type="bibr" target="#b16">[17]</ref> leverage RDMA to provide general distributed transactions. It abstracts a cluster as a partitioned global address space and leverages RDMA to fetch remote database records to be processed locally. It leverages the low-latency feature of RDMA operations to implement an optimized four-phase commit with replication, and can recover a failure in less than 50ms. In contrast, DrTM+R further combines HTM with RDMA to process distributed transactions and may have better performance under the same setting.</p><p>HTM-only designs: DBX <ref type="bibr" target="#b51">[52]</ref> combines HTM with an OCC protocol to implement efficient transactions on multicore machines. To reduce the working set of an HTM transaction, it separates execution from commit by only leveraging HTM transactions to protect the validation and write phases. This effectively reduces the working set of an HTM transaction from all data to all metadata of database records accessed in a database transaction. DBX-TC <ref type="bibr" target="#b38">[39]</ref> implements an optimized transaction chopping algorithm to decompose a set of large transactions into smaller pieces, and thus only uses HTM transactions to protect each piece. Due to mostly offloading concurrency control to HTM, it shows better performance than DBX. However, both of them are limited to single-machine transactions.</p><p>HTM/RDMA designs: DrTM <ref type="bibr" target="#b53">[54]</ref> is the closest work with DrTM+R. Like DrTM, DrTM+R also leverages HTM and RDMA to provide efficient transaction processing. Unlike DrTM, DrTM+R places no restrictions on transaction features such that it requires no priori knowledge of transaction working set and provides efficient replication for high availability, two important features that are missing in DrTM. Thus, unlike DrTM which combines two-phase locking (2PL) with HTM, DrTM+R provides a hybrid concurrency control protocol that combines optimistic concurrency control (OCC) with remote locking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview</head><p>Setting. DrTM+R assumes a modern cluster that is connected with high-speed, low-latency network with RDMA features. Each processor in the cluster is equipped with HTM and each machine contains a portion of battery-backed non-volatile memory for data and logging. DrTM+R targets OLTP workloads over a large volume of data; it scales by partitioning data into a large number of shards across multiple machines. DrTM+R employs a worker-thread model by running n worker threads atop n cores; each worker thread executes and commits a transaction at a time.</p><p>Approach Overview. Like prior work <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b53">54]</ref>, DrTM+R comprises of two independent components: transaction layer and memory store, as shown in Figure <ref type="figure" target="#fig_0">1</ref>. DrTM+R leverages a hybrid OCC and locking scheme using HTM and RDMA ( §4). On each machine, DrTM+R utilizes an OCCbased scheme to provide transaction support. Like typical OCC, DrTM+R separates execution from commit by first tracking the read/write sets of a transaction in the execution phase, validating the read set in the validation phase and finally committing the updates in the commit phase. The last two phases require atomicity, which DrTM+R guarantees using HTM transactions. DrTM+R exposes a partitioned global address space such that remote records and local records are explicitly distinguished using their address identifiers. DrTM+R follows a local execution model. To access remote data in a transaction, DrTM+R first fetches remote records into the hosting machine, makes necessary updates and then sends the records back to the remote machine. Remote accesses in DrTM+R are mainly done using one-sided RDMA operations for efficiency. As there is no apparent way to guarantee the atomicity between accessing a record in a remote machine and validating the record in the local machine, DrTM+R introduces a remote locking phase ( §4.4) before the validation and commit phases, which leverages one-sided RDMA operations to lock remote records.</p><p>The high availability of DrTM+R is guaranteed by efficient replication of database records before fully committing a transaction ( §5). This is achieved by leveraging a revised commit protocol ( §5.1). DrTM+R leverages ZooKeeper <ref type="bibr" target="#b19">[20]</ref> to reach an agreement on the current configuration among surviving machines. Inspired by FaRM <ref type="bibr" target="#b16">[17]</ref>, an RDMAbase protocol is used to manage leases, detect failures, and coordinate recovery( §5.2). Thanks to the fast interconnect, DrTM+R can detect a failure in a very short time with high accuracy. During recovery, DrTM+R first reconfigures the cluster and then recovers the state of crashed machines by leveraging surviving machines. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Supporting Distributed Transactions</head><p>DrTM+R uses an HTM-friendly optimistic concurrency control (OCC) protocol to provide transaction support within a single machine and further adopts an RDMA-friendly optimistic concurrency control (OCC) protocol to coordinate accesses to remote records for distributed transactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">HTM/RDMA-friendly OCC Protocol</head><p>Since an HTM transaction provides strong atomicity and one-sided RDMA operations are cache-coherent, the prior system <ref type="bibr" target="#b53">[54]</ref> leverages them to bridge the HTM and twophase locking (2PL) protocol for distributed transactions. However, it requires priori knowledge of read/write sets of transactions for proper locking to implement the 2PL-like protocol. Unfortunately, this is not always the case for some general transaction workloads, like TPC-C <ref type="bibr" target="#b45">[46]</ref> <ref type="foot" target="#foot_2">3</ref> and TPC-E <ref type="bibr" target="#b46">[47]</ref>, which have dependent transactions.</p><p>DrTM+R addresses this limitation by designing a hybrid OCC and locking protocol to provide strictly serializable transactions. The main observation is that the read-/write of an transaction will be known after the execution phase in OCC, due to its separation of execution from commit. Hence, DrTM+R has all read/write sets known after the execution phase. However, any RDMA operation inside an HTM transaction will unconditionally cause an HTM abort and thus we cannot directly access remote records through RDMA within an HTM transaction. To this end, DrTM+R adjusts the traditional OCC protocol by distinguishing operations on local and remote records, which will be protected using HTM and RDMA-based locking mechanisms respectively. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, DrTM+R organizes the concurrency protocol into two phases: execution and commit. In the execution phase, DrTM+R provides different interfaces to run transaction code with read and write accesses to local and remote records. For read accesses, DrTM+R ensures consistent accesses to local and remote records by HTM and RDMA-based versioning respectively, and maintains the locations (i.e., virtual address or RDMA address) and versions (i.e., sequence number) of the records in local and remote read sets (i.e., L RS and R RS). For write accesses, DrTM+R buffers all updates locally for both local and remote records, and maintains the location and the buffer of the records in local and remote write sets (i.e., L WS and R WS) ( §4.3). In the commit phase, DrTM+R attempts to atomically commit the transaction using HTM for local records and RDMA-based locking for remote records. DrTM+R follows the traditional OCC protocol to first validate that any record in read set is not changed, and then updates all local buffers in write set to actual records ( §4.4).</p><p>Since DrTM+R uses different mechanisms that protect the accesses and commits of local records by HTM and remote records by RDMA-based versioning and locking, DrTM+R cannot simply combine the HTM-based OCC protocol from an HTM-friendly local database (e.g, DBX <ref type="bibr" target="#b51">[52]</ref>) and RDMA-based OCC protocol (e.g., FaRM <ref type="bibr" target="#b16">[17]</ref>). For example, a conflicting local read within HTM may still read an inconsistent record, since the update from a remote transaction using one-sided RDMA WRITE is only cache-coherent within a cache line. To this end, DrTM+R must carefully cooperate operations on different types of records.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Structure of Records</head><p>Based on the general key-value store interface provided by the memory store layer, the transaction layer implements typed database tables, namely collections of records. To facilitate our hybrid protocol, the transaction layer further encodes the following metadata to each record, as shown in Figure <ref type="figure" target="#fig_2">3</ref>. Note that HTM tracks reads and writes at the granularity of a cache line, DrTM+R enforces each record starts at a new cache line, avoiding unnecessary HTM aborts due to false sharing.</p><p>Lock (64-bit): locks the record by distributed transactions on remote machines. It is used to ensure the isolation of transactions during the commit phase.</p><p>Incarnation (64-bit): tracks the number of frees at the key-value entry. It is used to detect whether the record has been freed or not during the commit phase. Sequence Number (64-bit): tracks the number of updates on the record. It is used to detect read-write conflict during the commit phase.</p><p>Version (16-bit): identifies the version (the low-order bits of sequence number) of data in each cache line. It is used to check the consistency of a remote access across multiple cache lines during the execution phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Execution Phase</head><p>In the execution phase of the hybrid protocol, DrTM+R only needs to ensure consistent read accesses to records. All write operations will be stored in a local private buffer.</p><p>For local read accesses, inspired by DBX <ref type="bibr" target="#b51">[52]</ref>, DrTM+R uses an HTM transaction to guarantee the consistency of a local read, as long as the update to the record is also protected by an HTM transaction. However, the update from a remote machine may cause inconsistent local read since one RDMA WRITE to a record larger than one cache line size will result in separate writes on multiple cache lines. As shown in Figure <ref type="figure" target="#fig_3">4</ref>, the results of the first, second, and fifth local reads are consistent, and the RDMA WRITE can correctly abort the third conflicting local read. However, if the local read runs between updates on multiple cache lines by the RDMA WRITE, the result will be inconsistent (e.g., the fourth read to a record crossing three cache lines, two updated and one dated).</p><p>Fortunately, we observe that a remote transaction always needs to lock the records before updating. Therefore, DrTM+R can simply check the lock field of record before reading to ensure consistency. If the record is locked, a local read can manually abort its HTM transaction, which will retry with a randomized interval until the record is unlocked before entering into a fallback handler. This avoids complicated mechanisms for consistent read across multiple cache lines, such as versioning <ref type="bibr" target="#b15">[16]</ref> or checksum <ref type="bibr" target="#b33">[34]</ref>. However, this also means that a locked record cannot be read by a local transaction even the value is consistent. For example, the second local read in Figure <ref type="figure" target="#fig_3">4</ref> will abort and retry. Note that it will not affect the correctness but only incur some necessary false aborts. The false abort is necessary because the locked record is likely to be updated by the remote transaction soon, the local transaction is inevitable to abort when validating its local read set during the commit phase, even if  it reads a consistent but stale record in the execution phase. Figure <ref type="figure" target="#fig_4">5</ref> illustrates the pseudo-code of local read and write in DrTM+R.</p><p>For remote accesses, inspired by FaRM <ref type="bibr" target="#b15">[16]</ref>, DrTM+R uses versioning to implement a lock-free and consistent read. It mainly relies on the strong consistency provided by one-sided RDMA READ, which ensures atomic read of the record written by a local write or a one-sided RDMA WRITE. However, since it only works in a single cache line, DrTM+R places the version of record at the start of each cache line (except the first), as shown in Figure <ref type="figure" target="#fig_2">3</ref> and requires a record write to update each version. Further, the remote read requires to match all versions of the record for the consistency of value. To save space, DrTM+R uses the least significant 16 bits of the sequence number as the version, which is usually sufficient to avoid overflow within a single remote read <ref type="bibr" target="#b15">[16]</ref>. Note that the versions of the record are invisible to the user-written transactions. Figure <ref type="figure" target="#fig_5">6</ref> illustrates the pseudo-code of remote read and write in DrTM+R. Different from the versioning in FaRM <ref type="bibr" target="#b15">[16]</ref>, DrTM+R does not check the lock field of a record, because the record may be locked by a distributed transaction on a remote machine even only for read during the commit phase (see §4.4). However, because DrTM+R will lock records in the remote read set during the commit phase, uncommitted read to a remote record in the execution phase can be detected, and the transaction can safely abort to ensure strict serializability. mote records in the execution phase. DrTM+R leverages a combination of HTM and versioning to guarantee the consistency between local/remote reads/writes. Finally, the insert/delete operations in DrTM+R will be shipped to the host machine using SEND/RECV Verbs and also locally executed within an HTM transaction. As in prior work <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b53">54]</ref>, DrTM+R adopts incarnation mechanism to detect invalidation between read and insert/delete operations. The incarnation is initially zero and is monotonously increased by insert/delete operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Commit Phase</head><p>To fully leverage advanced hardware features, DrTM+R proposes an HTM/RDMA-friendly six-step commit phase, which uses HTM for local records and RDMA-based locking for remote records. For the remote accesses, DrTM+R uses one-sided RDMA operations instead of messaging used in FaRM <ref type="bibr" target="#b16">[17]</ref>, since the later increases the number of interrupts and context switches on the remote machine, which will unconditionally abort the HTM transactions even without access conflicts. Figure <ref type="figure" target="#fig_6">7</ref> illustrates the pseudo-code of the commit phase in DrTM+R.</p><p>C.1 Lock (remote read/write sets). DrTM+R exclusively locks remote records in both read and write sets using one-sided RDMA CAS (compare-and-swap), which provides an equal semantic to the normal CAS instruction (i.e., local CAS). However, there is an atomicity issue between local CAS and RDMA CAS operations. The atomicity of RDMA CAS is hardware-specific <ref type="bibr" target="#b31">[32]</ref>, which can implement any one of the three levels: IBV ATOMIC NONE, IBV ATOMIC HCA, and IBV ATOMIC GLOB. The RDMA CAS can only correctly work with local CAS under IBV ATOMIC GLOB level, while our InfiniBand NIC <ref type="foot" target="#foot_3">4</ref> only provides the IBV ATOMIC HCA level of atomicity. This means that RDMA CASs can only correctly lock each other. Fortunately, the lock will only be acquired and released by remote accesses using RDMA CAS in our protocol. The local access will only check the state of a lock, which can correctly work with RDMA CAS due to the cache coherency of RDMA operations.</p><p>C.2 Validate (remote read set). DrTM+R performs read validation to remote read records using one-sided RDMA READs. It checks whether the current sequence numbers of records are equal to those acquired by remote reads in the execution phase. If any one is changed, the transaction is aborted. Different from traditional OCC protocol, DrTM+R must lock the remote records even for reads to ensure strict serializability, since local records in the write set are not protected by HTM until the next step. However, this lock will not block remote read in the execution phase. Further, in an NIC with the IBV ATOMIC GLOB atomicity level, the lock field can be encoded in the sequence number of a record, so that DrTM+R can lock and validate the record using a single RDMA CAS. Unfortunately, this is not available in our NIC, and DrTM+R first uses RDMA CAS to lock a remote record and then fetch the sequence number to validate the record locally.</p><p>C.3 Validate (local read set) and C.4 Update (local write set). DrTM+R performs read validation to local records in the read set first, and commits buffered updates and increased sequence number to local records in the write set. The entire accesses on local records are protected by an HTM transaction. The HTM transaction provides strong atomicity with any concurrent local accesses to the same records, and any remote conflicting RDMA accesses will also abort the HTM transaction. The only exception is that a remote transaction may lock a local record in the write set before the start of the HTM transaction. To remedy this issue, DrTM+R adds an additional check before the update and manually abort the transaction upon a failed check.  C5. Update (remote write set) and C.6 Unlock (remote read/write sets) DrTM+R writes back updates to remote records and increases their sequence numbers using RDMA WRITEs, and after that it reports the transaction as committed to user. Finally, DrTM+R unlocks all remote records using RDMA CAS.</p><p>Table <ref type="table" target="#tab_3">3</ref> summarizes different mechanisms used by DrTM+R to atomically commit the updates on local and remote records.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Read-only Transactions</head><p>Read-only transaction is a special case which usually has a very large read set involving up to hundreds or even thousands of records. Thus, it will likely abort an HTM transaction in the commit phase due to read validation on a large local read set, since HTM tracks reads and writes at the granularity of a cache line even if only several bytes (e.g., sequence number) are accessed. To address this issue, DrTM+R provides a separate protocol to execute read-only transactions without HTM and locking in the commit phase.</p><p>Figure <ref type="figure" target="#fig_7">8</ref> shows the pseudo-code and interfaces for readonly transactions. In the execution phase, the read access to local records is the same to that of read-write transactions, since it only reads one record at a time. In contrast, the read accesses to remote records requires an additional check for the lock to avoid reading uncommitted reads. If the record is concurrently updated by a remote transaction, the record must be locked. On the other hand, if the record is concurrently updated by a local transaction, the remote read using RDMA READ will abort the transaction. In the commit phase, DrTM+R can validate only the sequence numbers of records in both local and remote read set without any protection of HTM or locking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Strict Serializability</head><p>This section gives an informal argument on the strict serializability of our hybrid concurrency control protocol. We argue it by reduction that our protocol is equal to traditional optimistic concurrency control (OCC) <ref type="bibr" target="#b22">[23]</ref>.</p><p>Committed read-write transactions are serializable at the point of the end of HTM transaction in the commit phase. This is because the versions of all records in read and write sets are the same as the versions seen in the execution phase. First, locking ensures this for remote write records. Second, the HTM transaction ensures this for local write records. Finally, the validation phase ensures this invariant for all read records. Even if the read validation on remote records is earlier than the HTM transaction, locking on them makes it equivalent to the validation within the HTM transaction. Committed read-only transactions are serializable at the point of their last read. The validation phase ensures the versions of all records in the read set at the serialization point are the same as the versions seen in the execution phase. Therefore, this is equivalent to executing and committing the entire transaction atomically at the serialization point. Further, the serialization point of transactions is always between receiving the request to start the transaction and reporting the committed transaction to user, which ensures strict serializability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Replication</head><p>Many in-memory transaction systems <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b47">48]</ref> adopt replication on remote machines to support durability and availability. However, any I/O operation including RDMA inside an HTM transaction will unconditionally cause an HTM abort. Therefore, prior HTM-based transaction systems <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b53">54]</ref> only preserve durability rather than availability by logging to local reliable storage in case of machine failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Primary-backup Replication</head><p>DrTM+R follows FaRM <ref type="bibr" target="#b16">[17]</ref> to use vertical Paxos <ref type="bibr" target="#b23">[24]</ref> with primary-backup replication to provide durability and availability. DrTM+R should send all updates of records to the non-volatile logs on backup machines after read validation and before updating the primaries of both local and remote records, and ask them to truncate logs at the end of a transaction. Note that using auxiliary threads to truncate logs will not impact worker threads to update primaries since the backups of records will only be used in recovery. However, using HTM and RDMA to implement distributed transactions raises a key challenge for replication. Both validation (C.3) and update (C.4) to local records are performed within an HTM transaction, and thus replication to remote machines (R.1) through network I/O inside an HTM transaction is not allowed inside the HTM transaction, as shown in Figure <ref type="figure" target="#fig_8">9</ref>.</p><p>An intuitive solution is to directly move updating backups (R.1) after the HTM transaction commits. However, all machines can immediately observe the local updates after the HTM transaction commits (i.e., XEND) through local or RDMA read. Consequently, a subsequent transaction may read the updates and then commit, while this transaction may not commit due to machine failures and the backups does not receive updates.</p><p>DrTM+R proposes an optimistic replication scheme, which can cooperate with our hybrid OCC protocol. The key idea is to leave all locally written records in an uncommittable status after the HTM transaction commits; they will transform to a committable status until both primaries and backups of the written records have been applied. The uncommittable record can be optimistically read in the execution phase. In the commit phase, the record cannot be updated when being uncommittable, and read validation will fail if the record is still uncommittable or has been changed. The optimistic replication scheme preserves strict serializability since all subsequent transactions observing the records updated by a prior transaction will not commit until the prior transaction commits.</p><p>DrTM+R reuses the sequence number (SN) of records to implement optimistic replication. An odd sequence number indicates uncommittable, and an even sequence num- ber indicates committable, which is similar to the seqlock used in Linux. Table <ref type="table" target="#tab_4">4</ref> summarizes the change on HTMbased OCC to support optimistic replication. For backups of changed records (R.1) and primaries of remote written records (C.5), DrTM+R directly increases the sequence number by 2 when updating them. For primaries of local write records, DrTM+R increases the sequence number by 1 when updating them within the HTM transaction (C.4) and the makeup phase (R.2) accordingly. There is no change to the sequence number for local and remote read in the execution phase. In the commit phase, DrTM+R validates all written records using the condition that the current sequence number should be even, and changes the validation condition to all read records as the current sequence number should be equal to the closest committable sequence number of acquired sequence number in the execution phase. Since the write set is generally a subset of the read set (blind write is rare) and the condition for written records is included in the condition for read records, leveraging optimistic replication only incurs small overhead to the commit phase and has no impact to the execution phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Failure Recovery</head><p>DrTM+R uses similar failure models as prior work <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25]</ref>. All logs are stored in non-volatile memory, and the logs will not lose upon machine failures (e.g., relying on an uninterruptible power supply). A machine in a cluster may crash at any time, but only in a fail-stop manner instead of arbitrary failures like Byzantine failures <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22]</ref>. DrTM+R adopts primary-backup replication in nonvolatile memory with f + 1 copies. Therefore, it can provide durability even under a complete cluster failure and losing at most f copies for each record. DrTM+R can also provide availability with at least 1 copy of each record on surviving machines.</p><p>DrTM+R uses the same mechanisms in FaRM <ref type="bibr" target="#b16">[17]</ref> to detect machine failures and reconfigure the cluster, but a varied failure-recovery protocol for transaction state recovery. The main difference is that DrTM+R directly lock and unlock remote records using one-sided RDMA CAS. This reduces the latency of transactions compared to FaRM, which sends a LOCK message to the logs on target machines and relies on target worker threads to lock records and sends back responses. However, it may cause dangling locks after a failure since there is no log to find records locked by failed ma-chines. To avoid suspending the whole cluster and checking all records on each machine, DrTM+R adopts a passive approach to releasing such records. DrTM+R will first encode the owner machine ID into the lock of records. Further, the worker thread will check whether the owner of the locked record is the member of the current configuration or not. If the owner is absent, the worker thread will unlock the record before aborting and retrying the transaction. It should be noted that the additional check will not incur perceptibly overhead to DrTM+R since it is not on the critical path of normal execution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Implementation Issues</head><p>We have implemented DrTM+R using Intel's Restricted Transactional Memory (RTM) and Mellanox ConnectX-3 56Gbps InfiniBand. This section describes some specific implementation issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Fallback Handler and Contention Management</head><p>As a best-effort mechanism, an RTM transaction does not have guaranteed forward progress even in the absence of conflicts. A fallback handler will be executed after the number of RTM aborts exceeds a threshold. In typical implementation, the fallback handler first acquires a coarse-grained exclusive lock, and then directly updates all records. To cooperate with the fallback handler, the RTM transaction needs to check this lock before entering its RTM region.</p><p>In DrTM+R, however, since local records will also be remotely accessed by other transactions, the fallback handler may inconsistently update the record out of an RTM region. Therefore, DrTM+R needs to lock and validate the local records similar to those required for remote read/write records. To avoid deadlocks, the fallback handler should release all owned remote locks first, and then acquire appropriate locks for all records in a sorted order. After that, the fallback handler can execute the validation as usual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Atomicity Issues</head><p>As mentioned in §4.4, even if RDMA CAS on our Infini-Band NIC cannot preserve the atomicity with the local CAS, it will not incur consistency issues in the normal execution of transactions. However, in the RTM's fallback handler of the commit phase, DrTM+R has to lock both local and remote records. In fact, calling fallback handler in DrTM+R is rare (lower than 1%) since the conflicts between transactions are mainly detected by read validation of OCC. Therefore, even the current performance of RDMA CAS is two orders of magnitude slower than the local counterpart, DrTM+R still uniformly uses RDMA CAS to lock local records in fallback handlers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Memory Store</head><p>The memory store layer of DrTM+R provides a general keyvalue store interface to the upper transaction layer. The most common usage of this interface is to read or write records by given keys. To optimize for different access patterns <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>, DrTM+R provides both an ordered store in the form of a B + -tree and an unordered store in the form of a hash table. For the ordered store, we use the B + -tree in DBX <ref type="bibr" target="#b51">[52]</ref>, which uses HTM to protect the major B + -tree operations and was shown to have comparable performance with stateof-the-art concurrent B + -tree <ref type="bibr" target="#b30">[31]</ref>. For the unordered store, we use the HTM/RDMA-friendly hash table in DrTM <ref type="bibr" target="#b53">[54]</ref>, which uses one-sided RDMA operations for both reads and writes, as well as provides an RDMA-friendly, locationbased and host-transparent cache to reduce RDMA lookup cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Local Record Update</head><p>Since RTM tracks writes using L1 cache, the write working set (32K) is much smaller than that of read. To reduce the working set for local write within the HTM region in the commit phase, DrTM+R updates local records by swapping the pointer of local buffer instead of overwriting actual records. However, this optimization can only apply to records that are always locally accessed. For example, the NEW ORDER and CUSTOMER tables used by new-order and delivery transactions in TPC-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Evaluation</head><p>This section presents the evaluation of DrTM+R, with the goal of answering the following questions:</p><p>• How does the performance of DrTM+R with RTM and RDMA compare to that of the state-of-the-art systems without using such features?</p><p>• Can DrTM+R scale out with the increase of threads and machines?</p><p>• How does each design decision affect the performance of DrTM+R?</p><p>• How fast can DrTM+R recover from failures?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>The performance evaluation was conducted on a local cluster with 6 machines. Each machine has two 10-core RTMenabled Intel Xeon E5-2650 v3 processors with 64GB of DRAM. Each core has a private 32KB L1 cache and a private 256KB L2 cache, and all 10 cores on a single processor share a 24MB L3 cache. We disabled hyper-threading on all machines. Each machine is equipped with a ConnectX-3 MCX353A 56Gbps InfiniBand NIC via PCIe 3.0 x8 connected to a Mellanox IS5025 40Gbps InfiniBand Switch, and an Intel X520 10GbE NIC connected to a Force10 S4810P 10/40GbE Switch. All machines run Ubuntu 14.04 with Mellanox OFED v3.0-2.0.1 stack. We reserve two cores to run auxiliary threads on each processor for log truncation. DrTM+R=3 represents 3-way replication enabled for providing high availability, and will replicate to standby machines when running on less than 3 machines. We use two standard benchmarks to evaluate DrTM+R: TPC-C <ref type="bibr" target="#b45">[46]</ref> and SmallBank <ref type="bibr" target="#b3">[4]</ref>. TPC-C is a widely-used OLTP benchmark that simulates principal transactions of an order-entry environment. These transactions include entering and delivering orders (new-order and delivery), recording payments (payment), checking the status of orders (order-status), and monitoring the level of stock at the warehouses (stock-level). TPC-C scales by partitioning a database into multiple warehouses spreading across multiple machines. As specified by the benchmark, the throughput of TPC-C is defined as how many new-order transactions per second a system processed while the system is executing four other transactions types. We run the standard-mix but report the throughput of new-order transactions, which are 45% of total transactions. SmallBank models a simple banking application where transactions perform simple read and write operations on user accounts. The access patterns of transactions are skewed such that a few accounts receive most of the requests. SmallBank is a mix of six types of transactions for send-payment (SP), balance (BAL), deposit-checking (DC), withdraw-from-checking (WC), transfer-to-savings (TS), and amalgamate (AMG) procedures.</p><p>Table <ref type="table" target="#tab_5">5</ref> shows the percentage of each transaction type and its access pattern in TPC-C and SmallBank.</p><p>It is often hard for cross-system comparison especially for distributed systems. We keep the settings among different systems to be identical for each benchmark. We use the latest Calvin <ref type="bibr" target="#b47">[48]</ref> (released in Mar. 2015) and DrTM <ref type="bibr" target="#b53">[54]</ref> for comparison in our experiments. As Calvin is hard-coded to use 8 worker threads per machine, we have to skip it from the experiment with varying numbers of threads. We run Calvin on our InfiniBand network using IPoIB as it was not designed to use RDMA features, and the released code of Calvin does not provide logging or replication. We also run Silo <ref type="bibr" target="#b48">[49]</ref> (with logging disabled), a state-of-the-art singlemachine multicore database, on one machine of our cluster.</p><p>In all experiments, we dedicate one processor to run up to 8 worker threads and 2 auxiliary threads. We use the same machine to generate requests to avoid the impact of networking between clients and servers as done in prior work <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b51">52]</ref>. All experimental results are the average of five runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Performance and Scalability</head><p>TPC-C: We first run TPC-C with the increase of machines to compare the performance with DrTM and Calvin. Each machine is configured to run 8 worker threads and each of them hosts 1 warehouse with 10 districts. All warehouses in a single machine shares one memory store. Figure <ref type="figure" target="#fig_0">10</ref> shows the throughput of the new-order transaction in TPC-C's standard-mix workload. Compare to DrTM, DrTM+R trades roughly 9.8% (from 2.2%) performance for generality. The main overhead is due to manually maintaining the local read/write buffers of transactions.</p><p>DrTM+R can scale well in term of the number of machines and provide more than 1.49 million new-order and 3.31 million standard-mix transactions per second (txns/sec)   <ref type="figure" target="#fig_0">11</ref>). The reason is that DrTM+R=3 requires many RDMA operations for replication and thus saturate the limit of NIC. This finding is consistent with FaRM, whose successive version <ref type="bibr" target="#b16">[17]</ref> uses two 56Gbps RDMA-capable NICs per machine to overcome this bottleneck. We believe if we similarly deploy two NICs per machine, DrTM+R will scale much better. We further study the scalability of DrTM+R with the increase of worker threads using 6 machines. As shown in Figure <ref type="figure" target="#fig_0">11</ref>, the performance of DrTM drops over 8 threads due to cross-socket overhead and large working set in HTM. DrTM+R can scale well up to 16 threads, reaching 2.56 million new-order and 5.69 million standard-mix transactions per second. The speedup of throughput using 16 threads can reach 9.21X due to small working set in HTM and much lower HTM abort rate (less than 1%).</p><p>As an aside, DrTM+R also has very good single-node performance. Under 8 threads where all systems scale, the per-machine throughput for DrTM+R is 150,487 and 248,142 new-order transactions per second for with and without 3-way replication accordingly, which is comparable or even faster than Silo without logging (187,747 txns/sec<ref type="foot" target="#foot_5">5</ref> ). Under 16 threads, the per-machine throughput of Silo and DrTM+R is 354,579 and 426,628 txns/sec accordingly. This confirms that our HTM/RDMA-friendly concurrency protocol does not sacrifice per-machine efficiency.</p><p>To overcome the restriction of existing cluster size, we scale up to 4 separate logical nodes on a single machine to emulate the scalability experiment, each of which has fixed 4 worker threads. The interaction between logical nodes still uses our RDMA-based OCC protocol even on the same machine. As shown in Figure <ref type="figure" target="#fig_10">12</ref>, DrTM+R can scale well on 24 logical nodes, reaching 2.89 million new-order and 6.43 million standard-mix transactions per second.</p><p>SmallBank: We further study the performance and scalability of SmallBank with varying probability of distributed transactions on DrTM+R. Figure <ref type="figure" target="#fig_2">13</ref> and Figure <ref type="figure" target="#fig_3">14</ref> show the throughout of SmallBank on DrTM+R (3-way replication disabled) with the increase of machines and threads accordingly. For a low probability of distributed transactions (1%), DrTM+R provides high performance and can scale well in two dimensions. It can achieves over 94 million transactions per second using 6 machines with 16 threads each, and the speedup of throughput reaches more than 5.0X for 6 machines and 9.2X for 16 threads respectively. With the growth of distributed transactions, DrTM+R still performs stable throughput increase from 2 machines and scale-well within a single socket.</p><p>Figure <ref type="figure" target="#fig_4">15</ref> and Figure <ref type="figure" target="#fig_5">16</ref> show the throughput of Small-Bank on DrTM+R=3 (3-way replication enabled) with the increase of machines and threads accordingly. DrTM+R=3 can scale well with the increase of machines, but only scale up to 8 threads (6.4 million txns/sec) because the single 56Gbps InfiniBand NIC on each machine becomes the bottleneck. Each transaction requires at least four RDMA WRITEs for replication. Further, the peak throughput of DrTM+R=3 is much lower than that of DrTM+R since all transactions in SmallBank only perform a few accesses to the records (i.e., 1 read and 1 write). Consequently, additional RDMA operations for replication will dominate the execution time of transactions. Similarly, deploying more NICs per machine would make DrTM+R=3 scale much better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Impact from Distributed Transactions</head><p>We further investigate the performance of DrTM+R for distributed transactions. We adjust the probability of crosswarehouse accesses for new-order transactions from 1% to 100%, the default setting is 1% according to TPC-C specification. Since the average number of items accessed in the new-order transaction is 10, 10% of cross-warehouse accesses will result in approximate 57.2% of distributed transactions.</p><p>Figure <ref type="figure" target="#fig_13">17</ref> shows the throughput of new-order transaction on different systems with increasing cross-warehouse accesses. The 100% cross-warehouse accesses results in 73.1% and 81.7% slowdown for DrTM+R with and without 3-way replication respectively, because all transactions are distributed and any accesses are remote ones. However, the performance slowdown for 5% cross-warehouse accesses (close to 35% distributed transaction) is moderate  (11.0% and 11.1%). In addition, the performance gap between DrTM+R and DrTM becomes narrow with increasing distributed transactions, since both of them adopts a similar mechanism to update remote records.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Impact from High Contention</head><p>To evaluate the performance with a high contention scenario, we configure each machine to use only one warehouse for TPC-C. Figure <ref type="figure" target="#fig_14">18</ref> shows the throughput of new-order transaction in TPC-C for DrTM+R and DrTM on 6 machines with the increase of threads. DrTM+R can still outperform DrTM when there are less than 10 worker threads per machine, this is mainly because DrTM would fall back to a slow path with locking more frequently under high contentions. As an optimistic concurrency control scheme, DrTM+R incurs more overhead with the increase of threads due to more contention and increased read-write conflicts in the commit phase. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Impact from Data Size</head><p>To investigate the impact on throughput from the growing of database, we configure TPC-C with up to 384 warehouses (64 warehouses per machine), which uses approximately 28GB and 9GB of DRAM on each machine for DrTM+R with and without 3-way replication respectively. As shown in Figure <ref type="figure" target="#fig_15">19</ref>, the throughput of new-order transaction on with the increase of warehouses while fixing 6 machines and 8 threads each.</p><p>each system is stable and even increasing slightly from 48 warehouses. A large database may increase the cache miss rate, but it also reduces the contention on the database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Replication</head><p>To investigate the performance cost for replication, we evaluate how throughput and latency changes for TPC-C with 3-way replication. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7">Recovery</head><p>To evaluate performance of DrTM+R=3 upon failures, we run TPC-C on our 6-node cluster with 8 worker threads each. DrTM+R=3 enables 3-way replication and conservatively sets the leases of machines to 10ms. During evaluation, we kill one machine by turning off its networking, and the instance on failed machine will be recovered on one of the surviving machines. Figure <ref type="figure" target="#fig_16">20</ref> shows the timeline with the throughput of new-order transactions in TPC-C aggregated at 2ms intervals, which is a zoomed-in view around the failure. It also shows the time at which the failed machine is detected due to lease expired ("suspect"); the time at which the new configuration was committed at all surviving machines ("config-commit"); the time at which the recovery on all machines is done ("recovery-done"). As shown in Figure <ref type="figure" target="#fig_16">20</ref>, the throughput drops notably upon failure but rises rapidly again in about 40ms, 10ms of which is spent for suspecting a failure and the rest is used for recovery. The regained throughput of TPC-C is approximately 80% of original peak throughput, because the instance on failed machine is revived on a surviving machine and there are only 5 machines to handle the workload. Besides, two instances will slightly interfere with each other due to sharing a single InfiniBand NIC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Other Related Work</head><p>Distributed transactions: Providing low-latency, highthroughput transactions has been a long line of research <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref>. Rococo <ref type="bibr" target="#b34">[35]</ref> reorders conflicting pieces of contended transactions to reduce conflicts while retaining serializability. Callas <ref type="bibr" target="#b55">[56]</ref> instead provides a modular concurrency control scheme that partitions a set of transactions into a set of groups and enforces the serializability of each group separately. Yesquel <ref type="bibr" target="#b2">[3]</ref> instead leverages a distributed balance tree to provide scalable transactions across a cluster of machines. RIFL <ref type="bibr" target="#b25">[26]</ref> and Tapir <ref type="bibr" target="#b57">[58]</ref> instead boost transaction processing by providing a different underlying mechanism for transaction layer: RIFL provides exact-once RPC semantics to implement linearizable transactions; Tapir instead builds a consistent transaction layer atop an inconsistent replication layer to remove redundant support for consistency in both layers. DrTM+R has much better performance than these systems due to the use of advanced hardware features like HTM and RDMA.</p><p>Distributed transactional memory: There have been some effort to investigate the feasibility of distributed transactional memory using hardware of software approaches. Herlihy and Sun <ref type="bibr" target="#b18">[19]</ref> propose a hierarchical cache coherence protocol that takes distance and locality into account to support transactional memory in a cluster. However, there is no actual implementation and evaluation of the proposed schemes. Researchers have also investigated the design and implementation of distributed transactional memory <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b29">30]</ref>, which, however, usually have inferior performance than its hardware counterpart. Like DrTM <ref type="bibr" target="#b53">[54]</ref>, DrTM+R also leverages the strong consistency of RDMA and strong atomicity of HTM to support fast database transactions, but further provides availability and requires no priori knowledge of read/write sets.</p><p>Concurrency control: There have been multiple approaches to implement concurrency control, including twophase locking <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23]</ref>, timestamp ordering <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b26">27]</ref> and commit ordering <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>. There are also other varieties that leverages dependencies to improve performance, like dependency-aware software transactional memory <ref type="bibr" target="#b39">[40]</ref>, ordered sharing lock <ref type="bibr" target="#b1">[2]</ref> and balanced concurrency control <ref type="bibr" target="#b56">[57]</ref>. Besides DBX, DBX-TC, and DrTM, Leis et al. <ref type="bibr" target="#b26">[27]</ref> combines time-stamp ordering with HTM to provide scalable transactions. DrTM+R is built atop prior concurrency control approaches by combining OCC with HTM and RDMA to derive a hybrid approach to general transaction processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion</head><p>This paper described DrTM+R, an in-memory transaction processing system that leverages advanced hardware features like HTM and RDMA to provide high performance and low latency, while preserving the generality and providing high availability. DrTM+R leverages a hybrid concurrency scheme that combines OCC with remote locking for distributed transactions, and uses a progressive replication scheme to tackle the race condition between replication and HTM transaction commits. Evaluations using typical OLTP workloads like TPC-C and SmallBank confirmed the benefit of designs in DrTM+R.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The architecture overview of DrTM+R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The concurrency control protocol in DrTM+R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The structure of a record across three cachelines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The consistency of local read.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The pseudo-code of local read and write in DrTM+R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. the pseudo-code of remote read and write in DrTM+R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. The pseudo-code of commit in DrTM+R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. The pseudo-code of read-only transaction interface in DrTM+R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. The primary-backup replication in DrTM+R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .Figure 11 .</head><label>1011</label><figDesc>Figure 10. The throughput of new-order transactions in TPC-C with the increase of machines while fixing 8 threads each.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. The throughput of new-order transactions in TPC-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 13 .Figure 14 .</head><label>1314</label><figDesc>Figure 13. The throughput of standard-mix in SmallBank on DrTM+R with the increase of machines using different probability of cross-machine accesses for SP and AMP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 15 .Figure 16 .</head><label>1516</label><figDesc>Figure 15. The throughput of standard-mix in SmallBank on DrTM+R=3 with the increase of machines using different probability of cross-machine accesses for SP and AMP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 17 .</head><label>17</label><figDesc>Figure 17. The throughput of new-order transaction in TPC-C with the increase of cross-warehouse accesses while fixing 6 machines and 8 threads each.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 18 .</head><label>18</label><figDesc>Figure 18. The throughput of new-order transaction in TPC-C with increasing threads while fixing one warehouse per machine.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 19 .</head><label>19</label><figDesc>Figure 19. The throughput of new-order transaction in TPC-C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 20 .</head><label>20</label><figDesc>Figure 20. The throughput timeline for new-order transaction in TPC-C with failure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>A comparison of various in-memory transaction systems.</figDesc><table><row><cell>Remote Direct Mem-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>summarizes different mechanisms used by DrTM+R to ensure consistent read accesses to local and re-</figDesc><table><row><cell cols="3">CONSISTENCY COMMIT/L COMMIT/R</cell></row><row><cell>READ/L</cell><cell>HTM</cell><cell>HTM †</cell></row><row><cell>READ/R</cell><cell>Versioning</cell><cell>Versioning</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>A summary of different mechanisms used to ensure consistency of local and remote reads. L and R stand for Local and Remote records. ( †) READ/R needs to check the lock within HTM to avoid inconsistent read.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>A summary of different mechanisms used to ensure isolation of the commitment on local and remote records. L and R stand for Local and Remote records.</figDesc><table><row><cell>ISOLATION</cell><cell>COMMIT/L</cell><cell>COMMIT/R</cell></row><row><cell>COMMIT/L</cell><cell>HTM</cell><cell>HTM &amp; Locking</cell></row><row><cell>COMMIT/R</cell><cell>HTM &amp; Locking</cell><cell>Locking</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>RS SN old == SN cur (SN old + 0x1) &amp; ∼0x1 == SN cur C.2 R WS / SN cur &amp; 0x1 == 0x0 C.3 L RS SN old == SN cur (SN old + 0x1) &amp; ∼0x1 == SN cur (a) the change on sequence number (SN) and (b) the condition of validation for records within different read/write sets in COMMIT. OR stands for optimistic replication. L and R stand for Local and Remote. WS and RS stand for Write Set and Read Set.</figDesc><table><row><cell>OCC</cell><cell>OCC+OR</cell><cell></cell><cell>OCC</cell><cell>OCC+OR</cell></row><row><cell>C.4 Update L WS Primary SN new +1</cell><cell>SN new +1</cell><cell></cell><cell cols="2">Condition of Validation</cell></row><row><cell>R.1 Update L WS Backup R.1 Update R WS Backup R.2 Makeup L WS Primary C.5 Update R WS Primary SN new +1 / / /</cell><cell>SN new +2 SN new +2 SN new +1 SN new +2</cell><cell>C.2 R C.4 L WS</cell><cell>/</cell><cell>SN cur &amp; 0x1 == 0x0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>The transaction mix ratio in TPC-C and SmallBank. d and l stand for distributed and local. rw and ro stand for readwrite and read-only. The default probability of cross-warehouse accesses for NEW and PAY in TPC-C is 1% and 15% respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>shows the performance differ-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 .</head><label>6</label><figDesc>The impact of 3-way replication on throughput and latency for TPC-C on 6 machines with 8 threads each.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Seqlock, i.e., sequential lock, is special locking scheme used in Linux kernel that allows fast writes to a shared memory location among multiple racy accesses.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>This paper uses HTM/RTM transaction to denote the transactional code executed under HTM's protection, and uses transaction to denote the original user-written transaction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>DrTM leverages transaction chopping to address this issue for TPC-C</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Mellanox ConnectX-3 MCX353A</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>56Gbps InfiniBand NIC.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>Silo only reports standard-mix transactions per second which we multiplied by 45% to get the new order transactions per second.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We sincerely thank our shepherd Dushyanth Narayanan and the anonymous reviewers for their insightful suggestions. This work is supported in part by China National Natural Science Foundation (61402284, 61572314), Doctoral Fund of Ministry of Education of China (No. 20130073120040), National Youth Top-notch Talent Support Program of China, the Shanghai Science and Technology Development Fund for high-tech achievement translation (No. 14511100902), Zhangjiang Hi-Tech program (No. 201501-YP-B108-012) and Singapore NRF (CREATE E2S2).</p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability No</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distributed optimistic concurrency control with reduced rollback</title>
		<author>
			<persName><forename type="first">D</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sen-Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="59" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ordered shared locks for real-time databases</title>
		<author>
			<persName><forename type="first">D</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>El Abbadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jeffers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="87" to="126" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Yesquel: scalable sql storage for web applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Aguilera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Leners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kotla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wal-Fish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The cost of serializability on platforms that use snapshot isolation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alomari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Öhm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 24th International Conference on Data Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="576" to="585" />
		</imprint>
	</monogr>
	<note>ICDE&apos;08</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Genesis: An extensible database management system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Batoory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Garza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Twichell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1711" to="1730" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Concurrency control and recovery in database systems</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hadzilacos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Addison-wesley</publisher>
			<biblScope unit="volume">370</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Subtleties of transactional memory atomicity semantics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Software transactional memory for large scale clusters</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bocchino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Chamberlain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</title>
		<meeting>the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="247" to="258" />
		</imprint>
	</monogr>
	<note>PPoPP&apos;08, ACM</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Prototyping bubba, a highly parallel database system. Knowledge and Data Engineering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Boral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Clay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Copeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Danforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="4" to="24" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Asynchronous lease-based replication of software transactional memory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rodrigues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IFIP/USENIX 11th International Conference on Middleware (2010), Middleware&apos;10</title>
		<meeting>the ACM/IFIP/USENIX 11th International Conference on Middleware (2010), Middleware&apos;10</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="376" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Practical byzantine fault tolerance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Symposium on Operating Systems Design and Implementation</title>
		<meeting>the Third Symposium on Operating Systems Design and Implementation</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="173" to="186" />
		</imprint>
	</monogr>
	<note>OSDI&apos;99</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spanner: Google&apos;s globally-distributed database</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fikes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Furman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gubarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hochschild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kanthak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Melnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mwaura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nagle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Quinlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rolig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szymaniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wood-Ford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation</title>
		<meeting>the 10th USENIX Conference on Operating Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="251" to="264" />
		</imprint>
	</monogr>
	<note>OSDI&apos;12, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Granola: low-overhead distributed transaction coordination</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 USENIX conference on Annual Technical Conference</title>
		<meeting>the 2012 USENIX conference on Annual Technical Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>USENIX ATC&apos;12, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The gamma database machine project. Knowledge and Data Engineering</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghandeharizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bricker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-I</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="44" to="62" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SQL server&apos;s memory-optimized OLTP engine</title>
		<author>
			<persName><forename type="first">C</forename><surname>Diaconu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ismert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stonecipher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zwilling</surname></persName>
		</author>
		<author>
			<persName><surname>Hekaton</surname></persName>
		</author>
		<idno>SIG- MOD&apos;13</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2013 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1243" to="1254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">FaRM: Fast remote memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dragojevi Ć</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on Networked Systems Design and Implementation</title>
		<meeting>the 11th USENIX Conference on Networked Systems Design and Implementation</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="401" to="414" />
		</imprint>
	</monogr>
	<note>NSDI&apos;14</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">No compromises: Distributed transactions with consistency, availability, and performance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dragojevi Ć</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Nightingale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Renzelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shamis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Badam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cas-Tro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles</title>
		<meeting>the 25th Symposium on Operating Systems Principles<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="54" to="70" />
		</imprint>
	</monogr>
	<note>SOSP&apos;15, ACM</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Transaction processing: Concepts and Techniques</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reuter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed transactional memory for metric-space networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Herlihy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Distributed Computing (2005), DISC&apos;05</title>
		<meeting>the 19th International Conference on Distributed Computing (2005), DISC&apos;05</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="324" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wait-free coordination for internet-scale systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Konar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Junqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><surname>Zookeeper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 USENIX Conference on USENIX Annual Technical Conference</title>
		<meeting>the 2010 USENIX Conference on USENIX Annual Technical Conference</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="11" to="11" />
		</imprint>
	</monogr>
	<note>USENIX ATC&apos;10</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using rdma efficiently for key-value services</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kalia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaminsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM Conference on SIGCOMM</title>
		<meeting>the 2014 ACM Conference on SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="295" to="306" />
		</imprint>
	</monogr>
	<note>SIG-COMM&apos;14, ACM</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Speculative byzantine fault tolerance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kotla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alvisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dahlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><surname>Zyzzyva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Twenty-first ACM SIGOPS Symposium on Operating Systems Principles (2007), SOSP&apos;07, ACM</title>
		<meeting>Twenty-first ACM SIGOPS Symposium on Operating Systems Principles (2007), SOSP&apos;07, ACM</meeting>
		<imprint>
			<biblScope unit="page" from="45" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On optimistic methods for concurrency control</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="226" />
			<date type="published" when="1981-06">June 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Vertical paxos and primary-backup replication</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lamport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Malkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM Symposium on Principles of Distributed Computing</title>
		<meeting>the 28th ACM Symposium on Principles of Distributed Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="312" to="313" />
		</imprint>
	</monogr>
	<note>PODC&apos;09, ACM</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Implementing linearizability at large scale and low latency</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kejriwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ousterhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles</title>
		<meeting>the 25th Symposium on Operating Systems Principles<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="71" to="86" />
		</imprint>
	</monogr>
	<note>SOSP &apos;15, ACM</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Implementing linearizability at large scale and low latency</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kejriwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ousterhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM Symposium on Operating Systems Principles (SOSP15)</title>
		<meeting>the 25th ACM Symposium on Operating Systems Principles (SOSP15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploiting hardware transactional memory in main-memory databases</title>
		<author>
			<persName><forename type="first">V</forename><surname>Leis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kemper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 30th International Conference on Data Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="580" to="591" />
		</imprint>
	</monogr>
	<note>ICDE&apos;14</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A data management extension architecture</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcpherson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pirahesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1987 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 1987 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="220" to="226" />
		</imprint>
	</monogr>
	<note>SIGMOD&apos;87, ACM</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modular data storage with Anvil</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mammarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hovsepian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 22Nd Symposium on Operating Systems Principles</title>
		<meeting>the ACM SIGOPS 22Nd Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="147" to="160" />
		</imprint>
	</monogr>
	<note>SOSP &apos;09, ACM</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploiting distributed version concurrency in a transactional memory cluster</title>
		<author>
			<persName><forename type="first">K</forename><surname>Manassiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mihailescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Amza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM SIG-PLAN Symposium on Principles and Practice of Parallel Programming</title>
		<meeting>the Eleventh ACM SIG-PLAN Symposium on Principles and Practice of Parallel Programming</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="198" to="208" />
		</imprint>
	</monogr>
	<note>PPoPP&apos;06, ACM</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cache craftiness for fast multicore key-value storage</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM European Conference on Computer Systems</title>
		<meeting>the 7th ACM European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="183" to="196" />
		</imprint>
	</monogr>
	<note>EuroSys&apos;12, ACM</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><surname>Mellanox Technologies</surname></persName>
		</author>
		<ptr target="http://www.mellanox.com/related-docs/prod_software/RDMA_Aware_Programming_user_manual.pdf" />
		<title level="m">RDMA aware networks programming user manual</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Open cloudserver ocs v2 specification: Ocs open cloudserver powersupply v2</title>
		<author>
			<persName><surname>Microsoft</surname></persName>
		</author>
		<ptr target="http://www.opencompute.org/wiki/Server/SpecsAndDe-signs" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Using one-sided rdma reads to build a fast, cpu-efficient key-value store</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 USENIX Conference on Annual Technical Conference</title>
		<meeting>the 2013 USENIX Conference on Annual Technical Conference</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="103" to="114" />
		</imprint>
	</monogr>
	<note>USENIX ATC&apos;13</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Extracting more concurrency from distributed transactions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of OSDI</title>
		<meeting>of OSDI</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Naiad: A timely dataflow system</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Isaacs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles (2013), SOSP&apos;13, ACM</title>
		<meeting>the Twenty-Fourth ACM Symposium on Operating Systems Principles (2013), SOSP&apos;13, ACM</meeting>
		<imprint>
			<biblScope unit="page" from="439" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Phase reconciliation for contended in-memory transactions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Narula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation</title>
		<meeting>the 11th USENIX Conference on Operating Systems Design and Implementation</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="511" to="524" />
		</imprint>
	</monogr>
	<note>OSDI&apos;14</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Atrapos: Adaptive transaction processing on hardware islands</title>
		<author>
			<persName><forename type="first">D</forename><surname>Porobic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Liarou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tozun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Engineering (ICDE), 2014 IEEE 30th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="688" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Exploiting hardware transactional memory for efficient in-memory transaction processing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>Shanghai Key Laboratory of Scalable Computing and Systems, Shanghai Jiao Tong University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Committing conflicting transactions in an stm</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Ramadan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herlihy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Witchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</title>
		<meeting>the 14th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="163" to="172" />
		</imprint>
	</monogr>
	<note>PPoPP &apos;09, ACM</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The principle of commitment ordering, or guaranteeing serializability in a heterogeneous environment of multiple autonomous resource mangers using atomic commitment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Raz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Very Large Data Bases</title>
		<meeting>the 18th International Conference on Very Large Data Bases</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="292" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Serializability by commitment ordering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Raz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information processing letters</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="257" to="264" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Nvdimm special interest group</title>
		<author>
			<persName><surname>Snia</surname></persName>
		</author>
		<ptr target="http://www.snia.org/forums/sssi/NVDIMM" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<ptr target="http://hpts.ws/papers/2013/allwrong.pdf" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">H-Store</forename><surname>The</surname></persName>
		</author>
		<author>
			<persName><surname>Team</surname></persName>
		</author>
		<ptr target="http://hstore.cs.brown.edu/documentation/deployment/benchmarks/smallbank/" />
		<title level="m">SmallBank Benchmark</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<ptr target="http://www.tpc.org/tpcc/" />
		<title level="m">THE TRANSACTION PROCESSING COUNCIL. TPC-C Benchmark V5.11</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">The Transaction Processing</forename><surname>Council</surname></persName>
		</author>
		<ptr target="http://www.tpc.org/tpce/" />
		<title level="m">TPC-E Benchmark V1.14</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fast distributed transactions for partitioned database systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Diamond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><surname>Calvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note>SIGMOD&apos;12, ACM</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Speedy transactions in multicore in-memory databases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liskov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles</title>
		<meeting>the Twenty-Fourth ACM Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
	<note>SOSP&apos;13, ACM</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">micron announce new 3d xpoint memory type that&apos;s 1,000 times faster than nand</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Ung</surname></persName>
		</author>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="http://www.pcworld.com/article/2951864/storage/intel-micron-announce-new-3dxpoint-memory-type-thats-1000-times-faster-than-nand.html" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Opportunities and pitfalls of multi-core scaling using hardware transaction memory</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Asia-Pacific Workshop on Systems (2013), APSys&apos;13, ACM</title>
		<meeting>the 4th Asia-Pacific Workshop on Systems (2013), APSys&apos;13, ACM</meeting>
		<imprint>
			<biblScope unit="page" from="3" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Using restricted transactional memory to build a scalable in-memory database</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems</title>
		<meeting>the Ninth European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note>EuroSys&apos;14, ACM</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Persistent transactional memory</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Fast in-memory transaction processing using rdma and htm</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles</title>
		<meeting>the 25th Symposium on Operating Systems Principles<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="87" to="104" />
		</imprint>
	</monogr>
	<note>SOSP &apos;15, ACM</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Salt: Combining ACID and BASE in a distributed database</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kapritsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yagh-Mazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alvisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mahajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation</title>
		<title level="s">USENIX Association</title>
		<meeting>the 11th USENIX Conference on Operating Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="495" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">High-performance acid via modular concurrency control</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Littley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alvisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kapritsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles</title>
		<meeting>the 25th Symposium on Operating Systems Principles</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="279" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Reducing false aborts in optimistic concurrency control with affordable cost for in-memory databases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Bcc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New England Database Day</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Building consistent transactions with inconsistent replication</title>
		<author>
			<persName><forename type="first">I</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szekeres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krishna-Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R K</forename><surname>Ports</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles</title>
		<meeting>the 25th Symposium on Operating Systems Principles<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="263" to="278" />
		</imprint>
	</monogr>
	<note>SOSP &apos;15, ACM</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Transaction chains: Achieving serializability with low latency in geo-distributed storage systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sovran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Aguil-Era</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles (2013), SOSP&apos;13, ACM</title>
		<meeting>the Twenty-Fourth ACM Symposium on Operating Systems Principles (2013), SOSP&apos;13, ACM</meeting>
		<imprint>
			<biblScope unit="page" from="276" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fast databases with fast durability and recovery through multicore parallelism</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation</title>
		<meeting>the 11th USENIX Conference on Operating Systems Design and Implementation</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="465" to="477" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
