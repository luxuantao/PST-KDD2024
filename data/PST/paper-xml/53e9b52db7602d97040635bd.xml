<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A privacy threat analysis framework: supporting the elicitation and fulfillment of privacy requirements</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-11-16">16 November 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mina</forename><surname>Deng</surname></persName>
							<email>mina.deng@esat.kuleuven.be</email>
						</author>
						<author>
							<persName><forename type="first">Kim</forename><surname>Wuyts</surname></persName>
							<email>kim.wuyts@cs.kuleuven.be</email>
						</author>
						<author>
							<persName><forename type="first">Riccardo</forename><surname>Scandariato</surname></persName>
							<email>riccardo.scandariato@cs.kuleuven.be</email>
						</author>
						<author>
							<persName><forename type="first">Bart</forename><surname>Preneel</surname></persName>
							<email>bart.preneel@esat.kuleuven.be</email>
						</author>
						<author>
							<persName><forename type="first">Wouter</forename><surname>Joosen</surname></persName>
							<email>wouter.joosen@cs.kuleuven.be</email>
						</author>
						<author>
							<persName><forename type="first">Á</forename><forename type="middle">B</forename><surname>Preneel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Á</forename><forename type="middle">R</forename><surname>Scandariato</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Á</forename><forename type="middle">W</forename><surname>Joosen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Electrical Engineering Department</orgName>
								<orgName type="institution">IBBT-COSIC</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">K.U. Leuven Kasteelpark</orgName>
								<address>
									<addrLine>Arenberg 10</addrLine>
									<postCode>3001</postCode>
									<settlement>Heverlee</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">IBBT-DistriNet</orgName>
								<orgName type="institution">K.U. Leuven Celestijnenlaan 200A</orgName>
								<address>
									<postCode>3001</postCode>
									<settlement>Heverlee</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A privacy threat analysis framework: supporting the elicitation and fulfillment of privacy requirements</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-11-16">16 November 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">68E59714457594D7A144FD4B568D0C6D</idno>
					<idno type="DOI">10.1007/s00766-010-0115-7</idno>
					<note type="submission">Received: 20 November 2009 / Accepted: 25 October 2010 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Privacy</term>
					<term>Threat modeling</term>
					<term>Requirements</term>
					<term>Secure software engineering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Ready or not, the digitalization of information has come, and privacy is standing out there, possibly at stake. Although digital privacy is an identified priority in our society, few systematic, effective methodologies exist that deal with privacy threats thoroughly. This paper presents a comprehensive framework to model privacy threats in software-based systems. First, this work provides a systematic methodology to model privacy-specific threats. Analogous to STRIDE, an information flow-oriented model of the system is leveraged to guide the analysis and to provide broad coverage. The methodology instructs the analyst on what issues should be investigated, and where in the model those issues could emerge. This is achieved by (i) defining a list of privacy threat types and (ii) providing the mappings between threat types and the elements in the system model. Second, this work provides an extensive catalog of privacy-specific threat tree patterns that can be used to detail the threat analysis outlined above. Finally, this work provides the means to map the existing privacyenhancing technologies (PETs) to the identified privacy threats. Therefore, the selection of sound privacy countermeasures is simplified.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Privacy becomes increasingly important in the current society. Most of the information is now digitalized to facilitate quick and easy access. It is thus extremely important that digital privacy is sufficiently protected to prevent personal information from being revealed to unauthorized subjects. A stepping stone of security and privacy analysis is threat modeling, i.e., the ''black hat'' activity of looking into what can possibly go wrong in a system. Threats are crucial to the definition of the requirements and play a key role in the selection of the countermeasures. Unfortunately, the state-of-the-art lacks systematic approaches to model privacy threats, elicit privacy requirements, and instantiate privacy-enhancing countermeasures, accordingly. Indeed, there is an asymmetry for privacy with respect to security concerns. These latter have a far better support in terms of methodological approaches to threat modeling. For instance, in the goal-oriented requirements space, KAOS <ref type="bibr">[1]</ref> provides a methodology to systematically analyze a system's anti-goals (and the corresponding refined threats) and therefore derive security requirements <ref type="bibr" target="#b23">[2]</ref>. The same holds in the area of scenario-based techniques. For instance, Microsoft's STRIDE is an industrial-level methodology to eliciting threat scenarios and, therefore, deriving security use cases <ref type="bibr" target="#b24">[3]</ref>. Notably, a significantly sized body of reusable knowledge is also available in the secure software engineering community. Security knowledge is often packaged in the shape of checklists and patterns. For instance, STRIDE comes bundled with a catalog of security threat tree patterns that can be readily instantiated in the system at hand so as to elicit a close-to-exhaustive set of potential security threats. Methodologies and knowledge are two important pillars for software security and privacy, including requirements engineering <ref type="bibr" target="#b25">[4]</ref>. Surprisingly, privacy is still lagging behind. For instance, STRIDE does not cover privacy threats.</p><p>This paper contributes to the aforementioned dimensions, in terms of methodology and knowledge, by providing a comprehensive privacy threat modeling framework. A highlevel overview of this work is sketched out in Sect. <ref type="bibr" target="#b24">3</ref>.</p><p>First, this work provides a systematic methodology to model privacy-specific threats. Analogous to STRIDE, an information flow-oriented model of the system is leveraged to guide the analysis and to provide broad coverage. The data flow diagram (DFD) notation has been selected and, for reference, it is described in Sect. 2. The methodology instructs the analyst on what issues should be investigated and where in the model those issues could emerge. This is achieved by defining a list of privacy threat types and by providing the mapping between the threat types and the elements in the system model. This part of the methodology is described in Sect. 5. Note that the privacy threat types have been identified in contrast with well-known privacy objectives, which are summarized in Sect. <ref type="bibr" target="#b25">4</ref>.</p><p>Second, this work provides an extensive catalog of privacy-specific threat tree patterns that can be used to detail the threat analysis outlined previously. In a nutshell, they refine the privacy threat types by providing concrete examples. The catalog is described in Sect. 6, while Sect. 7 illustrates how to instantiate the threat tree patterns in order to elicit the misuse cases.</p><p>An additional contribution of this paper refers to the software engineering phase. This work provides the means to map the existing privacy-enhancing technologies (PETs) to the identified privacy threats, which simplifies the selection of sound privacy countermeasures. This is described in Sect. <ref type="bibr" target="#b29">8</ref>.</p><p>Concerning the rest of the paper, the related work is presented in Sect. 9, a discussion of the proposed methodology is presented in Sect. 10, and the concluding remarks are given in Sect. 11.</p><p>2 Background: security threat modeling using STRIDE Security, in contrast to privacy, has already been well integrated in the Secure Development Lifecycle (SDL) <ref type="bibr" target="#b24">[3]</ref>, which is a well-established methodology. To build a secure software system, an important aspect is to consider how an attacker might compromise the system by exploiting design flaws and building the necessary defense mechanisms in the system. In this respect, threat modeling plays the key role, and SDL has integrated a systematic approach for security threat modeling using STRIDE. In this section, we will briefly review the STRIDE threat modeling process, which consists of nine high-level steps.</p><p>Step 1: Define use scenarios. System designers need to determine which key functionality is within the scope.</p><p>Step 2: Gather a list of external dependencies. Each application depends on the operating system it runs on, the database it uses, and so on; these dependencies need to be defined.</p><p>Step 3: Define security assumptions. In the analysis phase, decisions are often based on implicit assumptions. Therefore, it is important to note down all the assumptions, to understand the entire system comprehensively.</p><p>Step 4: Create external security notes. Because each external dependency can have its implication on security, it is useful to list all the restrictions and implications introduced by the external security notes. An example of such a security note is to specify which ports are open for database access or HTTP traffic.</p><p>Step 5: Create one or more DFDs of the application being analyzed. The software-based system being analyzed is decomposed in relevant (either logical or structural) components, and for each of these parts, the corresponding threats are analyzed. This process is repeated over an increasingly refined model until a level is reached where the residual threats are acceptable.</p><p>The system is graphically represented using a data flow diagram (DFD), with the following elements: data flows (i.e. communication data), data stores (i.e. logical data or concrete databases, files, and so on), processes (i.e. units of functionality or programs), and external entities (i.e. endpoints of the system like users, external services, and so on). For threat modeling, trust boundaries are also introduced to indicate the border between trustworthy and untrustworthy elements. An example DFD is shown in Fig. <ref type="figure" target="#fig_0">1</ref> to illustrate a use case application (Social Network 2.0) that will be discussed throughout this paper. This Social Network 2.0 application is an abstract representation of a social network, where online users share personal information such as relationship status, pictures, and comments with their friends. In the DFD, the user is represented as an entity to interact with the system. The Social Network 2.0 application contains two processes (the portal and the service) and one data store containing all the personal information of the users. The trust boundary shows that the processes, the data store, and the communication (data flows)between the two are assumed to be trustworthy in this particular setting.</p><p>Step 6: Determine threat types. The STRIDE threat taxonomy is used to identify security threat types. STRIDE is an acronym for Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, and Elevation of privilege. These threats are the negation of the main security properties, namely confidentiality, integrity, availability, authentication, authorization, and non-repudiation.</p><p>Step 7: Identify the threats to the system. Each element of the data flow diagram is assigned to a set of susceptible threats. Table <ref type="table" target="#tab_0">1</ref> gives an overview of the different DFD elements with the corresponding security threats they are subject to (marked with 9).</p><p>To identify which threats are applicable to a specific system, threat tree patterns can be used. For each valid intersection in Table <ref type="table" target="#tab_0">1</ref>, a threat tree pattern suggests the possible security-related preconditions for the STRIDE category, in order to help analysts determine the relevance of a threat for the system. An example threat tree is presented in Fig. <ref type="figure" target="#fig_1">2</ref>. Each path of the threat tree indicates a valid attack path. Note that some trees cascade. For example, the tree in Fig. <ref type="figure" target="#fig_1">2</ref> shows the conditions that could lead to tampering threats against a process. The node indicated as a circle (or oval) in the threat tree means a root threat. These are the main STRIDE threats which, indirectly, can lead to another root threat, e.g. someone can indirectly tamper with a process by spoofing an external entity. The node indicated as a rectangle suggests a concrete threat in an attack path. The arrows connecting the nodes in general refer to a OR relation among the various preconditions, unless it is indicated explicitly with ''AND'' to refer to a AND relation.</p><p>Afterward, the identified privacy threats need to be documented as misuse cases, i.e., as a collection of threat scenarios in the system.  Step 8: Determine risk. For each threat, the appropriate security risk level has to be determined, which can be used to define the priorities of the threats to be resolved.</p><p>Step 9: Plan mitigation. In the final step of the methodology, the risk of the threat is reduced or eliminated by introducing proper countermeasures and defenses. Mitigating a risk to the threat corresponds to eliminating one attack path in the threat tree. An overview of some possible mitigation technologies linked to each security property is provided.</p><p>These steps are security related and should be enhanced by the corresponding privacy perspective in order to perform a privacy threat analysis. In particular, privacy assumptions need to be specified in step 3, and external privacy notes are considered in step 4. This paper proposes privacy-specific extensions to the key steps: determining privacy threat types (step 6) in Sect. 5.1 and identifying privacy threats (step 7) in Sects. 5.2 to 7. The mitigation of privacy threats via privacyenhancing solutions (step 9) is discussed in Sect. 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Security threat modeling techniques</head><p>STRIDE comes with the main advantage of an extensive, reusable knowledge base (i.e. the threat tree patterns). However, some alternatives to elicit security threats exist.</p><p>Attack trees are similar to fault trees <ref type="bibr">[5]</ref>. The root node describes the high-level attack, which is further decomposed in lower-level attack branches. Each node represents a step that must be successfully executed in order to complete the attack represented by the parent node. Nodes can be composed of conjunctions and disjunctions. Attack trees can have both a graphical and a textual representation.</p><p>Misuse cases <ref type="bibr">[6]</ref> or abuse cases are similar to regular use cases, however, with a focus on the attacker's actions. Misuse cases have a textual representation, similar to use cases, and can also be represented in a misuse case diagram, which summarizes all existing misuse cases for a certain system and their impact on the system's use cases. Both techniques can be used to elicit security threats; these techniques however do not provide methodological guidance to discover additional threats. Opdahl and Sindre <ref type="bibr" target="#b28">[7]</ref> have made an experimental comparison between attack trees and misuse cases of which the main finding was that attack trees are more effective for finding threats. Attack trees encourage the use of standard textbook threats and decomposition in lower-level threats. Misuse case analysis focuses more on user-level and organizational threats.</p><p>KAOS [1], a goal-oriented requirements analysis framework, has been extended with anti-goals to support the modeling of threats. Such anti-goals express the goals of an attacker who tries to abuse the system. Although no actual methodology exists to determine the threats, the root anti-goals are created by negating all the positive system goals. Next, the anti-goals are refined into trees. The formal nature of KAOS is an advantage that makes it possible to determine completeness of the (anti-)goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our approach-the LINDDUN methodology</head><p>In this work, we propose a systemic approach for privacy threat modeling-the LINDDUN methodology-to elicit the privacy requirements of software-intensive systems and select privacy-enhancing technologies accordingly. Each letter of ''LINDDUN'' stands for a privacy threat type obtained by negating a privacy property. Privacy properties and threats types are briefly described in Sects. 4 and 5, respectively.</p><p>Figure <ref type="figure">3</ref> depicts the building blocks of LINDDUN. In the figure, a distinction is marked between the proposed Fig. <ref type="figure">3</ref> The LINDDUN methodology and the required system-specific knowledge methodology and the supporting knowledge provided to assist each step. First of all, a data flow diagram is created based on the high-level system description. This is followed by mapping privacy threats to the DFD elements using Table <ref type="table">4</ref> as a guide to determine the corresponding threats. In particular, a number of privacy tree patterns from Sect. 6 will be proposed to detail the privacy threat instances in a designated system, by providing an overview of the most common preconditions of each threat. Next, the identified privacy threats that are relevant to the designated system are documented as misuse cases (cf. Sect. 7). A misuse case presents a collection of threat scenarios in the system.</p><p>The identified privacy threats that need to be evaluated and prioritized via risk assessment. Indeed, due to both time and budget constraints, not all threats are worthy of further treatment. Note that details on the risk-analysis process are beyond the scope of this work.</p><p>The last two steps comprise so-called ''white hat'' activities. The privacy requirements of the system are elicited from the misuse cases following the mapping in Table <ref type="table" target="#tab_4">6</ref>. Finally, appropriate privacy-enhancing solutions are selected according to the privacy requirements. Table <ref type="table" target="#tab_5">7</ref> provides an overview of the state-of-art techniques and the mapping to their corresponding privacy objectives.</p><p>The fact that the LINDDUN framework and STRIDE are based on similar approaches creates synergy. Therefore, the privacy and security analysis can be closely integrated into the SDL. Nevertheless, the aforementioned LINDDUN framework for privacy can be performed independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Privacy properties</head><p>It is not the intention to propose a new taxonomy of privacy definitions in this paper. However, it is crucial to have the right basis for the proposed LINDDUN framework; therefore, definitions of privacy properties are elaborately studied and reviewed in this section. The literature is rich in studies to conceptualize privacy, and we refer interested readers to the work by Solove <ref type="bibr" target="#b29">[8,</ref><ref type="bibr">9]</ref> for a comprehensive understanding of privacy. Most privacy properties in the LINDDUN framework comply with the terminology proposed by Pfitzmann et al. <ref type="bibr" target="#b31">[10]</ref>, as is widely recognized in the privacy research community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Understanding privacy: hard privacy vs. soft privacy</head><p>As an abstract and subjective concept, the definition of privacy varies depending on social and cultural issues, study disciplines, stakeholder interests, and application context. Popular privacy definitions include ''the right to be let alone'', focusing on freedom from intrusion, and ''the right to informational self-determination'', allowing individuals to ''control, edit, manage, and delete information about themselves and decide when, how, and to what extent that information is communicated to others'' <ref type="bibr" target="#b32">[11]</ref>.</p><p>Privacy can be distinguished as hard privacy and soft privacy, as proposed by Danezis <ref type="bibr" target="#b33">[12]</ref>. The data protection goal of hard privacy refers to data minimization, based on the assumption that personal data are not divulged to third parties. The system model of hard privacy is that a data subject (as a security user) provides as little data as possible and tries to reduce the need to ''trust'' other entities. The threat model includes service provider, data holder, and adversarial environment, where strategic adversaries with certain resources are motivated to breach privacy, similar to security systems. Soft privacy, on the contrary, is based on the assumption that data subject lost control of personal data and has to trust the honesty and competence of data controllers. The data protection goal of soft privacy is to provide data security and process data with specific purpose and consent, by means of policies, access control, and audit. The system model is that the data subject provides personal data, and the data controller (as a security user) is responsible for the data protection. Consequently, a weaker threat model applies, including different parties with inequality of power, such as external parties, honest insiders who make errors, and corrupt insiders within honest data holders. An overview of hard and soft privacy solutions will be given in Sect. 8.</p><p>Besides conceptualizing privacy, another research challenge is to define privacy properties in software-based systems. Some classical security properties are desired for building in privacy, including confidentiality (ensuring that information is accessible only by authorized parties), integrity (safeguarding the accuracy and completeness of information and processing methods), availability (or censorship resistance, ensuring information is accessible to authorized users), and non-repudiation (ensuring one not be able to deny what one has done). The definitions of these properties can be found in ISO 17799 <ref type="bibr" target="#b34">[13]</ref>.</p><p>In addition, a number of properties are also appreciated, including anonymity (hiding links between identity and action or a piece of information), unlinkability (hiding link between two or more actions, identities and pieces of information), undetectability (or covertness) and unobservability (hiding user's activity), plausible deniability (opposite as non-repudiation, no others can prove one has said or done something), and forward security (also referred as forward secrecy and freedom from compulsion, meaning that once the communication is securely over, it cannot be decrypted any more).</p><p>We decided to include the following privacy properties in the proposed framework, namely unlinkability, anonymity and pseudonymity, plausible deniability, undetectability and unobservability, and confidentiality (hiding data content, including access control) as hard privacy properties; user content awareness (including feedback for user privacy awareness, data update and expire) together with policy and consent compliance as soft privacy properties. These properties are described in the following sections. Note that properties such as integrity, availability, and forward security are also important for privacy. However, we consider them as typical security properties; hence, they are to be considered in the security engineering framework, such as STRIDE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Unlinkability</head><p>The unlinkability property refers to hiding the link between two or more actions, identities, and pieces of information. Examples of unlinkability include hiding links between two anonymous messages sent by the same person, two web page visits by the same user, entries in two databases related to the same person, or two people related by a friendship link in a social network.</p><p>Unlinkability is defined Pfitzmann et al. as <ref type="bibr" target="#b31">[10]</ref>: ''Unlinkability of two or more items of interest (IOIs, e.g., subjects, messages, actions, …) from an attackers perspective means that within the system (comprising these and possibly other items), the attacker cannot sufficiently distinguish whether these IOIs are related or not.'' Although it is not explicitly mentioned, the definition of unlinkability implies that the two or more IOIs are of the comparable types, otherwise it is infeasible to make the comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Anonymity</head><p>Essentially, the anonymity property refers to hiding the link between an identity and an action or a piece of information. Examples are anonymous sender of an email, writer of a text, person accessing a service, person to whom an entry in a database relates, and so on.</p><p>Anonymity is defined as <ref type="bibr" target="#b31">[10]</ref>: ''Anonymity of a subject from an attackers perspective means that the attacker cannot sufficiently identify the subject within a set of subjects, the anonymity set.'' Anonymity can also be described in terms of unlinkability. If one considers sending and receiving of messages as attributes; the items of interest (IOIs) are who has sent or received which message. Then, ''anonymity of a subject with respect to an attribute may be defined as unlinkability of this subject and this attribute.'' For instance, sender anonymity of a subject means that to this potentially sending subject, each message is unlinkable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Pseudonymity</head><p>The pseudonymity property suggests that it is possible to build a reputation on a pseudonym and possible to use multiple pseudonyms for different purposes. Examples include a person publishes comments on social network sites under different pseudonyms and a person uses a pseudonym to subscribe to a service.</p><p>Pfitzmann et al. <ref type="bibr" target="#b31">[10]</ref> defines pseudonymity as: ''A pseudonym is an identifier of a subject other than one of the subjects real names. Pseudonymity is the use of pseudonyms as identifiers. A subject is pseudonymous if a pseudonym is used as identifier instead of one of its real names.'' Pseudonymity can also be perceived with respect to linkability. Whereas anonymity and identifiability (or accountability) are the extremes with respect to linkability to subjects, pseudonymity is the entire field between and including these extremes. Thus, pseudonymity comprises all degrees of linkability to a subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Plausible deniability</head><p>For privacy, plausible deniability refers to the ability to deny having performed an action that other parties can neither confirm nor contradict. Plausible deniability from an attackers perspective means that an attacker cannot prove a user knows, has done or has said something. Sometimes, depending on the application, plausible deniability is desirable over non-repudiation; for instance, in an application used by whistleblowers, users will want to deny ever sent a certain message to protect their safety. Other examples include off-the-record conversations, possibility to deny the existence of an encrypted file, deny that a file is transmitted from a data source, or deny that a database record belongs to a person.</p><p>The relation between non-repudiation and plausible deniability is according to Roe in <ref type="bibr" target="#b35">[14]</ref>: ''The goal of the non-repudiation service is to provide irrefutable evidence concerning the occurrence or non-occurrence of an event or action. If we believe that there is a need for this as a security service <ref type="bibr">[…]</ref> we must also concede that some participants desire the opposite effect: that there be no irrefutable evidence concerning a disputed event or action.'' This ''complementary service'' is plausible deniability. In particular, it ensures that ''an instance of communication between computer systems leaves behind no unequivocal evidence of its having taken place. Features of communications protocols that were seen as defects from the standpoint of non-repudiation can be seen as benefits from the standpoint of this converse problem, which is called plausible deniability.''</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Undetectability and unobservability</head><p>The undetectability and unobservability properties refer to hiding the user's activities. Practical examples include, it is impossible to know whether an entry in a database corresponds to a real person, or to distinguish whether someone or no one is in a given location.</p><p>Undetectability is defined as <ref type="bibr" target="#b31">[10]</ref>: ''Undetectability of an item of interest (IOI) from an attackers perspective means that the attacker cannot sufficiently distinguish whether it exists or not. If we consider messages as IOIs, this means that messages are not sufficiently discernible from, e.g., random noise.'' For anonymity and unlinkability, not the IOI, but only its relationship to the subject or other IOIs is protected. For undetectability, the IOIs are protected as such.</p><p>Undetectability by uninvolved subjects together with anonymity even if IOIs can be detected is defined as unobservability <ref type="bibr" target="#b31">[10]</ref>: ''Unobservability of an item of interest (IOI) means undetectability of the IOI against all subjects uninvolved in it and anonymity of the subject(s) involved in the IOI even against the other subject(s) involved in that IOI.'' The definition suggests that unobservability is undetectability by uninvolved subjects AND anonymity even if IOIs can be detected. Consequently, unobservability implies anonymity, and unobservability implies undetectability. It means, with respect to the same attacker, unobservability reveals always only a subset of the information anonymity reveals. Later sections of this paper will focus on undetectability, since unobservability is in fact a combination of undetectability and anonymity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Confidentiality</head><p>The confidentiality property refers to hiding the data content or controlled release of data content. Examples include transferring encrypted email, applying access control to a classified document or a database containing sensitive information.</p><p>NIST <ref type="bibr" target="#b36">[15]</ref> describes confidentiality as following: Confidentiality means preserving authorized restrictions on information access and disclosure, including means for protecting personal privacy and proprietary information. Although confidentiality is a security property, as the definition above states, it is also important for preserving privacy properties, such as anonymity and unlinkability. Therefore, confidentiality is also considered an important privacy property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Content awareness</head><p>Unlike the aforesaid classical privacy properties, to our knowledge, the following two properties, namely content awareness, and policy and consent compliance, are not explicitly defined in the literature. However, we consider them important privacy objectives, due to their significance to privacy and data protection. With the emerging of Web 2.0 technologies, users tend to provide excessive information to service providers and lose control of their personal information. Therefore, the content awareness property is proposed to make sure that users are aware of their personal data and that only the minimum necessary information should be sought and used to allow for the performance of the function to which it relates.</p><p>The more personal identifiable information a data subject discloses is the higher is the risk for privacy violation. To ensure content awareness, a number of technical enforcement tools have been developed. For instance, the concept of personal information feedback tools has been promoted <ref type="bibr" target="#b37">[16,</ref><ref type="bibr" target="#b38">17]</ref> to help users gain privacy awareness and self-determine which personal data to disclose.</p><p>The Platform for Privacy Preferences Project (P3P) <ref type="bibr" target="#b39">[18]</ref> has been designed to allow Websites (as data controllers) to declare their intended use of the information that they collected about the browsing users (as data subjects). P3P addresses the content awareness property by making users aware of how personal data are processed by the data controller.</p><p>Although not necessarily privacy oriented, another responsibility of the user, within the realm of content awareness objective, is to keep user's data up-to-date to prevent wrong decisions based on incorrect data. This means that the data subject or the data controller (depends on applications) is responsible for deleting and updating inaccurate information. For example, it is crucial to maintain patient's data in e-health applications. Imagine a doctor forgetting to mention that the patient is a diabetic, the absence of information could cause fatal consequences for patients taking medication without considering negative side effects on diabetics.</p><p>To summarize, the content awareness property focuses on the user's consciousness regarding his own data. The user needs to be aware of the consequences of sharing information. These consequences can refer to the user's privacy, which can be violated by sharing too much personal identifiable information, as well as to undesirable results by providing incomplete or incorrect information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Policy and consent compliance</head><p>Unlike the content awareness property focused on the user, the policy and consent compliance property requires the whole system-including data flows, data stores, and processes-as data controller to inform the data subject about the system's privacy policy, or allow the data subject to specify consents in compliance with legislation, before users accessing the system. According to the definitions from the EU Directive 95/46/EC <ref type="bibr" target="#b40">[19]</ref>: ''Controller shall mean the natural or legal person, public authority, agency or any other body which alone or jointly with others determines the purposes and means of the processing of personal data.'' ''The data subject's consent shall mean any freely given specific and informed indication of his wishes by which the data subject signifies his agreement to personal data relating to him being processed.''</p><p>A policy specifies one or more rules with respect to data protection. These are general rules determined by the stakeholders of the system. Consents specify one or more data protection rules as well; however, these rules are determined by the user and only relate to the data regarding this specific user. The policy and consent compliance property essentially ensures that the system's policy and the user's consent, specified in textual form, are indeed implemented and enforced.</p><p>This property is closely related to legislation. There are a number of legal frameworks addressing the raised concerns of data protection, such as the Health issued the Insurance Portability and Accountability Act (HIPAA) <ref type="bibr" target="#b41">[20]</ref> in the United States, the Data Protection Directive 95/46/ EC <ref type="bibr" target="#b40">[19]</ref> in Europe, the Personal Information Protection and Electronic Documents Act and Privacy Act <ref type="bibr" target="#b42">[21]</ref> in Canada, the Commonwealth Privacy Act 1988 and Privacy Amendment (Private Sector) Act 2000 <ref type="bibr" target="#b43">[22]</ref> in Australia, and the OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data <ref type="bibr" target="#b44">[23]</ref>.</p><p>One example of consent compliance is in e-health, for some countries, health care professionals are not allowed to intervene until the data subject has given informed consent for medical treatment.</p><p>There are initiatives to protect data subjects and create openness; however, it is evidently important to ensure that internal rules actually comply with that promised in policies and consents. Unfortunately, few technical solutions exist to guarantee the compliance. A possible non-technical solution is to use employee contracts to enforce penalties (e.g., get fired or pay fines) to ensure compliance. Another solution is to hire an auditor to check policies compliance. Eventually, necessary legal actions can be taken by data subjects in case of non-compliance.</p><p>Breaux et al. <ref type="bibr" target="#b45">[24]</ref> pointed out that to ensure a product that complies with its privacy and security goals, legal requirements need to be identified and refined into product requirements, and the product requirements need to be integrated into the ongoing product design and testing processes. They presented an industry case study in which requirements of Cisco products were specified to comply with Section 508 of the U.S. Workforce Investment Act (WIA) of 1998 <ref type="bibr" target="#b46">[25]</ref>. They developed a set of qualitative metrics to rationalize the comparison of two requirements.</p><p>These metrics demonstrate that alignments between legal and product requirements can be described in detail by using the goal-oriented concept of refinement. Their analysis revealed that a frame-based requirements analysis method <ref type="bibr" target="#b47">[26]</ref>, which itemizes requirements and preserves legal language, is useful to incorporate legal requirements into a manufacturer's compliance framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Mapping privacy threats to DFD</head><p>In this section, we present the privacy threat categories based on the above-mentioned privacy properties. We also discuss how to map these categories to the DFD elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Privacy threat categories</head><p>As shown in Table <ref type="table" target="#tab_1">2</ref>, the methodology considers seven types of threats. LINDDUN is the mnemonic acronym that we use.</p><p>The following section describes LINDDUN components: 1. Linkability of two or more items of interest (IOIs, e.g., subjects, messages, actions, etc.) allows an attacker to sufficiently distinguish whether these IOIs are related or not within the system. 2. Identifiability of a subject means that the attacker can sufficiently identify the subject associated to an IOI, for instance, the sender of a message. Usually, identifiability refers to a set of potential subjects, called the identifiability set <ref type="bibr" target="#b31">[10]</ref>. In essence, identifiability is a special case of linkability when a subject and its attributes are involved. Identifiability is a threat to both anonymity and pseudonymity. 3. Non-repudiation, in contrast to security, this is a threat for privacy. Non-repudiation allows an attacker to of the information disclosed to the system. The user either provides too much information which allows an attacker to easily retrieve the user's identity or inaccurate information which can cause wrong decisions or actions. 7. Policy and consent Non-compliance means that even though the system shows its privacy policies to its users, there is no guarantee that the system actually complies with the advertised policies. Therefore, the user's personal data might still be revealed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Mapping privacy threat categories to the system</head><p>This section provides the guidelines to identify privacy threats of a software-based system. First, a data flow diagram (DFD) is created in correspondence with the application's use case scenarios. Second, privacy threats are mapped to the DFD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Creating application DFD based on use case scenarios</head><p>DFD is chosen to represent a software system based on two reasons. First, DFD is proven to be sufficiently expressive in a number of case studies examined by the authors. Second, DFD is also used by the SDL threat modeling process; hence, by deploying the same modeling technique, an interesting synergy can be created between the proposed framework and the SDL process.</p><p>Running example: Social Network 2.0 In our running example Social Network 2.0, Alice is a registered user of a social network. Each time Alice updates her friends list, she first connects to the social network's web portal. Accordingly, the portal communicates with the social network's server, and eventually, the friendship information of Alice and all other users of that social network is stored in a database.</p><p>The DFD for the Social Network 2.0 application was already presented in Fig. <ref type="figure" target="#fig_0">1</ref> of Sect. 2. Table <ref type="table" target="#tab_2">3</ref> lists the DFD elements.</p><p>The creation of the DFD is an important part in the analysis. If the DFD was incorrect, the analysis results would be wrong as well. Since privacy focuses on the protection of user's personal information, it is important to consider where the information will be stored or passed by, as these are the crucial elements for building in privacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Mapping privacy threats to DFD</head><p>After the DFD elements are listed, we identify the privacy threat categories for each DFD element by following the mapping depicted in Table <ref type="table">4</ref>. Each intersection marked with the symbol 9 indicates a potential privacy threat at a corresponding DFD element in the system.</p><p>In essence, each DFD element is subject to certain privacy threats, and the nature of the potential privacy threat is determined by the DFD element type. For example, a data flow is subject to a number of privacy threats such as identifiability, linkability, detectability, non-repudiation, and information disclosure. The following sections will explain how privacy threats affect DFD elements. More threat scenarios corresponding to our running example will be discussed in Sect. 7.</p><p>The nature of linkability indicates that the threat affects DFD elements by pair. In other words, linkability of a DFD element refers to a pair ðx 1 ; x 2 Þ, where x [ {E, DF, DS, P} is the linkable IOI. Obviously, linkability at entity, from an attackers perspective means that within the system (comprising these and possibly other items), the attacker can sufficiently distinguish whether these entities are related or not. Similar description applies for that of data flow, data store, and process. The identifiability threat affects all four DFD elements, such that each DFD element is made explicit as the attributes that identifiability (or its opposite property anonymity) relates to, by forming a pair with a subject. Essentially, identifiability at each DFD element refers to a pair (x, y), where x [ {E} is the identifiable subject, and y [ {E, DS, DF, P} is the attribute identifiability relates to. For example, identifiability at entity refers to a pair (E, E), meaning to identify an entity within a set of entities. Identifiability at data flow refers to a pair (E, DF), meaning that a message is linkable to a potentially sending or receiving subject. Identifiability at data store refers to a pair (E, DS), meaning that a database entry is linkable to a potential data holder or subject. Identifiability at process refers to a pair (E, P), meaning that a process is linkable to a potentially accessing subject.</p><p>Non-repudiation, opposite of plausible deniability, is a privacy threat that affects the DFD elements of data flow, data store and process. Non-repudiation might be appreciated for some system but undesirable for others. It depends on the system requirements. For e-commerce applications, non-repudiation is an important security property. Imagine a situation where a buyer signs for a purchased item upon receipt, the vendor can later use the signed receipt as evidence that the user received the item. For other applications, such as off-the-record conversations, participants may desire plausible deniability for privacy protection such that there will be no record to demonstrate the communication event, the participants and the content. In this scenario, non-repudiation is a privacy threat. Even though entity is the only DFD element being able to (non-)repudiate, the non-repudiation privacy threat actually occurs at data flow, data store, and process. Similar to linkability and identifiability, non-repudiation at each DFD element refers to a pair (x, y), where x [ {E} is the non-repudiating subject, and y [ {DS, DF, P} is the attribute it relates to.</p><p>Detectability threats occur at data flow, data store, and process, meaning that the attacker can sufficiently distinguish whether it exists or not. Though in some applications, techniques such as covert channel and steganography can be used to protect both messages (data flow) and communicating parties (entity), in this case, the threat actually occurs at data flow instead of entity. In other words, the asset we want to protect against the detectability threat includes data flow, data store, and process.</p><p>Information disclosure threats affect data flow, data store, and process, referring to the exposure of information at these DFD elements to individuals who are not supposed to have access to it.</p><p>The content unawareness threat is related to entity, since the entity (data subject or data controller) is actually responsible to provide the necessary consents to process personal data and update or delete the expired information.</p><p>Policy and consent non-compliance is a threat that affects system as a whole, because each system component (including data flow, data store and process) is responsible to ensure that actions are taken in compliance with privacy policies and data subject's consents.</p><p>Running example: Social Network 2.0 Considering the Social Network 2.0 application, the list of generic privacy threats to the modeled system is depicted in Table <ref type="table" target="#tab_3">5</ref>. This is obtained by gathering the elements from Table <ref type="table" target="#tab_2">3</ref> and then determining the susceptible threats with Table <ref type="table">4</ref>.</p><p>The intersections marked with 9 in Table <ref type="table" target="#tab_3">5</ref> are potential threats that have been considered as irrelevant to the specific usage scenario. Each intersection that is indicated with a number (1-10) in Table <ref type="table" target="#tab_3">5</ref> shows that there will be a privacy threat at the corresponding DFD element. These items marked with a number are the threats that we will actually consider. The number represents the ID of the generic threat and will be used later for ease of reference.</p><p>Primarily, we assume that DFD elements within the trust boundary (marked as dashed line in Fig. <ref type="figure" target="#fig_0">1</ref>) are trustworthy. We trust the processes within the boundary, as well as all data flows in the trust boundary. Therefore, we will not discuss linkability, identifiability, and information disclosure threats on these elements. We however do not trust the user and its communication with the portal and we also want to protect the data store containing all the user's information.</p><p>Moreover, non-repudiation and detectability threats are considered irrelevant for social networks. Presumably, it depends on what privacy properties are required for a particular social network system. In case plausible deniability and undetectability would be desirable for a certain application, we should still consider these threats for each DFD element accordingly.</p><p>Following the above reasoning, ten threats will be examined in detail in Sect. 7, and they are numbered in Table <ref type="table" target="#tab_3">5</ref>. Note that some items are indicated with a 10*. This means that the policy and consent non-compliance threat affects the system as a whole (including data flow, data store and process). However, we will only illustrate one misuse case for this threat in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Detailing privacy threats via threat tree patterns</head><p>This section presents an extensive catalog of threat tree patterns that can be used to detail the privacy threats to a realistic system. For each marked intersection in Table <ref type="table">4</ref>, a threat tree pattern exists showing the detailed preconditions for this specific threat category to materialize. The preconditions are hence vulnerabilities that can be exploited for a privacy attack scenario.</p><p>The present catalog is based on the state-of-art privacy developments, and the threat trees reflect common attack patterns and help application designers think about privacy conditions in the system. However, the threat trees depicted in this section present the best effort so far. The catalog is subject to continuous improvement in order to reflect newly discovered threats. Further, the catalog is meant to be updated as new results are available from the industrial validation experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Linkability of entity</head><p>Linkability of entity refers to an attacker can sufficiently distinguish whether two or more entities are related or not within the system. This implies that different pseudonyms can be linked to each other. The threat tree pattern is depicted in Fig. <ref type="figure">4</ref>. One precondition is that data flow or data store is not fully protected (e.g. unencrypted), which leads to the information disclosure threat of data flow and data store. The second precondition is that personal identifiable information (PII) can be linked, e.g. based on user temporary ID, IP address, behavioral patterns such as time, frequency and location, session ID, identifier and biometrics, computer ID, communication content or any combination of these factors. The aforementioned data store refers to the identity management system's database or any other database that contains personal identifiers of users. Having accessed such a data store, the attacker could easily link different pseudonyms to the same user. Linkability of data flow threat tree, as presented in Fig. <ref type="figure" target="#fig_3">5</ref>, suggests two preconditions. One precondition is that data flows are not fully protected (e.g. unencrypted), which leads to information disclosure of data flow; and communications are linkable due to little or insecure anonymity systems deployed. The other precondition is that communication can be linked. When no anonymous communication is deployed, basically the same preconditions apply as for the linkability of entity threat. Messages are linked to each other by user's identifiable information (e.g. based on user temporary ID, IP address, behavioral patterns such as time, frequency and location, session ID, identifier and biometrics, computer ID, communication content or any combination of these factors). Alternatively, when an insecure anonymity system is deployed, traffic analysis is possible to extract information out of patterns of traffic; passive attacks (e.g. long-term intersection attacks, traffic correlation and confirmation, fingerprinting, epistemic attacks (route selection), and predecessor attacks) and active attacks (e.g. N-1 attacks, Sybil attack, traffic watermarking, tagging attack, replay, and DoS attack) are possible to link entities together. An overview of these attacks can be found in <ref type="bibr" target="#b48">[27]</ref>.</p><p>6.3 Linkability of data store Two preconditions correspond to the threat of linkability of a data store, as shown in Fig. <ref type="figure">6</ref>. First, there is insufficient access control of the data store leading to the information disclosure threat at a data store. Second, insufficient data anonymization is applied or strong data mining is possible in the data store, meaning that the stored information still contains sufficient references to the corresponding data subject, which makes it possible to link different data items to each other within the same database. Another possibility is that data can be linked from one database to another, and hence, re-identification <ref type="bibr" target="#b49">[28]</ref> is possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Linkability of process</head><p>The threat tree of linkability of process suggests that the only way to prevent different actions being linked to the same subject is by gaining access to the process, as illustrated in Fig. <ref type="figure" target="#fig_8">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Identifiability of entity</head><p>Figure <ref type="figure" target="#fig_9">8</ref> shows the threat tree pattern for identifiability of entity. It gives an overview of the most common situations where an identifiability threat can occur at an entity. A first precondition is when the e-id is used as login (i.e., the user's actual identity is used); meanwhile, the data flow between the user and login portal is not sufficiently protected (i.e., the threat of information disclosure of data flow), and thus, the user's identity will be exposed. A second possibility occurs when a secret (e.g. a password) is used as log-in, and the relationship between this secret and the user can be revealed. This can happen if the identity management database is not secure (e.g. passwords are stored in clear); if the communication channel is insecure and the communicated passwords are weak and can be connected to the user (e.g. using a birthdate as password); or if replay attacks are possible (e.g. a keylogger is installed, the communication can be eavesdropped or the person entering the secret can be observed). A third possible precondition for the threat is the use of a token as login, which is weakly implemented or physically insecure. The final precondition is that biometrics is used as log-in, which means that biometrics is retrievable and can be linked to an entity. It is due to information disclosure of identity management database or data flow, which contains biometrics and linkability at data store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Identifiability of data flow</head><p>The threat tree of identifiability of data flow is presented in Fig. <ref type="figure">9</ref>. Similar to the linkability of data flow threat tree, identifiability of data flow is possible when data flows are not fully protected, which leads to information disclosure of data flow, or when the communication can be traced to an entity due to little or insecure anonymity system deployed. When no anonymity system is deployed, communication can be traced to an entity by means of identifiable information (e.g. based on user temporary ID, IP address, behavioral patterns such as time, frequency and location, session ID, identifier and biometrics, computer ID, communication content or any combination of these factors). Alternatively, when an insecure anonymity system is deployed, traffic analysis, passive attacks, and active attacks <ref type="bibr" target="#b48">[27]</ref> are possible to identify the particular entity of interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Identifiability of data store</head><p>The preconditions for identifiability of data store, as presented in Fig. <ref type="figure" target="#fig_0">10</ref>, are similar to the preconditions of linkability at a data store. Either there is insufficient access control of the data store, which refers to the information disclosure threat of a data store, or insufficient data anonymization or strong data mining techniques were applied in the data store, which means that the information stored still contains sufficient references to the corresponding person to reveal the person's identity, and hence, it refers to the identifiability threat of entity or the data can be linked with other relevant information, which can lead to re-identification of the data subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8">Identifiability of process</head><p>The threat tree of identifiability of process is presented in Fig. <ref type="figure" target="#fig_0">11</ref>. The only condition for the identifiability threat at a process is when access to the process is not sufficiently secured, and thus, it refers to the threat of information disclosure of a process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.9">Non-repudiation of data flow</head><p>Four general preconditions can be applied to the threat tree of non-repudiation of data flow, as presented in Fig. <ref type="figure" target="#fig_1">12</ref>. One condition is insufficient obfuscation for data sources or data flows, which means that the attacker can gain access to at least part of the data flow or data source. This can occur in a number of cases, for example, there is no automatic Fig. <ref type="figure">6</ref> Threat tree for linkability of a data store Fig. <ref type="figure" target="#fig_8">7</ref> Threat tree for linkability of a process replay of broadcasts, such that the sender of a file is sufficiently distinguishable from those who are merely relaying it. Another example is when a complete decrypted log of all network connections to and from a user's computer is disclosed, resulting in the disclosure of the origin of data flow. The final examples are that there is insufficient protection against censors or insufficient obfuscation of data extensions, such that operators or users of the network are able to know where the data comes from.</p><p>The second precondition of this threat is that little or a weak deniable encryption technique is used to protect data flow. One possible attack path is to prove data are Fig. <ref type="figure" target="#fig_9">8</ref> Threat tree for identifiability of an entity Fig. <ref type="figure">9</ref> Threat tree for identifiability of a data flow encrypted, either due to the encrypter proves the data are obviously an encryption or colluding users prove together that the data is encrypted. The second attack path is to prove data can be decrypted to a valid plain text, which can occur when the encrypter decrypts the file or colluding users can cooperate and show the decrypted message. The third attack path shows that all private keys are disclosed, and the last path suggests that cryptanalysis is possible to attack the used encryption scheme.</p><p>The third condition is that there are little or weak message authentication codes (MAC) used to ensure integrity of data flow content, such that an attacker can forge authentic looking messages and pretend that a certain data flow comes from a subject.</p><p>The final precondition indicates that there is little or a weak Off-the-Record Messaging (OTR) used, such that in a conversation, it is not possible to provide both deniability for the conversation participants and confidentiality of conversations content at the same time. Possible attack paths include replaying of previous transferred messages, and the use of signatures to demonstrate communication events, participants and communication content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.10">Non-repudiation of data store</head><p>The threat tree for non-repudiation of data store is depicted in Fig. <ref type="figure" target="#fig_0">13</ref>. Three preconditions can apply to this threat, namely a weak access control to the database, which leads to the threat of information disclosure at the data store; little or a weak deniable encrypted is used to protect the data, such that data can be proven to be an encryption or can be decrypted to a valid plaintext; and subjects with deniability are not able to edit data in the database to cover their tracks, and it can be either impossible to remove or Fig. <ref type="figure" target="#fig_0">10</ref> Threat tree for identifiability of a data store Fig. <ref type="figure" target="#fig_0">11</ref> Threat tree for identifiability of a process Fig. <ref type="figure" target="#fig_1">12</ref> Threat tree for nonrepudiation of a data flow alter the user's own data or impossible to remove or alter someone else's data concerning the user himself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11">Non-repudiation of process</head><p>Non-repudiation of process, as depicted in Fig. <ref type="figure" target="#fig_0">14</ref> can be achieved in two ways: either the process looses its confidentiality and information disclosure attacks at the process are possible, or the process uses a secure log to create an overview of all actions, which can evidently be traced back to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.12">Detectability of data flow</head><p>The threat tree of detectability of data flow, as depicted in Fig. <ref type="figure" target="#fig_7">15</ref>, suggests five preconditions for the threat to occur. One condition is that the system lacks a covert channel. This can happen when the covert channel uses too much bandwidth from a legitimate channel, resulting in the detection of the covert communication. It can also be because the patterns or characteristics of the communications medium of the legitimate channel are controlled or examined by legitimate users, e.g. checking file opening and closing operations patterns or watching the timing of requests, such that covert communication is detected. The second condition is side channel analysis on timing information, power consumption, electromagnetic leaks, as an extra source of information, which can be exploited to detect the communication. The third condition occurs when a weak information hiding technique is used, which makes a number of steganalysis attacks possible. Another condition is when there is no or insufficient dummy traffic sent at some lower layer of communication network, such that messages fail to appear random for all parties except the sender and the recipient(s). Last but not least, the threat can occur because of a weak spread spectrum communication, resulting in deficiencies in the establishment of secure communications, resistance to natural interference and jamming, and detection prevention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.13">Detectability of data store</head><p>As shown in Fig. <ref type="figure" target="#fig_0">16</ref>, detectability threats in a data store can occur if there is insufficient access control, which leads to the information disclosure threats for security, or if insufficient information hiding techniques are applied, such as information from a data store is revealed due to weak steganography algorithms employed.  <ref type="figure" target="#fig_0">13</ref> Threat tree for nonrepudiation of a data store Fig. <ref type="figure" target="#fig_0">14</ref> Threat tree for non-repudiation of a process 6.14 Detectability of process Similar to the previously described threats related to a process, the detectability of process threat, depicted in Fig. <ref type="figure" target="#fig_8">17</ref>, also refers to the threat of information disclosure of process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.15">Information disclosure of data flow, data store, and process</head><p>The threat tree concerning information disclosure of data flow, data store, and process, depicted in Fig. <ref type="figure" target="#fig_9">18</ref>, refers to the security threat tree of information disclosure. This illustrates the fact that privacy properties are part of security properties, and privacy may depend on security. For more information about the information disclosure threats, we refer to SDL <ref type="bibr" target="#b24">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.16">Content unawareness of entity</head><p>Content unawareness of an entity can occur in two situations: either the date subject provides more personal identifiable information than required, which has a negative influence on all the hard privacy objectives; or data subject does not keep information updated or does not remove the outdated information, and it can lead to wrong actions when decisions are based on this information. (Fig. <ref type="figure" target="#fig_0">19</ref>)</p><p>6.17 Consent and policy non-compliance of the system (data flow, process, and data store)</p><p>The user's privacy can be violated when internal system rules do not correspond to privacy policies provided to the Fig. <ref type="figure" target="#fig_7">15</ref> Threat tree for detectability of a data flow Fig. <ref type="figure" target="#fig_0">16</ref> Threat tree for detectability of a data store Fig. <ref type="figure" target="#fig_8">17</ref> Threat tree for detectability of a process user. This can occur when an attacker tampers with the internal policies, which is actually a security threat; or when the policy rules are incorrectly managed or updated (according to the user's requests) by the system administrator. (Fig. <ref type="figure" target="#fig_1">20</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Documenting threats scenarios in misuse cases</head><p>Threat tree patterns are used to detail the generic LIND-DUN threat categories into specific threat instances that can occur in a system. Furthermore, some threat instances could have been discarded during the risk-analysis step. The result of the above process should be a collection of threat scenarios that need to be documented. To this aim, misuse cases can be used. In particular, a misuse case can be considered as a use case from the misactor's point of view.</p><p>A misactor is someone who intentionally or unintentionally initiates the misuse case. Alexander <ref type="bibr" target="#b50">[29]</ref> provides some example misuse cases, together with the corresponding (positive) use cases. We chose misuse cases because they represent a well-established technique to elicit requirements, and a number of support tools exist as well.</p><p>The structure of a misuse case, which is based on the template provided by Sindre and Opdahl <ref type="bibr">[6]</ref> is described below:</p><p>Summary: provides a brief description of the threat. Assets, stakeholders and threats: describes the assets being threatened, their importance to the different stakeholders, and what is the potential damage if the misuse case succeeds. Primary misactor: describes the type of misactor performing the misuse case. Possible types are insiders, people with a certain technical skill, and so on. Also, some misuse case could occur accidentally, whereas other are most likely to be performed intentionally. Basic Flow: discusses the normal flow of actions, resulting in a successful attack for the misactor. Alternative Flows: describes the other ways the misuse can occur. Trigger: describes how and when the misuse case is initiated. Preconditions: precondition that the system must meet for the attack to be feasible.</p><p>The preconditions refer to the leaf nodes of the threat tree patterns, and the basic (and alternative) flow describes how a miuser could exploit these weaknesses of the system in order to mount an attack.</p><p>Running example: Social Network 2.0 In our running example, we assume that communication and processes within the social network service provider are trustworthy (see the trust boundary in the DFD depicted in Fig. <ref type="figure" target="#fig_0">1</ref>). However, we want to protect the data store against information disclosure. The data controllers could be users, social network providers, and application providers.</p><p>To illustrate how to create a misuse case based on the threat tree patterns, consider the threat tree of linkability at the data store (see Fig. <ref type="figure">6</ref>). The tree illustrates that in order Fig. <ref type="figure" target="#fig_9">18</ref> Threat tree for information disclosure Fig. <ref type="figure" target="#fig_0">19</ref> Threat tree for content unawareness Fig. <ref type="figure" target="#fig_1">20</ref> Threat tree for policy and consent non-compliance to be susceptible to this threat, neither the data store is sufficiently protected against information disclosure nor sufficient data anonymization techniques are employed. These are the preconditions of the misuse case. To create the attack scenarios, it is clear that the attacker first needs to have access to the data store, and secondly, either the user (as the data subject) can be re-identified (as the basic flow) or the pseudonyms can be linkable (as the alternative flow). The aforementioned misuse case is presented in this section. The additional nine misuse cases applicable to the social network example are described in Appendix A.</p><p>Title: MUC 1-Linkability of social network database (data store)</p><p>Summary: Data entries can be linked to the same person (without necessarily revealing the persons identity)</p><p>Assets, stakeholders, and threats: personal identifiable information (PII) of the user.</p><p>-The user:</p><p>-Data entries can be linked to each other which might reveal the persons identity -The misactor can build a profile of a user's online activities (interests, actives time, comments, updates, etc.)</p><p>Primary misactor: skilled insider/skilled outsider Basic Flow:</p><p>1. The misactor gains access to the database 2. The misactor can link the data entries together and possibly re-identify the data subject from the data content</p><p>Alternative Flow:</p><p>1. The misactor gains access to the database 2. Each data entry is linked to a pseudonym 3. The misactor can link the different pseudonyms together (linkability of entity) 4. Based on the pseudonyms, the misactor can link the different data entries</p><p>Trigger: by misactor, can always happen. Preconditions:</p><p>-no or insufficient protection of the data store -no or insufficient data anonymization techniques or strong data mining applied Note that formulating soft privacy threats is less straight-forward and requires some out-of-the-box thinking for suitable (non-)technical solutions. We refer the reader to misuse cases 9 and 10 in the appendix as an example of the latter case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Risk assessment</head><p>Similarly to STRIDE, LINDDUN can suggest a (large) number of documented threats. Before the process moves forward, the identified threats must be prioritized. Only the important ones should be considered for inclusion in the requirements specification and, consequently, in the design of the solution. Risk assessment techniques provide support for this stage. In general, risk is calculated as a function of the likelihood of the attack scenario depicted in the MUC (misuse case) and its impact. The risk value is used to sort the MUCs: the higher the risk, the more important the MUC is.</p><p>The LINDDUN framework (similarly to STRIDE) is independent from the specific risk assessment technique that is used. The analyst is free to pick the technique of choice, for instance the OWASP's Risk Rating Methodology <ref type="bibr" target="#b51">[30]</ref>, Microsoft's DREAD <ref type="bibr" target="#b52">[31]</ref>, NIST's Special Publication 800-30 <ref type="bibr" target="#b53">[32]</ref>, or SEI's OCTAVE <ref type="bibr" target="#b54">[33]</ref>. These techniques leverage the information contained in the MUC, as the involved assets (for the impact), and the attacker profile as well as the basic/alternative flows (for the likelihood). Many of the above-mentioned techniques include privacy considerations when assessing the impact of a threat. However, as a research challenge, a privacy-specific risk assessment technique is worthwhile to be investigated, as the on-field experience reveals any inadequacy of stateof-the-art techniques. This goes beyond the scope of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">From threat analysis to privacy-enhancing solutions</head><p>This section explains the elicitation of privacy requirements from threat analysis and the selection of mitigation strategies and techniques based on privacy objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Eliciting privacy requirements: from privacy threat analysis to mitigation strategy</head><p>Misuse cases describe the relevant (risk-wise) threat scenarios for the system. The preconditions are based on the threat tree patterns, and the basic and alternative flows are inspired by the system's use cases.</p><p>As a next step, the system's (positive) requirements can be extracted from the misuse cases. To this aim, the specification of the privacy requirements is facilitated by Table <ref type="table" target="#tab_4">6</ref>, which maps the types of threats scenarios to types of privacy requirements. Note that the table is a refinement of the more generic objectives in Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">From privacy requirements to privacy enhancing solutions</head><p>Similar to security, privacy requirements can be satisfied via a range of solution strategies:</p><p>1. Warn the user could be a valid strategy for lower risk (but still relevant) threats. However, precautions have to be taken so that users, especially nontechnical ones, do not make poor trust decisions. 2. Removing or turning off the feature is the only way to reduce the risk to zero. When threat models indicate that the risk is too great or the mitigation techniques are untenable, it is best not to build the feature in the first place, in order to gain a balance between user features and potential privacy risks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Countering threats with either preventive or reactive</head><p>privacy-enhancing technology is the most commonly used strategy to solve specific issues.</p><p>This section mainly focuses on the last strategy. When countering threats with technology is chosen as the mitigation strategy, system designers have to identify the sound and appropriate privacy-enhancing technology (PET). We summarize the state-of-art PETs in Table <ref type="table" target="#tab_5">7</ref> and map these techniques to each of the corresponding privacy requirements of Table <ref type="table" target="#tab_4">6</ref>. As a result, improved guidance is provided to the system designers over the solution selection process.</p><p>Note that the PETs categorization is inspired by the taxonomies proposed in <ref type="bibr" target="#b55">[34,</ref><ref type="bibr" target="#b56">35]</ref>. Further, Table <ref type="table" target="#tab_5">7</ref> introduces some key primitives of hard privacy technologies and the state-of-art of soft privacy technologies. New privacy-enhancing solutions keep emerging; therefore a complete list of PETs and best practices for choosing the appropriate mitigation is beyond the scope of this paper. The latest development of privacy-enhancing technologies can be found at <ref type="bibr" target="#b57">[36]</ref>.</p><p>In summary, privacy protection solutions boil down to either technical or legal enforcement. In general, privacy technology enables functionality while offering the highest protection for privacy. Further, Hard Privacy Technology provides cryptographically strong protections for privacy, assumes no unnecessary leakage of information, and replies on massive distribution of trust excluding potential adversary and privacy violators. Soft Privacy Technology (e.g. privacy policy and feedback tools in Table <ref type="table" target="#tab_5">7</ref>) offers protections against mass surveillance and violations, assumes data subjects sharing of personal data is necessary, and employs a weaker adversary model.</p><p>Running example: Social Network 2.0 Table <ref type="table" target="#tab_6">8</ref> summarizes the selection of PETs based on the privacy requirements elicited in our running example. It is possible that a more business-oriented example would suggest different mitigation strategies. Nevertheless, we hope the example depicted in this section can illustrate how the proposed framework can be applied in real-life applications.</p><p>In an attempt to make the running example more accessible to the reader, the system model, the misuse cases, and the mitigation techniques of the Social Network 2.0 are largely simplified due to the assumption that the social network providers are semi-trustworthy (i.e., the adversary model consists of external parties, data holder, honest insiders who make errors, and corrupt insiders). If different assumptions would hold, different misuse cases should be identified with a distinct mitigation approach. For instance, if we apply a smaller trust boundary and assume that the social network provider is totally untrustworthy, then extra privacy requirements and a stronger threat model would be considered. One possible misuse case would be that the malicious social network provider, as an attacker, takes advantage of profiling user's personal data for its own benefits. In that scenario, one solution could be building a security agriculture out of smart clients and an untrusted central server to removes the need for faith in network operators and gives users control of their privacy <ref type="bibr" target="#b104">[84]</ref>. Another solution could be using encryption to enforce access control for users' personal information based on their privacy preferences <ref type="bibr" target="#b105">[85,</ref><ref type="bibr" target="#b106">86]</ref>. Apply data anonymization techniques, such as kanonymity <ref type="bibr" target="#b87">[67]</ref> Protection of data store Enforce data protection by means of relationshipbased access control <ref type="bibr" target="#b99">[79]</ref> 2 Linkability of data flow of the user data stream (userportal)</p><p>Unlinkability of messages of user-portal communication; channel confidentiality Deploy anonymity system, such as TOR <ref type="bibr" target="#b68">[48]</ref> 3 Linkability of entities the social network users Unlinkability of different pseudonyms (user IDs) of social network users; channel confidentiality 1. Technical enforcement: deploy anonymity system, such as TOR <ref type="bibr" target="#b68">[48]</ref>, for communication between user and social network web portal 2. User privacy awareness: inform users that revealing too much information online can be privacy invasive 4</p><p>Identifiability at the social network data store Anonymity of social network users such that the user will not be identified from social network database entries Protection of the data store, by applying data anonymization techniques, such as k-anonymity <ref type="bibr" target="#b87">[67]</ref> Protection of data store Enforce data protection by means of relationshipbased access control <ref type="bibr" target="#b99">[79]</ref> 5</p><p>Identifiability at data flow of user data stream (userportal)</p><p>Anonymity of social network users such that the user will not be identified from user-portal communication by content; channel confidentiality Deploy anonymity system, such as TOR <ref type="bibr" target="#b68">[48]</ref>, for communication between user and social network web portal 6 Identifiability of the social network users Pseudonymize users IDs 1. Apply secure pseudonymization techniques to issue pseudonyms as user IDs 2. User privacy awareness: inform users using real ID has a risk for privacy violation Use identity management to ensure unlinkability is sufficiently preserved (as seen by an attacker) between the partial identities of an individual person required by the applications Employ privacy preserving identity management, e.g. proposed in <ref type="bibr" target="#b92">[72]</ref>, together with user-controlled identity management system <ref type="bibr" target="#b93">[73]</ref> to ensure usercontrolled linkability of personal data. System supports the user in making an informed choice of pseudonyms, representing his or her partial identities. Make the flow of this user's identity attributes explicit to the user and gives its user a large degree of control</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confidentiality of data flow in user-portal communication</head><p>Deploy anonymity system such as TOR <ref type="bibr" target="#b68">[48]</ref> 7 Information disclosure at the social network data store</p><p>Release of the social network data store should be controlled according to user's privacy preference</p><p>Apply access control at the social network databases, e.g. privacy aware collaborative access control based on relationships <ref type="bibr" target="#b99">[79]</ref> 8 Information disclosure of communication between the user and the social network Confidentiality of communication between the user and the social network should be ensured Employ a secure communication channel and deploy anonymity system such as TOR <ref type="bibr" target="#b68">[48]</ref> 9 Content unawareness of user Users need to be aware that they only need to provide minimal set of required personal data (the data minimization principle)</p><p>Use feedback tools to raise user's privacy awareness Another research discussion is concerning practicality to build user privacy feedback tools. In short, from a technical point of view, feedback could be realized by means of data mining techniques (e.g., k-anonymity model) to countermeasure user identification and data profiling attacks. It compares data user sends to the social network with a whole set of data composed of data from all networks users and checks the ''uniqueness'' of personal identifiable information (PII) of the user. With a unique PII, a user has a higher probability to be identified. Then, it warns users each time their activities provoke privacy risks, e.g. shows a risk level of identifiability by posting a message ''you are about to leave the anonymity safe zone''. There are some research incentives for feedback systems for social networks <ref type="bibr" target="#b37">[16,</ref><ref type="bibr" target="#b38">17,</ref><ref type="bibr" target="#b103">83]</ref>. However, this concept implies a paradox that in order to ensure accurate feedback, the feedback tool itself should be a ''perfect attacker'' that knows all the data from all users. Due to the space and scope limit of this paper, we cannot discuss this in detail. We encourage interested readers to formalize the feedback system model and investigate whether it is technically realistic to realize the feedback concept and beyond which threshold a feedback could be satisfactory. Intuitively speaking, the aforementioned feedback concept is not about technical problem purely but more an education problem to raise user's privacy awareness. The usability of such feedback tools is also an issue, such as how to design a user-friendly interface and encourage users to use feedback remains a research challenge. 9 Related work 9.1 Privacy requirements analysis Mylopoulos et al. <ref type="bibr" target="#b107">[87]</ref> are the first to point out that complexity of an information system is determined partly by its functionality (i.e. what the system does) and partly by its non-functional requirements (also referred as constrains, goals, and quality attributes), and the non-functional requirements ''play a crucial role during system development, serving as selection criteria for choosing among myriads of decisions''. They proposed a comprehensive framework for representing and using non-functional requirements during the development process in a processoriented approach. The framework consists of five basic components-goals, link types, methods (i.e., goal decomposition methods, goal satisfying methods, and argumentation methods), correlation rules, and the labeling procedure-as the representation of non-functional requirements in terms of interrelated goals. As suggested by Mylopoulos et al. ''such goals can be refined through refinement methods and can be evaluated in order to determine the degree to which a set of non-functional requirements is supported by a particular design'' <ref type="bibr" target="#b107">[87]</ref>. This framework can serve as the foundation for the aforementioned privacy requirement analysis methodology.</p><p>The privacy guidelines provided by Microsoft describes some basic privacy concepts <ref type="bibr" target="#b108">[88]</ref>, such as different types of consents or data minimization concepts. Besides, a number of guidelines are presented for selected scenarios concerning the following principles: notice, choice, onward transfer, access, security, and data integrity. However, it only contains a flat list of the required and recommended guidelines and does not intend to describe a more structured approach. These guidelines can still be used as inspiration to determine possible threats, e.g. to extend our catalog of threat trees.</p><p>In the documentation of SDL version 3.2 [89], privacy is also partially considered, but only at a generic level. For example, the threat modeling process described in the forth stage of SDL only mentions that a design review with the privacy expert is necessary. SDL also presents ten general privacy guidelines. An example guideline indicates that it is important to collect the least sensitive form of data. At this stage, privacy is not yet well integrated in SDL.</p><p>Yu and Cysneiros <ref type="bibr" target="#b109">[90]</ref> presented a framework using i*, an agent-oriented requirements modeling language, to deal with privacy requirements. This framework however focuses on reasoning about privacy and does not provide a structured methodology to examine the different privacy objectives. Liu et al. <ref type="bibr" target="#b110">[91]</ref> proposed a framework also using i* to deal with security and privacy requirements, which was inspired by the work of Yu and Cysneiros. They use four different analysis techniques to create a complete model: attacker analysis, dependency vulnerability analysis, countermeasure analysis and access control analysis. Although this framework contains the attacker analysis technique, which is similar to our idea of examining the possible privacy threats, the framework is again mainly meant to reason about privacy but lacks the necessary knowledge to empower the (non-expert) privacy analyst.</p><p>Miyazaki et al. <ref type="bibr" target="#b111">[92]</ref> defined a computer-aided privacy requirements elicitation technique. This technique returns the appropriate requirements for the system to be compliant with the law, based on a questionnaire that the system engineer fills out. This is in contrast to our methodology, which helps the analyst eliciting the privacy requirements in accordance with the stakeholders' wishes. 9.2 From privacy requirements to privacy solutions Several taxonomies have been proposed to create a link between privacy requirements and privacy solutions. This section gives an overview of some existing taxonomies that can be integrated in our threat modeling process to link the privacy requirements obtained by our methodology to the optimal privacy-enhancing solution(s).</p><p>The taxonomy of privacy goals, described by Anto ´n et al. <ref type="bibr" target="#b112">[93]</ref>, is to analyze Website privacy requirements. Privacy goals are divided into protection goals and (anti) vulnerability goals. The Code for Fair Information Practices is used to categorize the protection goals, namely notice and awareness, choice and consent, access and participation, integrity and security, and enforcement and redress. The (anti) vulnerability goals are classified according to the manner in which they violate the users privacy. The corresponding goals are monitoring, aggregation, storage, and information transfer. These goals are used to analyze and compare privacy policies and do not intend to link privacy requirements to general privacy solutions, instead, limited to Website privacy requirements.</p><p>The Pris method <ref type="bibr" target="#b56">[35]</ref> presents a structured way to create systems that adhere to the specified privacy requirements. It consists of four different phases: (1) Elicit privacyrelated goals, (2) Analyze the impact of privacy goals on organizational processes, (3) Model affected processes using privacy-process patterns, and (4) Identify the technique(s) that best support or implement the above processes. The last step uses a table that classifies privacy implementation techniques in six categories, (a) Administrative tools, (b) Information tools, (c) Anonymizer products, services and architectures, (d) Pseudonymizer tools, (e) Track and evidence erasers, and (f) Encryption tools, and it can be an interesting source of inspiration to determine appropriate privacy solutions.</p><p>Wuyts et al. <ref type="bibr" target="#b55">[34]</ref> created a hierarchical taxonomy that categorizes privacy into objectives. The objectives are divided in two branches. The proactive branch focuses on concealing the association between the data and the identity of the user before it is shared with the system, while the reactive branch focuses on guarding the relationship between the data and the identity when the data are already shared. Each objective corresponds to a number of strategies, which are a sub-classification of the objectives. These strategies can then be linked to their corresponding solutions. This paper only provides a sample solution for each category and does not provide a full overview of all existing solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Discussion</head><p>Despite the fact that the dualism between hard and soft privacy has already been generically introduced in a few talks <ref type="bibr" target="#b33">[12,</ref><ref type="bibr" target="#b113">94]</ref>, to our best knowledge, this paper is the first effort that concretely distinguishes these two concepts and categorizes privacy properties (and threats) accordingly. In short, hard privacy properties include unlinkability, anonymity and pseudonymity, plausible deniability, undetectability and unobservability, and confidentiality. Soft privacy properties include content unawareness and policy and consent compliance. Similarly, leveraging the link between privacy-enhancing technologies and privacy objectives, it is possible to make a distinction between hard and soft solutions. Hard privacy technologies are active in research but poor in deployment, due to cost and technical evolvement restrictions (such as cryptography). Soft privacy technologies are state-of-art and have fewer research activities. With legal compliance as a strong driver, soft privacy solutions reply on stakeholder's liability and the tradeoffs between cost of deploying privacy solutions and potential costs in case of massive data breach. After all, building in privacy in the system might not be cheap, but just cheaper than building in no privacy.</p><p>There are a number of insights concerning the proposed methodology that are worthy to be emphasized:</p><p>1. Some privacy threats, in contrast to security, affect DFD elements pair-wise (or sometimes group-wise).</p><p>For instance, unlinkability implies the relation of two or more items of interest. As an example, a relation may refer to a subject (an entity in the DFD) and its attributes (in the data stores). Consequently, it is straightforward to see that linkability threats always affect a pair or a group of DFD elements. Similarly, plausible deniability refers to the pair-wise relation between a subject and the attribute that the subject wants to deny. We can draw a conclusion that privacy emphasizes relationships between instances of DFD elements (e.g. two communication instances of the same data flow cannot be linked) or relationships between a DFD element and an entity, while security focuses on each individual DFD component in a more local way. 2. The process element in the DFD is less important for privacy because privacy cares more about the relationships between entities and data. It is quite the opposite in the case of security. For instance, all STRIDE threat categories apply to the process element, while, in LINDDUN, all privacy attack paths involving the process element are related to a security threat (namely, information disclosure of process) and not to privacy threats per se. This observation leads to our next finding. 3. The authors have chosen the DFD notation to represent a software-based system in order to keep compliance with the STRIDE approach. As STRIDE and LIND-DUN are expected to be applied in a synergic way, this choice fosters the reuse of the DFD models (and the modeling knowledge) across the security and the privacy threat analysis. However, it should be noticed that DFD elements (entities, processes, data flows, and data stores) represent the technical assets that require protection from privacy-specific harm. That is, the DFDs expose the privacy-relevant information concerning the technical assets from the system perspective. Therefore, the privacy analyst should pay attention to the fact that the important privacy assets are properly modeled by the DFD. For instance, data flows should be specific to IOIs in the privacy case. 4. For some privacy properties, an extension of the DFD semantics might be useful. For instance, for the case of privacy-sensitive information that is inferred over time, the notion of knowledge is necessary. This could be annotated in the DFD processes via epistemic constructs and then leveraged during the analysis. 5. Concerning the privacy threat trees, one can see that many paths lead to security threats (e.g. information disclosure and tampering). Consequently, privacy objectives heavily depend on security objectives (e.g. confidentiality and integrity of data flow, data store or process). We draw the general conclusion that it is interesting to analyze privacy threats together with security threats, and the necessary process (and tool) support should be built to facilitate such activities. This synergy would bring an advantage in terms of time and cost for system designers to work with. Further, privacy and security objectives might conflict (e.g. non-repudiation and plausible deniability, as explained in the previous sections). It is thus useful to perform the threat analysis for privacy and security altogether and consider both types of requirements at the same time.</p><p>Finally, it is necessary to clarify a few definitions to avoid confusion. Confidentiality refers to hiding the data content; anonymity and pseudonymity refer to hiding the subject's identity or hiding the link between identity and action or a piece of information; unlinkability refers to hiding links between two or more objectives (actions, identities, and pieces of information); and undetectability and unobservability refer to hiding a subject's activity. In particular, unlinkability of entities means that it is impossible to relate different entities based on some common personal identifiable information (PII), while anonymity of entities means that the subject cannot be identified within a anonymity set. Anonymity at data flow typically means that, in an anonymous communication setting, the subject cannot be identified from the data flow's content or side channel information; while anonymity at data store refers to data anonymization, meaning that the subject cannot be identified from the content of the data store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Conclusion</head><p>In this paper, we have presented a comprehensive framework to model privacy threats in software-based systems, elicit privacy requirements, and instantiate privacyenhancing countermeasures. The primary contribution is the systematic methodology to model privacy-specific threats. This is achieved by defining a list of privacy threat types and providing the necessary mappings to the elements in the system model. The second contribution is represented by the supporting body of knowledge, namely, an extensive catalog of privacy-specific threat tree patterns. In addition, this work provides the means to map the most commonly known privacy-enhancing technologies (PETs) to the identified privacy threats and the elicited privacy requirements. The privacy threat tree patterns and categorization of suggested PETs are expected to be continuously updated and improved upon, since new threats keep emerging, just as new privacy technologies keep evolving.</p><p>As future work, we plan to apply the proposed framework to larger case studies, for instance, validation in the context of a national e-health system is being performed. -data can be linked to each other, which might reveal the persons identity -attacker can build a profile of a user's online activities (interests, actives time, comments, updates, etc.)</p><p>Primary misactor: skilled insider/skilled outsider Basic Flow:</p><p>1. The misactor intercepts or eavesdrops two or more pseudonyms 2. The misactor can link the pseudonyms to each other and possibly link (by combining this information) to the user/data subject Trigger: by misactor, can happen whenever data are communicated Preconditions:</p><p>-Information disclosure of the data flow possible -Different ''pseudonyms'' are linked to each other based on content of the data flow Prevention capture points:</p><p>-protection of information such as user temporary ID, IP address, time and location, session ID, identifier and biometrics, computer ID, communication content, e.g. apply data obfuscation to protection this information (security) -message and channel confidentiality provided 1. The misactor gains access to the database 2. The data is linked to a pseudonym 3. The misactor can link the pseudonym to the actual identity (identifiability of entity) 4. The misactor can link the data to the actual user's identity</p><p>Alternative Flow:</p><p>1. The misactor gains access to the database 2. This can link information from the database to other information (from another database or information which might be publicly accessible) 3. The misactor can re-identify the user based on the combined information</p><p>Trigger: by misactor, can always happen Preconditions:</p><p>-no or insufficient protection of the data store -no data anonymization techniques used Prevention capture points:</p><p>-protection of the data store (security) -apply data anonymization techniques Prevention guarantee: hard-impossible to link data to identity (depending on applied technique) 1. The misactor gains access to the data flow 2. The data contains personal identifiable information about the user (user relationships, address, etc.) 3. The misactor is able to extract personal identifiable information from the user/data subject Trigger: by misactor, can happen whenever data is communicated Preconditions:</p><p>-no or weak anonymous communication system used -Information disclosure of data flow possible Prevention capture points:</p><p>-apply anonymous communication techniques -Use confidential channel</p><p>Prevention guarantee: hard-impossible to link data to identity (depending on applied technique) MUC 6: Identifiability of users of the social network system (entity) Summary: The users identity is revealed Asset: PII of the user -The user: revealed identity Primary misactor: skilled insider/skilled outsider Basic Flow:</p><p>1. The misactor gains access to the data flow 2. The data contains the user's password 3. The misactor has access to the identity management database 4. The misactor can link the password to the user Alternative Flow:</p><p>1. The misactor gains access to the data flow 2. The data contains the user's password 3. The misactor can link the user's password to the user's identity (password is initials followed by birthdate)</p><p>Trigger: by misactor, can happen whenever data are communicated and the user logs in using his ''secret'' Preconditions:</p><p>-Insecure IDM system OR -weak passwords used and information disclosure of data flow possible Prevention capture points:</p><p>-Strong pseudonymity technique used (e.g. strong passwords) -privacy-enhancing IDM system -Data flow confidentiality Prevention guarantee: hard(er) to link log-in to identity. -no or insufficient internal access policies Prevention capture points:</p><p>-strong access control policies (security). For example, rule-based access control based on friendships in the social network</p><p>Prevention guarantee: hard-impossible to obtain data without having the necessary permissions -communication goes through insecure public network</p><p>Prevention capture points:</p><p>-messages sent between user and social network web client is encrypted and secure communication channel is ensured</p><p>Prevention guarantee: hard-impossible to gain access to the data flow without having the right permissions MUC 9: Content unawareness Summary: User is unaware that his or her anonymity is at risk due to the fact that too much personal identifiable information is released Asset: PII of the user -The user: revealed identity Primary misactor: skilled insider/skilled outsider Basic Flow:</p><p>1. The misactor gain access to user's online comments 2. The misactor profiles the user's data and can identify the user</p><p>Trigger: by misactor, can always happen Preconditions:</p><p>-User provides too much personal data Prevention capture points:</p><p>-User provides only minimal set of required information Prevention guarantee: user will be informed about potential privacy risks MUC 10: Policy and consent noncompliance Summary: The social network provider doesn't process user's personal data in compliance with user consent, e.g., disclose the database to third parties for secondary use Asset: PII of the user -The user: revealed identity and personal information -The system/company: negative impact on reputation Primary misactor: Insider Basic Flow:</p><p>1. The misactor gains access to social network database 2. The misactor discloses the data to a third party Trigger: by misactor, can always happen Preconditions:</p><p>-misactor can tamper with privacy policies and makes consents inconsistent OR -policies not managed correctly (not updated according to user's requests)</p><p>Prevention capture points:</p><p>-Design system in compliance with legal guidelines for privacy and data protection and keep internal policies consistent with policies communicated to user -Legal enforcement: user can sue the social network provider whenever his or her personal data are processed without consents -Employee contracts: employees who share information with 3th parties will be penalized (fired, pay fine, etc.)</p><p>Prevention guarantee: Legal enforcement will lower the threat of an insider leaking information but it will still be possible to breach user's privacy</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 The data flow diagram (DFD) of the Social Network 2.0 application</figDesc><graphic coords="2,308.99,556.66,232.80,129.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig.2Example security threat tree pattern of tampering a process<ref type="bibr" target="#b24">[3]</ref> </figDesc><graphic coords="3,204.23,463.25,340.32,250.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 6 . 2</head><label>462</label><figDesc>Fig. 4 Threat tree for linkability of an entity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Threat tree for linkability of a data flow</figDesc><graphic coords="12,178.71,410.80,365.76,303.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.</head><label></label><figDesc>Fig.13Threat tree for nonrepudiation of a data store</figDesc><graphic coords="16,178.71,59.24,365.76,232.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Acknowledgments</head><label></label><figDesc>This research is partially funded by the Interuniversity Attraction Poles Programme Belgian State, Belgian Science Policy, and by the Research Fund K.U. Leuven. Appendix: A Misuse case examples MUC 2: Linkability of the user-portal data stream (data flow) Summary: Data flows can be linked to the same person (without necessarily revealing the persons identity) Asset: PII of the user -The user: -data flow can be linked to each other which might reveal the persons identity -the attacker can build a profile of a user's online activities (interests, active time, comments, updates, etc.) Primary misactor: skilled insider/skilled outsider Basic Flow: 1. The misactor intercepts/eavesdrops two or more data flows 2. The misactor can link the data flows to each other and possibly link them (by combining this information) to the user/data subject Trigger: by misactor, can happen whenever data are communicated Preconditions: -No anonymous communication system used -Information disclosure of data flow possible Prevention capture points: -Use strong anonymous communication techniques -Provide confidential channel Prevention guarantee: Impossible to link data to each other MUC 3: Linkability of the social network users (entity) Summary: Entities (with different pseudonyms) can be linked to the same person (without necessarily revealing the persons identity) Asset: PII of the user -The user:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Prevention guarantee: Impossible to link data to each other MUC 4: Identifiability at the social network database (data store) Summary: The users identity is revealed Asset: PII of the user -The user: revealed identity Primary misactor: skilled insider/skilled outsider Basic Flow:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>MUC 5 :</head><label>5</label><figDesc>Identifiability of user-portal data stream (data flow) Summary: The users identity is revealed Asset: PII of the user -The user: revealed identity Primary misactor: insider/outsider Basic Flow:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>MUC 7 :</head><label>7</label><figDesc>Information disclosure at the social network database (data store) Summary: Data are exposed to unauthorized users Asset: PII of the user -The user: revealed sensitive data Primary misactor: skilled insider/skilled outsider Basic Flow: 1. The misactor gains access to the database 2. The misactor retrieves data to which he should not have access Trigger: by misactor, can always happen Preconditions:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>MUC 8 :</head><label>8</label><figDesc>Information disclosure of communication between the user and the social network (data flow) Summary: The communication is exposed to unauthorized users Asset: PII of the user -The user: revealed sensitive data Primary misactor: skilled insider/skilled outsider Basic Flow:1. The misactor gains access to the data flow 2. The misactor retrieves data to which he should not have accessTrigger: by misactor, can happen whenever messages are being sent Preconditions:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,178.71,503.33,365.76,210.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,178.71,59.24,365.76,258.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,178.71,340.72,365.76,283.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="15,178.71,518.53,365.76,195.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="17,178.71,59.24,365.76,217.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="17,53.87,300.19,232.80,236.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Security concerns with corresponding security threats and DFD elements susceptible to threats, proposed by the Security Development Lifecycle (SDL)<ref type="bibr" target="#b24">[3]</ref> </figDesc><table><row><cell cols="2">Security property Security threat</cell><cell cols="3">DF DS P</cell><cell>E</cell></row><row><cell>Authentication</cell><cell>Spoofing</cell><cell></cell><cell></cell><cell>9</cell><cell>9</cell></row><row><cell>Integrity</cell><cell>Tampering</cell><cell>9</cell><cell>9</cell><cell>9</cell></row><row><cell>Non-repudiation</cell><cell>Repudiation</cell><cell></cell><cell>9</cell><cell>9</cell><cell>9</cell></row><row><cell>Confidentiality</cell><cell>Information disclosure</cell><cell>9</cell><cell>9</cell><cell>9</cell></row><row><cell>Availability</cell><cell>Denial of service</cell><cell>9</cell><cell>9</cell><cell>9</cell></row><row><cell>Authorization</cell><cell>Elevation of privilege</cell><cell></cell><cell></cell><cell>9</cell></row></table><note><p>DF Data flow, DS Data store, P Process, E External entity</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>In the LINDDUN methodology, privacy properties and the corresponding privacy threat are categorized as hard privacy and soft privacy</figDesc><table><row><cell>Privacy properties</cell><cell>Privacy threats</cell></row><row><cell>Hard privacy</cell><cell></cell></row><row><cell>Unlinkability</cell><cell>Linkability</cell></row><row><cell>Anonymity &amp; Pseudonymity</cell><cell>Identifiability</cell></row><row><cell>Plausible deniability</cell><cell>Non-repudiation</cell></row><row><cell>Undetectability &amp;</cell><cell>Detectability</cell></row><row><cell>unobservability</cell><cell></cell></row><row><cell>Confidentiality</cell><cell>Disclosure of information</cell></row><row><cell>Soft privacy</cell><cell></cell></row><row><cell>Content awareness</cell><cell>Content unawareness</cell></row><row><cell>Policy and consent compliance</cell><cell>Policy and consent</cell></row><row><cell></cell><cell>non-compliance</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>DFD elements in the Social Network 2.0 application</figDesc><table><row><cell>Entity</cell><cell>User</cell></row><row><cell>Process</cell><cell>Portal</cell></row><row><cell></cell><cell>Social network service</cell></row><row><cell>Data store</cell><cell>Social network DB</cell></row><row><cell>Data flow</cell><cell>User data stream (user-portal)</cell></row><row><cell></cell><cell>Service data stream (portal-service)</cell></row><row><cell></cell><cell>DB data stream (service DB)</cell></row></table><note><p>E Entity, DF Data flow, DS Data store, P Process Requirements Eng (2011) 16:3-32</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>Determining privacy threats for DFD elements within the Social Network 2.0 application</figDesc><table><row><cell></cell><cell>Threat target</cell><cell>L</cell><cell>I</cell><cell>N</cell><cell>D</cell><cell>D</cell><cell>U</cell><cell>N</cell></row><row><cell>Data store</cell><cell>Social network DB</cell><cell>1</cell><cell>4</cell><cell>9</cell><cell>9</cell><cell>7</cell><cell></cell><cell>1 0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>Privacy objectives based on LINDDUN threat types E entity, DF data flow, DS data store, P process</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>Mapping privacy objectives with privacy-enhancing techniques</figDesc><table><row><cell>Mitigation techniques: PETs</cell><cell>U A P</cell><cell>D C W O</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>Social Network 2.0 example: from misuse cases to privacy requirements and suggested mitigation strategies and techniques</figDesc><table><row><cell cols="2">No. Misuse cases</cell><cell>Privacy requirements</cell><cell>Suggested mitigation strategies and techniques</cell></row><row><cell>1</cell><cell>Linkability of social network</cell><cell>Unlinkability of data entries within the social</cell></row><row><cell></cell><cell>data store</cell><cell>network database</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Requirements Eng (2011) 16:3-32</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Requirements Eng (2011) 16:3-32</p></note>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data flow</head><p>User data stream (user-portal) 2</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">Service data stream</title>
		<imprint/>
	</monogr>
	<note>portal-service</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">From left to right: L linkability, I identifiability, N non-repudiation, D detectability, D information disclosure, U content unawareness, N consent/ policy non-compliance</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Linkability of (DS, DS) Unlinkability of</title>
		<imprint>
			<pubPlace>DS, DS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Unlinkability of (P, P) Identifiability of</title>
		<author>
			<persName><forename type="first">P</forename><surname>Linkability Of (p</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>E, E) Anonymity/pseudonymity of (E, E) Identifiability of (E, DF) Anonymity/pseudonymity of (E, DF</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">(</forename><forename type="middle">E</forename><surname>Identifiability</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<title level="m">Anonymity/pseudonymity of (E, P) Non-repudiation of (E, DF) Plausible deniability of</title>
		<meeting><address><addrLine>E, DF</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m">Non-repudiation of (E, DS) Plausible deniability of</title>
		<imprint/>
	</monogr>
	<note>E, DS</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Detectability of DF Undetectability of DF Detectability of DS Undetectability of DS Detectability of P Undetectability of P Information disclosure of DF Confidentiality of DF Information disclosure of DS Confidentiality of DS Information disclosure of P Confidentiality of P Content unawareness of E Content awareness of E Policy and consent non-compliance of the system Policy and consent compliance of the system Anonymity system Mix-networks</title>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P) ; E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<idno>ISDN-mixes [40</idno>
	</analytic>
	<monogr>
		<title level="m">Anonymizer, SafeWeb), anonymous Remailer (Cipherpunk Type 0, Type 1 [43], Mixmaster Type</title>
		<imprint>
			<date type="published" when="1981">1981. 1985. 1996. 1998. 1993-1996. 1994. 2003. 2004</date>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
	<note>Mixminion Type. and Low-latency communication (Freedom Network (1999-2001) [46], Java Anon Proxy (JAP) (2000) [47], Tor</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<idno>ISDN-mixes [40</idno>
		<title level="m">DC-net &amp; MIX-net ? dummy traffic</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Privacy preserving authentication Private authentication</title>
		<imprint/>
	</monogr>
	<note>51, 52</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Anonymous credentials</title>
		<imprint/>
	</monogr>
	<note>single show [53], multishow [54</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Privacy preserving cryptographic protocols Multiparty computation (secure function evaluation</title>
		<imprint/>
	</monogr>
	<note>57, 58</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Anonymous buyer-seller watermarking protocol</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Information retrieval Private information retrieval</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
		</imprint>
	</monogr>
	<note>dummy traffic</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Privacy preserving data mining</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Data anonymization K-anonymity model</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Pseudonymity systems Privacy enhancing identity management system</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m">Encryption techniques Symmetric key &amp; public key encryption</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Deniable encryption</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Homomorphic encryption</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Privacy-aware access control</title>
		<imprint/>
	</monogr>
	<note>79, 80</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m">Policy and feedback tools Policy communication</title>
		<imprint/>
	</monogr>
	<note>P3P [18</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Data removal tools (spyware removal, browser cleaning tools, activity traces eraser</title>
		<imprint/>
	</monogr>
	<note>harddisk data eraser</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">D Undetectability/unobservability, C Confidentiality, W Content awareness, O Policy and consent compliance of the system References 1</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Lamsweerde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brohez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Landtsheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janssens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Informatique</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the RE03 workshop on requirements for high assurance systems (RHAS03)</title>
		<meeting>the RE03 workshop on requirements for high assurance systems (RHAS03)</meeting>
		<imprint>
			<publisher>U Unlinkability</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
	<note>A Anonymity/Pseudonymity, P Plausible deniability</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Requirements engineering: from system goals to UML models to software specifications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Lamsweerde</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Wiley</publisher>
			<pubPlace>Chichester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The security development lifecycle</title>
		<author>
			<persName><forename type="first">M</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lipner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Microsoft Press</publisher>
			<pubPlace>Redmond, WA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Software security: building security</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mcgraw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Addison-Wesley Professional</publisher>
			<pubPlace>Boston, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Secrets and lies: digital security in a networked world</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schneier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Templates for misuse case description</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Opdahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th international workshop on requirements engineering, foundation for software quality</title>
		<meeting>the 7th international workshop on requirements engineering, foundation for software quality</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="4" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Experimental comparison of attack trees and misuse cases for security threat identification</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Opdahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sindre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPECIAL ISSUE: Model-Driven Development for Secure Information Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="916" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A taxonomy of privacy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Solove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ PA Law Rev</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">477</biblScope>
			<date type="published" when="2006">2006</date>
			<publisher>GWU Law School Public Law Research Paper No</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Understanding privacy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Solove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A terminology for talking about privacy by data minimization: anonymity, unlinkability, undetectability, unobservability, pseudonymity, and identity management (Version 0</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<ptr target="http://dud.inf.tu-dresden.de/Anon_Terminology.shtml" />
		<imprint>
			<date type="published" when="2010-04">2010. April 2010</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
		<respStmt>
			<orgName>TU Dresden and ULD Kiel</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">technical report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Linkage control integrating the essence of privacy protection into identity management systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Collaboration and the knowledge economy: issues, applications, case studies, Proceedings of eChallenges</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Cunningham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Cunningham</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1585" to="1592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Danezis</surname></persName>
		</author>
		<ptr target="http://www.petsfinebalance.com/agenda/index.php" />
		<title level="m">Talk: an introduction to u-prove privacy protection technology, and its role in the identity metasystem-what future for privacy technology</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Information technology code of practice for information security management</title>
		<idno>ISO 17799</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>British Standards Institute</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">technical report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Cryptography and evidence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Clare College</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Mccallister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kent</surname></persName>
		</author>
		<title level="m">Guide to protecting the confidentiality of personally identifiable information (PII) (draft), technical report</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (US)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Personal privacy through understanding and action: five pitfalls for designers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lederer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Landay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pers Ubiquitous Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="440" to="454" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Privacy considerations in awareness systems: designing with privacy in mind, chap 8</title>
		<author>
			<persName><forename type="first">S</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kobsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human computer interaction series</title>
		<imprint>
			<biblScope unit="page" from="187" to="206" />
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Platform for privacy preferences project, W3C P3P specifications</title>
		<author>
			<persName><surname>P3p</surname></persName>
		</author>
		<ptr target="http://www.w3.org/TR/P3P/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Directive 95/46/EC of the European parliament and of the council of 24 october 1995 on the protection of individuals with regard to the processing of personal data and on the free movement of such data</title>
		<author>
			<persName><surname>Eu</surname></persName>
		</author>
		<ptr target="http://europa.eu/scadplus/leg/en/lvb/l14012.htm" />
	</analytic>
	<monogr>
		<title level="j">Off J Eur Commun</title>
		<imprint>
			<biblScope unit="volume">281</biblScope>
			<biblScope unit="page" from="31" to="50" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">HIPAA administrative simplification: enforcement; final rule. United States Department of Health &amp; Human Service</title>
		<author>
			<persName><surname>Hipaa</surname></persName>
		</author>
		<ptr target="http://www.hhs.gov/ocr/privacy/hipaa/administrative/privacyrule/finalenforcementrule06.pdf" />
	</analytic>
	<monogr>
		<title level="j">Fed Regist Rules Regul</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">32</biblScope>
			<biblScope unit="page" from="8390" to="8433" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Personal information protection and electronic documents act</title>
		<author>
			<persName><surname>Pipeda</surname></persName>
		</author>
		<ptr target="http://laws.justice.gc.ca/en/showtdm/cs/P-8.6" />
		<imprint>
			<date type="published" when="2000">2009. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<ptr target="http://www.privacy.gov.au/law/act" />
		<title level="m">Australia&apos;s national privacy regulator: privacy act</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Guidelines on the protection of privacy and transborder flows of personal data, organization for economic cooperation and development</title>
		<author>
			<persName><surname>Oecd</surname></persName>
		</author>
		<ptr target="http://www.oecd.org/document/18/0,2340" />
		<imprint>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
	<note>en_2649_34255_1815186_1_1_1_1,00.html</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Legal requirements, compliance and practice: an industry case study in accessibility</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Breaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Anton</surname></persName>
		</author>
		<author>
			<persName><surname>Boucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorfman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RE&apos;08: Proceedings of the 16th IEEE international requirements engineering conference (RE&apos;08)</title>
		<imprint>
			<publisher>IEEE Society Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<ptr target="http://www.justice.gov/crt/508/508law.php" />
		<title level="m">Workforce investment act of 1998, SEC. 508. electronic and information technology</title>
		<imprint>
			<publisher>United States Department of Justice</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Analyzing regulatory rules for privacy and security requirements</title>
		<author>
			<persName><forename type="first">T</forename><surname>Breaux</surname></persName>
		</author>
		<author>
			<persName><surname>Anto ´n A</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Softw Eng</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="20" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Systems for anonymous communication</title>
		<author>
			<persName><forename type="first">G</forename><surname>Danezis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Syverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRC handbook of financial cryptography and security</title>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman and Hall</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">K-anonymity: a model for protecting privacy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Uncertain Fuzziness Knowl-Based Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="557" to="570" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Misuse cases: use cases with hostile intent</title>
		<author>
			<persName><forename type="first">I</forename><surname>Alexander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Softw</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="66" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><surname>Owasp</surname></persName>
		</author>
		<ptr target="http://www.owasp.org/index.php/OWASP_Risk_Rating_Methodology" />
		<title level="m">Risk rating methodology</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m">MSDN Library, Improving web application security: threats and countermeasures</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Risk management guide for information technology systems, special publication 800-30</title>
		<author>
			<persName><surname>Nist</surname></persName>
		</author>
		<ptr target="http://csrc.nist.gov/publications/nistpubs/800-30/sp800-30.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S E</forename><surname>Institute</surname></persName>
		</author>
		<ptr target="http://www.cert.org/octave/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Linking privacy solutions to developer goals. Availability, reliability and security</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wuyts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scandariato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Joosen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="847" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Addressing privacy requirements in system design: the pris method</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kalloniatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kavakli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gritzalis</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00766-008-0067-3</idno>
		<ptr target="http://dx.doi.org/10.1007/s00766-008-0067-3" />
	</analytic>
	<monogr>
		<title level="j">Requir Eng</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="241" to="255" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Annual symposium on privacy enhancing technologies</title>
		<author>
			<persName><surname>Pets</surname></persName>
		</author>
		<ptr target="http://petsymposium.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Untraceable electronic mail, return addresses, and digital pseudonyms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="84" to="88" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Security without identification: transaction systems to make big brother obsolete</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun ACM</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1030" to="1044" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The dining cryptographers problem: unconditional sender and recipient untraceability</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Cryptol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="75" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">ISDN-mixes: untraceable communication with very small bandwidth overhead</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Waidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the GI/ITG conference on communication in distributed systems</title>
		<meeting>the GI/ITG conference on communication in distributed systems</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="451" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Hiding routing information</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Goldschlag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Syverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of information hiding: first international workshop</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Anderson</surname></persName>
		</editor>
		<meeting>information hiding: first international workshop</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1174</biblScope>
			<biblScope unit="page" from="137" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Crowds: anonymity for web transactions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rubin</forename><forename type="middle">A</forename></persName>
		</author>
		<ptr target="http://avirubin.com/crowds.pdf" />
	</analytic>
	<monogr>
		<title level="j">ACM Transact Inf Syst Secur</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Bacard</surname></persName>
		</author>
		<author>
			<persName><surname>Anonymous</surname></persName>
		</author>
		<ptr target="http://www.andrebacard.com/remail.html" />
		<imprint/>
	</monogr>
	<note>to: Cypherpunk tutorial</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">Mixmaster</forename><surname>Mixmaster</surname></persName>
		</author>
		<author>
			<persName><surname>Homepage</surname></persName>
		</author>
		<ptr target="http://mixminion.net/" />
		<title level="m">Mixminion officia site</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Freedom systems 2.1 security issues and analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shostack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Inc</publisher>
		</imprint>
	</monogr>
	<note>white paper, Zero Knowledge Systems</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Web MIXes: a system for anonymous and unobservable internet access</title>
		<author>
			<persName><forename type="first">O</forename><surname>Berthold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Federrath</surname></persName>
		</author>
		<author>
			<persName><surname>Ko ¨psell S</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of designing privacy enhancing technologies: workshop on design issues in anonymity and unobservability</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Federrath</surname></persName>
		</editor>
		<meeting>designing privacy enhancing technologies: workshop on design issues in anonymity and unobservability</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000. 2009</date>
			<biblScope unit="page" from="115" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Tor: the secondgeneration onion router</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dingledine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mathewson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Syverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX security symposium</title>
		<meeting>the 13th USENIX security symposium</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Networks without user observability-design options</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Waidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EUROCRYPT 1985</title>
		<meeting>EUROCRYPT 1985</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">219</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The dining cryptographers in the disco: unconditional sender and recipient untraceability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Waidner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfitzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EUROCRYPT 1989</title>
		<meeting>EUROCRYPT 1989</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">434</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Private authentication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fournet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor Comput Sci</title>
		<imprint>
			<biblScope unit="volume">322</biblScope>
			<biblScope unit="page" from="427" to="476" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Just fast keying: key agreement in a hostile internet</title>
		<author>
			<persName><forename type="first">W</forename><surname>Aiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Bellovin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blaze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Canetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Keromytis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Inf Syst Secur</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Distance-bounding protocols (extended abstract)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brands</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT93</title>
		<title level="s">LNCS</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">765</biblScope>
			<biblScope unit="page" from="344" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Signature schemes and anonymous credentials from bilinear maps</title>
		<author>
			<persName><forename type="first">J</forename><surname>Camenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lysyanskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings crypto</title>
		<title level="s">LNCS</title>
		<meeting>crypto</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3152</biblScope>
			<biblScope unit="page" from="56" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Deniable ring authentication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of crypto 2002</title>
		<title level="s">LNCS</title>
		<meeting>crypto 2002</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2442</biblScope>
			<biblScope unit="page" from="481" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Off-the-record communication, or, why not to use PGP</title>
		<author>
			<persName><forename type="first">N</forename><surname>Borisov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 ACM workshop on privacy in the electronic society</title>
		<meeting>the 2004 ACM workshop on privacy in the electronic society<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Protocols for secure computations</title>
		<author>
			<persName><forename type="first">Acc</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 23rd IEEE symposium on foundations of computer science</title>
		<meeting>23rd IEEE symposium on foundations of computer science</meeting>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="160" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Communication complexity and secure function evaluation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<idno>cs.CR/0109011</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">An efficient buyerseller watermarking protocol based on composite signal representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Preneel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM workshop on multimedia and security</title>
		<meeting>the 11th ACM workshop on multimedia and security<address><addrLine>Princeton, NJ; New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="9" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Private information retrieval</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goldreich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kushilevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="965" to="981" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">How to exchange secrets by oblivious transfer, technical report tr-81</title>
		<author>
			<persName><forename type="first">Rabin</forename><surname>Mo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
		<respStmt>
			<orgName>Aiken Computation Laboratory, Harvard University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">On the foundations of oblivious transfer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cachin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in cryptology-Eurocrypt</title>
		<title level="s">LNCS 1403</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998. 1998</date>
			<biblScope unit="page" from="361" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">State-of-the-art in privacy preserving data mining</title>
		<author>
			<persName><forename type="first">V</forename><surname>Verykios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fovino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Provenza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Saygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Theodoridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="50" to="57" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Cryptographic techniques for privacy preserving data mining</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pinkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Searchable encryption revisited: consistency properties, relation to anonymous ibe, and extensions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abdalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Catalano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kiltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kohno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malone-Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Paillier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of CRYPTO</title>
		<meeting>eeding of CRYPTO</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="205" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Private searching on streaming data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Skeith</surname></persName>
		</author>
		<author>
			<persName><surname>Iii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="223" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Achieving k-anonymity privacy protection using generalization and suppression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Uncertain Fuzziness Knowl-Based Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="571" to="588" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">l-diversity: privacy beyond k-anonymity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Venkitasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on data engineering (ICDE&apos;06)</title>
		<meeting>the 22nd international conference on data engineering (ICDE&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">On the limits of steganography</title>
		<author>
			<persName><forename type="first">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petitcolas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J Sel Areas Commun</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="474" to="481" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Covert channels and anonymizing networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Moskowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Crepeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on privacy in the electronic society</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Robust covert communication over a public audio channel using spread spectrum</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Malvar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information hiding</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="354" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Privacy-enhancing identity management</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Berlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Clauß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Waidner</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1363-4127(04)00014-7</idno>
		<ptr target="http://dx.doi.org/10.1016/S1363-4127" />
	</analytic>
	<monogr>
		<title level="j">Inf Secur Tech Rep (ISTR)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="17" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Privacy-enhancing identity management</title>
		<author>
			<persName><forename type="first">S</forename><surname>Clauß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Herreweghen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPTS Rep</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="8" to="16" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Privacy weaknesses in biometric sketches</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simoens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Preneel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 30th IEEE symposium on security and privacy</title>
		<meeting>the 2009 30th IEEE symposium on security and privacy<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="188" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Handbook of applied cryptography</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pcv</forename><surname>Oorschot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Vanstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Washington</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">A survey of homomorphic encryption for non-specialists</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Galand</surname></persName>
		</author>
		<ptr target="http://www.hindawi.com/RecentlyAcceptedArticlePDF.aspx?journal=IS&amp;number=13801" />
	</analytic>
	<monogr>
		<title level="j">EURASIP J Inf Secur</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Verifiable encryption and applications to group signatures and signature sharing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Camenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Damgard</surname></persName>
		</author>
		<idno>RS-98-32</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>BRICS, Department of Computer Science, University of Aarhus</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Flexible team-based access control using contexts</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Georgiadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mavridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pangalos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="21" to="27" />
		</imprint>
		<respStmt>
			<orgName>SACMAT</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Privacy-aware collaborative access control in web-based social networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Carminati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd IFIP WG 11.3 working conference on data and applications security</title>
		<meeting>the 22nd IFIP WG 11.3 working conference on data and applications security</meeting>
		<imprint>
			<publisher>DBSEC</publisher>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Exploiting cryptography for privacy-enhanced access control: a result of the PRIME project</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ardagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kohlweiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Priem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Samarati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verdicchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Secur</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="160" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m">OASIS, eXtensible access control markup language: XACML</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Enterprise privacy authorization language: EPAL 1.2</title>
		<author>
			<persName><surname>Ibm</surname></persName>
		</author>
		<ptr target="http://www.w3.org/Submission/2003/SUBM-E" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Understanding privacy settings in facebook with an audience view</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Lipford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Besmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Watson</surname></persName>
		</author>
		<ptr target="http://www.usenix.org/events/upsec08/tech/full_papers/lipford/lipford.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st conference on usability, psychology, and security, USENIX Association</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Churchill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Dhamija</surname></persName>
		</editor>
		<meeting>the 1st conference on usability, psychology, and security, USENIX Association<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Privacyenabling social networking over untrusted networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Stajano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WOSN &apos;09: Proceedings of the 2nd ACM workshop on online social networks</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Enforcing access control in social networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Beato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kohlweiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wouters</surname></persName>
		</author>
		<ptr target="http://www.cosic.esat.kuleuven.be/publications/article-1240.pdf" />
	</analytic>
	<monogr>
		<title level="m">HotPets</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<author>
			<persName><surname>Primelife</surname></persName>
		</author>
		<ptr target="http://www.primelife.eu/" />
		<title level="m">The European PrimeLife research project-privacy and identity management in Europe for life</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Representing and using non-functional requirements: a process-oriented approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mylopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transact Softw Eng</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="483" to="497" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Privacy guidelines for developing software products and services, version 3.1, technical report</title>
		<imprint>
			<date type="published" when="2008-09">Sept 2008</date>
			<publisher>Microsoft Coorporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Designing for privacy and other competing requirements</title>
		<author>
			<persName><forename type="first">E</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Cysneiros</surname></persName>
		</author>
		<idno>SREIS-02</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd symposium on requirements engineering for information security</title>
		<meeting>the 2nd symposium on requirements engineering for information security</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="15" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Security and privacy requirements analysis within a social setting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mylopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Requir Eng IEEE Int Conf</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page">151</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Computer-aided privacy requirements elicitation technique</title>
		<author>
			<persName><forename type="first">S</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia-Pacific conference on services computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2008. 2006</date>
			<biblScope unit="page" from="367" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Analyzing website privacy requirements using a privacy goal taxonomy. In: RE &apos;02: Proceedings of the 10th anniversary IEEE joint international conference on requirements engineering</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Anto ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Earp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reese</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="23" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Danezis</surname></persName>
		</author>
		<ptr target="http://research.microsoft.com/en-us/um/people/gdane/talks/Privacy_Technology_cosic.pdf" />
		<title level="m">Talk: introduction to privacy technology</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
