<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generalized Canonical Time Warping</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Feng</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fernando</forename><surname>De La Torre</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">F. Zhou and F. De la Torre are with Robotics Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>1 2 3 4 5 6 7 8 9 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 6 7 8 1 2 3 4 5 1 2 3 4 5</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generalized Canonical Time Warping</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3088127C638A949BD51A25A362CB19FB</idno>
					<idno type="DOI">10.1109/TPAMI.2015.2414429</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2015.2414429, IEEE Transactions on Pattern Analysis and Machine Intelligence SUBMITTED TO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, DECEMBER 2014 1 This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2015.2414429, IEEE Transactions on Pattern Analysis and Machine Intelligence SUBMITTED TO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, DECEMBER 2014 This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2015.2414429, IEEE Transactions on Pattern Analysis and Machine Intelligence</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multi-modal sequence alignment</term>
					<term>Canonical correlation analysis</term>
					<term>Dynamic time warping</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Temporal alignment of human motion has been of recent interest due to its applications in animation, tele-rehabilitation and activity recognition. This paper presents generalized canonical time warping (GCTW), an extension of dynamic time warping (DTW) and canonical correlation analysis (CCA) for temporally aligning multi-modal sequences from multiple subjects performing similar activities. GCTW extends previous work on DTW and CCA in several ways: (1) it combines CCA with DTW to align multi-modal data (e.g., video and motion capture data); (2) it extends DTW by using a linear combination of monotonic functions to represent the warping path, providing a more flexible temporal warp. Unlike exact DTW, which has quadratic complexity, we propose a linear time algorithm to minimize GCTW. (3) GCTW allows simultaneous alignment of multiple sequences. Experimental results on aligning multi-modal data, facial expressions, motion capture data and video illustrate the benefits of GCTW.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>T EMPORAL alignment of multiple time series is an important problem with applications in many areas such as speech recognition <ref type="bibr" target="#b0">[1]</ref>, computer graphics <ref type="bibr" target="#b1">[2]</ref>, computer vision <ref type="bibr" target="#b2">[3]</ref>, and bio-informatics <ref type="bibr" target="#b3">[4]</ref>. In particular, alignment of human motion from sensory data has recently received increasing attention in computer vision and computer graphics to solve problems such as curve matching <ref type="bibr" target="#b4">[5]</ref>, temporal clustering <ref type="bibr" target="#b5">[6]</ref>, telerehabilitation <ref type="bibr" target="#b6">[7]</ref>, activity recognition <ref type="bibr" target="#b7">[8]</ref> and motion synthesis <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. While algorithms for aligning time series have been commonly used in computer vision and computer graphics, a relatively unexplored problem has been the alignment of multi-dimensional and multimodal time series that encode human motion. Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the main problem addressed by this paper: how can we efficiently find the temporal correspondence between (1) frames of a video, (2) samples of motion capture data and (3) samples of 3-axis accelerometers of different subjects performing a similar action?</p><p>The alignment of multi-dimensional, multi-modal time series of human motion poses several challenges. First, there is typically a large variation in the subjects' physical characteristics, motion style and speed performing the activity. Second, large changes in view point also complicate the correspondence problem <ref type="bibr" target="#b10">[11]</ref>. Third, it is unclear how existing techniques can be used to align sets of time series that have different modalities (e.g., video and motion capture data). While there is extensive literature on time series alignment (e.g., <ref type="bibr" target="#b11">[12]</ref>), standard extensions of dynamic time warping (DTW) or Bayesian networks are not capable of aligning align multi-modal data.</p><p>To address these problems, this paper proposes generalized canonical time warping (GCTW), a technique to temporally align multi-modal time series of different subjects performing similar activities. GCTW is a spatiotemporal alignment method that temporally aligns two or more multi-dimensional and multi-modal time series by maximizing the correlation across them. GCTW can be seen as an extension of DTW or canonical correlation analysis (CCA). To accommodate for subject variability and take into account the difference in the dimensionality of the signals, GCTW uses CCA as a measure of spatial correlation. GCTW extends DTW by incorporating a feature weighting mechanism to align signals of different dimensionality and provide higher weights to the features that make both signals more correlated. It also extends DTW by parameterizing the warping path as a combination of monotonic functions, providing more accurate alignment and faster optimization strategies. Unlike exact approaches based on DTW, which have quadratic cost, GCTW uses a Gauss-Newton algorithm that has linear complexity in the length of the sequence. Preliminary versions of this paper were published in <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Temporal alignment</head><p>This section discusses prior work on alignment of time series in the context of computer graphics, computer vision and data mining.</p><p>In the literature of computer graphics, temporal alignment of human motion has been commonly applied to solve problems such as content modeling <ref type="bibr" target="#b14">[15]</ref>, and motion blending <ref type="bibr" target="#b1">[2]</ref>. Hsu et al. <ref type="bibr" target="#b8">[9]</ref> proposed iterative motion warping, a robust method that finds a spatio-temporal warping between two instances of motion captured data. Shapiro et al. <ref type="bibr" target="#b15">[16]</ref> used independent component analysis to separate motion data into visually meaningful components called style components. In comparison, our method solves a more general problem of aligning human motion from multi-modal time series.</p><p>In the context of computer vision, temporal alignment of video captured with different cameras and view points has been a topic of interest. Rao et al. <ref type="bibr" target="#b16">[17]</ref> aligned trajectories of two moving points using constraints from the fundamental matrix. Junejo et al. <ref type="bibr" target="#b7">[8]</ref> adopted DTW for synchronizing human actions with view changes based on a view-invariant description. In comparison, our method simultaneously estimates the optimal spatial transformation and temporal correspondence to align video sequences. Recently, Gong and Medioni <ref type="bibr" target="#b17">[18]</ref> extended CTW approach to incorporate more complex spatial transformations through manifold learning. Nicolaou et al. <ref type="bibr" target="#b18">[19]</ref> proposed a probabilistic extension of CTW for fusing multiple continuous expert annotations in tasks related to affective behavior. These works show the flexibility of our framework for aligning various types of time series.</p><p>In the field of data mining, there have been several extensions of DTW to align time series that differ in the temporal and spatial domain. Keogh and Pazzani <ref type="bibr" target="#b19">[20]</ref>, for example, used derivatives of the original signal to improve alignment with DTW. Listgarten et al. <ref type="bibr" target="#b20">[21]</ref> proposed continuous profile models, a probabilistic method for simultaneously aligning and normalizing sets of time series in bio-informatics. Unlike these works, which were originally designed for aligning 1-D time series, our work addresses the more challenging problem of aligning multi-modal and multi-dimensional time series.</p><p>In the literature of manifold alignment, Ham et al. <ref type="bibr" target="#b21">[22]</ref> aligned manifolds of images in a semi-supervised manner. The prior knowledge of pairwise correspondences between two sets was used to guide the graph embedding. Wang and Mahadevan <ref type="bibr" target="#b22">[23]</ref> aligned manifolds based on an extension of the Procrustes analysis (PA). The main benefit of this approach is that PA learns a mapping generalized for out-of-sample cases. However, these models lack a mechanism to enforce temporal continuity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Canonical Correlation Analysis (CCA)</head><p>CCA <ref type="bibr" target="#b23">[24]</ref> is a technique to extract common features from a pair of multi-variate data. Given two sets of n variables (see footnote for the notation 1 ),</p><formula xml:id="formula_0">X = [x 1 , • • • , x n ] 2 R dx⇥n and Y = [y 1 , • • • , y n ] 2 R dy⇥n , CCA</formula><p>finds the linear combinations of the variables in X that are most correlated with the linear combinations of the variables in Y. Assuming zero-mean data ( P i x i = P j y j = 0), CCA finds a combination of the original features that minimizes the sum of the distances between samples:</p><formula xml:id="formula_1">min {Vx,Vy }2 Jcca = kV T x X V T y Yk 2 F + (Vx) + (Vy),<label>(1)</label></formula><p>where V x 2 R dx⇥d and V y 2 R dy⇥d denote the lowdimensional embeddings (d  min(d x , d y )) for X and Y respectively. (•) is a regularization function that penalizes the high-frequency components of the embedding matrices:</p><formula xml:id="formula_2">(V) = 1 kVk 2 F ,<label>(2)</label></formula><p>In order to avoid the trivial solution of V T x X and V T y Y being zero, CCA decorrelates the canonical variates (columns of V T x X and V T y Y) by imposing the orthogonal constraint as:</p><formula xml:id="formula_3">= n {Vx, Vy} V T x ⇣ (1 )XX T + I ⌘ Vx = I, V T y ⇣ (1 )YY T + I ⌘ Vy = I o .<label>(3)</label></formula><p>where 2 [0, 1] is a weight to trade-off between the least-squared error and the regularization terms. In the case of insufficient samples where the covariance matrices (XX T or YY T ) are singular, a positive regularization term I is necessary to avoid over-fitting and for numerical stability. Optimizing (1) has a closed-form solution in terms of a generalized eigenvalue problem, i.e., [V x ; V y ] = eig d (A, B), where:</p><formula xml:id="formula_4">A =  0 XY T YX T 0 , B = (1 )  XX T 0 0 YY T + I.</formula><p>See <ref type="bibr" target="#b24">[25]</ref> for a unification of several component analysis methods and a review of numerical techniques to efficiently solve generalized eigenvalue problems.</p><p>In computer vision, CCA has been used for matching sets of images in problems such as activity recognition from video <ref type="bibr" target="#b25">[26]</ref> and activity correlation from cameras <ref type="bibr" target="#b26">[27]</ref>. Recently, Fisher et al. <ref type="bibr" target="#b27">[28]</ref> proposed an extension of CCA with parameterized warping functions to align protein expressions. The learned warping function is a linear combination of hyperbolic tangent functions with non-negative coefficients, ensuring monotonicity. Similarly, Shariat and Pavlovic <ref type="bibr" target="#b28">[29]</ref> imposed monotonic constraints on CCA using non-negative least squares for activity recognition tasks. However, these methods were unable to deal with feature weighting.</p><p>1. Bold capital letters denote a matrix X, bold lower-case letters a column vector x. x i and x (i) represent the i th column and i th row of the matrix X respectively. x ij denotes the scalar in the i th row and j th column of the matrix X. All non-bold letters represent scalars.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dynamic Time Warping (DTW)</head><p>Given two time series, <ref type="bibr" target="#b0">[1]</ref> aligns X and Y such that the sum of the distances between the aligned samples is minimized:</p><formula xml:id="formula_5">X = [x 1 , • • • , x nx ] 2 R d⇥nx and Y = [y 1 , • • • , y ny ] 2 R d⇥ny , DTW</formula><formula xml:id="formula_6">min {px,py }2 J dtw = l X t=1 kx p x t y p y t k 2 2 ,<label>(4)</label></formula><p>where l max(n x , n y ) is the number of indices used to align the samples. The optimal l is automatically selected by the DTW algorithm. The warping paths, p x 2 {1 : n x } l and p y 2 {1 : n y } l , denote the composition of alignment in frames. The i th frame in X and the j th frame in Y are aligned if there exist p x t = i and p y t = j at some step t.</p><p>In order to find a polynomial time solution, the warping paths must satisfy three constraints: </p><formula xml:id="formula_7">= n {px, py} px 2 {1 : nx} l and py 2 {1 : ny} l ,<label>(5)</label></formula><formula xml:id="formula_8">Boundary: [p x 1 , p y 1 ] = [</formula><formula xml:id="formula_9">] [p x t 1 , p y t 1 ] 2 {[0, 1], [1, 0], [1, 1]} o .</formula><p>The choice of step size in the continuity constraint is not unique. For instance, replacing the step size by {[2, 1], <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b0">1]</ref>} can avoid the degenerate case in which a single frame of one sequence is assigned to many consecutive frames in the other sequence. See <ref type="bibr" target="#b0">[1]</ref> for an extensive review on several DTW's modifications to control the warping paths.</p><p>Although the number of possible ways to align X and Y is exponential in n x and n y , dynamic programming (DP) <ref type="bibr" target="#b29">[30]</ref> offers an efficient approach with complexity of O n x n y to minimize J dtw using Bellman's equation: where the cost-to-go value function, J ⇤ (p x t , p y t ), represents the cost remaining starting at the t th step using the optimal policy ⇡ ⇤ . The policy function, ⇡(•, •) : Once the policy queue is known, the alignment steps can be recursively selected by backtracking, p x l = n x and p y l = n y . Fig. <ref type="figure" target="#fig_1">2a</ref> shows an example of DTW for aligning two 1-D time series. Fig. <ref type="figure" target="#fig_1">2b</ref> illustrates the Euclidean distance of each pair of samples. To compute the optimal warping path, DP efficiently enumerates all possible steps as in Fig. <ref type="figure" target="#fig_1">2c</ref> from the upper-left corner to the bottom-right one. At the end, the optimal alignment (red curve) can be computed by iteratively tracing back along the arrows.</p><formula xml:id="formula_10">J ⇤ (p x t ,</formula><formula xml:id="formula_11">{1 : n x } ⇥ {1 : n y } ! {[1, 0], [0, 1], [1, 1]},</formula><p>Given two sequences of length n x and n y , exact DTW has a computational cost in space and time of O(n x n y ). In practice, various modifications <ref type="bibr" target="#b0">[1]</ref> on the step size, local weights and global constraints (e.g., the Sakoe-Chiba and Itakura Parallelogram bands <ref type="bibr" target="#b0">[1]</ref>) have been proposed to speed up the DTW computation as well as to better control the possible routes of the warping paths. In recent work <ref type="bibr" target="#b30">[31]</ref>- <ref type="bibr" target="#b32">[33]</ref>, a multi-scale searching scheme has been shown to effectively generate a speedup from one to three orders of magnitude, compared to the classic DTW algorithm. More recently, Rakthanmanon et al. <ref type="bibr" target="#b33">[34]</ref> have shown that DTW for mining 1-D subsequences can be scaled up to very large datasets using early-abandoning and cascading lower bounds. However, most of these works are originally designed for 1-D time series. In comparison, our method can be applied to deal with more general multi-dimensional sequences and align signals of different dimensionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CANONICAL TIME WARPING (CTW)</head><p>DTW lacks a feature weighting mechanism and thus it cannot be directly used for aligning multi-modal sequences (e.g., video and motion capture) with different features. To address this issue, this section presents CTW, a unified framework that combines DTW with CCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Least-squares formulation for DTW</head><p>In order to have a compact and compressible energy function for CTW, it is important to note that the original objective of DTW (4) can be reformulated in matrix form as:</p><formula xml:id="formula_12">min {px,py }2 J dtw = kXWx YWyk 2 F ,<label>(6)</label></formula><p>where X 2 R d⇥nx and Y 2 R d⇥ny denote the two time series to be aligned. W x = W(p x ) 2 {0, 1} nx⇥l and W y = W(p y ) 2 {0, 1} ny⇥l are two binary warping matrices (Fig. <ref type="figure" target="#fig_1">2e-f</ref>) associated with the warping paths by a non-linear mapping,</p><formula xml:id="formula_13">W(p) : {1 : n} l ! {0, 1} n⇥l ,<label>(7)</label></formula><p>The value of the elements of W is always 0 or 1. w pt,t is 1 for any step t 2 {1 : l}, and zero otherwise. The matrix W x X has the effect to replicate (possibly multiple times) samples of the X. Similarly for W y . Fig. <ref type="figure" target="#fig_1">2d</ref> shows that the DTW alignment in Fig. <ref type="figure" target="#fig_1">2a</ref> can be equivalently interpreted as stretching the two time series X and Y by multiplying them with the warping matrices W x and W y , respectively as shown in Fig. <ref type="figure" target="#fig_1">2e</ref>f. Note that ( <ref type="formula" target="#formula_12">6</ref>) is very similar to CCA's objective <ref type="bibr" target="#b0">(1)</ref>.</p><p>CCA applies a linear transformation to combine the rows (features), while DTW applies binary transformations to replicate the columns (time). It is important to notice that reformulating DTW as a least-squared optimization function allows easy generalizations, and this is one of the important contributions of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Objective function of CTW</head><p>In order to accommodate for differences in style and subject variability, add a feature selection mechanism, and reduce the dimensionality of the signals, CTW adds a linear transformation (V x 2 R dx⇥d and V y 2 R dy⇥d ) to the least-squared form of DTW <ref type="bibr" target="#b5">(6)</ref> </p><formula xml:id="formula_14">Jctw = kV T x XWx V T y YWyk 2 F + (Vx) + (Vy),<label>(8)</label></formula><p>where V x 2 R dx⇥d and V y 2 R dy⇥d parameterize the spatial transformation and project the sequences into the same low-dimensional coordinate system. Constrained by <ref type="bibr" target="#b4">(5)</ref>, W x and W y warp the signal in time to maximize the temporal correlation. Similar to CCA, (•) is a regularization term (2) for V x and V y . In addition, the projections satisfy the constraints,</p><formula xml:id="formula_15">= n {Vx, Vy} V T x ⇣ (1 )XWxW T x X T + I ⌘ Vx = I, V T y ⇣ (1 )YWyW T y Y T + I ⌘ Vy = I o ,</formula><p>where 2 [0, 1] is to trade-off between the least-squared error and the regularization term. Equation ( <ref type="formula" target="#formula_14">8</ref>) is the main contribution of this paper. CTW is a clean extension of CCA and DTW to align two signals in space and time. It extends previous work on CCA by adding temporal alignment and on DTW by allowing a feature selection and dimensionality reduction mechanism for aligning signals of different dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Optimization of CTW</head><p>Optimizing J ctw is a non-convex optimization problem with respect to the warping matrices and projection matrices. We take a coordinate-descent approach that alternates between solving the temporal alignment using DTW, and computing the spatial projections using CCA.</p><p>Given the warping matrices, the optimal projection matrices are the leading d generalized eigenvectors, i.e., [V x ; V y ] = eig d (A, B), where:</p><formula xml:id="formula_16">A =  0 X W xW T y Y T YWyW T x X T 0 , B = (1 )  XWxW T x X T 0 0 Y W y W T y Y T + I.</formula><p>In most experiments, we initialized CTW by setting W x and W y a uniform warping that aligns the sequences. In this case, the warping paths are computed as</p><formula xml:id="formula_17">p x = round(linspace(1, n x , l)) 0 ,<label>(9)</label></formula><p>where round(•) and linspace(•) are MATLAB functions.</p><p>But CTW can be initialized by any other time warping method such as DTW or iterative motion warping (IMW) <ref type="bibr" target="#b8">[9]</ref>. The dimension d can be selected to preserve a certain amount (e.g., 90%) of the total correlation. Once the spatial transformation is computed, the temporal alignment is computed using standard approaches for DTW. Alternating between these two steps (spatial and temporal alignment) monotonically decreases J ctw . J ctw is bounded below, so the proposed algorithm will converge to a critical point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GENERALIZED CANONICAL TIME WARPING (GCTW)</head><p>In the previous section, we described CTW, a technique that is able to align two multi-modal sequences with different features. However, CTW has three main limitations inherited from DTW: (1) The exact computational complexity of DTW for multi-dimensional sequences is quadratic both in space and time; (2) CTW and its extensions address the problem of aligning two sequences, but it is unclear how to extend it to the alignment of multiple sequences; (3) The temporal alignment is computed using DTW, which relies on DP to find the optimal path. In some problems (e.g., sub-sequence alignment) the warping path provided by DP is too rigid (e.g., the first and the last samples have to match).</p><p>To address these issues, this section proposes GCTW, an efficient technique for spatio-temporal alignment of multiple time series. To accommodate for subject variability and to take into account the difference in the dimensionality of the signals, GCTW uses multi-set CCA (mCCA). To compensate for temporal changes, GCTW extends DTW by incorporating a more efficient and flexible temporal warping parameterized by a set of monotonic basis functions. Unlike existing approaches based on DP with quadratic complexity, GCTW efficiently optimizes the time warping function using a Gauss-Newton algorithm, which has linear complexity in the length of the sequence. The warping function Qa is a linear combination of three basis functions including a constant function (q 1 ) and two monotonic functions (q 2 and q 3 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Objective function of GCTW</head><p>Given a collection of m time series, {X i } m i=1 , GCTW aims to seek for each</p><formula xml:id="formula_18">X i = [x i 1 , • • • , x i ni ] 2 R di⇥ni , a low- dimensional spatial embedding V i 2 R di⇥d and a non- linear temporal transformation W i = W(p i ) 2 {0, 1} ni⇥l parameterized by p i 2 {1 : n i } l , such that the resulting sequence V T i X i W i 2 R</formula><p>d⇥l is well aligned with the others in the least-squared sense. In a nutshell, GCTW minimizes the sum of pairwise distances:</p><formula xml:id="formula_19">min {V i } i 2 ,{p i } i 2 Jgctw = m X i=1 m X j=1 1 2 kV T i XiWi V T j XjWjk 2 F + m X i=1 ⇣ (Vi) + (pi) ⌘ ,<label>(10)</label></formula><p>where</p><formula xml:id="formula_20">(V i ) = m /(1 )kV i k 2</formula><p>F is the regularization function penalizing the irregularity of the spatial transformation V i .</p><p>2 [0, 1] is a trade-off parameter between the least-squared error and the regularization term. Following the multi-set CCA (mCCA) <ref type="bibr" target="#b34">[35]</ref>, GCTW constrains the spatial embeddings as:</p><formula xml:id="formula_21">= n {Vi}i m X i=1 V T i ⇣ (1 )XiWiW T i X T i + I ⌘ Vi = I o .</formula><p>(•) and (•), defined in the following sections, are used to respectively regularize and constrain the temporal transformation p i .</p><p>Let us consider a single sequence X 2 R d⇥n and its temporal warping, p 2 {1 : n} l . While the possible composition of the temporal warping path, p, is locally enforced by the original DTW constraints (5), the global shape of any valid p must correspond to a monotonic and continuous trajectory in matrix W 2 {0, 1} n⇥l starting from the upper-left corner and ending at the bottomright one. Recall that any nonnegative combination of monotonic trajectories is guaranteed to be monotonic. GCTW parameterizes the warping path p as a linear combination of monotonic functions:</p><formula xml:id="formula_22">p ⇡ k X c=1 acqc = Qa,<label>(11)</label></formula><p>where a 2 R k , a 0 is the non-negative weight vector and Q</p><formula xml:id="formula_23">= [q 1 , • • • , q k ] 2 [1,</formula><p>n] l⇥k is the basis set composed of k pre-defined monotonically increasing functions. Fig. <ref type="figure" target="#fig_2">3a</ref> illustrates five common choices for q c , including (1) polynomial (ax b ), ( <ref type="formula" target="#formula_2">2</ref>) exponential (exp(ax+b)), (3) logarithm (log(ax + b)), (4) hyperbolic tangent (tanh(ax + b)) and ( <ref type="formula" target="#formula_7">5</ref>) I-spline <ref type="bibr" target="#b35">[36]</ref>. Similar work by Fisher et al. <ref type="bibr" target="#b27">[28]</ref> also used hyperbolic tangent functions as temporal bases, and the weights were optimized using a non-negative least squares algorithm. However, GCTW differs in three aspects: (1) GCTW allows aligning multi-dimensional time series that have different features, while <ref type="bibr" target="#b27">[28]</ref> can only align one-dimensional time-series; (2) GCTW uses a more efficient eigen decomposition to solve mCCA and quadratic programming for optimizing the weights; and (3) GCTW uses a family of monotonic functions that allow for a more general warping (e.g., sub-sequence alignment), and constraints to regularize the solution.</p><p>To approximate the DTW constraints ( <ref type="formula" target="#formula_7">5</ref>) on the warping path p, we alternatively impose the following constraints on the weights a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Boundary conditions:</head><p>We enforce the position of the first frame, p 1 = q (1) a 1, and the last frame, p l = q (l) a  n, where q (1) 2 R 1⇥k and q (l) 2 R 1⇥k are the first and last rows of the basis matrix Q respectively. In contrast to DTW, which imposes a tight boundary (i.e., p 1 = 1 and p l = n), GCTW allows p to index a sub-part of X. This relaxation is useful in solving the more general problem of sub-sequence alignment. For instance, Fig. <ref type="figure" target="#fig_4">4</ref> illustrates an example of matching a shorter 1-D sequence (blue) to a sub-sequence of the longer one (red). In this sub-sequence alignment problem, GCTW models the time warping p as a combination of a linear basis q 1 and a constant basis q 2 . Monotonicity: We enforce t 1  t 2 ) p t1  p t2 by constraining the sign of the weight: a 0. Note that constraining the weights is a sufficient condition to ensure monotonicity but it is not necessary. See <ref type="bibr" target="#b36">[37]</ref>- <ref type="bibr" target="#b38">[39]</ref> for in-depth discussions on monotonic functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continuity:</head><p>To approximate the hard constraint on the step size, GCTW penalizes the curvature of the warping path using a temporal regularization term, P l t=1 krq (t) ak 2 2 ⇡ kF l Qak 2 2 where F l 2 R l⇥l is the 1 st order differential operator.</p><p>In summary, we constrain the warping path in (10) by adding the following constraints on a,</p><formula xml:id="formula_24">(a) = ⌘kF l Qak 2 2 , = {a | La  b},<label>(12)</label></formula><p>where L = [ I k ; q (1) ; q (l) ] and b = [0 k ; 1; n] Therefore, given a basis set of k monotone functions, all feasible weights belong to a polyhedron in R k parameterized by L 2 R (k+2)⇥k and b 2 R k+2 . For instance, Fig. <ref type="figure" target="#fig_2">3d</ref> illustrates an example of a warping function (solid line) as a combination of three monotone functions (dotted lines).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimization of GCTW w.r.t. spatial basis</head><p>Minimizing Jgctw (10) is a non-convex optimization problem with respect to the temporal transformation and the spatial projection. We optimize GCTW by alternating between solving for the time warping using an efficient Gauss-Newton algorithm (see Section 4.3), and computing the spatial transformation using mCCA.</p><p>Assuming the time warping is fixed, mCCA computes the optimal {Vi}i using a generalized eigen decomposition as</p><formula xml:id="formula_25">[V1; • • • ; Vm] = eig d (A, B)</formula><p>, where:</p><formula xml:id="formula_26">A = 2 6 6 4 Y1Y T 1 • • • Y1Y T m . . . . . . . . . YmY T 1 • • • YmY T m 3 7 7 5 2 6 6<label>4</label></formula><formula xml:id="formula_27">Y1Y T 1 • • • 0 . . . . . . . . . 0 • • • YmY T m 3 7 7 5 , B = (1 ) 2 6 6<label>4</label></formula><formula xml:id="formula_28">Y1Y T 1 • • • 0 . . . . . . . . . 0 • • • YmY T m 3 7 7 5 + I, Yi , XiWi</formula><p>These steps monotonically decrease J gctw , and because the function is bounded below, the alternating scheme will converge to a critical point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Optimization of GCTW w.r.t. temporal weights</head><p>This section describes how GCTW relaxes the warping path to be a linear combination of monotonic paths, 11 provides a new model for temporal alignment and new methods for optimizing it. Given k bases, Q 2 R l⇥k , optimizing <ref type="bibr" target="#b9">(10)</ref> with respect to the warping paths {p i } i can be written as:</p><formula xml:id="formula_29">min {a i } i Ja = m X i=1 m X j=1 1 2 k V T i XiW(Qai) | {z } Z(a i ) V T j XjW(Qaj) | {z } Z(a j ) k 2 F + m X i=1 ⌘kF l Qaik 2 2 , s. t. Liai  bi, 8i,<label>(13)</label></formula><p>where W(•) is a non-linear mapping function defined in <ref type="bibr" target="#b6">(7)</ref>. L i and b i are used to constrain the monotonicity and boundary of the time warping for each sequence. To shorten in notation, we denote each term</p><formula xml:id="formula_30">V T i X i W(Qa i ) 2 R d⇥l as Z(a i ).</formula><p>A direct optimization of J a is difficult due to the non-linear function W(•). Inspired by the Lucas-Kanade framework for image alignment <ref type="bibr" target="#b39">[40]</ref>, we approximate the temporal alignment problem using a Gauss-Newton (GN) method. More specifically, GN iteratively updates the weights âi a i + i by minimizing a series of firstorder Taylor approximations of J a centered at each term Z(a i ) given the initial a i , where i 2 R k denotes the increment of the weight a i .</p><p>To better understand the approximation, let us first focus on,</p><formula xml:id="formula_31">z t (a i ) 2 R d , the t th column of Z(a i ) = [z 1 (a i ), • • • , z l (a i )],</formula><p>which can be rewritten as,</p><formula xml:id="formula_32">zt(ai) = [V T i XiW(Qai)]t = V T i Xi[W(Qai)]t,<label>(14)</label></formula><p>where [•] t denotes the t th column of a matrix. According to the definition of W(•) in ( <ref type="formula" target="#formula_13">7</ref>), [W(Qa i )] t 2 {0, 1} n is a binary vector with only one non-zero element located at</p><formula xml:id="formula_33">q (t) a i , where q (t) 2 R 1⇥k is the t th row of Q. In other words, z t (a i ) is a replication of q (t) a th i column of the signal V T i X i , i.e., z t (a i ) = [V T i X i ] q (t) ai</formula><p>. Following <ref type="bibr" target="#b39">[40]</ref>, we approximate z t (a i + i ) as,</p><formula xml:id="formula_34">zt(ai + i) ⇡ zt(ai) + r(V T i Xi)| q (t) a i @q (t) ai @ai i,<label>(15)</label></formula><p>where r(V T i X i )| q (t) ai 2 R d denotes the row-wise gradient 2 of the signal V T i X i around column q (t) a i . The term, @q (t) a i /@a i = q (t) 2 R 1⇥k is the Jacobian of the time warping. Putting together the approximations of each column of Z(a i + i ) using ( <ref type="formula" target="#formula_34">15</ref>) yields:</p><formula xml:id="formula_35">vec ⇣ Z(ai + i) ⌘ ⇡ vi + Gi i,<label>(16)</label></formula><p>where vi = vec</p><formula xml:id="formula_36">⇣ Z(ai) ⌘ , Gi = 2 6 6 4 r(V T i Xi)| q (1) a i q (1) . . . r(V T i Xi)| q (l) a i q (l) 3 7 7 5 .</formula><p>Plugging ( <ref type="formula" target="#formula_35">16</ref>) in ( <ref type="formula" target="#formula_29">13</ref>) yields the approximation:</p><formula xml:id="formula_37">m X i=1 m X j=1 1 2 kvi + Gi i vj Gj j k 2 2 + m X i=1 ⌘kFiQ(ai + i)k 2 2 .</formula><p>Minimizing it with respect to all the weight increments</p><formula xml:id="formula_38">= [ 1 ; • • • ; m ] 2 R mk yields a quadratic programming problem: min 1 2 T H + f T , s. t. L  b La,<label>(17)</label></formula><p>whose components are computed as follows:</p><formula xml:id="formula_39">H = 2 6 6<label>4</label></formula><formula xml:id="formula_40">mG T 1 G1 + ⌘Q T F T 1 F1Q • • • G T 1 Gm . . . . . . . . . G T m G1 • • • mG T m Gm + ⌘Q T F T m FmQ 3 7 7 5 , f = 2 6 6 4</formula><p>G T 1 (mv1 </p><formula xml:id="formula_41">P i vi) + ⌘Q T F T 1 F1Qa1 . . . G T m (mvm P i vi) + ⌘Q T F T m FmQam<label>3</label></formula><formula xml:id="formula_42">L1 • • • 0 . . . . . . . . . 0 • • • Lm 3 7 7 5 .</formula><p>Note that the objective function of ( <ref type="formula" target="#formula_38">17</ref>) is convex. Fig. <ref type="figure" target="#fig_4">4</ref> illustrates an example of aligning two 1-D time series (Fig. <ref type="figure" target="#fig_4">4a</ref>) using this approach. To achieve sub-sequence alignment, we model the time warping path p as a combination of a linear basis q 1 and a constant one q 2 (Fig. <ref type="figure" target="#fig_4">4d</ref>). As shown in Fig. <ref type="figure" target="#fig_4">4c</ref>, Gauss-Newton takes three steps to find the optimal warping parameter in a 2-D space (Fig. <ref type="figure" target="#fig_4">4b</ref>).</p><p>In most experiments, we initialized a i by uniformly aligning the sequences (see GN-Init curve in Fig. <ref type="figure" target="#fig_5">5b</ref>). However, better results can be achieved by using a more sophisticated initialization method. The length of the warping path l is usually set to be l = 1.1 max m i=1 n i . The computational complexity of the algorithm is O(dlmk + m 3 k 3</p><p>).</p><p>2. The gradient is independently computed for each row of V T i X i . ) and a constant function (q 2 ) used for scaling and translation respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison with other DTW techniques</head><p>As discussed in <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b32">[33]</ref>, there are various techniques that have been proposed to accelerate DTW. For instance, the Sakoe-Chiba band (DTW-SC) and the Itakura Parallelogram band (DTW-IP) reduce the complexity of the original DTW algorithm to O( n x n y ) by constraining the warping path to be in a band of a certain shape, where &lt; 1 is the size ratio between the band and the original search space of DTW. However, using a narrow band (a small ) cuts off potential warping space, and may lead to a sub-optimal solution. For instance, Fig. <ref type="figure" target="#fig_5">5a</ref> shows an example of two 1-D time series and the alignment results calculated by different algorithms. The results computed by DTW-SC and DTW-IP are less accurate than the ones computed using our proposed Gauss-Newton (GN). This is because both the SC and IP bands are over-constrained (Fig. <ref type="figure" target="#fig_5">5b</ref>). Alternatively, instead of constraining the warping path, exhaustive DTW search can be approximated in a multi-level scheme. For instance, Salvador and Chan <ref type="bibr" target="#b32">[33]</ref> introduced FastDTW by recursively projecting a solution from a coarser resolution and refining the projected solution in a higher resolution. Although the coarse-to-fine framework could largely reduce the search space, the solution is not exact. See Fig. <ref type="figure" target="#fig_6">6</ref> for a detailed comparison.</p><p>To provide a quantitative evaluation, we synthetically generated 1-D sequences at 15 scales. For DTW-SC, we set the bandwidth to be = 0.1, which is common in practical applications. For FastDTW, we recursively shrink the sequence length in half from the finest level to the coarsest one. We then propagated the DTW solution from coarse to fine with radius r = 5. For GN, we varied k to be 5, 8, 12 to investigate the effect of the number of bases. For each scale, we randomly generated 100 pairs of sequences. The error was computed using <ref type="bibr" target="#b18">(19)</ref> and shown in Fig. <ref type="figure" target="#fig_5">5c-d</ref>. DTW obtains the lowest error but takes the most time to compute. This is because DTW exhaustively searches the entire parameter space to find the global optima. DTW-SC, DTW-IP and FastDTW all need less time than DTW because they search a smaller space. Empirically, DTW-SC is the least accurate compared to DTW-IP and FastDTW in our synthetic dataset. GN is most computationally efficient because it has linear complexity in the sequence length. Moreover, increasing the number of bases monotonically reduces the error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>This section compares CTW and GCTW against state-ofthe-art methods for temporal alignment of time series in seven experiments. In the first experiment, we compared the performance of CTW and GCTW against DTW, DDTW <ref type="bibr" target="#b19">[20]</ref>, and IMW <ref type="bibr" target="#b8">[9]</ref> in the problem of aligning synthetic time series of varying complexity. In the second experiment, we aligned videos of different subjects performing a similar activity; each video is represented using different types of visual features. In the third experiment, we showed how GCTW and CTW can be applied to provide a metric useful for activity recognition. In the fourth experiment, we aligned facial expressions across subjects on videos with naturally occurring facial behavior. In the fifth experiment, we showed how GCTW can be applied to large-scale alignment. We aligned approximately 50, 000 frames of motion capture data of two subjects cooking the same recipe. In the sixth experiment, we showed how GCTW can be used to localize common sub-sequences between two time series. The last experiment shows how GCTW is able to align three sequences of different subjects performing a similar action recorded with different sensors (motion capture data, accelerometers and video). In the first four experiments, the ground truth was known and we provided quantitative evaluation of the performance. In the others, we evaluated the quality of the alignment visually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation methods</head><p>In the experiments, we compared CTW and GCTW with several state-of-the-art methods for temporal alignment of time series. Below, we provide a brief description of the techniques that we used for comparison. DTW and mDTW: DTW is solved using a standard dynamic programming algorithm that minimizes (4). To evaluate the performance of temporal alignment of multiple sequences, we extended the concept of Procrustes analysis <ref type="bibr" target="#b40">[41]</ref> to time series. That is, given m (&gt; 2) time series, multi-sequence DTW (mDTW) seeks for a set of warping paths {p i } i that minimizes:</p><formula xml:id="formula_43">min {p i 2 } i J mdtw = m X i=1 m X j=1 1 2 kXiWi XjWjk 2 F = m m X i=1 kXiWi 1 m m X j=1 XjWjk 2 F .<label>(18)</label></formula><p>mDTW alternates between independently solving for each p i using an asymmetrical DTW and updating the mean sequence 1 m P m j=1 X j W j by averaging {X i W i } i . DDTW and mDDTW: In order to make DTW invariant to translation, derivative DTW (DDTW) <ref type="bibr" target="#b19">[20]</ref> uses the derivatives of the original features and minimizes:</p><formula xml:id="formula_44">min {px,py }2 J ddtw = kXF T nx Wx YF T ny Wyk 2 F ,</formula><p>where F nx and F ny are the 1 st order differential operators. To align multiple sequences, multi-sequence DDTW (mDDTW) extends DDTW in the Procrustes framework similar to <ref type="bibr" target="#b17">(18)</ref>.</p><p>IMW and mIMW: Similar to CTW, iterative motion warping (IMW) <ref type="bibr" target="#b8">[9]</ref> alternates between time warping and spatial transformation to align two sequences. Assuming the same number of spatial features between X 2 R d⇥nx and Y 2 R d⇥ny , IMW translates and re-scales each feature in X independently to match with Y. Written in a simple matrix form, IMW minimizes:</p><formula xml:id="formula_45">min px2 ,Ax,Bx Jimw = k(X Ax + Bx)Wx Yk 2 F + akAxF T nx k 2 F + b kBxF T nx k 2 F ,</formula><p>where A x , B x 2 R d⇥nx are the scaling and translation parameters respectively. a and b are the weights for the least-squared error and the regularization terms. The regularization terms are used to enforce a smooth change in the columns of A x and B x . In the experiments, we set them to be a = b = 1. IMW takes a coordinate-descent approach to optimize the time warping, scaling and translation. Given the warping matrix W x , the optimal spatial transformation can be computed in closed-form.</p><p>To align multiple sequences, we extended IMW to multisequence IMW (mIMW) in the Procrustes framework similar to mDTW <ref type="bibr" target="#b17">(18)</ref>.</p><p>mCTW: CTW was originally proposed to align two multi-modal sequences. We extended CTW to multisequence CTW (mCTW) for aligning multiple time series using the Procrustes analysis framework. mCTW optimizes the same objective <ref type="bibr" target="#b9">(10)</ref> as GCTW does, however, the temporal alignment step is different. mCTW alternates between warping each time series using asymmetric DTW and updating the mean sequence, while GCTW uses Gauss-Newton for jointly optimizing over all weights of the bases. Fig. <ref type="figure" target="#fig_6">6</ref> compares different temporal alignment methods as a function of the number of variables to optimize and their computational complexity. The comparison reports two cases: (1) alignment of two sequences (top of the table) and more than two sequences. Given two time series, X 2 R d⇥nx and Y 2 R d⇥ny , DTW and DDTW have the same complexity O(n x n y ) for finding the optimal l-length warping path. IMW additionally solves d least-squared problems for each row of A x and B x independently. Similarly, CTW relies on DTW to optimize the time warping, resulting in a complexity of O(n x n y ) in both space and time. However, CTW uses CCA to accommodate the difference in the number of features by solving a generalized eigen-decomposition of two (d x + d y )-by-(d x + d y ) matrices. CTW has fewer variables than IMW and thus is less likely to overfit the data. Compared to CTW, GCTW has the same complexity for computing the spatial embedding. The main computational advantage of GCTW is using Gauss-Newton, which optimizes a small-scale QP with 2k variables for the time warping. Given m sequences, {X i 2 R di⇥ni } m i=1 , a direct generalization of the DTW is computationally infeasible due to the combinatorial explosion of possible warpings, incurring a complexity of O( Q m i=1 n i ). In the experiment, mDTW is used as an approximation of the exact DTW optimization. However, mDTW and other DTW-based methods (mDDTW, mIMW and mCTW) still have quadratic complexity. Instead, GCTW approximates the combinatorial problem of time warping as a continuous optimization that can be more efficiently optimized by solving a small-scale QP with mk variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation metric</head><p>For all experiments, we used the normalized distance from the ground-truth as an error metric. More specifically, let us denote the alignment result of m sequences by a set of time warping paths,</p><formula xml:id="formula_46">P alg = [p alg 1 , • • • , p alg m ] 2 R l</formula><p>alg ⇥m , where p alg i 2 R l alg is the time warping path for the i th sequence. To evaluate the error of the time warping paths given by different methods, we computed their difference from the ground-truth path,</p><formula xml:id="formula_47">P tru = [p tru 1 , • • • , p tru m ] 2 R ltru⇥m</formula><p>, where the number of warping steps (l alg and l tru ) could be different. To better understand the error, let us consider each warping path P 2 R l⇥m as a curve in R m with l points (rows of P). For instance, Fig. <ref type="figure">8c</ref> and Fig. <ref type="figure" target="#fig_9">10c</ref> compare the warping paths as 3-D and 2-D curves respectively. The error can be hence defined as the normalized distance between the curves P alg and P tru ,</p><formula xml:id="formula_48">error = 1 2 ⇣ dist(P alg , Ptru) + dist(Ptru, P alg ) ⌘ , (<label>19</label></formula><formula xml:id="formula_49">)</formula><formula xml:id="formula_50">where dist(P1, P2) = 1 l1l2 X i=1•••l 1 min j=1•••l 2 kp (i) 1 p (j) 2 k2.</formula><p>The term,</p><formula xml:id="formula_51">min j=1•••l2 kp (i) 1 p (j)</formula><p>2 k 2 , measures the shortest distance between the point p (i) 1 and any point on the curve P 2 , where p</p><formula xml:id="formula_52">(i) 1 2 R 1⇥m and p (j)</formula><p>2 2 R 1⇥m are the i th row of P 1 and j th row of P 2 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Aligning synthetic sequences</head><p>In the first experiment, we synthetically generated spatio-temporal signals (3-D in space and 1-D in time) to evaluate the performance of mCTW and GCTW. As shown in Fig. <ref type="figure" target="#fig_7">7a</ref>, the signals were randomly generated by spatially and temporally transforming a latent 2-D spiral, Z 2 R 2⇥l , l = 300 as X = [U T (Z + b1 T )M; e T ] 2 R 3⇥n , where U 2 R 2⇥2 and b 2 R 2 were a randomly generated projection matrix and translation vector respectively. To synthesize the temporal distortion, a binary selection matrix M 2 {0, 1} l⇥n was generated by randomly choosing n  l columns from the  identity matrix I l . The third spatial dimension e 2 R n was added with a zero-mean Gaussian noise. In this experiment, mCTW and GCTW were compared with mDTW, mDDTW and mIMW for aligning three time series. The ground-truth alignment was known and the performance of each method was evaluated in terms of the alignment errors defined in <ref type="bibr" target="#b18">(19)</ref>. We repeated the above process 100 times with random numbers. In each trial, we studied three different initialization methods for mCTW and GCTW: uniform alignment for mCTW-U and GCTW-U as in <ref type="bibr" target="#b8">(9)</ref>, mDTW for mCTW-D and GCTW-D, and mIMW for mCTW-I and GCTW-I. The subspace dimensionality for CCA d was selected to preserve 90% of the total correlation. In this case, we have sufficient samples (l = 300) in 3-D space, and the regularization weight was set to zero. For GCTW, we selected three hyperbolic tangent and three polynomial functions as monotonic bases (upper-right corner in Fig. <ref type="figure" target="#fig_7">7b</ref>). Figs. 7 illustrates a comparison of the previously described methods for aligning multiple time series. Fig. <ref type="figure" target="#fig_7">7b</ref> shows the spatio-temporal warping estimated by mDTW, mDDTW, mIMW, mCTW-U and GCTW-U. Fig. <ref type="figure" target="#fig_7">7c</ref> shows the alignment errors <ref type="bibr" target="#b18">(19)</ref> for 100 randomly generated time series. Both mDTW and mDDTW performed poorly in this case since they do not have a feature weight mechanism to adapt the spatial transformation of the sequences. mIMW warps sequences towards others by translating and re-scaling each frame in each dimension. Moreover, mIMW has more parameters (2l P i d i ) than mCTW and GCTW (d</p><formula xml:id="formula_53">P i d i )</formula><p>, and hence mIMW is more prone to over-fitting. Furthermore, mIMW tries to fit the noisy dimension (3 rd spatial component), biasing alignment in time, whereas both mCTW and GCTW had a feature selection mechanism that effectively canceled out the third dimension. Among all initializations, the uniform alignment (mCTW-U and GCTW-U) and mIMW (mCTW-I and GCTW-I) achieved the best results. It is important to notice that mCTW and GTW always improved the initial error, that is, mCTW-D and mCTW-I obtained lower errors than their initializations given by mDTW and mIMW respectively. Compared to mCTW, GCTW achieved better performance when aligning more than two sequences because GCTW jointly optimizes over all the possible time warpings for each time series, while mCTW takes a greedy approach by warping each sequence towards the mean sequence independently. Fig. <ref type="figure" target="#fig_7">7d</ref> evaluates the computational cost of each method with respect to the average sequence length. mIMW was the most computationally intensive method because it solves a least-squared problem for each feature dimension. mCTW was more expensive than DTWbased methods because of the additional computation to solve CCA. As expected, GCTW was the most efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Aligning videos with different features</head><p>In the second experiment, we used mCTW and GCTW to align video sequences of different people performing a similar action. Each video was encoded using different visual features. The video sequences were taken from the Weizmann database <ref type="bibr" target="#b41">[42]</ref>, which contains nine people performing ten actions. To represent dynamic videos, we subtracted the background (the left three rows in Fig. <ref type="figure">8a</ref>) and computed three popular shape features (the right three rows of Fig. <ref type="figure">8a</ref>) for each 70-by-35 re-scaled mask image, including (1) binary image, (2) Euclidean distance transform <ref type="bibr" target="#b42">[43]</ref>, and (3) solution of Poisson equation <ref type="bibr" target="#b43">[44]</ref>. In order to reduce the dimension of the feature space (2450), we picked the top 123 principal components that preserved 99% of the total energy. We randomly selected three sequences and manually labeled their temporal correspondence as ground-truth. We repeated the process 10 times. All methods were initialized with uniform alignment. For GCTW, we used five hyperbolic tangent and five polynomial functions as the monotonic bases. Fig. <ref type="figure">8d</ref> shows the error for 10 randomly generated sets of videos. Neither mDTW nor mDDTW was able to align the videos because they were not able to handle alignment of signals of different dimensions. mIMW registered the top three components well in space; however, it overfitted the data and also computed a biased time warping path. In contrast, mCTW and GCTW warped the sequences accurately in both space and time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Activity classification</head><p>This section explores the use of CTW and GCTW as a (dis)similarity measure between videos with different features, and between videos and motion capture data. This (dis)similarity is used in combination with a nearest neighbor classifier.</p><p>Given a training set of videos of a subject performing an activity recorded with different visual features {X i } i , our goal is to find the testing video {Y j } j that contains similar activity. We took 24 sequences from the Weizmann dataset <ref type="bibr" target="#b41">[42]</ref>: 8 people performed three actions (walking, running and jumping). We repeated our experiments 10 times. In each trial, we randomly split the 24 sequences into two disjoint sets of 12 sequences used for training and testing respectively. The training sequences {X i } i were represented using the binary silhouette (see left columns of Fig. <ref type="figure">9a-b</ref> as examples) while the testing ones {Y j } j were encoded with the Euclidean distance features (see top rows of Fig. <ref type="figure">9a-b</ref> as examples). Given a pair of sequences, X i 2 R dx⇥nx i and Y j 2 R dy⇥ny j , we computed the (dis)similarity between videos using different methods: DTW, DDTW, IMW, CTW and GCTW. The warping path for each method is denoted as W alg xi 2 R nx i ⇥l and W alg yj 2 R ny j ⇥l . In order to provide a fair comparison with DTW, DDTW and mIMW (that cannot compute (dis)similarity between different features), we computed a pair of projection matrices, V x 2 R dx⇥d and V y 2 R dy⇥d for them. To do that, we took a subset of 1/3 of the training sequences encoded with both features {X tr i } and {Y tr i }, and uniformaly aligned each pair of sequences of the same label. The aligned frames were concatenated in two matrices X tr and Y tr , and the projections V x and V y were computed by CCA optimizing <ref type="bibr" target="#b0">(1)</ref>. Recall that the projection matrices were fixed for DTW, DDTW and IMW during testing, but for CTW and GCTW they were optimized by the algorithms. Then, the (dis)similarity between each pair of sequences was then computed as</p><formula xml:id="formula_54">dist(Xi, Yj) = 1 l alg kV T x XiW alg x i V T y YjW alg y j kF ,<label>(20)</label></formula><p>where the alignment step l alg was used to normalize the (dis)similarity. Given the (dis)similarity computed in <ref type="bibr" target="#b19">(20)</ref>, classification for a test sequence was done by finding the closest video in the training sequence. The overall classification error was averaged over all testing sequences. Fig. <ref type="figure">9a</ref>-b display the 12-by-12 (dis)similarity matrices computed by DTW and GCTW respectively. Each element in the matrices encodes the (dis)similarity between a training sequence (row) and a testing sequence (column). We re-ordered the rows and columns of the matrices so that the sequences containing the same activities were grouped in consecutive rows and columns. We then divided the matrix into nine 4-by-4 blocks (yellow lines), where the block in the i th row and j th column contains the (dis)similarity between the training sequences of the i th action and the testing data of the j th action, where i, j 2 {walk, run, jump}. Darker color denotes smaller (dis)similarity. Ideally, if the (dis)similarity would be able to capture perfectly the activity, the matrix will be perfect with zeros (black color) in the diagonal blocks and higher values (white color) elsewhere.</p><p>From Fig. <ref type="figure">9a</ref>, we can observe that the DTW (dis)similarity values in the first and last row of blocks were smaller than the blocks in the middle row. This is because, DTW does not have a feature adaptation mechanism and fails to provide semantic similarity of videos. In comparison, Fig. <ref type="figure">9b</ref> shows that GCTW captured better the (dis)similarity between actions. Fig. <ref type="figure">9c</ref> shows the nearest-neighbor classification error using different (dis)similarity. Overall, CTW and GCTW achieved lower errors than others due to their feature selection in aligning videos with different features.</p><p>In the second example, we recognized actions from motion capture sequences {Y j } j given a training set containing videos with different visual features {X i } i . From the Weizmann dataset <ref type="bibr" target="#b41">[42]</ref> we selected 24 videos containing three actions (walking, running and jumping). From the CMU motion capture database we selected 30 sequences of subjects performing the same three actions (walking, running and jumping). For the mocap data Y, we extracted quaternions on 20 joints <ref type="bibr" target="#b44">[45]</ref> and use them as features. Each video frame X was encoded with a binary silhouette feature. The experimental setting was similar to previous experiments. We divided all sequences into two disjoint sets used for training and testing respectively. Each test motion capture sequence was classified with the label of the video sequence training sequence X with smallest (dis)similarity <ref type="bibr" target="#b19">(20)</ref>. As shown in Fig. <ref type="figure">9f</ref>, GCTW achieved the lowest classification error compared to other methods. This was because our GCTW (dis)similarity captures between multi-modal similarity between actions in videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Aligning facial expression sequences</head><p>In the fourth experiment, we compared CTW and GCTW in the task of aligning unscripted facial expression sequences. The facial videos were taken from the RU-FACS database <ref type="bibr" target="#b45">[46]</ref>, which contains digitized videos of 29 young adults. The action units (AUs) in this database have been manually coded, and we randomly cropped video segments containing AU12 (smiling) for our experiments. Each event of AU12 is coded at its peak position. We used a person-specific active appearance model <ref type="bibr" target="#b46">[47]</ref> to track 66 landmarks on the face. For the alignment of AU12, we used only the 18 landmarks that correspond to the outline of the mouth. See Fig. <ref type="figure" target="#fig_9">10a</ref> for example frames where the mouth outlines are plotted.</p><p>The performance of CTW and GCTW were compared with DTW, DDTW and IMW. We initialized IMW, CTW and GCTW using the same uniform warping. Fig. <ref type="figure" target="#fig_9">10b</ref> shows the alignment result obtained by different methods, where the three dimensions correspond to the first three principal components of the original signals. As an approximate ground-truth, the position of the peak frame of each AU12 event is indicated as the red and blue points on the curves in Fig. <ref type="figure" target="#fig_9">10b</ref> and the intersection of the two dashed lines in Fig. <ref type="figure" target="#fig_9">10c</ref>. As we can see from Fig. <ref type="figure" target="#fig_9">10b-c</ref>, the two peaks in the low-dimensional projection found by CTW and GCTW are closer to the manually labeled peak than the ones in the original space used for DTW and DDTW. Finally, the distance between the peak point and the warping path is computed to quantitatively measure the performance. Fig. <ref type="figure" target="#fig_9">10d</ref> shows the average error as the distance normalized by the sequence lengths over 20 random repetitions, where CTW and GCTW achieved better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Aligning large-scale motion capture sequences</head><p>This experiment illustrates the benefits of using GCTW for aligning two large-scale motion capture sequences. The two sequences were taken from the CMU multimodal activity dataset <ref type="bibr" target="#b47">[48]</ref>, which contains multisensor recordings (video, audio, motion capture data and accelerometers) of naturalistic behavior of 40 subjects cooking five different recipes. The two motion capture sequences used in this experiment contain 44387 and 48724 frames respectively from two subjects cooking brownies. See Fig. <ref type="figure" target="#fig_10">11c</ref> for several key-frames of these two sequences. For each motion capture frame, we computed quaternions in four joints on the right hand, resulting in a 12-D feature vector. In this experiment, we only optimized the temporal component of GCTW, not the spatial component. We used five polynomial and five tanh(•) functions as monotonic bases for the time warping function.</p><p>To avoid local minima in the alignment, we used a temporal coarse-to-fine strategy for the Gauss-Newton optimization in GCTW. As shown in Fig. <ref type="figure" target="#fig_10">11a</ref>, the coarse-to-fine strategy proceeds in two steps: (1) In the pre-processing step, we obtained a three-level pyramid for each time series by recursively applying Gaussian smoothing with = 200. For instance, the first row of Fig. <ref type="figure" target="#fig_10">11b</ref> illustrates the two sequences in three levels, where the ones in the first level correspond to the original signals, while the ones in the third level contain less detailed but much smoother signals.</p><p>(2) In the optimization step, GCTW was first used to align the two sequences on the third level instead of the first level. The computed time warping result was then used to initialize GCTW on the second level. We repeated the same procedure to compute the final time warping result of the original sequences on the first level.</p><p>For this large-scale example, DTW was slow and computationally expensive. However, GCTW was able to efficiently find the temporal correspondence between the sequences in just a few seconds using Matlab on a regular laptop with a 2.5GHz Intel CPU. Since the groundtruth is unknown, we qualitatively evaluated GCTW by showing the aligned key frames in Fig. <ref type="figure" target="#fig_10">11c</ref>. Although the two subjects spent different amounts of time and followed different procedures in cooking, GCTW was able to align similar right hand actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Detection and alignment of similar subsequences</head><p>A major problem of DTW-type techniques is that they require an exact matching between the first frame and the last one, see <ref type="bibr" target="#b4">(5)</ref>. These boundary conditions are impractical and very restrictive when only a subset of the input sequence is similar to the sequence to be aligned. Fig. <ref type="figure" target="#fig_11">12</ref> illustrates this problem: how can we align four motion capture signals composed by different walking cycles? This problem is related to sub-sequence DTW <ref type="bibr" target="#b48">[49]</ref> and temporal commonality discovery <ref type="bibr" target="#b49">[50]</ref>. A major limitation of these methods is its inability to handle multiple sequences. This experiment shows how can we use GCTW for multiple sub-sequence alignment.</p><p>We selected four walking sequences from the CMU motion capture database <ref type="bibr">[51]</ref>. For each motion capture frame, we computed the quaternions for 14 joints on the body, resulting in a 42-D feature vector that describes the human pose. Fig. <ref type="figure" target="#fig_11">12a</ref> illustrates the first three principal components of the walking sequences. To allow for sub-sequence alignment, the warping path in GCTW is represented by a combination of a constant function and a linear one as the monotonic bases (see upper-left corner of Fig. <ref type="figure" target="#fig_11">12c</ref>). Both GCTW and the baseline mDTW method are initialized by uniformly aligning the sequences.</p><p>A visual comparison between mDTW and GCTW is illustrated in Fig. <ref type="figure" target="#fig_11">12</ref>. Without any manual cropping, most of the conventional DTW-based methods, such as mDTW, aligned the sequences by matching the first and the last frame, which results in incorrect alignments (see Fig. <ref type="figure" target="#fig_11">12b</ref>). Some parts (noted by arrows) of the sequences with fewer cycles have to be stretched into flat lines in order to match the other sequences with more cycles. Unlike conventional DTW-based methods built on dynamic programming, GCTW uses the Gauss-Newton method, which allows for a more flexible time warping. By incorporating a constant function in the set of bases, GCTW can naturally be generalized to deal with the sub-sequence alignment problem across multiple sequences. As shown in Fig. <ref type="figure" target="#fig_11">12c</ref>-d, GCTW is not only able to align the sequences in time, but also locate the boundaries of the sub-sequences that contain similar motions. This experiment demonstrates the benefits of GCTW in controlling the warping path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Aligning multi-modal sequences</head><p>The last experiment evaluates CTW and GCTW in the task of aligning multi-modal sequences recorded with different sensors. We selected one motion capture sequence from the CMU motion capture database, one video sequence from the Weizmann database <ref type="bibr" target="#b41">[42]</ref>, and we collected an accelerometer signal of a subject performing jumping jacks. Some instances of the multimodal data can be seen in Fig. <ref type="figure" target="#fig_12">13d</ref>. Note that, to make the problem more challenging, the two subjects in the mocap (top row) and video (middle row) sequences are performing the same activity, but in the accelerometer sequence (bottom row) the subject only moves one hand and not the legs. Even in this challenging scenario, GCTW is able to solve for the temporal correspondence that maximizes the correlation between signals. For the mocap data, we computed the quaternions for the 20 joints. In the case of the Weizmann dataset, we computed the Euclidean distance transform as described earlier. The X, Y and Z axis accelerometer data (40Hz) was collected using an X6-2 mini USB accelerometer (Fig. <ref type="figure" target="#fig_12">13a</ref>). Fig. <ref type="figure" target="#fig_12">13b</ref> shows the first components of the three sequences projected separately by PCA. As shown in Fig. <ref type="figure" target="#fig_12">13c</ref>, GCTW found an accurate temporal correspondence between the three sequences. Unfortunately, we do not have ground-truth for this experiment. However, visual inspection of the video suggests that the results are consistent with human labeling. Fig. <ref type="figure" target="#fig_12">13d</ref> shows several frames that have aligned by GCTW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>This paper proposes CTW and GCTW, two new techniques for spatio-temporal alignment of multiple multimodal time series. CTW extends DTW by adding a feature selection mechanism and enabling alignment of signals with different dimensionality. CTW extends CCA by adding temporal alignment and allowing temporally local projections. To improve the efficiency of CTW, allow a more flexible time-warping, and align multiple sequences, GCTW extends CTW by parameterizing the warping path as a combination of monotonic functions.</p><p>Inspired by existing work on image alignment, GCTW is optimized using coarse-to-fine Gauss-Newton updates, which allows for efficient alignment of long sequences.</p><p>Although CTW and GCTW have shown promising preliminary results, there are still unresolved issues. First, the Gauss-Newton algorithm used in GCTW for time warping converges poorly in areas where the objective function is non-smooth. Second, both CTW and GCTW are subject to local minima. The effect of local minima can be partially alleviated using a temporal coarse-to-fine approach as in the case of image alignment. In future work, we also plan to explore better initialization strategies. Third, although the experiments have shown good results using manually designed bases, an obvious extension is to learn a set of monotonic bases from training data, so the basis is adapted to a particular alignment problem. Finally, kernelization of CTW and GCTW might lead to improvements in alignment error.  conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Temporal alignment of sequences recorded with different sensors (from top to bottom: video, motion capture and accelerometers) of three subjects kicking a ball.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An example of DTW for aligning time series. (a) Two 1-D time series (n x = 7 and n y = 8) and the optimal alignment between samples computed by DTW. (b) Euclidean distances between samples, where the red curve denotes the optimal warping path (l = 9). (c) DP policy at each pair of samples, where the three arrow directions, #, &amp;, !, denote the policy, ⇡(•, •) 2 {[1, 0], [1, 1], [0, 1]}, respectively. (d) A matrix-form interpretation of DTW as stretching the two time series in matrix products. (e) Warping matrix W x . (f) Warping matrix W y .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Approximating temporal warping using monotonic bases. (a) Five common choices for monotonic bases. (b) An example of time warping XW(Qa) 2 R 1⇥70 of 1-D time series X 2 R 1⇥50 . (c) The warping matrix. (d)The warping function Qa is a linear combination of three basis functions including a constant function (q 1 ) and two monotonic functions (q 2 and q 3 ).</figDesc><graphic coords="5,139.81,135.67,73.61,52.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. An example of using Gauss-Newton for solving the sub-sequence alignment problem. (a) Two 1-D sequences. (b) The contour of the objective function (J a as defined in (13)) with respect to the weights of two bases. (c) The Gauss-Newton optimization procedure, the longer red sequence is warped to match the shorter blue sequence. (d) Warping function (p) as a combination of a linear function (q 1 ) and a constant function (q 2 ) used for scaling and translation respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Comparison between Gauss-Newton and variants of DTW for temporal alignment. (a) An example of two 1-D time series and the alignment results calculated using DTW, DTW constrained in the Sakoe-Chiba band (DTW-SC) and the Itakura Parallelogram band (DTW-IP), DTW optimized in a multi-level scheme (FastDTW) and Gauss-Newton (GN). (b) Comparison of different warping paths. GN-Init denotes the initial warping used for GN. SC-Bound and IP-Bound denote the boundaries of SC band and IP band respectively. (c) Alignment errors. (d) Computational costs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Comparison of temporal alignment algorithms as a function of degrees-of-freedom and complexity. l is the length of warping path. LS(n) and eig(n) denote the complexity of solving a least-squares of n variables and a generalized eigenvalue problem with two n-by-n matrices, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Comparison of temporal alignment algorithms on the synthetic dataset. (a) An example of three synthetic time series generated by performing a random spatio-temporal transformation of a 2-D latent sequence Z and adding Gaussian noise in the 3 rd dimension. (b) The alignment results. (c) Mean and variance of the alignment errors. (d) Mean and variance of the computational cost (time in seconds).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig. 8. Comparison of temporal alignment algorithms for aligning multi-feature video data. (a) An example of three aligned videos by GCTW. The left three sequences are the original frames after background subtraction, while the right three are the binary images, the Euclidean distance transforms and the solutions of the Poisson equation. (b) The alignment results. (c) Comparison of time warping paths. (d) Mean and variance of the alignment errors.</figDesc><graphic coords="11,72.86,445.61,54.01,54.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Comparison of algorithms for aligning facial expression across different subjects. (a) An example of two smiling expression sequences aligned by GCTW. The features of the two sequences are computed as the 18 landmark coordinates of the mouth given by a face tracker. (b) Alignment results. The position that corresponds to the peak of the expression is indicated by points on the curves in the top row. (c) Comparison of time warping paths. The position that corresponds to the peak of the expression is indicated by the intersection of the dashed lines. (d) Alignment errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Aligning two large-scale motion capture sequences using GCTW. (a) A coarse-to-fine strategy for improving the optimization performance of GCTW. (b) The first row shows the first principal components of the original sequences for three levels of the temporal pyramids. The second row corresponds to the aligned sequences using GCTW. (c) Key frames of similar body poses aligned by GCTW.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Aligning similar sub-sequences of four walking motion capture signals. (a) Original features of four mocap walking sequences. (b) Alignment achieved by mDTW. mDTW alings the sequences end-to-end and hence it has to stretch some parts of the sequences (flat lines indicated by arrows). (c) Alignment using GCTW. GCTW efficiently aligns the sub-sequences and also finds the boundaries of the sub-sequences containing similar motions. (d) Key frames aligned by GCTW.</figDesc><graphic coords="15,48.96,234.19,71.66,57.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Example of aligning multi-modal sequences. (a) Accelerometer. (b) Projection onto the first principal component for the motion capture data, video and accelerometers respectively. (c) GCTW. (d) Key frames aligned by GCTW. Notice that similar hand gestures have been aligned. From the top to bottom, we show mocap data, video, and accelerometer data respectively.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>SUBMITTED TO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, DECEMBER 2014</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This work was partially supported by the National Science Foundation under Grant No. EEEC-0540865, RI-1116583 and CPS-0931999. Any opinions, findings, and</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Fundamentals of speech recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Juang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Motion signal processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bruderlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Aligning non-overlapping sequences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Caspi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="51" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Aligning gene expression time series with time warping algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Church</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="495" to="508" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On aligning curves</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="125" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical aligned cluster analysis for temporal clustering of human motion</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hodgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="582" to="596" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wearable sensors and telerehabilitation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Engineering in Medicine and Biology Magazine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">View-independent action recognition from temporal self-similarities</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">N</forename><surname>Junejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dexter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="172" to="185" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Style translation for human motion</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Popovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised hierarchical modeling of locomotion styles</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rate-invariant recognition of humans and their activities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Veeraraghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K R</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1326" to="1339" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Gusfield</surname></persName>
		</author>
		<title level="m">Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Canonical time warping for alignment of human behavior</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generalized time warping for alignment of human motion</title>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Style machines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIG-GRAPH</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Style components</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GI</title>
		<imprint>
			<biblScope unit="page" from="33" to="39" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">View-invariant alignment and matching of video sequences</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gritai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fathima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dynamic manifold warping for view invariant action recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic probabilistic CCA for analysis of affective behavior and fusion of continuous annotations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1299" to="1311" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Derivative dynamic time warping</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiple alignment of continuous time series</title>
		<author>
			<persName><forename type="first">J</forename><surname>Listgarten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Emili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semisupervised alignment of manifolds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Manifold alignment using Procrustes analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">An introduction to multivariate statistical analysis</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Wiley-Interscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A least-squares framework for component analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1041" to="1055" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Canonical correlation analysis of video volume tensors for action categorization and detection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1415" to="1428" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Time-delayed correlation analysis for multi-camera activity understanding</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="106" to="129" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Time-series alignment by non-negative multiple generalized canonical correlation analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Isotonic CCA for sequence alignment and activity recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shariat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic programming and optimal control</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Iterative deepening dynamic time warping for time series</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Temporal alignment of communicative gesture sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heloir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gibet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Multon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Visual. Comp. Animat</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="347" to="357" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Toward accurate dynamic time warping in linear time and space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligent Data Analysis</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="561" to="580" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Searching and mining trillions of time series subsequences under dynamic time warping</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rakthanmanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J L</forename><surname>Campana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E A P A</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Westover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zakaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On multi-set canonical correlation analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCNN</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Ramsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Silverman</surname></persName>
		</author>
		<title level="m">Functional Data Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Estimating smooth monotone functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Ramsay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Series B Stat. Methodol</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Order restricted statistical inference</title>
		<author>
			<persName><forename type="first">T</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Dykstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Isotonic, convex and related splines</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Wegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="page" from="1023" to="1035" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Dryden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Mardia</surname></persName>
		</author>
		<title level="m">Statistical shape analysis</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Actions as space-time shapes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gorelick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2247" to="2253" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A linear time algorithm for computing exact Euclidean distance transforms of binary images in arbitrary dimensions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="270" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Shape representation and classification using the Poisson equation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gorelick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1991" to="2005" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Segmenting motion capture data into distinct behaviors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barbic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Safonova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hodgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Pollard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>GI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic recognition of facial actions in spontaneous expressions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Littlewort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lainscsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fasel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Movellan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Multimed</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="22" to="35" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Active appearance models revisited</title>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="164" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Detailed human data acquisition of kitchen activities: the CMUmultimodal activity database (CMU-MMAC)</title>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hodgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Valcarcel</surname></persName>
		</author>
		<idno>RI-TR-08-22</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>CMU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Matching incomplete time series with dynamic time warping: an algorithm and an application to post-stroke rehabilitation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tormene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Giorgino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Quaglini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stefanelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised temporal commonality discovery</title>
		<author>
			<persName><forename type="first">W.-S</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
