<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Segmentation and Interpretation of MR Brain Images: An Improved Active Shape Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nicolae</forename><surname>Duta</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Milan</forename><surname>Sonka</surname></persName>
							<email>milan-sonka@uiowa.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48823</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The University of Iowa</orgName>
								<address>
									<postCode>4400 EB, 52242</postCode>
									<settlement>Iowa City</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Segmentation and Interpretation of MR Brain Images: An Improved Active Shape Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">76B8AC9E80446E623DF371FE556F4076</idno>
					<note type="submission">received December 24, 1997; revised August 19, 1998.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports a novel method for fully automated segmentation that is based on description of shape and its variation using point distribution models (PDM's). An improvement of the active shape procedure introduced by Cootes and Taylor to find new examples of previously learned shapes using PDM's is presented. The new method for segmentation and interpretation of deep neuroanatomic structures such as thalamus, putamen, ventricular system, etc. incorporates a priori knowledge about shapes of the neuroanatomic structures to provide their robust segmentation and labeling in magnetic resonance (MR) brain images.</p><p>The method was trained in eight MR brain images and tested in 19 brain images by comparison to observer-defined independent standards. Neuroanatomic structures in all testing images were successfully identified. Computer-identified and observer-defined neuroanatomic structures agreed well. The average labeling error was 7% 6 3%. Border positioning errors were quite small, with the average border positioning error of 0.8 6 0.1 pixels in 256 2 256 MR images.</p><p>The presented method was specifically developed for segmentation of neuroanatomic structures in MR brain images. However, it is generally applicable to virtually any task involving deformable shape analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A UTOMATIC detection of brain structures is motivated by an ongoing effort to advance knowledge about relationships between anatomy and mental diseases in human brains. To better understand how human brain works and fails, an immense number of brain data sets from various sources [structural and functional magnetic resonance (MR), positron emission tomography (PET), single photon emission tomography (SPECT), etc.] must be analyzed. To date, most of the segmentation work in neuroscientific studies relies on manual tracing. As such, intraobserver and interobserver variability, and small study sample sizes remain a limiting factor. Despite the substantial interest and effort in the development of automated methods to identify brain structures <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b13">[14]</ref>, no reliable automated tools are available to date. Building models describing shape and appearance of nonrigid objects, and employing them for automated identification of such objects in the analyzed images has been of substantial research interest over the past several years <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b17">[18]</ref>. Among them, the point distribution model (PDM) representing the variation of a set of shapes around the average was designed by <ref type="bibr">Cootes and</ref> Taylor that has many favorable shape representation properties <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>.</p><p>The goal of our work reported here is twofold. The first goal was to develop a practically applicable MR brain segmentation method. The second goal was to improve the active shape procedure introduced by Cootes and Taylor <ref type="bibr" target="#b20">[21]</ref> to find new examples of previously learned shapes using the PDM's. The automated brain segmentation and interpretation approach described below represents a novel approach that incorporates a priori knowledge about neuroanatomic structures, their context, shapes, and shape variation to provide robust segmentation and labeling. The method presented below was specifically developed for segmentation of neuroanatomic structures in MR brain images. However, it is generally applicable to virtually any task involving deformable shape analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Statistics of Shape</head><p>Let shape instance denote a set of points in the Euclidean plane describing an object contour. If there is no connectivity information, a shape instance is an amorphous set of points similar to that shown in Fig. <ref type="figure" target="#fig_0">1(a)</ref>. By adding information about the number of contours and the point sequential order, the point set may become the shape model [Fig. <ref type="figure" target="#fig_0">1(b)</ref>]. A more detailed description of the anatomical significance of the points and the model construction methodology is given in Section IV.</p><p>Shape is defined to be the equivalence class of a shape instance, within the collection of all point sets of the same cardinality, under the operation of the similarity group (translation, rotation and scale). It is worth noting that an element of a shape class (a shape instance) is uniquely determined by the positions of two of its points since a planar linear transformation has exactly four parameters which can always be computed by fixing the coordinates of two points (imposing four constraints).</p><p>The squared shape distance between one point set (shape instance) and another point set (shape instance) is defined as the minimum sum of squared Euclidean distances between 0278-0062/98$10.00 Â© 1998 IEEE the points of and the corresponding points in sets as ranges over the whole set of shape instances equivalent to .</p><p>Mathematically speaking, let and . Then a set of points has the same shape as shape if and only if there exists a linear transformation (a composition of rotation, translation, and scaling) that maps the coordinates of into the coordinates of the corresponding points in . If we apply a rotation with an angle , a scale , and a translation to , its new coordinates are given by <ref type="bibr" target="#b0">(1)</ref> (2)</p><p>The squared shape distance between shape instances and is defined as</p><formula xml:id="formula_0">shape (3)</formula><p>One can prove that has the following properties.</p><p>1) The quantity is well defined for every two shape instances and ; 2)</p><p>is not symmetric, that is, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, but if A and B have roughly the same scale then ; 3) since for every shape , it can be considered the distance between the fixed shape instance and the shape class of .</p><p>Note that the point-coordinate averaging method of adding and dividing by their count cannot be used to average shapes. However, the alternate definition can be used in which the average is defined as the quantity about which the numbers have the least sum of squared distances. In this way, a notion of shape averaging using the least squared distance characterization is inherited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Shape Averaging</head><p>There is a large number of papers dealing with averaging/aligning shapes into a common coordinate frame. While the most popular approach in the statistical/medical vision communities is the Procrustes Analysis <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref>, the work of Horn <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> is better known to nonmedical vision researchers. Both frameworks provide analytic solutions to the shape alignment problem as well as approximate solution algorithms. The statistical shape literature mostly deals with theoretical considerations while the practical side of the problem is frequently left aside. Several iterative algorithms for aligning a set of shapes exist in the medical vision literature <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>. However, the papers do not state how well they approximate the closed-form solution. Therefore, our approach is not iterative and is based on deriving a linear system of equations for computing the least squares fit to a set of shape instances.</p><p>Let denote the number of shape instances, let be the number of points of each instance, and let be the coordinates of the th point of the instance . The least squares fit of the instances is sought, that is, a new shape instance should be determined for which the sum of the squared shape distances to each of the shape instances is minimum. Note that even if is unknown, it is a fixed shape instance. Therefore, its scale and pose must be fixed. For instance, it can be considered aligned with one of the given shape instances, let's say the last one. Then, the distance sum between and the instances is given by <ref type="bibr" target="#b3">(4)</ref> where are the unknown parameters of the linear transformation that maps each of the first instances into the instance of the corresponding shape which is closest to the least squares fit instance . One can prove that if all shape instances have roughly the same scale (for example are rescaled in such a way that the sum of the squared distances from the centroid to the vertices is equal to 1), it does not matter which of the shape instances is chosen to align with, since all the shape instances that minimize equations similar to (4) are equivalent (differ only by a linear transform). Practical results showed that this remains true even when the shape instances have quite different scales. Moreover, most of the time the square distance from that minimizes (4) to the set of shape instances from which it is derived is smaller than that produced by the iterative algorithms actually employed in the literature <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>. Now, is sought such that its coordinates minimize . By equating the partial derivatives of to zero, a linear system of equations in unknowns is obtained: <ref type="bibr" target="#b4">(5)</ref> where with and</p><p>The shape coordinates of a set of shapes describe the variation of the whole set of shapes around the average in terms of separate variations at the component points. They are visualized in Fig. <ref type="figure" target="#fig_2">2</ref> by overlaying each individual shape over the average shape. It can be seen that some of these points show little variability around the average, while others form more diffuse clusters. Importantly, model points do not move independently within the clusters-their positions are partially correlated. The theoretical assumptions initially stated by Cootes and Taylor are <ref type="bibr" target="#b20">[21]</ref> as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Point Distribution Model</head><p>1) The cluster points lie within an allowable shape domain (ASD) which is approximately ellipsoidal.  The principal axes of the -D ellipsoid are described by , the unit eigenvectors of the covariance matrix corresponding to , the th eigenvalue of . The principal axes can be calculated by employing the principal component analysis. Each axis gives a mode of variation, a way in which the landmark points tend to move together as the shape varies. The main properties of the ASD, also stated by Cootes and Taylor, are as follows.</p><p>1) The eigenvectors corresponding to the largest eigenvalues describe the longest axes of the ellipsoidal ASD. Thus, they describe the most significant modes of variation in the variables used to derive the covariance matrix.</p><p>2) The variance represented by each eigenvector is equal to the corresponding eigenvalue. 3) Most of the variation can usually be represented by a small number of modes, . This means that the -D ellipsoid can be approximated by a -dimensional ellipsoid ( ), where is chosen so that the original ellipsoid has a relatively small width along axes and above ( is the smallest number of modes such that the sum of their variances represents a sufficiently large proportion of the total variance )</p><p>4) Any point in the ASD (any allowable shape) can be reached by taking the mean (center) cluster point and adding a linear combination of the eigenvectors. Thus, any shape in the training set can be approximated using the mean shape and a weighted sum of deviations obtained from the first modes <ref type="bibr" target="#b6">(7)</ref> where <ref type="bibr" target="#b7">(8)</ref> is the matrix of the first eigenvectors, and</p><p>is a vector of weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) New examples of shapes similar to those in the training</head><p>set can be generated by varying the parameters within suitable limits (Fig. <ref type="figure" target="#fig_4">3</ref>). Cootes and Taylor propose to derive limits for by examining the distributions of the parameter values required  <ref type="formula">10</ref>) and ( <ref type="formula">16</ref>). The lengths of the b vectors correspond to the number t of modes used to explain the shape variance. (c) computed according to <ref type="bibr" target="#b9">(10)</ref>, <ref type="bibr" target="#b15">(16)</ref>, and <ref type="bibr" target="#b19">(20)</ref>. to generate the training set <ref type="bibr" target="#b20">[21]</ref>. They recommend that 's be chosen such that <ref type="bibr" target="#b9">(10)</ref> since most of the population lies within three standard deviations of the mean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Limitations of PDM's</head><p>While the PDM's have many favorable properties, they are not free of several limitations. The most important is given by the approximation introduced in (7) which is sensitive to both the percentage of variance explained by the chosen modes and the number of examples in the training set. While the approximation of a shape using a number of examples that approaches the dimension of the ASD and 100% variation explained does not exhibit visible differences from the original shape, the approximations using less examples and variation have a quite different look (Fig. <ref type="figure" target="#fig_5">4</ref>). Moreover, the approx-imation of an unacceptable shape [Fig. <ref type="figure" target="#fig_5">4(a)</ref>] may become acceptable if only a small number of examples were used to compute the approximation [Fig. <ref type="figure" target="#fig_5">4(b)</ref>]. One can also provide an example of a shape instance that has all the parameters smaller in absolute value than those of shape examples from the training set but are not acceptable since some of their points overlap (Fig. <ref type="figure" target="#fig_6">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PDM APPROACH TO MR BRAIN IMAGE INTERPRETATION</head><p>In many areas of image segmentation and interpretation, reliable a priori knowledge is available to help guide the image analysis process. For instance, in brain imaging, the image data are routinely represented in a normalized Talairach space <ref type="bibr" target="#b31">[32]</ref>. Consequently, approximate positions of individual neuroanatomic structures can be determined. Knowledge about their sizes, shapes, gray-level appearance, etc. can be acquired from a training set of examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Knowledge-Based Point Distribution Model</head><p>In order to improve the shape model and to take advantage of the available a priori knowledge, three additional features characteristic to MR brain images were included in the model: Gray-level appearance, border strength, and average position. We also used implicit knowledge about object context representing interrelationships of several objects.</p><p>Gray-level appearance is calculated in neighborhoods around each of the shape model points <ref type="bibr" target="#b20">[21]</ref>. It is determined for every shape model point of each training image along a profile of a constant length , centered at the point and perpendicular to the shape boundary [Fig. <ref type="figure" target="#fig_7">6(a)</ref>]. Since the profiles vary with gray-level scaling, derivatives of the gray levels along each profile are determined and normalized. Thus, invariance to uniform gray-level scaling and gray-level offset results. If we denote by the pixels along the profile , then the th element of the derivative profile is computed by , and, after normalizing the profile, Though the original PDM model <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref> also incorporates second-order statistics of the gray-level appearance, it decreases the detection speed. At the same time, the additional variation information is only partially relevant since half of the profile spans the background which in many cases is different from case to case. Therefore, for each model point, only a mean profile is computed and incorporated into the model in our method.</p><p>Border strength is determined for each border segment of the model. Every two consecutive model points that lie on the object boundary define a border segment. To compute its strength, a local filtering is applied to each clique on that border segment. The designed filter was inspired by that of Geman and Jedynak <ref type="bibr" target="#b32">[33]</ref>. If two pixels are located in close proximity and both belong to the same object, they are expected to have a smaller intensity difference than if one of them belongs to a different object or background [Fig. <ref type="figure" target="#fig_7">6(b)</ref>]. The filter is based on a pair of close parallel profiles. Let and be two profiles approximately perpendicular to the border segment and centered at points and as shown in Fig. <ref type="figure" target="#fig_7">6</ref>. The length of the parallel profiles (mask width) and the distance between them (mask length) are fixed when the model is defined. Due to the digitization, the actual width and length can vary slightly along the border depending on the orientation of the border segment. The overall response of the filter for a border segment is the aggregate of the individual responses of elementary cliques along that segment. An elementary clique is based on a pattern of four pixels -see Fig. <ref type="figure" target="#fig_7">6</ref>. The image response is given by ( <ref type="formula">11</ref>), shown at the bottom of the page. Let denote the image intensity at pixel , where should reflect the relative border strength for a particular border segment. Therefore, is determined as the largest integer such that the ratio of the overall border strength of the border segment and the maximum possible strength (twice the number of pixels in the border segment) is at least 0.66 (at least two-thirds of the cliques along an edge segment should return a nonzero response).</p><p>Average position of each shape model point that is calculated in the image coordinates is also incorporated in the model.</p><p>Interrelationships of several objects (object context) are implicitly included in the shape model. If more than one object occur in the same image, a decision must be made whether to include several of them in the same shape model if if only otherwise <ref type="bibr" target="#b10">(11)</ref> or whether to design an independent model for each of them. If contextual information is available, e.g., if it is known that two or more objects have a common border or are likely to appear in a prespecified relationship, combining them together may help overcome problems of their positioning or positioning of their mutual borders, especially if the borders are weak. On the other hand, it is not advisable to combine too many objects in a single object compound since the scattering of the model points in the training examples may be excessive [see, Fig. <ref type="figure" target="#fig_3">2(b)</ref>]. Such scattering may induce a biased average and cause difficulty to recognize unallowed shapes. Therefore, a compromise solution was adopted in which some of the objects are grouped while others are treated independently. As a generalization, two objects are grouped if they have a common border (in MR brain images, examples include the ventricle caudate nucleus) or if they are positioned in a close proximity and one of the objects exhibits a very weak boundary (e.g., putamen and globus pallidus).</p><p>To summarize, our knowledge-based shape model combines generally applicable parameters of the PDM and the knowledge-specific parameters appropriate for the image segmentation task in question. As such, the complete model is composed of the following.</p><p>1) The eigenvectors corresponding to the largest eigenvalues of the covariance matrix describing the ASD (Section II-C).</p><p>2) The average gray-level appearance values for each point of the model. 3) The average border strength for corresponding border segments and the parameters of the mask (width, length) for which the strength was computed. 4) The average position of the points of the average shape. 5) Connectivity information (the number of shapes, point ordering along contours).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Searching for Objects: Model Fitting</head><p>The searching procedure developed for our PDM approach to image segmentation and interpretation is based on the model fitting strategy. Let us assume that shape models were previously constructed during a training stage in which manually traced examples of objects were utilized. Then, the goal of the image segmentation/interpretation stage is to identify objects with properties similar to those of the training objects in the analyzed images. To accomplish this goal, the shape models are fitted to the analyzed image data. Our model fitting procedure substantially differs from the Active Shape Procedure of Cootes and Taylor. The difference is twofold. First, our search is entirely model driven. At each step of the fitting process, several model location hypotheses are considered and evaluated. During the hypothesis generation, the actual image data play no role (no image preprocessing is done). Second, an outlier detection and replacement procedure has been developed to detect misplaced points and infer their new positions. The outlier detection improves robustness and accuracy of the shape model fitting process.</p><p>The searching procedure consists of the following steps: 1) model fitting using linear transformations, 2) model fitting using piecewise linear transformations, 3) outlier removal, 4) final point adjustment, and 5) final outlier removal.</p><p>1) Model Fitting Function: As a result of the hypotheses generation processes, shape model locations are sequentially hypothesized. In order to evaluate the model location hypotheses, a fitness function is needed to assess the agreement between the image data and the particular model instance. We have designed a fitness function that consists of two components.</p><p>a) Fitness of the gray-level appearance is determined as the average squared Euclidean distance between the actual gray-level appearance and the mean gray-level profile incorporated in the shape model (Section III-A) <ref type="bibr" target="#b11">(12)</ref> where is the number of vertices in the model, is the normalized profile at point in the current image, and is the mean normalized profile at point computed from the training set. b) Fitness of the border is calculated as the average over the contour of the individual border segment fitness. A border segment fitness is the ratio between the aggregate response of all cliques along the border segment and the maximum possible response (twice the number of cliques), where the response of a clique is given by (11) using the average for that border segment as determined in the training set <ref type="bibr" target="#b12">(13)</ref> where # of cliques along edge <ref type="bibr" target="#b13">(14)</ref> It is clear that the computed fitness should increase with either a smaller average profile distance or a greater border fitness. Since the border fitness is a weak qualitative property (it is satisfied at many positions in an image) and the gray-level appearance of the brain structures in the used MR images did not vary too much, one should prefer a smaller profile distance over a larger border fit. We computed two-dimensional fitness maps (similar to those in <ref type="bibr" target="#b34">[35]</ref>-Fig. <ref type="figure" target="#fig_2">2</ref>) over the entire image for several functional combinations of the two quantities on a large data set. The fitness map that exhibited a global, clearly delimited peak at the real position was produced by the following fitness function : 3) Model Fitting Using Piecewise Linear Transformations: Since nonrigid objects or objects with intersubject variability are discussed here, rigid linear transformations do not account for any potential deformations of the expected shape [Fig. <ref type="figure">7(a)</ref>]. Therefore, in order to introduce deformations in our shape hypothesis, linear transformations (translation, rotation, and scaling) with a small range of parameters are applied to subsets of consecutive model points (subshapes of the model) [Fig. <ref type="figure">7(b)</ref>]. Each model point is taken in turn as the center of such a subset. After the best pose of the subset is obtained (Fig. <ref type="figure">7(c</ref>), only the position of the center point is kept and the remaining points are discarded. The number of consecutive points that are considered for this transform is application dependent and is a function of local border strength and length. To preserve robustness, the center point is not moved if the two border segments adjacent to it are very weak.</p><p>4) Outlier Removal: Under unfavorable circumstances, the previous step may introduce incorrectly positioned vertices-outliers. This may happen if a subshape fitted by the previous step exhibits weak edges [Fig. <ref type="figure">8(a)</ref>] or if there exists another border of similar properties in the neighborhood. In the existing literature dealing with PDM's, the only study we are aware of to approach the outlier problem is <ref type="bibr" target="#b30">[31]</ref>. A combination search-based solution was proposed that was based on a somewhat restricted assumption that the true position of a model point lies along the perpendicular profile through the current point position and constitutes a local peak that can be located by the gray-level model for that point. As noted by the authors, in many cases of high-curvature boundary points (and there are several such points in our brain model), the true position may not be located along the perpendicular profile and even a more time-consuming search would not help.</p><p>In most studies using PDM's, shapes that do not correspond to the allowed shape at any stage of the detection process are rejected or approximated with allowable shapes. In other Fig. <ref type="figure">9</ref>. Example of a shape hypothesis rejected by the original active shape model (ASM) procedure (left). Note the one outlier responsible for rejection (marked by 9). The same shape hypothesis after our outlier removal step (right, adjusted vertex marked by *). The average shape is shown in the middle. The values given below the figure are computed according to <ref type="bibr" target="#b9">(10)</ref>, <ref type="bibr" target="#b15">(16)</ref>, and ( <ref type="formula">20</ref>) and correspond to the left-most shape. Fig. <ref type="figure" target="#fig_0">10</ref>. Example of a shape hypothesis accepted by the original ASM procedure (left) despite the presence of an outlier (marked 1). The same shape hypothesis after outlier removal step (right, adjusted vertex marked by *). The average shape is shown in the middle. The values given below the figure are computed according to ( <ref type="formula">10</ref>), ( <ref type="formula">16</ref>), and ( <ref type="formula">20</ref>) and correspond to the left-most shape.</p><p>words, the model parameters must not exceed some maximum values <ref type="bibr" target="#b9">(10)</ref>. This approach can introduce two kinds of errors.</p><p>a) The shape/location hypothesis is completely rejected because one or two points are misplaced, such situation is documented in Fig. <ref type="figure">9</ref>. b) The hypothesis is accepted although one or two points are misplaced as seen in Fig. <ref type="figure" target="#fig_0">10</ref>. To treat the problem of outliers in a systematic fashion, an approach to outlier detection and position adjustment was developed. The misplaced points are identified using the information about the relative positions of the shape model vertices that are implicitly included in the shape model. Let be the model point positions after the piecewise linear transformations were applied and the resulting shape was aligned with the shape average. According to the shape model, the hypothesized shape should satisfy <ref type="bibr" target="#b6">(7)</ref>, specifically for some parameter vector . Usually, is not a square matrix but its columns are orthonormal vectors (they are eigenvectors of the covariance matrix). Therefore <ref type="bibr" target="#b15">(16)</ref> or by components <ref type="bibr" target="#b16">(17)</ref> where <ref type="bibr" target="#b17">(18)</ref> is the absolute variation induced by point in parameter . Let the percentage of variation induced by point in parameter be defined as <ref type="bibr" target="#b18">(19)</ref> and let the maximum percentage of variation induced by point in any of the parameters be defined as <ref type="bibr" target="#b19">(20)</ref> If all the points were to generate an equal amount of variation, then all the percentages were approximately , being the number of object points. However, since outliers may be present, larger variation may be associated with some points-the outliers. A point is considered to be an outlier if the percentage of variance generated by its position in any of the parameters of the model is more than 4 greater than the average amount of variation. Once such misplaced points are detected, they must be moved to a new position that can be inferred from the alignment of the rest of the shape instance with the average shape. If several outliers are present, the variance is distributed among them and (perhaps) the well placed points. As a result, it may be difficult to identify outliers if more than a few occur simultaneously. 5) Final Point Adjustment: Some of the shape model points may have been declared outliers in the previous step. Consequently, their position may have been adjusted solely considering the average shape appearance and not considering the image data [Fig. <ref type="figure">8(b)</ref>]. Therefore, they must be subjected to the position optimization step to better correspond with the image data. A hill-climbing procedure that searches a small (3 3) neighborhood of each point is employed, the model fitting function is utilized as the optimization criterion. This point adjustment process is performed twice for each point of the shape model, not just for the adjusted outliers.</p><p>6) Final Outlier Removal: Resulting from the previous steps or newly introduced during the final point adjustment, outliers may remain present in the shape model [Fig. <ref type="figure">8(c)</ref>]. Following the same outlier detection procedure applied in the first outlier removal step, the outliers are identified and removed, no adjustment is performed in this final step of model fitting [Fig. <ref type="figure">8(d)]</ref>.</p><p>One might be tempted to alternate the final point adjustment with the outlier removal several times what may not be a good idea. The two procedures involved have somehow opposite effects: the outlier removal tries to reduce the point scatter of the current shape making it closer to the average shape, while the adjustment tries to better match it with the image data which usually enlarges the point variance. While there are no restrictions regarding the new position of a point that is considered an outlier, the adjustment step can move a point only in a small neighborhood of its current location. Therefore, if we alternate these two steps several times, the current shape would converge toward the average shape. On the other hand, if we allow the adjustment procedure to search a large neighborhood of each point, then the algorithm would be much slower and may have a tendency to oscillate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL METHODS</head><p>The method presented above was employed to design a PDM shape model for ten brain structures (Fig. <ref type="figure" target="#fig_9">11</ref>) and its performance was assessed in in vivo MR brain images. The following ten neuroanatomic structures were identified in individual MR image slices (Fig. <ref type="figure" target="#fig_9">11</ref>): left/right ventricles, left/right caudate nucleus, left/right putamen, left/right globus pallidus, left/right thalamus. The brain image data, independent standard, and quantitative validation indexes were identical to those used in our previous study <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data</head><p>The image set consisted of individual T1-weighted contiguous MR images of the human brain, imaged in the coronal plane and acquired from a GE 1.5-T Signa scanner with inslice resolution of 256 256 pixels, slice thickness 1.5 mm, and a field-of-view of 26 cm, MR imaging parameters ms, and ms. The images were acquired from 27 subjects and normalized using a three-dimensional proportional Talairach grid system <ref type="bibr" target="#b31">[32]</ref>. Normalization using the Talairach grids-while not perfect-increased the likelihood that slice in each data set represented the same anatomic slice of the brain. Each image from the set contained the brain structures to be identified, as shown in Fig. <ref type="figure" target="#fig_9">11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Knowledge from Observer-Traced Contours</head><p>Observer-defined contours identified by a neuroanatomist were available for all the images in the brain data set. A training subset of eight images served for the shape model construction. The remaining 19 images formed the test set that was used for validation.</p><p>Using the observer-defined contours of the individual neuroanatomic structures of interest for guidance, the landmark points were manually identified for all structures in the training set of MR images (Fig. <ref type="figure" target="#fig_0">1</ref>). The landmarks were positioned to consistently represent the shape and shape variation of individual neuroanatomic structures. A prespecified number of landmarks was determined for each neuroanatomic structure of interest. If true landmarks were available (tips of putamen, tips of globus pallidus, etc.-numbered as 45, 47, 52, 69, 70, 74, etc. in Fig. <ref type="figure" target="#fig_0">1</ref>), these landmarks were consistently identified. Other points of the shape models did not correspond to true anatomic landmarks (e.g., points numbered as 53-56, 71-73, etc. in Fig. <ref type="figure" target="#fig_0">1</ref>). These points were identified to partition the border segments between true landmarks in border elements of approximately constant length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Quantitative Validation</head><p>Performance of the PDM approach to image interpretation was assessed in the test set by quantitatively comparing the labels, areas, and border positions of identified neuroanatomic structures with their respective true labels, areas, and border positions as determined by the observer-defined independent standard. Signed area error, labeling error and border positioning error were used as measures for comparing the observerdefined and computer-determined contours of neuroanatomic structures. The area errors resulting from automated object identification are reported in a normalized way in percents of true object areas. Labeling error was defined as a ratio of the number of incorrectly labeled pixels (both missing and extra) and the number of pixels of each object according to a priori knowledge and is expressed in percents. A one-pixel labeling insensitivity was used in the labeling error assessment performed here.</p><p>To evaluate the overall accuracy of the contours of the computer-identified brain structures, a distance function along object contours was derived. Considering a pair of contours, the distance function for a pixel on one contour was defined as the minimum Euclidean distance between that pixel and all other pixels on the second contour. For each border point on the computer identified contours, the average distance errors were calculated with respect to the observer traced contours. A maximum distance error measure, between pairs of contours, was also computed. This measure was calculated as the maximum of where was the maximum of the distance function of a computer detected contour with respect to an observer traced contour and was the maximum of the distance function of the observer traced contour with respect to the computer detected contour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS</head><p>The PDM approach to brain image segmentation and interpretation correctly interpreted the brain neuroanatomic structures in all images from the test set. Fig. <ref type="figure" target="#fig_10">12</ref> shows the observer-traced and computer-detected contours together with the intermediate results. In the test set, the neuroanatomic structures were identified with the signed percent area error of 12% 5% and labeling error of 7% 3%. Border positioning errors were quite small, with the average border positioning error of 0.8 0.1 pixels, and maximum border positioning error of 4.3 1.2 pixels. The detection time was about 1 min using a combination of C and MATLAB running on a Sun UltraSparc 1 workstation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION</head><p>Proper design of the objective function used for model fitting is important for the success of the method. Complexity of the objective function is inversely related to the processing speed. Similarly, the number of tested model hypotheses is related with the matching success. Therefore, selection of the objective function must be a compromise between the function complexity and the processing time that is also reflected in the number of model positioning hypotheses that may be explored in the process. In the past, several sophisticated fitness functions were proposed that were based on combining the Mahalanobis distance of the current shape hypothesis to the average shape with the Mahalanobis distance of the corresponding image profiles to the average (model) profiles <ref type="bibr" target="#b33">[34]</ref> and even including a background model in a Bayesian framework <ref type="bibr" target="#b34">[35]</ref>. These objective functions, however, lack a way of assessing the object properties between the model points. Clearly, if two consecutive model points lie on a boundary, this information together with the boundary strength may be used in the detection procedure. This is particularly needed when the number of model points is small. When an accurateenough initial guess of the object pose is not available, it may be necessary to test a large number of hypotheses. In the reported study, about 10 000 hypotheses were tested per image. In such case, computing Mahalanobis distances becomes a computational burden and in the tradeoff between the number of hypotheses and complexity of the objective function, evaluation of a larger number of hypotheses was considered more important. Therefore, our fitness function Identification of illegal shapes is another important problem considered in this paper. Mathematically speaking, an acceptable shape is a shape for which its complete vector of principal component analysis parameters (computed using a large set of examples by taking the parameters corresponding to all eigenvalues, Section II-C) is inside the ellipsoid defined by the parameters of the shapes in the training set. In our work, we applied a much weaker and informal condition-a shape was considered acceptable if it did not autointersect and the points along the contour were relatively equally spaced and if it was similar to the shapes present in the training set. The problems of illegal shapes come from inaccurate approximations due to a small training set and are unaffected by the model used.</p><p>The automatically determined borders of the ten neuroanatomic structures exhibit a high level of accuracy when compared to the manually identified independent standard. Putamen or caudate may serve as examples of consistently well determined structures with the average labeling errors ranging from 1% to 2%. However, the borders of the neuroanatomic structures that lack consistent border appearance like globus pallidus or thalamus represent a much bigger challenge both to the computer algorithm and human observers, average labeling errors for these structures ranged from 8% to 16%. The latter structures also exhibited larger shape variation compared to the former ones. The shape variations unmatched by the appropriate parameters of the model fitting transformations seem to be responsible for most of the gross errors in the incorrectly traced structures. Specifically, errors in detection of the lower tip of the globus pallidus and the outside border of the thalamus suggest Fig. <ref type="figure" target="#fig_4">13</ref>. Segmentation of globus pallidus using artificial deformations and extended scaling and rotation ranges. Columns from left to right: Original image, manual tracing, automated segmentation using computer-generated shapes, and automated segmentation using the average shape only; contrast-enhanced to improve visibility. that the searching scaling range used is less than the real variation in scale. This observation will serve for further improvement.</p><p>Another possible explanation of the imperfect border detection in structures with weak borders is based on the implemented strategy that does not apply the piecewise linear transform to vertices with weak border segments. While this approach improves the method's robustness, it may limit its accuracy. If the true positions of such vertices are not in the neighborhood of the average position, the above strategy may forbid the point's movement toward the correct location. A possible solution to this problem may be to find optimal deformations and positions not only for the average shape but also for a number of other computer generated example shapes. The examples can be generated by discretizing the parameter space for few parameters accounting for the largest variation modes of the PDM. Preliminary results using artificially gen-erated deformations and extended parameters for the model fitting transforms are presented in Fig. <ref type="figure" target="#fig_4">13</ref>. Although only eight computer-generated examples were used, Fig. <ref type="figure" target="#fig_4">13</ref> demonstrates a substantial improvement over the current approach.</p><p>Another improvement may result from incorporating better structure positioning information. At this moment, no statistical information is used concerning the relative positions of the neuroanatomic structures. The only constraint that is enforced after each step is that no two structures overlap. In case of overlapping, the faulting structures have to be grouped together. If a structure is misplaced but does not overlap another one, the hypothesis is accepted and a wrong detection occurs. While we did not experience such behavior, the possibility is present. Also, no statistical information is used now concerning the variation of model points. Incorporation of such information may be useful for the outlier detection procedure.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Landmarks of deep neuroanatomical structures. (a) MR image of the brain, coronal slice, resolution 256 2256, slice thickness 1.5 mm, with 114 landmark points superimposed. (b) A 114-point shape model of ten brain structures.</figDesc><graphic coords="2,41.34,391.44,254.64,262.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Each vertex shape instance from the training set of examples represents a single point in the -dimensional ( -D) space. Thus, a set of shape examples produces a cluster of points in this space. The point distribution model (PDM) describes the coordinates variation within the clusters assuming linear dependence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 )</head><label>2</label><figDesc>The training examples give an indication of size of the ASD.3) The cluster center is specified by the points of the least squares fit instance shape . 4) Every -D point within ASD represents a vertex sequence, the shape of which is broadly similar to the shapes of examples from the training set. Thus, by moving about the ASD, we can generate new shapes in a systematic way.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Scatter of the points from aligned brain shapes, with the mean shape overlaid. (a) Each brain structure averaged separately. (b) All structures averaged simultaneously.</figDesc><graphic coords="4,42.96,340.74,251.28,257.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Effect of simultaneously varying the model's parameters corresponding to the first two largest eigenvalues (on a bidimensional grid).</figDesc><graphic coords="4,312.36,59.58,238.56,150.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Example of a globus-pallidus-like shape containing two outliers, points 1 and 9 and its approximations using: (a) eight examples and 95% of variance explained, (b) 16 examples and 95% of variance explained, and (c) 16 examples and 100% of variance explained. (d) With the absolute values of the b parameters and the corresponding 3() 1=2 ranges for shapes given in (b)-(d) computed according to (10) and (16). The lengths of the b vectors correspond to the number t of modes used to explain the shape variance.</figDesc><graphic coords="5,113.76,54.96,372.72,201.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Example of thalamus from (a) the training set, (b) average thalamus, and (c) athalamus-like shape containing two outliers (points 4 and 5), with the absolute values of the b parameters and the corresponding 3() 1=2 ranges and maximum variance percentage values for shapes given in (b) and</figDesc><graphic coords="5,87.48,317.82,425.28,152.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Transversal profiles and edge cliques used to compute the gray-level appearance and edge strength: (a) contrast-enhanced to improve visibility and (b) schematic drawing of a clique.</figDesc><graphic coords="6,342.12,268.74,179.04,172.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( 15 ) 2 )Fig. 7 .Fig. 8 .</head><label>15278</label><figDesc>Fig. 7. The first two steps of a right ventricle segmentation. (a) Optimal average model position after linear transform step. (b) A five-point partial shape hypothesis is fitted to the image in a neighborhood of its actual position. (c) Optimal position of the partial ventricle hypothesis; only the position of the center vertex is kept. (d) Optimal model position after partial fitting of all model vertices. Images contrast-enhanced to improve visibility.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Neuroanatomic structures of interest.</figDesc><graphic coords="10,324.06,59.56,215.02,126.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Example of automated brain image segmentation and interpretation. Upper row from left to right: Manual tracings. Initial average position of the shape model. Optimal shape model position after linear transform step. Bottom row from left to right: Optimal shape model position after piecewise linear transform step. Outlier detection-outliers marked by dark dots. Final point adjustment. Images contrast-enhanced to improve visibility.</figDesc><graphic coords="12,51.18,54.99,497.78,439.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,52.80,55.01,494.51,160.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,57.54,279.87,485.02,147.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,106.62,63.96,386.88,275.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,106.38,414.48,387.36,289.20" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank N. Andreasen, M.D., Ph.D., M. Flaum, M.D., R. Rajarethinam, M.D., and T. Cizadlo, M.S. for providing both original and manually traced MR brain data utilized in the presented study. They would also like to thank Prof. G. Stockman for computer facility support.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Science Foundation (NSF) under Grant IRI 96-16747. The Associate Editor responsible for coordinating the review of this paper and recommending its publication was L. P. Clarke.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>A new fully automated segmentation and interpretation method has been presented. The method was utilized to identify ten neuroanatomic structures in individual MR images. The method was trained in a training set of eight MR brain images and tested in a test set of 19 MR brain images. The method correctly segmented and interpreted neuroanatomic structures in the test MR brain image set. Using quantitatively assessed comparison indexes, our method yielded brain image segmentation and interpretation with small labeling and small border positioning errors. Area measurements using computerdetected neuroanatomic structure borders correlated well with those derived from observer-defined tracings. Compared to our previously reported brain image segmentation and interpretation approach <ref type="bibr" target="#b11">[12]</ref>, our new method described here offers comparable performance while the interpretation process speed increased sixtyfold.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiresolution elastic matching</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kovacic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Graphics, Image Processing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Low-level segmentation of 3-D magnetic resonance brain images: A rule-based system</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Raya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="327" to="337" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated 3D MR image analysis with a rule-based segmentation system</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Ehricke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CAR &apos;91 Computer Assisted Radiology</title>
		<meeting>CAR &apos;91 Computer Assisted Radiology<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="543" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computer-based system for quantitative analysis of physiological structures from MRI data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hallgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Eng</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="49" to="55" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Knowledge based classification and tissue labeling of MR images of human brain</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldgof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="740" to="749" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Object recognition in brain CT-scans: Knowledge-based fusion of data from multiple feature extractors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deklerck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Cuyper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hermanus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nyssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="212" to="229" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Continuous voxel classification by stochastic relaxation: Theory and application to MR imaging and MR angiography</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Verbeeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Berben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IPMI &apos;93</title>
		<meeting>IPMI &apos;93<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="487" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic segmentation and volumetric calculations in nuclear magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Filipek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Caviness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Intergration of multiple knowledge sources in a system for brain CT-scan interpretation based on the blackboard</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deklerck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th Conf. Artificial Intelligence for Applications</title>
		<meeting>10th Conf. Artificial Intelligence for Applications<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Comput. Soc. Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic 3D segmentation of neuro-anatomical structures</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bizais</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht,, the Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="139" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Model-based 3-D segmentation of multiple sclerosis lesions in magnetic resonance brain images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shinghal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="442" to="453" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Knowledge-based interpretation of MR brain images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Tadikonda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="443" to="452" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A new automated method of identifying neuroanatomic regions of interest on imaging data (abstract)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Flaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arndt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cizadlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stoneall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Andreasen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc 34th Annu. Meet. American College of Neuropsychopharmacology</title>
		<meeting>34th Annu. Meet. American College of Neuropsychopharmacology</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">233</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Segmentation of 2-D and 3-D objects from MRI volume data using constrained elastic deformations of flexible Fourier contour and surface models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kelemen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brechbuhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="page" from="19" to="34" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Snakes: Active contour models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Conf. Computer Vision</title>
		<meeting>1st Int. Conf. Computer Vision<address><addrLine>London, U.K</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Boundary finding with parametrically deformable models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Staib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1061" to="1075" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Object matching using deformable templates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lakshmanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="277" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Image Processing, Analysis, and Machine Vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hlavac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boyle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Chapman Hall</publisher>
			<pubPlace>London,, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Use of active shape models for locating structures in medical images</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Haslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image, Vision Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="355" to="366" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Medical image interpretation: A generic approach using deformable templates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lindley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Informatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="59" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Active shape models-Their training and application</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Image Understanding</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="38" to="59" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Closed form solution of absolute orientation using unit quaternions</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer. A</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="629" to="642" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Closed form solution of absolute orientation using orthonormal matrices</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Hilden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Negahdaripou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer. A</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1127" to="1135" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Procrustes methods in the statistical analysis of shape</title>
		<author>
			<persName><forename type="first">C</forename><surname>Goodall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="285" to="339" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Morphometric Tools for Landmark Data</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Bookstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Cambridge Univ. Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The complex Bingham distribution and shape analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="285" to="299" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A mixture model for representing shape variation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conf., BMVA, 1997</title>
		<meeting>British Machine Vision Conf., BMVA, 1997</meeting>
		<imprint>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Shape and the information in medical images: A decade of the morphometric synthesis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Bookstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Image Understanding</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="97" to="118" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Morphometrics</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="28" to="31" />
		</imprint>
	</monogr>
	<note>Math Horizons</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Combining point distribution models with shape models based on finite-element analysis</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conf., BMVA</title>
		<meeting>British Machine Vision Conf., BMVA</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="419" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Data driven refinement of active shape model search</title>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conf., BMVA</title>
		<meeting>British Machine Vision Conf., BMVA</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="383" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Talairach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tournoux</surname></persName>
		</author>
		<title level="m">Co-Planar Stereotaxic Atlas of the Human Brain</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Thieme Medical Publishers, Inc</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An active testing model for tracking roads in satellite images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jedynak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Active shape model search using local grey-level models: A quantitative evaluation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conf., BMVA</title>
		<meeting>British Machine Vision Conf., BMVA</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A probabilistic fitness measure for deformable template models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Haslam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conf., BMVA</title>
		<meeting>British Machine Vision Conf., BMVA</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
