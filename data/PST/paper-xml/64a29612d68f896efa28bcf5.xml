<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TEA: Time-Proportional Event Analysis</title>
				<funder ref="#_EdSwu9P">
					<orgName type="full">UGent-BOF-GOA</orgName>
				</funder>
				<funder ref="#_vNafGX2">
					<orgName type="full">Research Foundation Flanders (FWO)</orgName>
				</funder>
				<funder ref="#_NDyQUYe">
					<orgName type="full">Research Council of Norway</orgName>
				</funder>
				<funder ref="#_k299wcp">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Bj?rn</forename><surname>Gottschall</surname></persName>
							<email>bjorn.gottschall@ntnu.no</email>
							<affiliation key="aff0">
								<orgName type="institution">Norwegian University of Science and Technology (NTNU</orgName>
								<address>
									<settlement>Trondheim</settlement>
									<country>Norway Lieven Eeckhout</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Ghent University Ghent</orgName>
								<address>
									<country>Belgium Magnus Jahre</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Norwegian University of Science and Technology (NTNU</orgName>
								<address>
									<settlement>Trondheim</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">ISCA &apos;23</orgName>
								<address>
									<addrLine>June 17-21</addrLine>
									<postCode>2023</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TEA: Time-Proportional Event Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3579371.3589058</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>? General and reference ? Performance</term>
					<term>Measurement</term>
					<term>? Computer systems organization ? Architectures Performance analysis, time proportionality, performance events</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As computer architectures become increasingly complex and heterogeneous, it becomes progressively more difficult to write applications that make good use of hardware resources. Performance analysis tools are hence critically important as they are the only way through which developers can gain insight into the reasons why their application performs as it does. State-of-the-art performance analysis tools capture a plethora of performance events and are practically non-intrusive, but performance optimization is still extremely challenging. We believe that the fundamental reason is that current state-of-the-art tools in general cannot explain why executing the application's performance-critical instructions take time.</p><p>We hence propose Time-Proportional Event Analysis (TEA) which explains why the architecture spends time executing the application's performance-critical instructions by creating timeproportional Per-Instruction Cycle Stacks (PICS). PICS unify performance profiling and performance event analysis, and thereby (i) report the contribution of each static instruction to overall execution time, and (ii) break down per-instruction execution time across the (combinations of) performance events that a static instruction was subjected to across its dynamic executions. Creating timeproportional PICS requires tracking performance events across all in-flight instructions, but TEA only increases per-core power consumption by ?3.2 mW (?0.1%) because we carefully select events to balance insight and overhead. TEA leverages statistical sampling to keep performance overhead at 1.1% on average while incurring an average error of 2.1% compared to a non-sampling golden reference; a significant improvement upon the 55.6%, 55.5%, and 56.0% average error for AMD IBS, Arm SPE, and IBM RIS. We demonstrate that TEA's accuracy matters by using TEA to identify performance issues in the SPEC CPU2017 benchmarks lbm and nab that, once addressed, yield speedups of 1.28? and 2.45?, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The end of Dennard scaling and the imminent end of Moore's law means that we can no longer expect general-purpose CPU architectures to deliver performance scaling <ref type="bibr" target="#b15">[16]</ref>. Industry has responded by exploiting specialization and integrating heterogeneous compute engines including GPU and domain-specific accelerators alongside conventional CPU cores <ref type="bibr" target="#b27">[28]</ref>. Counter-intuitively perhaps, sequential CPU code becomes relatively more performance-critical in heterogeneous systems due to Amdahl's Law, i.e., acceleratable code regions take much less time to execute while non-acceleratable code still takes the same amount of time <ref type="bibr" target="#b5">[6]</ref>. Performance tuning of sequential CPU code to better exploit the underlying hardware is hence becoming increasingly critical. Unfortunately, this is a timeconsuming and tedious endeavor because of how state-of-the-art CPU architectures optimize performance through various forms and degrees of instruction-level parallelism, speculation, caching, prefetching, and latency hiding.</p><p>Performance tuning is practically impossible without advanced performance analysis tools, such as Intel VTune <ref type="bibr" target="#b30">[31]</ref> and AMD ?Prof <ref type="bibr" target="#b1">[2]</ref>, whose purpose it is to help developers answer two fundamental questions: Q1 Which instructions does the application spend most time executing? Or in other words, which are the performancecritical instructions? 1 Q2 Why are instructions performance-critical? What are the microarchitectural events (cache misses, branch mispredictions, etc.) that render these instructions performance-critical?</p><p>The first question (Q1) is typically addressed with a performance profiler. The state-of-the-art performance profiler TIP <ref type="bibr" target="#b21">[22]</ref> is timeproportional, in contrast to other performance profilers <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b37">38]</ref>, which means that the importance of an instruction in its final performance profile is proportional to the instruction's relative contribution to overall execution time. Time proportionality is achieved by analyzing an instruction's impact on performance at commit time because that is where an instruction's latency is exposed. More specifically, an instruction's key contribution to execution time is the fraction of time it prevents the core from committing instructions <ref type="bibr" target="#b21">[22]</ref>. Time-proportional performance profiling is practical because it relies on statistical sampling, i.e., the profiler infrequently interrupts the CPU to retrieve the address(es) of the instruction(s) that the CPU is exposing the latency of in the cycle the sample is taken. While performance profiling is a necessary first step, it is not sufficient because it does not answer the second question (Q2). More specifically, performance profilers such as TIP <ref type="bibr" target="#b21">[22]</ref> do not explain why the architecture spends time on performance-critical instructions because they do not break down the time contribution of an instruction's execution across microarchitectural performance events. State-of-the-art approaches that attempt to address Q2 fall short because they account for performance events in a non-time-proportional manner, hence providing a skewed view on performance. Existing performance analysis approaches can be classified as instruction-driven versus event-driven. Instruction-driven approaches such as AMD IBS <ref type="bibr" target="#b18">[19]</ref>, Arm SPE <ref type="bibr" target="#b3">[4]</ref>, and IBM RIS <ref type="bibr" target="#b28">[29]</ref> tag instructions at either the fetch or dispatch stage in the pipeline and then record the performance events that a tagged individual instruction is subjected to. Tagging instructions at the fetch or dispatch stages biases the instruction profile towards instructions that spend a lot of time in the fetch and dispatch stages, and not necessarily at the commit stage -hence lacking time-proportionality. Event-driven approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b53">54]</ref> on the other hand rely on counting performance events (e.g., cache misses, branch mispredicts, etc.). Event counts are then either attributed to instructions or used to generate coarse-grained performance information, such as application-level cycles per instruction stacks. Event-driven approaches also provide a skewed view on performance because the performance event counts they provide do not necessarily correlate with the impact these events have on performance because of latency hiding effects (as we will quantify in Section 5).</p><p>Our key insight is that both Q1 and Q2 can be answered by creating time-proportional Per-Instruction Cycle Stacks (PICS) in which the time the architecture spends executing each instruction is broken down into the (combinations of) performance events it encountered during program execution. <ref type="foot" target="#foot_0">2</ref> Since our PICS are timeproportional by design, they have the desirable properties that (i) the height of the cycle stack is proportional to a static instruction's impact on overall execution time -addressing Q1 -and (ii) the size of each component in the cycle stack is proportional to the impact on overall performance that this (combination of) performance event(s) incurs -addressing Q2. While time-proportional TIP <ref type="bibr" target="#b21">[22]</ref> captures each static instruction's impact on overall execution time (thereby answering Q1), it cannot answer Q2 and create PICS because this requires breaking down each static instruction's performance impact across the events the instruction was subjected to during its dynamic executions.</p><p>A key challenge for creating PICS is that contemporary processors record many performance events, e.g., the Performance Monitoring Unit (PMU) of the recent Intel Alder Lake can report 297 distinct performance events <ref type="bibr" target="#b31">[32]</ref>. Building time-proportional PICS however requires tracking events across all in-flight instructions -and limiting the number of tracked events is hence key to keeping overheads in check. We address this issue by returning to first principles, i.e., PICS must break down the execution time impact of an instruction according to the architectural behavior that caused the instruction's latency. We must hence focus on the commit stage and exploit that it can be in three non-compute states: (i) Commit stalled because an instruction reached the head of the Re-Order Buffer (ROB) before it had fully executed; (ii) it drained because of a front-end stall; or (iii) it flushed due to, for instance, a mispredicted branch. The task at hand is hence to map these states back to the performance events that caused them. Fortunately, performance events form hierarchies, and we exploit these to select events that make PICS easy to interpret while keeping overheads low. Surprisingly perhaps, we find that capturing only nine events is sufficient to ensure that 99% of the stall cycles incurred by instructions that are not subjected to any event is less than 5.8 clock cycles.</p><p>We hence propose Time-proportional Event Analysis (TEA), which enables creating PICS by adding hardware support for tracking the performance events that each instruction encounters during its execution. More specifically, TEA allocates a Performance Signature Vector (PSV) for each dynamically executed instruction which includes one bit for each supported performance event. During application execution, TEA uses a cycle counter to periodically collect PSV(s) at a typical 4 KHz sampling frequency. The PMU then retrieves the instruction pointer(s) and PSV(s) of the instruction(s) that the architecture is exposing the latency of at the time of sampling following the time-proportional attribution policies described in prior work <ref type="bibr" target="#b21">[22]</ref>. When the sample is ready, the PMU interrupts the core, and the interrupt handler reads the instruction pointer(s) and PSV(s) and stores them in a memory buffer. When the application completes, the PSVs are post-processed to create PICS for each static instruction by aggregating the PSVs captured for each of its dynamic execution samples.</p><p>We implement TEA within the Berkeley Out-of-Order Machine (BOOM) core <ref type="bibr" target="#b57">[58]</ref>, and our implementation tracks nine performance events across all in-flight instructions. TEA incurs only minor overhead, i.e., requires 249 bytes of storage and increases per-core power consumption by only ?3.2 mW (?0.1%). We demonstrate the accuracy of TEA by comparing its PICS to those generated by AMD IBS <ref type="bibr" target="#b18">[19]</ref>, Arm SPE <ref type="bibr" target="#b3">[4]</ref>, and IBM RIS <ref type="bibr" target="#b28">[29]</ref> <ref type="foot" target="#foot_1">3</ref> , which are the state-ofthe-art instruction-driven performance analysis approaches, and an (unimplementable) golden reference that retrieves the PSVs for all dynamic instructions in all clock cycles. TEA is very accurate with an average error of 2.1% relative to the golden reference which is a significant improvement over the 55.6%, 55.5%, and 56.0% average error of IBS, SPE, and RIS, respectively. Since TEA relies on statistical sampling, the performance overhead of enabling it is only 1.1% on average.</p><p>To demonstrate that TEA is useful in practice, we used it to analyze the SPEC CPU2017 <ref type="bibr" target="#b45">[46]</ref> benchmarks lbm and nab. For both benchmarks, the PICS provided by TEA explains the performance problems whereas state-of-the-art approaches do not. The performance problem of lbm is due to a non-hidden load instruction, and we address this issue by inserting software prefetch instructions. TEA enabled us to choose a prefetch distance that is large enough to hide most of the load latency while not being too large as this creates contention for store resources in the core and L1 cache, yielding an overall performance improvement of 1.28?. For nab, the high accuracy of TEA enabled us to deduce that a floating-point square root instruction was performance-critical because an earlier instruction flushed the pipeline and hence caused it to be issued too late for its execution latency to be hidden. We addressed this issue by relaxing IEEE 754 compliance with the -finite-math and -fast-math compiler options which yielded speedups of 1.96? and 2.45?, respectively.</p><p>In summary, we make the following major contributions:</p><p>? We observe that time-proportional Per-Instruction Cycle Stacks (PICS) provide all the necessary information to explain both which instructions are performance-critical (i.e., answering Q1) and why these instructions are performance-critical (i.e., answering Q2) -thereby helping developers understand tedious performance problems. ? We propose Time-proportional Event Analysis (TEA) which captures the information necessary to create PICS by tracking key performance events for all in-flight instructions with Performance Signature Vectors (PSVs). ? We implement TEA at the RTL-level within the out-of-order BOOM core <ref type="bibr" target="#b57">[58]</ref> and demonstrate that it achieves a 2.1% average error relative to the golden reference; a significant improvement upon the 55.6%, 55.5%, and 56.0% error of IBS, SPE, and RIS, respectively. TEA has low overhead (i.e., storage overhead of 249 bytes, power consumption overhead of ?0.1%, and performance overhead of 1.1%).</p><p>? We used TEA to analyze the lbm and nab benchmarks from SPEC CPU2017. TEA identifies two performance problems that are difficult to identify with state-of-the-art approaches, and addressing them yields speedups of 1.28? and 2.45?, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND MOTIVATION</head><p>Time-proportional performance profiling <ref type="bibr" target="#b21">[22]</ref> is based on the observation that determining the contribution of each instruction to overall execution time requires determining the instruction(s) that the core is currently exposing the latency of. (We assume a baseline that already supports TIP <ref type="bibr" target="#b21">[22]</ref>, the state-of-the-art timeproportional performance profiler.) Time-proportional profiling needs to focus on the commit stage of the pipeline because this is where the non-hidden instruction latency is exposed. Focusing on commit is a necessary but not a sufficient condition for timeproportionality because, depending on the state of the CPU, it will expose the latency of different instruction(s). More specifically, the processor will be in one of four commit states in any given cycle:</p><p>? Compute: The processor is committing one or more instructions. Time-proportionality hence evenly distributes time across the committing instructions (i.e., 1/? cycles to each instruction when ? instructions commit in parallel).  ? Drained: The ROB is empty because of a front-end stall, for instance due to an instruction cache miss. Time is hence attributed to the next-committing instruction. ? Stalled: An instruction ? is stalled at the head of the ROB because it has not yet been fully executed. Time is hence attributed to ? which is the next-committing instruction. ? Flushed: An instruction ? caused the ROB to flush, for instance due to a mispredicted branch, and the ROB is empty. Time is hence attributed to ? but unlike in the stall and drain states it has already committed, i.e., it is the last-committed instruction. Explaining why it takes time to execute a particular instruction hence requires mapping the non-compute commit states Drained, Stalled, and Flushed to the performance events that caused them to occur. (Execution latency is fully hidden in the Compute state, and there is hence no additional execution time to explain in this state.) TEA example. Figure <ref type="figure" target="#fig_1">1</ref> illustrates how TEA works in practice when an application executes the short loop in Figure <ref type="figure" target="#fig_1">1b</ref> on an out-of-order processor that supports three performance events (i.e., instruction cache miss, data cache miss, and branch mispredict). TEA relies on statistical sampling and for the purpose of this example we assume that it samples once every 1,000 cycles; the samples that TEA collects are shown in Figure <ref type="figure" target="#fig_1">1a</ref>. (In our evaluation, TEA samples at 4 kHz, i.e., once every 800,000 cycles at 3.2 GHz, which is the default for Linux perf <ref type="bibr" target="#b37">[38]</ref>.) In Sample 1, the ROB has drained due to an instruction cache miss when fetching I1 and TIP <ref type="bibr" target="#b21">[22]</ref> hence samples I1. TEA additionally tracks the performance events that each dynamic instruction was subjected to by attaching a Performance Signature Vector (PSV) to each in-flight instruction. The PSV consists of one bit for each supported performance event and hence consists of three bits in this example. Since I1 was subjected to an instruction cache miss, its instruction cache miss event bit is set in its PSV, see 1 . A TEA sample hence consists of a PSV for all sampled instructions in addition to the information returned by TIP (i.e., instruction address(es) and timestamp).</p><p>In Sample 2, the ROB has again emptied, but now the reason is that branch instruction I4 was mispredicted. I4 hence committed The application terminates without additional samples being collected, and TEA then uses the captured samples to create PICS for I1, I2, I3, and I4 (see Figure <ref type="figure" target="#fig_1">1c</ref>). Each sample is mapped to static instructions using the address(es) of the instruction(s) and then categorized according to the PSV value -which identifies the (combination of) performance event(s) that caused the processor to expose the latency of this instruction in this sample. From Samples 1 and 3, TEA attributes 1,000 cycles to I1 due to the instruction cache miss event and data cache miss event, respectively, see 4 . Similarly, TEA attributes 1,000 cycles to I4 for the mispredicted branch in Sample 2. The remaining cycles are distributed evenly across I1, I2, I3, and I4 since they commit in parallel in Samples 4 and 5. This category is labeled 'Base' since none of the instructions were subjected to performance events.</p><p>If an instruction is subjected to multiple events, multiple bits are set in the PSV, and we refer to events that impact the same instruction as combined events. Combined events are often serviced sequentially, e.g., an instruction cache miss must resolve for a load to be executed and subjected to a data cache miss. The stall cycles caused by this load are hence caused by both events and it is challenging to tease apart the stall impact of each event. TEA hence reports combined events as separate categories. Out of all dynamic instruction executions that encounter at least one event, 30.0% are subjected to combined events (see <ref type="bibr">Section 5)</ref>. Combined events are hence not too common, but can help to explain challenging issues.</p><p>Capturing PSVs. Creating PICS requires recording the performance events each instruction is subjected to during its execution, i.e., creating a PSV for each instruction packet. An instruction packet is the instruction (or ?op) itself and its associated metadata (e.g., the instruction address) which the processor updates and forwards as the instruction flows through the pipeline. Figure <ref type="figure">2a</ref> illustrates how TEA captures PSVs by showing the execution state of an out-of-order core and PSVs for each instruction; this architecture supports six performance events and hence has a six-bit PSV format. (We will explain how we implement TEA in detail in Section 3.) In the front-end, the PSVs need to capture and pass along the events that can occur in this and previous pipeline stages which are instruction cache and TLB misses in this example, see 1 . At dispatch, TEA initializes the six-bit PSV associated with each ROB entry by setting the front-end bits of the PSV to their respective values and all remaining PSV-bits to zero. At 2 , instruction I5, which was subjected to an instruction cache miss, hence has its two most significant bits set to 10 as these are the front-end PSV-bits (see 3 ). In the cycle we focus on, I1 is the oldest instruction and stalled due to an L1 cache miss and a TLB miss and its two least significant PSV-bits are hence both 1, see 4 . Similarly, I2 is also a data cache miss while the PSVs for I3 and I4 are all zeros because they so far have not been subjected to any performance events. Since TEA is time-proportional, its hardware sampler selects I1 and its PSV before interrupting the processor such that the software sampling function can retrieve the sample and store it in a memory buffer.</p><p>Instruction-driven performance analysis. AMD IBS <ref type="bibr" target="#b18">[19]</ref>, Arm SPE <ref type="bibr" target="#b3">[4]</ref>, and IBM RIS <ref type="bibr" target="#b28">[29]</ref> fall short because they tag instructions at dispatch or fetch and are hence not time-proportional. Figure <ref type="figure">2b</ref> illustrates the operation of dispatch-tagging with the same core state as we used to explain TEA in Figure <ref type="figure">2a</ref>. Dispatch-tagging marks the instruction that is dispatched in the cycle the sample is taken, i.e., I5 (see 6 ). Fetch-tagging works in the same way except that it tags at fetch rather than at dispatch and would hence tag I8 in this example. The key benefit of tagging instructions in the front-end is that the scheme only needs to track events for the tagged instruction, i.e., it needs one PSV to record the events that the tagged instruction is subjected to, see 7 .</p><p>Tagging at dispatch or fetch does however incur significant error because it is not time-proportional. More specifically, sampling I5 or I8 is not time-proportional because I1 is stalled at the head of the ROB at the time the sample is taken, i.e., the processor is exposing the latency of I1 in this cycle. (Recall that TEA sampled I1 in Figure <ref type="figure">2a</ref>.) This situation is common because performancecritical instructions tend to stall at commit which in turn stalls the front-end -resulting in the PSVs of the instructions that are dispatched or fetched during stalls being overrepresented in the PICS. Tagging at dispatch or fetch also captures events that may not impact performance. For example, I1 is stalled on a combined data cache and TLB miss event, but dispatch-tagging captures I5's instruction cache miss (which is hidden under I1's events).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TIME-PROPORTIONAL EVENT ANALYSIS</head><p>We now explain the details of our TEA implementation. While we focus on the open-source BOOM core <ref type="bibr" target="#b57">[58]</ref> in this section, the approach will be similar for other microarchitectures, i.e., some implementation details will be different but the flow of information will remain the same.</p><p>Performance event hierarchies. PICS help developers understand why instructions are performance-critical, and TEA provides this information by mapping the non-compute commit states to the most important performance events that cause them. However, TEA has to track performance events for all in-flight instructions, and we hence need to carefully select a small set of performance events that collectively capture key architectural bottlenecks to keep overheads in check. Fortunately, performance events can be grouped according to the non-compute commit state they can cause. Performance events hence form hierarchies that we can exploit to trade off overhead against interpretability, i.e., the ability of the selected set of performance counters to explain commit stalls. Figure <ref type="figure" target="#fig_2">3</ref> explains how event hierarchies enable reasoning about event selection by focusing on the Stalled (ST) commit state. Performance events can be dependent or independent. Dependent performance events can only occur if a prior performance event has occurred, e.g., a load can only miss in the LLC if it has already missed in the L1 cache 1 . Independent performance events in contrast occur independently of each other, e.g., a load can hit in the L1 cache independently of it hitting or missing in the L1 TLB 2 . We can hence exploit the event hierarchy to balance how easy it is for a developer to interpret PICS -which favors capturing more events and thereby explaining increasingly complex architectural behaviors -against overheads -which increases with event count because TEA must track events for all in-flight instructions.</p><p>We refer to the events captured by a PSV as an event set. For the events in Figure <ref type="figure" target="#fig_2">3</ref>, we can create one single-bit PSV which only captures that a load stall occurred and hence has low overhead but offers limited insight. We can improve interpretability by moving to a 2-bit PSV. In this case, the most favorable option is to include the L1 data cache and TLB miss events as they cover all possible Level 2 events in the event hierarchy, see 3 . We can improve interpretability by adding the dependent events of the L1 data and TLB misses as exemplified by the 3-bit and 4-bit PSVs 4 . In this case, we still need to report the root event of each dependency chain to avoid losing interpretability. For example, if we capture LLC misses and not L1 misses, we can no longer identify LLC hits.</p><p>TEA's performance events. Table <ref type="table" target="#tab_1">1</ref> lists the nine performance events that TEA captures in our BOOM implementation. We name the performance events on the form X-Y where ? is the commit state and ? is the event, e.g., an L1 data cache miss is labeled ST-L1 since it explains the Stalled commit state. To explain the Drained state, TEA captures that an instruction missed in the L1 instruction TEA exploits event hierarchies to balance interpretability and overhead. Retaining interpretability means that TEA should assign events to instructions that caused long stalls, i.e., stalls that cannot be explained by instruction execution latencies and dependencies, because these determine the expected stall time in the absence of miss events. We evaluate TEA from this perspective by capturing the stalls caused by any dynamic instruction. Our golden reference provides this data because it captures all dynamic instructions and all clock cycles (see Section 4 for details regarding our experimental setup). We further extract the instructions that stall commit and TEA does not assign an event to. Overall, 99% of these instructions cause stalls that are shorter than 5.8 clock cycles, and TEA hence captures the events that can majorly impact performance.</p><p>Table <ref type="table" target="#tab_1">1</ref> also shows that the instruction-driven approaches AMD IBS <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref>, Arm SPE <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, and IBM RIS <ref type="bibr" target="#b28">[29]</ref> capture many of the same events as TEA which indicates that some events are important regardless of the specific architecture.</p><p>TEA microarchitecture. Figure <ref type="figure" target="#fig_3">4</ref> illustrates how we implement TEA in the BOOM core. The DR-L1 and DR-TLB events occur in Fetch which requires allocating a 2-bit PSV in the fetch packet, see 1 . Because the first instruction of the fetch packet always incurs the DR-L1 and DR-TLB events, TEA only requires a single PSV 2 . When the fetch packet is expanded into individual instructions and added to the Fetch Buffer, the PSV of the first instruction is copied and the PSVs of all other instructions are initialized to zero. In Decode, the instructions from the fetch buffer are decoded into ?ops and the PSV of each ?op is passed along 3 . Dispatch inserts ?ops into the ROB and the issue queues of the functional units. Dispatch detects DR-SQ when a store is the oldest ?op and cannot dispatch due to a full LSQ 4 . To avoid complicating the LSU-to-ROB interface, we allocate storage for an ST-TLB event in each LSU entry because it is detected before the cache responds 5 . ST-L1 and ST-LLC events in contrast become available upon a cache response and can hence be communicated immediately (through Writeback). The complete 9-bit PSV of each ?op is stored in the ?op's ROB-entry 6 . The FL-MB, FL-EX, and FL-MO events are already detected by the ROB because they require flushing the pipeline, and the ROB can hence record them in the PSV.</p><p>TEA is connected to the head of the ROB with the time-proportional sample selection logic inherited from TIP <ref type="bibr" target="#b21">[22]</ref> 7 . Once a cycle counter event is emitted by the PMU (see 8 ), the Sample Selection unit identifies the commit state (i.e., Computing, Stalled, Flushed, or Drained) and selects the appropriate instruction(s) given the state. TEA delays returning the sample in the Stalled and Drained state until the next ?op commits to ensure that the ?op's PSV is updated. A sample contains a timestamp, flags (i.e., commit state and valid bits) as well as the instruction address(es) and PSV(s) 9 . TEA is hence indifferent to tracking ?ops or dynamic instructions since it in both cases maps them to static instructions when sampling. Finally, the sample is written to TEA's Control and Status Registers (CSRs) and an interrupt is issued.</p><p>Sample collection and PICS generation. The interrupt causes the sampling software to retrieve TEA's sample as well as inspect other CSRs to determine the logical core identifier and process and thread identifiers before writing all of this information to a buffer in memory (which is flushed to a file when necessary); this is the typical operation of Linux perf <ref type="bibr" target="#b37">[38]</ref>. The logical core identifier maps to a hardware thread under Simultaneous Multi-Threading (SMT) and a physical core otherwise; we require one TEA unit per physical core. While we focus on single-threaded applications in this work, TEA is hence equally applicable to multi-threaded applications since we capture sufficient information to create PICS for each thread. The ability of profiling tools to map samples to processes also enables creating PICS for any piece of software (e.g., operating system code and just-in-time compilers).</p><p>All collected samples are hence available in a file when the application terminates. We have created a tool that takes this sample file as input and then aggregates cycles across the PSV signatures of each static instruction, thereby creating PICS for each static instruction in which each category corresponds to a specific (combination of) performance event(s). A developer can then use this tool to analyze application performance by visualizing PICS at various granularities (e.g., static instructions and functions).</p><p>Overheads. We assume a baseline that implements TIP <ref type="bibr" target="#b21">[22]</ref>, and TIP incurs a storage overhead of 57 B compared to an unmodified BOOM core. TEA additionally needs to track PSVs across all inflight instructions and hence requires adding two bits per entry in the 48-entry fetch buffer to store the DR-L1 and DR-TLB events (12 B) and a 9-bit PSV field to each ROB entry (216 B for our 192entry ROB). TEA also needs three 2-bit registers in fetch to track DR-L1 and DR-TLB for all fetch packets and 2 bits for each entry in decode and dispatch to track these events through the rest of the front-end. TEA needs a one-bit register in dispatch to track the DR-SQ event and one bit in each LSU entry to track ST-TLB until the load completes. TEA also needs a register for the PSV of the last-committed instruction to correctly handle the Flushed state (2 B). The overall storage overhead of TEA is hence 249 B per core (and 306 B per core for TEA and TIP).</p><p>Since IBS, SPE, and RIS tag instructions in the front-end, they know which instruction to capture PSVs from and hence only require storing 6, 5, and 7 bits, respectively, i.e., one byte. They do however capture other information such as branch targets, memory addresses, and various latencies when implemented in commercial cores. The minimum storage requirements of IBS, SPE, and RIS are hence negligible, but this benefit is due to tagging instructions in the front-end which is also the root cause of their large errors.</p><p>To better understand the power overhead of TEA (and TIP), we synthesized the ROB and fetch buffer modules of the BOOM core in a commercially available 28 nm technology with and without TEA using Cadence Genus <ref type="bibr" target="#b9">[10]</ref> and estimated its power consumption with Cadence Joules <ref type="bibr" target="#b10">[11]</ref>. We focus on the ROB and fetch buffer because they account for 91.7% of TEA's storage overhead. (Recall that the events TEA captures are already identified in the microarchitecture.) Overall, TEA increases the power consumption of these units by 4.6%. In absolute terms, supporting TEA in these units increases power consumption by 3.2 mW which is negligible. For example, RAPL <ref type="bibr" target="#b16">[17]</ref> reports a core power consumption of 32.7 W on a recent laptop with an Intel i7-1260P chip running stress-ng on all 8 physical cores which yield 4.7 W per core. Implementing TEA on this system would hence increase per-core power consumption by ?0.1%. If this power overhead is a concern, the PSVs can be clock or power-gated and enabled ahead of time such that the PSVs for all in-flight instructions are updated when sampling.</p><p>TEA's performance overhead is the same as TIP because we can pack the PSVs into the CSR that TIP uses to communicate sample metadata to software. A CSR must be 64 bit wide to match the width of the other registers in the architecture, but TIP only uses 10 bits for metadata. Communicating four PSVs requires 36 bits which result in TEA using 46 out of 64 CSR bits. TEA hence retains the 88 B sample size from TIP which results in a performance overhead of 1.1% <ref type="bibr" target="#b21">[22]</ref>. TEA's logic is not on any critical path of the BOOM core, and TEA hence does not impact cycle time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP</head><p>Simulator. We use FireSim <ref type="bibr" target="#b32">[33]</ref>, a cycle-accurate FPGA-accelerated full-system simulator, to evaluate the different performance profiling strategies. The simulated model is the BOOM 4-way superscalar out-of-order core <ref type="bibr" target="#b57">[58]</ref>, see Table <ref type="table" target="#tab_2">2</ref> for its configuration, which runs a common buildroot 5.7.0 Linux kernel. The BOOM core is synthesized to and runs on Xilinx U250 FPGAs in NTNU's Idun cluster <ref type="bibr" target="#b44">[45]</ref>. We account for the frequency difference between the FPGA-realization of the BOOM core and the FPGA's memory system using FireSim's token mechanism. We use TraceDoctor <ref type="bibr" target="#b22">[23]</ref> to capture cycle-by-cycle traces that contain the instruction address and the valid, commit, exception, and flush flags as well as the PSV of the head ROB-entry in each ROB bank; the trace includes the ROB's head and tail pointers which we need to model dispatchtagging. We configure a highly parallel framework of TraceDoctor workers on the host to enable on-the-fly processing while minimizing simulation slowdown. The performance analysis approaches are hence modeled on the host CPUs that operate in parallel with the FPGA by processing the traces. This allows us to simulate and evaluate multiple configurations out-of-band in a single simulation run; we run up to 15 configurations on 12 CPUs per FPGA simulation run. We evaluate multiple configurations with a single run because (i) it enables fairly comparing analysis approaches as they sample in the exact same cycle, and (ii) it reduces evaluation time.</p><p>Benchmarks. We run a broad set of SPEC CPU2017 <ref type="bibr" target="#b45">[46]</ref> benchmarks that are compatible with our setup. We simulate the benchmarks to completion using the reference inputs. We compile all benchmarks using GCC 10.1 with the -O3 -g compilation flags and static linking. We enable the performance analyzers when the system boots up until the system shuts down after the benchmark has terminated. We only retain the samples that hit user-level code because (i) the time our benchmarks spend in OS code (e.g., syscalls) is limited (1.7% of total time), and (ii) we do not want to include system boot and shutdown time in the profiles.</p><p>Golden reference. The baseline we compare against computes PICS for every instruction, i.e., we know for each instruction how it contributes to the total execution time and where it spends its time -we consider this to be our golden reference. This is clearly impractical to implement in a real system because it would require communicating the PSVs to software for every dynamically executed instruction which would incur too high performance overhead. More specifically, the golden reference requires communicating and parsing 2.7 petabytes of performance data in total at a rate of 116 GB/s. This golden reference is nevertheless extremely useful because it represents the ideal performance profile to compare against.</p><p>Error metric. Quantifying the accuracy of the cycle stacks obtained by TEA (or any other technique) requires an error metric that quantifies the error across all components in the cycle stack. Moreover, we want to be able to compute the error metric at the level of granularity at which the cycle stack is computed. We consider instruction and function granularities in this work. We refer to a component in the cycle stack as ? ?,? , 1 ? ? ? ? with ? being the number of components in the stack and ? being a unit of granularity, i.e., an instruction, a basic block, a function or the entire application. The corresponding component in the cycle stack as obtained through the golden reference is referred to as ? ? ?,? . The correctly attributed cycle count per component hence equals min(? ?,?, , ? ? ?,? ). Summing up these correctly attributed cycle counts across all components and all units ? at the granularity of interest yields the total number of correctly attributed cycles, i.e., ? correct = ? ?=1 ? ?=1 min(? ?,?, , ? ? ?,? ). The error is defined as the relative difference between the total cycle count ? total and the correctly attributed cycle count, i.e., ? = (? total -? correct ) /? total . Not all techniques that we evaluate generate the same set of components. In particular, IBS, SPE, and RIS do not provide the same components as TEA. For fair comparison against the golden reference, we hence compare each scheme against a golden reference with the same set of components as the scheme supports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>The state-of-the-art approaches for creating Per-Instruction Cycle Stacks (PICS) are represented by IBS, SPE, and RIS which are our best-effort implementations<ref type="foot" target="#foot_2">4</ref> of AMD IBS <ref type="bibr" target="#b0">[1]</ref>, Arm SPE <ref type="bibr" target="#b3">[4]</ref>, and IBM RIS <ref type="bibr" target="#b28">[29]</ref>. IBS and SPE tags instructions at dispatch whereas RIS tags instructions while forming instruction groups in the fetch stage. IBS, SPE, and RIS all record the performance events that tagged instructions are subjected to while they travel through the pipeline but support different event sets (see Table <ref type="table" target="#tab_1">1</ref>). We also compare against two variants of TEA. NCI-TEA combines the events supported by TEA with the Next-Committing Instruction (NCI) sampling policy used by Intel PEBS <ref type="bibr" target="#b29">[30]</ref> which has been shown to be significantly more accurate than tagging instructions at fetch or dispatch <ref type="bibr" target="#b21">[22]</ref>. TEA is our approach as described in Section 3 which uses time-proportional PSV sampling. We sample instructions at a frequency of 4 KHz for all techniques, unless mentioned otherwise. We also evaluated a version of TEA that tags instructions at dispatch which yields similar accuracy to IBS, SPE, and RIS, but we could not include this configuration due to page restrictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Average Accuracy</head><p>We first focus on the accuracy of TEA for generating PICS, and Figure <ref type="figure" target="#fig_4">5</ref> reports error per benchmark. A couple of interesting observations can be made. First, IBS, SPE, and RIS are significantly less accurate than NCI-TEA and TEA. The reason is that IBS, SPE, and Figure <ref type="figure">6</ref>: PICS for the top-3 instructions as provided by IBS, TEA, and the golden reference (GR). The PICS provided by TEA are accurate compared to the golden reference, in contrast to IBS.</p><p>RIS tag instructions at dispatch or fetch which leads to non-timeproportional performance profiles. (This confirms the observation from prior work <ref type="bibr" target="#b21">[22]</ref>.) Fundamentally, tagging an instruction in the front-end skews the profile to instructions that spend a significant amount of time at dispatch or fetch -which are not necessarily the instructions the application spends time on at commit. RIS performs slightly worse than IBS and SPE because it captures more events and the cycle stacks thus have more components. By consequence, accurately capturing all components in the stack is more challenging. The marginal difference between IBS and SPE is also due to capturing different event sets. Second, sampling instructions at commit substantially improves accuracy as is evident from comparing NCI-TEA versus IBS, SPE, and RIS. NCI-TEA samples the instructions as they contribute to execution time, i.e., an instruction that stalls commit has a higher likelihood of being sampled, and, as a result, the cycle stack is more representative of the contribution of this instruction to the program's overall execution time.</p><p>Third, sampling at commit is not a sufficient condition for obtaining accurate cycle stacks. We need to attribute the sample to the correct instruction and we need to attribute the sample to the correct signature. Attributing the sample to the next-committing instruction (NCI) is inaccurate in case of a pipeline flush due to a mispredicted branch or an exception. The instruction which is to blame is not the next-committing instruction but the instruction that was last committed, namely the mispredicted branch or the excepting instruction. TEA solves this issue by keeping track of the PSV of the last-committing instruction as previously described in Section 3.</p><p>Overall, TEA achieves an average error of 2.1% (and at most 7.7%). This is significantly more accurate compared to the other techniques: NCI-TEA (11.3% average error and up to 22.0%), RIS (56.0% average error and up to 79.7%), IBS (55.6% average error and up to 79.7%), and SPE (55.5% average error and up to 79.7%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Per-Instruction Accuracy</head><p>The previous section quantified the average accuracy of the PICS across all instructions within a benchmark. We now zoom in on the accuracy for individual instructions. Figure <ref type="figure">6</ref> reports the PICS of the top-3 (most execution time) instructions for four benchmarks for IBS, TEA, and the golden reference; we take IBS as representative of SPE and RIS since their accuracy is very similar (see Figure <ref type="figure" target="#fig_4">5</ref>). We select bwaves, omnetpp, and fotonik3d because they collectively illustrate how TEA reports solitary versus combined events, and exchange2 because it is the benchmark for which IBS yields the lowest error. The overall conclusion is that the PICS reported by IBS are inaccurate for two reasons: (i) the height of the cycle stacks is inaccurate because IBS is not time-proportional, and (ii) the relative importance of the components within the cycle stacks is inaccurate because of signature misattribution. This also applies to exchange2 which is the benchmark for which IBS incurs the lowest error (i.e., comparing Figure <ref type="figure">6d</ref> to Figure <ref type="figure" target="#fig_4">5</ref>). This analysis also illustrates TEA's ability to detect combined events. For example, the combination of cache and TLB misses, Figure <ref type="figure">7</ref>: Quantifying the correlation between event count and its impact on performance. Some event counts correlate strongly with their impact on performance while others do not.</p><p>i.e., (ST-L1, ST-TLB) and (ST-LLC, ST-TLB), accounts for a significant fraction of the PICS of the top-3 instructions for bwaves and omnetpp (see Figures <ref type="figure">6a</ref> and<ref type="figure">6b</ref>). Out of all dynamic instruction executions that are subjected to at least one event, 30.0% encounter combined events. Combined events are hence not too common, but they can help explain specific performance problems. Optimizing bwaves would for example require improving both cache and TLB utilization, whereas optimizing fotonik3d can focus solely on improving cache utilization (see Figures <ref type="figure">6a</ref> and<ref type="figure">6c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Why Event-Driven Analysis Falls Short</head><p>As aforementioned in the introduction, event-driven performance analysis attempts to answer question (Q2) of why instructions are performance-critical by counting performance events (e.g., cache misses, TLB misses, branch mispredicts, etc.). This is a widely used approach for software tuning. Unfortunately, it is extremely tedious and time-consuming and appears to be more of an art than a science, i.e., performance tuning requires intimate familiarity with the code and the underlying hardware. The fundamental reason is that event counts do not necessarily correlate with the impact these events have on overall performance. Having developed a method to compute accurate PICS, we can now quantify the adequacy of performance event counting.</p><p>We do this by computing the correlation between event counts and the corresponding components in the cycle stack. We compute the Pearson correlation coefficient ? which varies between -1 and +1. In our context, ? close to one implies an almost perfect positive correlation; on the other hand, ? close to zero means no correlation. Figure <ref type="figure">7</ref> reports box plots for the Pearson correlation coefficient for all PSV events across all benchmarks. 5 Some performance events strongly correlate with performance, as is the case for branch mispredictions (FL-MB), exceptions (FL-EX), and memory ordering violations (FL-MO). The reason is that these events lead to a pipeline flush, which in most cases cannot be hidden. TLB misses (DR-TLB and ST-TLB) and cache misses (ST-L1, ST-LLC, and DR-L1) on the other hand show moderate correlation with performance, with LLC misses (SL-LLC) showing higher correlation than L1 data cache misses (ST-L1). The reason is that cache misses can be partially hidden, and this is true more so for L1 data cache misses than for LLC misses. The least correlation and the largest spread are observed for store queue stalls (DR-SQ), i.e., in some cases, a full 5 Event-driven approaches such as Intel PEBS <ref type="bibr" target="#b29">[30]</ref> and DCPI <ref type="bibr" target="#b2">[3]</ref> cannot detect combined events because they must fundamentally sample based on the event they are counting; many events only apply to certain instruction types (e.g., only loads and stores can miss in the cache). When counting multiple events in parallel, the events will not be captured in the same cycle, yielding independent profiles.  store queue is completely hidden while in other cases a full store queue stalls the processor.</p><p>While the above analysis is intuitively understood, i.e., architects are well aware of latency hiding effects, this work is the first to quantify the (lack of) correlation between event counts and their impact on performance. This is also the fundamental reason why performance tuning using event counts is so tedious and timeconsuming. TEA solves this problem by providing accurate PICS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Sensitivity analysis</head><p>Sampling frequency. Figure <ref type="figure" target="#fig_6">8</ref> reports the accuracy of the various techniques as a function of sampling frequency. Accuracy is rather insensitive to sampling frequency above 4 KHz, which is why we chose it as our baseline sampling frequency to balance accuracy and run-time overhead.</p><p>Analysis granularity. Figure <ref type="figure" target="#fig_7">9</ref> evaluates the accuracy of the various techniques when cycle stacks are computed at the instruction and function granularities; basic block and application granularities exhibit the same trends. TEA is uniformly the most accurate technique. While the error decreases at function granularity for the alternative approaches, it does not decrease as steeply as one may expect. The reason is that cycles are systematically misattributed to the wrong events. As a result, the alternative approaches fall short, even at coarse granularity. This reinforces the need for a more adequate analysis technique such as TEA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CASE STUDIES</head><p>We now demonstrate that TEA -by identifying the performancecritical instructions (Q1) and explaining why they are performancecritical (Q2) -comprehensively identifies application optimization opportunities that state-of-the-art approaches miss by analyzing and optimizing lbm and nab. As in Section 5.2, we take IBS as representative of SPE and RIS.</p><p>Analyzing lbm. When using current state-of-the-art approaches, the first step is to collect a performance profile. If we use TIP <ref type="bibr" target="#b21">[22]</ref>,  the profile is time-proportional and hence reports the contribution of each static instruction to overall execution time (i.e., answers Q1). TIP however does not explain why a particular instruction is performance-critical and therefore forces developers to guess what the problem could be from the instruction type and TIP's flags.</p><p>In the case of lbm, TIP will identify the performance-critical load instruction and, unsurprisingly perhaps, report that this load stalls commit.</p><p>TEA in contrast provides PICS as shown in Figure <ref type="figure" target="#fig_9">10a</ref> which (i) identify the performance-critical lw instruction -thereby answering Q1 -and (ii) explains that this lw instruction always misses in the LLC while hiding the latency of the following load instructions that also miss in the LLC -hence answering Q2; TEA's PICS are practically identical to the PICS generated by the golden reference. Figure <ref type="figure" target="#fig_9">10b</ref> shows PICS generated by IBS for the region of the code which it identifies as performance-critical. IBS attributes the performance problem to some arithmetic instructions that happen to dispatch while the performance-critical lw instruction is stalled at the head of the ROB. The event-driven analysis is also unclear because lbm has 11 load instructions in the inner loop which all incur between 3.3 and 3.9 billion misses each. The key problem is that event counting does not differentiate between hidden and non-hidden misses.</p><p>TEA explains that the key performance problem of lbm is that (i) its working set exceeds the size of the LLC, and (ii) the architecture is not able to issue the load instructions sufficiently early to hide their latency. More specifically, the body of the inner loop of lbm contains sufficient compute instructions to fill the ROB and hence blocks the processor from issuing the loads of the next iteration while processing a previous iteration. TEA, unlike TIP, IBS, and event counting, provides all of this information in its PICS -and thereby explains that software prefetching is the optimization to apply.</p><p>Optimizing lbm. Applying software prefetching is challenging because the developer must insert prefetches sufficiently early to hide memory latencies while at the same time taking care not to bottleneck other core resources (e.g., the LSQ) or pollute the caches. (Since the BOOM core does not support software prefetching, we implemented a custom software prefetch instruction using its ROCC interface.) Figure <ref type="figure" target="#fig_10">11</ref> shows the TEA-generated PICS for the most performance-critical load and store instructions when issuing software prefetches for the three cache lines lbm requires to execute  Figure <ref type="figure" target="#fig_1">12</ref>: Nab performance analysis. TEA identifies that the fsqrt.d instruction issues too late to hide its execution latency.</p><p>the body of its inner loop ? iterations before it is used (we refer to this as a prefetch distance of ?). The PICS show that as we increase prefetch distance, the impact of the most performance-critical load instruction on overall execution time goes down until it saturates at prefetch distance 4, i.e., LLC hits (ST-L1) accounts for most of its execution time impact. This increases performance which in turn increases store bandwidth requirements. The performance impact of the most performance-critical store instruction hence increases, mainly due to categories involving a full store queue (DR-SQ). Lbm writes 19 cache lines in each iteration, and prefetching hence moves its bottleneck from load latency to store bandwidth. While latency issues typically affect one static instruction, a bandwidth problem is typically distributed over multiple instructions, e.g., lbm has seven store instructions with a runtime over 10 billion clock cycles at distance 4.</p><p>Addressing this performance problem requires sweeping prefetch distances to identify the point where the load latency and store bandwidth effects balance out which exemplifies why TEA -by providing a comprehensive view on performance after running the application once -is desirable. The optimal prefetch distance for this architecture is 3 which yields a speedup of 1.28? over the original (see the line in Figure <ref type="figure" target="#fig_10">11</ref>). Analyzing nab. Figure <ref type="figure" target="#fig_1">12a</ref> shows the PICS as reported by TEA for the code region that contains the performance-critical fsqrt.d instruction of nab. Again, the PICS reported by TEA are very similar to the golden reference whereas the PICS generated by IBS are not (Figure <ref type="figure" target="#fig_1">12b</ref>). (Flushing instructions such as fsflags and frflags always flush the pipeline in this architecture and can hence be identified statically.) In this example, none of the instructions are subjected to performance events, and the key advantage of TEA is hence that the developer can trust that (i) the time attributed to fsqrt.d is accurate, and (ii) that TEA did not miss any performance events that can majorly impact performance.</p><p>Fsqrt.d is hence performance-critical because its execution latency was not hidden. The reason is that the fsflags and frflags instructions that were executed just prior to it always flush the pipeline in this architecture. These instructions are inserted by the compiler to be compliant with the IEEE 754 standard because flt.d by default should not trigger an exception upon a comparison involving a NaN value. The RISC-V ISA however does not include a non-excepting version of the flt.d instruction, and the fsflags and frflags instructions are hence required to mask exceptions. While understanding this (involved) behavior is possible when looking at the PICS of these exact instructions, it would be extremely challenging to understand otherwise.</p><p>Optimizing nab. Addressing this problem is simple because nab does not require any special handling of comparisons involving NaN values. More specifically, enabling the compiler options -finite -math or -fast-math yields speed-ups of 1.96? and 2.45?, respectively. The reason for the significant speedups is that avoiding pipeline flushes enables the processor to fetch and execute further ahead into the instruction stream, thereby better hiding the execution latencies of independent floating-point instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>The most related approaches to TEA are the instruction-driven performance analysis approaches AMD IBS <ref type="bibr" target="#b18">[19]</ref>, Arm SPE <ref type="bibr" target="#b3">[4]</ref>, and IBM RIS <ref type="bibr" target="#b28">[29]</ref> which are inaccurate because they are not timeproportional (see <ref type="bibr">Section 5)</ref>.</p><p>A large body of work relies on event-driven performance analysis using Performance Monitoring Counters (PMCs) as provided by Intel <ref type="bibr" target="#b29">[30]</ref> and DCPI <ref type="bibr" target="#b2">[3]</ref>. Researchers have hence investigated PMU design <ref type="bibr" target="#b35">[36]</ref>, and PMUs have a variety of uses (e.g., runtime optimization <ref type="bibr" target="#b8">[9]</ref>, performance analysis in managed languages <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b58">59]</ref>, profile-guided compilation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, and profile-guided metaprogramming <ref type="bibr" target="#b7">[8]</ref>). Xu et al. <ref type="bibr" target="#b52">[53]</ref> focus on providing correct offsets in PMC sampling by exploiting counters that are the same when running on real hardware and during binary instrumentation (e.g., retired instructions). BayesPerf <ref type="bibr" target="#b6">[7]</ref> encodes known relationships between performance counters in a machine learning model and then infers which performance counter values can be trusted. It is wellknown that PMCs can be challenging to make sense of <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b56">57]</ref>, and approaches have been proposed for reducing the consequences of the fact that only a limited number of events can be monitored concurrently (e.g., <ref type="bibr" target="#b40">[41]</ref>). We demonstrated in Section 5 that optimization based on PMCs is challenging because PMC counts often correlate poorly with performance, and adopting TEA will hence also address these issues.</p><p>Eyerman et al. <ref type="bibr" target="#b19">[20]</ref> propose a PMC architecture that enables constructing Cycles Per Instruction (CPI) stacks. The top-down model <ref type="bibr" target="#b53">[54]</ref>, which combines PMC output with a performance model to classify the application as mainly retiring instructions or being front-end-bound, back-end-bound, or suffering from bad speculation, can be viewed as a restricted form of a cycle stack because it presents a classification of an application's predominant performance bottleneck whereas a CPI stack breaks down an application's overall CPI across the units of the processors in which time was spent. Unlike TEA, these approaches cannot produce per-instruction cycle stacks -and our case studies demonstrate that instruction-level analysis is critical to understand performance issues.</p><p>While TEA explains why instructions are performance-critical, other performance aspects are also interesting. Vertical profiling <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> combines hardware performance counters with software instrumentation to profile an application across deep software stacks, while call-context profiling <ref type="bibr" target="#b59">[60]</ref> efficiently identifies the common orders functions are called in. Causal profiling <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b54">55]</ref> is able to identify the criticality of program segments in parallel codes by artificially slowing down segments and measuring their impact. Researchers have also devised approaches for profiling highly optimized code <ref type="bibr" target="#b47">[48]</ref>, assessing input sensitivity <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b55">56]</ref>, and profiling deployed applications <ref type="bibr" target="#b34">[35]</ref>.</p><p>Static instrumentation modifies the binary to gather (extensive) application execution data at the cost of performance overhead <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b48">49]</ref>. Dynamic instrumentation (e.g., Pin <ref type="bibr" target="#b38">[39]</ref> and Valgrind <ref type="bibr" target="#b41">[42]</ref>) does not modify the binary which leads to higher performance overheads than static instrumentation. Statistical performance analysis approaches (e.g., TEA, IBS, SPE, and RIS) do not modify the binary and hence have (much) lower overhead than instrumentation-based approaches. Simulation and modeling can also be used to understand key performance issues. The most related approach to ours is FirePerf <ref type="bibr" target="#b33">[34]</ref> which uses FireSim <ref type="bibr" target="#b32">[33]</ref> to non-intrusively gather extensive performance statistics. FirePerf would hence, unlike TEA, incur a significant performance overhead if used in a non-simulated environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We have presented Time-Proportional Event Analysis (TEA) which explains execution time by mapping commit stalls to the performance events that caused them -thereby enabling the creation of time-proportional Per-Instruction Cycle Stacks (PICS). To generate PICS, TEA tracks performance events across all in-flight instructions, but, by carefully selecting which events to track, it only increases per-core power consumption by ?0.1%. TEA relies on statistical sampling and hence has a performance overhead of merely 1.1%, yet only incurs an average error of 2.1% compared to a nonsampling golden reference. We demonstrate the utility of TEA by using it to identify performance problems in the SPEC CPU2017 benchmarks lbm and nab that, once addressed, yield speedups of 1.28? and 2.45?, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example explaining how TEA creates PICS. TEA explains how performance events cause performance loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance event hierarchy for the Stalled (ST) commit state.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: TEA microarchitecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Quantifying the error for the PICS obtained through IBS, SPE, RIS, NCI-TEA, and TEA. TEA achieves the highest accuracy within 2.1% (and at most 7.7%) compared to the golden reference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>ISCA ' 23 ,</head><label>23</label><figDesc>June 17-21, 2023, Orlando, FL, USA DR-SQ DR-TLB ST-TLB ST-L1 ST-LLC DR-L1 FL-MB FL-EX FL-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Error versus sampling frequency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Errors at instruction and function granularity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>PICS generated by IBS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Lbm performance analysis. TEA identifies the performance-critical load whereas IBS does not.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: PICS and speedup for the most performancecritical load instruction and store instruction of lbm across a range of prefetch distances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The performance events of TEA, IBS, SPE, and RIS.</figDesc><table><row><cell>Event</cell><cell>Description</cell><cell cols="4">TEA IBS SPE RIS</cell></row><row><cell>DR-L1</cell><cell>L1 instruction cache miss</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell cols="2">DR-TLB L1 instruction TLB miss</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>DR-SQ</cell><cell>Store instruction stalled at dispatch</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>FL-MB</cell><cell>Mispredicted branch</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>FL-EX</cell><cell>Instruction caused exception</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>FL-MO</cell><cell>Memory ordering violation</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>ST-L1</cell><cell>L1 data cache miss</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>ST-TLB</cell><cell>L1 data TLB miss</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>ST-LLC</cell><cell>LLC miss caused by a load instruction</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell cols="6">cache (DR-L1), missed in the L1 instruction TLB (DR-TLB), and that</cell></row><row><cell cols="6">the ROB drains due to a full store queue (DR-SQ). The DR-SQ event</cell></row><row><cell cols="6">captures the case where the ROB drains because a store cannot</cell></row><row><cell cols="6">dispatch because the Load/Store Queue (LSQ) is full of completed</cell></row><row><cell cols="6">but not yet retired stores; this improves interpretability when the</cell></row></table><note><p>application is sensitive to store bandwidth. For the Flushed state, TEA captures that an instruction is a mispredicted branch (FL-MB), caused an exception (FL-EX), and caused a memory ordering violation (FL-MO). A memory ordering violation occurs when a load executes before an older store to the same address and hence has read stale data. It is addressed by re-executing the load and squashing all younger in-flight instructions (which is time-consuming). To explain the Stalled state, TEA captures L1 data cache misses (ST-L1), L1 data TLB misses (ST-TLB), and LLC misses caused by load instructions (ST-LLC). Capturing LLC misses improves interpretability for memory-sensitive applications.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Baseline architecture configuration.</figDesc><table><row><cell>Part</cell><cell>Configuration</cell></row><row><cell>Core</cell><cell>OoO BOOM [58]: RV64IMAFDCSUX @ 3.2 GHz</cell></row><row><cell cols="2">Front-end 8-wide fetch, 48-entry fetch buffer, 4-wide decode, 28 KB TAGE</cell></row><row><cell></cell><cell>branch predictor, 60-entry fetch target queue, max. 30 outstanding</cell></row><row><cell></cell><cell>branches</cell></row><row><cell>Execute</cell><cell>192-entry ROB, 192 integer/floating-point physical registers, 48-entry</cell></row><row><cell></cell><cell>dual-issue memory queue, 80-entry 4-issue integer queue, 48-entry</cell></row><row><cell></cell><cell>dual-issue floating-point queue</cell></row><row><cell>LSU</cell><cell>64-entry load/store queue</cell></row><row><cell>L1</cell><cell>32 KB 8-way I-cache, 32 KB 8-way D-cache w/ 16 MSHRs, 64</cell></row><row><cell></cell><cell>SDQ/RPQ entries, next-line prefetcher</cell></row><row><cell>LLC</cell><cell>2 MiB 16-way dual-bank w/ 12 MSHRs</cell></row><row><cell>TLB</cell><cell>Page Table Walker, 32-entry fully-assoc L1 D-TLB, 32-entry fully-</cell></row><row><cell></cell><cell>assoc L1 I-TLB, 1024-entry direct-mapped L2 TLB</cell></row><row><cell>Memory</cell><cell>16 GB DDR3 FR-FCFS quad-rank, 16 GB/s maximum bandwidth, 14-</cell></row><row><cell></cell><cell>14-14 (CAS-RCD-RP) latencies @ 1 GHz, 8 queue depth, 32 max</cell></row><row><cell></cell><cell>reads/writes</cell></row><row><cell>OS</cell><cell>Buildroot, Linux 5.7.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Performance-critical instructions are typically executed in (nested) loops and have many dynamic executions; we collect performance events across multiple sampled dynamic executions per static instruction in the binary.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>The key benefit of the front-end-tagging strategy used by IBS, SPE, and RIS is that it only requires tracking performance events for a single instruction which yields a single byte of storage overhead (compared to 249 bytes for TEA). Unfortunately, this lower overhead comes at the cost of poor accuracy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>While we took great care to implement and configure IBS, SPE, and RIS as faithfully as possible, we are ultimately limited by the information that has been disclosed publicly. The fundamental issue with these approaches is however that they are not time-proportional.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We thank the reviewers for their valuable feedback. Lieven Eeckhout is supported in part by the <rs type="funder">UGent-BOF-GOA</rs> grant No. <rs type="grantNumber">01G01421</rs>, the <rs type="funder">Research Foundation Flanders (FWO)</rs> grant No. <rs type="grantNumber">G018722N</rs>, and the <rs type="funder">European Research Council (ERC)</rs> Advanced Grant agreement No. <rs type="grantNumber">741097</rs>. <rs type="person">Magnus Jahre</rs> is supported by the <rs type="funder">Research Council of Norway</rs> (Grant No. <rs type="grantNumber">286596</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EdSwu9P">
					<idno type="grant-number">01G01421</idno>
				</org>
				<org type="funding" xml:id="_vNafGX2">
					<idno type="grant-number">G018722N</idno>
				</org>
				<org type="funding" xml:id="_k299wcp">
					<idno type="grant-number">741097</idno>
				</org>
				<org type="funding" xml:id="_NDyQUYe">
					<idno type="grant-number">286596</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><surname>Amd</surname></persName>
		</author>
		<ptr target="https://www.amd.com/en/support/tech-docs/preliminary-processor-programming-reference-ppr-for-amd-family-19h-model-21h" />
		<title level="m">Processor Programming Reference (PPR) for AMD Family 19h Model 21h, Revision B0 Processors</title>
		<meeting>essor Programming Reference (PPR) for AMD Family 19h Model 21h, Revision B0 essors</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>Amd</surname></persName>
		</author>
		<ptr target="https://developer.amd.com/amd-uprof/" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Continuous Profiling: Where Have All the Cycles Gone?</title>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lance</forename><forename type="middle">M</forename><surname>Berc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monika</forename><forename type="middle">R</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shun-Tak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">L</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">T</forename><surname>Sites</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">A</forename><surname>Vandevoorde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">E</forename><surname>Waldspurger</surname></persName>
		</author>
		<author>
			<persName><surname>Weihl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="357" to="390" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">ARM Architecture Reference Manual Supplement Statistical Profiling Extension</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
		<ptr target="https://static.docs.arm.com/ddi0586/a/DDI0586A_Statistical_Profiling_Extension.pdf" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Arm Neoverse N2 Core Technical Reference Manual</title>
		<author>
			<persName><surname>Arm</surname></persName>
		</author>
		<ptr target="https://developer.arm.com/documentation/102099/0000/Statistical-Profiling-Extension-support/Statistical-Profiling-Extension-events-packet" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Redefining the Role of the CPU in the Era of CPU-GPU Integration</title>
		<author>
			<persName><forename type="first">Manish</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhra</forename><surname>Mazumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">B</forename><surname>Baden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="16" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BayesPerf: Minimizing Performance Monitoring Errors Using Bayesian Statistics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Subho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravishankar</forename><forename type="middle">K</forename><surname>Kalbarczyk</surname></persName>
		</author>
		<author>
			<persName><surname>Iyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="832" to="844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Profile-Guided Meta-Programming</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swaha</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>St-Amour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Kent</forename><surname>Dybvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using HPM-Sampling to Drive Dynamic Compilation</title>
		<author>
			<persName><forename type="first">Dries</forename><surname>Buytaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Georges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Arnold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA)</title>
		<meeting>the ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="553" to="568" />
		</imprint>
	</monogr>
	<note>Lieven Eeckhout, and Koen De Bosschere</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName><surname>Cadence</surname></persName>
		</author>
		<ptr target="https://www.cadence.com/ko_KR/home/tools/digital-design-and-signoff/synthesis/genus-synthesis-solution.html" />
	</analytic>
	<monogr>
		<title level="j">Genus Synthesis Solution</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><surname>Cadence</surname></persName>
		</author>
		<ptr target="https://www.cadence.com/en_US/home/tools/digital-design-and-signoff/power-analysis/joules-rtl-power-solution.html" />
		<title level="m">Joules RTL Power Solution</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate and Practical Profile-Driven Compilation Using the Profile Buffer</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kishore</forename><forename type="middle">N</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><surname>Hirsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture</title>
		<meeting>the International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>MICRO). IEEE Computer Society</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using Branch Handling Hardware to Support Profile-Driven Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Burzin</forename><forename type="middle">A</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Input-Sensitive Profiling</title>
		<author>
			<persName><forename type="first">Emilio</forename><surname>Coppa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camil</forename><surname>Demetrescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irene</forename><surname>Finocchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Coz: Finding Code That Counts with Causal Profiling</title>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Curtsinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emery</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Operating Systems Principles (SOSP)</title>
		<meeting>the Symposium on Operating Systems Principles (SOSP)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="184" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain-Specific Hardware Accelerators</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yatish</forename><surname>Turakhia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="48" to="57" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">RAPL: Memory Power Estimation and Capping</title>
		<author>
			<persName><forename type="first">Howard</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Gorbatov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ulf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Hanebutte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Low Power Electronics and Design (ISLPED)</title>
		<meeting>the International Symposium on Low Power Electronics and Design (ISLPED)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">ProfileMe: Hardware Support for Instruction-Level Profiling on Out-of-Order Processors</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">A</forename><surname>Waldspurger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">E</forename><surname>Weihl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Chrysos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture</title>
		<meeting>the International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>MICRO). IEEE Computer Society</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="292" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Instruction-Based Sampling: A New Performance Analysis Technique for AMD Family 10h Processors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><surname>Drongowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>AMD</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Performance Counter Architecture for Computing Accurate CPI Components</title>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tejas</forename><surname>Karkhanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="175" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://github.com/gperftools/gperftools" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">TIP: Time-Proportional Instruction Profiling</title>
		<author>
			<persName><forename type="first">Bj?rn</forename><surname>Gottschall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magnus</forename><surname>Jahre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="15" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">TraceDoctor: Versatile High-Performance Tracing for FireSim</title>
		<author>
			<persName><forename type="first">Bj?rn</forename><surname>Gottschall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magnus</forename><surname>Jahre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First FireSim and Chipyard User and Developer Workshop at ASPLOS</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gprof: A Call Graph Execution Profiler</title>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">B</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marshall</forename><forename type="middle">K</forename><surname>Mckusick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Symposium on Compiler Construction (SIGPLAN)</title>
		<meeting>the ACM SIGPLAN Symposium on Compiler Construction (SIGPLAN)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="120" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Performance Debugging in the Large via Mining Millions of Stack Traces</title>
		<author>
			<persName><forename type="first">Yingnong</forename><surname>Shi Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Software Engineering (ICSE)</title>
		<meeting>the International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="145" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automating Vertical Profiling</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">F</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)</title>
		<meeting>the ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="281" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Vertical Profiling: Understanding the Behavior of Object-Priented Applications</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">F</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)</title>
		<meeting>the ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="251" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Accelerator-Level Parallelism. Commun</title>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><forename type="middle">Janapa</forename><surname>Reddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="36" to="38" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><surname>Ibm</surname></persName>
		</author>
		<ptr target="https://ibm.ent.box.com/s/" />
		<title level="m">POWER9 Performance Monitor Unit User&apos;s Guide</title>
		<imprint>
			<date type="published" when="2018">2018. 8kh0orsr8sg32zb6zmq1d7zz6hud3f8j</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Intel 64 and IA-32 architectures software developer&apos;s manual combined volumes: 1</title>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<pubPlace>2A, 2B, 2C, 2D, 3A, 3B, 3C</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="https://www.intel.com/content/dam/develop/external/us/en/documents/vtune-profiler-user-guide.pdf" />
		<title level="m">VTune Profiler User Guide</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Performance Monitoring Event Reference</title>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="https://perfmon-events.intel.com/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Firesim: FPGA-Accelerated Cycle-Exact Scale-out System Simulation in the Public Cloud</title>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Biancolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dayeol</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Pemberton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Amaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qijing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Kovacs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Borivoje</forename><surname>Nikolic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randy</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">FirePerf: FPGA-Accelerated Full-System Hardware/Software Performance Profiling and Co-Design</title>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randy</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Borivoje</forename><surname>Nikoli?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="715" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">IntroPerf: Transparent Context-Sensitive Multi-Layer Performance Inference Using System Stack Traces</title>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Junghwan</forename><surname>Rhee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nipun</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guofei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</title>
		<meeting>the International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="235" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Survey and Taxonomy of On-Chip Monitoring of Multicore Systems-on-Chip</title>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Kornaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dionisios</forename><surname>Pnevmatikatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems (TODAES)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">LLVM: A Compilation Framework for Lifelong Program Analysis &amp; Transformation</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization (CGO)</title>
		<meeting>the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization (CGO)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><surname>Linux</surname></persName>
		</author>
		<ptr target="https://perf.wiki.kernel.org/index.php/Main_Page" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pin: Building Customized Program Analysis Tools with Dynamic Instrumentation</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harish</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artur</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><forename type="middle">Janapa</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="190" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Evaluating the Accuracy of Java Profilers</title>
		<author>
			<persName><forename type="first">Todd</forename><surname>Mytkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">F</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI). Association for Computing Machinery</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI). Association for Computing Machinery</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Time Interpolation: So Many Metrics, So Few Registers</title>
		<author>
			<persName><forename type="first">Todd</forename><surname>Mytkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">F</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Diwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
		<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="286" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Valgrind: a Framework for Heavyweight Dynamic Binary Instrumentation</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Nethercote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Seward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="89" to="100" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">What-If Analysis of Page Load Time in Web Browsers Using Causal Profiling</title>
		<author>
			<persName><forename type="first">Ardalan</forename><surname>Behnam Pourghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aparna</forename><surname>Amiri Sani</surname></persName>
		</author>
		<author>
			<persName><surname>Chandramowlishwaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</title>
		<meeting>the International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="87" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The CSI Framework for Compiler-Inserted Program Instrumentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Schardl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damon</forename><surname>Denniston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><forename type="middle">C</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I-Ting Angelina</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Measurement and Analysis of Computing Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Magnus</forename><surname>Sj?lander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magnus</forename><surname>Jahre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunnar</forename><surname>Tufte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nico</forename><surname>Reissmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.05848[cs.DC]</idno>
		<title level="m">EPIC: An Energy-Efficient, High-Performance GPGPU Computing Research Infrastructure</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">SPEC CPU</title>
		<author>
			<persName><surname>Spec</surname></persName>
		</author>
		<ptr target="https://www.spec.org/cpu" />
		<imprint>
			<date type="published" when="2017">2019. 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Using Hardware Performance Monitors to Understand the Behavior of Java Applications</title>
		<author>
			<persName><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendon</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Perry</forename><surname>Cahoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Grove</surname></persName>
		</author>
		<author>
			<persName><surname>Hind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Virtual Machine Research And Technology Symposium</title>
		<meeting>the Conference on Virtual Machine Research And Technology Symposium</meeting>
		<imprint>
			<publisher>VM). USENIX Association</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Binary Analysis for Measurement and Attribution of Program Performance</title>
		<author>
			<persName><forename type="first">Nathan</forename><forename type="middle">R</forename><surname>Tallent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Mellor-Crummey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Fagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="441" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Demystifying Page Load Performance with WProf</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Sophia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Aruna</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wetherall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Conference on Networked Systems Design and Implementation (NSDI). USENIX Association</title>
		<meeting>the USENIX Conference on Networked Systems Design and Implementation (NSDI). USENIX Association</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="473" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Can Hardware Performance Counters be Trusted?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sally</forename><forename type="middle">A</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><surname>Mckee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Workload Characterization (IISWC)</title>
		<meeting>the International Symposium on Workload Characterization (IISWC)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Non-Determinism and Overcount on Modern Hardware Performance Counter Implementations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirley</forename><surname>Terpstra</surname></persName>
		</author>
		<author>
			<persName><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
		<meeting>the International Symposium on Performance Analysis of Systems and Software (ISPASS)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="215" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A Portable Sampling-Based Profiler for Java Virtual Machines</title>
		<author>
			<persName><forename type="first">John</forename><surname>Whaley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Java Grande (JAVA)</title>
		<meeting>the Conference on Java Grande (JAVA)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Can We Trust Profiling Results? Understanding and Fixing the Inaccuracy in Modern Profilers</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingsen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizy</forename><surname>Kurian John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Supercomputing (ICS)</title>
		<meeting>the International Conference on Supercomputing (ICS)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="284" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A Top-Down Method for Performance Analysis and Counters Architecture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yasin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
		<meeting>the International Symposium on Performance Analysis of Systems and Software (ISPASS)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Parallelism-Centric What-If and Differential Analyses</title>
		<author>
			<persName><forename type="first">Adarsh</forename><surname>Yoga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santosh</forename><surname>Nagarakatte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="485" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Algorithmic Profiling</title>
		<author>
			<persName><forename type="first">Dmitrijs</forename><surname>Zaparanuks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hauswirth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="67" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Accuracy of Performance Counter Measurements</title>
		<author>
			<persName><forename type="first">Dmitrijs</forename><surname>Zaparanuks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Jovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hauswirth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
		<meeting>the International Symposium on Performance Analysis of Systems and Software (ISPASS)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Sonic-BOOM: The 3rd Generation Berkeley Out-of-Order Machine</title>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Korpan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abraham</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>Fourth Workshop on Computer Architecture Research with RISC-V</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Accurate Profiling in the Presence of Dynamic Compilation</title>
		<author>
			<persName><forename type="first">Yudi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lubom?r</forename><surname>Bulej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Binder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)</title>
		<meeting>the ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="433" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Accurate, Efficient, and Adaptive Calling Context Profiling</title>
		<author>
			<persName><forename type="first">Xiaotong</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><forename type="middle">J</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harold</forename><forename type="middle">W</forename><surname>Cain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong-Deok</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="263" to="271" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
