<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Handling Occlusions in Dense Multi-view Stereo</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bing</forename><surname>Sing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research Microsoft Research The Robotics Institute Microsoft Corporation Microsoft Corporation</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Kang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research Microsoft Research The Robotics Institute Microsoft Corporation Microsoft Corporation</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinxiang</forename><surname>Szeliski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research Microsoft Research The Robotics Institute Microsoft Corporation Microsoft Corporation</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><surname>Chai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research Microsoft Research The Robotics Institute Microsoft Corporation Microsoft Corporation</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Handling Occlusions in Dense Multi-view Stereo</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F99F66138FB67C94CDD03D85D28531BD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While stereo matching was originally formulated as the recovery of 3D shape from a pair of images, it is now generally recognized that using more than two images can dramatically improve the quality of the reconstruction. Unfortunately, as more images are added, the prevalence of semioccluded regions (pixels visible in some but not all images) also increases. In this paper, we propose some novel techniques to deal with this problem. Our first idea is to use a combination of shiftable windows and a dynamically selected subset of the neighboring images to do the matches. Our second idea is to explicitly label occluded pixels within a global energy minimization framework, and to reason about visibility within this framework so that only truly visible pixels are matched. Experimental results show a dramatic improvement using the first idea over conventional multibaseline stereo, especially when used in conjunction with a global energy minimization technique. These results also show that explicit occlusion labeling and visibility reasoning do help, but not significantly, if the spatial and temporal selection is applied first.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the classic research problems in computer vision is that of stereo, i.e., the reconstruction of three-dimensional shape from two or more intensity images. Such reconstruction has many practical applications, including robot navigation, object recognition, and more recently, realistic scene visualization (image-based rendering).</p><p>Why is stereo so difficult? Even if we disregard nonrigid effects such as specularities, reflections, and transparencies, we still have to deal with depth discontinuities, which cause occlusions and disocclusions, and with lack of texture in images. Depth discontinuities cause objects to appear and disappear at different viewpoints, thus confounding the matching process at or near object boundaries. The lack of texture, meanwhile, results in ambiguities in depth assignments caused by the presence of multiple good matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Previous work</head><p>A substantial amount of work has been done on stereo; a survey on stereo methods can be found in <ref type="bibr" target="#b9">[10]</ref>. Stereo can generally be described in terms of the following components: matching criterion, aggregation method, and winner selection <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref>. (Due to space limitations, we only cite the most recent or relevant references.)</p><p>The matching criterion is used as a means of measuring the similarity of pixels or regions across different images. A typical error measure is the RGB or intensity difference between images (these differences can be squared, or robust measures can be used). Some methods compute subpixel disparities by computing the analytic minimum of the local error surface or using gradient-based techniques <ref type="bibr" target="#b14">[15]</ref>. Birchfield and Tomasi <ref type="bibr" target="#b2">[3]</ref> measure pixel dissimilarity by taking the minimum difference between a pixel in one image and the interpolated intensity function in the other image.</p><p>The aggregation method refers to the manner in which the error function over the search space is computed or accumulated. The most direct way is to apply search windows of a fixed size over a prescribed disparity space for multiple cameras <ref type="bibr" target="#b18">[19]</ref>. Others use adaptive windows <ref type="bibr" target="#b17">[18]</ref>, shiftable windows <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b26">27]</ref>, or multiple masks <ref type="bibr" target="#b16">[17]</ref>. Another set of methods accumulates votes in 3D space, e.g., the space sweep approach <ref type="bibr" target="#b8">[9]</ref> and voxel coloring and its variants <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>Once the initial or aggregated matching costs have been computed, a decision must be made as to the correct disparity assignment for each pixel d(x, y). Local methods do this at each pixel independently, typically by picking the disparity with the minimum aggregated value. Cooperative/competitive algorithms can be used to iteratively decide on the best assignments <ref type="bibr" target="#b28">[29]</ref>.</p><p>Dynamic programming can be used for computing depths associated with edge features or general intensity similarity matches. These approaches can take advantage of one-dimensional ordering constraints along the epipolar line to handle depth discontinuities and unmatched regions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6]</ref>. However, these techniques are limited to two frames.</p><p>Fully global methods attempt to find a disparity surface d(x, y) that minimizes some smoothness or regularity property in addition to producing good matches. Such approaches include Markov Random Field optimization with simulated annealing <ref type="bibr" target="#b0">[1]</ref>, nonlinear diffusion of support at different disparity hypotheses <ref type="bibr" target="#b20">[21]</ref>, graph cut methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b6">7]</ref>, and the use of graph cuts in conjuction with planar surface fitting <ref type="bibr" target="#b3">[4]</ref>.</p><p>While occlusions are usually only explicitly handled in the dynamic programming approaches (where semi-  occluded regions are labelled explicitly), some techniques have been developed for reasoning about occlusions in a multiple-image setting. These approaches include using multiple matching templates <ref type="bibr" target="#b16">[17]</ref>, voxel coloring and its variants <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b13">14]</ref>, estimating a depth map per image <ref type="bibr" target="#b23">[24]</ref>, and graph cuts with the enforcement of unique correspondences <ref type="bibr" target="#b12">[13]</ref>.</p><p>In this paper, we present two complementary approaches to better deal with occlusions in multi-view stereo matching. The first approach (Section 3) uses not only spatially adaptive windows, but also selects a temporal subset of the frames to match at each pixel. The second approach (Section 4) uses a global (MRF) minimization approach based on graph cuts that explicitly models occluded regions with a special label. It also reasons about occlusions by selectively freezing good matching points, and erasing these from the set of pixels that must be matched at depths further back. Both approaches can be combined into a single system, as shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem formulation</head><p>In a multi-view stereo problem, we are given a collection of images {I k (x, y), k = 0 . . . K} and associated camera matrices {P k , k = 0 . . . K}. I 0 (x, y) is the reference image for which we wish to compute a disparity map d(x, y) such that pixels in I 0 (x, y) project to their corresponding locations in the other images when the correct disparity is selected.</p><p>In the classic forward-facing multi-baseline stereo configuration <ref type="bibr" target="#b18">[19]</ref>, the camera matrices are such that disparity (inverse depth) varies linearly with horizontal pixel motion,</p><formula xml:id="formula_0">Îk (x, y, d) = I k (x + b k d(x, y), y), (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where Îk (x, y, d) is image I k warped by the disparity map d(x, y). In a more general (plane sweep) multi-view setting <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref>, each disparity corresponds to some plane equation in 3-D. Hence, the warping necessary to bring pixels at some disparity d into registration with the reference image can be represented by a homography H k (d),</p><formula xml:id="formula_2">Îk (x, y, d) = H k (d) • I k (x, y), (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where the homography can be computed directly from the camera matrices P 0 and P k and the value of d <ref type="bibr" target="#b24">[25]</ref>. In this paper, we assume the latter generalized multi-view configuration, since it allows us to reconstruct depth maps from arbitrary collections of images. Given the collection images warped at all candidate disparities, we can compute an initial raw (unaggregated) matching cost E raw (x, y, d, k) = ρ I 0 (x, y) -Îk (x, y, d) , <ref type="bibr" target="#b2">(3)</ref> where ρ(•) is some (potentially) robust measure of the color or intensity difference between the reference and warped image (see, e.g., <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref> for some comparative results with different robust metrics). In this paper, we use a simple squared color difference in our experiments.</p><p>The task of stereo reconstruction is then to compute a disparity function d(x, y) such that the raw matching costs are low for all images (or at least the subset where a given pixel is visible), while also producing a "reasonable" (e.g., piecewise smooth) surface. Since the raw matching costs are very noisy, some kind of spatial aggregation or optimization is necessary. The two main approaches used today are local methods, which only look in a neighborhood of a pixel before making a decision, and global optimization methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Local techniques</head><p>The simplest aggregation method is the classic sum of sum of squared distances (SSSD) formula, which simply aggregates the raw matching score over all frames <ref type="bibr" target="#b3">(4)</ref> where W(x, y) is an n×n square window centered at (x, y). This can readily be seen as equivalent to a convolution with a 3-dimensional box filter.</p><formula xml:id="formula_4">E SSSD (x, y, d) = k =0 (u,v)∈W(x,y) E raw (u, v, d, k),</formula><p>After the aggregated errors have been computed, local techniques choose the disparity with the minimum SSSD error, which measures the degree of photoconsistency at a hypothesized depth. The best match can also be assigned a local confidence computed using the variance (across disparity) of the SSSD error function within the vicinity of the best match <ref type="bibr" target="#b15">[16]</ref>.</p><p>While window-based techniques work well in textured regions and away from depth discontinuities or occlusions, they run into problems in other cases. Figure <ref type="figure" target="#fig_1">2</ref> shows how a symmetric (centered) window may lead to erroneous matching in such regions. Two ways of dealing with this problem are spatially shiftable windows and temporal selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Spatially shiftable windows</head><p>The idea of spatially shiftable windows is an old one that has recently had a resurgence in popularity <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b26">27]</ref>. The basic idea is to try several windows that include the pixel we are trying to match, not just the window centered at that pixel (Figure <ref type="figure" target="#fig_3">3</ref>). <ref type="foot" target="#foot_0">1</ref> This approach can improve the matching   of foreground objects near depth discontinuities (so long as the object is not too thin), and also handle background regions that are being disoccluded rather than occluded (the black pixel in the middle and left image of Figure <ref type="figure" target="#fig_3">3</ref>). To illustrate the effect of shiftable windows, consider the flower garden sequence shown in Figure <ref type="figure">6</ref>. The effect of using spatially shiftable windows over all 11 frames is shown in Figure <ref type="figure">7</ref>(b) for a 5 × 5 window size. As can be seen, there are differences, but they are not dramatic. The errors seen can be attributed to ignoring the effects of occlusions and disocclusions.</p><formula xml:id="formula_5">A B C D E F A B C D E F A B C D E F left middle right</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Temporal selection</head><p>Rather than summing the match errors over all the frames, a better approach would be to pick only the frames where the pixels are visible. Of course, this is not possible in general without resorting to the kind of visibility reasoning present in volumetric <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b13">14]</ref> or multiple depth map <ref type="bibr" target="#b23">[24]</ref> approaches, and also in the multiple mask approach of <ref type="bibr" target="#b16">[17]</ref>. However, often a semi-occluded region in the reference image will only be occluded in the predecessor or successor frames, i.e., for a camera moving along a continuous path, objects that are occluded along the path in one  direction tend to be seen along the reverse direction. (A similar idea has recently been applied to optic flow computation <ref type="bibr" target="#b22">[23]</ref>.) Figure <ref type="figure" target="#fig_3">3</ref> shows this behavior. The black pixel in region B and its surrounding (shifted) square region can be matched in the left image but not the right image. Figure <ref type="figure" target="#fig_4">4</ref> show this same phenomenon in a spatio-temporal slice (epipolar plane image). It can readily be seen that temporal selection is equivalent to shifting the window in time as well as in space.</p><p>Temporal selection as a means of handling occlusions and disocclusions can be illustrated by considering selected error profiles depicted in Figure <ref type="figure" target="#fig_5">5</ref>. Points such as A, which can be observed at all viewpoints, work without shiftable windows and temporal selection. Points such as C, which is an occluding point, work better with shiftable windows but do not require temporal selection. Points such as B, however, which is occluded in a fraction of the viewpoints, work best with both shiftable windows and temporal selection.</p><p>Rather than just picking the preceding or succeeding frames (one-sided matching), a more general variant would be to pick the best 50% of all images available. In this case, we compute the local SSD error for each frame separately, and then sum up the lowest values. This kind of approach can better deal with objects that are intermittently visible,  i.e., a "picket fence" phenomenon.</p><p>We have experimented with both variants, and found that they have comparable performance. Figure <ref type="figure">7(c-d</ref>) shows the results on the flower garden sequence, while Figure <ref type="figure">8</ref> shows results on the other two sequences. (See our supplementary materials for higher quality versions of these images.) As you can see, using temporal selection yields a dramatic improvement in results, especially near depth discontinuities (occlusion boundaries) such as the edges of the tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Adaptive window size</head><p>If a purely window-based technique is to be used, a reasonable way to handle untextured areas would be to use variable window sizes. We have implemented a novel variable window size approach that works as follows.</p><p>Instead of simply selecting the best depth at each pixel for a fixed (initial) window size, only a fraction (currently 15%) of the depths computed are committed based on their reliability. The reliability (or local confidence) assigned to each depth is the local variance of the error function around that depth. The higher the variance, the higher the perceived reliability. At every new iteration, the process is repeated with a larger window size over the uncommitted pixels. After 12 iterations, any undecided pixels are forced to commit. By using the error variance as a measure of depth reliability, we ensure that larger regions of textureless surfaces get to be handled by larger windows.</p><p>Our approach bears some resemblance to the recent proposal by Zhang and Shan <ref type="bibr" target="#b27">[28]</ref>, which starts with point matches and grows matching regions around these points. In our approach, however, there is no requirement to grow existing regions; instead, the most confident pixels are simply selected at each iteration. Our idea of variable window sizes is also similar to <ref type="bibr" target="#b17">[18]</ref>. However, we adopt a highest confidence first approach <ref type="bibr" target="#b7">[8]</ref> to choosing a window size rather than testing at each pixel location all the windows sizes in order to select an optimal size.</p><p>Results of using the incremental selection approach can be seen in Figure <ref type="figure" target="#fig_7">9</ref>. While it generally interpolates across textureless regions reasonably well, determining the correct fraction of pixels to commit at each iteration requires a heuristic decision (i.e., it may be scene dependent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Global techniques</head><p>The second general approach to dealing with ambiguity in stereo correspondence is to optimize a global energy function. Typically, such a function consists of two terms,</p><formula xml:id="formula_6">E global (d(x, y)) = E data + E smooth . (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>The value of the disparity field d(x, y) that minimizes this global energy is chosen as the desired solution. 2</p><p>2 Because of the tight connection between this kind of global energy and the log-likelihood of a Bayesian model using Markov Random Fields, these methods are also often called Bayesian or MRF methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>The data term E data is just a summation of the local (aggregated or unaggregated) matching costs, e.g.,</p><formula xml:id="formula_8">E data = (x,y) E SSSD (x, y, d(x, y)). (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>Because a smoothness term is used, spatial aggregation is usually not used, i.e., the window W (x, y) in the SSSD term is a single pixel (but see, e.g., <ref type="bibr" target="#b5">[6]</ref> for a global method that starts with a window-based cost measure).</p><p>The smoothness term E smooth measures the piecewisesmoothness in the disparity field,</p><formula xml:id="formula_10">E smooth = (x,y) s h x,y φ(d(x, y) -d(x + 1, y)) (7) + s v x,y φ(d(x, y) -d(x, y + 1)).</formula><p>The smoothness potential φ(•) can be a simple quadratic, a delta function, a truncated quadratic, or some other robust function of the disparity differences <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7]</ref>. The smoothness strengths s h x,y and s v x,y can be spatially varying. The MRF formulation used by <ref type="bibr" target="#b6">[7]</ref> makes s h</p><p>x,y and s v x,y monotonic functions of the local intensity gradient, which greatly helps in forcing disparity discontinuities to be coincident with intensity discontinuities.</p><p>If the vertical smoothness term is ignored, the global minimization can be decomposed into an independent set of 1-D optimizations, for which efficient dynamic programming algorithms exist <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6]</ref>. Many different algorithms have also been developed for minimizing the full 2-D global energy function, e.g., <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>In this section, we propose two extensions to the graph cut formulation introduced by <ref type="bibr" target="#b6">[7]</ref> in order to better handle the partial occlusions that occur in multi-view stereo: explicit occluded pixel labeling, and visibility computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Explicit occluded pixel labeling</head><p>When using a global optimization framework, pixels that do not have good matches in other images will still be assigned some disparity. Such pixels are often associated with a high local matching cost, and can be detected in a postprocessing phase. However, occluded pixels also tend to occur in contiguous regions, so it makes sense to include this information within the smoothness function (i.e., within the MRF formulation).</p><p>Our solution to this problem is to include an additional label that indicates pixels that are either outliers or potentially occluded. A fixed penalty is associated with adopting this label, as opposed to the local matching cost associated with some other disparity label. (In our current implementation, this penalty is set at 18 intensity levels.) The penalty should be set to be somewhat higher that the largest value observed for correctly matching pixels. The smoothness term for this label is a delta function, i.e., a fixed penalty is paid for every non-occluded pixel that borders an occluded one. Examples of using such a label can be seen in Figure <ref type="figure" target="#fig_8">10</ref>. Unfortunately, this approach sometimes fails to correctly label pixels in occluded textureless regions (since these pixels may still match correctly at the frontal depth). In addition, the optimal occluded label penalty setting depends on the amount of contrast in a given scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Visibility reasoning</head><p>An idea that has proven to be very effective in dealing with occlusions in volumetric <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b13">14]</ref> or multiple depth map <ref type="bibr" target="#b23">[24]</ref> approaches is that of visibility reasoning. Once a pixel has been matched at one disparity level, it is possible to "erase" that pixel from consideration when considering possible matches at disparities further back. This is the most principled way to reason about visibility and partial occlusions in multi-view stereo. However, since the algorithms cited above make independent decisions between pixels or frames, their results may not be optimal.</p><p>To incorporate visibility into the global optimization framework, we compute a visibility function similar to the one presented in <ref type="bibr" target="#b24">[25]</ref>. The visibility function v(x, y, d, k) can be computed as a function of the disparity assignments at layers closer than d. <ref type="figure">Let o(x,</ref><ref type="figure">y,</ref><ref type="figure">d ) = δ(d ,</ref><ref type="figure">d(x,</ref><ref type="figure">y</ref>)) be the opacity (or indicator) function, i.e., a binary image of those pixels assigned to level d . The shadow <ref type="figure">s(x,</ref><ref type="figure">y,</ref><ref type="figure">d ,</ref><ref type="figure">d,</ref><ref type="figure">k</ref>) that this opacity casts relative to camera k onto another level d can be derived from the homographies that map between disparities <ref type="figure">d</ref> and<ref type="figure">d   s(x, y, d , d, k</ref></p><formula xml:id="formula_11">) = (H k (d)H -1 k (d )) • o(x, y, d )<label>(8)</label></formula><p>(we can, for instance, use bilinear resampling to get "soft" shadows, indicative of partial visibility). The visibility of a pixel (x, y) at disparity d relative to camera k can be computed as</p><formula xml:id="formula_12">v(x, y, d, k) = d &lt;d (1 -s(x, y, d , d, k)). (<label>9</label></formula><formula xml:id="formula_13">)</formula><p>Finally, the raw matching cost (3) can then be replaced by</p><formula xml:id="formula_14">E vis (x, y, d, k) = v(x, y, d, k)ρ I 0 (x, y) -Îk (x, y, d) . (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>The above visibility-modulated matching score thus provides a principled way to compute the goodness of a particular disparity map d(x, y) while explicitly taking into account occlusions and partial visibility. For any given labeling d(x, y), we can compute the opacities, shadows, and visibilities, and then sum up the visibility-modulated matching scores <ref type="bibr" target="#b9">(10)</ref> to obtain the final global energy <ref type="bibr" target="#b4">(5)</ref>. Unfortunately, it is not obvious how to minimize such a complicated energy function.</p><p>One possibility would be to start with all pixels visible, and to then run the usual graph-cut algorithm. From the initial d(x, y) solution, we could recompute visibilities, and then re-optimize the modified energy function. Unfortunately, this process may not converge, since the energy function is being modified from iteration to iteration, and the visibilities assumed for one iteration may be undone by a re-assignment of labels in that iteration.</p><p>The alternative we have come up with (inspired by Chou's Highest Confidence First algorithm <ref type="bibr" target="#b7">[8]</ref>) is to progressively commit the best-matching depths (i.e., freeze their labels) and apply graph cut on the remaining pixels. This approach is related to the voxel coloring work <ref type="bibr" target="#b21">[22]</ref>, where voxels are tagged from front to back. However, in our approach, the best 15% of the pixels (based on the current visibility-modulated matching score (10)) whose depths have been computed by the graph cut are frozen. The visibility function and matching costs are then recomputed, which may affect costs at more distal voxels. Within each iteration, graph-cut labeling effectively takes into account neighboring pixels'preferences and tries to make the disparity function piecewise-smooth, whereas the voxel coloring approach only uses per-pixel photo-consistency. After 12 iterations, the remaining uncommitted pixels are frozen at their best value.</p><p>Figure <ref type="figure" target="#fig_0">11</ref> shows the results of adding visibility reasoning to the graph cut algorithm when starting with all frames as the data cost (no temporal selection). As can be seen by comparing the first two columns, the improvement is significant. (See our supplementary materials for higher quality versions of these images, as well as additional ex-</p><formula xml:id="formula_16">(a) (b) (c) (d) (e) (f) (g) (h) (i)</formula><p>Figure <ref type="figure" target="#fig_0">11</ref>: Effect of applying incremental visibility-based graph cuts: (a,d,g) results using all frames; (b,e,h) results using all frames and visibility; (c,f,i) results using best half sequence and no visibility. (There is no significant improvement in adding visibility reasoning when starting with the best half sequence (or best frames) data term.) perimental results.) Surprisingly, the addition of visibility computation to the graph cut did not produce significant improvements to our algorithm when the original matching costs were computed using a shiftable window and temporal selection. (The third column of Figure <ref type="figure" target="#fig_0">11</ref> shows the results of regular graph cuts combined with temporal selection using the best half sequence. The results are almost identical when visibility reasoning is added.) This suggests that the shiftable window, and especially temporal selection, handled the occlusion problem well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this section, we summarize our experimental results applied to the image sequences shown in Figure <ref type="figure">6</ref>. Due to space limitations, we only present a brief sampling from the larger set of experiments we have run. Please see the accompanying supplementary material Web pages and our longer technical report <ref type="bibr" target="#b11">[12]</ref> for a more complete set of results.</p><p>Figures <ref type="figure">7</ref> and<ref type="figure">8</ref> show some results using spatially shiftable windows optionally combined with temporal selection, followed by a simple winner-take-all. The effects of temporal selection are more dramatric than spatial shifting, and yield their biggest improvements near depth discontinuities. Large textureless regions are still not recovered well.</p><p>Using incremental window sizes (Figure <ref type="figure" target="#fig_7">9</ref>) helps fill in more reasonable disparity values in textureless regions, but still does not do that well in some areas such as the sky in the Symposium sequence and the upper right corner of the U. Tsukuba sequence. Global optimization techniques generally outperform this idea.</p><p>Adding an extra occluded pixel label to global optimization helps find regions that are visible in only one image, such as the start and end frames for a multi-view sequence (Figure <ref type="figure" target="#fig_8">10</ref>). This should help the most when only a small number of frames is available (e.g., in classical two-frame matching).</p><p>Finally, visibility reasoning is a good way to obtain better results near depth discontinuities when the complete set of images is used as input to the data cost term (Figure <ref type="figure" target="#fig_0">11</ref>). Reasoning about which pixels are occluded allows us to iteratively re-compute a better data term. However, to our surprise, this idea does not seem to help much if temporal selection has already been applied to heuristically reject possibly occluded pixels, at least not on the data sets we have currently tried.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we have presented several new ideas for improving the results of multi-view stereo correspondence algorithms. Our particular emphasis has been on better dealing with pixels and regions that are occluded in some images but not in others. Some of our ideas, such as temporal selection, can be applied at the initial matching cost stage. Other ideas, such as outlier/invisible pixel labeling and visibility reasoning, can be used to enhance the performance of global optimization techniques such as graph cut algorithms.</p><p>Of all the ideas we have developed, using temporal selection (using only a subset of all frames for computing the matching cost), followed by a regular graph cut global optimization, seems to yield the best results for the least computational effort. It will be interesting to see how these ideas generalize to other versions of multi-view stereo reconstruction, such as the extraction of multiple layers and volumetric reconstruction techniques.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of our stereo approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A simple three-image sequence (the middle image is the reference image), with a frontal gray square (marked F), and a stationary background. Regions B, C, D, and E are partially occluded. A regular SSD algorithm will make mistakes when matching pixels in these regions (e.g. the window centered on the black pixel in region B), and also in windows straddling depth discontinuities (the window centered on the white pixel in region F).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Shiftable windows help mitigate the problems in partially occluded regions and near depth discontinuities. The shifted window centered on the white pixel in region F now matches correctly in all frames. The shifted window centered on the black pixel in region B now matches correctly in the left image. Temporal selection is required to disable matching this window in the right image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The spatio-temporal diagram (epipolar plane image) corresponding to the previous figure. The three images (middle, left, right) are slices through this EPI volume. The spatially and temporally shifted window around the black pixel is indicated by the rectangle, showing the the right image is not being used in matching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Error profiles for three points in reference image. A: point seen all the time, B: point occluded about half the time, C: occluding point. Left: Reference image, Right: Error graph at respective optimal depths with respect to the frame number (frame #6 is the reference).</figDesc><graphic coords="3,318.65,276.83,115.20,80.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :Figure 7 :Figure 8 :</head><label>678</label><figDesc>Figure 6: Middle (reference) images from the three test sequences: 11-image flower garden sequence; 5-image Symposium sequence, courtesy of Dayton Taylor; 5-image sequence, courtesy of the University of Tsukuba.</figDesc><graphic coords="4,63.83,97.95,154.44,108.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Final results of incremental window size algorithm run on all three sequences. See the supplementary materials for intermediate (partial) results.</figDesc><graphic coords="4,63.83,569.31,154.44,108.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Effect of using the undefined label for 11-frame flower garden sequence (64 depth levels, no visibility terms, using best frames): (a) Reference image is 1st image, (b) Reference image is 6th image, (c) Reference image is 11th image. The undefined label is black, while the intensities for the rest are bumped up for visual clarity.</figDesc><graphic coords="6,60.05,90.00,158.40,109.30" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>When using square windows, finding the best matching shifted window can be computed by passing a min-filter over the original SSD scores.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stochastic stereo matching over scale</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Barnard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="32" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Bayesian-approach to binocular stereopsis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="260" />
			<date type="published" when="1996-08">August 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A pixel dissimilarity measure that is insensitive to image sampling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Birchfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="406" />
			<date type="published" when="1998-04">April 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiway cut for stereo and motion with slanted surfaces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Birchfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;99</title>
		<meeting><address><addrLine>Kerkyra, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="489" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the unification of line processes, outlier rejection, and robust statistics with applications in early vision</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="91" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large occlusion stereo</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Bobick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Intille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="200" />
			<date type="published" when="1999-09">September 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;99</title>
		<meeting><address><addrLine>Kerkyra, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The theory and practice of Bayesian image labeling</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="210" />
			<date type="published" when="1990-06">June 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A space-sweep approach to true multi-image matching</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR&apos;96</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="358" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Structure from stereo-a review</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Dhond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1489" to="1510" />
			<date type="published" when="1989-12">November/December 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Occlusions, discontinuities, and epipolar lines in stereo</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV&apos;98</title>
		<meeting><address><addrLine>Freiburg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="232" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Handling occlusions in dense multi-view stereo</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chai</surname></persName>
		</author>
		<idno>MSR-TR-2001- 80</idno>
		<imprint>
			<date type="published" when="2001-09">September 2001</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computing visual correspondence with occlusions via graph cuts</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<meeting><address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">2001. July 2001</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="508" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A theory of shape by space carving</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Kutulakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;99</title>
		<meeting><address><addrLine>Kerkyra, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application in stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI-81</title>
		<meeting><address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="674" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Kalman filter-based algorithms for estimating depth from image sequences</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Matthies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="209" to="236" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Occlusion detectable stereo -occlusion patterns in camera matrix</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Satoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Ohta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR&apos;96</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-06">June 1996</date>
			<biblScope unit="page" from="371" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A locally adaptive window for signal matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="162" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A multiple baseline stereo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="1993-04">April 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A maximum-flow formulation of the n-camera stereo correspondence problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;98</title>
		<meeting><address><addrLine>Bombay</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-01">January 1998</date>
			<biblScope unit="page" from="492" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stereo matching with nonlinear diffusion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="174" />
			<date type="published" when="1998-07">July 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Photorealistic scene reconstrcution by voxel coloring</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR&apos;97</title>
		<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="1067" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Motion estimation based on optical flow with adaptive gradients</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Haynor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP-2000</title>
		<meeting><address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-09">September 2000</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="852" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A multi-view approach to motion and stereo</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR&apos;99</title>
		<imprint>
			<publisher>Fort Collins</publisher>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stereo matching with transparency and matting</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="61" />
			<date type="published" when="1999-08">August 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An experimental comparison of stereo algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Work. Vision Algorithms</title>
		<meeting><address><addrLine>Kerkyra, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A global matching framework for stereo computation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2001</title>
		<meeting><address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A progressive scheme for stereo matching</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-07">2000. July 2000</date>
			<biblScope unit="page" from="68" to="85" />
			<pubPlace>SMILE; Dublin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A cooperative algorithm for stereo matching and occlusion detection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="675" to="684" />
			<date type="published" when="2000-07">July 2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
