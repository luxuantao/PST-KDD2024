<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Drug Protein Interaction using Quasi-Visual Question Answering System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shuangjia</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Supercomputer Center</orgName>
								<address>
									<settlement>Guangzhou</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Pharmaceutical Sciences</orgName>
								<orgName type="institution">Sun Yat-Sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongjian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Supercomputer Center</orgName>
								<address>
									<settlement>Guangzhou</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sheng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Supercomputer Center</orgName>
								<address>
									<settlement>Guangzhou</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
							<email>junxu@biochemomes.com</email>
							<affiliation key="aff2">
								<orgName type="department">School of Pharmaceutical Sciences</orgName>
								<orgName type="institution">Sun Yat-Sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuedong</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Supercomputer Center</orgName>
								<address>
									<settlement>Guangzhou</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Drug Protein Interaction using Quasi-Visual Question Answering System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying novel drug-protein interactions is crucial for drug discovery. For this purpose, many machine learning-based methods have been developed based on drug descriptors and one-dimensional (1D) protein sequences. However, protein sequence can't accurately reflect the interactions in 3D space. On the other hand, a direct input of 3D structure is of low efficiency due to the sparse 3D matrix, and is also prevented by limited number of co-crystal structures available for training. In this work, we propose an end-to-end deep learning framework to predict the interactions by representing proteins with 2D distance map from monomer structures (Image), and drugs with molecular linear notation (String), following the Visual Question Answering mode. For an efficient training of the system, we introduced a dynamic attentive convolutional neural network to learn fixed-size representations from the variable-length distance maps and a self-attentional sequential model to automatically extract semantic features from the linear notations. Extensive experiments demonstrate that our model obtains competitive performance against state-ofthe-art baselines on the DUD-E, Human and Bind-ingDB benchmark datasets. Further attention visualization provides biological interpretation to depict highlighted regions of both protein and drug molecules.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Prediction of drugprotein interactions (DPIs) is of crucial importance for drug design and development. Though experimental assays remain to be the most reliable approach for determining DPIs, experimental characterization of every possible drug-protein pair is daunting due to the vast amount of money and labors in experiments.</p><p>Computational prediction of DPIs has therefore made rapid progress recently. In general, it falls roughly into two categories: physic-based and machine-learning method-s. Physic-based methods such as molecular docking apply physics-inspired predetermined energy functions to assess drug-protein interactions at the atomic level <ref type="bibr" target="#b2">[Trott and Olson, 2010</ref>]. However, these methods are usually of limited accuracy due to difficulties to evaluate the conformational entropy and solvent contributions. Furthermore, these atom level methods are sensitive to structural fluctuations and can't process protein flexibility well.</p><p>With the recent increase in protein structural data and protein-ligand interaction datasets, there is a rapid progress in machine learning-based methods <ref type="bibr" target="#b1">[Ragoza et al., 2017;</ref><ref type="bibr" target="#b2">Tsubaki et al., 2018;</ref><ref type="bibr" target="#b0">Gao et al., 2018]</ref>. Usually, the prediction is treated as a task of binary classification by integrating information of ligands, proteins, and their interactions in a unified framework.</p><p>Drug molecules can be well represented by their linear notations since most drugs contain less than 100 heavy atoms, and thus have a relatively small structural space. Recent studies have proven that current deep learning techniques can accurately predict structural properties from their linear representation <ref type="bibr" target="#b3">[Zheng et al., 2018;</ref><ref type="bibr" target="#b0">Öztürk et al., 2018]</ref>. In contrast, protein molecules are much bigger, typically containing more than 1000 heavy atoms. The prediction from 1D sequence to 3D structure is the well-known challenging problem called protein folding. Therefore, traditional representation by 1D protein sequence is insufficient to capture the structural features in 3D space that decides the prediction of DPIs. Although the direct input of 3D structure was attempted in recent studies <ref type="bibr">[Wallach et al., 2015;</ref><ref type="bibr" target="#b1">Ragoza et al., 2017;</ref><ref type="bibr" target="#b2">Stepniewska-Dziubinska et al., 2018]</ref>, they achieved relatively low accuracy due to a few reasons. First, the irregular protein 3D structure needs a big 3D matrix to contain the whole structure. The high-dimension, sparse matrix caused a large number of tedious input variables. Secondly, these studies suffered from small number of high-quality 3D structures because they need co-crystal structures of protein-ligand pairs that are difficult to determine by experiments.</p><p>As a balance, proteins can be alternatively represented by 2D pairwise distance map. Previous studies indicated that the distance map can recover protein 3D structures <ref type="bibr" target="#b2">[Skolnick et al., 1997]</ref>. More recently, DeepMind group 1 predicted protein structures more precisely than prior state-of-the-art so-lutions by using 2D image feature from a predicted distance map.</p><p>Inspired by these studies, we will utilize 2D distance map to represent proteins, and thus the DPI task can be converted into a classical Visual Question Answering (VQA) problem. Here, images are the distance maps for proteins, questions are the molecular linear notations for drugs, and answers are whether they will interact. This framework enables a training on protein monomer structures without need of co-crystal structures with their binding ligands, which significantly expands usable datasets for training.</p><p>However, there exists to be differences between VQA and DPI prediction. First, in many VQA scenarios, image size can be resized to a fixed value, but the distance map represents the real-world scale and can't be resized. Second, the grammatical rules of chemical language are different from natural language, which force us to utilize customized tokenization process and suitable model for obtaining the semantic feature of molecular sequence. Third, our training set is still much smaller than other applications, which requires us to carefully design the networks.</p><p>To address the above problems, we present a VQA-inspired interpretable model that predicts DPIs directly from protein distance map and chemical language. The 2D map and chemical language are respectively encoded by a dynamic convolutional neural network (DynCNN) and bi-directional long short-term memory (BiLSTM) with attention, and the outputs are concatenated to dense layer to make prediction.</p><p>The proposed model is shown to outperform state-of-theart approaches over three public DPI datasets. More importantly, the learned attentions enable visualized individual contributions between binding regions on proteins and ligands that is important for ligand refinement.</p><p>In summary, the main contributions of our work are as follows. To our best knowledge,</p><p>• this is the first study to utilize protein 2D distance map for predicting DPI;</p><p>• this is the first attempt to solve the DPI prediction with the VQA framework;</p><p>• extensive experiments are conducted on different level public datasets to demonstrate the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related works</head><p>Current drug-protein interaction prediction approaches could mainly be summarized as below: Docking-based methods, such as <ref type="bibr" target="#b2">[Trott and Olson, 2010;</ref><ref type="bibr" target="#b0">Koes et al., 2013]</ref>, are widely used to predict the binding mode and affinity given the 3D structure inputs of a drug compound and a protein. These methods apply predefined force fields to estimate the binding score to assess DPIs at the atomic level.</p><p>Machine learning-based methods have been investigated to predict DPIs. For example, <ref type="bibr" target="#b0">[Bleakley and Yamanishi, 2009]</ref> proposed the bipartite local model by training local SVM classifiers from chemical structure similarity and protein sequence similarity. <ref type="bibr" target="#b0">[Ballester and Mitchell, 2010]</ref> used random forest algorithm to capture binding effects during molecular docking process; <ref type="bibr" target="#b0">[Durrant and McCammon, 2011]</ref> presented a scoring function based on fully connected neural networks to characterize the binding affinities of proteinligand complexes; <ref type="bibr">[Tabei and Yamanishi, 2013]</ref> further improved the DPI prediction by using hashing algorithm with more compact fingerprints of compound-protein pairs.</p><p>Recently, deep learning techniques have been introduced to predict DPIs by direct use of <ref type="bibr">3D protein-compound complexes [Wallach et al., 2015;</ref><ref type="bibr" target="#b1">Ragoza et al., 2017;</ref><ref type="bibr" target="#b2">Stepniewska-Dziubinska et al., 2018]</ref>. Since the input features were based on 3D matrix defined around pocket-ligand complexes, these methods generated a large number input variables, and suffered from limited number of training set.</p><p>In addition, though a few representation learning studies predicted DPIs based on protein sequence or their functional annotations <ref type="bibr" target="#b2">[Tsubaki et al., 2018;</ref><ref type="bibr" target="#b0">Gao et al., 2018;</ref><ref type="bibr" target="#b0">Öztürk et al., 2018]</ref>, their accuracies were limited with a lack of protein structural information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>Our task is to predict the interaction between a drug compound and a target protein. Concretely, drug compound is represented in SMILES format, a text string for the topological information based on chemical bonding rules. For example, the benzene ring can be encoded as 'c1ccccc1'. Each lowercase 'c' represents an aromatic carbon atom and '1' for the start and closing of a cycle. All hydrogen atoms weren't shown because they can be deduced via simple rules.</p><p>To preserve important chemical features, we tokenized drug molecules using the following regular expression inspired by the work of <ref type="bibr">[Olivecrona et al., 2017]</ref>:</p><formula xml:id="formula_0">token regex = "(\[[ˆ\[\]]{1, 6}\])"<label>(1)</label></formula><p>Additionally, we replaced the multi-character symbols using the following rules: 'Br':R, 'Cl':L, 'Si':A, 'Se':Z. Suppose we have a drug molecular linear notation containing n tokens, the molecule can be represented in a sequence of molecular embeddings as M = (t 1 , . . . , t n ), where t i is a vector of d-dimensional token embedding for the i-th token. Thus, M ∈ R n×d is a representation of 2D matrix by concatenating all the token embeddings together.</p><p>Similarly, a protein can be simply described as a linear sequence that consists of a list of amino acids residues P = (r 1 , . . . , r l ), where r i is a one-hot representative vector with length of 20 for the amino acid type at position i, and l is the sequence length. Additionally, we calculate a 2D pairwise distance map by:</p><formula xml:id="formula_1">ŝ(r i , r j ) = 1 1 + d(r i , r j )/d 0 , r i , r j ∈ P (2)</formula><p>where d(r i , r j ) is the distance between C α atoms of residues i and j, and</p><formula xml:id="formula_2">d 0 is set to 3.8 Å. Let ŝi ∈ [ŝ(r i , r 1 ), . . . , ŝ(r i , r l )]</formula><p>be the l-dimensional distance vector with all the residues in P of r i . The protein can be represented as a distance matrix: The goal of DPI prediction is to learn a system that takes a pair (M ;P ) as input and outputs label y ∈ {0, 1}, where y = 1 means an interaction between M and P .</p><formula xml:id="formula_3">P = [ ŝ1 , ŝ2 , ..., ŝl ] l×l</formula><p>Figure <ref type="figure" target="#fig_0">1</ref> is the architecture of our DrugVQA model. It comprises two main components: dynamic CNN with sequential attention (Sec.3.2) and BiLSTM with multi-head self-attention (Sec.3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dynamic attentive CNN</head><p>Preliminary. In our model, adapted CNN is employed to code protein distance maps to fixed-size vector representations. Our CNN module consists of stacked residual blocks and a sequential self-attention block. For the residual block, we use modified Resnet <ref type="bibr" target="#b0">[He et al., 2016]</ref> to process protein inputs. Concretely, given a protein distance map P ∈ R l×l , we apply a 3 × 3 convolutional layer with N f 1 filters. The output is then processed with stacked residue blocks. The inputs of each intermediate residue units can be represented by x q , where q(1 ≤ q ≤ Q) is the block unit index.</p><p>Each residue block could be defined as:</p><formula xml:id="formula_4">y q = H(x q ) + F(x q + W q ), (4) x q+1 = f (y q ) (5)</formula><p>where x q and x q+1 are input and output of the q-th block unit, and F is a residual function, H(x q ) = x q set as an identity mapping. W q = {w q,N q f } is a set of weights associated with the q-th residual unit, where N q f is the number of filters. The f function in Equation( <ref type="formula">5</ref>) is the activation function, and we utilize the Exponential Linear Unit (ELU) <ref type="bibr" target="#b0">[Clevert et al., 2015]</ref> instead of traditionally used Rectified Linear Unit (Re-LU). As shown in Figure <ref type="figure" target="#fig_1">2</ref>(a), each residual unit is stacked by a 5 × 5 convolutional layer and a 3 × 3 convolutional layer.</p><p>Dynamic processing. Different from VQA tasks that often preprocess images to the same size, the real-world proteins are of different lengths of amino acids and can't be scaled. Therefore, we want to design a dynamic neural network that could 1) handle inputs of variable lengths and 2) predict the importance of each amino acid. For this purpose, we take off the pooling layers between the residual block and use zero padding to two sides of input to ensure that the results of residual blocks have the same size as the input. Thus, the output of the last residual block remains the dimension of l × l × N f . Afterward, we apply average pooling to compress the information-enriched output of residual blocks for the downstream processing.</p><p>Sequential attention. Through average pooling, we obtain a protein feature map P q ∈ R l×N f . Practically, P q can be viewed as protein sequential representation where l is the number of amino acids (sites) in the protein, and N f represents the spatial feature of each site. As most sites are not directly related to the binding with drugs, recognizing the small portion binding sites is critical for the accurate prediction of DPIs. Inspired by the work of <ref type="bibr" target="#b0">[Lin et al., 2017]</ref>, we adopt a multi-head sequential attention mechanism to fully use these features for classification. As shown in Figure <ref type="figure" target="#fig_1">2</ref>(b), the attention mechanism takes the P q as input, and outputs a vector of weights a p :</p><formula xml:id="formula_5">a p = sof tmax(w p2 tanh(W p1 P T q )) I ∑ i=1 (a p i ) = 1, ∀i, 1 ≤ i ≤ l (6)</formula><p>where W p1 ∈ R da×N f , and w p2 is a vector of parameters with size d p , the d p is an adjustable hyper-parameter. This vector representation usually focuses on a set of consecutive sites of protein sequence. Since a protein binding-pocket is composed of multiple consecutive sites neighbored in space, we further extend the w p2 into a r p -by-d p matrix, noted as W p2 , to capture the overall structural information of the binding-pocket. Thus, a p is converted to a multi-head attention weight A p ∈ R rp×l as,</p><formula xml:id="formula_6">A p = sof tmax(W p2 tanh(W p1 P T q ))<label>(7)</label></formula><p>Practically, Equation ( <ref type="formula" target="#formula_6">7</ref>) can be deemed as a 2-layer multilayer perceptron (MLP) without bias, whose hidden unit numbers is d a , and parameters are {W p1 , W p2 }. We compute the r p weighted sums by multiplying the annotation matrix A p and feature map P q :</p><formula xml:id="formula_7">P a = A p P q (8)</formula><p>where P a is an attentive feature map containing the latent relationship between contribution of sites on the interaction. The size of P a is r p -by-N f . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Self-attentive BiLSTM</head><p>Each drug molecular SMILES string is encoded to a twodimensional embedding matrix M ∈ R n×d . Token vectors in the molecular matrix M are independent to each other. To gain some dependency between adjacent tokens within a molecule, a bi-directional LSTM is used to process a molecule:</p><formula xml:id="formula_8">− → h i = −−−−→ LST M (t i , − − → h i−1 ) (9) ← − h i = ←−−−− LST M (t i , ← − − h i+1 ) (10) − → h i is concatenated with ← − h i</formula><p>, and a hidden state h i is obtained to replace token embedding t i , and thus h t becomes a more information-enriched vector that gains some dependency between adjacent tokens in a molecule. For simplicity, we note all h i in every time step i as H.</p><formula xml:id="formula_9">h i = ( − → h i , ← − h i ) (11) H = (h 0 , h i • • • h n ) (12)</formula><p>If the hidden unit number for each uni-directional LSTM is set as u, the shape of H would be n-by-2u.</p><p>The next goal is to know which part of the molecule contributed most to the interaction prediction. In other words, we want to identify the relationship between tokens and interaction, which can be used for a chemist to design or improve chemical compounds. Similarly, we achieve this by introducing multi-head self-attention mechanism. The attention mechanism takes the whole LSTM hidden states H as input, and outputs a vector of weights A m as</p><formula xml:id="formula_10">A m = sof tmax(M LP (H T )) (13)</formula><p>where hidden unit numbers of MLP is d m , and parameters are {W m1 , W m2 }. We compute the weighted sums by multiplying the annotation matrix A m and LSTM hidden states H, the resulting matrix is the self-attentive molecular embedding:</p><formula xml:id="formula_11">M a = A m H (14)</formula><p>where M a is a self-attentive drug molecular feature map that contains the latent relationship between tokens contribution of interaction. The size of M a is r m -by-2u, where r m is an adjustable hyper-parameter representing the number of attention vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Classifier</head><p>For P a and M a , we summed up over all the attention vectors, and then normalized the resulting weight vector to sum up to 1. This process enables us to obtain two information-enriched 1-D vectors P a and M a , which will be fed into the classification layer. We concatenate P a and M a , i.e., [ P a ; M a ], and obtain an output vector o ∈ R 2 , which is the input to DPI classifer:</p><formula xml:id="formula_12">o = W o [ P a ; M a ] + b o (15)</formula><p>where</p><formula xml:id="formula_13">W o ∈ R 2×(N f +2u</formula><p>) is the weight matrix and b o ∈ R 2 is the bias vector. Finally, a sigmoid function is appended on top of the output layer o = [y 0 , y 1 ] to model the DPI probability as follows:</p><formula xml:id="formula_14">p t = σ(o) = 1 1 + e −o (<label>16</label></formula><formula xml:id="formula_15">)</formula><p>where t ∈ {0, 1} denotes the binary label (i.e., interact or not) and p t is the probability of t, and we denote ŷ as the probability of t = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training</head><p>Given a dataset D = {(m i , p i , y i )}, the training objective is to minimize the loss function L, given as the cross-entropy loss as follows:</p><formula xml:id="formula_16">L(Θ) = − N ∑ i=1 y i log ŷ + (1 − y i )log(1 − ŷ) + λ 2 ∥Θ∥ 2 2 (17)</formula><p>where Θ is the set of all weight matrices and bias vectors in our system, and N is the total number of drug-protein pairs in the training dataset, and λ is an L2 regularization hyperparameter. Θ is trained using the backpropagation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments 4.1 Dataset</head><p>To enable head-to-head comparisons of DrugVQA to existing machine learning-based methods and docking programs, we evaluated our proposed model on three public DPI datasets: the DUD-E dataset, the Human dataset, and BindingDB dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DUD-E:</head><p>The DUD-E is a well-known benchmark consisting of 102 targets across 8 protein families <ref type="bibr" target="#b0">[Mysinger et al., 2012]</ref>. On average, each target has 224 actives and over 10,000 decoys. Computational decoys are chosen such that they are physically similar but topologically dissimilar to the actives. The finally dataset contains 22, 645 positive examples and 1, 407, 145 negative examples. We adopt a threefold cross-validation strategy to train and evaluate our model on the DUD-E dataset following <ref type="bibr" target="#b1">[Ragoza et al., 2017]</ref>. The folds were split between targets, where all ligands of the same target belong to the same fold. To avoid the impact of homologous proteins, targets belonging to the same protein families were strictly kept in the same fold. For a fast training of models, we used balanced set (all positives and randomly chosen equivalent negatives for each target) for training, but kept using the whole set (unbalanced ones) for evaluation.</p><p>Human. Created by <ref type="bibr" target="#b0">[Liu et al., 2015]</ref>, this dataset includes highly credible negative samples of compound-protein pairs obtained by using a systematic screening framework. Following <ref type="bibr" target="#b2">[Tsubaki et al., 2018]</ref>, we use a balanced dataset, where the ratio of positive and negative samples is 1:1. Finally, the human dataset contains 6, 675 interactions and 1, 998 unique proteins. We adopt the same five-fold cross validation strategy as in the original paper.</p><p>BindingDB. We further choose the BindingDB datasets <ref type="bibr" target="#b0">[Gilson et al., 2015]</ref> as the real-world dataset to evaluate our model. BindingDB is a public database of experimentally measured binding affinities, focusing chiefly on the interactions of small molecules and proteins. In our experiments, we use the customized BindingDB dataset constructed by <ref type="bibr" target="#b0">[Gao et al., 2018]</ref> for head-to-head comparisons. The dataset contains 39, 747 positive examples and 31, 218 negative examples from bindingDB. We report the results on their customized testing datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation and Evaluation Strategy</head><p>Proposed Model. We implemented the proposed model with Pytorch 0.4.0 <ref type="bibr">[Paszke et al., 2017]</ref>. The training process lasts at most 50 epochs on all the datasets using the Adam optimizer with a learning rate of 0.001 and batch size of 1. Considering the limitation of memory of the used GPU (GTX1080Ti 12GB), we employed 30 residual blocks with 16 and 32 filters (the N f 2 and N f 3 in Figure <ref type="figure" target="#fig_1">2</ref>), respectively. The hidden state of BiLSTM was set to 64 (the u in Sec 3.3), 0.2 dropout was applied on the BiLSTM and self-attention MLP unit. In addition, attention MLPs both in CNN and BiLSTM had a hidden layer with 100 units (the d p ), and we chose the matrix embedding to have 10 rows (the r p ) for protein and 18 rows (the r m ) for drug. The coefficient of L2 regularization was 0.001. We explored hyperparameters in a wide range and find the above set of hyperparameters yields the highest performance.</p><p>Evaluation Metrics. Performance were evaluated by the area under the receiver operating characteristic curve (AUC). In addition, for Human dataset, we report the Precision and Recall value following <ref type="bibr" target="#b2">[Tsubaki et al., 2018]</ref>. For DUD-E dataset, we report the ROC enrichment metric (RE) following the work of <ref type="bibr" target="#b1">[Ragoza et al., 2017]</ref>. Specifically, the RE score is defined as the ratio of the true positive rate (TPR) to the false positive rate (FPR) at a given FPR threshold. Here, we report the RE scores at 0.5%, 1%, 2%, and 5% FPR thresholds. For BindingDB dataset, we also report the accuracy following <ref type="bibr" target="#b0">[Gao et al., 2018]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparisons on the Human dataset</head><p>Compared Models. In this section, we compare our DrugVQA with the state-of-the-art DPI approaches on the Human dataset. We compare it with k-NN, random forest (R-F), L2-logistic (L2), SVM models (results obtained from <ref type="bibr" target="#b0">[Liu et al., 2015]</ref>), and <ref type="bibr">GNN [Tsubaki et al., 2018]</ref> (we retrained the model with the same parameter settings as in the original papers). To verify the effectiveness of our proposed model, we also include a version of our model by replacing protein distance map with protein sequence (DrugVQA(seq)). The protein sequences were processed as drug SMILES through self-attentive BiLSTM.</p><p>Results. As shown in Table <ref type="table" target="#tab_0">1</ref>, DrugVQA outperforms protein sequence-based model with an increase of 1.9%, 3.3%, and 4.4% on AUC, recall, and precision, respectively. This agrees with our expectation that the distance maps contain more information than sequences for the prediction of DPI. The DrugVQA (seq) is comparable to GNN method though GNN employed graphical neural network for coding chemical structure of drugs. Due to relatively simple structure of drugs, the GNN doesn't bring significant changes compared to our self-attentive BiLSTM. Other descriptor-based machine learning techniques have low performance with AUC ranging from 0.86 to 0.94, indicating that the end-to-end learned representations can learn important information from proteins and drugs for DPI prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparisons on the DUD-E dataset</head><p>Compared Models. We compare our DrugVQA with the state-of-the-art DPI approaches on DUD-E dataset, which can be divided into three categories: 1) conventional docking approaches Vina <ref type="bibr" target="#b2">[Trott and Olson, 2010]</ref>; Smina <ref type="bibr" target="#b0">[Koes et al., 2013]</ref>; 2) machine-learning scoring functions <ref type="bibr">NN-Score [Durrant and McCammon, 2011]</ref>; RF-Score <ref type="bibr" target="#b0">[Ballester and Mitchell, 2010]</ref>; 3) deep learning-based method 3D-CNN <ref type="bibr" target="#b1">[Ragoza et al., 2017]</ref>; <ref type="bibr">AtomNet [Wallach et al., 2015]</ref>; <ref type="bibr">GNN [Tsubaki et al., 2018]</ref>.</p><p>Results. As listed in Tab 2, DrugVQA achieved an orderof-magnitude improvement over baselines at a level of accuracy useful for drug discovery. On the full DUD-E dataset, DrugVQA outperforms the state-of-the-art GNN model with an average AUC of 0.971 versus 0.94. Though 3D-CNN have employed three-dimensional structure for training, it has the lowest performance among three deep learning methods. This is likely due to the sparse data in 3D space, whereas the 2D pairwise distance map provides a good balance. As a result, DrugVQA outperforms 3D-CNN for 96% of the DUD-E targets on a per-target basis.  <ref type="bibr">et al., 2018]</ref> using GCN and LSTM to process drug molecules and protein highlevel information (Gene Ontology annotations) respectively; 4) <ref type="bibr">GNN [Tsubaki et al., 2018]</ref>.</p><p>Results. The experimental results on BindingDB dataset are demonstrated in Figure <ref type="figure" target="#fig_2">3</ref>. Our approach consistently performs well across the test sets and all metrics. Three baselines (Tiresias, DBN, and GNN) perform well on seen proteins, but have much worse performance on unseen proteins. This indicates there exists to be over-fitting over proteins used for training. On the other hand, E2E give a consistent performance for seen and unseen proteins, but it is consistently lower than DrugVQA by 2.6% and 2.3% for AUC and accuracy in average. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Case study</head><p>Another advantage of our model is its interpretability. To exemplify this, we selected two top predicted interactions in DUD-E dataset: protein Hsp90 (PDB: 3EKR) and CDK2 (PDB: 2DUV) with their corresponding actives. As shown in Fig <ref type="figure" target="#fig_3">4</ref>, the green highlighted the sites with high attentions in the binding pocket, and the red cloud indicates drug atoms with attentions. Darker colors indicate higher attention coefficients. In both cases, molecular components with weights higher than 0.6 overlap substantially with the interaction sites between a molecule and a protein. In the meanwhile, for Hsp90 (left), the pocket importance map highlights residues Asn51A, Asp93A, Met98A, which highly overlap with the key pocket residues observed in the co-crystal complex (PDB: 2DUV). For CDK2 (right), the highlighted key residues (Phe80A, Asp145A) and ligand functional groups in the importance maps show high similarity to observed interactions in the 3EKR. This result suggests that our model can provide reasonable cues for drug-protein binding mode, which is helpful for finding promiscuous domains and designing the active improved drug compounds. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this article, we have presented a novel end-to-end deep learning framework like Visual Question Answering (VQA) task to predict drug-protein interactions. It is the first time to employ self-attentive convolutional and recurrent structures for extracting features simultaneously from protein 2D distance map and molecular language in DPI study. Experimental evaluations demonstrate that our model consistently shows the best performances on three public datasets. Furthermore, the model is shown to be able to provide biological insights for understanding the nature of molecular interactions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The framework of our proposed DrugVQA model. It consists of two main components, dynamic CNN with sequential attention and BiLSTM with multi-head self-attention.</figDesc><graphic url="image-1.png" coords="3,54.00,53.87,510.37,157.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Dynamic attentive CNN. It includes two key components: (a) stacked residual blocks and (b) attention block.</figDesc><graphic url="image-2.png" coords="4,62.11,101.16,227.11,271.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance comparisons of our proposed method and baselines on seen and unseen protein targets from the BindingDB.</figDesc><graphic url="image-3.png" coords="6,55.03,492.33,241.13,126.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Importance visualization of pocket and ligand pairs (PDB ID:3EKR, 2DUV). The green highlighted the sites with high attentions in the binding pocket, and the red cloud indicates drug atoms with attentions. Darker colors indicate higher attention coefficients.</figDesc><graphic url="image-4.png" coords="6,314.99,265.65,255.40,170.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison results of proposed models and baselines on Human Dataset.</figDesc><table><row><cell></cell><cell cols="2">AUC Recall Precision</cell></row><row><cell>k-NN</cell><cell>0.860 0.927</cell><cell>0.798</cell></row><row><cell>RF</cell><cell>0.940 0.897</cell><cell>0.861</cell></row><row><cell>L2</cell><cell>0.911 0.913</cell><cell>0.861</cell></row><row><cell>SVM</cell><cell>0.910 0.950</cell><cell>0.966</cell></row><row><cell>GNN</cell><cell>0.970 0.918</cell><cell>0.923</cell></row><row><cell>DrugVQA(seq)</cell><cell>0.968 0.930</cell><cell>0.911</cell></row><row><cell>DrugVQA</cell><cell>0.987 0.963</cell><cell>0.955</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Mean AUC and ROC Enrichment (RE) across targets on the DUD-E Dataset for proposed models and baselines.</figDesc><table><row><cell>Model</cell><cell cols="4">AUC 0.5% RE 1.0% RE 2.0% RE 5.0% RE</cell></row><row><cell>Vina</cell><cell>0.716 9.139</cell><cell>7.321</cell><cell>5.811</cell><cell>4.444</cell></row><row><cell>Smina</cell><cell>0.696 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">NN-score 0.584 4.166</cell><cell>2.980</cell><cell>2.460</cell><cell>1.891</cell></row><row><cell>RF-score</cell><cell>0.622 5.628</cell><cell>4.274</cell><cell>3.499</cell><cell>2.678</cell></row><row><cell>3D-CNN</cell><cell>0.868 42.559</cell><cell>26.655</cell><cell>19.363</cell><cell>10.710</cell></row><row><cell>AtomNet</cell><cell>0.895 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>GNN</cell><cell>0.940 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">DrugVQA 0.971 87.766</cell><cell>58.511</cell><cell>34.479</cell><cell>17.383</cell></row></table><note>4.5 Comparisons on the BindingDB datasetCompared Models. We further assess our model on the BindingDB dataset. We compare our model with four baselines: 1) Similarity-based method Tiresias<ref type="bibr" target="#b0">[Fokoue et al., 2016]</ref>; 2)DBN [Wen et al., 2017], a deep learning method using middle-level features from predefined molecular fingerprints and protein descriptors; 3) E2E [Gao</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://deepmind.com/blog/alphafold/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has funded in part of the national science &amp; technology major project of the ministry of science and technology of China (2018ZX09735010), and Natural Science Foundation of China (U1611261 and 61772566).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking</title>
		<author>
			<persName><forename type="first">Mitchell</forename><forename type="middle">;</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">J</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John Bo Mitchell ;</forename><surname>Bleakley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yamanishi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Bleakley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshihiro</forename><surname>Yamanishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Clevert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07289</idno>
		<idno>arXiv:1703.03130</idno>
	</analytic>
	<monogr>
		<title level="m">Hui Liu, Jianjiang Sun, Jihong Guan, Jie Zheng, and Shuigeng Zhou</title>
				<editor>
			<persName><forename type="first">Marcus</forename><surname>Olivecrona</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Blaschke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ola</forename><surname>Engkvist</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hongming</forename><surname>Chen</surname></persName>
		</editor>
		<meeting><address><addrLine>Sam Gross</addrLine></address></meeting>
		<imprint>
			<publisher>Arzucan Özgür, and Elif Ozkirimli</publisher>
			<date type="published" when="2009">2010. 2010. 2009. 2009. 2015. 2015. 2011. 2011. 2016. 2016. 2018. 2018. 2015. 2015. 2016. 2016. 2013. 2013. 2017. 2017. 2015. 2015. 2012. 2012. 2017. 2017. 2018. 2018. 2017</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="821" to="829" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>NIPS-W</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Protein-ligand scoring with convolutional neural networks</title>
		<author>
			<persName><surname>Ragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="942" to="957" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Tabei and Yamanishi, 2013] Yasuo Tabei and Yoshihiro Yamanishi. Scalable prediction of compound-protein interactions using minwise hashing</title>
		<author>
			<persName><surname>Skolnick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.02855</idno>
	</analytic>
	<monogr>
		<title level="m">Izhar Wallach, Michael Dzamba, and Abraham Heifets. Atomnet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery</title>
				<imprint>
			<date type="published" when="1997">1997. 1997. 2018. 2018. 2013. 2010. 2010. 2018. 2018. 2015. 2017. 2017</date>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="1401" to="1409" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Journal of proteome research</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying structure-property relationships through smiles syntax analysis with self-attention mechanism</title>
		<author>
			<persName><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
