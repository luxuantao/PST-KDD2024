<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Large yet Imperceptible Adversarial Image Perturbations with Perceptual Color Distance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-03-31">31 Mar 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhengyu</forename><surname>Zhao</surname></persName>
							<email>z.zhao@cs.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhuoran</forename><surname>Liu</surname></persName>
							<email>z.liu@cs.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martha</forename><surname>Larson</surname></persName>
							<email>m.larson@cs.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Large yet Imperceptible Adversarial Image Perturbations with Perceptual Color Distance</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-03-31">31 Mar 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1911.02466v2[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The success of image perturbations that are designed to fool image classifier is assessed in terms of both adversarial effect and visual imperceptibility. The conventional assumption on imperceptibility is that perturbations should strive for tight L p -norm bounds in RGB space. In this work, we drop this assumption by pursuing an approach that exploits human color perception, and more specifically, minimizing perturbation size with respect to perceptual color distance. Our first approach, Perceptual Color distance C&amp;W (PerC-C&amp;W), extends the widely-used C&amp;W approach and produces larger RGB perturbations. PerC-C&amp;W is able to maintain adversarial strength, while contributing to imperceptibility. Our second approach, Perceptual Color distance Alternating Loss (PerC-AL), achieves the same outcome, but does so more efficiently by alternating between the classification loss and perceptual color difference when updating perturbations. Experimental evaluation shows PerC approaches outperform conventional L p approaches in terms of robustness and transferability, and also demonstrates that the PerC distance can provide added value on top of existing structure-based methods to creating image perturbations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Research on creating adversarial examples for deep visual classifiers has focused on perturbations that cause misclassification while being imperceptible to the human eye <ref type="bibr" target="#b6">[7,</ref><ref type="bibr">43,</ref><ref type="bibr" target="#b48">49]</ref>. Larger image perturbations are known to improve adversarial strength (i.e., the ability to fool a classifier), but are also associated with visually noticeable changes in the image. A commonly agreed-upon assumption is that tight L p -norm constraints on the size of adversarial perturbations in RGB space are a good guarantee of imperceptibility. Evaluation of adversarial examples has conventionally followed this assumption, considering perturbations with smaller L p norms to be better (e.g., Figure <ref type="figure">1</ref>: Comparison of (a) C&amp;W <ref type="bibr" target="#b6">[7]</ref> with (b) our PerC-C&amp;W. Perceptual color (PerC) distance allows larger RGB perturbations (cf. L 2 and L ∞ norm in middle row), while also contributing to imperceptibility (bottom row). (Setting: untargeted with κ = 40; classifier Inception v3.)</p><p>L ∞ <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29]</ref>, L 2 <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b48">49]</ref> and L 0 <ref type="bibr" target="#b6">[7,</ref><ref type="bibr">43]</ref>). Keeping with this assumption, defense approaches are designed to be effective against adversarial perturbations under a specific L p bound <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b53">54]</ref>. Our research is motivated by the importance of questioning the necessity of small RGB perturbations for imperceptibility.</p><p>In this work, we propose to create adversarial examples by perturbing images with respect to perceptual color (PerC) distance. Using PerC distance makes it possible to move away from the assumption that it is necessary to tightly constrain the L p norm of the perturbations in RGB space. Fig. <ref type="figure">1</ref> illustrates the difference between C&amp;W <ref type="bibr" target="#b6">[7]</ref>, a well-known approach that perturbs with respect to an L p norm in RGB space, and our own extension, PerC-C&amp;W, which perturbs with respect to a perceptual color dis-tance. PerC perturbations are less perceptible, especially in smooth regions of saturated color (cf. Fig. <ref type="figure">1</ref> in bottom row). Also, they are distributed strategically over the RGB color channels (cf. downsized perturbation images in the middle row). PerC distance effectively allows us to hide large perturbations in RGB space, in a way not readily noticeable to the human eye. Our PerC-based approaches can increase the L p norm substantially (cf. Fig. <ref type="figure">1</ref>, L 2 and L ∞ in middle row), leading to a strong adversarial effect that maintains imperceptibility.</p><p>Fig. <ref type="figure" target="#fig_0">2</ref> motivates the use of perceptual color distance for creating adversarial images. Here, we have taken a solid color image (left) and added the same perturbations to the green channel (middle) and to the blue channel (right). Although both RGB channels were perturbed identically, the perturbations are only visible in the green channel. The reason is that color as it is perceived by the human eye does not change uniformly over distance in RGB space. Relatively small perturbations in RGB space may correspond to large difference in perceptual color space. Conversely, relatively large changes in RGB space may remain unnoticeable if they lead to small perceived color difference.</p><p>Our work is in line with a growing awareness in the literature on adversarial examples that the difference between two images as measured by an L p norm in RGB space is actually quite poorly aligned with human perception <ref type="bibr" target="#b44">[45]</ref>. Building on this observation, researchers have attempted to address imperceptibility by exploiting similarity defined with respect to semantics <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b45">46]</ref> or structural information <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b58">59</ref>] in the image. However, little work on adversarial examples has questioned the wisdom of optimizing perturbations with respect to distance in RGB space. The exceptions are a handful of approaches that have proposed allowing only luminance change when perturbing pixels <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref>. The approach that is closest to our own is [3], which perturbs in CIELAB color space, but carries out no investigation of the potential and limitations of the idea. Our work is distinct from this initial effort because we use a more accurate polar form (known as CIELCH) of the CIELAB color space, and more importantly, use an actual perceptual color distance. The distance is CIEDE2000 <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38]</ref>, and will be discussed in detail in Section 2. To our knowledge, ours is the first work that proposes optimizing adversarial image perturbations directly with respect to a perceptual color distance.</p><p>In order to fully appreciate our proposal, it is necessary to understand two key aspects. First, we do not claim that PerC approaches will always yield dramatically less perceptible perturbations than conventional RGB approaches. For cases in which the perturbations are small, the difference may not be so great. However, we find that there are two cases in which PerC approaches are particularly important. First, our experimental results (see Section 5.2.2) show that as we attempt to create adversarial images that are misclassified with high confidence (i.e., high-confidence adversarial examples), it becomes important to perturb with respect to perceptual color distance. Second, we demonstrate that the effect of PerC approaches is additive and can be used in combination with existing structural approaches to improve imperceptibility.</p><p>The contributions of this paper are as follows:</p><p>• An in-depth study of the use of perceptual color (PerC) distance to hide large RGB perturbations in images. • PerC-C&amp;W: a method for creating adversarial images that introduces perceptual color distance into the joint optimization of C&amp;W. • PerC-AL: an efficient method that optimizes alternating loss (AL) functions, switching between classification loss and perceptual color difference. • Experimental validation demonstrating that PerC perturbations in high-confidence settings yield more robust and transferable adversarial examples, without sacrificing imperceptibility. • Experimental results showing that PerC perturbations can be used in combination with structural information for further improvement of imperceptibility. The code, which also includes a differentiable solution compatible with PyTorch's autograd to efficiently implement perceptual color distance (CIEDE2000), is available at https://github.com/ZhengyuZhao/PerC-Adversarial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background on Perceptual Color Distance</head><p>Conventionally, computer vision research has intensively explored color and human perception, but has paid surprisingly little attention to distance in perceptual color spaces. Here, we mention some key points about color in computer vision history. Early on, research focused on intensitybased descriptors, which then evolved to also capture color information. Unsurprisingly, color boosted the performance of object and scene recognition <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b51">52]</ref> and semantic segmentation <ref type="bibr" target="#b7">[8]</ref>. Researchers extracted descriptors from opponent color spaces, most notably HSV and CIELAB, which separate luminance and chrominance. Most recently, color is attracting more attention in the area of image synthesis. Notable examples, such as style transfer <ref type="bibr" target="#b17">[18]</ref> and cross-domain image generation <ref type="bibr" target="#b49">[50]</ref>, find that color plays an important role in preserving the look of an image. In general, we observe that until now the focus has been on the color space itself, and not on color distance, which we explore here.</p><p>The perceptual color distance that we use is CIEDE2000, which is the latest ∆E standard formula developed by the CIE (International Commission on Illumination). CIEDE2000 refined the definition of previous editions by adding five corrections, and has been experimentally demonstrated to better align with human visual perception <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38]</ref>. Specifically, the pixel-wise perceptual color distance can be calculated as:</p><formula xml:id="formula_0">∆E 00 = ( ∆L ′ k L S L ) 2 + ( ∆C ′ k C S C ) 2 + ( ∆H ′ k H S H ) 2 + ∆R, ∆R = R T ( ∆C ′ k C S C )( ∆H ′ k H S H ),<label>(1)</label></formula><p>where ∆L ′ , ∆C ′ , ∆H ′ denotes the distance between pixel values of the three channels, L (lightness), C (chroma) and H (hue) in the CIELCH space, and ∆R is an interactive term between chroma and hue differences <ref type="bibr" target="#b37">[38]</ref>. The weighting functions S L , S C , S H and R T are determined based on large-scale human studies and act as compensations to better simulate human color perception. The k L , k C and k H are usually unity for the application of graphic arts. Detailed definitions of all the parameters and relevant explanations can be found in <ref type="bibr" target="#b37">[38]</ref>. We note that it is also possible to use an L p norm to measure distance in CIELAB space. However, this distance is not as close to human perceptual distance as CIEDE2000 is.</p><p>We point out that a limited amount of previous research has also adopted CIEDE2000. However, the goal has been to evaluate the color similarity of image pairs. Examples of such research include work on image quality assessment <ref type="bibr" target="#b57">[58]</ref> and image super-resolution <ref type="bibr" target="#b33">[34]</ref>. In contrast, in our work we use CIEDE2000 directly for optimization with back propagation and not only for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head><p>In this section, we cover the existing literature, which focuses on creating L p norm-bounded adversarial examples, and we also mention recent approaches that attempt to move beyond L p norms. We preface our discussion with a short definition of an 'adversary', i.e., an approach that generates an adversarial image example. Given a classifier f (x) : x → y that predicts a label y for an image x, the adversary attempts to induce a misclassification by modifying the original x to create a new x ′ . In the untargeted setting, the adversary is successful if the image is classified into an arbitrary class other than y, i.e., meets the condition f (x ′ ) = y. In the targeted setting, the adversary must ensure that the image is classified into a class with a predefined label t, i.e., meets the condition f (x ′ ) = t. The untargeted case is generally recognized to be less challenging than the targeted case <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">L p norm-bounded Adversarial Examples</head><p>Typically, adversaries <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b48">49]</ref> create an adversarial image, x ′ , by adding a perturbation vector δ ∈ R n that is constrained by an L p norm to the original image, x. The first L p norm-bounded approach <ref type="bibr" target="#b48">[49]</ref> optimized an objective combining the classification loss and the L 2 norm of the perturbations, balanced by a constant λ. Formally, the solution is expressed as:</p><formula xml:id="formula_1">minimize δ λ δ 2 − J(x ′ , y), s.t. x ′ ∈ [0, 1] n , (2)</formula><p>where J(x ′ , y) is the cross-entropy loss w.r.t. x ′ . The authors of <ref type="bibr" target="#b48">[49]</ref> solved the problem by using box-constrained L-BFGS (Limited memory Broyden-Fletcher-Goldfarb-Shanno) method <ref type="bibr" target="#b32">[33]</ref>.</p><p>The C&amp;W method <ref type="bibr" target="#b6">[7]</ref> improves on <ref type="bibr" target="#b48">[49]</ref> by introducing a new variable using the tanh function to eliminate the box constraint. Additionally, it introduces a more sophisticated objective function that optimizes differences between the logits, Z, which are output before the softmax layer. This can be formulated as:</p><formula xml:id="formula_2">minimize w x ′ − x 2 2 + λf (x ′ ), where f (x ′ ) = max(max{Z(x ′ ) i : i = t} − Z(x ′ ) t , −κ), and x ′ = 1 2 (tanh(arctanh(x) + w) + 1),</formula><p>(3) where w is the new variable and Z(x ′ ) i denotes the logit with respect to the i-th class. In an untargeted setting, the definition of f is modified to:</p><formula xml:id="formula_3">f (x ′ ) = max(Z(x ′ ) y − max{Z(x ′ ) i : i = y}, −κ). (4)</formula><p>The parameter κ controls the confidence level of the misclassification. The first approach that we propose, PerC-C&amp;W, is built on C&amp;W. In our experiments, we will vary κ in order to assess the ability of an adversary to create strong adversarial images, i.e., images that are misclassified with high confidence.</p><p>Due to the need for line search in order to find the optimal constant, λ, such an optimization approach is inevitably time-consuming. For this reason, <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b43">44]</ref> propose a more efficient solution that does not impose a penalty during optimization. Instead, respect of the norm constraint is ensured by projecting perturbations onto an ǫ-sphere around the original image. Specifically, the fast gradient sign method (FGSM) <ref type="bibr" target="#b18">[19]</ref> was first proposed to achieve adversarial effect with only one step, formulated as:</p><formula xml:id="formula_4">x ′ = x + ǫ • sign(∇ x J(x, y)),<label>(5)</label></formula><p>where the perturbation size is implicitly constrained by specifying a small ǫ.</p><p>Subsequently, an extension of this method referred to as I-FGSM <ref type="bibr" target="#b28">[29]</ref> was introduced for leveraging finer gradient information by iteratively updating the perturbations with a smaller step size α:</p><formula xml:id="formula_5">x ′ 0 = x, x ′ k = x ′ k−1 + α • sign(∇ x J(x ′ k−1 , y)),<label>(6)</label></formula><p>where the intermediate perturbed image x ′ k is projected onto a ǫ-sphere around the original x, to satisfy the L ∞norm constraint. Note that I-FGSM constrains only the maximum change of individual image coordinates without considering the image-level accumulated difference. For this reason, I-FGSM yields poor imperceptibility, especially in high-confidence settings (cf. Fig. <ref type="figure" target="#fig_1">3</ref>).</p><p>A generalization of I-FGSM to the L 2 norm can be achieved by changing the sign operation in the updating to:</p><formula xml:id="formula_6">∇ x J(x ′ k−1 , y) ∇ x J(x ′ k−1 , y) 2 , (<label>7</label></formula><formula xml:id="formula_7">)</formula><p>where the projection is implemented by:</p><formula xml:id="formula_8">x ′ k = x + ǫ x ′ k − x x ′ k − x 2 . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>A recent method called the Decoupled Direction and Norm (DDN) <ref type="bibr" target="#b43">[44]</ref>, which is based on the L 2 norm-based I-FGSM, yielded the best performance (smallest L 2 norm) in the untargeted track of NIPS 2018 Adversarial Vision Challenge <ref type="bibr" target="#b4">[5]</ref>, with substantially fewer iterations than the conventional C&amp;W. In DNN, the ǫ is designed to be adjustable in each iteration based on whether the perturbed image is adversarial or not, leading to a finer search for the minimal norm. Our second approach, PerC-AL, follows a similar strategy as DDN to improve efficiency by decoupling the joint optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Adversarial examples beyond L p norms</head><p>Our work is part of the current movement away from tight L p norms and towards conceptualization of image similarity in terms of semantics or perceptual properties. Research that defines similarity in terms of semantics, requires the adversarial image to have the same content as the original image from the point of view of the human viewer. Some of the first work in this direction has explored geometric transformation <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b55">56]</ref>, global color shift <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b30">31]</ref>, and image filters <ref type="bibr" target="#b8">[9]</ref>.</p><p>Such approaches are interesting, but we do not pursue them here because they tend to be limited in their adversarial strength, due to the restricted size of the search space for possible adversarial image transformations.</p><p>Research that investigates similarity with respect to texture and structure <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b58">59]</ref>, has focused on hiding perturbations in image regions with visual variation. Such hiding can be achieved by either using existing structure-aware metrics <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b54">55]</ref>, such as structural similarity (SSIM) <ref type="bibr" target="#b52">[53]</ref> and Wasserstein distance <ref type="bibr" target="#b24">[25]</ref>, or directly allowing more perturbations in the high-variance image regions <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b58">59</ref>]. All of these approaches share a common challenge: They have difficulties in dealing with smooth regions (e.g., sky, ground and artificial objects), which appear frequently in images taken in commonly occurring real-world settings (referred to as natural images). In contrast, our PerC perturbations are applicable in smooth regions in the case of saturated color. Our experiments show that PerC perturbations can be combined productively with a structure-based approach (see Section 5.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed approaches</head><p>In this section, we present two approaches to using perceptual color (PerC) distance for adversarial image perturbations. We focus on image-level accumulated perceptual color difference, i.e., the L 2 norm of the color distance vector, in which each component represents the perceptual color distance (∆E 00 in Eq. ( <ref type="formula" target="#formula_0">1</ref>)) calculated for the corresponding image pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Perceptual color distance penalty (PerC-C&amp;W)</head><p>Our first approach, PerC-C&amp;W, adopts the joint optimization of the well-known C&amp;W, but replaces the original penalty on the L 2 norm with a new one based on perceptual color difference. It can be formally expressed as:</p><formula xml:id="formula_10">minimize w ∆E 00 (x, x ′ ) 2 + λf (x ′ ), (<label>9</label></formula><formula xml:id="formula_11">)</formula><p>where w is the new introduced variable as in the Eq. (3) of C&amp;W. Like the original C&amp;W, the optimization problem is solved by binary search over the constant λ. By using the gradient information from perceptual color difference, perturbation updating is translated into a perceptually uniform color space. Large RGB perturbations, which have a strong adversarial effect, remain hidden from the human eye, as will be shown in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Perceptual color distance alternating loss (PerC-AL)</head><p>Although, Eq. 9 enjoys a concise expression, the joint optimization of PerC-C&amp;W faces difficulties in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Perceptual Color Distance Alternating Loss (PerC-AL) Input:</head><p>x: original image, t: target label, K: number of iterations α l : step size in minimizing classification loss α c : step size in minimizing perceptual color difference Output: x ′ : adversarial image</p><formula xml:id="formula_12">1: Initialize x ′ 0 ← x, δ 0 ← 0 2: for k ← 1 to K do 3: if x ′ k−1 is not adversarial then 4: g ← −∇ x J(x ′ k−1 , t) 5: g ← α l • g g 2 6: δ k ← δ k−1 + g ⊲ Update δ in the direc- tion of g 7:</formula><p>else 8:</p><formula xml:id="formula_13">C 2 ← − ∆E 00 (x, x ′ k−1 ) 2 9: g c ← ∇ x C 2 10: g c ← α c • g c g c 2 11: δ k ← δ k−1 + g c ⊲ Update δ in the di- rection of g c 12:</formula><p>end if 13:</p><p>x</p><formula xml:id="formula_14">′ k ← clip(x + δ k , 0<label>, 1) 14:</label></formula><p>x</p><formula xml:id="formula_15">′ k ← quantize(x ′ k ) ⊲ Ensure x ′ k is valid 15: end for 16: return x ′ ← x ′</formula><p>k that is adversarial and has smallest C 2</p><p>Adversarial training <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b38">39]</ref>, for example, presents challenges. The reason is that PerC-C&amp;W requires timeconsuming binary search in order to find an optimal λ, which normally varies substantially among different images <ref type="bibr" target="#b43">[44]</ref>. To address the inefficiency, we propose PerC-AL, which decouples the joint optimization by alternately updating the perturbations with respect to either classification loss or perceptual color difference. Our strategy is inspired by DDN, which is basically a projected gradient descent (PGD) method with a dynamic L 2 -norm bound. However, PerC-AL goes beyond this idea to alternate two gradient descents.</p><p>The full PerC-AL method is described in Algorithm 1. We start from an original image x with the perturbation δ initialized as 0, and iteratively update it to create an adversarial image. In each iteration, the perturbation is either enlarged to achieve stronger adversarial effect based on the gradients from the classification loss, or shrunk to minimize perceptual color differences. These two operations are alternated based on whether the intermediate perturbed image x ′ k is adversarial or not, leading to a finer search of a minimal perceptual color difference by repeatedly crossing the decision boundary. To ensure the adversarial image is valid, the output is clipped into the range [0,1] and quantized into 255 levels (corresponding to 8-bit image encoding).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we first provide a picture of the differences between RGB and PerC approaches (Section 5.2). Then, we carry out experiments that compare different approaches in terms of robustness (Section 5.3) and transferability (Section 5.4) by considering the case of highconfidence adversarial examples. Finally, in Section 5.5, we show that structural information can be elegantly integrated into our efficient decoupled approach, PerC-AL, for further improvement in the imperceptibility of images that contain areas with rich visual variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental setup</head><p>Dataset and Networks. Following recent work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b58">59]</ref>, we conduct our experiments on the development set (1000 RGB natural images with the size of 299 × 299) of the ImageNet-Compatible dataset <ref type="foot" target="#foot_0">1</ref> . This dataset was introduced by the NIPS 2017 Competition on Adversarial Attacks and Defenses <ref type="bibr" target="#b29">[30]</ref> and consists of 6000 images labeled with 1000 ImageNet classes. We choose this dataset because we would like to study imperceptibility under realworld conditions. In contrast, some other work <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b36">37]</ref> on addressing imperceptibility mainly focuses on the tiny images from MNIST <ref type="bibr" target="#b31">[32]</ref> and CIFAR-10 <ref type="bibr" target="#b27">[28]</ref>. As in the competition, the Inception V3 <ref type="bibr" target="#b47">[48]</ref> model pre-trained on Image-Net is used as the target classifier. Baselines. Three well-known baselines, I-FGSM <ref type="bibr" target="#b28">[29]</ref>, C&amp;W <ref type="bibr" target="#b6">[7]</ref>, and the state-of-the-art DDN <ref type="bibr" target="#b43">[44]</ref>, are compared with our approaches. Among them, I-FGSM targets minimum L ∞ norm, while C&amp;W and DDN target minimum L 2 norm. Note that I-FGSM is not designed for imperceptibility, but we consider it here for completeness. Parameters. I-FGSM is repeated multiple rounds with increased L ∞ -norm bound, where in each round, a large enough iteration budget (100 in our implementation) is specified with the step size α = 1/255.</p><p>C&amp;W and PerC-C&amp;W use the Adam optimizer <ref type="bibr" target="#b26">[27]</ref> with a learning rate of 0.01 for updating the perturbations. We impose a budget on the number of search steps used to find the optimal λ. The initialization of λ is particularly important for small budgets. We perform grid search for the initialization value of λ over the range [0.01, 0.1, 1, 10, 100], and adopt the value that yields the smallest average perturbation size. The selected initialization values are shown in Table <ref type="table">4</ref> of the appendix.</p><p>For DDN and PerC-AL, we decrease the step size (α in DDN and α l in PerC-AL) that is used for updating the perturbations with respect to the classification loss from 1 to 0.01 with cosine annealing. The L 2 -norm constraint ǫ in DDN is initialized to 1 and adjusted iteratively by γ = 0.05, iterations to find the optimal initialization of λ. The budget for I-FGSM varies on different images.</p><p>as in the original work DDN <ref type="bibr" target="#b43">[44]</ref>. The α c in PerC-AL is gradually reduced from 0.5 to 0.05 with cosine annealing.</p><p>Evaluation Protocol. We investigate a set of reasonable operating points, based on pre-defined budgets. Note that our goal is to show the relative behavior of PerC vs. RGB approaches. For this purpose, we only need to create a fair comparison, and it is not necessary to drive all approaches to an absolute optimum. For each image, an approach is considered successful if the perturbed image can achieve adversarial effect with the given budget. Specifically, I-FGSM requires varied repetitions for different images. For C&amp;W and PerC-C&amp;W, the budget refers to N(search steps) × N(iterations of gradient descent). We apply relatively high budget (9 × 1000), and are also interested in lower budgets (5 × 200 and 3 × 100), which are more directly comparable with more efficient approaches, namely, DDN and PerC-AL. We test DDN and our PerC-AL with three different iteration budgets (100, 300 and 1000), adopted from the original work <ref type="bibr" target="#b43">[44]</ref>.</p><p>Adversarial strength is evaluated by the success rate, i.e., the proportion of successful cases over the whole dataset. The averaged perturbation size over all successful images is reported. It is measured in terms of the L 2 and L ∞ norm in RGB space (L 2 and L ∞ ) and also in terms of image-level accumulated perceptual color difference (C 2 ). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Adversarial strength and imperceptibility</head><p>In this section, we investigate the adversarial strength and imperceptibility of the perturbed images generated by different approaches in a white-box scenario, where the full information of the network is accessible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Sufficient-confidence adversarial examples</head><p>We first present, in Table <ref type="table" target="#tab_0">1</ref>, a comparison demonstrating how PerC approaches relax L p norms. Our comparison uses adversarial examples created under a commonly used condition where the aim is to achieve a just sufficient adversarial effect. Sufficient-confidence adversarial examples just cross the decision boundary without pursuing a higher confidence score for the adversarial label. As expected, all approaches achieve 100% success rate and the resulting perturbation size gets smaller as the budget increases.</p><p>Table <ref type="table" target="#tab_0">1</ref>, which reports the targeted results, confirms that PerC approaches, PerC-C&amp;W and PerC-AL, show the behavior they are designed for, i.e., decreasing the average accumulated perceptual color difference C 2 . More importantly, PerC approaches do this without tightly constraining the L p norms in RGB space as the other approaches do, as reflected by L 2 and L ∞ . Moreover, PerC-AL achieves lower C 2 than PerC-C&amp;W (57.10 vs. 67.79) with notably fewer iterations. For comparison, we provide C 2 for the RGB approaches. The untargeted results follow a similar pattern and can be found in Table <ref type="table">5</ref> of the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">High-confidence adversarial examples</head><p>In order to gain deeper insight into the performance of our approaches, we investigate adversarial examples that have a high confidence score for the adversarial label. High confidence was initially investigated by <ref type="bibr" target="#b6">[7]</ref> in order to achieve more transferable adversarial examples, and also been explored in the "Unrestricted Adversarial Examples" contest <ref type="bibr" target="#b5">[6]</ref>. In the untargeted setting, an approach is regarded as successful only if the logit with respect to the original class becomes lower than the maximum of the other logits by a pre-defined margin κ. For C&amp;W and PerC-C&amp;W, this requirement can be directly implemented by specifying the factor κ in Eq. ( <ref type="formula">4</ref>). For I-FGSM, DDN and PerC-AL, this can be achieved by running the iterations until the required logit difference is satisfied. For this experiment, we adopt the settings generating the smallest perturbations for each approach in Section 5.2.1.</p><p>Fig. <ref type="figure" target="#fig_1">3</ref> shows some adversarial examples generated by different approaches at κ = 40. The images produced by our PerC approaches look more visually acceptable than those of the other approaches (best viewed on screen). The good visual appearance of the PerC examples is consistent with their low averaged aggregated perceptual color difference, C 2 , as seen in Table <ref type="table" target="#tab_1">2</ref>, which shows both κ = 40 and κ = 20 values. The challenge of the high-confidence setting is seen in the success rates, which are not longer perfect for all conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Robustness</head><p>In order to gain additional practical insight, we test the robustness of the adversarial examples against two commonly studied image transformation-based defense methods, i.e., JPEG compression <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20]</ref> and bit-depth reduction <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>The results are shown in Fig. <ref type="figure" target="#fig_2">4</ref>. Overall, increasing κ from 20 to 40 leads to improved robustness. For a specific unsurprisingly, I-FGSM outperforms other approaches since it greedily perturbs all the pixels, but at the cost of worse image quality (see Fig. <ref type="figure" target="#fig_1">3</ref>). Among the other four approaches that target minimal image-level accumulated image difference with sparse perturbations, the best results are consistently achieved by either our PerC-C&amp;W or PerC-AL. Specifically, PerC-C&amp;W outperforms the original C&amp;W in all cases, while PerC-AL consistently outperforms DDN. Recall that our PerC approaches cause fewer visual distortions, as shown in Fig. <ref type="figure" target="#fig_1">3</ref>, contributing to imperceptibility. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Transferability</head><p>Existing research <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b50">51]</ref> has demonstrated that the adversarial effect of images optimized with respect to a specific network may transfer to another We test the transferability of different approaches from the original Inception V3 to other three pre-trained networks, namely, GoogLeNet <ref type="bibr" target="#b47">[48]</ref>, ResNet-152 <ref type="bibr" target="#b20">[21]</ref>, and VGG-16 <ref type="bibr" target="#b46">[47]</ref>. Specifically, an untargeted adversarial example generated for the original model is regarded to be transferable to a new model if it can also induce misclassification of that model.</p><p>We report results on a subset of our data containing im-   ages that all four models originally classify correctly. Table 3 reports the success rates under transferability on these images (767 in total). I-FGSM again outperforms the other approaches, but uses excessive perturbations (and for this reason is shown in italics). Among the other approaches, we can observe that the best results are always achieved by one of our two PerC approaches<ref type="foot" target="#foot_1">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Assembling structural information</head><p>We explore the possibility of assembling structural information for further improving imperceptibility without impacting adversarial strength. Specifically, we introduce a texture complexity vector σ, which has the same size as the image, as a weighting term into our PerC-AL framework. Following existing work <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b36">37]</ref> on addressing imperceptibility with respect to image structure, this vector is obtained by calculating the standard deviation of the pixel values in each 3 × 3 square per channel. The components with top 5% highest values in the map are clipped for stability and the map is normalized into the range [0,1] before use. Concretely, step 8 in Algorithm 1 is adjusted to:</p><formula xml:id="formula_16">C 2 ← − (1 − σ) • ∆E 00 (x, x ′ k−1 ) 2 ,<label>(10)</label></formula><p>where C 2 also becomes sensitive to image differences in terms of local visual variation. As shown in Fig. <ref type="figure" target="#fig_4">5</ref>, with the help of additional structural information, perturbations in the smooth regions are suppressed, while more changes, which are barely perceptible, are triggered in the area with rich visual variation. It is worthwhile for future work to investigate this combined approach in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Outlook</head><p>This paper has demonstrated the usefulness of perceptual color distance for creating large yet imperceptible adversarial image perturbations. We have proposed two approaches for creating adversarial images, PerC-C&amp;W and PerC-AL. Our experimental investigation of these approaches shows that perceptual color distance is able to improve imperceptibility, especially in smooth, saturated regions. We show that  <ref type="formula" target="#formula_16">10</ref>)).</p><p>these approaches have perturbations with larger RGB L p norms than approaches that perturb directly in RGB space. This effect translates into adversarial strength, i.e., the ability of the perturbations to fool a classifier.</p><p>Our work has made a contribution to recent work that seeks to create adversarial images that are imperceptible to the eye of the human observer. This work has been carried out in the area of security <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr">43]</ref> (defend inference of a legitimate classifier) and privacy <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42]</ref> (prevent inference of an illegitimate classifier). In the security area, imperceptible perturbations can mean that adversarial images can poison the training data without being noticed by human annotators. In the privacy area, imperceptible perturbations mean wider acceptance of the use of adversarial images to protect against classification attacks.</p><p>In the future, we will continue to consider perceptual color in adversarial images from both the privacy and the security angle. Our first direction will be related to the fact that neither conventional RGB perturbations nor PerC perturbations perform well in smooth regions with low saturation. We would like to develop techniques that can make perturbations imperceptible, or unnecessary, in such regions. Our future work will also look at model robustness specifically against our PerC adversaries. On one hand, adversarial training on images perturbed by PerC is worth exploring to complement current research on L p robustness. On the other hand, it would be interesting to investigate ways to detect whether PerC has been applied to an image, or design countering methods that can mitigate PerC-based perturbations by, for example, applying bit-depth reduction directly in perceptual color space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Left: Original image (a 20 × 20 8-bit RGB image patch with color (15,240,15)). Middle: Image perturbed by adding noise in the G channel, sampled from a uniform distribution in the range [-15,15]. Right: Image perturbed by adding the identical noise, but in the B channel. The B-channel perturbations are imperceptible (best viewed on screen).</figDesc><graphic url="image-2.png" coords="2,308.86,72.00,236.24,74.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Examples of adversarial images generated by five different approaches with high confidence level κ = 40</figDesc><graphic url="image-3.png" coords="7,74.86,72.00,445.51,165.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Evaluation of robustness of high-confidence adversarial examples at (a) κ = 20 and (b) κ = 40, against two types of image transformations: JPEG compression (top row) and bit-depth reduction (bottom row).</figDesc><graphic url="image-4.png" coords="7,308.86,278.12,236.25,211.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>κ = 20 κ = 40 κ = 20 κ = 40 κ = 20 κ = 40</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Adversarial examples of an image at κ = 40. Top: Generated by PerC-AL (Algorithm 1). Bottom: Generated by PerC-AL plus structure (Algorithm 1 plus Eq. (10)).</figDesc><graphic url="image-5.png" coords="8,308.86,72.00,236.24,160.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Success rates and perturbation sizes on the 1000 images from the ImageNet-Compatible dataset, with varied budgets in the targeted setting. Perturbation size is quantified in terms of L 2 and L ∞ norms of the perturbations in RGB space (L 2 and L ∞ ) and also in terms of imagelevel accumulated perceptual color difference (C 2 ). Note that C&amp;W and PerC-C&amp;W actually need more (here, 5×)</figDesc><table><row><cell>Approach</cell><cell>Budget</cell><cell>Success Rate (%)</cell><cell>Perturbation Size L 2 L ∞ C 2</cell></row><row><cell>I-FGSM [29]</cell><cell>-</cell><cell>100.0</cell><cell>2.51 1.59 317.96</cell></row><row><cell></cell><cell>3×100</cell><cell>100.0</cell><cell>1.32 8.84 159.85</cell></row><row><cell>C&amp;W [7]</cell><cell>5×200</cell><cell>100.0</cell><cell>1.09 8.20 132.86</cell></row><row><cell></cell><cell>9×1000</cell><cell>100.0</cell><cell>0.92 8.45 114.36</cell></row><row><cell></cell><cell>3×100</cell><cell>100.0</cell><cell>2.77 14.29 150.44</cell></row><row><cell>PerC-C&amp;W (ours)</cell><cell>5×200</cell><cell>100.0</cell><cell>1.48 12.06 83.93</cell></row><row><cell></cell><cell>9×1000</cell><cell>100.0</cell><cell>1.22 15.57 67.79</cell></row><row><cell></cell><cell>100</cell><cell>100.0</cell><cell>1.00 7.84 136.11</cell></row><row><cell>DDN [44]</cell><cell>300</cell><cell>100.0</cell><cell>0.88 7.58 120.12</cell></row><row><cell></cell><cell>1000</cell><cell>100.0</cell><cell>0.82 7.62 111.65</cell></row><row><cell></cell><cell>100</cell><cell>100.0</cell><cell>1.30 11.98 69.49</cell></row><row><cell>PerC-AL (ours)</cell><cell>300</cell><cell>100.0</cell><cell>1.17 13.97 61.21</cell></row><row><cell></cell><cell>1000</cell><cell>100.0</cell><cell>1.13 17.04 57.10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Evaluation of the success rate and perceptual color difference achieved by different approaches in highconfidence settings.</figDesc><table><row><cell>Approach</cell><cell cols="2">κ = 20 Suc. (%)</cell><cell>C 2</cell><cell cols="2">κ = 40 Suc. (%)</cell><cell>C 2</cell></row><row><cell>I-FGSM [29]</cell><cell>100.0</cell><cell cols="2">375.74</cell><cell>99.9</cell><cell>576.06</cell></row><row><cell>C&amp;W [7]</cell><cell>100.0</cell><cell cols="2">159.00</cell><cell>100.0</cell><cell>241.92</cell></row><row><cell>DDN [44]</cell><cell>100.0</cell><cell cols="2">150.68</cell><cell>98.1</cell><cell>238.37</cell></row><row><cell>PerC-C&amp;W (ours)</cell><cell>100.0</cell><cell cols="2">90.86</cell><cell>100.0</cell><cell>136.22</cell></row><row><cell>PerC-AL (ours)</cell><cell>100.0</cell><cell cols="2">75.43</cell><cell>100.0</cell><cell>115.17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Success rates of adversarial examples at two high confidence levels κ = 20 and κ = 40 in the transfer scenario, from the source model Inception V3 to three others.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://github.com/tensorflow/cleverhans/tree/master/examples/ nips17 adversarial competition/dataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Results in Table</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">are different from those in previous arXiv version due to changed normalization implementations, while the claims still hold.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was carried out on the Dutch national einfrastructure with the support of SURF Cooperative.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">5</ref>: Success rates and perturbation sizes on the 1000 images from the ImageNet-Compatible dataset, with varied budgets in the targeted setting. Perturbation size is quantified in terms of L 2 and L ∞ norms of the perturbations in RGB space (L 2 and L ∞ ) and also in terms of imagelevel accumulated perceptual color difference ( C 2 ). For this relatively easy untargeted case, PerC-AL is initialized with α c = 0.1.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<idno>ISO/CIE 11664-6:2014</idno>
		<title level="m">(E) Colourimetry-Part 6: CIEDE2000 Colour difference Formula</title>
				<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">What else can fool deep learning? Addressing color constancy errors on deep neural network performance</title>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Afifi</surname></persName>
		</author>
		<author>
			<persName><surname>Michael S Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Synthesizing robust adversarial examples</title>
		<author>
			<persName><forename type="first">Anish</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="284" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Unrestricted adversarial examples via semantic manipulation</title>
		<author>
			<persName><forename type="first">Anand</forename><surname>Bhattad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaizhao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
		<idno>ICLR, 2020. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behar</forename><surname>Veliqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Salathé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sharada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Mohanty</surname></persName>
		</author>
		<author>
			<persName><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.01976</idno>
		<title level="m">Adversarial vision challenge</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.08352</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Unrestricted adversarial examples</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy (S&amp;P)</title>
				<imprint>
			<date type="published" when="2006">2017. 1, 3, 5, 6</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Color image segmentation: advances and prospects</title>
		<author>
			<persName><forename type="first">Heng-Da</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xihua</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingli</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2259" to="2281" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The geo-privacy bonus of popular photo enhancements</title>
		<author>
			<persName><forename type="first">Jaeyoung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Friedland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Hanjalic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Certified adversarial robustness via randomized smoothing</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elan</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1310" to="1320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sparse and imperceivable adversarial attacks</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2008">2019. 2, 4, 5, 8</date>
			<biblScope unit="page" from="4724" to="4732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Shield: Fast, practical defense and vaccination for deep learning using JPEG compression</title>
		<author>
			<persName><forename type="first">Nilaksh</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madhuri</forename><surname>Shanbhogue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><surname>Shang-Tse Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siwei</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duen</forename><surname>Kounavis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chau</forename><surname>Horng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="196" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evading defenses to transferable adversarial examples by translation-invariant attacks</title>
		<author>
			<persName><forename type="first">Yinpeng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Gintare</forename><surname>Karolina Dziugaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.00853</idno>
		<title level="m">A study of the effect of JPG compression on adversarial images</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A rotation and a translation suffice: Fooling CNNs with simple transformations</title>
		<author>
			<persName><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2017 Workshop on Machine Learning and Computer Security</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Perceptual quality-preserving black-box attack against deep learning image classifiers</title>
		<author>
			<persName><surname>Gragnaniello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security (TIFS)</title>
		<imprint>
			<date type="published" when="2008">2019. 2, 4, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust physical-world attacks on deep learning models</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Eykholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Evtimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Earlence</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Rahmati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaowei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atul</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tadayoshi</forename><surname>Kohno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1625" to="1634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Leon</forename><forename type="middle">A</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05897</idno>
		<title level="m">Preserving color in neural artistic style transfer</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Countering adversarial images using input transformations</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adversarial example defense: Ensembles of weak defenses are not strong</title>
		<author>
			<persName><forename type="first">Warren</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Workshop on Offensive Technologies</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantic adversarial examples</title>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radha</forename><surname>Poovendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semantic adversarial attacks: Parametric transformations that fool deep classifiers</title>
		<author>
			<persName><forename type="first">Ameya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amitangshu</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumik</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chinmay</forename><surname>Hegde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4773" to="4783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">On a space of completely additive functions</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Vasilevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kantorovich</forename><surname>Gennady S Rubinstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958">1958</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
		<respStmt>
			<orgName>Vestnik Leningrad. Univ</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Color attributes for object detection</title>
		<author>
			<persName><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rao</forename><surname>Muhammad Anwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><surname>Van De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Weijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><forename type="middle">M</forename><surname>Vanrell</surname></persName>
		</author>
		<author>
			<persName><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="3306" to="3313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Masters thesis</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adversarial examples in the physical world</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2006">2017. 1, 3, 4, 5, 6</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adversarial attacks and defences competition</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinpeng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangzhou</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The NIPS&apos;17 Competition: Building Intelligent Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="195" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Functional adversarial attacks</title>
		<author>
			<persName><forename type="first">Cassidy</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soheil</forename><surname>Feizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Colorization for single image super resolution</title>
		<author>
			<persName><forename type="first">Shuaicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seon Joo</forename><surname>Michael S Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Wing</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Delving into transferable adversarial examples and blackbox attacks</title>
		<author>
			<persName><forename type="first">Yanpei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Who&apos;s afraid of adversarial queries? The impact of image modifications on content-based image retrieval</title>
		<author>
			<persName><forename type="first">Zhuoran</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="306" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Towards imperceptible and robust adversarial example attacks against neural networks</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<date type="published" when="2008">2018. 2, 4, 5, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ronnier Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guihua</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rigg</surname></persName>
		</author>
		<title level="m">The development of the CIE 2000 colour-difference formula: CIEDE2000. Color Research and Application</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Gender privacy: An ensemble of semi adversarial networks for confounding arbitrary gender classifiers</title>
		<author>
			<persName><forename type="first">Vahid</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Raschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Biometrics Theory, Applications and Systems (BTAS)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">DeepFool: a simple and accurate method to fool deep neural networks</title>
		<author>
			<persName><forename type="first">Seyed-Mohsen</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alhussein</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Adversarial image perturbation for privacy protection a game theory perspective</title>
		<author>
			<persName><forename type="first">Joon</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1491" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The limitations of deep learning in adversarial settings</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Berkay Celik</surname></persName>
		</author>
		<author>
			<persName><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE European Symposium on Security and Privacy (EuroS&amp;P)</title>
				<imprint>
			<date type="published" when="2008">2016. 1, 3, 8</date>
			<biblScope unit="page" from="372" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Ismail Ben Ayed, Robert Sabourin, and Eric Granger. Decoupling direction and norm for efficient gradient-based L2 adversarial attacks and defenses</title>
		<author>
			<persName><forename type="first">Jérôme</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Luiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><forename type="middle">S</forename><surname>Hafemann</surname></persName>
		</author>
		<author>
			<persName><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2006">2019. 3, 4, 5, 6</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On the suitability of Lp-norms for creating and preventing adversarial examples</title>
		<author>
			<persName><forename type="first">Mahmood</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lujo</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1605" to="1613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A general framework for adversarial examples with objectives</title>
		<author>
			<persName><forename type="first">Mahmood</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sruti</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lujo</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Privacy and Security (TOPS)</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rethinking the Inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised cross-domain image generation</title>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Ensemble adversarial training: Attacks and defenses</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Evaluating color descriptors for object and scene recognition</title>
		<author>
			<persName><forename type="first">Koen</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theo</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cees</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1582" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eero</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions On Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Provable defenses against adversarial examples via the convex outer adversarial polytope</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5283" to="5292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Wasserstein adversarial examples via projected sinkhorn iterations</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Spatially transformed adversarial examples</title>
		<author>
			<persName><forename type="first">Chaowei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warren</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Feature squeezing: Detecting adversarial examples in deep neural networks</title>
		<author>
			<persName><forename type="first">Weilin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjun</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Network and Distributed Systems Security Symposium (NDSS)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Color image quality assessment based on CIEDE2000. Advances in Multimedia</title>
				<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Teddy Furon, and Laurent Amsaleg. Smooth adversarial examples</title>
		<author>
			<persName><forename type="first">Hanwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Avrithis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Information Security (JIS)</title>
		<imprint>
			<date type="published" when="2005">2020. 2, 4, 5</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
