<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differential Privacy as a Mutual Information Constraint</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Paul</forename><surname>Cuff</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lanqing</forename><surname>Yu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Differential Privacy as a Mutual Information Constraint</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">93B313F28BD4C445CAF86EA4757C4E6B</idno>
					<idno type="DOI">10.1145/2976749.2978308</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Differential privacy, information theory</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differential privacy is a precise mathematical constraint meant to ensure privacy of individual pieces of information in a database even while queries are being answered about the aggregate. Intuitively, one must come to terms with what differential privacy does and does not guarantee. For example, the definition prevents a strong adversary who knows all but one entry in the database from further inferring about the last one. This strong adversary assumption can be overlooked, resulting in misinterpretation of the privacy guarantee of differential privacy.</p><p>Herein we give an equivalent definition of privacy using mutual information that makes plain some of the subtleties of differential privacy. The mutual-information differential privacy is in fact sandwiched between -differential privacy and ( , δ)-differential privacy in terms of its strength. In contrast to previous works using unconditional mutual information, differential privacy is fundamentally related to conditional mutual information, accompanied by a maximization over the database distribution. The conceptual advantage of using mutual information, aside from yielding a simpler and more intuitive definition of differential privacy, is that its properties are well understood. Several properties of differential privacy are easily verified for the mutual information alternative, such as composition theorems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Differential privacy is a concept proposed in <ref type="bibr" target="#b12">[12]</ref> for database privacy. It allows queries to be answered about aggregate quantities of data while protecting the privacy of individual entries in the database. In the absence of a precise mathematical framework such as differential privacy, practitioners have been tempted to use various rules-of-thumb to protect privacy (e.g. "don't answer a query that averages fewer than k entries together"-see the query restriction approach in <ref type="bibr" target="#b1">[1]</ref>). Instead, differential privacy directly addresses the statistical distinguishability of the database and has led to algorithms for answering general queries with just the right amount of randomness used in order to preserve privacy. <ref type="foot" target="#foot_0">1</ref>Differential privacy requires that two adjacent databases, which differ in only one entry, are statistically indistinguishable, as measured by a probabilistic metric defined in Section 2. This guarantee is particularly effective for making individuals feel comfortable contributing personal information to a dataset. For instance, if a person decides to participate in a survey, his answers only constitute one response out of the entire collection, and the responses of other people remain unchanged. Differential privacy is meant to assure the one participant that his answers are concealed.</p><p>This privacy metric has gained a lot of traction in recent years. The main contribution of this work is to cast differential privacy as a mutual information constraint. There have been many attempts in the literature to connect differential privacy to mutual information. Here we give not only a connection but an equivalence.</p><p>To briefly summarize the main result, consider a database X n = (X1, . . . , Xn) that returns a query response Y according to a random mechanism P Y |X n . Let X -i denote the set of database entries excluding Xi.</p><p>Definition 1 (( , δ)-Differential Privacy <ref type="bibr" target="#b13">[13]</ref>). A randomized mechanism P Y |X n satisfies ( , δ)-differential privacy if for all neighboring database instances x n and xn</p><formula xml:id="formula_0">P Y |X n =x n ( ,δ) ≈ P Y |X n =x n ,<label>(1)</label></formula><p>where the approximation in (1) is defined later in Definition 4, and neighboring database instances are defined in Definition 3 as any pair of database vectors that differ in only one entry (i.e. Hamming distance one). <ref type="foot" target="#foot_1">2</ref>Definition 2 (Mutual-Information Diff. Priv.). A randomized mechanism P Y |X n satisfies -mutual-information differential privacy if sup i,P X n I(Xi; Y |X -i ) ≤ nats.</p><p>(</p><formula xml:id="formula_1">)<label>2</label></formula><p>Note that nats are the information units that result from using the natural logarithm instead of the logarithm base two, which would give bits.</p><p>The main claim of this paper, which appears in Section 3, is an equivalence between mutual-information differential privacy (MI-DP) and the standard definition of ( , δ)-differential privacy (( , δ)-DP). The original definition of differential privacy <ref type="bibr" target="#b12">[12]</ref>, defined formally in Section 2, parameterized privacy with a single positive number . For various reasons it has since been relaxed <ref type="bibr" target="#b13">[13]</ref> to have two parameters and δ playing multiplicative and additive roles in the likelihood constraint. We refer to the original DP as -DP and the relaxed form as ( , δ)-DP. In this notation, -DP is simply ( , 0)-DP.</p><p>The claim herein is that MI-DP is sandwiched between these two definitions in the following sense: It is weaker than -DP but stronger than ( , δ)-DP. That is, a mechanism that satisfies -DP also satisfies -MI-DP. <ref type="foot" target="#foot_2">3</ref> Similarly, if -MI-DP holds then ( , δ)-DP also must hold, where and δ vanish as goes to zero. In fact, the connection between MI-DP and ( , δ)-DP is an equivalence if either the domain or range of the query mechanism is a finite set.</p><p>The advantage of this alternative but equally strong definition of differential privacy is that mutual information is a well-understood quantity. It provides a clear picture of what differential privacy does and does not guarantee. Furthermore, several properties of differential privacy are immediate to prove in this form.</p><p>While the mathematics of differential privacy, in its standard form, are straightforward, an intuitive understanding can be elusive. The definition of ( , δ)-DP involves a notion of neighboring database instances. Upon examination one realizes that this has the affect of assuming that the adversary has already learned about all but one entry in the database and is only trying to gather additional information about the remaining entry. We refer to this as the strong adversary assumption, which is implicit in the definition of differential privacy. Notice that MI-DP needs no definition of neighborhood. The strong adversary assumption is made explicit in the conditioning within the conditional mutual information term.</p><p>The strong adversary assumption is both a feature and a vulnerability of the definition of differential privacy. It is a feature when recruiting individual participants for a survey. The individual can decide whether or not to participate but cannot do anything about the information contributed by others (which may inform on them indirectly). Differential privacy assures them that even with access to everyone else's responses, the survey reports will not further reveal anything about their individual response. However, DP also has its shortcomings as a privacy guarantee. Among all adversaries with different prior knowledge of the database, the strong adversary may not be the one which benefits the most from the query output. Indeed, it is shown in <ref type="bibr" target="#b18">[18]</ref> that a weaker adversary can compromise privacy severely if the entries in the database are correlated, which is quite typical in certain applications such as social networks.</p><p>As an equivalent privacy metric, MI-DP benefits and suffers in the same way. Fortunately, the definition of MI-DP puts this potential weakness in plain sight. It shows explicitly that information leakage is only being restricted conditioned on the remainder of the database being known. Clearly, this does not bound the unconditional mutual information when correlations are present.</p><p>Somewhat paradoxically, mutual information can serve simultaneously as both a measure of privacy, as in MI-DP, and as a quantification of utility-for example, the mutual information between the entire database and the query response, I(X n ; Y ). The close connection between mutual information and estimation and detection further captures the privacyutility trade-off.</p><p>Several works <ref type="bibr" target="#b20">[20,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b3">3,</ref><ref type="bibr" target="#b10">10]</ref> relate mutual information to differential privacy by upper bounding mutual information given a differential privacy achieving mechanism. One common point of these works is that they all use unconditional mutual information rather than conditional. Often, the conclusion is a bound on the unconditional mutual information between the whole database and the private output. The use of conditional mutual information in Definition 2 captures the prior knowledge of the database possessed by a potential adversary (i.e. the strong adversary assumption implicit in DP). This is crucial in developing an equivalence with the standard DP definition.</p><p>Another crucial ingredient that some of the literature fails to properly incorporate (e.g. <ref type="bibr" target="#b25">[25]</ref>) when applying mutual information to differential privacy is that differential privacy is a property of the query mechanism and assumes no specific prior distribution on the database. Mutual information, on the other hand, is not well defined without a joint distribution, which must include a distribution for the database. The remedy is to maximize the mutual information over all possible distributions on the database, as seen in the definition of MI-DP in Definition 2. <ref type="foot" target="#foot_3">4</ref> Had we defined MI-DP with respect to any particular database distribution (e.g. with independent and identically distributed entries), we would have significantly reduced its strength as a privacy metric. The formula in Definition 2 in fact looks like a channel capacity formula one would encounter in expressing the fundamental limit of communication through a noisy channel. This maximization removes any distributional assumption and makes MI-DP a property of the mechanism itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><p>The set {1, 2, • • • , m} is denoted as <ref type="bibr">[m]</ref>. An index set I is a subset of [n] whose elements are enumerated as (i1, • • • , i |I| ), where | • | denotes the cardinality of a set.</p><p>We use X n as shorthand notation for the sequence of random variables (X1, • • • , Xn). The symbol X -i denotes the sequence of n-1 random variables (X1,</p><formula xml:id="formula_2">• • • , Xi-1, Xi+1, • • • , Xn),</formula><p>in other words, all of X n except Xi. The lower case symbol x -i is an instance of X -i . For any index set I, we use XI to denote the sequence of random variables (Xi</p><formula xml:id="formula_3">1 , • • • , Xi |I| ) specified by I. Similarly the lower case xI = (xi 1 , • • • , xi |I| ) is an instance of XI.</formula><p>A database X n consists of n entries, where the i-th entry takes values from Xi. Definition 3 (Neighbor). Two database instances x n and xn are neighbors if they differ in only one entry. In other words,</p><formula xml:id="formula_4">dH (x n , xn ) = 1,<label>(3)</label></formula><p>where dH (•, •) is Hamming distance.</p><p>The output of a privacy mechanism is a random variable represented as Y and takes values from Y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Statistical Indistinguishability</head><p>Two probability distributions can be considered statistically indistinguishable if they are close under an appropriate metric. The criterion for indistinguishability used in the standard definition of differential privacy is the following. Definition 4 (( , δ)-Closeness). Two probability distributions P and Q over the same measurable space (Ω, F) are ( , δ)-close, denoted as</p><formula xml:id="formula_5">P ( ,δ) ≈ Q (4) if P (A) ≤ e Q(A) + δ, ∀A ∈ F ,<label>(5)</label></formula><formula xml:id="formula_6">Q(A) ≤ e P (A) + δ, ∀A ∈ F .<label>(6)</label></formula><p>Consider two special cases, δ = 0 and = 0. If δ = 0, then P and Q are mutually absolutely continuous, denoted as P Q, and ( , 0)-closeness is a statement about the Radon-Nikodym derivative dP dQ :</p><formula xml:id="formula_7">P ( ,0) ≈ Q ⇐⇒ ln dP dQ (a) ≤ ∀a ∈ Ω. (<label>7</label></formula><formula xml:id="formula_8">)</formula><p>On the other hand, with = 0, (0, δ)-closeness is a statement about the total variation distance:</p><formula xml:id="formula_9">P (0,δ) ≈ Q ⇐⇒ P -Q T V ≤ δ.<label>(8)</label></formula><p>We can also relate ( , δ)-closeness to Kullback-Leibler divergence, denoted as D(• •). For example, by relaxing the right side of <ref type="bibr" target="#b7">(7)</ref> to be an expected value rather than a statement about all a ∈ Ω, we immediately get the following implication:</p><formula xml:id="formula_10">P ( ,0) ≈ Q =⇒ D(P Q) ≤ nats, D(Q P ) ≤ nats. (<label>9</label></formula><formula xml:id="formula_11">)</formula><p>Tighter expressions of the relationship to Kullback-Leibler divergence are given next, in Properties 1 and 2. We give a proof of Property 1 in Appendix A.</p><p>Property 1.</p><formula xml:id="formula_12">P ( ,0) ≈ Q =⇒ D(P Q) ≤ min , 2 nats, D(Q P ) ≤ min , 2 nats. (<label>10</label></formula><formula xml:id="formula_13">)</formula><p>In fact, the tightest possible statement of this form is</p><formula xml:id="formula_14">P ( ,0) ≈ Q =⇒ D(P Q) ≤ (e -1) 1 -e - (e -1) + (1 -e -)</formula><p>nats,</p><formula xml:id="formula_15">D(Q P ) ≤ (e -1) 1 -e - (e -1) + (1 -e -)</formula><p>nats.</p><p>(11) Equality on the right side of (11) can be achieved with binary distributions. For small , the right side of (11) is asymptotically 1 2 2 nats. Property 2. By Pinsker's inequality,</p><formula xml:id="formula_16">D(P Q) ≤ nats =⇒ P 0, √ /2 ≈ Q. (<label>12</label></formula><formula xml:id="formula_17">)</formula><p>Property 1 and Property 2 are strict in the sense that the reverse implications are not true in any form (i.e. closeness bounds on the right, no matter how small the parameters, do not even imply finiteness of the parameters on the left). Also, we already mentioned that Property 1 is tight. Property 2 is known to be tight up to a multiplicative constant.</p><p>The quantities arising in the above definitions and properties have concrete connections to inference. Total variation distance precisely captures the error probability in a binary hypothesis test. That is, one minus the total variation distance is the minimum sum of the two types of binary error probability. Kullback-Leibler divergence precisely captures the asymptotic hypothesis testing error upon observing many independent observations <ref type="bibr" target="#b8">[8,</ref><ref type="bibr">Chapter 11]</ref>. The strongest of these metrics, ( , 0)-closeness, has an interpretation in the Bayesian setting as a bound on the Bayes factor. That is, the log-posterior-odds-ratio cannot change by more than due to the observation. Finally, ( , δ)-closeness is shown in <ref type="bibr" target="#b17">[17]</ref> to be precisely a piecewise linear constraint on the error region in a binary hypothesis test. By inspection of that relationship, the following property is apparent (proven in Appendix B).</p><formula xml:id="formula_18">Property 3. For any non-negative &lt; , let δ = 1 - e +1 (1-δ) e +1 . P ( ,δ) ≈ Q =⇒ P ( ,δ ) ≈ Q. (<label>13</label></formula><formula xml:id="formula_19">)</formula><p>Property 3 is the tightest possible trade-off between and δ with respect to ( , δ)-closeness. Notice that δ &gt; δ. It is not possible for a larger δ to imply a smaller one, for any finite and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Differential Privacy</head><p>The definition of ( , δ)-DP in Definition 1 has been now made precise with Definition 3 (neighbor) and Definition 4 (( , δ)-closeness).</p><p>We define -DP and (δ)-DP by setting either of the two parameters to zero. Definition 5 ( -Differential Privacy <ref type="bibr" target="#b12">[12]</ref>). A randomized mechanism P Y |X n satisfies -DP if it satisfies ( , 0)-DP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 6 ((δ)-Differential Privacy</head><formula xml:id="formula_20">). A random- ized mechanism P Y |X n satisfies (δ)-DP if it satisfies (0, δ)- DP.</formula><p>Mutual-information differential privacy was defined in the introduction in Definition 2.</p><p>Finally, let us define one additional privacy metric based on Kullback-Leibler divergence, which we will call KL-DP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 7 (KL Differential Privacy).</head><p>A randomized mechanism P Y |X n satisfies -KL-DP if for all neighboring database instances x n and xn</p><formula xml:id="formula_21">D P Y |X n =x n P Y |X n =x n ≤ nats. (<label>14</label></formula><formula xml:id="formula_22">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Ordering of Privacy Metrics</head><p>This work is about showing equivalence of privacy metrics. In order to do so, we must define an ordering.</p><p>Definition 8 (Stronger Privacy Metric). As a placeholder, take α-DP and β-DP to represent two generic privacy guarantees with positive parameters α and β. We say that α-DP is stronger than β-DP, denoted as</p><formula xml:id="formula_23">α-DP β-DP,<label>(15)</label></formula><p>if for all β &gt; 0 there exists an α &gt; 0 such that</p><formula xml:id="formula_24">α'-DP =⇒ β'-DP. (<label>16</label></formula><formula xml:id="formula_25">)</formula><p>If the parameters are vectors, then β &gt; 0 and α &gt; 0 should be interpreted as inequalities on each coordinate.</p><p>Example 1. It is clear that -DP ( , δ)-DP and (δ)-DP ( , δ)-DP, since -DP implies ( , δ)-DP for any nonnegative δ, and likewise for (δ)-DP, by definition.</p><p>Also, ( , δ)-DP = (δ)-DP by Property 3. Notice that even if we set = 0, the quantity δ , as defined in the property, goes to zero as and δ go to zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MAIN RESULT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Equivalence</head><p>The emphasis of this work is the equivalence of mutualinformation differential privacy with classical differential privacy.</p><p>Theorem 1 (Main Result).</p><p>-DP MI-DP ( , δ)-DP.</p><p>Furthermore, if the cardinality of the database entries or the query response is bounded, then</p><formula xml:id="formula_27">MI-DP = ( , δ)-DP,<label>(18)</label></formula><p>where the relationship ( , δ)-DP MI-DP is dependent on the cardinality bound</p><formula xml:id="formula_28">min |Y|, max i |Xi| . (<label>19</label></formula><formula xml:id="formula_29">)</formula><p>Precise bounds for the privacy parameters are given in the three lemmas in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Related Work</head><p>Using information theoretic measures to quantify the privacy guarantee of differential privacy is not a new idea. An upper bound of mutual information is shown in <ref type="bibr" target="#b20">[20]</ref> in a twoparty differential privacy setting. Later this upper bound is used in <ref type="bibr">[9]</ref> to get I(X n ; Y ) ≤ 3 n. In <ref type="bibr" target="#b3">[3]</ref> and <ref type="bibr" target="#b4">[4]</ref>, min-entropy is considered rather than the usual Shannon entropy, and upper bounds are proven. In fact, [4, Corollary 1] implies an ordering relationship similar to the first inequality of ( <ref type="formula" target="#formula_26">17</ref>) but for min-entropy based information leakage with only a single database entry. In <ref type="bibr" target="#b25">[25]</ref>, a "mutual information privacy" metric is defined and studied.</p><p>These works have in common that they all consider the use of unconditional mutual information. This doesn't capture the structure in the definition of differential privacy and the bounds are limited to the mutual information between the whole database and the sanitized query output, with no focus on individual entries. Needless to say, an equivalence is not established. Some of the information theory literature bares resemblance to this work. In <ref type="bibr" target="#b5">[5]</ref>, similar proof steps to this work are used to show an equivalence between semantic security and a mutual information constraint. As in this work, there is a maximization over distributions of inputs to the randomized mechanism; however, conditional mutual information is not a part of that result, while it is a necessary ingredient here. Also, the notion of ( , δ)-closeness goes by the name of Eγ distance in some of the information theory literature, such as <ref type="bibr" target="#b22">[22]</ref> and <ref type="bibr" target="#b19">[19]</ref>. Specifically, P ( ,δ) ≈ Q is equivalent to the pair of statements Ee (P Q) ≤ δ and Ee (Q P ) ≤ δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Proof of Theorem 1</head><p>We prove <ref type="bibr" target="#b17">(17)</ref> of Theorem 1 by proving a stronger chain of inequalities:</p><p>-DP</p><formula xml:id="formula_30">(A) KL-DP (B) MI-DP (C) (δ)-DP (D) = ( , δ)-DP. (20)</formula><p>It is worth noting both (A) and (B) are in fact strict orderings ( )-the reverse implications do not hold, even if cardinality bounds are assumed.</p><p>We now state the components of the proof in separate lemmas. Orderings (A) and (B) are the subject of Lemma 1, and ordering (C) is handled by Lemma 2. Equality (D) comes from Property 3, as discussed in Example 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1 (Orderings (A) and (B))</head><p>.</p><formula xml:id="formula_31">-DP =⇒ min , 2 -KL-DP,<label>(21)</label></formula><p>-KL-DP =⇒ -MI-DP.</p><p>Therefore,</p><formula xml:id="formula_33">-DP =⇒ min , 2 -MI-DP.<label>(23)</label></formula><p>Proof. The first statement, <ref type="bibr" target="#b21">(21)</ref>, is established by Property 1. Both -DP and KL-DP are defined the same way in terms of neighboring database instances.</p><p>The second statement, <ref type="bibr" target="#b22">(22)</ref>, is best understood through the geometric interpretation of capacity as the radius of the information ball <ref type="bibr" target="#b8">[8,</ref><ref type="bibr">Theorem 13.1.1]</ref>. The radius cannot be more than the maximum of pairwise distances. However, we will not directly use that machinery here. Instead, consider the following direct proof.</p><p>Start by assuming that the randomized mechanism P Y |X n satisfies -KL-DP. Let i ∈ {1, . . . , n} and PXn be arbitrary. For notational clarity, let Xn ∼ PXn , and begin with a representation of conditional mutual information for a general distribution in terms of Kullback-Leibler divergence:</p><formula xml:id="formula_34">I(Xi; Y |X -i ) = E D P Y |X n = Xn P Y |X -i = X-i<label>(24)</label></formula><p>Now we bound</p><formula xml:id="formula_35">D P Y |X n =x n P Y |X -i =x -i for each in- stance x n . Fix x n arbitrarily, and let X ∼ P X i |X -i =x -i . Consider, P Y |X -i =x -i = E P Y |X i = X,X -i =x -i .<label>(25)</label></formula><p>Therefore, by Jensen's inequality, and using the fact that D(• •) is convex in the second argument, we conclude,</p><formula xml:id="formula_36">D P Y |X n =x n P Y |X -i =x -i = D P Y |X n =x n E P Y |X i = X,X -i =x -i ≤ E D P Y |X n =x n P Y |X i = X,X -i =x -i ≤ nats, (<label>26</label></formula><formula xml:id="formula_37">)</formula><p>where the last inequality is due to the fact that any two databases that agree on X -i are neighbors.</p><p>Lemma 2 (Ordering (C)).</p><p>-MI-DP =⇒ 0, √ 2 -DP.</p><p>In fact, the tightest possible statement of this form is</p><formula xml:id="formula_39">-MI-DP =⇒ 0, δ -DP,<label>(28)</label></formula><p>with δ = 1 -2h -1 (ln 2 -), where h -1 is the inverse of the increasing part of the binary entropy function in units of nats. This formula holds for ∈ [0, ln 2]. For &gt; ln 2, the implication becomes (1)-DP, which is vacuous. The claim in (27) is looser than that in (28) but asymptotically tight for small .</p><p>Proof. The essence of this claim is found in the binary case, with a binary database and a binary query response. We show this reduction first.</p><p>Start by assuming that the randomized mechanism P Y |X n satisfies -MI-DP. Consider an arbitrary pair of neighboring database instances x n and xn , and let i be the location where they differ. Denote by ∆xn,xn the subset of probability distributions over the space of databases D that only put positive mass on x n and xn . Therefore, all distributions in ∆xn,xn are binary, and X -i is deterministic with respect to any of them.</p><p>Also, let A be an arbitrary measurable subset of Y. Consider the indicator function</p><formula xml:id="formula_40">B(y) = 1, y ∈ A, 0, y / ∈ A.<label>(29)</label></formula><p>The random variable B is the binary function B(Y ).</p><p>max</p><formula xml:id="formula_41">P X n ∈∆ x n ,x n I(Xi; B)<label>(a)</label></formula><p>≤ max</p><formula xml:id="formula_42">P X n ∈∆ x n ,x n I(Xi; Y ) (b)</formula><p>= max</p><formula xml:id="formula_43">P X n ∈∆ x n ,x n I(Xi; Y |X -i ) ≤ sup P X n I(Xi; Y |X -i ) (c) ≤ nats,<label>(30)</label></formula><p>where (a) is due to the data processing inequality, (b) comes from the fact that X -i is deterministic for all distributions in ∆xn,xn , and (c) is by assumption of -MI-DP.</p><p>To summarize, we have arrived at a binary input and binary output randomized mechanism P B|X i , where Xi ∈ {xi, xi}, defined by</p><formula xml:id="formula_44">P B|X i =x i ({1}) = P Y |X n =x n (A),<label>(31)</label></formula><formula xml:id="formula_45">P B|X i =x i ({1}) = P Y |X n =x n (A). (<label>32</label></formula><formula xml:id="formula_46">)</formula><p>This mechanism is shown in (30) to satisfy -MI-DP. Also, since A, x n , and xn were chosen arbitrarily, any (δ)-DP claim that can be made about P B|X i must also hold for</p><formula xml:id="formula_47">P Y |X n .</formula><p>In Appendix C, we complete the proof by showing that Lemma 2 holds for all randomized mechanisms with a binary input and binary output, and that the characterization is tight.</p><p>A more complete characterization is also possible, of the form</p><formula xml:id="formula_48">-MI-DP =⇒ , δ -DP,<label>(33)</label></formula><p>for a particular set of values ( , δ ) which, among other things, has the property that δ must be greater than some positive threshold which depends on , and as δ approaches this threshold, must go to infinity. This characterization is also arrived at by first reducing to the binary case as we have done above. However, a description of the trade-off is too unwieldy for this discussion.</p><p>We prove <ref type="bibr" target="#b18">(18)</ref> of Theorem 1 with the following claim. The proof is given in Appendix D.</p><p>Lemma 3 (Reverse direction). If |Xi| is finite for all i ∈ {X1, . . . , Xn}, or if |Y| is finite, then</p><formula xml:id="formula_49">(δ)-DP =⇒ -MI-DP,<label>(34)</label></formula><p>where, for any δ ∈ [0, 1],</p><p>= 2h(δ) + 2δ ln min |Y|,</p><formula xml:id="formula_50">max i |Xi| + 1 . (<label>35</label></formula><formula xml:id="formula_51">)</formula><p>Slightly tighter bounds can be found in ( <ref type="formula">105</ref>) and (126) of the proof. Although these bounds may have some looseness, the following example shows that they get roughly within a factor of two of the correct scaling for large cardinalities.</p><p>Example 2 (Erasure channel). Consider a database with only one entry, X1.</p><formula xml:id="formula_52">Let X1 = [N ] and Y = [N ] ∪ {0}. Define P Y |X 1 =x 1 =      1 -δ, y = 0, δ, y = x1, 0, otherwise.<label>(36)</label></formula><p>This randomized mechanism is usually referred to as an erasure channel, where the output Y = 0 is considered an erasure. It is known that the capacity of this channel is</p><formula xml:id="formula_53">C = δ log N,<label>(37)</label></formula><p>where N = |X1| = |Y| -1. This implies that there exists a distribution of the database (in this case, the uniform distribution for X1 ∈ X1) such that</p><formula xml:id="formula_54">I(X1; Y |X -1 ) = I(X1; Y ) = δ log |X1| = δ log(|Y| -1). (<label>38</label></formula><formula xml:id="formula_55">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PROPERTIES OF DIFF. PRIVACY</head><p>Now that we have MI-DP as an equivalent metric of privacy, we explore the insights that this brings and simple proofs of properties about privacy.</p><p>The following are three basic and well-known properties of mutual information:</p><formula xml:id="formula_56">Property 4. If U is independent of W , then I(U ; V |W ) ≥ I(U ; V ). (<label>39</label></formula><formula xml:id="formula_57">)</formula><p>Property 5. If U , V , and W form a Markov chain U -V -W , meaning that U and W are conditionally independent given V , then</p><formula xml:id="formula_58">I(U ; V |W ) ≤ I(U ; V ). (<label>40</label></formula><formula xml:id="formula_59">)</formula><p>Property 6 (Chain rule).</p><formula xml:id="formula_60">I(U ; V, W ) = I(U ; V ) + I(U ; W |V ). (<label>41</label></formula><formula xml:id="formula_61">)</formula><p>We will use these three properties (sometimes conditioned on other random variables) to make claims about MI-DP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Strong Adversary Assumption</head><p>We refer to a strong adversary as one who knows the entire database except for any one entry Xi. Differential privacy is implicitly designed as a protection against further information leakage to this adversary. The definition of MI-DP, now shown to be equivalent, makes this attribute explicit by conditioning on the remainder of the database and bounding I(Xi; Y |X -i ). But how much information does the sanitized output Y leak to an adversary with no prior knowledge?</p><p>In <ref type="bibr" target="#b18">[18]</ref>, this is referred to as evidence of participation. In the mutual information context, this may be measured by the unconditional mutual information I(Xi; Y ). It is pointed out in <ref type="bibr" target="#b18">[18]</ref> that if the entries of the database are independent, the evidence of participation can be protected properly by differential privacy. This claim is straightforward using MI-DP in light of Property 4.</p><p>Corollary 1 (Independent Data). If {Xi} n i=1 are mutually independent and P Y |X n satisfies -MI-DP, then sup i,P X i P X -i</p><formula xml:id="formula_62">I(Xi; Y ) ≤ sup i,P X i P X -i I(Xi; Y |X -i ) ≤ nats.<label>(42)</label></formula><p>On the other hand, it is often the case that entries of a database are correlated. Differential privacy does not provide a strong guarantee about the evidence of participation in general. Consider the following familiar example:</p><p>Example 3 (Correlated database). Consider a database with n binary entries. A data curator decides to release the mean of all entries and chooses the Laplace mechanism. Noise with distribution Lap( 1 n ) is added to the sample mean to ensure -DP (also -MI-DP by <ref type="bibr">Lemma 1)</ref>. Now suppose all database entries are in fact equal to each other (maximally correlated). Let X ∼ Bern(0.5) and Xi = X for all i ∈ {1, . . . , n}. For large enough n, the noise added is negligible, and the binary value of the sample mean can be estimated with high accuracy, revealing each individual entry. In terms of mutual information, I(Xi; Y ) ≈ 1 bit for each i even while I(Xi; Y |X -i ) = 0 because H(Xi|X -i ) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Composition</head><p>Among the most important properties of differential privacy is composability. This states that a collection of queries, each satisfying differential privacy, collectively satisfies differential privacy with a parameter scaled proportional to the number of queries.</p><p>A great deal of effort has been made in deriving tight composition theorems for differential privacy. A straightforward composition theorem can be found in <ref type="bibr" target="#b13">[13]</ref>. More intricate trade-offs can be found in <ref type="bibr" target="#b14">[14]</ref> and <ref type="bibr" target="#b17">[17]</ref>, with the latter establishing a tight characterization.</p><p>The following claims for MI-DP mirror those found in <ref type="bibr" target="#b21">[21]</ref> for ( , 0)-DP and are in fact tight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 2 (Conditionally independent queries).</head><p>If several query responses {Y1, . . . , Y k } are produced conditionally independently given the database, and each mechanism P Y j |X n satisfies j -MI-DP individually, then as a collection P Y k |X n satisfies j j -MI-DP.</p><p>Proof. For any i and PXn , the chain rule of mutual information (Property 6) gives (a), and Property 5 gives (b):</p><formula xml:id="formula_63">I(Xi; Y k |X -1 ) (a) = k j=1 I(Xi; Yj|X -i , Y j-1 ) (b) ≤ k j=1 I(Xi; Yj|X -i ) ≤ k j=1 j nats. (<label>43</label></formula><formula xml:id="formula_64">)</formula><p>Corollary 2 states that the effect of releasing multiple conditionally independent query responses has no more than an additive effect on the parameter of privacy. It is worth noting two important points. First, query responses that are not conditionally independent (i.e. the noise from one query response is somehow reused in the next) have no such guarantee, as the following example illustrates.</p><p>Example 4 (Correlated query responses). Consider a database where each entry has a finite alphabet |Xi| ≤ ∞. Consider two outputs of a query mechanism, Y1 = X1 ⊕ U and Y2 = U , where U is a uniformly distributed random variable on the set {1, . . . , |X1|}, independent of the database instance, and ⊕ is addition modulo |X1|. In other words, the first output Y1 is X1 encrypted by a one-time pad, and the second output Y2 is the key to the one-time pad. Clearly, the combination of Y1 and Y2 reveals X1 and violates differential privacy.</p><p>On the other hand, Example 4 does not imply that correlated query responses should not be considered. Quite to the contrary, query responses that are carefully constructed to be correlated with each other have the potential to achieve significantly better privacy after multiple queries, as demonstrated in <ref type="bibr" target="#b15">[15]</ref> and <ref type="bibr" target="#b6">[6]</ref>.</p><p>In general, the same composition claim of Corollary 2 holds even if the query responses are correlated as long as each response in sequence is specifically designed to satisfy differential privacy even with respect to the previous responses. The following corollary states this claim, and the proof follows directly from the proof of Corollary 2 simply by skipping (43). Proof. Let f (i) be the index j such that i ∈ Ij. For any i and PXn , the chain rule of mutual information (Property 6) gives:</p><formula xml:id="formula_65">I(Xi; Y k |X -1 ) = I(Xi; Y f (i) |X -i ) + I(Xi; Y -f (i) |X -i , Y f (i) ) = I(Xi; Y f (i) |X -i ) ≤ nats.</formula><p>(44)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">A DISCREPANCY</head><p>While most properties of -DP or ( , δ)-DP are also properties of MI-DP, it turns out that one basic property does not carry over.</p><p>Differential privacy is defined with respect to neighboring database instances. What privacy can be guaranteed if some bounded number of entries are changed in the database? Similar to the composition properties, the closeness of the output distribution scales proportionally with the number of database changes. The following properties are obtained by repeated application ( <ref type="formula" target="#formula_5">5</ref>) and ( <ref type="formula" target="#formula_6">6</ref>) from Definition 4.</p><p>Property 7 (Epsilon). Suppose x n and xn are instances of the database that differ in at most k entries, and that the randomized mechanism P Y |X n is -DP. Then</p><formula xml:id="formula_66">P Y |X n =x n (k ,0) ≈ P Y |X n =x n . (<label>45</label></formula><formula xml:id="formula_67">)</formula><p>Property 8 (Delta). Suppose x n and xn are instances of the database that differ in at most k entries, and that the randomized mechanism P Y |X n is (δ)-DP. Then</p><formula xml:id="formula_68">P Y |X n =x n (0,kδ) ≈ P Y |X n =x n . (<label>46</label></formula><formula xml:id="formula_69">)</formula><p>Property 9 (General). Suppose x n and xn are instances of the database that differ in at most k entries, and that the randomized mechanism P Y |X n is ( , δ)-DP. Then</p><formula xml:id="formula_70">P Y |X n =x n k , e k -1 e -1 δ ≈ P Y |X n =x n . (<label>47</label></formula><formula xml:id="formula_71">)</formula><p>On the other hand, MI-DP does not have an analogous property. Even if a mechanism satisfies -MI-DP, there may not be a bound on I(XI; Y |XIc ), where I represents a subset of |I| = k indices. Consider the following example. </p><p>This mechanism satisfies ( ln 2)-MI-DP. Notice that for any value of X2 = x2, we have a binary erasure channel from X1 to Y , with binary input determined by whether X1 = x2 or not. The symbol e1 serves as the erasure. The symbol e2 represents the unerased indicator that X1 = x2. This binary erasure channel with erasure probability 1 -has mutual information bounded above by ln 2 nats (the capacity of the erasure channel).</p><p>On the other hand, the mutual information I(X1, X2; Y ) is unbounded if there are no constraints on X1 and X2. Indeed, if we let X1 be a continuous random variable, and we set X2 = X1, then</p><formula xml:id="formula_73">I(X1, X2; Y ) = ∞. (<label>50</label></formula><formula xml:id="formula_74">)</formula><p>More generally, if the domains X1 and X2 are equal, then the capacity of the erasure channel gives the achievable mutual information (where e2 represents an additional input symbol selected by any choice of X1 = X2):</p><formula xml:id="formula_75">max P X 1 ,X 2 I(X1, X2; Y ) = log(|X1| + 1) = log(|Y| -1). (<label>51</label></formula><formula xml:id="formula_76">)</formula><p>In fact, Example 5 might be best interpreted as a fortunate advantage of MI-DP. With any query mechanism, there is a trade-off between privacy and the informational utility to be gained from the output. If we apply Property 7 with k = n, the conclusion is that</p><formula xml:id="formula_77">P Y |X n =x n (n ,0) ≈ P Y |X n =x n<label>(52)</label></formula><p>for any two databases x n and xn . By revisiting the proof of Lemma 1, we obtain</p><formula xml:id="formula_78">I(X n ; Y ) ≤ min n , (n ) 2 nats.<label>(53)</label></formula><p>One way to view this is as a crude bound on the utility of the query output. The bound is detrimental if n is not large. On the other hand, MI-DP does not imply such a constraint. If, however, we take into account a cardinality bound on the database entries or the query output, then there is indeed an upper bound on the information leaked from a group of database entries. This is obtained by using Property 8 in combination with Lemma 2, followed by repeating the proof of Lemma 3 for a group rather than an individual entry.</p><p>Corollary 5. Suppose the randomized mechanism P Y |X n satisfies -MI-DP. Then for any subset of indices I, with |I| = k, and with</p><formula xml:id="formula_79">I c = [n] \ I, sup P X n I(XI; Y |XIc ) ≤ 2h k √ 2 + 2k √ 2 log M,<label>(54)</label></formula><p>where M = min |Y|, (maxi |Xi|) k + 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">VARIATIONS OF DIFF. PRIVACY</head><p>Many variations of differential privacy have been proposed in the literature to provide different assurances. Here we demonstrate how mutual-information differential-privacy can be adapted to correspond to these various definitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Personalized Differential Privacy</head><p>Personalized differential privacy <ref type="bibr" target="#b16">[16]</ref> addresses the situation where participants of the database may have different concerns about the level of privacy. This is handled by assigning a different i for each database entry Xi. That is, for any database instances x n and xn which differ in only the ith place,</p><formula xml:id="formula_80">P Y |X n =x n ( i ,0) ≈ P Y |X n =x n .<label>(55)</label></formula><p>The modification to MI-DP would be to require that for each i, sup</p><formula xml:id="formula_81">P X n I(Xi; Y |X -i ) ≤ i nats.</formula><p>(56)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Free-Lunch Privacy</head><p>Free-lunch privacy was both defined and refuted in <ref type="bibr" target="#b18">[18]</ref> as a stronger privacy definition which puts no restriction on which database instances must be indistinguishable. A mechanism P Y |X n is -free-lunch private if every pair of database instances x n and xn satisfies</p><formula xml:id="formula_82">P Y |X n =x n ( ,0) ≈ P Y |X n =x n .<label>(57)</label></formula><p>The MI-DP equivalent of this would be sup</p><formula xml:id="formula_83">P X n I(X n ; Y ) ≤ nats. (<label>58</label></formula><formula xml:id="formula_84">)</formula><p>We can easily see the strength of this definition by applying the chain rule of mutual information (Property 6) to (58).</p><p>The result is that for any pair of disjoint index sets I and J , sup</p><formula xml:id="formula_85">P X n I(XI; Y |XJ ) ≤ nats. (<label>59</label></formula><formula xml:id="formula_86">)</formula><p>On the other hand, (58) and (59) illustrate the poor utility provided by the -free-lunch privacy mechanism, as the information contained in the output is always upper bounded by regardless of distribution and prior knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Bayesian Differential Privacy</head><p>Bayesian differential privacy [26] deals with the possible privacy degradation of differential privacy if the entries in the database are correlated. As was discussed in Section 4.1, a weak adversary who has less background knowledge of the database may stand to gain much more information than the adversary who knows all but one entry. Bayesian differential privacy is meant to protect simultaneously against all adversaries, but in order to do so it assumes a prior distribution on the database.</p><p>Given a prior distribution PXn , a mechanism P Y |X n is -Bayesian differentially private if, for any index i and subset of indices I,</p><formula xml:id="formula_87">P Y |X i =x i ,X I =x I ( ,0) ≈ P Y |X i =x i ,X I =x I .<label>(60)</label></formula><p>Notice that the conditional distributions are not necessarily conditioned on the entire database. The MI-DP equivalent is, for any index i and subset of indices I,</p><formula xml:id="formula_88">I(Xi; Y |XI) ≤ nats,<label>(61)</label></formula><p>which is in fact implied by (60). Furthermore, this notion of privacy can be strengthened by maximizing over database distributions, making it a stronger notion of privacy than differential privacy.</p><p>In spite of the additional strength of this privacy metric (especially when removing the Bayesian prior assumption by maximizing over the database distribution), this is not nearly as pessimistic as free-lunch privacy. As a comparison, the chain rule of mutual information (Property 6) in this case implies that for any two disjoint index sets I and J ,</p><formula xml:id="formula_89">I(XI; Y |XJ ) ≤ |I| nats.<label>(62)</label></formula><p>Consequently,</p><formula xml:id="formula_90">I(X n ; Y ) ≤ n nats. (<label>63</label></formula><formula xml:id="formula_91">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Adversarial Privacy</head><p>Adversarial privacy <ref type="bibr" target="#b23">[23]</ref> does three things differently from differential privacy. First, it assumes a prior distribution PXn on the database (like Bayesian differential privacy). Second, it does not restrict attention to neighboring database instances (like free-lunch privacy). Third, it asymmetrically requires</p><formula xml:id="formula_92">ln dP X n |Y =y dPXn ≤ ∀y ∈ Y. (<label>64</label></formula><formula xml:id="formula_93">)</formula><p>The idea is that the adversary can not increase certainty about a particular database value by much, even while other database values may be eliminated. Since mutual information is the expected value of the quantity on the left of (64), it is clear that adversarial privacy implies</p><formula xml:id="formula_94">I(X n ; Y ) ≤ nats. (<label>65</label></formula><formula xml:id="formula_95">)</formula><p>Thus, adversarial privacy has similarity to free-lunch privacy, though in the Bayesian setting. The subtleties of the asymmetric constraint are not captured in this MI-DP variant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RÉNYI ENTROPY GENERALIZATION</head><p>The notion of α-mutual-information is the generalization of mutual information using Rényi information measures. There are many proposed ways to accomplish such a generalization. Here we adopt Sibson's proposal (see <ref type="bibr" target="#b24">[24]</ref>):</p><formula xml:id="formula_96">I s α (X; Y ) = min Q Y Dα(P Y |X QY |PX ), (<label>66</label></formula><formula xml:id="formula_97">)</formula><p>where Dα is the conditional Rényi divergence of order α and the minimization is over all distributions QY on Y. Shannon's mutual information corresponds to α = 1.</p><p>A simple upper bound holds for α-mutual information for all α ≥ 0, given in the following lemma.</p><p>Lemma 4 (α-mutual-information upper bound). If a randomized mechanism P Y |X n satisfies -DP, then for all α ≥ 0, i, and instances of the remainder of the database x -i , sup</p><formula xml:id="formula_98">P X i I s α (Xi; Y |X -i = x -i ) ≤ nats.<label>(67)</label></formula><p>Proof. Let α ≥ 0, i, and PXn be arbitrary. In order to abbreviate notation, denote the event {X -i = x -i } as U . Pick an arbitrary xi ∈ Xi,</p><formula xml:id="formula_99">I s α (Xi; Y |U ) = min Q Y Dα(P Y |X i ,U QY |P X i |U ) ≤ Dα(P Y |X i ,U P Y |X i =x i ,U |P X i |U ) = Dα(P Y |X i ,U P X i |U P Y |X i =x i ,U P X i |U ) = 1 α -1 log E dP Y |X i ,U P X i |U dP Y |X i =x i ,U P X i |U (Y * , X * ) α-1 = 1 α -1 log E dP Y |X i ,U dP Y |X i =x i ,U (Y * , X * ) α-1 ,<label>(68)</label></formula><p>where (Y * , X * ) ∼ P Y |X i ,U P X i |U .</p><p>For α = 1, the -DP constraint implies that</p><formula xml:id="formula_100">dP Y |X i U dP Y |X i =x i ,U ≤</formula><p>e for all values of Xi, thus</p><formula xml:id="formula_101">I s α (Xi; Y |U ) ≤ 1 α -1 log E[e ] α-1 = nats. (<label>69</label></formula><formula xml:id="formula_102">)</formula><p>For the case α = 1, the α-mutual-information reduces to Shannon's mutual information, and we have</p><formula xml:id="formula_103">I s α (Xi; Y |U ) = I(Xi; Y |U ) ≤ from Lemma 1.</formula><p>Combining Property 7 with the proof of Lemma 4 gives the following corollary: Corollary 6. If the mechanism P Y |X n satisfies -DP, then sup</p><formula xml:id="formula_104">P X n I s α (X n ; Y ) ≤ n nats.<label>(70)</label></formula><p>Furthermore, for α &gt; 0, when maximizing over database distributions PXn , all three notions of α-mutual-information discussed in <ref type="bibr" target="#b24">[24]</ref> are equivalent. Thus, sup</p><formula xml:id="formula_105">P X n I s α (X n ; Y ) = sup P X n I a α (X n ; Y ) = sup P X n I c α (X n ; Y ) ≤ n nats.</formula><p>(71) In <ref type="bibr" target="#b3">[3]</ref> and <ref type="bibr" target="#b4">[4]</ref>, the information leakage is defined as</p><formula xml:id="formula_106">I∞(X n ; Y ) = H∞(X n ) -H∞(X n |Y ) (72)</formula><p>where</p><formula xml:id="formula_107">H∞(X n |Y ) = -log E max x n P X n |Y (x n |Y ) .<label>(73)</label></formula><p>This definition matches Arimoto's proposal I a ∞ (X n ; Y ), so it is a special case of (71). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conference on</head><formula xml:id="formula_108">≈ Q. (<label>74</label></formula><formula xml:id="formula_109">)</formula><p>As stated in <ref type="bibr" target="#b7">(7)</ref>, this gives</p><formula xml:id="formula_110">ln dP dQ (a) ≤ ∀a ∈ Ω,<label>(75)</label></formula><p>which is equivalent to</p><formula xml:id="formula_111">dP dQ (a) ∈ e -, e ∀a ∈ Ω. (<label>76</label></formula><formula xml:id="formula_112">)</formula><p>Consider that</p><formula xml:id="formula_113">D(P Q) = dP (a) ln dP dQ (a) = dQ(a) dP dQ (a) ln dP dQ (a) = E dP dQ (X) ln dP dQ (X) ,<label>(77)</label></formula><p>where X ∼ Q.</p><p>Let us define the random variable Z = dP dQ (X). We know the following facts:</p><p>Z ∈ e -, e w.p. 1, (78)</p><formula xml:id="formula_114">E[Z] = 1,<label>(79)</label></formula><formula xml:id="formula_115">D(P Q) = E[Z ln Z].<label>(80)</label></formula><p>Since the function f (x) = x ln x for x &gt; 0 is convex, we know that a distribution of Z that maximizes D(P Q) under these constraints places all mass at the endpoints of the allowed support interval. Therefore, maximum D(P Q) occurs with the following choice of distribution for Z: Z = e , w.p. </p><p>A computation of E[Z ln Z] gives the desired result. This extreme is achieved by a symmetric pair of binary distributions, consistent with the distribution of Z derived above. Thus, coincidentally, for this choice of extreme distributions that maximize D(P Q), it turns out that D(P Q) = D(Q P ).</p><p>The relaxation in Property 1 can be arrived at by making the following observation:</p><formula xml:id="formula_117">(e -1) 1 -e - (e -1) + (1 -e -) ≤ 1 -e - ≤ min , 2 .<label>(82)</label></formula><p>Other bounds in the literature (Lemma III.2 of <ref type="bibr" target="#b14">[14]</ref> and Theorem 1 of <ref type="bibr" target="#b10">[10]</ref>), while slightly loose, establish that ( , 0)closeness implies an upper bound of roughly 2 nats of Kullback-Leibler divergence for small , which is only off by a factor of two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. PROOF OF PROPERTY 3</head><p>Assume the P and Q are ( , δ)-close. To show that they are ( , δ )-close, we must show that for any A ∈ F</p><formula xml:id="formula_118">P (A) ≤ δ + e Q(A),<label>(83)</label></formula><formula xml:id="formula_119">Q(A) ≤ δ + e P (A).<label>(84)</label></formula><p>By symmetry, we need only argue (83). We will build the proof from two inequalities. The first is a direction application of (5):</p><formula xml:id="formula_120">P (A) ≤ δ + e Q(A). (<label>85</label></formula><formula xml:id="formula_121">)</formula><p>The second is an application of ( <ref type="formula" target="#formula_6">6</ref>) to the complement of A, denoted as A c :</p><formula xml:id="formula_122">Q(A c ) ≤ δ + e P (A c ). (<label>86</label></formula><formula xml:id="formula_123">)</formula><p>By substituting P (A c ) = 1 -P (A) and</p><formula xml:id="formula_124">Q(A c ) = 1 -Q(A)</formula><p>and rearranging, this implies</p><formula xml:id="formula_125">P (A) ≤ 1 -e -(1 -δ) + e -Q(A).<label>(87)</label></formula><p>Now we complete the proof with some simple manipulations and by substituting the value δ</p><formula xml:id="formula_126">= 1 - e +1 (1-δ) e +1</formula><p>stated in Property 3. From (85) we can conclude</p><formula xml:id="formula_127">P (A) ≤ δ + e Q(A) = δ + e Q(A) + (δ -δ ) + e -e Q(A) = δ + e Q(A) + e -e Q(A) - 1 -δ e + 1 .<label>(88)</label></formula><p>From (87) we have</p><formula xml:id="formula_128">P (A) ≤ 1 -e -(1 -δ) + e -Q(A) = δ + e Q(A) + 1 -e -(1 -δ) -δ + e --e Q(A) = δ + e Q(A) + e -e - 1 -δ e + 1 -Q(A) .<label>(89)</label></formula><p>If Q(A) ≤ 1-δ e +1 then (88) establishes (85), since ≥ ≥ 0. Otherwise, (89) establishes (85).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. PROOF OF LEMMA 2</head><p>According to the arguments immediately following Lemma 2, we only need to show that the claim holds for randomized mechanisms P Y |X that have binary input and binary output. That is,</p><formula xml:id="formula_129">|X | = |Y| = 2.</formula><p>Start by assuming that the randomized mechanism P Y |X satisfies -MI-DP. Since X is a database with only one entry, -MI-DP simply means max</p><formula xml:id="formula_130">P X I(X; Y ) ≤ nats. (<label>90</label></formula><formula xml:id="formula_131">)</formula><p>Notice that the left side is the expression for channel capacity from information theory, where P Y |X would be interpreted as a communication channel. With this interpretation, what we are trying to show is that a bound on the channel capacity for binary channels implies a total variation bound between the conditional output distributions. It has already been argued that binary channels contain the extreme cases, since total variation can be expressed as an inequality relating probabilities of a single arbitrary set (in general, the form of ( <ref type="formula" target="#formula_5">5</ref>) and ( <ref type="formula" target="#formula_6">6</ref>) gives this conclusion). The next step is to show, specifically for total variation, that binary symmetric channels are the extreme cases. Because X and Y are binary, the channel P Y |X can be parametrized with two parameters:</p><formula xml:id="formula_132">a P[Y = 1|X = 0], (<label>91</label></formula><formula xml:id="formula_133">) b P[Y = 1|X = 1].<label>(92)</label></formula><p>Now consider the complementary channel P Ỹ | X , where X = X ⊕ 1 and Ỹ = Y ⊕ 1, with ⊕ representing addition modulo 2. This gives</p><formula xml:id="formula_134">P Ỹ = 1 X = 0 = 1 -b,<label>(93)</label></formula><formula xml:id="formula_135">P Ỹ = 1 X = 1 = 1 -a.<label>(94)</label></formula><p>Finally, define a new binary channel, denoted P Ŷ | X , which is a convex combination of the original channel and the complementary channel. Then,</p><formula xml:id="formula_136">P Ŷ = 1 X = 0 = 1 2 + a -b 2 ,<label>(95)</label></formula><formula xml:id="formula_137">P Ŷ = 1 X = 1 = 1 2 - a -b 2 .<label>(96)</label></formula><p>Notice that for all three channels, P Y |X , P Ỹ | X , and P Ŷ | X , the total variation between the two conditional output distributions is the same:</p><formula xml:id="formula_138">P Y |X=0 -P Y |X=1 T V = P Ỹ | X=0 -P Ỹ | X=1 T V = P Ŷ | X=0 -P Ŷ | X=1 T V = |a -b|.<label>(97)</label></formula><p>On the other hand, channel capacity is a convex function of the channel parameters. By symmetry, P Y |X and P Ỹ | X have the same capacity. Therefore, the convex combination P Ŷ | X , which is a binary symmetric channel, has a lower capacity. Thus, binary symmetric channels are the extreme points in the trade-off between capacity and total variation. For every binary channel, there is a binary symmetric channel with the same capacity but with greater or equal total variation distance between the conditional output distributions. Finally, we arrive at Lemma 2 by applying the formula for channel capacity of a binary symmetric channel. If we denote by δ the total variation distance between the conditional output distributions, then the cross-over probability is 1  2 -δ 2 . The channel capacity is then</p><formula xml:id="formula_139">C = ln 2 -h 1 2 - δ 2 nats,<label>(98)</label></formula><p>where h(•) is the binary entropy function in nats. Inverting this equation gives (28). The relaxed bound in ( <ref type="formula" target="#formula_38">27</ref>) is established by the fact that the second order Tailor expansion of h(x) about x = 1  2 is in fact an upper bound:</p><formula xml:id="formula_140">h(x) ≤ ln 2 -2 x - 1 2 2 . (<label>99</label></formula><formula xml:id="formula_141">)</formula><p>An alternative simple argument directly arrives at the looser bound in (27), without even reducing to the binary case. We again refer to the geometric interpretation of capacity as the radius of the information ball <ref type="bibr" target="#b8">[8,</ref><ref type="bibr">Theorem 13.1.1]</ref>. By Pinsker's inequality (Property 2), each conditional output distribution is within total variation distance 2 of the center of the information ball. The triangle inequality gives (27).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. PROOF OF LEMMA 3</head><p>Assume that the randomized mechanism P Y |X n is (δ)-DP, and let i ∈ {1, . . . , n} and PXn be arbitrary.</p><p>Two proof arguments are needed, one based on the database entries {Xi} having a finite set of possible values, and the other based on the same for the query response Y . In both cases, however, we first note that the conditional mutual information I(Xi; Y |X -i ) is an expected value over instances of X -i . We provide bounds that uniformly hold for each instance of x -i . To that end, fix x -i arbitrarily, and let ( X, Ỹ ) ∼ P X i ,Y |X -i =x -i . This gives, I(Xi; Y |X -i = x -i ) = I( X; Ỹ ).</p><p>(100)</p><p>Notice further that any two databases in the set {x n :</p><p>x-i = x -i } are neighbors according to Definition 3. Therefore, by assumption,</p><formula xml:id="formula_142">P Ỹ | X=x 1 (0,δ) ≈ P Ỹ | X=x 2<label>(101)</label></formula><p>for any two values x1 and x2. We now aim to bound I( X; Ỹ ). Consider first the case where |Y| &lt; ∞. By construction, | Ỹ| = |Y|.</p><p>From (101) we can claim that for any value x</p><formula xml:id="formula_143">P Ỹ | X=x (0,δ) ≈ P Ỹ .<label>(102)</label></formula><p>This is justified by letting X ∼ P X and noting</p><formula xml:id="formula_144">P Ỹ | X=x -P Ỹ T V = P Ỹ | X=x -E P Ỹ | X=X T V ≤ E P Ỹ | X=x -P Ỹ | X=X T V ≤ δ,<label>(103)</label></formula><p>where the first inequality is due to Jensen's inequality and the convexity of the total variation distance.</p><p>Next we decompose mutual information into entropy terms:</p><formula xml:id="formula_145">I( X; Ỹ ) = H( Ỹ ) -H( Ỹ | X).<label>(104)</label></formula><p>Finally, a continuity property of entropy found in <ref type="bibr">[27]</ref> (see (4) within), derived from optimal coupling and Fano's inequality, bounds the difference in entropy as a function of total variation distance and | Ỹ|. Combining this with ( <ref type="formula" target="#formula_143">102</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Corollary 3 (</head><label>3</label><figDesc>Sequential queries). If several query responses {Y1, . . . , Y k } are produced in sequence, and each mechanism P Y j |X n ,Y j-1 satisfies j -MI-DP individually, then as a collection P Y k |X n satisfies j j -MI-DP. The next claim is about query responses that each depend on different subsets of the database. Corollary 4 (Partial queries). If several query responses {Y1, . . . , Y k } are produced conditionally independently of each other from disjoint subsets of the database entries, denoted as XI 1 , . . . , XI k , with each mechanism P Y j |X I j satisfying -MI-DP individually, then as a collection P Y k |X n also satisfies -MI-DP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Example 5 .</head><label>5</label><figDesc>Consider a database with two entries, X1 and X2, which are real valued. The randomized mechanism P Y |X 1 ,X 2 produces an output Y which can be a real number or one of two special values e1 or e2. The behavior of the mechanism is best described in two cases: If X1 = X2: Y = X1, with probability , e1, with probability 1 -. (48) If X1 = X2: Y = e2, with probability , e1, with probability 1 -.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) and (104) givesI( X; Ỹ ) ≤    h(δ) + δ ln | Ỹ| -1 , δ ≤ | Ỹ|-1 | Ỹ| , ln | Ỹ|, δ &gt; | Ỹ|-1 | Ỹ| (105) ≤ h(δ) + δ ln | Ỹ| nats.(106)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Communication, Control, and Computing (Allerton), pages 1086-1092, Sept 2014. [26] B. Yang, I. Sato, and H. Nakagawa. Bayesian differential privacy on correlated data. In SIGMOD International Conference on Management of Data,</figDesc><table><row><cell cols="2">pages 747-762. ACM, 2015.</cell></row><row><cell cols="2">[27] Z. Zhang. Estimating mutual information via</cell></row><row><cell cols="2">kolmogorov distance. IEEE Transactions on</cell></row><row><cell cols="2">Information Theory, 53(9):3280-3282, 2007.</cell></row><row><cell>APPENDIX</cell><cell></cell></row><row><cell cols="2">A. PROOF OF PROPERTY 1</cell></row><row><cell>Assume that</cell><cell></cell></row><row><cell>P</cell><cell>( ,0)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1-e - e -e -, e -, w.p. e -1e -e -.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Differential privacy does not assume the adversary has any computational limitation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Another similar definition for "neighbor" exists in the literature, involving the removal of one entry of the database.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The other direction is not true in general, as there exist mechanisms which satisfy -MI-DP but not -DP for any .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>This approach, using worst-case database distribution, appears in various works throughout the literature, e.g.<ref type="bibr" target="#b11">[11]</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGEMENTS</head><p>This work was supported by the Air Force Office of Scientific Research (grant FA9550-15-1-0180) and the National Science Foundation (grant CCF-1350595).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Next we consider the case where maxi |Xi| &lt; ∞. By construction, | X | ≤ maxi |Xi|.</p><p>For this case, we take (102) a bit further. In fact, P X, Ỹ (0,δ)</p><p>This is justified by letting X ∼ P X and noting</p><p>This time we decompose mutual information in the reverse direction:</p><p>To complete the proof we need a continuity argument for condition entropy. The following lemma is inspired by ideas from <ref type="bibr" target="#b7">[7]</ref> which in turn come from <ref type="bibr" target="#b2">[2]</ref>.</p><p>Lemma 5 (Continuity of conditional entropy). If P and Q are two distributions on U × V with |U | &lt; ∞, then</p><p>Proof. Since the bound in the lemma is monotonic in δ, we assume without loss of generality that</p><p>We first translate closeness in total variation distance to the existence of a common distribution that is close to both relative to the boundaries of the set of probability distributions. To be more precise, there exists a probability distribution p * which is a convex combination of P and another probability distribution, with most of the convex weight on P , and the same relationship holds between p * and Q. That is:</p><p>Once we have established this existence, the exact construction of p * , p, and q will have no consequence on the conclusion.</p><p>Consider the Hahn decomposition of the signed measure P -Q into positive and negative parts that are mutually singular, represented by the non-negative measures µ + and µ -, as follows:</p><p>The total measure of each part, µ + and µ -, is the total variation between P and Q, which is δ. Thus, to normalize µ + and µ -to become probability measures, we must divide by δ.</p><p>Then we have that p * is the greater part of P and Q, normalized as</p><p>which satisfies both (112) and ( <ref type="formula">113</ref>).</p><p>Next, to complete the proof, we show that</p><p>By symmetry, an argument for only one of the inequalities is needed.</p><p>The following bound is aided by defining a binary random variable B ∼ Bern δ The proof of Lemma 3 is completed by applying Lemma 5 with P X, Ỹ as P and P X P Ỹ as Q, due to (107). Combined with (109) this gives</p><p>≤ 2h(δ) + 2δ ln | X | + 1 nats. (127)</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Security-control methods for statistical databases: A comparative study</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Worthmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="515" to="556" />
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Continuity of quantum conditional information</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fannes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">L55</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Differential privacy: on the trade-off between utility and information leakage</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Alvim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Andrés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chatzikokolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Degano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Palamidessi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Aspects of Security and Trust</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="39" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Information-theoretic bounds for differentially private mechanisms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Köpf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th Computer Security Foundations Symposium (CSF)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="191" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic security for the wiretap channel</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tessaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology-CRYPTO</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="294" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A learning theory approach to noninteractive database privacy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ligett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the continuity of the secrecy capacity of compound and arbitrarily varying wiretap channels</title>
		<author>
			<persName><forename type="first">H</forename><surname>Boche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2531" to="2546" />
			<date type="published" when="2015-12">Dec 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lower bounds in differential privacy</title>
		<author>
			<persName><forename type="first">A</forename><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Cryptography</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="321" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Local privacy and statistical minimax rates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">54th Annual Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="429" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Privacy aware learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2014-12">Dec. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<title level="m">Differential privacy. Automata, Languages and Programming</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Our data, ourselves: Privacy via distributed noise generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology-EUROCRYPT</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="486" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Boosting and differential privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010-10">Oct 2010</date>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A multiplicative weights mechanism for privacy-preserving data analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010-10">Oct 2010</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Conservative or liberal? personalized differential privacy</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st International Conference on Data Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-04">April 2015</date>
			<biblScope unit="page" from="1023" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The composition theorem for differential privacy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Viswanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">No free lunch in data privacy</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Machanavajjhala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD Int&apos;l. Conference on Management of data</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="193" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Resolvability in eγ with applications to lossy compression and wiretap channels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cuff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verdú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l. Symp. on Information Theory (ISIT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="755" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The limits of two-party differential privacy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcgregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Privacy integrated queries: an extensible platform for privacy-preserving data analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Mcsherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD International Conference on Management of data</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Channel coding rate in the finite blocklength regime</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Polyanskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verdú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2307" to="2359" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Relationship privacy: output perturbation for queries with joins</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">α-mutual information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Verdú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Theory and Applications Workshop</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">On the relation between identifiability, differential privacy, and mutual-information privacy</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In 52nd Annual Allerton</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
