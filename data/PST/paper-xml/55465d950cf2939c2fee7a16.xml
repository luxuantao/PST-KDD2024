<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Matrix Completion for Weakly-Supervised Multi-Label Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ricardo</forename><surname>Cabral</surname></persName>
							<email>rscabral@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">ISR</orgName>
								<orgName type="institution">Instituto Superior T ecnico</orgName>
								<address>
									<settlement>Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fernando</forename><surname>De La Torre</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Robotics Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jo</forename><surname>Ão</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paulo</forename><surname>Costeira</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Bernardino</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Matrix Completion for Weakly-Supervised Multi-Label Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">71B29544464B73B72CF33FC03F002E17</idno>
					<idno type="DOI">10.1109/TPAMI.2014.2343234</idno>
					<note type="submission">received 24 Jan. 2013; revised 24 Apr. 2014; accepted 3 June 2014. Date of publication 25 July 2014; date of current version 5 Dec. 2014.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Weakly-supervised learning</term>
					<term>multi-label image classification</term>
					<term>segmentation</term>
					<term>rank minimization</term>
					<term>nuclear norm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the last few years, image classification has become an incredibly active research topic, with widespread applications. Most methods for visual recognition are fully supervised, as they make use of bounding boxes or pixelwise segmentations to locate objects of interest. However, this type of manual labeling is time consuming, error prone and it has been shown that manual segmentations are not necessarily the optimal spatial enclosure for object classifiers. This paper proposes a weakly-supervised system for multi-label image classification. In this setting, training images are annotated with a set of keywords describing their contents, but the visual concepts are not explicitly segmented in the images. We formulate the weakly-supervised image classification as a low-rank matrix completion problem. Compared to previous work, our proposed framework has three advantages: (1) Unlike existing solutions based on multiple-instance learning methods, our model is convex. We propose two alternative algorithms for matrix completion specifically tailored to visual data, and prove their convergence. (2) Unlike existing discriminative methods, our algorithm is robust to labeling errors, background noise and partial occlusions. (3) Our method can potentially be used for semantic segmentation. Experimental validation on several data sets shows that our method outperforms state-of-the-art classification algorithms, while effectively capturing each class appearance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>W ITH the ever-growing amount of digital image data in multimedia databases, there is a great need for algorithms that can provide effective semantic indexing. Attributing keywords to digital images, however, is the quintessential example of a challenging classification problem. Several aspects contribute to the difficulty of this problem, including the large variability in appearance, illumination and pose any object class can exhibit. To add to this complexity, natural images often depict many objects rather than a single one. In this multi-label setting, the interaction between objects needs to be modeled so classifiers can discern between co-occurring concepts. To address this issue, standard discriminative approaches such as support vector machines (SVMs) or Linear Discriminant Analysis have been extended to the multi-label case <ref type="bibr" target="#b0">[1]</ref>. A major limitation of these approaches, however, is that the location for objects of interest has to be known in the training images, usually in the form of bounding boxes or a full-blown pixelwise segmentation. While efforts have been made to provide data sets with this information <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, manual labeling is still labor intensive, subjective and an error prone process. Moreover, it has been shown that manual segmentations are not necessarily the optimal spatial enclosure for object classifiers <ref type="bibr" target="#b3">[4]</ref>. To cope with an increasing number of concepts and larger scale data sets, there has been an increased interest in transitioning away from these fully supervised approaches.</p><p>Weakly-supervised algorithms <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> relieve the labeling burden by learning from simpler labels. Fig. <ref type="figure">1</ref> illustrates this setting and the problem we address in this paper: given a weakly-labeled training set (Fig. <ref type="figure">1a</ref>), we segment and label new test images (Fig. <ref type="figure">1b</ref>). Several multiple instance learning (MIL) methods <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> have been proposed in the literature for solving this type of weakly supervised learning problem. However, existing MIL methods have three major drawbacks: <ref type="bibr" target="#b0">(1)</ref> The MIL problem is usually cast as a NP-hard binary quadratic problem <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Most existing algorithms to solve MIL lead to non-convex models and consequently are highly sensible to initialization. Moreover, the extension of MIL to the multi-label case is not trivial. Current multi-label MIL approaches <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> heavily rely on an explicit enumeration of instances, which are then solved by single class MIL or Multi-label learning.</p><p>(2) They lack robustness to outliers. Recall that most discriminative approaches project data directly onto linear or non-linear spaces <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Thus, a single outlier can bias the solution, severely degrading classification performance. <ref type="bibr" target="#b2">(3)</ref> It is unclear how existing MIL approaches can be extended to use partial information, such as incomplete label assignments or missing feature descriptions. For instance, in Fig. <ref type="figure">1a</ref> one training image has no label for the category grass.</p><p>We observe that the image classification and localization problem has more structure than the one exploited by MIL problems. MIL approaches consider images as bags with many instances denoting possible regions of interest.</p><p>A major contribution of our work is to instead make use of the additive property of histogram representations such as bag of words (BOWs) <ref type="bibr" target="#b13">[14]</ref>: the histogram of an entire image is a weighted sum of the histogram information of all of its subparts. Using this property, we bypass the combinatorial nature of finding desired regions in every positive image. Instead, the main aim of our algorithm is to factorize the histogram of an image as a weighted sum of class histograms (as many as objects are present) plus an error to model the background. Fig. <ref type="figure">2</ref> shows an illustration of the histogram factorization for one training image. By using this property, image classification can be posed as a rank minimization problem, since class histograms are shared across images, and the number of class histograms is small compared to the number of images. This paper proposes to cast the weakly supervised multi-label image classification problem under a matrix completion framework. Contrary to typical MIL approaches, ours is fueled by recent advances in rank minimization <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> and therefore is convex. Fig. <ref type="figure">3</ref> illustrates the main idea of the paper. Each column of Z obs has a concatenation of the labels (1 if the class is present and zero otherwise) and the histogram h tr i for one training image (Fig. <ref type="figure">3a</ref>). In the test set (Fig. <ref type="figure">3b</ref>), labels are unknown and denoted as question marks ð?Þ. Our method fills the unknown entries and corrects known features and labels such that Z has the smallest rank possible. It can also infer the feature descriptor of a particular class (Fig. <ref type="figure">3c</ref>). This is achieved by looking for the unknown histograms whose label vector denotes the presence of only this class. In doing so, we obviate the need for training with precise localization or expensive combinatorial MIL models, as required by previous methods. To summarize, the main contributions of this work are threefold: 1) We show the advantages of matrix completion over classic discriminative approaches for image classification. By performing classification under this inherently multi-label paradigm, we can easily cope with missing information as well as outliers in both the feature and the label space. We present comparisons on several data sets that show how these properties lead to a classification improvement over state-ofthe-art methods; 2) We exploit the additive nature of histogram features.</p><p>Since histograms of images are sums of their subparts, a rank minimization criteria allows for learning latent individual representations for all classes in the data set. Thus, we can recover the localization information without the need for fully supervised training or MIL. We show empirical validation that our approach is able to associate the semantic concepts with regions in images; 3) We propose two new convex rank minimization algorithms, MC-Pos and MC-Simplex, motivated by the multi-label image classification problem and the additive histogram property. We prove that these enjoy the same convergence properties of fixed point continuation (FPC) methods for rank minimization without constraints. A preliminary version of this work was published in <ref type="bibr" target="#b16">[17]</ref>. This section reviews related image classification work and provides a brief survey on the use of the nuclear norm as a surrogate for rank minimization problems in computer vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Image Classification</head><p>Since the seminal work of Barnard and Forsyth <ref type="bibr" target="#b17">[18]</ref>, many researchers have addressed the problem of associating words to images. Image semantic understanding is now typically formulated as a multi-label problem. In this setting, each image may be simultaneously assigned to more than one class. This is an important difference from multiclass classification, where classes are assumed to be independent and mutually exclusive. While multi-label can trivially be handled in multi-class approaches by dropping the mutual exclusivity constraint, Desai et al. <ref type="bibr" target="#b18">[19]</ref> have shown the need to model object interactions. Therefore, many multi-class techniques such as SVM and LDA have been modified to make use of label correlations to improve multilabel classification performance <ref type="bibr" target="#b0">[1]</ref>. In these approaches, localization is achieved by detection, using e.g., a sliding window. This is, however, at the expense of a fully supervised training set where localization is known a priori.</p><p>Several researchers have addressed the problem of classifying an image and providing precise class localization. Petridis et al. <ref type="bibr" target="#b19">[20]</ref> used a CRF to learn new class appearances from previously known ones obtained with supervised training. Blaschko and Lampert <ref type="bibr" target="#b20">[21]</ref> learned a supervised structured output regression where the outputs are coordinates of a bounding box enclosing the object. Jamieson et al. <ref type="bibr" target="#b6">[7]</ref> associated configurations of SIFT features to captions. Tighe and Lazebnik <ref type="bibr" target="#b21">[22]</ref> proposed lazy learning for large scale image parsing.</p><p>Alternatively to these approaches, multiple instance learning has surfaced as a reliable framework for performing learning in the presence of unknown latent factors. First proposed in <ref type="bibr" target="#b22">[23]</ref>, this class of learning problems extends the typical classification setting to the case where labels are no longer applied individually, but to multi-sets or "bags": a bag is labeled positive if at least one of its instances is positive and negative if none of its constituents are. In computer vision, this framework has been used for weakly supervised learning tasks such as learning deformable part models <ref type="bibr" target="#b11">[12]</ref> and to explicitly model the relations between labels and specific regions of the image, as initially proposed by Maron and Ratan <ref type="bibr" target="#b23">[24]</ref>.</p><p>This method allows for the localization and classification tasks to benefit from each other, thus reducing noise in the corresponding feature space and making the learned semantic models more accurate <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. Although promising, the MIL framework is combinatorial, so several approaches have been proposed to avoid local minima and deal with the prohibitive number of possible subregions in an image. Zha et al. <ref type="bibr" target="#b9">[10]</ref> made use of hidden CRFs while Vijayanarasimhan and Grauman <ref type="bibr" target="#b10">[11]</ref> recurred to multi-set kernels to emphasize instances differently. Yang et al. <ref type="bibr" target="#b7">[8]</ref> exploited asymmetric loss functions to balance false positives and negatives. These methods, however, require an explicit enumeration of instances in the image. This is usually obtained by breaking images in a small fixed number of segments or applied in settings where detectors perform well, such as the problem of associating faces to captioned names <ref type="bibr" target="#b26">[27]</ref>. On the other hand, to avoid explicitly enumerating the instances, Nguyen et al. <ref type="bibr" target="#b3">[4]</ref> coupled constraint generation algorithms with a branch and bound method for fast localization. This is also seen in the negative data-mining process of <ref type="bibr" target="#b11">[12]</ref>. Yakhnenko and Honavar <ref type="bibr" target="#b25">[26]</ref> proposed a MIL algorithm of linear complexity in the number of instances by using a non-convex Noisy-Or model. Multi-task learning has also been proposed as a way to regularize the MIL problem to avoid local minima due to many available degrees of freedom. In this setting, the MIL optimization is jointly learned with a fully supervised task <ref type="bibr" target="#b24">[25]</ref>.</p><p>To the best of the authors' knowledge, the only work modeling MIL as a convex problem is by Li and Sminchisescu <ref type="bibr" target="#b12">[13]</ref>. They replace the classifier loss and the non-convex constraints on the positive bags by convex Fig. <ref type="figure">3</ref>. Our weakly supervised classification algorithm works by completing a matrix Z obs as shown above, where the question marks denote unknown entries. We complete this matrix such that it can be factorized into a low rank matrix Z and an error matrix E. This ensures that background distributions and feature/label outliers are captured in E, since they increase the rank of Z. In the training submatrix (a), the ith column concatenates the image histogram h tr i with its respective f0; 1g label assignments. Note that a partially labeled example such as the second training image (a) is trivially handled by our framework. In the test submatrix (b), the jth column is a concatenation of histogram h tst j with unknown assignments. In this transductive setting, the statistics of the test set are also used in the learning. By completing (c), we obtain a representative histogram for each class, in spite of their co-occurrence in the images.</p><p>alternatives (f-divergence family loss and class likelihood ratios for each instance). They show promising results over standard MIL formulations as the ratio of positive instances in positive bags increase. Unfortunately, this is not the setting in image classification, as the percentage of possible negative bounding boxes in an image largely exceeds that of the positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Nuclear Norm as a Surrogate for Rank Minimization</head><p>Rank minimization has recently received much attention due to its success in collaborative filtering problems such as the Netflix challenge. Rank minimization techniques have also been applied to minimum order control <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, to find least complex solutions achieving a performance measure.</p><p>A breakthrough by Cand es and Recht <ref type="bibr" target="#b14">[15]</ref> stated the minimization of the rank function, under broad conditions, can be achieved with the nuclear norm (sum of singular values). This result is a clear parallel with the results in <ref type="bibr" target="#b29">[30]</ref> for the ' 1 and ' 0 norms. Since the natural reformulation of the nuclear norm gives rise to a Semidefinite Program, off-the-shelf optimizers can only handle problems of limited size. Thus, several methods have been devised for its efficient <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref> and incremental <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref> optimization.</p><p>In the context of computer vision, the nuclear norm has been applied to several problems: Structure from motion <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, robust PCA <ref type="bibr" target="#b37">[38]</ref>, subspace clustering <ref type="bibr" target="#b38">[39]</ref>, segmentation <ref type="bibr" target="#b39">[40]</ref>, tag refinement <ref type="bibr" target="#b40">[41]</ref>, camera calibration <ref type="bibr" target="#b41">[42]</ref>.</p><p>The nuclear norm regularizer has been applied to classification tasks in e.g., <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>. Most of these approaches exploit the nuclear norm to enforce correlations between classifiers <ref type="bibr" target="#b46">[47]</ref> or to allow for dimensionality reduction <ref type="bibr" target="#b42">[43]</ref> in discriminative settings. Harchaoui et al. <ref type="bibr" target="#b46">[47]</ref> decomposed the nuclear norm into a surrogate infinite-dimensional optimization, allowing the feasibility of coordinate descent in large scale settings with smooth losses. Instead, we propose a generative approach based on <ref type="bibr" target="#b45">[46]</ref> that is able to decouple appearance descriptions of cooccurring classes, allows for a recovery of segments and thus localization in the images.</p><p>This work can also relate to Latent Semantic Analysis, as the low rank justifications provided in Section 3 are similar in nature to the ones provided for subspaces obtained from document-term matrices. Bosch et al. <ref type="bibr" target="#b47">[48]</ref> provided preliminary results that visual words associated with high probability to a given category can provide cues for localization. Our method, however, is not subject to local minima and estimates subspace ranks automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MATRIX COMPLETION FOR MULTI-LABEL CLASSIFICATION OF VISUAL DATA</head><p>This section describes the main contributions of this paper: We start by presenting the use of matrix completion for general classification tasks. Then, we describe its use for weakly supervised multi-label image classification and localization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Classification as a Matrix Completion Problem</head><p>In a supervised setting, a classifier learns a mapping (see footnote 1 for notation) W : X ! Y between the space of features X and the space of labels Y. This learning is done from a data set of N training tuples ðx tr i ;</p><formula xml:id="formula_0">y tr i Þ 2 R D Â R K ,</formula><p>where D is the feature dimension and K the number of classes. In particular, linear classifiers minimize a loss lðÁÞ between the output space and the projection of the input space, as</p><formula xml:id="formula_1">minimize W;b X N i¼1 l y tr i ; ½W &gt; b x tr i 1 ! ;<label>(1)</label></formula><p>where parameters W 2 R DÂK and b 2 R KÂ1 describe the class decision boundaries. After the training stage, these parameters are used to estimate unknown labels for test samples y tst j from their feature descriptors x tst j . This is typically done independently for each test entry, as</p><formula xml:id="formula_2">y tst j ¼ ½W &gt; b x tst j 1 ! :<label>(2)</label></formula><p>In this paper, we formulate the problem of jointly classifying M test samples as one of matrix completion. For this purpose, let us define the feature matrices X tr 2 R DÂN and X tst 2 R DÂM . These matrices respectively collect in each column feature vectors for N training and M test samples. Without loss of generality, the linear model assumed in (2) can be written in matrix form. Specifically, it states that Y tr 2 R KÂN , the matrix concatenating the labels for all training images, can be obtained by the linear combination</p><formula xml:id="formula_3">Y tr ¼ ½W &gt; b X tr À E tr X 1 &gt; ! À E tr Y ;<label>(3)</label></formula><p>where E Y tr and E X tr denote errors in the labels and features, respectively. The test labels Y tst 2 R KÂM are obtained as</p><formula xml:id="formula_4">Y tst ¼ ½W &gt; b X tst À E tst X 1 &gt; ! ;<label>(4)</label></formula><p>with no error in the labels since they are unknown.</p><p>Concatenating labels and features in ( <ref type="formula" target="#formula_3">3</ref>) and ( <ref type="formula" target="#formula_4">4</ref>) in one matrix yields</p><formula xml:id="formula_5">Z ¼ Y tr Y tst X tr X tst 1 &gt; 2 4 3 5 À E tr Y 0 E tr X E tst X 0 &gt; 2 4 3 5 ¼ Z obs À E;<label>(5)</label></formula><p>1. Bold capital letters denote matrices (e.g., D), bold lower-case letters represent column vectors (e.g., d). All non-bold letters denote scalar variables. d j is the jth column of the matrix D. d ij denotes the scalar in the row i and column j of D. hd 1 ; d 2 i denotes the inner product between two vectors d 1 and d 2 . jjdjj 2 2 ¼ hd; di ¼ P i d 2 i denotes the squared Euclidean Norm of the vector d. trðAÞ ¼ P i a ii is the trace of the matrix A. jjAjj Ã designates the nuclear norm (sum of singular values) of A.kAjj 2 F ¼ trðA &gt; AÞ ¼ trðAA &gt; Þ designates the squared Frobenius Norm of A. 1 k 2 R KÂ1 is a vector of ones, and e j 2 R KÂ1 denotes the jth canonical vector, with 1 at the jth position and zero otherwise. 0 KÂN 2 R KÂN is a matrix of zeros and I K 2 R KÂK denotes the identity matrix.</p><p>where Z obs 2 R ðKþDþ1ÞÂðMþNÞ holds all observed entries (with Y tst unknown) and E is a matrix of errors, also unknown.</p><p>Note that according to (3) and ( <ref type="formula" target="#formula_4">4</ref>), the matrix Z defined in ( <ref type="formula" target="#formula_5">5</ref>) is rank deficient. That is, the rows comprising the labels are linearly dependent on the feature rows. In the absence of error (E ¼ 0), the input matrix Z obs is also low rank, as</p><formula xml:id="formula_6">rankðZÞ ¼ rankðZ obs Þ ¼ rank X tr X tst 1 &gt; ! :<label>(6)</label></formula><p>In this case, we observe that (3) becomes</p><formula xml:id="formula_7">Y tr ¼ ½W &gt; b X tr 1 &gt; ! ;<label>(7)</label></formula><p>and thus the Y tst in (4) does not increase the rank of Z, since</p><formula xml:id="formula_8">Y tst ¼ ½W &gt; b X tst 1 &gt; ! :<label>(8)</label></formula><p>Using this result, Goldberg et al. <ref type="bibr" target="#b45">[46]</ref> suggested that unknown test labels in Y tst can be recovered by completing these entries such that the rank of Z is minimized. This can be written as minimize</p><formula xml:id="formula_9">Y tst rankðZÞ subject to Z ¼ Y tr Y tst X tr X tst 1 &gt; 2 6 4 3 7 5:<label>(9)</label></formula><p>In practice E 6 ¼ 0, so we modify (9) to include <ref type="bibr" target="#b4">(5)</ref>. To avoid trivial solutions, we penalize errors with a loss lðÁÞ, as minimize</p><formula xml:id="formula_10">Y tst ;E tr Y ;E X rankðZÞ þ lðEÞ subject to Z ¼ Y tr Y tst X tr X tst 1 &gt; 2 6 4 3 7 5 À E tr Y 0 E X 0 &gt; 2 6 4 3 7 5;<label>(10)</label></formula><p>where is a tradeoff parameter and E</p><formula xml:id="formula_11">X ¼ E tr X E tst X Â Ã</formula><p>. We discuss the choices of loss functions lðÁÞ in detail in Section 3.4.</p><p>There are three fundamental advantages in casting a general classification problem as the matrix completion in <ref type="bibr" target="#b9">(10)</ref>.</p><p>First, it bypasses the estimation of the model parameters W and b. This allows our formulation to estimate errors in the features E X . Parametric models that estimate W and b (such as linear regression or SVMs) do not model this error, and thus implicitly assume E X ¼ 0. Note that the product W &gt; E X in (3) will result in a nonconvex problem when both W and E X are considered as optimization variables. While <ref type="bibr" target="#b9">(10)</ref> is also non-convex, we show in Section 3.3 that a convex relaxation exists, backed by the recent advances in rank minimization.</p><p>Second, errors and missing data in features and labels are estimated jointly.</p><p>Third, we minimize the rank of Z, containing training and test samples. This transductive setting allows the model to leverage the statistics of the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Image Classification as Matrix Completion</head><p>In spite of justifying the applicability of matrix completion as a generic classification framework, the explanation provided by Goldberg et al. <ref type="bibr" target="#b45">[46]</ref> described in Section 3.1 only spans the row space of Z. In this section, we provide an alternative explanation for the low rank of Z in (5), based instead on its column space. Let us assume the case when histograms are used as feature vectors. Note that several popular techniques for obtaining global representations of images in computer vision, such as bag of words or HOG, fall under this assumption. Let h i denote such a histogram representation for image i. In this case, the feature submatrix X ¼ ½X tr X tst in (5) contains one histogram per column, as</p><formula xml:id="formula_12">X ¼ h tr 1 . . . h tr N j h tst 1 . . . h tst M Â Ã :<label>(11)</label></formula><p>One property of image histograms is that they can be represented by a sum of the histograms of its segments (see Fig. <ref type="figure">2</ref>). Without loss of generality, we consider these latent histograms as C k 2 R DÂN k , the N k canonical histogram representations for class k. Therefore, we have that the histogram of image i can be written as a sum of class representatives C k weighted by coefficients a k;i 2 R N k Â1 , as</p><formula xml:id="formula_13">h i ¼ X k C k a k;i þ E X i ;<label>(12)</label></formula><p>where E X i collects errors (e.g., words in the background that do not pertain to any class). If we concatenate the representatives C k in the matrix</p><formula xml:id="formula_14">C ¼ C 1 C 2 . . . C K ½ ;<label>(13)</label></formula><p>and collect weights a k;i in a matrix A we can write <ref type="bibr" target="#b10">(11)</ref> as</p><formula xml:id="formula_15">X ¼ CA þ E X :<label>(14)</label></formula><p>Additionally, since we postulated each c k j as belonging to only class k, the correspondent label matrix for C is given by</p><formula xml:id="formula_16">Y C ¼ Â e 1 1 &gt; N 1 . . . e K 1 &gt; N K Ã ;<label>(15)</label></formula><p>where e i denotes the ith canonical vector. Merging ( <ref type="formula" target="#formula_12">11</ref>) and ( <ref type="formula" target="#formula_16">15</ref>), we obtain the data matrix Z obs in (5) as</p><formula xml:id="formula_17">Z obs ¼ Y C C ! A þ E Y E X ! ¼ Z þ E;<label>(16)</label></formula><p>the sum of a low rank component matrix Z with an error matrix E. A close inspection of ( <ref type="formula" target="#formula_17">16</ref>) allows us to state that Z obs is low rank also due to its column space, in absence of background noise, since class histograms are shared across images and therefore</p><formula xml:id="formula_18">P k N k &lt; N þ M.</formula><p>Additionally, it allows for the observation that the appearance of individual classes can be recovered from a multi-label data set by estimating C. In this paper, we assume that for localization purposes, each class can be well represented by a single histogram. In this case, <ref type="bibr" target="#b14">(15)</ref> becomes Y C ¼ I K , and therefore our approach can obtain an estimate of C by completing in Z obs the features correspondent to the canonical labels (see Fig. <ref type="figure">3c</ref>). By directly estimating C, we are able to recover the appearance of each class and thus provide the localization for each concept in the images. This is done despite the weakly supervised setting and bypassing the combinatorial nature of searching for bounding boxes such as in MIL problems. Also, note that this assumption is not used in the classification, where our algorithm estimates class subspace dimensions automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Nuclear Norm as a Convex Surrogate of the Rank Function</head><p>Since the rank is a highly non-convex and non-differentiable function, it is nontrivial to minimize. Therefore, we relax (10) by using the convex envelope of the rank function, the nuclear norm. Let Z ¼ USV &gt; be the SVD of Z.</p><p>The nuclear norm is defined as trðSÞ, the sum of singular values of Z. It has been shown that under general assumptions of low coherence of the singular vectors of Z, minimizers obtained using the nuclear norm are equal to minimizers of rank with high probability <ref type="bibr" target="#b14">[15]</ref>. Therefore, we rewrite <ref type="bibr" target="#b9">(10)</ref> as</p><formula xml:id="formula_19">minimize Y tst ;E Y tr ;E X kZk Ã þ lðEÞ subject to Z ¼ Y tr Y tst X tr X tst 1 &gt; 2 6 4 3 7 5 À E tr Y 0 E X 0 &gt; 2 6 4 3 7 5:<label>(17)</label></formula><p>We provide a simple intuition as to why this norm is in fact the largest possible convex underestimator of the rank function: Since the singular values of matrices are always positive, the nuclear norm can be interpreted as an ' 1 -norm of the singular values. Under this interpretation, one can easily identify it as the convex envelope of the rank function, since the latter is the cardinality (or ' 0 -norm) of the singular values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Toy Example</head><p>To understand why the singular value sparsity induced by the nuclear norm is important for the matrix completion in <ref type="bibr" target="#b16">(17)</ref>, consider completing a rank-1 matrix</p><formula xml:id="formula_20">Z ¼ 1 1 1 1 1 ? ! ;<label>(18)</label></formula><p>where only one entry z 2;3 is unknown. The results shown in Fig. <ref type="figure">4</ref> plot the nuclear norm and Frobenius norm of Z for all possible completions in a range around the value that minimizes its rank z 2;3 ¼ 1. In this case, the sparsity induced by the nuclear norm (' 1 -norm on the singular values) yields the optimal solution for Z with singular values s ¼ ½2:4495 0, a rank-1 matrix. In opposition, the Frobenius Norm (' 2 -norm of singular values) will set the entries to zero, thus leading to a solution with singular values s ¼ ½2:1358 0:6622, a rank-2 matrix. This key difference can be attributed to the fact that completing a matrix under the rank or nuclear norm favors the interaction between rows and columns to find a global solution, while the Frobenius norm treats each entry in the matrix independently (recall that kZk 2</p><formula xml:id="formula_21">F ¼ P ij z 2 ij ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Adding Robustness into Matrix Completion</head><p>In practical applications, we have several sources of errors in the features (e.g., changes in pose, illumination, background noise) and missing data in the training samples (e.g., missing labels), which will translate into nonzero error matrices in the models of ( <ref type="formula" target="#formula_5">5</ref>) and ( <ref type="formula" target="#formula_17">16</ref>). We account for these possible violations by allowing the matrix Z in <ref type="bibr" target="#b16">(17)</ref> to deviate from the original data matrix. The resulting optimization problem finds the best label assignment Y tst and error matrices</p><formula xml:id="formula_22">E X ¼ E X tr E X tst ½ ; E Y tr such that the rank of Z is mini- mized, as minimize Y tst ;E Y tr ;E X mkZk Ã þ l x ðE X Þ þ l y À E tr Y Á subject to Z ¼ Y tr Y tst X tr X tst 1 &gt; 2 6 4 3 7 5 À E tr Y 0 E X 0 &gt; 2 6 4 3 7 5:<label>(19)</label></formula><p>Here, distortions of Z from known labels and features are penalized according to l y ðÁÞ and l x ðÁÞ, respectively. The parameters ; m are positive trade-off weights between better feature adaptation and label error correction. We rewrite <ref type="bibr" target="#b18">(19)</ref> by defining sets V X and V Y of known feature and label entries and Z Y ; Z X ; Z 1 as the label, feature and last rows of Z, as</p><formula xml:id="formula_23">minimize Z mkZk Ã þ 1 jV X j X ij2V X l x À z ij ; z obs ij Á þ jV Y j X ij2V Y l y À z ij ; z obs ij Á ; subject to Z 1 ¼ 1 &gt; ;<label>(20)</label></formula><p>where the constraint that Z 1 be equal to one is necessary for dealing with the bias b in (3). The model in (20) can be solved using fixed point continuation <ref type="bibr" target="#b15">[16]</ref>, described in Section 3.6.</p><p>In <ref type="bibr" target="#b45">[46]</ref>, l x ðÁÞ was defined as the least squares error and l y ðÁÞ a log loss to emphasize the error on entries switching classes as opposed to their absolute numerical difference. We note that in this model (MC-1), the log loss in l y ðÁÞ, albeit asymmetric, incurs in unnecessary penalization of entries belonging to the same class as the original entry. Therefore, we generalize this loss to a smooth approximation of the Hinge loss, controlled by a parameter g. For labels fÀ1; 1g, we have Fig. <ref type="figure">4</ref>. Comparison of nuclear and Frobenius norms as function of one single unknown entry z 2;3 for the matrix in <ref type="bibr" target="#b17">(18)</ref>.</p><formula xml:id="formula_24">l y À z ij ; z obs ij Á ¼ 1 g log À 1 þ exp À À gz obs ij z ij ÁÁ ;<label>(21)</label></formula><p>and for the case of labels f0; 1g, we have</p><formula xml:id="formula_25">l y À z ij ; z obs ij Á ¼ 1 g log À 1 þ exp À À g À 2z obs ij À 1 ÁÀ z ij À z obs ij ÁÁÁ :<label>(22)</label></formula><p>Also, in the bag of words model, visual data are encoded as histograms. In this setting, ( <ref type="formula" target="#formula_23">20</ref>) is inadequate as it introduces negative values to the histograms in Z X . Thus, we replace the least-squares penalty in l x ðÁÞ by a x 2 distance,</p><formula xml:id="formula_26">x 2 À z j ; z j 0 Á ¼ X F i¼1 x 2 i À z ij ; z obs ij Á ¼ X F i¼1 À z ij À z obs ij Á 2 z ij þ z obs ij ;<label>(23)</label></formula><p>and constrain all feature vectors to be positive (MC-Pos model)</p><formula xml:id="formula_27">minimize Z mkZk Ã þ 1 jV X j X ij2V X x 2 i À z ij ; z obs ij Á þ jV Y j X ij2V Y l y À z ij ; z obs ij Á subject to Z X ! 0 Z 1 ¼ 1 &gt; ;<label>(24)</label></formula><p>or in the Probability Simplex P (MC-Simplex model)</p><formula xml:id="formula_28">minimize Z mkZk Ã þ 1 jV X j X ij2V X x 2 i À z ij ; z obs ij Á þ jV Y j X ij2V Y l y À z ij ; z obs ij Á subject to Z X 2 P Z 1 ¼ 1 &gt; ;<label>(25)</label></formula><p>depending on whether we wish to perform normalization on the data or not. Observe that ( <ref type="formula" target="#formula_23">20</ref>) and ( <ref type="formula" target="#formula_28">25</ref>) are both convex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Comparison to Other Subspace Techniques</head><p>It is important to note that many standard dimensionality reduction techniques such as PCA and LDA have been robustified by using a nuclear norm penalization typically coupled with an ' 1 error function <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b48">[49]</ref>. The differences and similarities between the method presented in Section 3.4 and these techniques can be analyzed if one interprets <ref type="bibr" target="#b23">(24)</ref>, <ref type="bibr" target="#b24">(25)</ref> as forms of PCA with missing data. Our method can be seen as an extension of Robust PCA in two ways: 1) it includes labels as additional "features" in the data samples 2) it penalizes label and features errors with different losses l x and l y .</p><p>A comparison between the behavior of PCA, LDA, RPCA <ref type="bibr" target="#b37">[38]</ref>, RLDA <ref type="bibr" target="#b48">[49]</ref> and our method in the presence of noise can be seen in Fig. <ref type="figure" target="#fig_1">5</ref>. We generated a two-class data set of 2;000 500-dimensional vectors. The positive and negative classes (resp.) have 1;000 samples of the form À1 500 and 1 500 (resp.). We refer to this as clean data. The first two principal components of this clean data are in Fig. <ref type="figure" target="#fig_1">5a</ref>. Then, we added to the clean data noise sampled from a Normal distribution with zero mean and standard deviation 20I 500Â500 . We plot the two principal components data in Fig. <ref type="figure" target="#fig_1">5b</ref>. Note that PCA does not recover the underlying structure of the clean data due to the significant amount of noise.</p><p>In this example, because the data does not have outliers and the noise does not follow a Laplacian distribution, the ' 1 error function assumed by RPCA <ref type="bibr" target="#b37">[38]</ref> is not able to clean the noisy data (Fig. <ref type="figure" target="#fig_1">5c</ref>). Similarly, augmenting the space by adding the labels as an additional dimension does not help since for RPCA the errors in features and labels are weighted equally. In both these cases, the output of RPCA (Fig. <ref type="figure" target="#fig_1">5c</ref>) is similar to the one obtained by regular PCA (Fig. <ref type="figure" target="#fig_1">5b</ref>). LDA (Fig. <ref type="figure" target="#fig_1">5d</ref>) is able to find a projection which classifies most of the points correctly. However, observe that it fails to clean the data, which results in several misclassified points on the class boundary. Our matrix completion approach, in turn, balances a trade-off between correcting the data points, correcting the labels and minimizing the rank. Therefore, it is able to correct the feature data (Fig. <ref type="figure" target="#fig_1">5e</ref>) by giving more weight to the information on the labels. This capability of correcting the errors in features is only matched by our work in Robust LDA <ref type="bibr" target="#b48">[49]</ref>, which achieved the result in Fig. <ref type="figure" target="#fig_1">5f</ref>. While this method has the advantage of obtaining an explicit transformation from the feature to the label space, the matrix completion has the ability to clean the test data during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Fixed Point Continuation for MC-Pos/MC-Simplex</head><p>Albeit convex, the nuclear norm makes ( <ref type="formula" target="#formula_27">24</ref>) and ( <ref type="formula" target="#formula_28">25</ref>) not smooth. Since nuclear norm problems are naturally cast as Semidefinite Programs, existing interior point methods are inapplicable due to the large dimension of Z. Thus, several methods have been devised to efficiently optimize this problem class <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>. The FPC method <ref type="bibr" target="#b15">[16]</ref>, in particular, consists of a series of gradient descent updates hðÁÞ ¼ IðÁÞ À tgðÁÞ with step size t and gradient gðÁÞ as</p><formula xml:id="formula_29">gðz ij Þ ¼ jV Y j Àz obs ij 1 þ exp À gz obs ij z ij Á if z ij 2 V Y ; 1 jV X j z 2 ij þ 2z ij z obs ij À 3z obs ij 2 À z ij þ z obs ij Á 2 if z ij 2 V X ; 8 &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; :<label>(26)</label></formula><p>and 0 otherwise. These steps are alternated with a shrinkage operator S n ðÁÞ ¼ maxð0; Á À nÞ on the singular values of the resulting matrix, to minimize its rank. Provided hðÁÞ is nonexpansive, FPC converges to the optimal solution for the unconstrained problem. FPC was originally devised in <ref type="bibr" target="#b15">[16]</ref> for unconstrained problems and extended in <ref type="bibr" target="#b45">[46]</ref> to solve the formulation MC-1 (20) by adding a projection step. However, its convergence was only empirically verified. In Section 5, we prove the convergence of FPC for ( <ref type="formula" target="#formula_23">20</ref>), ( <ref type="formula" target="#formula_27">24</ref>), (25) using the fact that projections onto convex sets are nonexpansive. Key to the feasibility of FPC is an efficient way to project Z onto the constraint sets in <ref type="bibr" target="#b23">(24)</ref> and <ref type="bibr" target="#b24">(25)</ref>. While for MC-Pos (24) the non-negative orthant projection is done by setting negative components to zero, efficiently projecting onto the probability simplex in MC-Simplex (25) is not straightforward. By exploring the dual of the projection problem we obtain a closed form, cf. <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b49">[50]</ref>. The algorithms are summarized in Algorithm 1. The computational bottleneck is the computation of the SVD of Z. State-of-the-art methods for SVD (e.g., Lanczos bidiagonalization with partial reorthogonalization) take a</p><formula xml:id="formula_30">flop count of OððK þ D þ 1ÞðM þ NÞ 2 þ ðM þ NÞ 3 Þ.</formula><p>Algorithm 1. FPC for MC-Pos <ref type="bibr" target="#b23">(24)</ref> and MC-Simplex ( <ref type="formula" target="#formula_28">25</ref>)</p><formula xml:id="formula_31">Input: Initial Matrix Z obs , known entries sets V X ; V Y Z as the rank-1 approximation of Z obs for m ¼ m 1 &gt; m 2 &gt; Á Á Á &gt; m k do while Rel. Error &gt; do Gradient Descent: A ¼ Z À tgðZÞ Shrink 1: A ¼ USV &gt; Shrink 2: Z ¼ US tm ðSÞV &gt; Project Z X : Z X ¼ maxðZ X ; 0Þ for (24)</formula><p>Project Z X onto the probability simplex P for (25) Project Z 1 : Z 1 ¼ 1 &gt; end while end for Output: Complete Matrix Z</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>This section presents the evaluation of the algorithms MC-Pos <ref type="bibr" target="#b23">(24)</ref> and MC-Simplex (25) in several tasks. In Section 4.2, we validated the low rank assumption of Section 3.2 using two multi-label data sets, MSRC 2 and SIFTFlow <ref type="bibr" target="#b50">[51]</ref>. In Section 4.3, we evaluated the classification and localization performance of our method on the CMU-Face data set <ref type="bibr" target="#b3">[4]</ref> (a two-class problem). In Section 4.4, we evaluated the performance of our method for multi-label classification in the MSRC and PASCAL VOC2007 data sets. We also perform an experiment for localization (Section 4.5) in MSRC. We compared our methods with MC-1 <ref type="bibr" target="#b19">(20)</ref>, an SVM baseline, and several state-of-the-art MIL approaches <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b51">[52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Parameters</head><p>For MC-Pos, MC-Simplex and MC-1, the values considered for parameter tuning were g 2 ½1; 30; 2 ½10 À4 ; 10 2 . The continuation steps require a decreasing sequence of m, which we chose as m k ¼ 0:25m kÀ1 , stopping when m ¼ 10 À9 . We used m 0 ¼ 0:25s 1 , where s 1 is the largest singular value of Z obs , with unknown entries set to zero. Convergence was defined as a relative change in the objective function smaller than 10 À2 . In a transduction setting, since the task is to classify an already known test set, one could choose the parameters which perform best on the final test set. However, to be fair to other baselines, we tuned the parameters in a cross validation setting. As such, the results reported are for the choice of parameters which, from the aforementioned ranges, yielded the best average result on all the validation sets provided by cross-validation. The results reported for the SVM baselines were obtained using libSVM, with parameter C 2 ½10 À6 ; 10 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Low Rank Assumption Validation</head><p>In this experiment, we empirically validated the assumption in ( <ref type="formula" target="#formula_17">16</ref>) that histograms of objects of the same class share a low-dimensional subspace. We constructed a bag of words representation for the MSRC data set, which consists of 591 real world images distributed among 21 classes, with an average of three classes present per image. To replicate the setup of <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, we dismissed the classes void, mountain and horse. To obtain a bag of words descriptor, we clustered texton filter responses <ref type="bibr" target="#b52">[53]</ref> obtained from all three CIELab color channels into a codebook by applying k-means to a random subset of 40; 000 descriptors. In this model <ref type="bibr" target="#b13">[14]</ref>, images are encoded as histograms representing the distribution of the 400 words from the codebook. Then, using the ground truth segmentation labeling, we collected feature matrices X 1 by concatenating all the histograms of the same class. We compared these with feature matrices X 2 of the same dimension with an equal amount of elements from all classes (including elements from the class of X 1 ). In order to compare the singular value distribution of these matrices, we normalized them so columns have unit ' 2 norm. Then, we measured their nuclear norm ratio (NNR), defined as</p><formula xml:id="formula_32">NNRðX 1 ; X 2 Þ ¼ kX 1 k Ã kX 2 k Ã :<label>(27)</label></formula><p>This measure provides an empirical validation of our assumption and is linked to what our model is optimizing and is an indirect measure of the rank of a matrix, as explained in Section 3.3. Results on Table <ref type="table">1a</ref> show that for all classes in the MSRC data set, we obtained a NNR lower than 1. An assignment of test entries to incorrect class labels yields a higher nuclear norm of Z, thus validating our model. For visualization, we plot the singular value distribution of X 1 and corresponding X 2 for some classes in the data set (Fig. <ref type="figure" target="#fig_2">6</ref>).</p><p>It might be argued that explanation of ( <ref type="formula" target="#formula_17">16</ref>) only holds when the columns dominate the estimate of the rank, i.e., rankð X tr X tst Â Ã Þ N þ M F . However, we also validated this hypothesis in the case when the feature dimension F is smaller than the number of images N þ M in the data set. Since there are only 591 images in the MSRC data set and some classes exhibit a small number of exemplars, we validated this assumption in the larger scale SIFTFlow data set <ref type="bibr" target="#b50">[51]</ref>. This data set is a collection of 2;688 images distributed among 33 classes. Following <ref type="bibr" target="#b50">[51]</ref>, we extracted a dense HoG feature map <ref type="bibr" target="#b53">[54]</ref> from every image in the data set and built a BoW codebook of 200 words. We collected the histograms for all the 25;758 ground truth segments in the data set according to their class label. Then, we calculated the distribution of singular values for matrices X 1 as aforementioned, for all classes with more than 200 samples in the data set. We compared the NNR of the matrices X 1 with matrices X 2 of the same dimension comprised by an equal amount of elements from all classes. Results in Table <ref type="table">1b</ref> corroborate the MSRC data set results, showing our assumption is also valid when the feature dimensions are smaller than the number of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classification and Localization on a Two-Class Problem</head><p>In this experiment, we tested the classification performance of our method in a two-class classification problem. We used the CMU Face data set <ref type="bibr" target="#b54">[55]</ref>, which consists of 624 images of 20 subjects. All subjects are captured with varying expression and poses, with and without sunglasses. Fig. <ref type="figure" target="#fig_3">7</ref> shows examples of our positive (wearing sunglasses) and negative class (not wearing sunglasses). We have two goals: First, we want to build a classifier that, given a new face image, determines whether the subject is wearing sunglasses or not. Second, Nguyen et al. <ref type="bibr" target="#b3">[4]</ref> argue that better results are obtained when the classifier training is restricted to the region that has the discriminative information (e.g., the glasses region in this case). They propose using a multiple instance learning framework (MIL-SegSVM) that localizes the most discriminative region in each image while learning a classifier to discriminate between classes. We show how our method is also able to estimate the histogram of the discriminative region (i.e., sunglasses) and localize it in the training and test set.</p><p>To allow for direct comparison, we used the setup and features of <ref type="bibr" target="#b3">[4]</ref>: Our training set is built using images of the first 8 subjects (126 images with sunglasses and 128 without), leaving the remainder for testing (370, equally split among the positive and negative classes). We represented each image with the BoW model by extracting 10;000 SIFT features <ref type="bibr" target="#b55">[56]</ref> at random scales and positions and quantizing them onto a 1;000 visual codebook, obtained by performing hierarchical k-means clustering on 100;000 features randomly selected from the training set. For the first part of the experiment, we compared the results of our classifier to what is obtained using several methods: (1) SVM-Img: a support vector machine trained using the entire image, (2) SVM-FS: an SVM trained using a manually labeled discriminative region (in this case, the region of the glasses), (3) MIL-SegSVM: a MIL SVM method proposed by <ref type="bibr" target="#b3">[4]</ref>. For MC-1, MC-Pos and MC-Simplex, we proceeded as follows: we built Z with the label vector and the BoW histograms of  each entire image and left the test set labels Y tst as unknown entries. For the MC-Simplex case, we further preprocessed Z by dividing each histogram in Z X by its sum. The performance, measured using the area under ROC curve (AUROC), is shown in Table <ref type="table" target="#tab_1">2</ref>. These results indicate both the fully supervised (SVM-FS) and the MIL approach (MIL-SegSVM) are more robust to the noise introduced by non-discriminative parts of the images, when compared to training without localization (SVM-Img). However, this is done at either the cost of labeling efforts or by iteratively approximating the solution of the MIL problem, an integer quadratic problem. The matrix completion approaches (MC-1, MC-Pos, MC-Simplex), in turn, are able to surpass these classification scores by solving a convex minimization.</p><p>Beyond improving the classification performance, our algorithm is able to localize the discriminative region of interest (the sunglasses region, in this data set). Recall that the error E X removes the portion of the histogram introduced by the non-discriminative regions of the image. To illustrate this property, after we run the matrix completion classification, we obtain the most discriminative bounding box for all images in the data set. For each image i in the data set, we searched for the bounding box that best matches the features of the ith column of the completed matrix z X i ¼ h i À e X i (recall Fig. <ref type="figure">3</ref>). We use a sliding window detector varying scale and using the size criteria in <ref type="bibr" target="#b3">[4]</ref> and measure similarity using the x 2 distance. The results are shown in Fig. <ref type="figure" target="#fig_4">8</ref> for MC-Pos (similar results were obtained with MC-Simplex). Similarly to MIL-SegSVM, which used a linear SVM score for the subwindow search, our methods correctly localized the eyes region, that discriminates between the classes. Note that MC-1 does not allow to pursue localization of the class representative since it may introduce negative numbers in the histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Classification in Multi-Label Data Sets</head><p>In this experiment, we ran our method on two multilabel data sets: MSRC and PASCAL VOC 2007. The MSRC data set consists of 591 photos distributed among 21 classes, with an average of three classes present per image. We mimicked the setup of <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> and used as features histograms of textons <ref type="bibr" target="#b52">[53]</ref>. Then, we obtained a 400 word codebook by applying k-means clustering to a random subset of 40;000 descriptors.</p><p>In this task, all training images are labeled with one or several classes, and the goal is to label the test images. Observe that the test image can have several labels (i.e., it's a multi-label classification task). We proceeded as in the experiment described in Section 4.3. We compared MC-Pos and MC-Simplex with MC-1 and several state-of-the-art multi-label MIL approaches: Multiple Set Kernel MIL (MSK-MIL) by Vijayanarasimhan and Grauman <ref type="bibr" target="#b10">[11]</ref>, Multilabel multiple instance learning (ML-MIL) by Zha et al. <ref type="bibr" target="#b9">[10]</ref>, Discriminative Multiple Instance Multiple Label model by Yakhnenko and Honavar <ref type="bibr" target="#b25">[26]</ref>. We also compared to a oneversus-all linear SVM.</p><p>The obtained average AUROC classification scores on the test set using 5-fold cross validation are shown in Table <ref type="table" target="#tab_2">3</ref>. Results show that our methods outperformed MC-1, thus showing the improvement introduced by the additional constraints and improved loss functions. Moreover, they outperformed results given by state-of-the-art MIL techniques, including the non-linear classifier MSK-MIL. This can be explained by the fact that MIL methods select regions from images to be the positive examples for a class while learning that class boundary. Since possible regions are enumerated by a segmentation algorithm, it is not guaranteed they match exactly the ground truth segmentation. The feature error correction in MC-Pos and MC-Simplex does not require this segmentation step and thus allows for superior results in this weakly supervised multi-label scenario.</p><p>We also tested our method in the PASCAL VOC 2007 data set. This data set consists of 9;963 images labeled with at least one of 20 classes, split into trainval and test sets. We used the same features as the winning approach (INRIA_Genetic) <ref type="bibr" target="#b1">[2]</ref>. This method achieved a mean average precision (mAP) of 0.542. Given that it is a non-linear fusion method, we compare to its simplest feature setting to ensure a fair comparison. We represented each image by extracting dense SIFT features <ref type="bibr" target="#b55">[56]</ref> and quantizing them onto a 4;096 dimension codebook, built by k-means clustering on features randomly selected from the training set followed by ' 2 normalization, as implemented in VlFeat <ref type="bibr" target="#b56">[57]</ref>. INRIA_Genetic reports a mAP of 0.48 for these features. Results in Table <ref type="table" target="#tab_4">4</ref> show increased performance for the same features compared to the state of the art circa 2007. Furthermore, we tested using state of the art features obtained from Overfeat,  <ref type="bibr" target="#b3">[4]</ref> 0.94 MIL-SegSVM <ref type="bibr" target="#b3">[4]</ref> 0.96 MC-1 <ref type="bibr" target="#b45">[46]</ref> 0.96 MC-Pos 0.97 MC-Simplex 0.96   <ref type="bibr" target="#b10">[11]</ref> 0.90 ML-MIL <ref type="bibr" target="#b9">[10]</ref> 0.90 DMIML-' 2 <ref type="bibr" target="#b25">[26]</ref> 0.91 MC-1 <ref type="bibr" target="#b45">[46]</ref> 0.91 MC-Pos 0.95 MC-Simplex 0.92 Linear SVM 0.89 a Convolutional Neural Network trained on ImageNet <ref type="bibr" target="#b57">[58]</ref>.</p><p>We rescaled every image to 221 Â 221 pixels and obtained a single 4;096 dimensional feature vector as the output from layer 22 of the network for every image in the data set. Our independent testing corroborates the results obtained in <ref type="bibr" target="#b58">[59]</ref>, and the difference to bag of words models shows the impressive boost in recognition research in the past six years. From these tests, we can conclude Matrix Completion classifiers obtain performances comparable to a linear SVM classifier, while being more versatile in allowing for missing data, as well as noise in labels and features. Moreover, our approach is able to tackle multi-label classification directly and can be useful for object localization, as shown in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Localization in a Multi-Label Data Set</head><p>In this section, we propose an alternative exploratory paradigm for the association of labels to regions in the image. The purpose of the method presented herein is not to provide competitive state-of-the-art results for semantic segmentation, but merely to build a working prototype that builds on the histogram representatives naturally obtained by our method, and discuss its advantages and current limitations. Recall that in the two-class example of Section 4.3, we used each corrected histogram in the training and test set to localize the bounding box containing the most discriminative region. In the multi-label case, however, several classes coexist in one image. Since corrected histograms contain a mixture of classes, they can't be used for class localization in the images. One possible approach to solve this problem is to presegment the test images and use the learned class models to classify each region individually. However, this approach has several drawbacks: 1) having to select a fixed number of segments, 2) the segments are obtained through only texture and color cues, so they might not match the ground truth regions of the classes, and 3) contextual information between segments is lost, which results in poorer classification performance when compared to the classifiers learned on the entire image.</p><p>We propose an alternative method that does not suffer from these drawbacks, by explicitly recovering representative histograms for each class. We proceeded as in 4.4, but padded the matrix Z with 21 extra columns where the labels are the identity and the features are unknown, to recover one representative histogram per class (see Fig. <ref type="figure">3c</ref>). Observe that we do not require segmentation for this classification. For each class in an image (Fig. <ref type="figure" target="#fig_5">9a</ref>), we plot a heatmap of which words belong to the class using its respective histogram (Fig. <ref type="figure" target="#fig_5">9b</ref>). Then, we oversegmented each image using the hierarchical segmentation of Arbelaez et al. [60] (Fig. <ref type="figure" target="#fig_5">9c</ref>). We used code provided by the authors and set the parameter boundary segmentation scale to k ¼ 0:1. Last, in order to get the localization for a class in an image, we used the class histograms and the obtained segments for that image as the input to the efficient region search (ERS) method of Vijayanarasimhan and Grauman <ref type="bibr" target="#b60">[61]</ref>. ERS selects a group of connected segments (Fig. <ref type="figure" target="#fig_5">9d</ref> that maximizes a detection score as measured by an SVM classifier. Since the output of our algorithm is a probability map, we emulated the SVM weight vector by using the class representative subtracted by its mean. We show qualitative results of this approach on Figs. 10 and 11 for independent recovery of classes in the same image. The failures of our approach can be generally attributed to one of two cases: class confusion in both the classification and the fact that ERS is applied individually to each class (Fig. <ref type="figure" target="#fig_7">12a</ref>); the fact that the solution obtained by ERS is by design a single contiguous region (Fig. <ref type="figure" target="#fig_7">12b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PROOF OF CONVERGENCE OF MC-1/POS/SIMPLEX</head><p>This section proves the convergence of FPC in Algorithm 1 by the fact that projections onto Convex sets are nonexpansive; thus, the composition of gradient, shrinkage and projection steps is also non-expansive. Since the problem is convex, a unique fixed point exists in its optimal solution.</p><p>Lemma 1. The gradient operator hðÁÞ for ( <ref type="formula" target="#formula_24">21</ref>), ( <ref type="formula" target="#formula_25">22</ref>), ( <ref type="formula" target="#formula_26">23</ref>) is nonexpansive for step sizes t 2 ½0; minð 4jV Y j g ; t X jV X jÞ.</p><p>Proof. These values are obtained from <ref type="bibr" target="#b25">(26)</ref>    Applying the Cauchy-Schwarz inequality to (28) yields</p><formula xml:id="formula_33">C ðZ Ã Þk ¼ kZ À Z Ã k iff p C ðZÞ À p C ðZ Ã Þ ¼ Z À Z Ã . Proof. For non-expansiveness, [62, Prop. 3.1.3] states that kp C ðZÞ À p C ðZ Ã Þk 2 F hp C ðZÞ À p C ðZ Ã Þ; Z À Z Ã i:<label>(28)</label></formula><formula xml:id="formula_34">kp ðZÞ À p C ðZ Ã Þk F kZ À Z Ã k F :<label>(29)</label></formula><p>For the equivalence part, let us write</p><formula xml:id="formula_35">kp C ðZÞ À p C ðZ Ã Þ À Z À Z Ã ð Þ k 2 F ¼ kp C ðZÞ À p C ðZ Ã Þk 2 F þ kZ À Z Ã k 2 F À 2hp C ðZÞ À p C ðZ Ã Þ; Z À Z Ã i;<label>(30)</label></formula><p>where the inner product can be bounded by <ref type="bibr" target="#b27">(28)</ref>, yielding</p><formula xml:id="formula_36">kp C ðZÞ À p C ðZ Ã Þ À Z À Z Ã ð Þ k 2 F kp C ðZÞ À p C ðZ Ã Þk 2 F þ kZ À Z Ã k 2 F À 2kp C ðZÞ À p C ðZ Ã Þk 2 F :<label>(31)</label></formula><p>Since our hypothesis kp C ðZÞ À p</p><formula xml:id="formula_37">C ðZ Ã Þk ¼ kZ À Z Ã k, (31) is kp C ðZÞ À p C ðZ Ã Þ À Z À Z Ã ð Þ k 2 F 0;<label>(32)</label></formula><p>from which we conclude an equality is in place. t u Theorem 3. Let Z Ã be an optimal solution to ( <ref type="formula" target="#formula_27">24</ref>) or <ref type="bibr" target="#b24">(25)</ref>. Then Z is also an optimal solution if kp C ðS n ðhðZÞÞÞ À p C ðS n ðhðZ Ã ÞÞÞk ¼ kZ À Z Ã k:    </p><p>from which we conclude Z is an optimal solution to (20). t u Theorem 4. A sequence fZ k g generated by Algorithm 1 converges to Z Ã , an optimal solution of ( <ref type="formula" target="#formula_27">24</ref>) (( <ref type="formula" target="#formula_28">25</ref>), resp.).</p><p>Proof. We can use the same rationale as in <ref type="bibr" target="#b15">[16,</ref><ref type="bibr">Theorem 4</ref>], once we note the non-expansiveness of p C ðÁÞ, S n ðÁÞ and hðÁÞ ensures the composite operator p C ðS n ðhðÁÞÞÞ is also non-expansive. Therefore, the sequence fZ k g lies in a compact set and must have a limit point, which we define as Ẑ ¼ lim k!1 Z k . Also, for any solution Z Ã 2 Z Ã , we have</p><formula xml:id="formula_40">kZ kþ1 À Z Ã k ¼ kp C ðS n ðhðZ k ÞÞÞ À p C ðS n ðhðZ Ã ÞÞÞk kS n ðhðZ k ÞÞ À S n ðhðZ Ã ÞÞk khðZ k Þ À hðZ Ã ÞÞk kZ k À Z Ã k<label>(36)</label></formula><p>so we conclude the sequence fkZ k À Z Ã kg is monotonically non-increasing and culminates in any limit point Ẑ, i.e.,</p><formula xml:id="formula_41">lim k!1 kZ k À Z Ã k ¼ k Ẑ À Z Ã k:<label>(37)</label></formula><p>On the other hand, by the continuity of p C ðS n ðhðÁÞÞÞ, we have that the image of Ẑ is</p><formula xml:id="formula_42">p C ðS n ðhð ẐÞÞÞ ¼ lim k!1 p C ðS n ðhðZ k ÞÞÞ ¼ lim k!1 Z k ¼ Ẑ (38)</formula><p>is also a limit point of fZ k g, yielding kp C ðS n ðhð ẐÞÞÞ À p C ðS n ðhðZ Ã ÞÞÞk ¼ k Ẑ À Z Ã k; <ref type="bibr" target="#b38">(39)</ref> from which we can recall Theorem 3. t u</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS AND FUTURE WORK</head><p>Weakly supervised learning algorithms allow for learning image classification models without labeling based on bounding boxes or segmentation masks. It has been shown that these labeling efforts are not only expensive, but can be subjective and error prone. Thus, reducing manual labeling in image labeling is critical for the applicability of image classification methods, especially in large scale data sets with many classes. Limitations of existing MIL approaches include their non-convexity and reliance on an explicit enumeration of possible regions given by a segmentation algorithm.</p><p>A key idea of our method is that histograms of full images contain the information for parts contained therein, so weakly supervised learning can be formulated as a lowrank problem due to its addive nature, and solved using a transductive matrix completion framework. Three are the main benefits of our approach: First, unlike existing MIL approaches to weakly-supervised learning, we presented two new convex methods for performing multi-label classification of histogram data, with proven convergence properties. Second, unlike the majority of existing classifiers, we showed that matrix completion allows for handling of missing data, labeling errors, background noise and partial occlusions. Third, we were able to find class histogram representations and provide localization in the images. This is done despite of the weakly-supervised training set, where class locations are unknown.</p><p>Experiments show that our convex methods perform comparably or better than state-of-the-art MIL methods in several data sets. Our feature error correction provides superior results for weakly supervised multi-label classification, when compared to explicitly enumerating possible regions in the image using segmentation algorithms or bounding box localization. When annotating individual regions, our method was only surpassed by a non-linear MIL method. Error correction also allows to perform localization of the discriminative regions of the image in a twoclass problem. Class representative histograms allow for class localization in multi-label problems.</p><p>We note that our approach is not a full replacement for MIL, since in other settings features may not respect the low rank assumptions in Section 3. Despite not requiring segmentation for classification, our approach has the limitation of only capturing one representative histogram per class (Fig. <ref type="figure">3a</ref>). Future work should address the extension of this framework to allow for the use of representative subspaces. As an extension of a component analysis technique, this work should be kernelized, to couple the feature error correction and the use of non-linear techniques into a single framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. This work proposes a weakly-supervised method for multi-label image classification. The training set images (a) are labeled with the objects that are present but their location in the image is unknown. Given unseen test images (b), our method is able to classify which classes are present in the image and segment the image into regions that correspond to the classes.</figDesc><graphic coords="2,31.73,45.49,240.05,202.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Comparison of results obtained for two-class classification of the random data set in 5. Unlike others, the error correction in Robust LDA (f) and Matrix Completion (e) allow for recovery of the original data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Comparison of singular value distribution of matrices X 1 with histograms of the same class (solid) versus corresponding matrices X 2 of the same dimension with an equal amount of histograms from all classes (dashed) for different classes on the MSRC data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Example images of the CMU-Face data set. (a) shows the positive class (wearing sunglasses) and (b) shows the negative class (no sunglasses).</figDesc><graphic coords="9,294.65,45.49,240.42,52.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. A sliding window search shows that histograms corrected by MC-Pos (24) are most similar to the discriminative region of the eyes in the images.</figDesc><graphic coords="10,31.75,655.31,240.00,53.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Illustration of our method for Matrix Completion localization.</figDesc><graphic coords="11,291.74,45.52,246.24,168.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>)</head><label></label><figDesc>Fig. 11. Multi-label segmentation results on the MSRC data set.</figDesc><graphic coords="12,28.74,440.16,246.24,284.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Multi-label segmentation failure cases. Left: Original Image. Middle: Heatmap generated by the class representative histogram. Right: Segmentation obtained by ERS with class representatives.</figDesc><graphic coords="12,291.74,45.52,246.24,322.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Histograms corrected by our method in the MSRC data set preserve semantic meaning. The input image is shown in (a). The heatmap generated by the class representative histogram is shown in (b). ERS [61] uses the heatmap in (b) and the over segmentation in (c) to produce the segmentation in (d).</figDesc><graphic coords="12,31.75,45.53,240.00,324.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,34.24,45.52,498.24,150.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">AUROC Result Comparison for the</cell></row><row><cell>CMU Face Data Set</cell><cell></cell></row><row><cell>Method</cell><cell>AUROC</cell></row><row><cell>SVM-Img [4]</cell><cell>0.90</cell></row><row><cell>SVM-FS</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">Five-Fold Cross Validation Average AUROC</cell></row><row><cell cols="2">Comparison for Image Classification Tasks</cell></row><row><cell>on MSRC Data Set</cell><cell></cell></row><row><cell>Method</cell><cell>Image</cell></row><row><cell>MSK-MIL</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>by noting the gradient of the Log loss function is Lipschitz continuous with L ¼ 0:25 and choosing t X such that the x 2 error, for the Non-Negative Orthant, is Lipschitz continuous with L ¼ 1.</figDesc><table /><note><p>t u Lemma 2. Let p C ðÁÞ be a projection operator onto any given convex set C. It follows that p C ðÁÞ is non-expansive and kp C ðZÞ À p</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 4 Mean</head><label>4</label><figDesc>Average Precision Classification Task Result Comparison in the PASCAL VOC 2007 Challenge for Two Sets of Features</figDesc><table><row><cell>Method</cell><cell>mAP BoW</cell><cell>mAP Overfeat</cell></row><row><cell>INRIA_Genetic</cell><cell>0:48</cell><cell>-</cell></row><row><cell>MC-1 [46]</cell><cell>0:48</cell><cell>0:73</cell></row><row><cell>MC-Pos</cell><cell>0:50</cell><cell>0:73</cell></row><row><cell>MC-Simplex</cell><cell>0:50</cell><cell>0:72</cell></row><row><cell>Linear SVM</cell><cell>0:49</cell><cell>0:73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>kZ À Z Ã k ¼ kp C ðS n ðhðZÞÞÞ À p C n ðhðZ Ã ÞÞÞk kS n ðhðZÞÞ À S n ðhðZ Ã ÞÞk khðZÞ À hðZ Ã ÞÞk kZ À Z Ã k (34) so we conclude the inequalities are equalities. Using the second part of the Lemmas, we getp C ðS n ðhðZ Ã ÞÞÞ À p C ðS n ðhðZÞÞÞ ¼ S n ðhðZ Ã ÞÞ À S n ðhðZÞÞ ¼ hðZ Ã Þ À hðZÞ ¼ Z À Z Ã Since Z Ã isoptimal, by the projected subgradient method and [16, Corollary 1], we have that p C ðS n ðhðZ Ã ÞÞÞ ¼ Z Ã ) p C ðS n ðhðZÞÞÞ ¼ Z;</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 37, NO. 1, JANUARY 2015</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Support for this research was provided by the FCT (Portuguese Foundation for Science and Technology) through the Carnegie Mellon Portugal program under grant FCT/CMU/P11. Partially funded by FCT projects Printart PTDC/EEA-CRO/098822/2008 and PEst-OE/ EEI/LA0009/2013 and project Poeticon++ from the European FP7 program (grant agreement no. 288382). Fernando De la Torre was partially supported by Grant CPS-0931999 and NSF IIS-1116583. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Alexandre Bernardino received the PhD degree in electrical and computer engineering in 2004 from Instituto Superior Tcnico (IST). He is an assistant professor at IST and a researcher at the Institute for Systems and Robotics (ISR-Lisboa) with the Computer Vision Laboratory (VisLab). He participates in several national and international research projects in the fields of robotics, cognitive systems, computer vision, and surveillance. He published several articles in international journals and conferences, and his main research interests include the application of computer vision, cognitive science, and control theory to advanced robotic and surveillance systems.</p><p>" For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-label linear discriminant analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Eur. Conf. Comput. Vis</title>
		<meeting>11th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="126" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Pascal visual object classes (VOC) challenge</title>
		<author>
			<persName><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LabelMe: A database and web-based tool for image annotation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weakly supervised discriminative localization and classification: A joint learning process</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1925" to="1932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using multiple segmentations to discover objects and their extent in image collections</title>
		<author>
			<persName><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1605" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Object class recognition by unsupervised scale-invariant learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning structured appearance models from captioned images of cluttered scenes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fazly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wachsmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 11th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 11th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Region-based image annotation using asymmetrical support vector machine-based multipleinstance learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2057" to="2063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning with application to scene classification</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Inf</title>
		<meeting>Neural Inf</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1609" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint multi-label multi-instance learning for image classification</title>
		<author>
			<persName><forename type="first">Z.-J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-J</forename><forename type="middle">Q</forename><surname>Zengfu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What&apos;s it going to cost you?: Predicting effort versus informativeness for multi-label image annotations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayanarasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2262" to="2269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convex multiple instance learning by estimating likelihood ratio</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1360" to="1368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Video Google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 9th Int. Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE 9th Int. Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exact low-rank matrix completion via convex optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 46th Annu. Allerton Conf. Commun., Control, Comput</title>
		<meeting>46th Annu. Allerton Conf. Commun., Control, Comput</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="806" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fixed point and bregman iterative methods for matrix rank minimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="321" to="353" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Matrix completion for multi-label image classification</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning the semantics of words and pictures</title>
		<author>
			<persName><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 8th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 8th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="408" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative models for multi-class object layout</title>
		<author>
			<persName><forename type="first">C</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 12th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 12th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="229" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Localizing objects while learning their appearance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pessiot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Eur. Conf. Comput. Vis</title>
		<meeting>11th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="452" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to localize objects with structured output regression</title>
		<author>
			<persName><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th Eur. Conf. Comput. Vis</title>
		<meeting>10th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="2" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Superparsing: Scalable nonparametric image parsing with superpixels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tighe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Eur. Conf. Comput. Vis</title>
		<meeting>11th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="352" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Solving the multiple instance problem with axis-parallel rectangles</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="71" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multiple-instance learning for natural scene classification</title>
		<author>
			<persName><forename type="first">O</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ratan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Int. Conf. Mach. Learn</title>
		<meeting>15th Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="341" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards weakly supervised semantic segmentation by means of multiple instance and multitask learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vezhnevets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3249" to="3256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for image classification with large vocabularies</title>
		<author>
			<persName><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Brit. Mach. Vis. Conf</title>
		<meeting>Brit. Mach. Vis. Conf</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Who&apos;s in the picture?</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A rank minimization heuristic with application to minimum order system approximation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fazel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hindi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Amer. Conf. Control</title>
		<meeting>Amer. Conf. Control</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="4734" to="4739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dynamic context for tracking behind occlusions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">I</forename><surname>Camps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sznaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th Eur. Conf. Comput. Vis</title>
		<meeting>12th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="580" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stable signal recovery from incomplete and inaccurate measurements</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Cand Es</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Romberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1207" to="1223" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno>UILU-ENG-09-2215</idno>
		<imprint>
			<date type="published" when="2009-10">Oct. 2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
	<note>submitted to Mathematical Programming</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A singular value thresholding algorithm for matrix completion</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1956" to="1982" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An accelerated proximal gradient algorithm for nuclear norm regularized least squares problems</title>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Toh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific J. Optim</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="615" to="640" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Matrix completion from a few entries</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Keshavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Montanari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2980" to="2998" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Online identification and tracking of subspaces from highly incomplete information</title>
		<author>
			<persName><forename type="first">L</forename><surname>Balzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Allerton Conf</title>
		<meeting>Allerton Conf</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="704" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast incremental method for matrix completion: An application to trajectory correction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 18th Int. Conf. Image Process</title>
		<meeting>IEEE 18th Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1417" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Element-wise factorization for N-view projective reconstruction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Eur. Conf. Comput. Vis</title>
		<meeting>11th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="396" to="409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robust principal component analysis: Exact recovery of corrupted low-rank matrices by convex optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2080" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A closed form solution to robust subspace estimation and clustering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1801" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-task lowrank affinity pursuit for image segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2439" to="2446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Image tag refinement towards low-rank, content-tag prior and error sparsity</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Multimedia, 2010</title>
		<meeting>Int. Conf. Multimedia, 2010</meeting>
		<imprint>
			<biblScope unit="page" from="461" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Camera calibration with lens distortion from low-rank textures</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2321" to="2328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Bilinear classifiers for visual recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1482" to="1490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Scene discovery by matrix factorization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Loeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th Eur. Conf. Comput. Vis</title>
		<meeting>10th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="451" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Face liveness detection from a single image with sparse low rank bilinear discriminative model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Eur. Conf. Comput. Vis</title>
		<meeting>11th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="504" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Transduction with matrix completion: Three birds with one stone</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="757" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Large-scale image classification with trace-norm regularization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dudik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="3386" to="3393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Scene classification via pLSA</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Eur. Conf. Comput. Vis</title>
		<meeting>9th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="517" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Robust regression</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th Eur. Conf. Comput. Vis</title>
		<meeting>12th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="616" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Efficient projections onto the l1-ball for learning in high dimensions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int. Conf. Mach. Learn</title>
		<meeting>25th Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="272" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Nonparametric scene parsing via label transfer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2368" to="2382" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">SUN database: Large-scale scene recognition from abbey to zoo</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3485" to="3492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Eur. Conf. Comput</title>
		<meeting>9th Eur. Conf. Comput<address><addrLine>Vis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<title level="m">Machine Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">VLFeat: An open and portable library of computer vision algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fulkerson</surname></persName>
		</author>
		<ptr target="http://www.vlfeat.org/" />
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">OverFeat: Integrated recognition, localization and detection using convolutional networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learning Representations</title>
		<meeting>Int. Conf. Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">CNN features off-the-shelf: An astounding baseline for recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Efficient region search for object detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayanarasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1401" to="1408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Hiriart-Urruty and C. Lemar echal, Fundamentals of Convex Analysis</title>
		<author>
			<persName><forename type="first">J.-B</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
