<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recognizing and Counting Freehand Exercises Using Ubiquitous Cellular Signals ?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-07-04">4 July 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Guanlong</forename><surname>Teng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yue</forename><surname>Xu</surname></persName>
							<email>xuyue@stu.ouc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Feng</forename><surname>Hong</surname></persName>
							<email>hongfeng@ouc.edu.cn</email>
							<idno type="ORCID">0000-0002-4167-6037</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianbo</forename><surname>Qi</surname></persName>
							<email>qijianbo2018@stu.ouc.edu.cn</email>
							<idno type="ORCID">0000-0002-4167-6037</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruobing</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Liu</surname></persName>
							<email>liuchao@ouc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhongwen</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Youn-Hee</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hyon-Young</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jong-Hyouk</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jin</forename><forename type="middle">Ryong</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recognizing and Counting Freehand Exercises Using Ubiquitous Cellular Signals ?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-07-04">4 July 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3390/s21134581</idno>
					<note type="submission">Received: 25 May 2021 Accepted: 30 June 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cellular signal</term>
					<term>freehand exercise</term>
					<term>wireless sensing</term>
					<term>mobile sensing</term>
					<term>cellular sensing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Freehand exercises help improve physical fitness without any requirements for devices or places. Existing fitness assistant systems are typically restricted to wearable devices or exercising at specific positions, compromising the ubiquitous availability of freehand exercises. In this paper, we develop MobiFit, a contactless freehand exercise assistant using just one cellular signal receiver placed on the ground. MobiFit passively monitors the ubiquitous cellular signals sent by the base station, which frees users from the space constraints and deployment overheads and provides accurate repetition counting, exercise type recognition and workout quality assessment without any attachments to the human body. The design of MobiFit faces new challenges of the uncertainties not only on cellular signal payloads but also on signal propagations because the sender (base station) is beyond the control of MobiFit and located far away. To tackle these challenges, we conducted experimental studies to observe the received cellular signal sequence during freehand exercises. Based on the observations, we constructed the analytic model of the received signals. Guided by the insights derived from the analytic model, MobiFit segments out every repetition and rest interval from one exercise session through spectrogram analysis and extracts low-frequency features from each repetition for type recognition. Extensive experiments were conducted in both indoor and outdoor environments, which collected 22,960 exercise repetitions performed by ten volunteers over six months. The results confirm that MobiFit achieves high counting accuracy of 98.6%, high recognition accuracy of 94.1% and low repetition duration estimation error within 0.3 s. Besides, the experiments show that MobiFit works both indoors and outdoors and supports multiple users exercising together.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Freehand exercise, with its advantage of convenience, has become one of the most popular physical activities to improve fitness, reduce weight and keep in shape <ref type="bibr" target="#b0">[1]</ref>. The assistant to track and assess freehand exercises helps improve fitness quality. However, existing fitness assistants based on cameras, wearable devices or RFIDs have various limitations. Camera-based systems are sensitive to lighting conditions and may introduce privacy issues <ref type="bibr" target="#b1">[2]</ref>. Wearable devices attached to the body might cause discomfort during exercises <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. Besides, some studies have shown decreased adherence to wearable devices over time <ref type="bibr" target="#b5">[6]</ref>. RFIDs have been used to track workouts when attached to dumbbells, which is inapplicable to freehand exercise monitoring <ref type="bibr" target="#b6">[7]</ref>.</p><p>A more promising alternative for fitness assistants is to capture human motion through wireless sensing <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>, e.g., using Wi-Fi and RFID backscatter signals <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. However, existing wireless sensing approaches exhibit three limits. First, the signal transmitters must transmit periodic sinusoid signals, so the wireless channel has to be dedicated to sensing and is not compatible with any data communication. Second, users must exercise within a specific area (such as the first 8-12 Fresnel zones) between a pair of RF signal transceivers <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref>. Third, they cannot support multiple users exercising together in one room, due to the mutual interference on signal reflections among users.</p><p>To overcome the above limits, we propose a cellular-based freehand exercise assistant system, MobiFit. Since the base stations are widely distributed by commercial cellular operators, the user can use MobiFit anywhere just by placing a cellular signal receiver on the ground. MobiFit traces freehand exercises by monitoring the received cellular signals and provides exercise quality indicators, including repetition number, exercise type and duration for each exercise repetition. MobiFit faces two new challenges: <ref type="bibr" target="#b0">(1)</ref> The cellular signals transmitted by the base station are beyond MobiFit's control, which are interwoven with both control messages and traffic data. MobiFit has to extract the signals affected by exercises through uncontrollable and unpredictable cellular signals. <ref type="bibr" target="#b1">(2)</ref> The long signal propagation distance between the base station and the receiver leads to the time-variant propagation paths, which eliminates the applicability of Doppler analysis.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> illustrates the typical application scenario (MobiFit Demo: https://youtu. be/Dupmc1LAWTU (accessed on 14 July 2020) and https://www.bilibili.com/video/BV1 5p4y1S7As/ (accessed on 14 July 2020)), where we conducted the experimental study. We observed that the envelope of the recorded signal sequence fluctuates periodically with the ups and downs of the torso motions during freehand exercises, as shown in Figure <ref type="figure" target="#fig_0">1b</ref>. Based on the observation, we construct an analytic model of the received signals and demonstrate the torso block effect on signal propagation as the primary cause for the periodic fluctuations. The analytic model also points out that low-frequency components can help in exercise repetition segmentation and type recognition. Guided by the insights, MobiFit exploits the spectrogram analysis on the received signals and realizes real-time segmentation of exercise repetitions. MobiFit then applies Fast Fourier Transform (FFT) and Discrete Wavelet Transform (DWT) to extract the low-frequency coefficients from each repetition sequence and applies the Support Vector Machine (SVM) for exercise type recognition. MobiFit tackles the challenges by focusing only on the low-frequency coefficients for repetition counting and type recognition. The frequency band and data rate of cellular signals are high and independent of low-frequency coefficients. Thus, MobiFit does not require an exclusive channel for sensing, solving the first challenge. Since the block effect on signal propagation comes from the torso motion nearby the receiver, the signal propagation path diversity from the base station to the receiver becomes negligible. It not only solves the second challenge but also implies the possibility of providing exercise assistance for multiple users exercising together in the same room.</p><p>We implemented the prototype of MobiFit on USRP-1 and RFX900 sub-board to trace the GSM signal and output 100 Hz down-sampled signal sequence for freehand exercise tracking. We deployed MobiFit under three typical scenarios, both indoors and outdoors. We collected 22,960 exercise repetitions of six freehand exercise types performed by ten volunteers over six months. The results confirm that MobiFit counts repetitions with an error ratio as low as 1.4% per exercise session, across all volunteers and exercise types. Overall, 98% of the repetition duration estimation error is within 0.3s. Moreover, only using the SVM can accurately recognize each exercise repetition with 94.1% accuracy under five-fold cross-validation on all traces. Besides, MobiFit's recognition is permanent, i.e., robust across two weeks. What is more, MobiFit provides counting and type recognition of every exercise repetition with only 5 s delay, instead of after the whole session required by existing works. Finally, the experiments demonstrate the feasibility of MobiFit supporting multiple users exercising together and exercising both indoors and outdoors.</p><p>The main contributions of this work can be summarized as follows:</p><p>? This work proposes and verifies the feasibility of applying cellular signals for passive freehand exercise tracking, which sheds light on a new kind of wireless signals for motion sensing, especially at the advent of 5G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We propose an analytic model to quantify the impact on the received cellular signals when humans conduct freehand exercise nearby. The analytical model provides two insights for other motion tracking research with cellular signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We propose a real-time freehand exercise repetition segmentation scheme and several low-frequency features for type recognition, which may be further applied in motion repetition counting and recognition with cellular signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We implemented the prototype of MobiFit and evaluated it with extensive experiments, both indoors and outdoors. The results confirm that MobiFit achieves high accuracy in counting and type recognition for freehand exercises.</p><p>The rest of the paper is organized as follows. In Section 3, experimental studies are presented to verify the feasibility of MobiFit. In Section 2, we survey the related works and analyze the limitations of existing studies. In Section 4, the analytic model is introduced and used to guide system design. We present the proposed freehand exercise assistant system, MobiFit, in Section 5 and evaluate it in Section 6, followed by the conclusions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We divide and review the existing wireless sensing work into two categories: cellular signal-based and non-cellular signal-based motion sensing systems. The authors of <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> used the mobile phone as a body-attached cellular signal sensor. Sohn et al. <ref type="bibr" target="#b15">[16]</ref> applied the mobile phone to measure and record the surrounding GSM radio environment. Then, they inferred whether the user is walking, driving or staying stationary from the variance of measured signals and counted the step number. Shakra <ref type="bibr" target="#b16">[17]</ref> used an Artificial Neural Network to analyze GSM signal strength to estimate whether the user is walking, driving or staying stationary. Anderson et al. <ref type="bibr" target="#b17">[18]</ref> also employed the patterns of signal strength fluctuations and changes to the current serving cell and neighboring cells to distinguish between various states of movement such as walking, driving and remaining stationary. Unlike the above research, MobiFit does not require the user to attach their mobile phone to the body during exercises, which is often cumbersome and may cause unwanted motion changes. At the same time, the existing studies based on cellular signals do not count the motions, so it cannot provide a complete exercise monitoring for users.</p><p>Recently, LTE-based passive radar <ref type="bibr" target="#b18">[19]</ref> achieves moving target detection via Doppler resolution. Chen et al. <ref type="bibr" target="#b19">[20]</ref> recognized dynamic hand gesture interaction by analyzing CSI extracted from LTE signals. SpiderMon <ref type="bibr" target="#b20">[21]</ref> performs keystroke monitoring using the cellular signals transmitted by commercial base stations. Furthermore, a few 5G prototype systems are proposed and applied to human sensing. For example, Gholampooryazdi et al. <ref type="bibr" target="#b21">[22]</ref> enabled crowd-size detection and walking speed recognition. However, these studies only realize motion detection but do not provide motion counting. Thus, they cannot be applied as freehand exercise assistants.</p><p>Existing wireless sensing systems with other RF signals can be further classified into dedicated device based, RFID based and WiFi based. For the first category, RF-Capture [23], RF-Pose <ref type="bibr" target="#b23">[24]</ref> and DFAR <ref type="bibr" target="#b24">[25]</ref> use dedicated wireless devices to scan RF reflections, which can recognize and count user's actions. For the second category, FEMO <ref type="bibr" target="#b6">[7]</ref> attaches passive RFID tags on dumbbells and measures the Doppler shift profile of the backscatter signals to count and recognize repetitions of arm exercises. Motion-Fi <ref type="bibr" target="#b25">[26]</ref> deploys two USRPs to measure the backscattered signal of passive RFID tags to count and recognize free-weight exercises.</p><p>WiFi-based motion tracking relies on RSSI or the more detailed CSI to realize activity detection <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref>, gesture recognition <ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref> and tracking <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref>. WiFit <ref type="bibr" target="#b40">[41]</ref> enables people to practice three kinds of freehand exercises with the body on the line-of-sight between Wi-Fi transceivers. Guo et al. <ref type="bibr" target="#b13">[14]</ref> also exploited Wi-Fi to count and recognize repetitions for free-weight exercises. Zhang et al. <ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr">[45]</ref> designed Fresnel zone-based methods to sense and count human activities.</p><p>Existing wireless sensing systems study the signal reflection profile by the body, which requires the sender to emit periodic sinusoid signals on the sensing channel. Different from these systems, MobiFit does not take any control of the sender, whose receiver directly makes use of the cellular signals transmitted from the nearby mobile station. Hence, MobiFit does not need a wireless channel exclusively used for sensing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Study</head><p>In this section, we first give a brief introduction to GSM signals. Then, we describe the setup, process and observation of the experimental study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">GSM Background</head><p>The Global System for Mobile communications (GSM) describes the protocols for cellular networks used by mobile devices such as mobile phones and tablets <ref type="bibr">[46]</ref>. GSM uses a cellular network structure to achieve frequency band reuse between cells. To ensure the stability of communication, the size of the cellular is determined by the density of the base station deployed by the operator. GSM only stipulates the maximum cell radius of 35 km. To meet the increasing demand for communication, the base station density is usually at kilometers level. Cellular signal propagation paths are more dynamic than those of Wi-Fi due to the longer distance.</p><p>The base station uses both FDMA and TDMA to embed logical channels. The base station uses frequency division multiplexing on the physical frequency bands. Each physical band is further divided into eight time slots for time-sharing, grouped as a TDMA multi-frame. The time slot is the basic unit to embed one logical channel.</p><p>Each base station has a predefined physical frequency band called Beacon Channel, as shown in Figure <ref type="figure" target="#fig_1">2</ref>. The control messages and data payloads are interwoven among slots. Beacon Channel loads the control logic channels in Slots 0-2. Slots 3-7 are loaded with data traffic. The base station repeatedly broadcasts TDMA multi-frame over the Beacon Channel. The mobile terminal obtains the access information of the base stations in a cell by analyzing their corresponding BCCHs. It selects one base station to access according to the signal strength. After the mobile terminal associates with one base station, it keeps monitoring the Beacon Channel for changes in BCCH or controlling messages such as calls to itself. The continuous broadcast feature of Beacon Channel makes it possible for cellular signals to track freehand exercises. However, it also brings two challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Setup</head><p>To explore the feasibility of using GSM signals to monitor freehand fitness, we conducted experiments in the corridor shown in Figure <ref type="figure" target="#fig_2">3</ref>. Since mobile phones do not provide any API to access the cellular signals, the prototype of MobiFit with a USRP-1 and an RFX900 sub-board was used to simulate the whole procedure of receiving GSM signals on the smartphone and output 100 Hz down-sampled sequences for exercise tracking. The receiver continuously received the cellular signal sequence on the Beacon Channel and outputted the signal sequence down-sampled to 100 Hz. The volunteer performed freehand exercises such as squats at a distance of 60 cm around the receiver, which was put on the ground. In the corridor, a volunteer completed ten squats in front of the signal receiver, recorded by video. Figure <ref type="figure" target="#fig_4">4a</ref> shows an example of the signal sequence received. Its envelope presents periodic fluctuation. Figure <ref type="figure" target="#fig_4">4b</ref> shows a zoom-in view of the signal sequence of the box marked in Figure <ref type="figure" target="#fig_4">4a</ref>. The squat exercise can be divided into four phases in sequence: resting, concentric contraction, dropping and eccentric contraction, labeled in Figure <ref type="figure" target="#fig_4">4b</ref> as P 1 -P 4 through video analysis. Every phase of freehand exercises lasts a certain time to train muscle groups. Figure <ref type="figure" target="#fig_4">4b</ref> shows that the fluctuation of the signal sequence coincides with the four phases of squat exercises.</p><p>The torso moves up and down once during repetition because body weights are the only resistance to work multiple muscle groups in freehand exercises. The periodic torso motion in the consecutive squats will cause periodic impact, which in turn exhibits periodic change on the signal sequence envelope. Thus, the fluctuation period of the sequence envelope will be the same as the exercise repetition period. Figure <ref type="figure" target="#fig_4">4c</ref> exhibits the amplitude distributions of the signal sequences in these four phases of squat exercises. Concentric contraction and eccentric contraction have similar distributions in Figure <ref type="figure" target="#fig_4">4c</ref>, whose signal sequences are also symmetric with time in Figure <ref type="figure" target="#fig_4">4b</ref>. Both resting and dropping phases have normal distributions, but the mean amplitude in the dropping phase is lower than that of resting.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Experiments on Different Positions</head><p>To evaluate the effect of the exercise position to the receiver, a volunteer conducted squats on four orthogonal locations of one circle.</p><p>Figure <ref type="figure" target="#fig_5">5</ref> shows the recorded corresponding signal sequences during squatting at Positions B-D. The envelopes of the three sequences also exhibit the phenomenon of ups and downs consistent with the squat. Thus, our observation is extended to: during indoor squatting, the envelope of down-sampled cellular signal sequence shows periodic ups and downs consistent with the squat repetition. As shown in Figures <ref type="figure" target="#fig_4">4a</ref> and<ref type="figure" target="#fig_5">5</ref>, all starting parts of the received sequences correspond to the volunteer in the resting phase (P 1 ). For squats at Positions A and D, the sequence envelope first falls and then rise back from phase P 1 to phase P 4 . The sequences obtained at Positions B and C show the opposite process of change.</p><p>We queried the actual location of the connected base station, which was located in the northwest direction to the receiver. Thus, the cellular signals propagated from the base station to the receiver in the southeast direction. Thus, the difference between Positions A and D and Positions B and C lies in whether the cellular signals arrive first at the volunteer or the receiver for Positions A and D. Thus, the torso may block a larger portion of the cellular signals from reaching the receiver during the action phase than in the resting phase. This may result in a decrease in the amplitudes of the received signals during phases P 2 -P 4 . For Positions B and C, after some portion of cellular signals passes over the receiver, they will be reflected back to the receiver by the torso during phases P 2 -P 4 . Thus, the sequence envelope will be higher during the action phase than during the resting phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Experiments on Different Exercises</head><p>We further carried out experiments on other types of freehand exercises, including push-ups, crunches and sit-ups. Figure <ref type="figure" target="#fig_6">6</ref> shows three segments of the recorded signal sequences when a volunteer carries out corresponding exercises at Position A. Since there is also the block effect during the action phases of these three exercises, the sequence envelopes are consistent with the proposed observation. As a summation, we observed empirically that the envelope of the recorded signal amplitude sequence fluctuates periodically, consistent with the exercise cycle of ups and downs of torso motions during freehand exercises. The observation is confirmed by the proposed analytic model in the next section. The scenario is expanded to outdoor environments in the evaluation section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Analytic Model</head><p>In this section, we construct the analytic model for the received signals. The analytic model begins with multi-path analysis. Although cellular signals can transverse walls, there are some proportion of signals reflected by the walls and other objects. Hence, cellular signals propagate from the transmitter (base station) to the receiver (mobile terminal) via multiple reflections, especially when the receiver is indoors. The received signals are the superposition of the signals from all the propagation paths.</p><p>As the human body is a good reflector of cellular signals, during freehand exercises, the multi-path propagations of cellular signals arriving at the receiver will be changed according to the torso motion. Figure <ref type="figure" target="#fig_7">7</ref> shows a schematic diagram of cellular signal multi-path propagation under two decomposed phases during squats.</p><p>Figure <ref type="figure" target="#fig_7">7a</ref>,b corresponds to the resting and dropping phases of squats, respectively. The solid line represents a propagation path unaffected by the torso motion; the dotted line represents the dynamic reflection path created by the torso motion; and the dash-dotted line indicates the block effect on the cellular signal propagation related to the torso motion. Under the resting phase, the cellular signals propagating along the red dash-dotted line can reach the receiver, while the ones propagating along the blue dash-dotted line and the dotted line cannot reach the receiver. Under the dropping phase, the signals propagating along the dotted line are reflected by the torso to reach the receiver. The cellular signals propagating along the blue dash-dotted reach the receiver because there is no blocking. Moreover, the cellular signals propagating along the red dash-dotted line are reflected away from the receiver. In Figure <ref type="figure" target="#fig_7">7</ref>, we use the shadow metaphor to describe the variation of the blocking effect of the torso on cellular signal propagation. To analyze the received signals, we first divided the signal propagation paths based on whether they are affected by human exercise or not, called dynamic and static paths <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b46">47]</ref>, as shown in Equation (1). y s ( f , t) represents the cellular signal propagating along the static paths not affected by the human motion. y s ( f , t) does not contain the low-frequency components corresponding to our observation, because the payloads are at 10s kbps, and the modulated frequency is over 900 MHz for GSM.  Here, the periodic block effect of the torso on signal propagation is represented with a square wave function ? p (t), defined as Equation <ref type="bibr" target="#b4">(5)</ref>. T represents the repetition cycle of freehand fitness; t 1 and t 2 mark the start and end timestamp of the block effect on signal propagation along with path p. Figure <ref type="figure" target="#fig_10">8</ref> shows two examples of switch functions with different duty cycles. The frequency of freehand exercise is quite low (?1 Hz), referring to experimental observation. y b ( f , t) is the only possible factor which can introduce low-frequency components. First, ? p (t) of all paths share the same cycle T of freehand exercise repetition. Second, y b ( f , t) accounts for a large proportion of change of y( f , t) due to the larger area of the torso to block signal propagation. Previous research <ref type="bibr" target="#b25">[26]</ref> confirmed that the influence of limbs on wireless signal propagation is far less than that of the torso. Third, the torso's size is larger than the cellular signal's wavelength, and the torso is near the receiver. Thus, most of the blocked propagation paths will share similar phases, creating the aggregated fluctuation after superposition. Thus, the switch function ? p (t) leads to the ups and downs of the amplitude envelope of y( f , t). The analytic model explains and verifies the experimental observation, i.e., the torso motion causes periodic ups and downs on the received signal sequence's envelope with its frequency the same as exercise repetition.</p><formula xml:id="formula_0">y( f , t) = y s ( f , t) + y d ( f , t)<label>(1)</label></formula><formula xml:id="formula_1">y d ( f , t) = y r ( f , t) + y b ( f , t)<label>(2)</label></formula><formula xml:id="formula_2">y r ( f , t) = ? p?p r a p ( f , t)x(t - d p -v(t) f c )e -j2? f (t- dp - v(t) f c ) (3)</formula><formula xml:id="formula_3">y b ( f , t) = ? p?p b ? p (t)a p ( f , t)x(t - d p c )e -2? f (t-dp ? p (t) = 0 t 1 &lt; t mod T &lt; t 2 1 otherwise<label>(5)</label></formula><p>To this end, we summarize the key insights of the analytic model as follows: (1) Each component in y b ( f , t) shares the same cycle T of freehand exercise repetitions. By sifting out the low-frequency component near the frequency T -1 , we may cut out the exercise repetitions from each session. (2) Different kinds of freehand exercises contain different procedures of torso motions, which in turn creates different kinds of block effects. Then, ? p (t) for each involved propagation path will have different duty circle ratio ( |t 2 -t 1 | T ) for various exercises. Different duty cycle ratio in square wave ? p (t) will create various lowfrequency components. These low-frequency components correspond to the characteristic of the torso motion among different types of freehand exercises, which are potential features for exercise type recognition. These two insights form the basis of MobiFit design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">System Design</head><p>MobiFit counts and recognizes the exercise repetitions by processing the downsampled cellular signals. As shown in Figure <ref type="figure" target="#fig_11">9</ref>, MobiFit consist of five modules: signal receiving, segmentation, feature extraction, classification and output. The signal receiving module monitors cellular signals and outputs a signal sequence down-sampled to 100 Hz. The segmentation module cuts the signal sequence into exercise repetitions and rest intervals. From the signal sequence of each repetition, the feature extraction module extracts the low-frequency features. Then, the SVM classifier recognizes the type of current repetition. The output module presents the number of repetitions for each exercise type and the duration distribution of exercise repetition and rest intervals. This section focus on the details of the segmentation and feature extraction module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Segmentation</head><p>The segmentation module cuts in real-time the down-sampled cellular signal sequence into the sequences of exercise repetitions and rest intervals between two continuous repetitions. The challenge of segmentation lies in the nonuniform rest intervals, which directly limits the applicability of template matching. During exercises, ordinary users cannot control the rest intervals between exercise repetitions due to the lack of fitness ability and experience. Thus, there may be short or long intervals between two repetitions. Figure <ref type="figure" target="#fig_12">10</ref> shows a volunteer's ten consecutive squats, which has a long rest interval between the sixth and seventh squats.  (1) Calculate the amplitude curve corresponding to the primary frequency. MobiFit applies STFT with a sliding window of 512 samples (5.12 s) to cover a single exercise repetition completely in one window. Because most repetitions of the freehand exercise lie within 3-5 s <ref type="bibr" target="#b0">[1]</ref>, the sliding step is set to 8, corresponding to a time resolution of 0.08 s. Figure <ref type="figure" target="#fig_14">11a</ref> shows the spectrogram of the signal sequence in Figure <ref type="figure" target="#fig_12">10</ref>. It shows that the highlighted parts of the low-frequency components are consistent with the repetitions. Figure <ref type="figure" target="#fig_14">11b</ref> illustrates the amplitude curve of the primary frequency in Figure <ref type="figure" target="#fig_14">11a</ref> with a solid black line. Comparing to Figure <ref type="figure" target="#fig_12">10</ref>, the peaks on the amplitude curve correspond to the midpoints of each exercise repetition during squats. However, there is an error peak in the long rest interval (32-35 s), which does not correspond to an exercise repetition. (2) Find the potential timestamps corresponding to the start and end of each exercise repetitions, shown on Lines 7-22. Although the peak of the solid black line in Figure <ref type="figure" target="#fig_14">11b</ref> is located near the midpoints of each exercise repetition, MobiFit needs to find the specific timestamps at which each exercise repetition starts and ends. At the beginning of the exercise repetition, the human body changes from the static state to the exercise state, so the amplitude curve of primary frequency changes significantly at this moment. Similarly, at the end of the exercise repetition, the amplitude curve of the primary frequency will also exhibit great change. MobiFit finds the start and end of each repetition by calculating the change rate of the amplitude curve on the primacy frequency, as shown in Equation <ref type="bibr" target="#b5">(6)</ref>. A(p) is the amplitude of the primary frequency at sliding window p, and d is the interval for calculating the change rate, set as 4. D(p) is the change rate at sliding window p. The red dotted line in Figure <ref type="figure" target="#fig_14">11b</ref> shows the change rate of the black line. Each extremum pair from the maximum to the minimum on the change rate curve marks the boundary of one squat repetition in Figure <ref type="figure" target="#fig_12">10</ref>, except two extremum pairs around 13 and 33 s, labeled with blue circles. The extremum pair around 13 s may exist due to noise, while some relaxing actions may cause the other pair in the long rest interval. These two extremum pairs do not correspond to the exercise repetition and require further processing.</p><formula xml:id="formula_4">D(p -d) = A(p) -A(p -d)<label>(6)</label></formula><p>(3) Eliminate the false-positive extremum pairs. MobiFit double-checks whether each maximum and minimum are the start or end timestamps of an exercise repetition. For maximum check, the duration criterion is applied to check whether the time length from the end of the last exercise repetition to the current maximum is longer than ? r , which represents the shortest rest interval, shown on Line 9. When multiple consecutive maxima satisfy the duration criterion, MobiFit selects the maxima with the larger value as the start of the current repetition. MobiFit judges a potential end by the duration and amplitude criteria. The duration criterion for the potential end is that the time length from the start of current repetition to the minimum should be longer than ? a , which represents the shortest repetition duration. If the duration criterion is satisfied, MobiFit then evaluates the amplitude criterion, i.e., the average amplitude of the signal sequence from the start to the minimum should be higher than the average amplitude of previous rest interval, shown on Line 16 in Algorithm 1.</p><p>MobiFit applies the end updating criterion when one new minimum appears. Here, the current repetition already has a start and an end. The updating criterion checks whether the current minimum is close to the end of current repetition and its value is smaller, shown on Line 21 in Algorithm 1. If so, MobiFit updates the end of current exercise repetition to this minimum.</p><p>Through double-check, MobiFit can eliminate the wrong extremum pairs. We take the process of the ten squats shown in Figure <ref type="figure" target="#fig_12">10</ref> as an example. For the extremum pair around 13 s in Figure <ref type="figure" target="#fig_14">11b</ref>, when the first maximum appears, marked with the first blue circle, it satisfies the duration criterion and will be saved as the start of the current repetition. When the minimum of the second blue circle appears, it does not satisfy the duration criterion on end judging and is ignored. When the second maximum with the red circle appears, MobiFit updates the start of current repetition to this maximum because it satisfies the duration criterion and has a larger value. Hence, the extremum pair around 13 s can be eliminated.</p><p>For the extremum pair in the rest interval around 32-35 s, the first maximum, marked with a blue circle, satisfies the duration and amplitude criteria to judge the start, which will be saved as the start of current repetition. The minimum around 35 s, marked with a blue circle, satisfies the duration criterion to judge an end but fails the amplitude criterion. Thus, the minimum around 35 s is ignored. Then, the current repetition only labels its start as the maximum around 32 s, while it has no end yet. When the maximum around 37 s appears, it is updated as the start of current repetition because it satisfies the duration criterion, and its value is larger than the maximum at 32 s. Therefore, MobiFit eliminates the error extremum pair around 32-35 s. The elimination process ensures that all the detected extremum pairs represent the starts and ends of exercise repetitions, which realizes the repetition segmentation.</p><p>N est = size(t s )</p><formula xml:id="formula_5">DA est [i] = t e [i] -t s [i], i = 1, ..., N est<label>(7)</label></formula><formula xml:id="formula_6">DI est [i] = t s [i] -t e [i -1], i = 2, ..., N est<label>(8)</label></formula><p>After segmentation, MobiFit records two arrays t s and t e , which store the start and end of each repetition, respectively. Based on these two arrays, MobiFit calculates three exercise indicators using Equations ( <ref type="formula" target="#formula_5">7</ref>)- <ref type="bibr" target="#b8">(9)</ref>. N est represents the repetition number of one exercise session, which evaluates whether one session satisfies the fitness requirement of the repetition number. DA est and DI est indicate the duration of each exercise repetition and rest interval, respectively. The distribution of DA est shows the stability of each repetition and whether the duration of each repetition satisfies the time length requirement; the distribution of DI est shows the stability of rest intervals.</p><p>For the 10 squats in Figure <ref type="figure" target="#fig_12">10</ref>, Figure <ref type="figure" target="#fig_15">12a</ref> shows the duration distribution of each squat repetition and rest interval after segmentation. The ten squats were all completed in 2-4 s, reaching the fitness standard. However, there is one long rest interval after the sixth repetitions, reminding the user to control the rest interval in future training. One further question for segmentation is that there may be exercise type switching inside one session, where extra actions may cause counting errors. For example, Figure <ref type="figure" target="#fig_15">12b</ref> shows that volunteer v 1 tries two consecutive deficit deadlifts, two squats, two sit-ups and two crunches in one session. The red lines and numbers show the segmentation results of MobiFit, which correctly cut out eight repetitions. However, a false positive repetition appears inside the process of changing from the standing posture to the lying posture. For reducing false positives, existing studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b25">26]</ref> require that each session should contain at least three consecutive repetitions of one type to distinguish between exercise and nonexercise actions. MobiFit revises this rule to eliminate non-exercise repetition, whose type is different from previous or subsequent repetitions, called segmentation refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Feature Extraction</head><p>From the signal sequence of each exercise repetition, MobiFit extracts the low-frequency features representing different types of exercises according to Insight 2 from the analytic model. ( <ref type="formula" target="#formula_0">1</ref>) Insight 2 illustrates that different freehand exercise may have different ? p (t) of the human block effect during exercising. (2) We apply two frequency analysis tools, FFT and DWT, to calculate the low-frequency features from the repetition traces. Before frequency analysis, MobiFit resamples every repetition to 512 using Cubic Spline Interpolation.</p><p>FFT decomposes a signal into a frequency spectrum. Because the major frequency of freehand exercises lie in the range of 0.2-1 Hz, we take the normalized coefficients from the second to the fifth lowest frequencies. This frequency range corresponds to 0.4-1.0 Hz. We omit the basic frequency of 0.2 Hz, because all exercise types share the same cycle, which is used in segmentation.</p><p>Since FFT loses time resolution, MobiFit applies DWT to measure the low-frequency components with specific time resolution. Different exercises may have different frequency components in the start, middle and end phase of an exercise repetition. For example, sit-ups have more low-frequency components than crunches in the middle phase, as shown in Figure <ref type="figure" target="#fig_6">6</ref>. MobiFit decomposes the signal sequence into seven levels, using the lowfrequency coefficients of the seventh level and the high-frequency coefficients of the fifth to seventh levels as features. The frequency ranges of these four groups of wavelet coefficients are 0-0.78, 0.78-1.56, 1.56-3.13 and 3.13-6.25 Hz. Figure <ref type="figure" target="#fig_16">13</ref> shows the signal sequences and corresponding features of six exercise types, which exhibit some differences among these features for various types. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation</head><p>In this section, we present the implementation, deployment and experiment process. Then, we evaluate MobiFit's counting error, recognition accuracy and duration estimation of exercise repetition and rest intervals, comparing to Motion-Fi <ref type="bibr" target="#b25">[26]</ref>. We also evaluate the feasibility of using MobiFit for multiple people exercising together and outdoors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Setting and Process</head><p>We conducted experiments in a corridor, a public room and the observation deck on campus, as shown in Figure <ref type="figure" target="#fig_17">14</ref>. Our experimental studies show that the envelope of the received signal sequences exhibit the same periodic ups and downs when a volunteer squats at four different locations nearby. Besides, as we do not require the users to know the position of the cellular base station. The volunteer conducted freehand exercises at the different locations in the room for a long period (over six months). The key to segment and classify each exercise repetition lies in the analysis of low-frequency features from the received signal sequence. Because the low-frequency features are not affected by the locations where volunteers exercise, the proposed system can count and recognize repetitions for different exercises. The only requirement on deployment is that the receiver should be put on the ground and the user exercise at a position about 60 cm away from the receiver. Ten volunteers were recruited to participate in the experiments, whose age and body parameters are shown in Table <ref type="table" target="#tab_0">1</ref>. In general, the volunteers recruited have low BMIs, i.e., they are thin. MobiFit counts and recognizes exercise repetitions majorly through analyzing the block effect of the torso on cellular signal propagation, so thin bodies increase the difficulty for MobiFit. There are no restrictions on clothes for volunteers. After discussing with ten volunteers on exercise difficulty and quality, we chose six kinds of freehand exercises: squats, lunges, sit-ups, deadlifts, crunches and push-ups (Figure <ref type="figure" target="#fig_18">15</ref>). Considering upper limb strength, the females conducted knee push-ups. We hired a fitness instructor to explain and demonstrate the motion mechanism for each type of freehand exercise and guide the volunteers during the experiments.  In order to ensure fitness improvement and avoid possible physical injury, we set the minimum requirement of 10 repetitions for an exercise session. The volunteer was allowed to increase the repetition number in one session based on her/his physical condition. An exercise session could include different kinds of freehand exercises. In the first two weeks, we required the volunteers to complete at least one session for each kind of freehand exercises per day. After two weeks, volunteers exercised in the corridor or public space according to their own exercise frequency. After each session, the volunteers recorded the meta-data, including name, exercise type and repetition number. The whole experiment lasted over six months. The final session and repetition numbers for each volunteer are also shown in Table <ref type="table" target="#tab_0">1</ref>. All volunteers completed 22,960 repetitions. To evaluate the duration accuracy of each exercise repetition and rest interval, we recorded the first 100 squats with cameras for each volunteer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Results</head><p>Existing studies except for Motion-Fi <ref type="bibr" target="#b25">[26]</ref> exploit MIMO information from the receiving signals, while MobiFit only monitors single cellular band. Hence, we compared the results with Motion-Fi. Note that Motion-Fi cannot distinguish between exercise repetitions and rest intervals, which are all combined as exercise repetitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.">Repetition Counting</head><p>For all the traces collected indoors, Figure <ref type="figure" target="#fig_6">16</ref> shows the comparison on counting error ratio between MobiFit and Motion-Fi for every exercise type and each volunteer. Here, the counting error ratio is defined in Equation <ref type="bibr" target="#b9">(10)</ref>. N est is the estimated repetition number for one session and N truth is the repetition number recorded by a volunteer. The counting error ratio of MobiFit is the result without applying the refinement from exercise type recognition. It shows that most counting error ratio of MobiFit is less than 2%, except for push-ups practiced by two females (v 5 and v 6 ). We show one typical error session of v 5 in Figure <ref type="figure" target="#fig_7">17</ref> with its corresponding spectrogram. There is one missed repetition around Sample 2250. There are two factors that cause the counting miss. First, Volunteers v 5 and v 6 are both petite females, whose torso is relatively small. Second, they practiced knee push-ups, whose motion is also lower comparing to push-ups done by male volunteers. For this particular situation, a closer distance between the petite females and the receiver would decrease counting error, which introduces more variation on the block effect. v 5 and v 6 further conducted knee push-ups at 40 cm to the receiver, whose counting error ratios are 0.6% and 1.3%, respectively, as shown in Figure <ref type="figure" target="#fig_7">17c</ref>. Figure <ref type="figure" target="#fig_6">16b</ref> shows the counting error ratio of Motion-Fi on the same traces. Except for the count error ratio of 3% of v 1 , all the other volunteers bear the counting error ratio of over 4%. Motion-Fi uses a template-matching approach for repetition segmentation, requiring the repetition to be stable in a session. However, it is difficult for users who lack exercise experience to keep the workout stable, especially with rest intervals. Figure <ref type="figure" target="#fig_10">18</ref> compares segmentation using MobiFit and Motion-Fi for a squat trace performed by v 6 . MobiFit correctly segments the long rest interval between the second and third squats. However, Motion-Fi does not distinguish the exercise repetition and rest interval, which wrongly counts the long rest interval as two repetitions, as shown in Figure <ref type="figure" target="#fig_10">18b</ref>.</p><formula xml:id="formula_8">Counting Error Ratio = | N est -N truth N truth | ? 100%<label>(10)</label></formula><p>When volunteers repeat exercise repetitions at least twice for each type, MobiFit uses type recognition to reduce the counting error ratio. Figure <ref type="figure" target="#fig_11">19a</ref> compares the false positive rate of counting with/without the refinement. The results are improved after applying refinement, which removes the non-exercise actions during exercise type switching. Because most wrongly counted actions come from switching between standing and lying postures, they do not happen repeatedly. After refinement, the average counting error ratio is reduced to 1.4%.</p><p>After segmentation, MobiFit also outputs the duration of each exercise repetition and rest interval. The duration distribution shows the stability of volunteers during freehand exercises, which is an indicator of the quality of freehand exercises. Figure <ref type="figure" target="#fig_11">19b</ref> shows the cumulative distribution function (CDF) of repetition duration on squats for ten volunteers. Volunteer v 1 exhibits the most stable repetition duration, with over 65% of their squats being between 3 and 3.5 s. Figure <ref type="figure" target="#fig_11">19b</ref> also shows that female Volunteers v 5 and v 6 have the shortest duration, which needs to be prolonged to achieve the exercise effect of squats. To evaluate accuracy on the duration estimation, we recorded the first 100 squats for each volunteer. The video rate is 30 frames per second. We manually analyzed the video and selected the start and end frames for each squat, recording the corresponding timestamp as TS truth and TE truth . We calculated the start, end and duration error for each squat repetition, using Equations ( <ref type="formula">11</ref>)-( <ref type="formula">13</ref>), respectively. Figure <ref type="figure" target="#fig_11">19c</ref> shows the CDF of estimation error on start, end and duration. The start and end errors are within 0.21 and 0.27 s, respectively. Overall, 98% of the duration error is within 0.3 s. We evaluated the recognition accuracy of MobiFit with two procedures and compared the results of Motion-Fi. The first took all traces for five-fold cross-validation and then selected the best combination of features and classifiers. The second used the traces of the first week to train the model. Then, the recognition accuracy was evaluated day by day with the traces in the second week and after three months to show recognition permanence, i.e., the recognition accuracy does not decline quickly with time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Start Time Error</head><p>Cross-validationon Features and classifier: For feature combinations, we exploited the classifier of Cubic SVM, whose results are shown in Table <ref type="table" target="#tab_2">2</ref>, compared with Motion-Fi. The first two rows indicate that the low-frequency features outperform the time domain features of Motion-Fi, which confirms Insight 2 in the analytic model. After adding the FFT coefficient, the mean recognition accuracy across all volunteers is 94.1%. There are two reasons Motion-Fi's is inferior to MobiFit. First, Motion-Fi does not distinguish the exercise repetition and rest interval, increasing the difficulty of recognition. Second, all the features used in Motion-Fi are time-domain features, which are affected by the variance of payload traffic contained in cellular signals. We further dug into the confusion matrix of v 3 , as shown in Figure <ref type="figure" target="#fig_21">20</ref>. Motion-Fi misclassifies 33% of lunges to deadlifts, and its classification accuracy of sit-ups is only 82%. On the contrary, MobiFit achieves high classification accuracy on lunges. For MobiFit, the highest classification error is misclassifying 8% of sit-ups as push-ups, as sit-ups are harder to complete stably. With the best feature combination, we evaluated recognition accuracy on different classifiers, as shown in Table <ref type="table" target="#tab_3">3</ref>. The table shows that all the classifiers with high-order kernels achieve above 90% accuracies, reflecting that the characteristics of low-frequency features are in high orders. best classifier the SVM with the cubic kernel. Therefore, MobiFit chooses the low-frequency features from FFT and DWT and applies the Cubic SVM as the classifier. Permanence: To verify the permanence of MobiFit on recognition, we used the firstweek traces to train the classifier. The data traces in the second week were used to test the accuracy day by day, and we further used the data traces after three months for verification. We did the same permanence evaluation with Motion-Fi. Table <ref type="table" target="#tab_4">4</ref> shows the permanence results across all volunteers. MobiFit's classification accuracy decreases slowly over time, remaining above 92% within one week and dropping to 81% after three months. The drop after three months may come from the seasonal clothing changes that cause action distortion during exercises. Motion-Fi's classification accuracy decays more quickly over time than that of MobiFit. We evaluated and compared the performance of MobiFit and Motion-Fi in terms of counting accuracy, activity recognition accuracy and permanence in the evaluation section. Through comparison, we first confirm that the proposed repetition segmentation scheme outperforms the template matching algorithm of Motion-Fi on the accuracy of repetition counting. Second, we show the proposed low-frequency features are better than time-domain features extracted by Motion-Fi for type classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Parameter Evaluation</head><p>In this section, we evaluate the deployment parameters, including the distance between the receiver and the volunteer, the deployment height of the receiver and the sliding window size of spectrogram analysis. Finally, we evaluate the feasibility of using MobiFit outdoors and for multiple people exercising together.</p><p>The distance between user and receiver affects the block effect of the torso on signal propagation. The receiver will fall to capture the block effect due to large distances. We studied the impact of different distances between user and receiver on repetition counting. On account of the stability during freehand exercises, we selected Volunteer v 1 to carry out squats at 40, 60, 80, 100 and 120 cm away from the receiver. Figure <ref type="figure" target="#fig_22">21a</ref> shows that MobiFit achieves counting error ratio below 3% within 80 cm. When the distance reaches 120 cm, the counting error is over 50%. It reveals that the user should exercise at a distance of 40-80 cm from the receiver. During the deployment of MobiFit, the distance of 60 cm is taken as default. It also suggests the possibility to support multiple people exercising together when they are more than 120 cm apart. To further explore the block effect beyond 120 cm, we collected the signal sequence when v 1 stands stationary at 140 cm for about 50 s. Figure <ref type="figure" target="#fig_22">21b</ref> compares the signal sequences' standard deviations when v 1 squats at five positions and stands at 140 cm. The standard deviation of signal sequence when squatting at 120 cm is close to that of the static sequence at 140 cm, which confirms that the receiver cannot capture freehand exercises beyond 120 cm.</p><p>When volunteers perform different freehand exercises, their torsos experience different heights during workouts, so we evaluated the impact of different heights to put the receiver on counting error. We placed the receiver at 0, 30, 60 and 90 cm above the ground. v 1 carries out six types of freehand exercises for each receiver's height. Figure <ref type="figure" target="#fig_23">22a</ref> shows the counting error ratio. Push-ups are mostly affected by different heights, because the torso is close to the ground when doing push-ups, undoubtedly limiting the variation of block effect for high receiver height. For the receiver's height of 60 cm, the crunch and sit-up errors also increase clearly, as the highest point of the torso is no more than 100 cm for most people during these two workouts. The squat counting error is relatively small because the lowest point of the torso is at least 40-50 cm. In general, the recommended deployment of MobiFit is to place the receiver on the ground, taking a step back and practicing in front of the receiver for most freehand exercises.</p><p>The spectrogram analysis uses a sliding window; therefore, the choice of the window size is critical to the counting result. Since MobiFit only deals with 100 Hz down-sampled signals, we cannot observe the frequency components below 1 Hz when the window length is smaller than 100. On the contrary, when the window is too large, such as 1000, a window may contain more than one repetition because the exercise repetition is usually within 3-5 s. To evaluate the impact of STFT's window size on counting, we increased the window size from 100 to 1000 with steps of 100. We used Volunteer v 1 's 100 squats for evaluation. Figure <ref type="figure" target="#fig_23">22b</ref> depicts the minimum count ratio achieves at window size 500. Since the window size is recommended to be a power of 2 when performing DWT, MobiFit selects the window size as 512. Exercising together: Figure <ref type="figure" target="#fig_24">23a</ref> shows the photo when v 3 and v 4 are squatting together. Both volunteers work out in front of their corresponding receivers. We set three distances between two volunteers at 60, 120 and 180 cm. v 3 only carried out squats, while v 4 conducted three types of activities, squat, sit-up and limb exercises, such as raising arms or kicks. The counting errors of v 3 are shown in Figure <ref type="figure" target="#fig_24">23b</ref>. When the two volunteers are 60 cm apart, the squats and sit-ups of Volunteer v 4 has more effect on the counting error of v 3 , compared to when v 4 was conducting limb exercises. Here, v 4 was about 85cm from v 3 's receiver, which is still not far enough to avoid his interference. It also reveals that the torso has a more significant impact on cellular signal propagation than limbs. When the two volunteers were 120 cm apart, the count error of v 3 is below 2%. It confirms that MobiFit supports multiple users exercising together, if they are 120 cm apart.</p><p>Outdoor: v 1 and v 2 conducted squats on the observation deck on campus, as shown in Figure <ref type="figure" target="#fig_17">14c</ref>. v 1 and v 2 exercised in front of their receiver and collected 150 repetitions each. Figure <ref type="figure" target="#fig_24">23</ref> shows the counting error ratio of 1.3% and 2% for v 1 and v 2 , respectively, consistent with the results indoors, which confirms the feasibility of using MobiFit outdoors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this paper, we study the feasibility of using ubiquitous cellular signals to help users perform effective freehand exercises. MobiFit works in a contactless manner, which can automatically count and recognize six freehand exercises and provide exercise repetition and rest interval distribution for each session to evaluate workout quality. To build MobiFit, we study the relationship between freehand exercises and received down-sample cellular signal sequence, formulate the torso block effect on cellular signal propagation and construct the analytic signal model. Moreover, we propose a spectrogram analysis method to segment the exercise repetition and rest interval of each repetition and count the repetition number. Based on the segmented phases of each repetition, we extract lowfrequency features to classify different types of freehand exercises. MobiFit achieves an accuracy of 98.6% in repetition counting, 94.1% in exercise classification and low repetition duration estimating error within 0.3 s. Moreover, the experiments confirm the feasibility of MobiFit both indoors and outdoors and to support multiple users exercising together.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Application scenario of MobiFit and the collected data trace during ten squats with segmentation result [15].</figDesc><graphic url="image-6.png" coords="2,66.50,474.50,180.86,135.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Multi-frame structure on Beacon Channel.</figDesc><graphic url="image-8.png" coords="5,69.95,85.74,455.38,111.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Corridor deployment for experimental study.</figDesc><graphic url="image-9.png" coords="5,167.27,451.00,386.87,146.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Signal sequence with two squats labeled out (b) Phase decomposition of two squats (c) Amplitude distributions of four phases</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Down-sampled signal sequence while squatting [15].</figDesc><graphic url="image-12.png" coords="6,373.49,183.19,178.58,133.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Down-sampled signal sequence recorded while squatting at different positions.</figDesc><graphic url="image-13.png" coords="6,40.66,499.58,168.00,126.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Signal sequences of three different freehand exercises.</figDesc><graphic url="image-16.png" coords="7,48.80,270.46,165.15,134.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Impact of human motion on signal propagation [15].</figDesc><graphic url="image-20.png" coords="8,362.37,159.09,189.50,105.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>y d ( f , t) represents the superposition of cellular signals propagating along the dynamic paths. y d ( f , t) can be further divided into two terms, as shown in Equation (2). y r ( f , t) represents the superposition of signals reflected by the torso during exercises, shown in Equation (3). P r indicates the path set whose signal propagation distance changes with body motion. a p ( f , t) is the complex-value representation of attenuation along with path p. x(t) is the symbol transmitted within time t. c denotes the speed of light and f represents the beacon channel frequency. d p denotes the distance of the path p. The reflected path change will cause the frequency or phase shift in y r ( f , t). Wi-Fi-or RFID-based exercise assistants focus on extracting Doppler frequency shift or phase shift for exercise recognition. For MobiFit, the propagation paths of cellular signals are on the kilometer level, much longer than the 10 m level under Wi-Fi or RFID. More reflection exists during cellular signal propagation except for human motion. Thus, y r ( f , t) also does not account for low-frequency fluctuation of the observation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>y b ( f , t) represents the superposition of cellular signals related to block effect, calculated in Equation (4). P b indicates the signal propagation path involved in the block effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Block effect function of ? p (t) with different duty ratio.</figDesc><graphic url="image-21.png" coords="9,167.27,134.85,355.28,116.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. MobiFit framework with an example of a squat session [15].</figDesc><graphic url="image-23.png" coords="10,167.27,400.24,328.73,142.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. A session of squats performed by a volunteer with red lines and number marking the ground truth of each repetition.Inspired by Insight 1 from the analysis model, each exercise repetition has a similar primary frequency corresponding to the exercise repetition cycle. MobiFit performs spectrogram analysis on the cellular signal sequence to study the amplitude changes on the primary frequency for exercise repetition segmentation, which consists of the following three steps shown in Algorithm 1 (Segmentation Code: https://github.com/TGL-Silver/MobiFit (accessed on 26 June 2021)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Algorithm 1 : 4 F 6 //judge start 7 if 8 //duration criterion and amplitude criterion 9 if 10 S 16 if 20 //update criterion 21 if</head><label>14678910162021</label><figDesc>Segmentation. Input: a[] //received amplitude sequence Output: S[], E[] //timestamps of the start and end for each repetition 1 ? r = 0.8; ? a = 0.75; ? = 1.5 //scale factor for time and amplitude criterion 2 w = 512, l = 8, d = 4; //STFT window, sliding step, differentiating interval 3 for each window i do [i]=STFT(a[tw : t], Hamming);//create spectrogram with Hamming Window 5 D(i) = A[i] -A[id];//calculate differentiation on primary frequency peak(D(i)) then (ie n-1 ) &gt; ? r ? r and (S n = null or D(i) &gt; D(S n )) then (i -S n ) &gt; ? a ? a and (A(S n , i)) &gt; ?(A(E n-1 , E n )) then 17 if E n = null then 18 E n = i; n + +; 19 end (i -E n-1 ) &lt; ? r ? r and D(i) &lt; D(E n-1 ) then 22 E n-1 = i;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Spectrogram analysis for segmentation [15].</figDesc><graphic url="image-24.png" coords="12,53.90,269.47,220.37,166.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Repetition analysis results of MobiFit [15].</figDesc><graphic url="image-26.png" coords="13,169.76,417.58,168.00,126.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Features extracted from repetitions of six exercise types. Note that MobiFit cut out one repetition only with a delay of one sliding window. The feature extraction is carried out immediately after segmentation, and then the SVM classifier is called to recognize the exercise type of current repetition. The features used in SVM are the second to fifth low-frequency coefficients extracted by FFT and the lowfrequency coefficients of the seventh and high-frequency coefficients of the fifth to seventh levels extract by DWT. MobiFit realizes real-time repetition counting and recognition.</figDesc><graphic url="image-28.png" coords="14,36.00,336.42,529.76,316.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. Evaluation scenarios [15].</figDesc><graphic url="image-30.png" coords="15,219.57,347.50,155.29,116.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 15 .</head><label>15</label><figDesc>Figure 15. Six kinds of freehand exercises [15].</figDesc><graphic url="image-32.png" coords="16,167.27,259.83,342.90,136.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 16 .Figure 17 .</head><label>1617</label><figDesc>Figure 16. Counting error ratio comparison.</figDesc><graphic url="image-36.png" coords="17,215.02,431.75,165.24,127.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 18 .Figure 19 .</head><label>1819</label><figDesc>Figure 18. Counting comparison with checks labeled repetitions.</figDesc><graphic url="image-41.png" coords="18,211.47,455.28,176.40,132.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 20 .</head><label>20</label><figDesc>Figure 20. Comparison on confusion matrix of type recognition for Volunteer v 3 .</figDesc><graphic url="image-43.png" coords="19,169.76,501.04,185.35,156.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 21 .</head><label>21</label><figDesc>Figure 21. Impact of different distances and heights.</figDesc><graphic url="image-45.png" coords="21,169.76,92.39,188.78,141.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 22 .</head><label>22</label><figDesc>Figure 22. Impact of different deployment heights and window sizes.</figDesc><graphic url="image-47.png" coords="22,169.76,98.56,188.20,148.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 23 .</head><label>23</label><figDesc>Figure 23. Results of exercising together and outdoors [15].</figDesc><graphic url="image-49.png" coords="22,43.06,512.21,163.20,125.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Detailed parameters for ten volunteers [15].</figDesc><table><row><cell cols="2">Volunteer Gender</cell><cell>Height</cell><cell>Weight</cell><cell>BMI</cell><cell>Age</cell><cell cols="2">Session Repetition</cell></row><row><cell>v 1</cell><cell>male</cell><cell>184</cell><cell>72</cell><cell>21.3</cell><cell>24</cell><cell>249</cell><cell>2670</cell></row><row><cell>v 2</cell><cell>male</cell><cell>180</cell><cell>75</cell><cell>23.1</cell><cell>23</cell><cell>224</cell><cell>2307</cell></row><row><cell>v 3</cell><cell>male</cell><cell>177</cell><cell>70</cell><cell>22.3</cell><cell>22</cell><cell>216</cell><cell>2246</cell></row><row><cell>v 4</cell><cell>male</cell><cell>175</cell><cell>67</cell><cell>21.9</cell><cell>23</cell><cell>222</cell><cell>2375</cell></row><row><cell>v 5</cell><cell>famale</cell><cell>166</cell><cell>55</cell><cell>20.0</cell><cell>24</cell><cell>192</cell><cell>1971</cell></row><row><cell>v 6</cell><cell>famale</cell><cell>165</cell><cell>50</cell><cell>18.4</cell><cell>22</cell><cell>195</cell><cell>1988</cell></row><row><cell>v 7</cell><cell>male</cell><cell>170</cell><cell>65</cell><cell>22.5</cell><cell>26</cell><cell>222</cell><cell>2298</cell></row><row><cell>v 8</cell><cell>male</cell><cell>173</cell><cell>70</cell><cell>23.4</cell><cell>25</cell><cell>219</cell><cell>2276</cell></row><row><cell>v 9</cell><cell>male</cell><cell>176</cell><cell>78</cell><cell>25.2</cell><cell>23</cell><cell>230</cell><cell>2532</cell></row><row><cell>v 10</cell><cell>male</cell><cell>178</cell><cell>85</cell><cell>26.8</cell><cell>24</cell><cell>217</cell><cell>2297</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>= |TS est -TS truth | (11) End Time Error = |TE est -TE truth | (12) Duration Error = |(TE est -TS est ) -(TE truth -TS truth )|</figDesc><table><row><cell>(13)</cell></row><row><cell>6.2.2. Recognition Classification</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Recognition comparison of MobiFit, Motion-Fi [15].</figDesc><table><row><cell>Features Volunteer</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Mean</cell></row><row><cell>Motion-Fi</cell><cell cols="11">83.5% 80.2% 81.4% 84.2% 82.9% 82.1% 82.6% 80.7% 81.3% 83.6% 82.3%</cell></row><row><cell>Wavelt</cell><cell cols="11">92.4% 91.3% 87.3% 91.7% 91.4% 90.7% 91.4% 90.6% 91.5% 91.8% 91%</cell></row><row><cell>Wavelt+FFT</cell><cell cols="11">94.3% 93.4% 95.2% 94.6% 94.2% 95.2% 95.3% 92.7% 93.6% 92.4% 94.1%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Classification comparison of classifiers of MobiFit</figDesc><table><row><cell>Method</cell><cell>Tree</cell><cell cols="6">Ensemble KNN SVM:Cubic Linear Quadratic Gaussian</cell></row><row><cell cols="2">Accuracy 80.6%</cell><cell>89.7%</cell><cell>82.4%</cell><cell>94.1 %</cell><cell>88.6%</cell><cell>91.4%</cell><cell>90.2%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Classification permanence of MobiFit, Motion-Fi [15].</figDesc><table><row><cell>Day</cell><cell>Day 1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Day 2 Day 3 Day 4 Day 5 Day 6 Day 7 After 3 Months</head><label></label><figDesc></figDesc><table><row><cell>MobiFit(%)</cell><cell>96.5</cell><cell>95.9</cell><cell>95.2</cell><cell>94.7</cell><cell>93.6</cell><cell>93.4</cell><cell>92.7</cell><cell>81</cell></row><row><cell>Motion-Fi(%)</cell><cell>93.4</cell><cell>90.3</cell><cell>87.2</cell><cell>85.4</cell><cell>80.6</cell><cell>82.4</cell><cell>80.2</cell><cell>43.5</cell></row></table></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Availability Statement: Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of Interest:</head><p>The authors declare no conflict of interest.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">Fitness on the Go: The Anytime Anywhere Holistic Workout for Busy People</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</editor>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Ebury Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Kinect-based rehabilitation exercise monitoring and guidance system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Espy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Reinthal</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICSESS.2014.6933678</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE 5th International Conference on Software Engineering and Service Science</title>
		<meeting>the 2014 IEEE 5th International Conference on Software Engineering and Service Science<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">June 2014</date>
			<biblScope unit="page" from="762" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">RunBuddy: A Smartphone System for Running Rhythm Monitoring</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1145/2750858.2804293</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing<address><addrLine>Osaka, Japan; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-09">September 2015. 2015</date>
			<biblScope unit="page" from="133" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">FitCoach: Virtual fitness coach empowered by wearable mobile devices</title>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM.2017.8057208</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE INFOCOM 2017-IEEE Conference on Computer Communications</title>
		<meeting>the IEEE INFOCOM 2017-IEEE Conference on Computer Communications<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-05">May 2017</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Passive Capacitive based Approach for Full Body Gym Workout Recognition and Counting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">F</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hevesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lukowicz</surname></persName>
		</author>
		<idno type="DOI">10.1109/PERCOM.2019.8767393</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 IEEE International Conference on Pervasive Computing and Communications (PerCom)</title>
		<meeting>the 2019 IEEE International Conference on Pervasive Computing and Communications (PerCom)<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-03">March 2019</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Why We Use and Abandon Smart Devices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tanenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.1145/2750858.2804288</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing<address><addrLine>Maui, HI, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-09">September 2015. 2015</date>
			<biblScope unit="page" from="635" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A platform for free-weight exercise monitoring with passive tags</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shangguan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMC.2017.2691705</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Mob. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3279" to="3293" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Device free localization technology for human detection and counting with RF sensor networks: A review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shukri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Kamarudin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jnca.2017.08.014</idno>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="157" to="174" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">WiFi Sensing with Channel State Information: A Survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3310194</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Human Activity Sensing with Wireless Signals: A Survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hong</surname></persName>
		</author>
		<idno type="DOI">10.3390/s20041210</idno>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<date type="published" when="1210">2020. 1210</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Hristov</surname></persName>
		</author>
		<title level="m">Fresnel Zones in Wireless Links, Zone Plate Lenses and Antennas</title>
		<meeting><address><addrLine>Norwood, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Artech House</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Understanding and Modeling of WiFi Signal Based Human Activity Recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahzad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2789168.2790093</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 21st Annual International Conference on Mobile Computing and Networking<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09">September 2015</date>
			<biblScope unit="page" from="7" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">RT-Fall: A Real-time and Contactless Fall Detection System with Commodity WiFi Devices</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMC.2016.2557795</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Mob. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="511" to="526" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Device-free Personalized Fitness Assistant Using WiFi</title>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Chuah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MobiFit: Contactless Fitness Assistant for Freehand Exercises Using Just One Cellular Signal Receiver</title>
		<author>
			<persName><forename type="first">G</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Mobility, Sensing and Networking</title>
		<meeting>the 16th International Conference on Mobility, Sensing and Networking<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12">December 2020</date>
			<biblScope unit="page" from="17" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mobility Detection Using Everyday GSM Traces</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Varshavsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lamarca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Consolvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hightower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Griswold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>De Lara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UbiComp 2006: Ubiquitous Computing</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Dourish</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Friday</surname></persName>
		</editor>
		<meeting><address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer: Berlin/Heidelberg</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="212" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tracking and Sharing Daily Activity Levels with Unaugmented Mobile Phones</title>
		<author>
			<persName><forename type="first">I</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maitland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Barkhuus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chalmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><surname>Shakra</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11036-007-0011-7</idno>
	</analytic>
	<monogr>
		<title level="j">Mob. Netw. Appl</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="185" to="199" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Practical Activity Recognition using GSM Data</title>
		<author>
			<persName><forename type="first">I</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<idno>CSTR-06-016</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>University of Bristol: Bristol, UK</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Moving target detection by using new LTE-based passive radar</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S A R</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rashid</surname></persName>
		</author>
		<idno type="DOI">10.2528/PIERB15070901</idno>
	</analytic>
	<monogr>
		<title level="j">Prog. Electromagn. Res. B</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="145" to="160" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust Dynamic Hand Gesture Interaction using LTE Terminals</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 19th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)</title>
		<meeting>the 2020 19th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04">April 2020</date>
			<biblScope unit="page" from="109" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards Using Cell Towers as Illuminating Sources for Keystroke Monitoring</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><surname>Spidermon</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM41043.2020.9155447</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE INFOCOM 2020-IEEE Conference on Computer Communications</title>
		<meeting>the IEEE INFOCOM 2020-IEEE Conference on Computer Communications<address><addrLine>Toronto, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="666" to="675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">5G Ubiquitous Sensing: Passive Environmental Perception in Cellular Systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gholampooryazdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sigg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 IEEE Vehicular Technology Conference (VTC-Fall)</title>
		<meeting>the 2017 IEEE Vehicular Technology Conference (VTC-Fall)<address><addrLine>Toronto, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10-27">24 September-27 October 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Capturing the human figure through a wall</title>
		<author>
			<persName><forename type="first">F</forename><surname>Adib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<idno type="DOI">10.1145/2816795.2818072</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">219</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Through-wall human pose estimation using radio signals</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abu Alsheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="page" from="7356" to="7365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">RF-Sensing of Activities from Non-Cooperative Subjects in Device-Free Recognition Systems Using Ambient and Local Signals</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beigl</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMC.2013.28</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Mob. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="907" to="920" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Motion-Fi: Recognizing and Counting Repetitive Motions with Passive Wireless Backscattering</title>
		<author>
			<persName><forename type="first">N</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE INFOCOM 2018-IEEE Conference on Computer Communications</title>
		<meeting>the IEEE INFOCOM 2018-IEEE Conference on Computer Communications<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04">April 2018</date>
			<biblScope unit="page" from="2024" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Device-Free Fall Detection by Wireless Networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><surname>Wifall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE INFOCOM 2014-IEEE Conference on Computer Communications</title>
		<meeting>the IEEE INFOCOM 2014-IEEE Conference on Computer Communications<address><addrLine>Toronto, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-05-02">April 27-May 2, 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ubiquitous smoking detection with commercial wifi infrastructures</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shangguan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Smokey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications</title>
		<meeting>the IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-04">April 2016</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Wi-chase: A WiFi based human activity recognition system for sensorless environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arshad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 IEEE 18th International Symposium on A World of Wireless, Mobile and Multimedia Networks (WoWMoM)</title>
		<meeting>the 2017 IEEE 18th International Symposium on A World of Wireless, Mobile and Multimedia Networks (WoWMoM)<address><addrLine>Macau, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06">June 2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">E-eyes: device-free location-oriented activity identification using fine-grained wifi signatures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gruteser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 20th Annual International Conference on Mobile Computing and Networking<address><addrLine>Maui, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
			<biblScope unit="page" from="617" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Indoor Motion Detection Using Wi-Fi Channel State Information in Flat Floor Environments Versus in Staircase Environments</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pahlavan</surname></persName>
		</author>
		<idno type="DOI">10.3390/s18072177</idno>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2018">2018. 2177</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Wig: Wifi-based gesture recognition system</title>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 24th International Conference on Computer Communication and Networks (ICCCN)</title>
		<meeting>the 2015 24th International Conference on Computer Communication and Networks (ICCCN)<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-08">August 2015</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A device-free number gesture recognition approach based on deep learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 12th International Conference on Computational Intelligence and Security (CIS)</title>
		<meeting>the 2016 12th International Conference on Computational Intelligence and Security (CIS)<address><addrLine>Wuxi, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12">December 2016</date>
			<biblScope unit="page" from="57" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multi-user gesture recognition using WiFi</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Venkatnarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahzad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services</title>
		<meeting>the 16th Annual International Conference on Mobile Systems, Applications, and Services<address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="page" from="401" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">New insights into wifi-based device-free localization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Youssef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM Conference on Pervasive and Ubiquitous Computing Adjunct Publication</title>
		<meeting>the 2013 ACM Conference on Pervasive and Ubiquitous Computing Adjunct Publication<address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
			<biblScope unit="page" from="541" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fine-grained Device-free Motion Tracing using RF Backscatter</title>
		<author>
			<persName><forename type="first">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bharadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kotaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katti</surname></persName>
		</author>
		<author>
			<persName><surname>Wideo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI 15)</title>
		<meeting>the 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI 15)<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
			<biblScope unit="page" from="189" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Probr-a generic and passive WiFi tracking system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Scheuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mazlami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sch?ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Carli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bocek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 IEEE 41st Conference on Local Computer Networks (LCN)</title>
		<meeting>the 2016 IEEE 41st Conference on Local Computer Networks (LCN)<address><addrLine>Dubai, UAE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11">November 2016</date>
			<biblScope unit="page" from="495" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An evaluation method of channel state information fingerprinting for single gateway indoor localization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Berruet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Baala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caminada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Guillet</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jnca.2020.102591</idno>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<date type="published" when="2020">2020. 102591</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">When RSSI encounters deep learning: An area localization scheme for pervasive sensing systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tagami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jnca.2020.102852</idno>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<date type="published" when="2021">2021. 102852</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">WiGId: Indoor Group Identification with CSI-Based Random Forest</title>
		<author>
			<persName><forename type="first">X</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.3390/s20164607</idno>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">4607</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Ubiquitous Bodyweight Exercise Monitoring with Commodity Wi-Fi Devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Wifit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Ubiquitous Intelligence &amp; Computing</title>
		<meeting>the 2018 Ubiquitous Intelligence &amp; Computing<address><addrLine>Guangzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10">October 2018</date>
			<biblScope unit="page" from="530" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Human Respiration Detection with Commodity Wifi Devices: Do User Location and Body Orientation Matter?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<idno type="DOI">10.1145/2971648.2971744</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing<address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09">September 2016</date>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Device-Free WiFi Human Sensing: From Pattern-Based to Model-Based Approaches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCOM.2017.1700143</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Mag</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="91" to="97" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Toward Centimeter-Scale Human Activity Sensing with Wi-Fi Signals</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="48" to="57" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">From Fresnel Diffraction Model to Fine-grained Human Respiration Sensing with Commodity Wi-Fi Devices</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Interact. Mob. Wearable Ubiquitous Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Foreword By-Haug, T. The GSM System for Mobile Communications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mouly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Pautet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Telecom Publishing</publisher>
			<pubPlace>Palaiseau, France</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Boosting Fine-Grained Activity Sensing by Embracing Wireless Multipath Effects</title>
		<author>
			<persName><forename type="first">K</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3281411.3281425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Emerging Networking EXperiments and Technologies</title>
		<meeting>the 14th International Conference on Emerging Networking EXperiments and Technologies<address><addrLine>Heraklion/Crete, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12">December 2018</date>
			<biblScope unit="volume">pp</biblScope>
			<biblScope unit="page" from="139" to="151" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
