<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast and Globally Convergent Pose Estimation from Video Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Chien-Ping</forename><surname>Lu</surname></persName>
							<email>cplu@ibeam.com..</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE Computer Society</roleName><forename type="first">Gregory</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
							<email>hager@cs.jhu.edu..</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Eric</forename><surname>Mjolsness</surname></persName>
							<email>eric.d.mjolsness@jpl.nasa.gov</email>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<postCode>94086</postCode>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The Johns Hopkins University</orgName>
								<address>
									<addrLine>3400 N. Charles St</addrLine>
									<postCode>21218</postCode>
									<settlement>Baltimore</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Jet Propulsion Laboratory</orgName>
								<address>
									<addrLine>4800 Oak Grove Dr</addrLine>
									<postCode>126-346, 91109-8099</postCode>
									<settlement>Pasadena</settlement>
									<region>MS, CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast and Globally Convergent Pose Estimation from Video Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">74307E2C10FF794E0F6CE965A69F0BA7</idno>
					<note type="submission">received 18 Feb. 1998; revised 24 Feb. 2000; accepted 20 Mar. 2000. Recommended for acceptance by K. Bowyer.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index TermsÐPose estimation</term>
					<term>absolute orientation</term>
					<term>optimization</term>
					<term>weak-perspective camera models</term>
					<term>numerical optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>AbstractÐDetermining the rigid transformation relating 2D images to known 3D geometry is a classical problem in photogrammetry and computer vision. Heretofore, the best methods for solving the problem have relied on iterative optimization methods which cannot be proven to converge and/or which do not effectively account for the orthonormal structure of rotation matrices. We show that the pose estimation problem can be formulated as that of minimizing an error metric based on collinearity in object (as opposed to image) space. Using object space collinearity error, we derive an iterative algorithm which directly computes orthogonal rotation matrices and which is globally convergent. Experimentally, we show that the method is computationally efficient, that it is no less accurate than the best currently employed optimization methods, and that it outperforms all tested methods in robustness to outliers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>D ETERMINING the rigid transformation that relates images to known geometry, the pose estimation problem, is one of the central problems in photogrammetry, robotics, computer graphics, and computer vision. In robotics, pose estimation is commonly used in hand-eye coordination systems <ref type="bibr" target="#b0">[1]</ref>. In computer graphics, it plays a central role in tasks that combine computer-generated objects with photographic scenesÐe.g., landmark tracking for determining head pose in augmented reality <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> or interactive manipulation of objects. In computer vision, pose estimation is central to many approaches to object recognition <ref type="bibr" target="#b5">[6]</ref>.</p><p>The information available for solving the pose estimation problem is usually given in the form of a set of point correspondences, each composed of a 3D reference point expressed in object coordinates and its 2D projection expressed in image coordinates. For three or four noncollinear points, exact solutions can be computed: A fourth-or fifth-degree polynomial system can be formulated using geometrical invariants of the observed points and the problem can be solved by finding roots of the polynomial system <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. However, the resulting methods can only be applied to a limited number of points and are thus sensitive to additive noise and possible outliers.</p><p>For more than four points, closed form solutions do not exist. The classical approach used in photogrammetry is to formulate pose estimation as a nonlinear least-squares problem and to solve it by nonlinear optimization algorithms, most typically, the Gauss-Newton method <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. In the vision literature, the work by Lowe and its variants <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> is an example of applying the Gauss-Newton method to the pose estimation problem. As with most nonlinear optimizations, these methods rely on a good initial guess to converge to the correct solution.</p><p>There is no guarantee that the algorithm will eventually converge or that it will converge to the correct solution.</p><p>A class of approximate methods for pose estimation has been developed by relaxing the orthogonality constraint on rotation matrices and/or by simplifying the perspective camera model <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. In iterative reduced perspective methods <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b25">[26]</ref>, an approximate solution computed using a simplified camera model is iteratively refined to approach a full perspective solution. In these methods, the rotation matrix is computed in two steps: First, a linear (unconstrained) solution is computed and then this solution is fit to the ªclosestº orthogonal matrix. It has been shown that this two-step approach for computing rotation is not the same as finding the best orthogonal matrix <ref type="bibr" target="#b26">[27]</ref>. Again, with such methods there is no guarantee that they will eventually converge to the correct solution when applied iteratively.</p><p>The developments in this article were originally motivated by the work of Haralick et al. <ref type="bibr" target="#b27">[28]</ref>. They introduced a pose estimation algorithm which simultaneously computes both object pose and the depths of the observed points. The algorithm seems to be globally convergent, although a complete proof was not given. What makes this algorithm attractive is that the nonlinearity due to perspective is eliminated by the introduction of the depth variables. However, this algorithm has not received much attention, probably due its slow local convergence rate (hundreds of iterations), as indicated in <ref type="bibr" target="#b27">[28]</ref> and found by ourselves.</p><p>In our approach, we reformulate the pose estimation problem as that of minimizing an object-space collinearity error. From this new objective function, we derive an algorithm that operates by successively improving an estimate of the rotation portion of the pose and then estimates an associated translation. The intermediate rotation estimates are always the best ªorthogonalº solution for each iteration. The orthogonality constraint is enforced by using singular value decomposition, not from specific parameterization of rotations, e.g., Euler angles. We further prove that the proposed algorithm is globally convergent. Empirical results suggest that the algorithm is also extremely efficient and usually converges in five to 10 iterations from very general geometrical configurations. In addition, the same experiments suggest that our method outperforms the Levenberg-Marquardt methods, one of the most reliable optimization methods currently in use, in terms of both accuracy against noise and robustness against outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Outline of the Article</head><p>The remainder of this article is organized as follows: Section 2 describes the formulation of the pose estimation problem more formally and briefly reviews some of the classical iterative methods used to solve it. Section 3 introduces the orthogonal iteration algorithm and proves its global convergence. The link between weak perspective and the proposed method is also presented. In Section 4, detailed performance analyses using large scale simulations are given to compare our method to existing methods. Finally, Section 5 concludes by suggesting some directions in which the method could be extended. An appendix contains technical arguments for two results needed for discussions within the article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM FORMULATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Camera Model</head><p>The mapping from 3D reference points to 2D image coordinates can be formalized as follows: Given a set of noncollinear 3D coordinates of reference points The camera reference frame is chosen so that the center of projection of the camera is at the origin and the optical axis points in the positive z direction. The reference points p i are projected to the plane with z H I, referred to as the normalized image plane, in the camera reference frame. 1 Let the image point v i u i Y v i Y I t be the projection of p i on the normalized image plane. Under the idealized pinhole imaging model, v i , q i and the center of projection are collinear. This fact is expressed by the following equation: 1. We assume throughout this article that the camera internal calibration (including both lens distortion and the mapping from metric to pixel coordinates) is known.</p><formula xml:id="formula_0">p i x i Y y i Y z i t Y i IY F F F Y nY n ! Q expressed in an object-cen- tered reference frame, the corresponding camera-space coordinates q i x H i Y y H i Y z H i t ,</formula><formula xml:id="formula_1">u i r t I p i t x r t Q p i t z Q v i r t P p i t y r t Q p i t z Q or</formula><formula xml:id="formula_2">v i I r t Q p i t z p i tY R</formula><p>which is known as the collinearity equation in the photogrammetry literature. However, another way of thinking of collinearity is that the orthogonal projection of q i on v i should be equal to q i itself. This fact is expressed by the following equation:</p><formula xml:id="formula_3">p i t i p i tY S where i v i v t i v t i v i T</formula><p>is the line-of-sight projection matrix that, when applied to a scene point, projects the point orthogonally to the line of sight defined by the image point v i . Since i is a projection operator, it satisfies the following properties:</p><formula xml:id="formula_4">kxk ! k i xkY x P Q Y U t i i Y U P i i t i i X U</formula><p>In the remainder of this article, we refer to (4) as the image space collinearity equation and (5) as the object space collinearity equation. The pose estimation problem is to develop an algorithm for finding the rigid transform Y t that minimizes some form of accumulation of the errors (for example, summation of squared errors) of either of the collinearity equations (see Fig. <ref type="figure" target="#fig_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classical Iterative Methods</head><p>As noted in the introduction, the most widely used and most accurate approaches to the pose estimation problem use iterative optimization methods. In classical photogrammetry, the pose estimation problem is usually formulated as the problem of optimizing the following objective function:</p><formula xml:id="formula_5">n iI 4 u i À r t I p i t x r t Q p i t z P v i À r t P p i t y r t Q p i t z P 5 Y V</formula><p>given observed image points v i u i Y v i Y I t , which are usually modeled as theoretical image points perturbed by Gaussian noise. The rotation matrix, , is usually parameterized using Euler angles. Note that this is a minimization over image-space collinearity.</p><p>Two commonly used optimization algorithms are the Gauss-Newton method and Levenberg-Marquardt method. The Gauss-Newton method is a classical technique for solving nonlinear least-squares problems. It operates by iteratively linearizing the collinearity equation around the current approximate solution by first-order Taylor series expansion and then solving the linearized system for the next approximate solution. The Gauss-Newton method relies on a good local linearization. If the initial approximate solution is good enough, it should converge very quickly to the correct solution. However, when the current solution is far from the correct one and/or the linear system is illconditioned, it may converge slowly or even fail to converge altogether. It has been empirically observed <ref type="bibr" target="#b28">[29]</ref> that, for the Gauss-Newton method to work, the initial approximate solutions have to be within IH percent of scale for translation and within IS o for each of the three rotation angles.</p><p>The Levenberg-Marquardt method can be regarded as an interpolation of steepest descent and the Gauss-Newton method. When the current solution is far from the correct one, the algorithm behaves like a steepest descent method: slow, but guaranteed to converge. When the current solution is close to the correct solution, it becomes a Gauss-Newton method. It has become a standard technique for nonlinear least-squares problems and has been widely adopted in computer vision <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> and computer graphics <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Why Another Iterative Algorithm?</head><p>Classical optimization techniques are currently the only choice when observed data is noisy and a high accuracy solution to the pose estimation problem is desired. However, since these algorithms are designed for solving general optimization problems, the specific structure of the pose estimation problem is not fully exploited. Furthermore, the commonly used Euler angle parameterization of rotation obscures the algebraic structure of the problem. The analysis for both global and local convergence is only valid when the intermediate result is close to the solution. At the same time, recent developments in vision-based robotics <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref> and augmented reality demand pose estimation algorithms be not only accurate, but also be robust to corrupted data and be computationally efficient. Hence, there is a need for algorithms that are as accurate as classical optimization methods, yet are also globally convergent and fast enough for real-time applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE ORTHOGONAL ITERATION ALGORITHM</head><p>In this section, we develop our new pose estimation algorithm, subsequently referred to as the orthogonal iteration (OI) algorithm. The method of attack is to first define pose estimation using an appropriate object space error function and then to show that this function can be rewritten in a way which admits an iteration based on the solution to the 3D-3D pose estimation or absolute orientation problem. Since the algorithm depends heavily on the solution to absolute orientation, we first review the absolute orientation problem and its solution before presenting our algorithm and proving its convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Optimal Absolute Orientation Solution</head><p>The absolute orientation problem can be posed as follows: Suppose the 3D camera-space coordinates q i could be reconstructed physically (for example, by range sensing) or computationally (for example, by stereo matching or structure-from-motion). Then, for each observed point, we have</p><formula xml:id="formula_6">q i p i tX W</formula><p>Computing absolute orientation is the process of determining and t from corresponding pairs q i and p i X With three or more noncollinear reference points, and t can be obtained as a solution to the following least-squares problem</p><formula xml:id="formula_7">min Yt n iI kp i t À q i k P Y sujet to t sX IH</formula><p>Such a constrained least-squares problem <ref type="bibr" target="#b34">[35]</ref> can be solved in closed form using quaternions <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref> or singular value decomposition (SVD) <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>.</p><p>The SVD solution proceeds as follows: Let fp i g and fq i g denote lists of corresponding vectors related by (1) and define</p><formula xml:id="formula_8">" p def I n n iI p i Y " q def I n n iI q i Y II</formula><p>that is, " p and " q are the centroid of fp i g and fq i g, respectively. Define</p><formula xml:id="formula_9">p H i p i À " pY q H i q i À " qY IP and w n iI q H i p H i t X IQ</formula><p>In other words, I n w is the sample cross-covariance matrix between fp i g and fq i gX It can be shown that <ref type="bibr" target="#b26">[27]</ref> if Ã Y t Ã minimize <ref type="bibr" target="#b9">(10)</ref>, then they satisfy</p><formula xml:id="formula_10">Ã rg mx tr t w IR t Ã " q À Ã " pX IS Let Y AEY be a SVD of w, that is, t w AEX Then, the solution to (10) is Ã t X IT</formula><p>Note that the optimal translation is entirely determined by the optimal rotation and all information for finding the best rotation is contained in w as defined in <ref type="bibr" target="#b12">(13)</ref>. Hence, only the position of the 3D points relative to their centroids is relevant in the determination of the optimal rotation matrix. It is also important to note that, although the SVD of a matrix is not unique, the optimal rotation is as shown in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Algorithm</head><p>We now turn to the development of the Orthogonal Iteration Algorithm. The starting point for the algorithm is to state the pose estimation problem using the following object-space collinearity error vector (see Fig. <ref type="figure" target="#fig_1">2</ref>):</p><formula xml:id="formula_11">e i s À i p i tY IU</formula><p>where i is the observed line-of-sight projection matrix defined as:</p><formula xml:id="formula_12">i v i v t i v t i v i X IV</formula><p>We then seek to minimize the sum of the squared error iY t n iI ke i k P n iI ks À i p i tk P IW over and t. Note that all the information contained in the set of the observed image points fv i g is now completely encoded in the set of projection matrices f i g. Since this objective function is quadratic in t, given a fixed rotation , the optimal value for t can be computed in closed form as:</p><formula xml:id="formula_13">t I n s À I n j j 2 3 ÀI j j À sp j X PH</formula><p>For <ref type="bibr" target="#b19">(20)</ref> to be well-defined, s À I n n iI i must be positive definite, which can be verified as follows:</p><p>For any 3-vector x P Q , it can be shown that</p><formula xml:id="formula_14">x t s À I n n iI i x I n n iI kxk P À x t i x I n n iI kxk P À x t t i i x I n n iI kxk P À k i xk P b HX</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PI</head><p>While kxk P À k i xk P can be individually greater than or equal to zero, they cannot be all equal to zero unless all scene points are projected to the same image point. Therefore, ( <ref type="formula">21</ref>) is generally strictly greater than zero and, thus, the positive definiteness of i is asserted. Given the optimal translation as a function of and defining</p><formula xml:id="formula_15">q i def i p i t nd " q def I n n iI q i Y PP<label>(19)</label></formula><p>can be rewritten as:</p><formula xml:id="formula_16">i n iI kp i t À q i k P X PQ</formula><p>This equation now bears a close resemblance to the absolute orientation problem (compare with <ref type="bibr" target="#b9">(10)</ref>). Unfortunately, in this case, we cannot solve for in closed form as the sample cross-covariance matrix between fp i g and fq i g, that is,</p><formula xml:id="formula_17">w n iI q H i p H i t</formula><p>where p H i p i À " pY q H i q i À " qY PR is dependent on itself. However, can be computed iteratively as follows: First, assume that the kth estimate of is k , t k t k , and q k i k p i t k . The next estimate, kI , is determined by solving the following absolute orientation problem:</p><formula xml:id="formula_18">kI rg min n iI kp i t À i q k i k P PS rg mx tr t w k Y PT</formula><p>where the set of i q k i is treated as a hypothesis of the set of the scene points q i in <ref type="bibr" target="#b9">(10)</ref>. In this form, the solution for kI is given by <ref type="bibr" target="#b15">(16)</ref>. We then compute the next estimate of translation, using <ref type="bibr" target="#b19">(20)</ref>, as:</p><formula xml:id="formula_19">t kI t kI PU</formula><p>and repeat the process. A solution Ã to the pose estimation problem using the orthogonal iteration algorithm is defined to be a fixed point to <ref type="bibr" target="#b24">(25)</ref>, that is, Ã satisfies</p><formula xml:id="formula_20">Ã rg min n iI kp i t À i Ã p i t Ã k P X PV</formula><p>Note that a solution does not necessarily correspond to the correct true pose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Global Convergence</head><p>We now wish to show that the orthogonal iteration algorithm will converge to an optimum of (25) for any set of observed points and any starting point H . Our proof, which is based on the Global Convergence Theorem [39, chapter 6], requires the following definitions: Definition 3.1. A point-to-set mapping e from to is said to be closed at x P if the assumptions</p><formula xml:id="formula_21">1. x k 3 xY x k P 2. y k 3 yY y k P ex k imply 3. y P exX</formula><p>The point-to-set mapping e is said to be closed on if it is closed at each point of .</p><p>Note that continuous point-to-point mappings are special closed point-to-set mappings. Definition 3.2. A set is said to be closed if x k 3 x with x k P implies x P . is said to be compact if it is both closed and bounded.</p><p>Define ys X yQU 3yQ to be the mapping that generates kI from k , that is, kI ys k . According to the Global Convergence Theorem <ref type="bibr" target="#b38">[39]</ref>, to prove the global convergence of the orthogonal iteration algorithm we need to show that 1. ys is closed. 2. All f k g generated by ys are contained in a compact set. 3. ys strictly decreases the objective function unless a solution is reached. To verify the first condition, we note that ys can be considered as the composition of three mappings: p X yQU 3 QÂQ is a point-to-point mapping that represents the computation of w k w k in <ref type="bibr" target="#b23">(24)</ref>.</p><p>h X QÂQ U 3yQ Â qvQ Â yQ is a point-to-set mapping that represents the calculation of the SVD of w k .</p><p>q X yQ Â qvQ Â yQU 3yQ is a point-to-point mapping that represents the computation of kI from the SVD of w k using ( <ref type="formula">16</ref>), where yQ is the set of Q Â Q orthogonal matrices and qvQ is the set of Q Â Q diagonal matrices.</p><p>The first and the last mappings, p and q, are continuous and, hence, are closed. In Appendix A, it is shown that h is also a closed mapping. Therefore, it follows that ys is closed using the fact that the composition of closed mappings is also closed <ref type="bibr" target="#b38">[39]</ref>.</p><p>Since ys always generates orthogonal matrices and the set of orthogonal matrices yQ is compact (closed and bounded), the second criteria is met.</p><p>Finally, we seek to prove the third criteria. The sum of squared error of the estimate kI can be related to that of k as follows:</p><formula xml:id="formula_22">i kI n iI kq kI i À i q kI k P n iI kq kI i À i q k i i q k i À i q kI i k P n iI kq kI i À i q k i k P n iI q k i À q kI i t t i P q kI i À i q k i i q k i À i q kI i n iI kq kI i À i q k i k P n iI q k i À q kI i t t i Pq kI i À i q k i q kI i X</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PW</head><p>Applying the fact that i t i i to the second term in the righthand side of the last equation in ( <ref type="formula">29</ref>), we have</p><formula xml:id="formula_23">n iI P i q k i t i q kI i À Pk i q kI i k P À k i q k i k P k i q kI i k P À n iI k i q kI i À i q k i k P X</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QH</head><p>But, according to ( <ref type="formula">25</ref>) and ( <ref type="formula">27</ref>),</p><formula xml:id="formula_24">n iI kq kI i À i q k i k P n iI kq k i À i q k i k P i k QI</formula><p>and we obtain</p><formula xml:id="formula_25">i kI i k À n iI k i q kI i À i q k i k P X QP</formula><p>Assume that k is not a fixed point of ys, which implies kI T k and q</p><formula xml:id="formula_26">kI i T q k i . If n iI k i q kI i À i q k i k P is equal to zero, then i q kI i i q k i .</formula><p>But since the optimal solution to the absolution orientation problem is unique, according to (25), we must have kI k , which contradicts our assumption that k is not a fixed point. Therefore, n iI k i q kI i À i q k i k P cannot be zero. Combined with (32), we have</p><formula xml:id="formula_27">i kI `i k Y QQ</formula><p>meaning that ys decreases i strictly unless a solution is reached. Now, we can claim that the orthogonal iteration algorithm is globally convergent, that is, a solution, or a fixed point, will eventually be reached from arbitrary starting point. Although global convergence does not guarantee that the true pose will always be recovered, it does suggest that the true pose can be reached from very a broad range of initial guesses. Based on the experiments in Section 4.1, we have empirically observed that the only constraint on H for ys to recover the true pose is that it does not result in translation with negative z component, i.e., it does not place the object behind the camera.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Initialization and Weak Perspective Approximation</head><p>The ys algorithm can be initiated as follows: Given an initial guess H of , compute t H . The initial pose H Y t H is then used to establish a set of hypothesized scene points i H p i t H , which are used to start the first absolute orientation iteration. Although the orthogonal iteration algorithm is globally convergent, it does not guarantee that it will efficiently or eventually converge to the correct solution. Instead of choosing H , we can treat v i themselves as the first hypothesized scene points. This leads to an absolute orientation problem between the set of 3D reference points p i and the set of image points v i considered as coplanar 3D points. This initial absolute orientation problem is related to weak perspective approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Weak-Perspective Model</head><p>Weak-perspective is an approximation to the perspective camera model described in Section 2.1. Under the weak perspective model, we have the following relation for each reference point</p><formula xml:id="formula_28">p i u i % I s r t I p i t x QR v i % I s r t P p i t y Y QR</formula><p>where s is called scale or principle depth. Weak perspective is valid when the depths of all camera-space coordinates are roughly equal to the principle depth and the object is close to the optical axis of the camera. Conventionally, the principle depth is chosen as the depth of the origin of the object space, that is, the z-component of the translation t z when " p, the center of the reference points, is also the origin of the object space. Here, we decouple the scale s from t z , so it can be chosen as the one that minimizes its deviation from the depths of the camera space coordinates</p><formula xml:id="formula_29">n iI r t Q p i t z À s À Á P X QS</formula><p>Of course, we also need to minimize the square of the image error over , t, and s n iI</p><formula xml:id="formula_30">r t I p i t x À s u i À Á P r t P p i t y À s v i À Á P ! X QT</formula><p>Combining <ref type="bibr" target="#b34">(35)</ref> and <ref type="bibr" target="#b35">(36)</ref>, and weighting them equally, we have the following least-squares objective function:</p><formula xml:id="formula_31">n iI kp i t À s v i k P X QU</formula><p>This is the same objective function as for absolute orientation, <ref type="bibr" target="#b9">(10)</ref>, but with the additional scale variable and the (implicit) constraint that all camera-space coordinates have the same depth. In this new objective function, the value of s together with and t must be determined simultaneously.</p><p>By considering the following modified objective function <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b26">[27]</ref> min</p><formula xml:id="formula_32">YtYs n iI k I s p p H i À s p q H i k P Y QV</formula><p>the solution for s can be found to be</p><formula xml:id="formula_33">s n iI kp H i k P n iI kq H i k P s X QW</formula><p>The rotation matrix of the pose is independent of s, yet it reduces the overall least-squares objective function. After and s are determined, t can be computed as:</p><formula xml:id="formula_34">t s" v À " pY RH</formula><p>where " v I n n iI v i . Note that if the origin of the object space is placed at " p, i.e., " p H, then s t z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Initial Absolute Orientation Solution</head><p>With the ys algorithm, the initial rotation will be the same as those computed using the aforementioned weak-perspective algorithm, however, the translation is different in that it is computed using (20) as a result of optimizing <ref type="bibr" target="#b18">(19)</ref>.</p><p>Let us rewrite (20) here</p><formula xml:id="formula_35">t I n s À I n j j 2 3 ÀI j j À s À Á p j X RI</formula><p>Comparing ( <ref type="formula">40</ref>) and ( <ref type="formula">41</ref>), we find that the former is approximated by the latter if the following conditions hold:</p><formula xml:id="formula_36">s À I n j j 2 3 ÀI % s RP I n j j p j % s" v for some s b HX RQ</formula><p>The first condition states that the scene points are located close to the optical axis and the second condition states that the scene points are distributed like a plane parallel to the image plane. These two conditions closely resemble the conditions under which weak-perspective approximation is valid.</p><p>In summary, we have reformulated the pose estimation problem under the weak-perspective model as the problem of fitting the set of the reference points to a planar projection of the image points. Using the image points themselves as the hypothesized scene points in the initial absolute orientation iteration results in a pose solution better than the unmodified weak-perspective solution. This pose solution serves, therefore, as a good initial guess for the subsequent iterative refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Depth-Dependent Noise</head><p>The global convergence of the ys algorithm is attained at the expense of being biased when the observed image points are perturbed by homogeneous Gaussian noise. The pose solution will implicitly more heavily weight reference points that are farther away from the camera. This is because the object-space collinearity error increases as the reference point is moved away from the camera.</p><p>We can reduce this bias by slightly modifying the optimization algorithm. Note that the projection operator, i Y is a function of the image vector v i . If the noise distribution were accounted for, the orthogonal iteration algorithm would involve minimizing the following objective function:</p><formula xml:id="formula_37">n iI p i t t s À i Ã Ã ÀI i s À i p i tY RR</formula><p>where Ã Ã i is the covariance matrix associated with i due to noise in image point v i . The presence of this matrix prohibits using the orthogonality of the rotation matrix to simplify the dependence of the objective function on . An exact closed-form solution is not possible unless the orthogonality constraint on rotation is dropped, in which case the problem becomes a linear least-squares problem. This linear approach faces the same problems encountered by other linear methods for pose estimation.</p><p>Although the general weighted least-squares problem cannot be solved, if, instead, the absolute orientation problem is presented as an equally-weighted or a scalarweighted least squares, we can still find closed-form solutions in which the orthogonality constraint is fully considered. In order to do this, we must assume that image error for each image coordinate is identical. Supposing that the error in camera-space coordinates is roughly proportional to the depth, the covariance matrix can then be approximated as:</p><formula xml:id="formula_38">Ã Ã k i % d kÀI i P sY RS</formula><p>where is some constant and</p><formula xml:id="formula_39">d kÀI i</formula><p>is the depth of q kÀI i . The intermediate absolute orientation problem can now be formulated as a scalar-weighted least squares</p><formula xml:id="formula_40">n iI I d k i P kp i t À i k p i t k k P X RT</formula><p>Such weighting schemes were used in <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref> and can be easily incorporated into the algorithm developed above. Note, however, that this kind of bias is significant only when the object is very close to the camera or the depth of the object is comparable to the distance between the object and the camera. According our experiments in Section 4.1, the bias is noticeable only when the ratio between the size of the object in the direction of optical axis and distance to camera is smaller than 3.5, in which cases unbiased methods like Levenberg-Marquardt may be preferable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We have developed implementations of ys in both C++ and in Matlab. The code for the latter can be found from http:// www.cs.jhu.edu/~hager. These implementations have been tested in both simulation and on real data and have also been compared with implementations of other pose estimation algorithms. The results of these experiments are detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dependence on Object Location and Initial Guesses</head><p>In this section, we evaluate the proposed algorithm as a function of distances to camera and to optical axis, respectively. The purpose is to study the following three aspects of the algorithm:</p><p>1. The performance of ys when it is initialized with a weak-perspective pose as a function of how sufficient the weak-perspective model approximates the true perspective camera model. The validity of the weak-perspective model can be characterized by the following two parameters:</p><p>. distance to camera and . distance to optical axis.</p><p>2. The effect of the bias described in Section 3.5 when the distance between the object and the camera is relatively small compared to the size of the object in the direction of optical axis. 3. The performance of ys when it is randomly initialized compared to that of ys when it is initialized with a weak-perspective pose. The set of 3D reference points are defined as the eight corners of the box defined by ÀSY S Â ÀSY S Â ÀSY S in the object space. The translation vector is varied with increasing distance to camera and with increasing distance to optical axis. Uniformly distributed random 3D rotation is generated for each translation <ref type="bibr" target="#b41">[42]</ref>. The set of reference points are then transformed by the selected rotation and translation.</p><p>Finally, the resulting 3D points are projected onto the normalized image plane to produce image points. Gaussian noise with signal-to-noise ratio (SNR) = 70 dB is added to both coordinates of the image points to generate the perturbed image points. The variance ' of the noise is related to signal-to-noise ratio (x) by x ÀPH log't z aIH df.</p><p>The following two tests are conducted on the generated input data: D1. The translation vector is generated by fixing t x S and t y S, and varies t z aIH from 1.5 to 50 by a step of 1. The purpose is to measure how well the proposed algorithm performs when the target object is approaching the camera.</p><p>D2. The translation vector is generated by fixing t x S and t z PHH and varies t y aIH from 1.5 to 50 by a step of 1. The purpose is to measure how well the proposed algorithm performs when the target object is moving away from the optical axis.</p><p>The distances are expressed relative to the object size. For each translation, the average rotation error and translation error are computed over 1,000 uniformly distributed rotation matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Results and Discussions</head><p>Depth-dependent noise. From Fig. <ref type="figure" target="#fig_2">4</ref> and Fig. <ref type="figure" target="#fig_7">5</ref>, we can see that, as the target object moves closer to the camera, the translation error increases due to the bias of ys toward points farther away from camera. However, the effect is significant only when the ratio between the distance to camera and the object size in z direction is smaller than 3.5. Beyond this, the average translation error remains almost constant as the object moves away from the camera when image points are perturbed by noise with the same SNR.</p><p>It is interesting to see that the average rotation error is almost not affected by the bias. It seems that the biasing effects introduced by each i are canceled by each other during the computation of rotation, while their influences remain significant in the computation of translation using <ref type="bibr" target="#b19">(20)</ref>.  Weak-perspective approximation. Besides the effect of depth-dependent noise, we can see that the average rotation and translation errors do not vary significantly as the distance to camera and the distance to optical axis change (see the plots of squares (t u) in Figs. <ref type="bibr">4, 5, 7, and 8)</ref>. However, the number of iterations does decrease (see plots of squares (t u) in Figs. <ref type="figure" target="#fig_3">3</ref> and<ref type="figure" target="#fig_6">6</ref>) as the camera model is better approximated by weak-perspective model when the object moves away from the camera and/or approaches the optical axis. This means that, when the weakperspective pose is closer to the true pose, ys can converge to it faster. However, even if the weak-perspective pose is not close enough, ys can still reach it with the same accuracy. It just takes more steps. Initial guesses. When ys is initialized with randomly generated rotation, the average number of iterations taken by ys to converge is roughly the same for different object locations and is generally higher than when using weakperspective initialization (see plots of diamonds (Å) in Figs. <ref type="figure" target="#fig_3">3</ref> and<ref type="figure" target="#fig_6">6</ref>). From Fig. <ref type="figure" target="#fig_2">4</ref> and<ref type="figure" target="#fig_5">7</ref>, we can see that the average rotation error is almost the same as with weak-perspective initialization, while average translation error varies within a range of 2 percent of the true translation (see plots of diamonds (Å) in Figs. <ref type="figure" target="#fig_7">5</ref> and<ref type="figure" target="#fig_4">8</ref>).</p><p>With more than six point correspondences, one expects a unique pose solution <ref type="bibr" target="#b42">[43]</ref> under noiseless conditions. Although in noisy cases there may be a few spurious fixed points to which ys converges, our experiments show that, by merely constraining initial rotation so that it does not    place the object behind the camera, ys seems to be able to reach the true pose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparisons to Other Methods</head><p>In this section, the the proposed algorithm is compared to other methods using different test strategies with synthetically generated data. The protocol for generating the input data used throughout this section is governed by the following control parameters: number of points x, signalto-noise ratio (x), and percentage of outliers (PO). The test data was generated as follows:</p><p>A set of x 3D reference points are generated uniformly within a box defined by ÀSY S Â ÀSY S Â ÀSY S in the object space. A uniformly distributed random 3D rotation is generated as in Section 4.1. For translation, the x and y components are uniformly selected from the interval SY IS and the z component was selected from the interval PHY SH. The set of reference points is then transformed by the randomly selected rotation and translation.</p><p>Following this, a fraction (= PO) of the 3D points are selected as outliers. Each of these points is replaced by another 3D point whose components are taken from a uniform distribution within a box ÀSY S Â ÀSY S Â ÀSY S in the object space. The rest of the processing is the same as that in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Standard Comparison Tests</head><p>In the following section, we will investigate the properties of the proposed method in comparison to other techniques based on experimental results. For this purpose, we design a set of standard comparison tests on synthetic data with varying noise, percentages of outliers, and numbers of reference points.</p><p>The following four standard tests were conducted on the generated input data:</p><p>C1. Set x = 20, PO = 0. Record the log errors of rotation and translation against x (30 dB-70 dB in 10 dB step). The purpose is to measure how well the tested methods resist noise.</p><p>C2. Set x = 20, x = 60 dB. Record the log errors of rotation and translation against PO (5-25 percent in 5 percent step). The purpose is to see how well the tested methods tolerate outliers.</p><p>C3. Set PO = 0, x = 50 dB. Record the log errors of rotation and translation against x (10 to 50 by step of 10).    The purpose is to investigate how the accuracy can be improved by increasing the number of reference points.</p><p>To assess the performance of the methods, we measure the mean error in rotation and translation over 1,000 trials for each setting of the control parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Results and Discussions</head><p>The methods tested here are the orthogonal iteration algorithm, a linear method using full perspective camera model <ref type="bibr" target="#b17">[18]</ref>, and a classical method using Levenberg-Marquardt minimization. An implementation of LM (called LMDIF) in MINPACK<ref type="foot" target="#foot_0">2</ref> is used in our experiments. LM starts from the same initial solutions as those generated from the orthogonal iteration algorithm. The geometrical configurations are chosen in such a way that the weakperspective approximation is poor in general. With poor initial guesses, LM behaves like a steepest descent method, which exhibits a slow convergence rate. This explains why LM is slower than the proposed method with increasing SNR or PO. On the other hand, the proposed method is as fast as LM when both are initialized with appropriate values. This leads us to believe that the proposed method has quadratic-like local convergence similar to that of the Gauss-Newton method.</p><p>Figs. 9 and 10 show the average running times and number of iterations of the methods we tested against the number of reference points. These times are measured for x TH dB and PO H on a Silicon Graphics IRIS Indigo with a MIPS R4400 processor. The orthogonal iteration algorithm is clearly much more efficient than LM, having about the same accuracy as LM without outliers (see <ref type="bibr">Figs. 11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">and 16)</ref>. It significantly outperforms LM in the presence of outliers, as shown by Figs. 13 and 14.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this article, we have presented a fast and globally convergent pose estimation algorithm. Large-scale empirical testing has shown that this algorithm is generally more efficient and no less accurate than the classical Levenberg-Marquardt method in unconstrained geometrical conditions. Hence, the algorithm is well-suited for any situation,    especially where both efficiency and accuracy are desired and, in particular, when good prior initialization is not available.</p><p>There are several possible extensions to this algorithm. For example, the method can be extended to handle uncertainty in the locations of the reference points on the object by slight modification of the objective function. The optimization could also be easily extended to perform a robust optimization step using IRLS methods <ref type="bibr" target="#b43">[44]</ref>, making it yet more robust to outliers. In addition, our results suggest that ys tends to find the correct pose solution, suggesting that there are few, if any, spurious local minima. We are currently working to determine the conditions under which the pose computed by ys is unique and the error of ys can be analytically determined.</p><p>We are currently implementing a version of the algorithm within the XVision <ref type="bibr" target="#b44">[45]</ref> environment for use in robotic applications, as well as augmented and virtual reality. An initial implementation described in <ref type="bibr" target="#b45">[46]</ref> has shown that, by combining efficient local tracking with efficient pose estimation, it is relatively simple to construct a real-time object tracking system which runs on typical desktop hardware. An interesting extension will be to extend the formalism to include pose estimation from lines and to compare the efficiency and accuracy with other existing pose tracking system such as demonstrated by Lowe <ref type="bibr" target="#b29">[30]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The reference frames in the pose estimation problem.</figDesc><graphic coords="2,117.07,69.17,332.28,248.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Object-space and image-space collinearity errors.</figDesc><graphic coords="3,117.41,69.17,331.71,239.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Rotation error as a function of distance to camera. The results for ys initialized with weak-perspective pose are plotted as squares ( t u) and the results for ys randomly initialized are plotted as diamonds (Å). Each point represents results averaged over 1,000 uniformly distributed rotations.</figDesc><graphic coords="8,297.58,69.17,234.37,188.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Number of iterations as a function of distance to camera.The results for ys initialized with weak-perspective pose are plotted as squares ( t u) and the results for ys randomly initialized are plotted as diamonds (Å). Each point represents results averaged over 1,000 uniformly distributed rotations.</figDesc><graphic coords="8,34.58,69.17,234.37,188.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Translation error as a function of distance to optical axis. The results for ys initialized with weak-perspective pose are plotted as squares ( t u) and the results for ys randomly initialized are plotted as diamonds (Å). Each point represents results averaged over 1,000 uniformly distributed rotations.</figDesc><graphic coords="9,297.58,317.54,234.37,188.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Rotation error as a function of distance to optical axis. The results for ys initialized with weak-perspective pose are plotted as squares ( t u) and the results for ys randomly initialized are plotted as diamonds (Å). Each point represents results averaged over 1,000 uniformly distributed rotations.</figDesc><graphic coords="9,297.41,69.17,234.71,188.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Number of iterations as a function of distance to optical axis. The results for ys initialized with weak-perspective pose are plotted as squares ( t u) and the results for ys randomly initialized are plotted as diamonds (Å). Each point represents results averaged over 1,000 uniformly distributed rotations.</figDesc><graphic coords="9,34.75,317.20,233.97,189.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Translation error as a function of distance to camera. The results for ys initialized with weak-perspective pose are plotted as squares (t u), and the results for ys randomly initialized are plotted as diamonds (Å). Each point represents result averaged over 1,000 uniformly distributed rotations.</figDesc><graphic coords="9,34.36,69.17,234.71,188.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Result (average translation error) of Experiment C1 for comparing with the Levenberg-Marquardt method. Error is in log scale. Each point in the plot represents 1,000 trials.</figDesc><graphic coords="10,292.14,278.59,245.14,168.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Result (average rotation errors) of Experiment C1 for comparing with the Levenberg-Marquardt method. Error is in log scale. Each point in the plot represents 1,000 trials.</figDesc><graphic coords="10,292.14,69.17,245.14,167.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Average numbers of iterations used by the tested methods. Each point in the plot represents 1,000 trials.</figDesc><graphic coords="10,31.86,270.82,239.75,168.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Average running times used by the tested methods. Each point in the plot represents 1,000 trials.</figDesc><graphic coords="10,30.78,69.17,241.91,169.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Result (average translation errors) of Experiment C3 for comparing with the Levenberg-Marquardt method. Error is in log scale. Each point in the plot represents 1,000 trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Result (average rotation errors) of Experiment C3 for comparing with the Levenberg-Marquardt method. Error is in log scale. Each point in the plot represents 1,000 trials.</figDesc><graphic coords="11,298.83,279.04,231.82,168.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Result (average translation errors) of Experiment C2 for comparing with the Levenberg-Marquardt method. Error is in log scale. Each point in the plot represents 1,000 trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Result (average rotation errors) of Experiment C2 for comparing with the Levenberg-Marquardt method. Error is in log scale. Each point in the plot represents 1,000 trials.</figDesc><graphic coords="11,31.29,277.29,240.83,168.72" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Visit http://www.mcs.anl.gov/summaries/minpack93/ summary.html for information about the public-domain package MIN-PACK-2 that implements these methods.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A UNIQUENESS OF THE OPTIMAL SOLUTION TO THE ABSOLUTE ORIENTATION PROBLEM</head><p>We show that the best rotation to <ref type="bibr" target="#b9">(10)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B CLOSEDNESS OF SVD</head><p>Suppose that</p><p>From the closedness of yQY and are orthonormal matrices. Likewise, the set of diagonal matrices in qvQ is a closed subgroup and, hence, AE is a diagonal matrix. Therefore, Y AEY is an SVD of some matrix w H AE t . However, by the continuity of transposition and matrix multiplication,</p><p>k 3 AE t and, hence, w k 3 w H . Therefore, w w H and, consequently, Y AEY is an SVD of w. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Wilson</surname></persName>
		</author>
		<title level="m">ªVisual Servo Control of Robots Using Kalman Filter Estimates of Robot Pose Relative to Work-Pieces,º Visual Servoing</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Hashimoto</surname></persName>
		</editor>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="71" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ªAn Automatic Registration Method for Frameless Stereotaxy, Image Guided Surgery, and Enhanced Reality Visualization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="430" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>State</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hirota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Livingston</surname></persName>
		</author>
		<title level="m">ªSuperior Augmented Reality Registration by Integrating Landmark Tracking and Magnetic Tracking,º Proc. ACM SIGGRAPH</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="429" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ªImproving Static and Dynamic Registration in an Optical See-Through HMD</title>
		<author>
			<persName><forename type="first">R</forename><surname>Azuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="197" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Bajura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ohbuchi</surname></persName>
		</author>
		<title level="m">ªMerging Virtual Objects with the Real World: Seeing Ultrasound Imagery within the Patient,º Proc. SIGGRAPH</title>
		<imprint>
			<date type="published" when="1992-07">July 1992</date>
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Object Recognition by Computer</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ganapathy</surname></persName>
		</author>
		<title level="m">ªDecomposition of Transformation Matrices for Robot Vision,º Pattern Recognition Letters</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="401" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªRandom Sample Consensus: A Paradigm for Model Fitting and Automatic Cartography</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="381" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">ªAn Analytic Solution for the Perspective 4-Point Problem,º Computer Vision, Graphics, and Image Processing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Canio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Leboullenx</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="33" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ªAnalysis and Solutions of the Three Point Perspective Pose Estimation Problem</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ottenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="592" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ªExact and Approximate Solutions of the Perspective-Three-Point Problem</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dementhon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="100" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ªDetermination of the Attitude of 3D Objects from a Single Perspective View</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dhome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richetin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lapreste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Â</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="265" />
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">ªThe Problem of Exterior Orientation in Photogrammetry,º Photogrammetric Eng</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Rosenfield</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1959">1959</date>
			<biblScope unit="page" from="536" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">ªThe Projective Theory of Relative Orientation,º Photogrammetria</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Tompson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968">1968</date>
			<biblScope unit="page" from="67" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Computer and Robot Vision</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ªThree-Dimensional Object Recognition from Single Two-Dimensional Image</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="355" to="395" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">ªA Fully Projective Formulation for Lowe&apos;s Tracking Algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Carceroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brown</surname></persName>
		</author>
		<idno>641</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Rochester</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">I</forename><surname>Abdel-Aziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Karara</surname></persName>
		</author>
		<title level="m">ªDirect Linear Transformation into Object Space Coordinates in Close-Range Photogrammetry,º Proc. Symp. Close-Range Photogrammetry</title>
		<imprint>
			<date type="published" when="1971-01">Jan. 1971</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ªA System for Extracting Three-Dimensional Measurements from a Stereo Pair of TV Cameras</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yakimovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="195" to="210" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ªCalibration Problem for Stereo</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toscani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1986-06">June 1986</date>
			<biblScope unit="page" from="15" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">ªAn Effecient and Accurate Camera Calibration Technique for 3D Machine Vision</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="364" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ªTechniques for Calibration of the Scale Factor and Image Center for High Accuracy 3D Machine Vision Metrology</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="713" to="720" />
			<date type="published" when="1988-03">Mar. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Dementhon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lines of Code,º Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="123" to="141" />
			<date type="published" when="1995-06">June 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">D Pose from Corresponding Points under Weak-Perspective Projection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Alter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Techical Report A.I. Memo</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">378</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>MIT Artificial Intelligence Lab</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ªRecognizing Solid Objects by Alignment with an Image,º Int</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="212" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">ªObject Pose: The Link between Weak Perspective, Para Perspective and Full Perspective</title>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Christy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dornaika</surname></persName>
		</author>
		<idno>RR-2356</idno>
	</analytic>
	<monogr>
		<title level="j">INRIA</title>
		<imprint>
			<date type="published" when="1994-09">Sept. 1994</date>
		</imprint>
	</monogr>
	<note type="report_type">Techical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">ªClosed-Form Solution of Absolute Orientation Using Orthonomal Matrices</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Hilden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Negahdaripour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. Am</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ªPose Estimation from Corresponding Point Data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Harlalick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="426" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Computer and Robot Vision</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Addison-Wesley</publisher>
			<biblScope unit="page">132</biblScope>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ªFitting Parametrized Three-Dimensional Models to Images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="441" to="450" />
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">ªOptimal Motion and Structure Estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="864" to="884" />
			<date type="published" when="1993-09">Sept. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<title level="m">ªReal-Time Feature Tracking and Projective Invariance as a Basis for Hand-Eye Coordination,º Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="533" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ªEye-to-Hand Coordination for Vision-Guided Robot Control Applications,º Int</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wijesoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">l J. Robotics Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="78" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Robust Vision for Vision-Based Control of Motion</title>
		<editor>M. Vincze and G. Hager eds.</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Three-Dimensional Computer Vision</title>
		<author>
			<persName><forename type="first">O</forename><surname>Faugeras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">ªClosed-Form Solution of Absolute Orientation Uusing Unit Quaternion</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. Am</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="629" to="642" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">ªEstimating 3D Location Parameters Using Dual Number Quaternions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Volz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP: Image Understanding</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="358" to="367" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Blostein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªLeast-Squares Fitting of Two 3D Point Sets</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="698" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Linear and Nonlinear Programming</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Luenberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Addison Wesley</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">ªObstacle Avoidance and Navigation in the Real World by a Seeing Robot Rover</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Moravec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<title level="m">ªTriangulation Errors in Stereo Algorithms,º Proc. IEEE Workshop Computer Vision</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Graphics Gems III</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kirk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="124" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Netravali</surname></persName>
		</author>
		<title level="m">ªMotion and Structure from Feature Correspondences: A Review,º IEEE Proc</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="252" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Pyne, ªConvergence of the Iteratively Reweighted Least-Squares Algorithm for Robust Regression</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename></persName>
		</author>
		<idno>No. 313</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. of Math. Science</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>The Johns Hopkins Univ</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toyama</surname></persName>
		</author>
		<title level="m">ªXVision: A Portable Substrate for Real-Time Vision Applications,º Computer Vision and Image Understanding</title>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
			<biblScope unit="volume">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Lu</surname></persName>
		</author>
		<title level="m">ªOnline Pose Estimation and Model Matching,º PhD thesis</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Yale Univ.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
