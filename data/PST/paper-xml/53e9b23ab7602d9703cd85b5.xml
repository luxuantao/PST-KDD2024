<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Image Sets Alignment for Video-based Face Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhen</forename><surname>Cui</surname></persName>
							<email>zhen.cui@vipl.ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Scholl of Computer Science and Technology</orgName>
								<orgName type="institution">Huaqiao University</orgName>
								<address>
									<postCode>361021</postCode>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
							<email>sgshan@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haihong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Omron Social Solutions Co., LTD</orgName>
								<address>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shihong</forename><surname>Lao</surname></persName>
							<email>lao@ssb.kusatsu.omron.co.jp</email>
							<affiliation key="aff2">
								<orgName type="institution">Omron Social Solutions Co., LTD</orgName>
								<address>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xilin</forename><surname>Chen</surname></persName>
							<email>xlchen@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Image Sets Alignment for Video-based Face Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FD93EC11F9E0D9ABA1B9BF2FAD6ADCA6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Video-based Face Recognition (VFR) can be converted to the matching of two image sets containing face images captured from each video. For this purpose, we propose to bridge the two sets with a reference image set that is well-defined and pre-structured to a number of local models offline. In other words, given two image sets, as long as each of them is aligned to the reference set, they are mutually aligned and well structured. Therefore, the similarity between them can be computed by comparing only the corresponded local models rather than considering all the pairs. To align an image set with the reference set, we further formulate the problem as a quadratic programming. It integrates three constrains to guarantee robust alignment, including appearance matching cost term exploiting principal angles, geometric structure consistency using affine invariant reconstruction weights, smoothness constraint preserving local neighborhood relationship. Extensive experimental evaluations are performed on three databases: Honda, MoBo and YouTube. Compared with competing methods, our approach can consistently achieve better results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Face recognition has traditionally been posed as the problem of identifying a face from a single image, and many current methods assume face images are attained under controlled environments. However, facial appearance changes dramatically due to variations in illumination, pose, expression and other factors in unconstrained real-world applications such as video surveillance. Thus, face recognition algorithms learned with images captured under controlled conditions may not suffice for reliable recognition in many practical applications.</p><p>Recently, there has been an increasing interest on video-based Face Recognition (VFR) <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> because video cameras are commonly available and provide more information compared to still cameras. In the case of VFR, both gallery and query set are video sequences rather than still images. So VFR problem can be converted to measuring the similarity between two video sequences. Intuitively, one could build an appearance-based system by choosing a subset of representative frames (so-called key-frames or exemplars) from video sequence as models and then perform still image based recognition. Obviously, such an approach does not fully utilize spatiotemporal information. To make use of it, some techniques are developed, for instance, by using Hidden Markov Model (HMM) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. However, temporal model based approaches</p><p>have not yet shown their full potentials as they also suffer from some drawbacks, such as only using global features while ignoring local information, the lack of discriminability between the facial dynamics.</p><p>On the contrary, without the temporal information, face images from a video sequence form an image set. So VFR can be generalized to image-set based classification, where each target person may be enrolled with one or even multiple image sets (so-called gallery set) and a query image set need to be assigned to the identity of its nearest gallery set by calculating its distance from each gallery image set.</p><p>Relevant approaches to image-set based classification underwent an explosive development in recent years <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>. Generally speaking, such approaches fall into two categories: parametric model methods and nonparametric sample methods. The former <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12]</ref> exploit some parametric distribution (e.g. Gaussian) to represent each image set and then measure the between-distribution similarity. One limitation of the parametric methods is that they have to assume some distribution and handle the parameter estimation problem. If the data set does not follow the predefined statistic distribution, the estimated model will not consist with the data set.</p><p>More recently, some non-parametric methods attempt to represent an image set as a linear subspace <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref> or a nonlinear manifold <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b14">15]</ref>. Such approaches do not impose any assumption on data distribution, and have shown many merits compared to parametric models. Meanwhile, some algorithms which measure the similarity or distance between two subspaces are also developed. The representative methods are the principal angles which compute the angles between the principal components of two spaces <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, and the nearest points which use the nearest distance between two affine hulls <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. Hu et al. <ref type="bibr" target="#b10">[11]</ref> applied the affine hull model to account for unseen appearances and proposed Sparse Approximated Nearest Point (SANP) to measure between-set similarity, which enforces nearest points to be close to some facets by imposing sparsity constraints.</p><p>Based on the assumption that face images of the same subject are distributed on a nonlinear manifold rather than a linear subspace, Wang et al. extended Subspace-Subspace Distance (SSD) to Manifold-Manifold Distance (MMD) <ref type="bibr" target="#b6">[7]</ref>, where a nonlinear manifold is partitioned into a number of local linear models by Maximal Linear Patch (MLP) <ref type="bibr" target="#b15">[16]</ref>, and then MMD is converted to integrating the distances between pair-wise subspaces. An extension of MMD, called Manifold Discriminant Analysis (MDA) <ref type="bibr" target="#b7">[8]</ref> is also proposed to solve the supervised between-manifold distance. These methods based on nonlinear manifold have achieved the state of the art results in several public face databases.</p><p>However, MMD and MDA ignore the correspondence between the subspaces from the manifolds (of the two image sets) when calculating similarity. They divide each image set into several subspaces by clustering and then perform pair-wise subspaces comparison. Thus, these methods have the following disadvantage: given two sequences, face images under the same condition might be partitioned differently because of the uncertainty of the clustering. For example, face images with yaw within [10 o ,  20 o ] might be partitioned to one cluster for one sequence, while the face image with yaw within [15 o , 25 o ] might fall into one cluster in another sequence. This implies that the distance between two manifolds in above methods might not be well defined. In addition, MDA <ref type="bibr" target="#b7">[8]</ref> only learns one linear transformation, which is not sufficient to capture the discriminant information because the face images in a sequence are distributed on a nonlinear manifold.</p><p>To avoid the above bias originated from clustering, alignment between two image sets is a possible solution. One scheme is aligning the test image set to each gallery image set respectively, and then comparing them directly. However, such strategy is unreasonable in practical VFR for two reasons: (1) in many cases, the query image set does not wholly but only partially corresponds with the gallery image set, which implies difficult alignment; (2) it is too time-consuming to align the query set with each of the gallery sets online. To address the above issues, a reference set is introduced to bridge the query set and the gallery set. Furthermore, to obtain more discriminant features, multiple linear transformations can be learned from corresponded local models which are structured by aligning all gallery image sets with the pre-partitioned reference set.</p><p>To solve this alignment between two image sets, some previous methods assume each image set is distributed on a nonlinear manifold, and then do manifold alignment by utilizing dimensionality reduction algorithms <ref type="bibr" target="#b16">[17]</ref>. But most of existing manifold alignment algorithms <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref> fall into supervised or semi-supervised category, which require some known matching points obtained from manual annotation or other prior knowledge. Therefore, they are unsuitable for our question because it is intractable to get the matching point for the large scale video database by manual annotation.</p><p>Confronted with this problem, an alternative is to align two sequences without any prior information, i.e. unsupervised image sets alignment. However, to our best knowledge, few studies discussed this problem. Recently, Wang et al. <ref type="bibr" target="#b25">[26]</ref> proposed an unsupervised alignment method without correspondence, which learns a projection transforming instances from two subspaces to a lower dimensional space, and simultaneously matches the local geometry structures by the k nearest neighbors. Nevertheless, when matching k neighbors of two points, the authors considered all k! permutations to find the best match, which is too time-consuming.</p><p>To address above problem, in this paper, we propose to align all image sets to a reference image set that is well-defined and pre-structured into a number of local linear models offline. In other words, given two image sets for comparison, as long as each of them is aligned to the reference set, they are mutually aligned and well structured. Therefore the similarity between them can be computed by comparing only the corresponded local models instead of all the pair-wise ones. Furthermore, instead of a global linear transformation in MDA <ref type="bibr" target="#b7">[8]</ref>, multiple linear transformations from corresponded subspaces are learned during the training, and then applied to the query image sets.</p><p>In addition, inspired by Wang's alignment method <ref type="bibr" target="#b25">[26]</ref>, we explicitly formulate the image sets alignment problem as a quadratic programming, which can be solved faster than Wang's method. Our proposed model contains three terms. The first term checks consistency of local geometric structure. The second term measures the matching cost between two points. The last term constrains the smoothness of manifold. Different from Wang's geometric structure matching methods, we exploit the local reconstruction relationship, which is affine invariant and thus does not need to consider all possible permutations. In addition to the smoothness which is also applied in <ref type="bibr" target="#b25">[26]</ref>, we add the matching cost term into our model to increase stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Overview of the proposed method</head><p>In this section, we briefly describe our proposed method. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, before images sets alignment, we choose an image set as the reference set so that all image sets can mutually align to it. The motivation of utilizing a reference set lies in three folds: (1) avoiding the bias from clustering in MMD and MDA as mentioned above; (2) addressing the difficulty due to possible partial correspondence between the query and gallery set; (3) reducing the high computational cost for online alignment of the query set and all the gallery sets.</p><p>For above purposes, the reference image set should cover as many variations as possible including pose and illumination and other factors. In our experiments, we select randomly one video sequence of one person from the gallery sets with enough frames covering diverse variations. An elaborately designed reference set can possibly further improve the recognition performance, which will be our future work.</p><p>After the reference set is selected, an offline process is applied to it, e.g. MLP <ref type="bibr" target="#b6">[7]</ref>, which partitions the reference image set into a number of local linear subspaces. Then both the test samples and the gallery samples are aligned to the reference set by our proposed image sets alignment algorithm (details in Section 3). Note that, as the test set and the gallery set might have no common intersection set due to non-overlapping poses for instance, we mirror all the samples before alignment. Subsequently, corresponded subspace division is performed on the test and gallery image sets by exploiting the pre-partition of reference set. Thus, the subspaces from the test and gallery sets are aligned naturally.</p><p>At last, the distances only between the corresponded subspaces rather than all pair-wise ones are calculated as the similarity vectors by a series of corresponded mappings (e.g. Fisherfaces) pre-learned from a training image sets. The similarity score vectors can be further fed into a classifier, or simply pooled by SUM or MIN rule to get the final score for face recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Unsupervised image sets alignment</head><p>Video sequences may be captured in different sceneries with complicated variations in pose, illumination and expression so on. Thus, it is difficult to directly evaluate the appearance similarity between two images from two different sequences respectively. Usually, the angles between two subspaces may reflect the variant modes, which have been widely used to measure the similarity between two image sets <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13]</ref>. Therefore, we can describe a point more robust with a subspace spanned by this point and its neighbors. Furthermore, the appearance matching cost between the two samples can be represented by the maximum principal angle.</p><p>An important assumption of manifold alignment is the consistency of the local geometry structure <ref type="bibr" target="#b25">[26]</ref>. One may search all possible permutations to verify the consistency, which however is too time-consuming. To reduce the computational time, we formulate the local structure as a quadratic programming term by exploiting the affine invariant reconstruction weight.</p><p>In addition, the manifold should be smooth. Thus, we also add the smoothness constraint to the proposed method to decrease mismatching.</p><p>In what follows, we first develop a primary formulation to solve the image sets alignment problem, and then detailed descriptions about each term of the model are provided. At last, an efficient algorithm is summarized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem formulation</head><p>Without loss of generality, in this paper, we concatenate  </p><formula xml:id="formula_0">{ } s c g E E E f 2 1 min arg ˆλ λ + + = ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">∑ ∈ = X f i i g i i N f N g E i x x x x x ) ), ( ; , ( ) ( ,<label>(2)</label></formula><formula xml:id="formula_2">∑ ∈ = X i i c f c E i x x x )) ( , ( ,<label>(3)</label></formula><formula xml:id="formula_3">∑ ∑ ∈ ∈ = X N j i s i i j f f s E x x x x x )) ( ), ( ( .<label>(4)</label></formula><p>In above equations, i N x denotes the neighbors of x i , λ 1 and λ 2 balance the effect of the three terms. The first term E g represents the geometric similarity score between the two image sets, where g is the geometric consistency function measuring the dissimilarity between two local models. The second term E c reflects the appearance similarity, where c is the matching cost function between two points. The third term E s is used to keep the smoothness, i.e. the neighborhood relationship in the target set should be preserved in the reference set. The following three subsections detail the above three terms respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Local geometry consistency</head><p>Inspired by Locally Linear Embedding (LLE) <ref type="bibr" target="#b26">[27]</ref> and the recent literature <ref type="bibr" target="#b27">[28]</ref>, we introduce a locally invariant geometric constraint for image sets alignment.</p><p>As mentioned above, we represent each image set as a manifold. To characterize the geometric properties of the neighborhood of each point in the manifold, we assume each x i can be approximately represented by an affine combination of its neighbor points,</p><formula xml:id="formula_4">∑ ∈ = i j N j ij i W x x x x ,<label>(5)</label></formula><p>where W ={W ij } is the reconstruction weight matrix for all points and the i-th row of W stores all reconstruction coefficients for the i-th point x i with ∑ j W ij =1. Specifically, least squares is exploited to describe the local geometric properties of each point, i.e., 0</p><formula xml:id="formula_5">= -∑ ∈ i j N j ij i W x x x x .<label>(6)</label></formula><p>Obviously, Eq. ( <ref type="formula" target="#formula_5">6</ref>) is affine invariant approximately. Thus, we can further formulate E g in (2) as the following object function by the weight matrix W,</p><formula xml:id="formula_6">∑ ∑ ∈ ∈ - = X N j x ij i g i i j f W f E x x x x x 2 ) ( ) ( ,<label>(7)</label></formula><p>where W x represents the reconstruction weight matrix of the image set X. If we mark the mapping relation of each point as a vector, the function f can be represented by a {0,1} binary matrix F m×n . Thus, the function ( <ref type="formula" target="#formula_6">7</ref>) can be rewritten as the matrix formulation,</p><p>) (</p><formula xml:id="formula_8">T x T x g FY L FY W I E = - = . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>Because of the sum of each row in W equals to 1, L x can be treated as the Laplacian matrix of a graph, where the edge may be constructed by W x . Note I is an identity matrix.</p><p>Compared with Wang's method <ref type="bibr" target="#b25">[26]</ref>, which exploits the Euclidean distance matrix of the k nearest neighbors to describe the local geometry structure, where all k! possible permutations are considered in the image matching with the cost O(k!), our model is locally affine invariant and easy to solve the mapping F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Appearance matching cost</head><p>In order to measure the similarity between two images coming from different image sets with variations in pose, illumination, expression and other factors, we exploit the maximum principal angle of their corresponded local linear subspaces as the appearance matching cost.</p><p>Formally, given two linear subspaces S 1 and S 2 , the principal angles 0≤α 1 ≤…≤α r ≤π/2(r=min(dim(S 1 ),dim(S 2 ))) are uniquely defined as following <ref type="bibr" target="#b6">[7]</ref>,</p><formula xml:id="formula_10">k T k S S k k k k k v u v v v u u u ) ( max max ) cos( } , , { \ } , , { \ 1 1 2 1 1 1 - - ∈ ∈ = α ,<label>(9)</label></formula><p>where u k and v k are called the k-th pair of canonical vectors, "\" means the subtracting operation on subspaces. The cosine values of the principal angles are called canonical correlations. Obviously, the smaller the maximum principal angle is, the closer the subspaces are. Generally, we select the distance between the first pair of canonical vectors, corresponding to the most similar modes, as the distance between the two subspaces. To solve this model, a numerically stable method based on Singular Value Decomposition (SVD) is exploited from <ref type="bibr" target="#b28">[29]</ref>.</p><p>Given the above definition of subspace distance, the appearance matching cost of two images can be calculated based on the maximum principal angle between two local linear subspaces, expanded respectively by the neighbors of the two images. Formally, for two images x i and y j respectively from X and Y, their k-NN neighbors on X and Y expand subspace S x and S y . Then, the matching score between x i and y j is computed by the above subspace distance and denoted by C ij . Then, we mark the matching scores between two image sets X and Y as the matrix C={ C ij }. Then the function E c in (3) can be re-written as,</p><formula xml:id="formula_11">) ( tr F C E T c = . (<label>10</label></formula><p>) where "tr" means the trace operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Smoothness constraint</head><p>Intuitively, manifolds should be smooth, curved surfaces embedded in higher dimensional Euclidean space. Thus, the local neighborhood relationship should be preserved when aligning two image sets. That is, if two images in X are neighbors, their corresponding images in Y should also be neighbors.</p><p>Formally, we denote the k-th neighborhood relationship of each image in X as a matrix R k ,</p><formula xml:id="formula_12">⎩ ⎨ ⎧ = else or , 0 of neighbor th - the is , 1 ) ( i j ij k k R x x .<label>(11)</label></formula><p>Thus, the third term E s in ( <ref type="formula" target="#formula_3">4</ref>) is formulated as follows,</p><formula xml:id="formula_13">∑ ∑ = = = - = K k T k K k T k T s FY L FY R FY E 1 2 1 2 , (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>where L k =I-R k , K is the local neighbor number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Efficient solution</head><p>Followed by above analysis, the object function ( <ref type="formula" target="#formula_0">1</ref>) can be formulated as a quadratic programming with an integer constraint as follows,</p><formula xml:id="formula_15">{ } . , 1 , 0 , . . ) ( tr min arg ˆ1 1 1 1 2 2 1 l F F F t s FY L F C FY L F m T n m m n K k T k T T x F ≤ ∈ = + + = × × × × = ∑ 1 1 1 2 λ λ (13)</formula><p>The variable F is an m×n binary assignment matrix that represents the image matching function f. Each row of F contains only one 1, which means any points in X must be projected to one and only one point in Y. There are three constrains in <ref type="bibr" target="#b12">(13)</ref>. The first one guarantees all images in X should be matched to Y. The second one shows that the matching between X and Y's points is either "Yes" or "No". The third constraint allows that at most l images in X can be permitted to match the same image in Y.</p><p>The problem ( <ref type="formula">13</ref>) is a quadratic object function with integer constraints, which is NP-complete and cannot be efficiently solved. We relax the integer constraint and meanwhile simplify the object function as follows, . , 0 , . .</p><formula xml:id="formula_16">) ( tr min arg ˆ1 1 1 1 2 l F F F t s F C UFY F m T m n T T F ≤ ≥ = + = × × × 1 1 1 λ (14)</formula><p>where U can be calculated by SVD with the following equation,</p><formula xml:id="formula_17">∑ = + = K k k T k x T x T L L L L U U 1 2 ) ( ) ( λ . (<label>15</label></formula><formula xml:id="formula_18">)</formula><p>We exploit "interior-point" method <ref type="bibr" target="#b29">[30]</ref> to optimize the object function ( <ref type="formula">14</ref>) with Matlab toolboxes. The entire algorithm of unsupervised image sets alignment is summarized in Algorithm 1.</p><p>In order to accelerate the algorithm, we utilize the trust region shrinkage method (as in <ref type="bibr" target="#b8">[9]</ref>) to solve the convex optimization problem approximately. We initialize the trust region with the most similar t samples taken from Y by the geometric structure and the appearance similarity. Thus, the main time cost is to solve the object function <ref type="bibr" target="#b13">(14)</ref>. Fortunately, this object function is convex, which therefore can converge to the minimum fast. Typically, aligning hundreds of samples takes only several seconds on standard PC with Matlab programming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first perform image set alignment experiments to demonstrate the effectiveness of the proposed alignment method. Then, we apply the proposed alignment method to video-based face recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Image sets alignment</head><p>To validate the efficacy of the proposed alignment algorithm, we execute face image matching across poses. Multi-PIE database <ref type="bibr" target="#b35">[36]</ref> is exploited to evaluate our method. Here, we compare the proposed method with <ref type="bibr" target="#b25">[26]</ref> and direct matching in original feature space (DM). We randomly collect 50 subjects. For each subject, 83 face images under 7 poses with yaw within [-45 o , +45 o ] (with 15 o intervals) and with different expressions and illuminations are selected. These images are cropped to 20×30 pixels to simulate the low quality video face images. 4. Initialize the trust region T i ={y i1 ,y i2 ,…,y it }for each point x i ∈ X. 5. While trust region is enough large 6.</p><p>Solve F by <ref type="bibr" target="#b13">(14)</ref>. (Section 3.5) 7.</p><p>Shrinkage the trust region by removing these points whose value is very low in F. 8. End 9. Solve F in ( <ref type="formula">14</ref>) by the final trust region. 10.Quantify F to {0,1} matrix.</p><p>We carry out between-set alignment and report the quantitative results in Figure <ref type="figure" target="#fig_3">2</ref>. The nearest poses are also viewed as a correct matching when r equals to 1, while r=0 means only the corresponded pose is counted as correct matching. As we can see, our approach can achieve an accuracy large than 98% when r=1, which means that nearly all the matching results lie in ±15 o pose error at most. It is worth pointing out that the dataset might favor DM more because all face images come from the same scenes. Wang's method <ref type="bibr" target="#b25">[26]</ref> only used the geometric similarity without appearance matching cost. Our method achieves a higher accuracy than Wang's method and DM, probably because we utilize appearance matching cost and geometric structure similarity simultaneously. In addition, our approach only needs about 3 seconds to finish the matching between two image sets, which is much faster than Wang's method. Some alignment results are shown in Figure <ref type="figure" target="#fig_2">3</ref>, where the third images are incorrectly aligned: a front face image is aligned to a face image with yaw +15 o .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Face recognition</head><p>Datasets: We used three public datasets: Honda/UCSD <ref type="bibr" target="#b30">[31]</ref>, CMU MoBo <ref type="bibr" target="#b31">[32]</ref> and YouTube Celebrities <ref type="bibr" target="#b32">[33]</ref>.</p><p>Honda/UCSD was collected by Lee et al. for video-based face recognition. In our experiment, we exploit their first subset containing 59 videos of 20 subjects (at least 2 videos for each subject). Each video sequence has different pose and expression vibrations. A cascaded face detector <ref type="bibr" target="#b33">[34]</ref> is applied to detect faces in each video sequence. Then all faces are resized to a 20×20 pixels gray image as <ref type="bibr" target="#b6">[7]</ref>. The length of the videos varies from 12 to 645 frames. To eliminate the lighting effects, histogram equalization is employed to pre-process the images.</p><p>CMU MoBo database was originally created for human pose identification. This database includes 96 sequences of 24 different subjects, i.e. 4 videos per subject. Each video was captured from walking on treadmill and has 300 frames. We exploit the same strategy as we did for the Honda dataset to obtain the face images with 30×30 pixels.</p><p>YouTube Celebrities was collected from YouTube for face tracking and recognition in real world applications. The dataset contains 1910 video sequences of 47 celebrities (actors, actresses and politicians). Each sequence has hundreds of frames with low resolution and high compression rates. Compared with Honda and MoBo databases, this database is much more challenging because of noises and complicated variations in pose, illumination and expression. Face images are also cropped as above and resized to 30×30 pixels.</p><p>On all of three datasets, we conduct five-fold cross validation experiments, i.e. five randomly selected training and testing combinations, to evaluate our proposed method. For Honda and MoBo database, one video sequence per subject is used for training and the rest sequences for testing. For YouTube, each person has 41 clips on average which cover 3 sections. We randomly choose 9 clips per person, 3 clips per section, as the experimental data. One clip per section is used for training and 6 for testing for each subject.</p><p>Comparison with existing methods: We compare our proposed approach with several image-set based methods proposed in recent years, including Mutual Subspace Method (MSM) <ref type="bibr" target="#b34">[35]</ref>, Discriminant Canonical Correlation Analysis (DCC) <ref type="bibr" target="#b4">[5]</ref>, Manifold-to-Manifold Distance (MMD) <ref type="bibr" target="#b6">[7]</ref>, Manifold Discriminant Analysis (MDA) <ref type="bibr" target="#b7">[8]</ref>, and Sparse Approximated Nearest Points (SANP) <ref type="bibr" target="#b10">[11]</ref>. Here we do not provide more experimental results of exemplar-based methods except LDA because recent literatures <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11]</ref> have shown that image-set based methods are generally superior to exemplar based methods.</p><p>Our implementation: For LDA and MSM, we adopt the techniques in accordance with <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b4">[5]</ref> respectively. The source codes of MMD, MDA and SANP are downloaded from the original authors, and referred parameters are followed by the referred literatures <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>The important parameters in our proposed method include: (i) the nearest neighbors size is set to 10; (ii) the control parameters: λ 1 =2, λ 2 =0.1; (iii) the dimension of PCA is set to 70, 60, 80 for three database respectively when projecting the gray features of local linear model; (iv) the dimension of LDA is set to the number of classes minus 1. In our experiments, we utilize the Euclidean distance to calculate the similarity between two corresponded linear models after mapping, and then the minimum value is exploited as the final between-set distance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and analysis:</head><p>The recognition results of all comparative methods on the three different face databases are summarized in Table <ref type="table">1</ref>. From this table, we can find our proposed method achieves superior performances in most testing. Now we conclude as follows.</p><p>(1)The comparison methods based on image sets have shown distinct performance. Among them, MSM, MMD and SANP, deal with image data generatively, which makes them less appealing than DCC, MDA and the proposed method, which exploit disciminant label information. SANP is superior to MSM because the sparsity constraint enforces the nearest point to close on facets of affine hull. MMD is comparable to SANP and also exhibits more excellent recognition results than MSM because it represents the complex image set as several local linear models. This also explains the superiority of MDA and our proposed method over DCC. MDA exploits nonlinear models, but it ignores between-set correspondences, only learns a global linear transformation to extract the discriminant features and performs the comparisons of pair-wise subspaces without the alignment process. Compared with MDA, our proposed method is more superior because of eliminating the biases from clustering.</p><p>(2)Among three databases, all methods have the worst performance on YouTube database, because the video sequences are captured from real world with low quality and broad appearance variations. From Table <ref type="table">1</ref>, we can find our proposed method outperforms other competing methods, about 7 percents on YouTube. Note that the results of SANP are slightly lower than those reported in <ref type="bibr" target="#b10">[11]</ref>, because the testing protocol in <ref type="bibr" target="#b10">[11]</ref> is different from ours on YouTube, and <ref type="bibr" target="#b10">[11]</ref> exploited LBP as the face feature on MoBo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discussion</head><p>In our experiments on three video databases (5 random experiments per database), we only randomly selected the image set of one subject with enough images covering various variations for each experiment as the reference set. The consistently good results imply desirable insensitivity of the reference set selection. Intuitively, the reference set should be a "complete" set, which means it should be as large as possible to cover sufficient variations. Moreover, such a "complete" set could help alignment and further promote face recognition performance. To create such a reference set, a direct method is to capture all the various face images with a well-configured complicated environment by a camera, as in Multi-PIE database <ref type="bibr" target="#b35">[36]</ref> with configurations of different illuminations and poses. However, a "complete" set is not easy to be obtained from a single video sequence in real world, even specially designing. A practical method is to build a statistical reference model from large scale video sequences, which is also our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Manifold alignment (or more generally image sets alignment) facilitates video-based face recognition. In this paper, a reference set that is well pre-defined and pre-structured to a number of local models is used as the bridge aligning two image sets. Thus, similarity scores can be attained by only comparing the corresponded local models instead of all the pair-wise ones. To the best of our knowledge, the proposed unsupervised image set alignment algorithm is the first attempt to solve this problem as an optimization problem from the view of manifold. Experimental results on three public databases demonstrate that the proposed method is convincingly applicable to video-based face recognition, and achieves consistently better performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The framework of our proposed approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 .</head><label>1</label><figDesc>Unsupervised image sets alignment Input: X={x 1 ,…,x m },Y={y 1 ,…,y n },m≤n Output: binary matrix F m × n 1. Find the K neighbors of each point in X and Y respectively. 2. Calculate the weight matrix W x by (6). 3. Calculate the appearance matching cost C by principle angles (Section 3.3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Examples of alignment under different poses.</figDesc><graphic coords="6,335.28,237.48,229.44,64.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The alignment accuracy across poses.</figDesc><graphic coords="6,338.88,78.72,195.00,139.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>all pixels to form the feature vector representing any face image. Formally, two image sets, one target (gallery or test) set and the reference set are denoted respectively by X={x i | i=1,2,…,m} and Y={y i | i=1, …,n}, where x i and y i represent the samples, m and n are the sample numbers in X and Y respectively. Our goal is to seek a mapping function f, the so-called alignment function, which maps any target image x in X to some reference image y in Y. We formulate this task as an optimization problem,</figDesc><table><row><cell>the intensity of</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Test samples</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Image sets</cell><cell>Corresponded</cell><cell></cell><cell></cell><cell></cell></row><row><cell>alignment</cell><cell>subspace division</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>W1</cell><cell>Wi</cell><cell>Wp</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Similarity vector</cell></row><row><cell>Subspace division</cell><cell>d 1</cell><cell>d i</cell><cell>d p</cell><cell>(d 1 ,d 2 ,…,d p )</cell></row><row><cell>Reference image set</cell><cell>W1</cell><cell>Wi</cell><cell>Wp</cell><cell></cell></row><row><cell>Image sets</cell><cell>Corresponded</cell><cell></cell><cell></cell><cell></cell></row><row><cell>alignment</cell><cell>subspace division</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gallery samples</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partially supported by the National Basic Research Program of China (973 Program) under contract 2009CB320902, and the Natural Science Foundation of China under contract Nos. 60832004, 61025010 and 61173065, and the Beijing Natural Science Foundation under contract No. 4111003. Haihong Zhang and Shihong Lao are partially supported by "R&amp;D Program for Implementation of Anti-Crime and Anti-Terrorism Technologies for a Safe and Secure Society", Special Coordination Fund for Promoting Science and Technology of MEXT, the Japanese Government.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>The mean and standard deviation of recognition rates of different methods </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Video-based Face Recognition Using Adaptive Hidden Markov Models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Face Tracking and Recognition with Visual Constraints in Real-World Videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Face Recognition with Image Sets Using Manifold Density Divergence</title>
		<author>
			<persName><forename type="first">O</forename><surname>Arandjelović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Manifold Approach to Face Recognition from Low Quality Video Across Illumination and Pose Using Implicit Super-Resolution</title>
		<author>
			<persName><forename type="first">O</forename><surname>Arandjelović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discriminative Learning and Recognition of Image Set Classes Using Canonical Correlations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Arandjelović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental Learning of Locally Orthogonal Subspaces for Set-based Object Recognition</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Manifold-Manifold Distance with Application to Face Recognition based on Image Set</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Manifold Discriminant Analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recognizing Faces of Moving People by Hierarchical Image-Set Matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nishiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wakasugi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Face Recognition Based on Image Sets</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cevikalp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sparse Approximated Nearest Points for Image set Classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Face Recognition from Long-term Observations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Face Recognition with the Multiple Constrained Mutual Subspace Method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nishiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fukui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AVBPA</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Kernel Orthogonal Mutual Subspace Method and Its Application to 3D Object Recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graph Embedding Discriminant Analysis on Grassmannian Manifolds for Improved Image Set Matching</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lovell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Maximal Linear Embedding for Dimensionality Reduction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1776" to="1792" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Patch Alignment for Dimensionality Reduction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1299" to="1313" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Manifold Alignment Using Procrustes Analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning a Manifold -Constrained Map between Image Sets: Applications to Matching and Pose Estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Semi-Supervised Framework for Mapping Data to the Intrinsic Manifold</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data Fusion and Multicue Data Matching by Diffusion Maps</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semisupervised Alignment of Manifolds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Proc. of the Tenth Int&apos;l Workshop on Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="120" to="127" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semi-Definite Manifold Alignment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Manifold Alignment via Corresponding Projections</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning Nonlinear Image Manifolds by Global Alignment of Local Linear Models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Manifold Alignment without Correspondence</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Joint Conf</title>
		<meeting>Int&apos;l Joint Conf</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1273" to="1278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonlinear Dimensionally Reduction by Locally Linear Embedding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Object Matching with a Locally Affine-Invariant Constraint</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Å</forename><surname>Björck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<title level="m">Numerical Methods for Computing Angles between Linear Subspaces. Mathematics, of Computation</title>
		<imprint>
			<date type="published" when="1973">1973</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="579" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Practical Optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Academic press</publisher>
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Video-Based Face Recognition Using Probabilistic Appearance Manifolds</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The CMU Motion of Body (MoBo) database</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<idno>CMU-RI-TR-01-18</idno>
		<imprint>
			<date type="published" when="2001-06">June 2001</date>
		</imprint>
		<respStmt>
			<orgName>Robotics Institute, Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Face Tracking and Recognition with Visual Constraints in Real-World Videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust Real-Time Face Detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Face Recognition Using Temporal Image Sequence</title>
		<author>
			<persName><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-PIE</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
