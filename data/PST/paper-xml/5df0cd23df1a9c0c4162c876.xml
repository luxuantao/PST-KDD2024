<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Reinforcement Learning for Intelligent Internet of Vehicles: An Energy-Efficient Computational Offloading Scheme</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Zhaolong</forename><surname>Ning</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peiran</forename><surname>Dong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaojie</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Guo</surname></persName>
							<email>guolei@cqupt.edu.cn</email>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Joel</forename><forename type="middle">J P C</forename><surname>Rodrigues</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Xiangjie</forename><surname>Kong</surname></persName>
							<email>xjkong@ieee.org</email>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Jun</forename><surname>Huang</surname></persName>
							<email>jhuang@cqupt.edu.cn.z.ning</email>
						</author>
						<author>
							<persName><forename type="first">Ricky</forename><forename type="middle">Y K</forename><surname>Kwok</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Software</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116620</postCode>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Chongqing Key Laboratory of Mobile Communications Technology</orgName>
								<orgName type="institution">Chongqing University of Posts and Telecom-munications</orgName>
								<address>
									<postCode>400065</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">National Institute of Telecommunications (Inatel)</orgName>
								<orgName type="institution">Santa Rita do Sapucaí</orgName>
								<address>
									<region>MG</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Instituto de Telecomunicac ¸ões</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Federal University of Piauí (UFPI)</orgName>
								<address>
									<settlement>Teresina</settlement>
									<region>PI</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Reinforcement Learning for Intelligent Internet of Vehicles: An Energy-Efficient Computational Offloading Scheme</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">331A5FF3CAD0D69ADA478E65A04CF3F9</idno>
					<idno type="DOI">10.1109/TCCN.2019.2930521</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TCCN.2019.2930521, IEEE Transactions on Cognitive Communications and Networking 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Internet of vehicles</term>
					<term>deep reinforcement learning</term>
					<term>computation offloading</term>
					<term>energy efficiency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The emerging vehicular services call for updated communication and computing platforms. Fog computing, whose infrastructure is deployed in close proximity to terminals, extends the facilities of cloud computing. However, due to the limitation of vehicular fog nodes, it is challenging to satisfy the quality of experiences of users, calling for intelligent networks with updated computing abilities. This paper constructs a three-layer offloading framework in intelligent Internet of Vehicles (IoV) to minimize the overall energy consumption while satisfying the delay constraint of users. Due to its high computational complexity, the formulated problem is decomposed into two parts: flow redirection and offloading decision. After that, a deep reinforcement learning based scheme is put forward to solve the optimization problem. Performance evaluations based on real-world traces of taxis in Shanghai (China) demonstrate the effectiveness of our methods, where average energy consumption can be decreased by around 60 percent compared with the baseline algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>H uman driving mistakes and misjudgments lead to 90% of traffic accidents <ref type="bibr" target="#b0">[1]</ref>. Internet of Vehicles (IoV) is a key enabling technology for smart cities, and is promising to alleviate congestion and reduce traffic accidents caused by driving misbehaviors. With the development of IoV and vehicle intelligence, vehicles are transforming from travel tools to intelligent terminals <ref type="bibr" target="#b1">[2]</ref>. For an American, over ten hours are spent in vehicles each week on average. Thanks to the telematics applications, IoV is becoming a platform for convenience and entertainment during the journey. However, the ever-increasing requirements of users' Quality of Experience (QoE) and vehicle intelligence challenge the implementation of telematics applications, especially the computation intensive applications, such as complicated decision making and realtime resource management <ref type="bibr" target="#b2">[3]</ref>.</p><p>Cloud computing, which evolves from distributed computing to grid computing is developed to overcome above obstacles of vehicular applications. Although it can provide sufficient computing resources, cloud or cloudlet centers may be far away from terminal users, reulting in large network latency <ref type="bibr" target="#b3">[4]</ref>. In 2020, more than 1.5 billion vehicles will be connected, and the requirements of real-time computing processing and data management challenge the bandwidth of core networks and users' QoE <ref type="bibr" target="#b4">[5]</ref>. Distinct sorts of data in IoV are collected and processed by vehicles to support the decisionmaking process of traffic management based applications, such as vehicular safety and intelligent driving <ref type="bibr" target="#b5">[6]</ref>.</p><p>Mobile subscriber is becoming the dominated data source, for example, a self-driving vehicle can generate more than 1 TB data per hour. How to make full use of the computing and storage abilities of vehicles is rather challenging, thus mobility supporting and geographical distribution are crucial. Motivated by this observation, the concept of fog computing is presented by Cisco company. By deploying fog servers with computational capabilities and storage resources at the edge of networks, users' QoE, especially network latency requirement, can be significantly promoted. According to the report of Cisco global cloud index, the total generated amount of data by Internet of Things (IoT) devices will be 4-fold greater in 2021 than that in 2016, and the amount of data stored on the edge of devices will reach over 80% of the total created data in 2021 <ref type="bibr" target="#b6">[7]</ref>. The widely distributed and real-time connections call for fog computing, because distinct communication patterns, e.g., Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure (V2I), and Vehicle-to-Sensor (V2S), coexist in IoV.</p><p>With the hypergrowth of sensors in intelligent vehicles, the variety and vast amount of generated data significantly challenge the decision making and network management in IoV, and call for intelligent computing technologies <ref type="bibr" target="#b7">[8]</ref>. The integration of emerging technologies, such as Deep Reinforcement Learning (DRL), computational offloading and cognitive computing, is promising to widen the horizons of solutions in IoV <ref type="bibr" target="#b8">[9]</ref>. Based on the report by McKinsey &amp; Company in 2016, intelligence and connectivity are essential for autonomous vehicles, which will occupy 15% of the vehicle market in 2030 <ref type="bibr" target="#b9">[10]</ref>. Generally speaking, the superiorities of intelligent IoV can be summarized as: cognitive intelligence, reliable decision making, efficient resource utilization, and rich market potentiality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivation</head><p>In 2016, the power consumption of data centers in China has reached 120 billion kilowatt-hours, dominating around 1.5% of the total electricity consumption in China and is even larger than the gross generated power by the Three Gorges Project. Althougn fog computing is acknowledged to be an alternative to reduce network latency and energy consumption in IoV, energy shortage is becoming a crucial obstacle to limit the development of IoV. According to the statistics <ref type="bibr" target="#b10">[11]</ref>, the increasing energy demands are 16.5% for electricity, 11.9% for traditional renewable, and 6.4% for coal. Instead, fossil fuels make up 49.4% of the total energy consumption, which are mainly consumed by current vehicles. Therefore, it is worth to carefully consider the energy consumption of the vehicular applications. Specially, Electric Vehicles (EVs) or hybrid EVs will dominate the market in the very near future. This motivates us to consider energy consumption in IoVs.</p><p>Current researches on green IoV mainly focus on energy management of either battery-equipped Road Side Units (RSUs) or EVs. However, energy-efficient computational offloading has not been fully investigated, which is significant to save energy and accelerate the computation process in IoV. Because of the limited computing and hardware capabilities of vehicles, two issues should be fully considered for fogenabled offloading in IoV: one is whether offloading tasks by fog computing or not; the other is whether offloading network loads fully or partially. Therefore, energy-efficient computing based on the coordination between cloudlet servers and fog nodes deserves to be well studied.</p><p>With the objective of realizing intelligent energy-efficient IoV, how to implement DRL algorithms in IoV systems deserves to be well investigated. Data centers with strong processing abilities and large memory resources are suitable for employing DRL algorithms. In order to provide (approximate) real-time responses for vehicles, implementing DRL algorithms at the network edge is regarded as a promising solution, since it can process the generated data close to the event occurrence location. However, the majority of the machine learning and artificial intelligence algorithms consumes a large amount of energy, which may not always be available for edge devices. Therefore, RSUs equipped with MEC servers are desired to undertake the decision making task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contribution</head><p>Different from the emergent message transmission (such as road safety and dangerous activities) in IoVs, our work focuses on the services for vehicular entertainment, which are not urgent but consume large resources, such as bandwidth and energy. In order to minimize the overall energy consumption of the computational facilities and vehicles while satisfying the delay constraint for traffic offloading, this paper constructs a three-layer energy efficient offloading scheme in IoV. The designed framework is rational for intelligent IoV, because computational intensive tasks can be processed on fog nodes to satisfy the requirements of delay-sensitive vehicular applications. After that, a DRL based scheme is designed to solve the optimization problem. The main contribution of our work can be summarized as follows:</p><p>• We construct a three-layer architecture in IoV, and formulate an energy-efficient computational offloading problem to minimize the overall power consumption while satisfying the delay constraint.</p><p>• The formulated problem is decomposed into two parts, i.e., flow redirection and offloading decision. For the first part, an Edmonds-Karp based scheme is developed to balance the traffic load among RSUs, while a DRL based model is investigated for the second part. • The DRL model is constructed based on the queuing theory, where the system state comprises the arrival rate of moving vehicles, the arrival rate of offloading task folws and the number of parked vehicles. These variables are the main factors that affect the offloading decision macroscopically.</p><p>• Performance evaluations based on the real-world traces of taxies in Shanghai (China) demonstrate the effectiveness of our solutions, i.e., the developed Edmonds-Karp algorithm can balance the load of RSUs with relatively low energy consumption, and the DRL based offloading decision scheme is superior to other compared methods with various parameters. The rest of this paper is organized as follows. We first provide an overview of the related studies in Section II. After that, we illustrate the system model in Section III. The optimization problem is formulated in Section IV. We briefly introduce the overview of DRL in Section V. Edmonds-Karp and the DRL based schemes are specified for energyefficient offloading in IoV in Section VI. In Section VII, performance evaluations demonstrate the effectiveness of our methods. Finally, we conclude our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>This section outlines the current research progresses of intelligent computing for IoV from the following three aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cognitive IoV</head><p>By data mining, pattern recognition, and natural language processing, cognitive computing is an alternative for decision making. As an integration of cognitive computing and IoV, cognitive IoV leverages cognitive technologies and comprehensively analyzes the collected data in physical and network spaces <ref type="bibr" target="#b11">[12]</ref>. Different from the traditional IoV focusing on traffic data, cognitive IoV concentrates on the top-level issues, such as promoting the intelligence of vehicles for decision making. Furthermore, the spectrum scarcity of IoV is severe due to the ever-increasing density of vehicles <ref type="bibr" target="#b12">[13]</ref>. An opportunistic traffic offloading scheme is investigated in IoV <ref type="bibr" target="#b13">[14]</ref>, which comprehensively takes users' satisfaction, offloading performance and network operators' revenue into consideration. A cognitive method is designed to predict offloading potential and access costs. Although current machine learning solutions generally concentrate on the computational efficiency, security is critical for the machine learning based computing architectures to ensure that the system can perform as expected without harmful behaviors. However, the high-level security mechanism generally accompanies large energy consumption due to the high computational complexity, challenging the energy-constrained fog devices. Therefore, it is challenging for energy-aware security cognitive computing. One way is to design low complexity cryptographic algorithms, so that the encryption overhead and energy consumption of fog devices can be reduced. Another solution is to study energy-harvesting schemes for green IoV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Vehicular Fog Computing</head><p>DRL based solutions, relying on mass data for training or tons of documents for processing, are power consuming. A centralized cloud center is capable to obtain the overall network knowledge and can guarantee network security by efficient network management. However, cloud or GPU based deep learning may not cope with the rapid traffic demands in IoV. Therefore, Vehicular Fog Computing (VFC) can be integrated into the cloud computing model to enhance learning efficiency.</p><p>VFC is promising for real-time traffic management by making full use of idle resources in vehicles, such as vehicles on the move or in the parking slot <ref type="bibr" target="#b14">[15]</ref>. However, the computational and storage capacities of VFC are still limited comparing with the cloud or cloudlet computing. In addition, the fog nodes generally lack resources to become intelligent by self-learning. In VFC, accurate prediction of vehicle mobility largely impacts the utilization of computing resources and energy. One way is to mine traffic flow according to the position, direction and velocity of vehicles. As EVs are becoming popular, vehicle-to-grid technology has been investigated to charge EVs and monitor their power status in the smart grid. A hybrid computing model for vehicle-togrid networks is designed in <ref type="bibr" target="#b15">[16]</ref>, including a permanent cloud or cloudlet and temporary vehicular fog nodes. In <ref type="bibr" target="#b16">[17]</ref>, the authors design a hierarchical architecture enabled by VFC to provide prompt responses at neighborhood, community and city-wide traffic management, and detect events threatening network safety. Recently, L. Tan et al <ref type="bibr" target="#b17">[18]</ref> design a mobilityaware edge caching vehicular networks. A classical machine learning method is developed to solve the advanced particle swarm optimization problem, which also guarantees the global optimal solution with fast convergence and high stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Deep Reinforcement Learning based Offloading</head><p>Since the limited training data and novel applications appear continually, supervised learning becomes difficult for feature learning. Although unsupervised learning is promising to exploit the features of network traffic, it is challenging to fulfill real-time training processing <ref type="bibr" target="#b18">[19]</ref>. The authors in <ref type="bibr" target="#b19">[20]</ref> present an online reinforcement learning method to balance traffic loads in vehicular networks. By learning from the feedback and traffic patterns under dynamic vehicular circumstances, this method can well regulate network traffic. Because vehicles are not competent enough to analyze data or recognize traffic patterns in IoV, a DRL based framework is constructed to customize network services <ref type="bibr" target="#b20">[21]</ref>. Due to the insufficient resource of fog devices, the realization of a complex deep learning system is challenging, not to mention the real-time deep learning for IoV with strict delay limitation.</p><p>In order to fulfill high-efficient traffic management in IoV, a joint communication, caching and computing problem is investigated in <ref type="bibr" target="#b21">[22]</ref>. A DRL based method is further presented to solve the mentioned problem. The authors in <ref type="bibr" target="#b22">[23]</ref> propose a knowledge driven service offloading decision framework for IoV. They consider a long-term offloading scheduling, and provide the multi-task offloading policy by exploring the DRL based method. The resource allocation strategy is formulated as a joint optimization problem in <ref type="bibr" target="#b23">[24]</ref>, where the gains of not only networking but also caching and computing are taken into consideration. Due to the complexity of the formulated problem, a DRL based approach is developed to obtain the optimal solution. The authors in <ref type="bibr" target="#b24">[25]</ref> transform the original joint computation offloading and content caching into a convex problem, and then solve it in a distributed and efficient way. Different from current researches that focus on content caching or distributed offloading schemes, our work presents an energy-efficient and load balancing offloading algorithm based on queuing theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SYSTEM MODEL</head><p>This section first provides an overview of the constructed three-layer system model. Then, the communication and computation models in the cloudlet and fog layers are specified, respectively. After that, the optimization problem focusing on the overall energy minimization is formulated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. System Model</head><p>Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the system model, including the layers of cloudlet, RodeSide Units (RSUs), and fog nodes. In our system, vehicles can send their offloading tasks to nearby RSUs. Instead of uploading all tasks to remote cloud servers or base stations, RSUs allocate these tasks to the cloudlet or nearby fog nodes for processing. Both parked and moving vehicles can be viewed as fog nodes <ref type="bibr" target="#b14">[15]</ref>, and they are referred to be parked vehicle-based and moving vehicle-based fog nodes, respectively. Since computation offloading consumes massive electric power, our main focus is to minimize the overall energy consumption during the offloading procedure.</p><p>Through real dataset analysis, vehicular flows arriving at RSU r i follow a Poisson process, with an arrival rate denoted as λ vehicle i <ref type="bibr" target="#b25">[26]</ref>. Therefore, the uploading procedure of offloading tasks can be viewed as a subprocess of the vehicular flows. Correspondingly, the task flow arriving at RSU r i also follows a Poisson process, with an arrival rate λ i . In addition, vehicular networks within urban city can be partitioned into several regions, and we focus on one of them as an example. The constructed offloading system is easy to be extended to other city-wide vehicular networks. In region G, there exists a cloudlet server c, a set of RSUs</p><formula xml:id="formula_0">{r 1 , • • • , r u }, a group of parked vehicles {v p 1 , • • • , v p l }</formula><p>, and a stream of moving vehicles</p><formula xml:id="formula_1">{v m 1 , • • • , v m n }.</formula><p>The objective of our work is to minimize the overall energy consumption of the offloading processes while satisfying the corresponding delay constraint. The energy consumption can be computed by E = P × t tol , where P denotes the power of processing servers and t tol denotes the duration of the computation offloading. Specifically, the total execution delay of offloading can be obtained by t tol = t up + t wat + t pro + t down , where t up and t down are transmission time of uploading and downloading between an RSU and a process server. The symbol t wat denotes the queue waiting time for a task at the process server, and the processing time is represented by t pro . For simplicity, t up can be regarded as equal to t dowm . Therefore, t tol = 2t up + t wat + t pro denotes system execution delay for offloading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Cloudlet Model</head><p>Since the computation capability of vehicles are limited, cloudlet can be leveraged to process offloading tasks with strict delay requirement. The total execution time contains four parts: t c tol = t c up + t c wat + t c pro + t c down . In addition, the cloudlet processing system can be modeled as an M/M/b queue, including b homogeneous servers with fixed processing rate µ c . Let λ c denote the number of offloading flow waiting in the queue. The service rate for cloudlet can be computed by ρ c = λ c /bµ c , and ρ c &lt; 1 holds. According to queuing theory <ref type="bibr" target="#b26">[27]</ref>, expectation waiting time in queue E(t wat ) for a task can be computed by:</p><formula xml:id="formula_2">E(t wat ) = f (b, ρ) = b-1 k=0 b k ! 1 -ρ 2 (bρ) b-k ρ + 1 -ρ ρ -1 .<label>(1)</label></formula><p>The expectation processing time is E(t c pro ) = 1/µ c . In addition, the uploading time t up is related to achievable transmission rate, which can be calculated by:</p><formula xml:id="formula_3">R ri→cloudlet = W log 2 1 + p i,c h i,c σ 2 + u j=1,j =i p j,c h j,c ,<label>(2)</label></formula><p>where W is the allocated bandwidth. Transmission power p ri→cloudlet and channel gain h ri→cloudlet are simplified as p i,c and h i,c , respectively. Variable σ 2 denotes the Guassian noise. Non-Orthogonal Multiple Access (NOMA) technology is utilized for the connection between cloudlets and RSUs. The interference caused by other RSUs occupying the same channel is represented by u j=1,j =i p j,c h j,c . Vehicles are considered to generate offloading tasks T = {d, t max }, where d represents the data size to be processed, and t max denotes the maximal tolerable delay. Therefore, the uploading time can be calculated by t c up = d ri→cloudlet /R ri→cloudlet . The expectation of total execution time t c tol can be obtained by:</p><formula xml:id="formula_4">E(t c tol ) = 2 × t c up + E(t c wat ) + E(t c pro ) = 2 × d ri→cloudlet R ri→cloudlet + f (b, ρ c ) + 1 µ c .<label>(3)</label></formula><p>Thus, the total energy consumption of cloudlet offloading procedure can be calculated by:</p><formula xml:id="formula_5">E c tol = E c up + E c wat + E c pro + E c down = (P up i,c + P dowm c,i )t c up + P wat c E(t c wat ) + P pro c E(t c pro ).<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Fog Model</head><p>As mentioned in Section III-A, both parked and moving vehicles can be leveraged for fog nodes. In this subsection, we specify the fog model.</p><p>1) Parked Vehicle-based Fog Model: Considering that there are s time slots in a day, the number of parked vehicles l keeps unchanged during each time slot. A parked vehicle can be regarded as a fog node equipped with one processing server (with a fixed service rate µ p ). These l parked vehicle based fog nodes can be modeled as an M/M/L queue. Similar to the cloudlet, the service rate of the parked vehicles can be calculated by ρ p i = λ p i /lµ p , where λ p i represents the flow waiting number for parked vehicles to process, and ρ p i &lt; 1 holds. The expectation of total execution time for one task can be obtained by:</p><formula xml:id="formula_6">E(t p tol ) = E(t p wat ) + E t p pro + 2 × t p up = f (l, ρ p i ) + 1 µ p + 2 × t p up .<label>(5)</label></formula><p>Then, the total energy consumption of parked vehicles can be computed by: (6) 2) Moving Vehicle-based Fog Model: A moving vehicle can also be viewed as a fog node with a processing server. Due to its mobility, it is more complicated than a parked vehicle. It is demonstrated that moving vehicles can be modeled as an M/M/1 queue with an arrival rate λ vehicle i <ref type="bibr" target="#b14">[15]</ref>. Since RSU r i allocates the arriving offloading flow to cloudlet, parked vehicles and moving vehicles, offloading flows arriving at moving vehicles λ m i can be viewed as a subpart of the offloading flow arriving at RSU r i , with arriving rate λ i . Thus, λ m i &lt; λ i holds. Correspondingly, λ m i &lt; λ i &lt; λ vehicle i holds. In addition, we assume that the computation capabilities of all moving vehicles are the same for simplicity. When a moving vehicle enters in the wireless communication range of RSU r i , it picks up an offloading task waiting in front of the queue, and can accomplish the processing before moving out of the communication range. The offloading flow waiting in the queue can be regarded as a stochastic process, represented as {X n , n ≥ 0}. The discrete status, i 0 , i 1 , ..., i n+1 , indicates the number of tasks in the waiting queue, and P {X 0 = i 0 , X 1 = i 1 , ..., X n = i n } &gt; 0 holds. It can be observed that the number of offloading tasks in the waiting queue at time slot t + 1 only depends on the status at time slot t, i.e., P</p><formula xml:id="formula_7">E p tol = E p up + E p</formula><formula xml:id="formula_8">{X n+1 = i n+1 | X 0 = i 0 , ..., X n = i n } = P {X n+1 | X n = i n }.</formula><p>Therefore, the offloading flow waiting for moving vehicles to process can be modeled as a Markov chain. The transition rate matrix is as follows:</p><formula xml:id="formula_9">      -λ m i λ m i λ vehicle i -λ vehicle i + λ m i λ m i ... λ vehicle i -λ vehicle i + λ m i λ vehicle i ...       . (7)</formula><p>We can observe that the above transition rate matrix is formally identical to the M/M/1 queuing system. Therefore, the offloading system of moving vehicle based fog nodes can be modeled as an M/M/1 queue, where λ m i denotes the task arrival rate, and the processing rate of moving vehicles is λ vehicle i . Thus, the service rate can be calculated by ρ m i = λ m i /λ vehicle i . In addition, the expectation of total execution time can be computed by:</p><formula xml:id="formula_10">E(t m tol ) = E(t m wat ) + E t m pro + 2 × t m up = ρ m i λ vehicle i (1 -ρ m i ) + 1 λ vehicle i + 2 × t m up . = 1 λ vehicle i -λ m i + 2 × t m up .<label>(8)</label></formula><p>Correspondingly, the total energy consumption of moving vehicles can be obtained by:</p><formula xml:id="formula_11">E m tol = E m up + E m wat + E m pro + E m down = (P up i,m + P dowm m,i )t m up + P wat m E(t m wat ) + P pro m E(t m pro ).<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Redirection Model</head><p>In order to balance offloading task flows, RSUs are considered to be reachable from each other, similar to <ref type="bibr" target="#b27">[28]</ref>.</p><p>Since flows arriving at RSUs may be significantly different, overloaded RSU can redirect part of its flows to unloaded RSUs. Variable g (i, k) is defined as the amount of task flows redirected from RSUs r i to r k . In addition, the following constraints should be satisfied:</p><formula xml:id="formula_12">g (i, k) = -g (k, i) , i = k , 0, otherwise. (<label>10</label></formula><formula xml:id="formula_13">) u i=1 u k=1 g (i, k) = 0,<label>(11)</label></formula><formula xml:id="formula_14">u k=1 max {g (i, k) , 0} ≤ λ i ,<label>(12)</label></formula><p>where indicators i, k ∈ {1, 2, ..., u}. The communication channel states are assumed to be identical and keep unchanged during one scheduling time slot. Let d ri,r k indicate unit transmission delay caused by transferring offloading tasks between RSU r i and RSU r k . If redirected flow g(i, k) &lt; 0, RSU r k transfers flows to RSU r i and delay (-g (i, k)×d ri,r k ) exists. The total delay t j i,redirect incurred by redirecting flows from RSU i to other RSUs during time slot j can be calculated as follows:</p><formula xml:id="formula_15">t j i,redirect = u k=1 | max {g (i, k) , 0} × d ri,r k |.<label>(13)</label></formula><p>In addition, the energy consumption of redirection for RSU r i at time slot j can be obtained by E j i,redirect = P ri × t j i,redirect . The final arriving task flows at RSU r i can be computed by:</p><formula xml:id="formula_16">λ i = λ i - u i=1 g (i, k) .<label>(14)</label></formula><p>IV. PROBLEM FORMULATION The optimization problem is formulated in this section. Since the formulated problem is a Mixed Integer Non-Linear Programming (MINLP) problem, and variables are tightly coupled in different constraints, the optimization problem is divided into two sub-problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Optimization Objective</head><p>When a vehicle generates an offloading task, it uploads the task flow to the nearby RSU. After RSU receives accurate information of all tasks, it will judge whether it is overloaded or not. Then, RSUs perform flow redirection to achieve load balance among them. In order to minimize energy consumption, RSUs make offloading decisions on the redirected task flow.</p><p>In our work, urban area is divided into several regions. In each region, a central cloudlet and u distributed RSUs are available. Both parked and moving vehicles in the proximity of RSUs can be utilized as fog nodes. The total energy consumption of RSU r i at time slot j can be calculated by:</p><formula xml:id="formula_17">E j i,tol = αE c(j) i,tol + βE p(j) i,tol + γE m(j) i,tol + E j i,redirect ,<label>(15)</label></formula><p>where α + β + γ = 1, and α = 1, if the message is processed by the cloudlet, 0, otherwise. ( <ref type="formula">16</ref>) </p><formula xml:id="formula_18">β =      1,</formula><formula xml:id="formula_19">λ c i ,λ p i ,λ m i ,b 1 su s j=1 u i=1 E j i,tol ,<label>(19)</label></formula><formula xml:id="formula_20">s.t.                          Equations (10) -<label>(14)</label></formula><p>,</p><formula xml:id="formula_21">λ c i + λ p i + λ m i ≤ λ i , λ c = u i=1 λ c i , 0 &lt; λ c bµ c , λ p i lµ p , λ m i λ vehicle i &lt; 1, α + β + γ = 1, α, β, γ ∈ {0, 1} .<label>(20)</label></formula><p>Based on above constraints, we can observe that the formulated problem is a MINLP problem, which is difficult to solve. Thus, the original problem is divided into two solvable sub-problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Flow Redirection</head><p>Distributed in various urban areas, the amount of task flows arriving at RSUs may be significantly distinct. If RSUs only process tasks within their regions, RSUs located at business district or stations may be overloaded. Therefore, load balancing is necessary before offloading decision making. Since cloudlet server is generally equipped with sufficient electric energy, the optimization target of load balancing is to balance the processing load among fog nodes (i.e., parked vehicles and moving vehicles) through flow redirection.</p><p>Load ratio σ is defined as the ratio of processing rate by fog nodes compared to arriving task flows at RSUs, i.e.,</p><formula xml:id="formula_22">σ = u i=1 (lµ p + λ vehicle i ) u i=1 λ i . (<label>21</label></formula><formula xml:id="formula_23">)</formula><p>RSUs are divided into two sets, where one is unloaded set</p><formula xml:id="formula_24">V u = k|lµ p + λ vehicle k ≤ λ k , and the other is overloaded set V o = i|lµ p + λ vehicle i &gt; λ i .</formula><p>For each overloaded RSU r i , i ∈ V o , the amount of task flows that can be redirected to other RSUs is defined as φ i . Based on Equation <ref type="bibr" target="#b20">(21)</ref>, φ i can be obtained by</p><formula xml:id="formula_25">φ i = λ i × σ -lµ p -λ vehicle i</formula><p>, where φ i &gt; 0 holds. Similarly, for each unloaded RSU, the amount of task flows allowing to be redirected from other RSUs can be calculated by φ k = lµ p + λ vehicle k -λ k × σ, where φ k &gt; 0 holds. Then, the first sub-problem is formulated as follows:</p><formula xml:id="formula_26">min 1 s s j=1 i∈Vo k∈Vu E j i,redirect .<label>(22)</label></formula><p>objective is to minimize the energy consumption of redirection for all time slots. Since flow redirection is identical for each time slot, it is equivalent to minimize the energy consumption in each time slot, where the objective is:</p><formula xml:id="formula_27">min i∈Vo k∈Vu E i,redirect .<label>(23)</label></formula><formula xml:id="formula_28">s.t.                  Equations (10) -(14), i∈Vo g (i, k) = φ k , k ∈ V u , k∈Vu g (i, k) = φ i , i ∈ V o , g (i, k) ≥ 0.<label>(24)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Offloading Decision</head><p>After redirecting task flows, RSUs make offloading decisions by scheduling arrived task flows to cloudlet or fog nodes. To minimize the average energy consumption of task offloading, the objective of the second sub-problem can be expressed as follows:</p><formula xml:id="formula_29">min λ c i ,λ p i ,λ m i ,b 1 su s j=1 u i=1 (αE c(j) i,tol + βE p(j) i,tol + γE m(j) i,tol ).<label>(25)</label></formula><p>After redirecting task flows, the optimization objective, i.e., minimizing the average energy consumption for all RSUs, is equivalent to minimizing the energy consumption for each RSU. Therefore, the second sub-problem becomes:</p><formula xml:id="formula_30">min λ c i ,λ p i ,λ m i ,b 1 s s j=1 (αE c(j) i,tol + βE p(j) i,tol + γE m(j) i,tol ),<label>(26)</label></formula><formula xml:id="formula_31">s.t.                    λ c i + λ p i + λ m i ≤ λ i , λ c = u i=1 λ c i , 0 &lt; λ c bµ c , λ p i lµ p , λ m i λ vehicle i &lt; 1, α + β + γ = 1, α, β, γ ∈ {0, 1} .<label>(27)</label></formula><p>V. OVERVIEW OF DEEP REINFORCEMENT LEARNING Before implementing the DRL based algorithm, we briefly provide an overview of DRL.</p><p>Reinforcement Learning (RL) is a significant branch of machine learning. It refers to the process of achieving a target through multiple steps and appropriate decisions under a series of scenarios, which can be regarded as a multistep sequence decision problem. Different from traditional machine learning, RL can not obtain final results immediately, but only observes a temporary reward (mostly set by human experience). Thus, RL can also be viewed as a kind of delayed supervision learning. Dynamic Programming (DP) and policy-based optimization algorithms are generally leveraged to solve the problems in RL, where DP includes value iteration and policy iteration. In model-free algorithms, DP can be classified as Monte Carlo and temporal difference algorithms. With the development of RL, it is utilized to deal with problems with continuous state and action spaces. It is almost impossible to measure each state or action with a simple value function. Therefore, policy-based optimization is proposed by parameterizing the policy, which introduces neural networks into RL. Q-learning is a typical temporal difference RL algorithm. It defines Q-function to evaluate the long-term reward of the policy, which is replaced by neural networks in DRL. For each episode, Q-learning makes decisions based on the Q-value, which evaluates the selected action under current circumstances. Deep learning fits data distribution and function model through multi-layer nonlinear neural networks. DRL integrates the superiority of both RL and deep learning. In addition, based on the characteristics of trial and error and reward delay, the performance of DRL is satisfactory in realistic decision making problems.</p><p>Experience replay can improve the utilization ratio of samples while reducing the correlation. Random sampling means that each transition is sampled with the same probability. However, the value of all samples may vary greatly. Learning simple and common samples does not improve the Deep Q-Network (DQN) model significantly. If DQN treats all transitions equally, it can spend much time on ordinary samples, which can not fully exploit the potential of the training data. Priority experience replay solves this deficiency by assigning a certain sampling weight according to the performance of the current sample. The worse the performance is, the higher the weight is assigned, resulting in the higher the probability of sampling becomes. In this way, those samples, decreasing the model performance, have high probabilities to be re-learned.</p><p>In the training phase, every step of sampling is random. To obtain accurate Q-values, we can perform multiple samples to obtain the expected value of Q-network, which is the key idea of the asynchronous DRL. Thus, the equation for reward calculation becomes:</p><formula xml:id="formula_32">Q = E(r + γQ(s , arg max a Q(s , a ; θ); θ -)). (<label>28</label></formula><formula xml:id="formula_33">)</formula><p>In practical applications, asynchronous solutions are usually performed in multiple threads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DEEP REINFORCEMENT LEARNING BASED OFFLOADING ALGORITHM</head><p>In this section, Edmonds-Karp algorithm and DRL based schemes are leveraged to solve the formulated two subproblems, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Flow Redirection</head><p>An example of flow redirection is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, where overloaded RSU r i redirects part of its received offloading task flows to unloaded RSU r k . The first sub-problem (i.e., Equation ( <ref type="formula" target="#formula_27">23</ref>)) can be viewed as a typical network flow problem, where RSUs and energy consumption are network nodes and cost, respectively. In addition, the topology of RSUs within G constitutes a network flow graph.</p><formula xml:id="formula_34">RSU i r i  RSU k r k  ) , ( k i g ) , ( k i g k   Cloudlet b servers m i p i i k i g       ) , ( m k p k k k i g       ) , (        </formula><p>Edmonds-Karp algorithm based scheme is leveraged to solve this problem, and its pseudocode is specified in Algorithm 1. In order to construct a maximum flow problem, a super source node s and a super destination node t are added in graph G to form G , where RSUs in V o and V u connect to nodes s and t, respectively. For RSUs in V o , the capacity of the connection between RSU r i and source node s is φ i . Similarly, the capacity of the connection between RSU r k ∈ V u and destination node t is φ k . Note that the transmission delay among RSUs and super nodes is 0. By the breadth-first search method, Edmonds-Karp algorithm based scheme searches the shortest augmentation path in G until no more augmentation path exists. In particular, it can fulfill Ford-Fulkerson algorithm with polynomial time complexity. Flow redirection is promising to make more RSUs not overloaded under the premise of minimum energy consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DRL for Energy Consumption Minimization</head><p>Different from traditional machine learning algorithms, does not prepare training data in advance, but samples unlabeled data. Traditional DQN utilizes the same Q-network to evaluate the selection of system actions and approximate the true action-value function. Although this method improves the robustness of the DQN model, action selection by the greedy strategy results in inherent shortcomings of DQN, e.g., overestimation. Therefore, Double DQN (DDQN) is proposed in <ref type="bibr" target="#b28">[29]</ref> by constructing different action-value functions to the selection scheme (i.e., the evaluated Q-network) and approximate the real action-value function (i.e., the target Q-network). When implementing DDQN, DQN copies the parameter of evaluated Q-network as the target Q-network. Then, evaluated Q-network and target Q-network update alternately. The proposed DRL based algorithm for Minimizing Energy Consumption (DMEC) is based on DDQN. Note that implementing a simple Q-learning algorithm through neural networks in DRL model can cause shocks or divergence. The reasons are follows:</p><p>• Data serialization: Time-continuous samples are interrelated and not independently distributed; </p><formula xml:id="formula_35">i ∈ V o do capacity[s][i] = φ i ; delay[s][i] = 0; end while k ∈ V u do capacity[k][t] = φ k ; delay[k][t] = 0; end for each edge e[i][j] in G do f lows[i][j] = 0; end while find a shortest route p from s to t in G do m = min(capacity[i][j]|e[i][j] ∈ p); for each edge e[i][j] in p do if m &lt;= capacity[i][j] then capacity[j][i] = capacity[j][i] + m; f lows[i][j] = f low[i][j]</formula><p>+ m; end end minEnergyConsumption = P ri ×f lows×delay; end • Policy may oscillate: Minor changes in Q values may dramatically affect policies; • The value range of reward functions is unknown: Gradients in simple Q-learning are very unstable when backpropagating. In order to overcome the mentioned obstacles, experience replay is investigated to prevent training results from falling into local optimum. In addition, it utilizes random sampling to simulate supervised learning and break the correlation among data training. Specific steps of experience replay are: initialize a buffer in memory, and store Markov Decision Process (MDP) based training data during simulation. Then, randomly sample a batch of samples in stored training data. After that, calculate Q value and update network parameters. When the experience replay buffer is full, the newly sampled training data substitute the old data. The exploition of the experience replay mechanism can be viewed as the utilization of Monte Carlo algorithm in deep Q-learning.</p><p>The second sub-problem (i.e., Equation ( <ref type="formula" target="#formula_29">25</ref>)) is a cost minimization problem with a period of time. Due to the immense space of available offloading decisions and timevarying characteristics, the energy consumption minimization problem can be formulated as a DRL process. The DRL problem can be viewed as an optimal control problem based on MDP, where convolutional neural networks are leveraged to represent the action-value function. Specifically, there are four significant elements in DRL: agents, system states, system actions and rewards. In the following, they are identified to construct the DRL-based model:</p><p>• Agents: RSUs are selected to be agents in the DRL process. For each episode, RSUs choose an action according to system states, with the target of maximizing rewards. • System States: They comprise the arrival rate λ vehicle i that moving vehicular flows arriving at RSU r i , the arrival rate of offloading task flows λ i , and the number of parked vehicles within the communication range of RSU l. Since the current values of system states are only related to the value of the last time slot, they are modeled as Finite-State Markov Chains (FSMC) <ref type="bibr" target="#b29">[30]</ref>, which can be expressed as:</p><formula xml:id="formula_36">S i (t) = [λ vehicle i (t), λ i (t), l(t)].<label>(29)</label></formula><p>• System Actions: RSU r i is responsible for scheduling arrival task flow λ i to three platforms: cloudlet λ c i , parked vehicles λ p i , and moving vehicles λ m i . The infrastructure based cloudlet generally consumes more energy than that of fog nodes. Thus, task flows are preferentially assigned to parked vehicle based and moving vehicle based fog nodes. In addition, moving vehicles are not stable, and their locations vary a lot during a time slot. Therefore, task flows assigned to parked vehicles satisfy λ p i = lµ p . Then, RSUs decide the value of λ m i through DRL. Finally, the rest task flows are scheduled to the cloudlet:</p><formula xml:id="formula_37">λ c i = λ i -λ p i -λ m i .</formula><p>Since the value of the task flow is continuous in reality, the available system action space is infinite. Therefore, the value range of λ m i should be discretized and quantized into L = min λ vehicle i , |λ i -λ p i | levels, which is presented as:</p><formula xml:id="formula_38">a i (t) = [0, 1, 2, • • • , L -1, L] .<label>(30)</label></formula><p>• Rewards: Generally, agents aim to maximize rewards for all time slots in DRL. However, the optimization target of our model is to minimize the overall energy consumption. Thus, the reward function is defined as the opposite number of the energy consumption in Equation <ref type="bibr" target="#b22">(23)</ref>, which is expressed as follows:</p><formula xml:id="formula_39">R i = - 1 s s j=1 αE c(j) i,tol + βE p(j) i,tol + γE m(j) i,tol<label>(31)</label></formula><p>pseudo-code of DMEC is presented in Algorithm 2. First, experience replay buffer and parameters of DQN are initialized. Specially, the evaluated Q-network is initialized with the same parameter to the target Q-network, i.e., θ = θ -.</p><p>For each episode, RSUs choose actions randomly with probability ε. A greedy strategy is leveraged to select the action that maximizes current rewards. Then, the immediate reward and the next system states can be observed. In addition, current system states, the selected action, the obtained rewards and the next observed system states constitute a transition, which is stored in the replay buffer to train target Q-network. Sample random mini-batch of transitions (x j , a i , r j , x j+1 ) from D; if episode terminates at step j + 1 then the target Q-value y j = r j ; end else y j = r j + γQ(x j+1 , arg max a Q(x j+1 , a ; θ); θ -); end Perform gradient decent on y j -Q(x j , a j ; θ) 2 ; Every C steps, update the target Deep Q-Network parameters and probability ε with rate σ and µ,</p><formula xml:id="formula_40">θ -= σθ + (1 -σ)θ -, ε = ε -µε.</formula><p>end end leveraged to calculate the temporal difference target. After gradient descent is performed to update parameters of evaluated Q-network. Finally, by considering both fitting accuracy and convergence speed, parameters of target Qnetwork and random probability ε are updated every C steps, where C is a constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Complexity Analysis</head><p>In this subsection, we theoretically analyze the complexity of our proposed two algorithms. For the Edmonds-Karp algorithm based flow redirection, we assume that all RSUs can communicate with each other, i.e., the flow redirection graph is a complete graph. Therefore, the computation complexity of the Edmonds-Karp algorithm based scheme is O(u 3 ), where u represents the number of RSUs. Since vehicles do not participate in the flow redirection, the complexity of the Edmonds-Karp algorithm based scheme does not scale when the number of vehicles increases. Since the number of RSUs is much less than that of vehicles, its computation complexity is acceptable.</p><p>With neural networks, the computation complexity of the DMEC algorithm is related to the number of training and updating parameters. Let U denote the total training episodes, can be viewed as a hyper-parameter. For each episode, the DMEC loops until the offloading task is terminated, where the total number of time slots is denoted as T . Without loss of generality, the computation complexity of gradient decent and parameter updating can be defined as M and N respectively. In order to improve training efficiency, the parameter of target DQN is updated every C steps, where C is a constant. In summary, the computation complexity of the DMEC is O(U × T ((M + N )/C). Note that the size of the input layer of the DMEC is the same as that of the system states, which is proportional to the number of vehicles. Thus, the growing number of vehicles can lead to the scaling of the computation complexity of the DMEC algorithm. Two methods are utilized to decrease the computation complexity. The first one is increasing C to decline the computation complexity at the expense of training accuracy. The second one is limiting the number of vehicles by dividing a city into multiple districts according to the map or administrative areas. Performance evaluations based on real-world traces of taxies in Jingan district, Shanghai (China), demonstrate the effectiveness of our proposed method in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. PEFORMANCE EVALUATION</head><p>With python anaconda 4.3, TensorFlow 0.12 is employed to implement the DMEC algorithm on Ubuntu 16.04 LTS. To balance the trade-off between training accuracy and time consumption, we select Jingan district in Shanghai (China) as illustrated in Fig. <ref type="figure" target="#fig_2">3</ref>, while the method can be extened to other districts. One cloudlet server and 5 RSUs equipped with MEC servers are considered to be within the district. The selected GPS locations are presented in Table <ref type="table" target="#tab_4">I</ref>. Performances are evaluated based on real-world traces of taxies that is collected in the whole April 2015, including the GPS information of more than 1000 taxies. The learning rate of the DMEC is set as 0.99. There are 3 hidden layers (each with 128 full connected neurons) for both evaluated Q-Networks and target Q-Networks. The total training episodes are 20000, and the parameter of the target Q-Network is updated every 10 time slots. On the flow redirection stage, our optimization target is to minimum energy consumption under the premise of RSUs not overloaded. Parameter delay matrix can be calculated according to Equation <ref type="bibr" target="#b12">(13)</ref>. In addition, there are two performance indicators, i.e., average energy consumption of flow redirection and overloaded ratio of RSUs.</p><p>For the second stage, key parameters are illustrated in Table <ref type="table" target="#tab_4">II</ref>, where W c and W v denote the bandwidth that RSUs communication with cloudlets and vehicles, respectively. Three schemes are selected to compare with the presented DMEC:   transferred to the cloudlet server for processing. Fig. <ref type="figure" target="#fig_3">4</ref> illustrates the performance of average energy consumption of flow redirection with different offloading task arrival rates. We can observe that the average energy consumption raises gradually with the increasing of the offloading task arrival rate. It is because that increasing tasks lead to more overloaded RSUs, and more task flows need to be redirected. In addition, when the task arrival rate is relatively low (e.g., 15 or 20), little distinction exists among the performance of Edmonds-Karp, the greedy and the exhaustive algorithms.  As the arrival rate increases, the energy consumed by the method raises sharply. This is because that the number of searching is small when the arrival rate is low, and quickly with the increase of the arrival rate. Edmonds-Karp algorithm based scheme always chooses the current shortest augmentation path in the network flow graph through breath-first searching. Therefore, it is superior to the greedy method.</p><p>Fig. <ref type="figure" target="#fig_4">5</ref> shows the performance of the overloaded ratio of RSUs with different offloading task arrival rates. Herein, the overloaded ratio of RSUs is defined as</p><formula xml:id="formula_41">|V o |/(|V u | + |V o |).</formula><p>For ease of description and without loss of generation, we select three situations to illustrate the performance, where the task arrival rate equals to 15, 25 and 40, respectively. It can be observed that the performance of flow redirection based on low task arrival rate is better than that of based on high task arrival rate. It is because that when the arrival rate is high, more than half of RSUs are overloaded, and the space of flow redirection is limited. Thus, the overloaded ratio of RSUs still maintains high after flow redirection. In addition, even though exhaustive method performs better than the Edmonds-Karp algorithm based scheme, it consumes more energy at the same time. In summary, the Edmonds-Karp algorithm based scheme can achieve effective and energy efficient performances.</p><p>Fig. <ref type="figure">6</ref> illustrates the performance of average energy consumption with different offloading task arrival rates for one RSU. It can be observed that energy consumption raises as the task arrival rate increases. The trends of cloudlet computing and randomized strategy raise almost linearly, while the growth rate of the proposed DMEC algorithm increases slowly. When the task arrival rate increases from 100 to 400 per time slot, the energy consumption reduction ratio of the DMEC compared with cloudlet computing decreases from 43 percent to 33 percent, respectively. In addition, the reduction ratio decreases quickly with the increasing of the task arrival rate. The reasons are as follows: When the task arrival rate is relatively low (e.g., 100 or 200 per time slot), fog nodes (i.e., both parked and moving vehicles) can fulfill task loading as arrival rate increases. Since fog nodes consume less energy than cloudlet servers, average energy consumption grows slowly. However, when the number of increased tasks exceeds the burden of fog nodes, overloaded tasks need to be transferred to the cloudlet server for processing, increasing the growth rate of DMEC.</p><p>The results of average energy consumption based on different service rates of parked vehicles are shown in Fig. <ref type="figure">7</ref>. When the service rate of parked vehicles increases, the processing capability of parked vehicles becomes powerful. As a result, there is a steady decline on average energy consumption with the increasing of the service rate. Since cloudlet is irrelevant to parked vehicles, the performance of cloudlet computing remains constant. The performance of  DMEC is about 33 percent better than that of Q-learning. This is because Q-learning always chooses system actions in a greedy manner. On the contrary, DMEC applies trial-and-error search to balance exploration and exploitation. In addition, DMEC can learn from tagged historical data, increasing the accuracy of DQN.</p><p>Fig. <ref type="figure" target="#fig_6">8</ref> elaborates the performance of average energy consumption varying with average number of parked vehicles. The number of parked vehicles at each RSU is randomly generated by the uniform distribution centered on the average number, and average energy consumption is calculated as the performance indicator. Through comparison, we can observe that average energy consumption drops gradually with the increasing number of parked vehicles. This is because more parked vehicles share the burden of cloudlet servers with a relatively small amount of energy consumption, reducing the total energy consumption of the system. Especially, when computing resources of fog nodes are insufficient (e.g., the average number of parked vehicles is from 100 to 125), the average energy consumption decreases sharply. However, when the number of parked vehicles is relatively sufficient, this effect is not such obvious.</p><p>The performance of average energy consumption with different sizes of offloading tasks is illustrated in Fig. <ref type="figure" target="#fig_7">9</ref>. The increasing of offloading data size mainly influences the energy consumption from transferring among RSUs and processing servers. Since fog nodes locate in the proximity of RSUs, the performance of cloudlet computing raises faster than that of the proposed DMEC, which consumes less time to transfer offloading data to fog nodes. The larger the amount of data is, the more obvious the energy consumption can be reduced. However, when the offloading task is beyond the computation capability of vehicles (e.g., 80MB), the consumed energy of the DMEC algorithm increases quickly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>This paper investigates energy efficient task offloading with DRL. We focus on a three-layer network model, where both parked vehicles and moving vehicles are leveraged as fog nodes based on queuing theory. By jointly considering load balance and delay constraint, we formulate the optimization problem to minimize energy consumption during traffic offloading. Due to its computation complexity, this problem is further divided into two stages: flow redirection and offloading decision. Edmonds-Karp and DRL based DMEC algorithms are respectively developed to solve the formulated problem. Finally, numerical results based on real-world traces of taxies in Shanghai (China) demonstrate that the Edmonds-Karp based algorithm can approach the performance gained by the exhaustive method, and decreases the energy consumption by 30 percent. For the second stage, the DMEC algorithm performs 35 and 60 percent better than Q-learning and cloudlet computing schemes, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Three-layer system model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Flow redirection from RSUs r i to r k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Map of Jingan District in Shanghai (China).</figDesc><graphic coords="10,84.49,56.07,180.00,180.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Average energy consumption of flow redirection with different offloading task arrival rates.</figDesc><graphic coords="10,347.51,56.06,179.99,149.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Overloaded ratio of RSUs with different offloading task arrival rates.</figDesc><graphic coords="10,347.51,247.47,180.00,149.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Average energy consumption with different offloading task arrival rates.</figDesc><graphic coords="11,84.49,56.07,180.00,143.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Average energy consumption with different number of parked vehicles.</figDesc><graphic coords="11,347.51,56.06,180.01,145.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Average energy consumption with different sizes of offloading tasks.</figDesc><graphic coords="11,347.51,237.06,179.99,144.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>µ c , µ p , d ri→cloudlet , λ 1 , ...λ s , l, λ vehicle</figDesc><table><row><cell>γ =</cell><cell cols="5"> 1, if the message is processed by the moving   vehicle based fog nodes,</cell><cell>(18)</cell></row><row><cell></cell><cell cols="2">  0, otherwise.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Therefore,</cell><cell>the</cell><cell></cell><cell>optimization</cell><cell cols="2">problem</cell></row><row><cell>is</cell><cell>defined</cell><cell>as:</cell><cell>if</cell><cell>network</cell><cell cols="2">parameters</cell></row><row><cell cols="7">can obtained, the optimization target is to find available λ c be (G, i i , λ p i , λ m i and b, such that the average energy consumption at</cell></row><row><cell cols="5">each time slot can be minimized, i.e.,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>min</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(17)</cell></row></table><note><p>if the message is processed by the parked vehicle based fog nodes, 0, otherwise.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 1: Pseudo-code of Edmonds-Karp algorithm based delay minimization scheme Input: Graph of RSUs G, V u , V o delay, capacity Output: f lows, minEnergyConsumption Add a super source node s and a super destination node t in G to form G ; while</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>In the training phase, a mini-batch transition is randomly sampled from replay buffer to eliminate the coupling of time series training data. For each transition, if the next state is the termination state, the immediate reward is the temporal difference target of training. Otherwise, target Q-network is Algorithm 2: Pseudo-code of DMEC. Input: system states S i (t), available action space a i (t) Output: maximum rewards R i Initialize the experience replay buffer; Initialize the evaluated Deep Q-Network with weights θ; Initialize the target Deep Q-Network with weights θ -= θ; for each episode i = 1, 2, • • • , U do Initialize observation s 1 , and pre-process sequence x 1 = ϕ(s 1 ); for t = 1, 2, • • • , T -1 do With probability ε select a random action a i,k (t) Otherwise, select a t = arg max a i,k (t) Q(x, a; θ); Execute action a i,k (t); Observe the immediate reward r t = R i (t) and the next observation s t+1 ; Process s t+1 to be the next state x t+1 = ϕ(s t+1 ); Store transition (x t , a t , r t , x t+1 ) into D;</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE I SELECTED</head><label>I</label><figDesc>GPS LOCATIONS IN JINGAN DISTRICT</figDesc><table><row><cell>Server ID</cell><cell>GPS locations</cell></row><row><cell>Cloudlet</cell><cell>31.267186, 121.467802</cell></row><row><cell>RSU 1</cell><cell>31.299528, 121.456591</cell></row><row><cell>RSU 2</cell><cell>31.241008, 121.451848</cell></row><row><cell>RSU 3</cell><cell>31.281631, 121.456447</cell></row><row><cell>RSU 4</cell><cell>31.317300, 121.450698</cell></row><row><cell>RSU 5</cell><cell>31.257432, 121.476282</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>IX. ACKNOWLEDGMENTS This work is partially supported by National Nature Science Foundation of China under Grants 61671092 and 61771120, by China Postdoctoral Science Foundation under grant 2018T110210, by Fundamental Research Funds for the Central Universities under Grant DUT19JC18 and Grant DUT18JC09, by National Funding from the FCT -Fundac ¸ão para a Ciência e a Tecnologia, through the UID/EEA/50008/2019 Project; by RNP, with resources from MCTIC, Grant No. 01250.075413/2018-04, under the Centro de Referência em Radiocomunicac ¸ões -CRR project of the Instituto Nacional de Telecomunicac ¸ões (Inatel), Brazil; and by Brazilian National Council for Research and Development (CNPq) via Grant No. 309335/2017-5.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Zhaolong Ning (M'14-SM <ref type="bibr">'18)</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Critical reasons for crashes investigated in the national motor vehicle crash causation survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Traffic Safety Facts -Crash Stats</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">State-of-the-art deep learning: Evolving machine intelligence toward tomorrow&apos;s intelligent network traffic control systems</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Fadlullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Akashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mizutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2432" to="2455" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A cooperative quality-aware service access system for social internet of vehicles</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Obaidat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2506" to="2517" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Green survivable collaborative edge computing in smart cities</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1594" to="1605" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vehicular fog computing: Enabling real-time traffic management for smart cities</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="93" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Vehicular social networks: Enabling smart mobility</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="49" to="55" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Cisco global cloud index: Forecast and methodology</title>
		<imprint>
			<date type="published" when="2016">2016-2021. 2018</date>
			<publisher>White Paper</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Social-oriented adaptive transmission in opportunistic Internet of smartphones</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Obaidat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="810" to="820" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Applications of deep reinforcement learning in communications and networking: A survey</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>IEEE Communications Surveys &amp; Tutorials</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automotive revolution and perspective towards 2030</title>
		<author>
			<persName><forename type="first">I</forename><surname>Delhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auto Tech Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="20" to="25" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The study on the effect of electric bus (non-fixed route) to energy consumption in thailand</title>
		<author>
			<persName><forename type="first">S</forename><surname>Emprecha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pattaraprakorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chutiprapat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhasaputra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cognitive internet of vehicles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fortino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Humar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="58" to="70" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the performance of cognitive Internet-of-vehicles with unlicensed user-mobility and licensed user-activity</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alsabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bajracharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="98" to="106" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Opportunistic WiFi offloading in vehicular environment: A game-theory approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1944" to="1955" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Offloading in internet of vehicles: A fog-enabled real-time traffic management system</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4568" to="4578" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Foud: Integrating fog and cloud for 5G-enabled V2G networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="8" to="13" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Incorporating intelligence in fog computing for big data analysis in smart cities</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hefferman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2140" to="2150" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Twin-timescale artificial intelligence aided mobility-aware edge caching and computing in vehicular networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hanzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Routing or computing? the paradigm shift towards intelligent computer network packet transmission based on deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Fadlullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Akashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mizutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1946" to="1960" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">User association for load balancing in vehicular networks: An online reinforcement learning approach</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2217" to="2228" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for vehicular edge computing: An intelligent offloading system</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mobility-aware edge caching and computing in vehicle networks: A deep reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Q</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">203</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Vehicular edge computing via deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04290</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Integrated networking, caching, and computing for connected vehicles: A deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="55" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Computation offloading and resource allocation in wireless cellular networks with mobile edge computing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4924" to="4938" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Delay minimization for data dissemination in large-scale VANETs with buses and taxis</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1939" to="1950" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Queueing systems volume 1: Theory</title>
		<author>
			<persName><forename type="first">L</forename><surname>Klennrock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reinforcement learning for resource provisioning in the vehicular cloud</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Salahuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning with double q-learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2016">2016</date>
			<pubPlace>Phoenix, AZ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributed optimal relay selection in wireless cooperative networks with finite-state markov channels</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2149" to="2158" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mobile edge computing-enabled internet of vehicles: Toward energy-efficient scheduling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
