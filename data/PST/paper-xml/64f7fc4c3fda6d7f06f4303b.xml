<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cognitive Architectures for Language Agents</title>
				<funder>
					<orgName type="full">Oracle Collaborative Research</orgName>
				</funder>
				<funder>
					<orgName type="full">National Defense Science and Engineering</orgName>
					<orgName type="abbreviated">NDSEG</orgName>
				</funder>
				<funder ref="#_pd4PU8r">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Harold W. Dodds</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-09-05">5 Sep 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Theodore</forename><surname>Sumers</surname></persName>
							<email>sumers@princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
							<email>shunyuy@princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
							<email>karthikn@princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cognitive Architectures for Language Agents</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-09-05">5 Sep 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2309.02427v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent efforts have incorporated large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning. However, these efforts have largely been piecemeal, lacking a systematic framework for constructing a fully-fledged language agent. To address this challenge, we draw on the rich history of agent design in symbolic artificial intelligence to develop a blueprint for a new wave of cognitive language agents. We first show that LLMs have many of the same properties as production systems, and recent efforts to improve their grounding or reasoning mirror the development of cognitive architectures built around production systems. We then propose Cognitive Architectures for Language Agents (CoALA), a conceptual framework to systematize diverse methods for LLM-based reasoning, grounding, learning, and decision making as instantiations of language agents in the framework. Finally, we use the CoALA framework to highlight gaps and propose actionable directions toward more capable language agents in the future. * Equal contribution, order decided by coin flip. Each person reserves the right to list their name first. A CoALA-based repo of recent work on language agents: https://github.com/ysymyth/awesome-language-agents.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite revolutionizing natural language processing (NLP), large language models (LLMs; <ref type="bibr" target="#b148">Vaswani et al., 2017;</ref><ref type="bibr" target="#b14">Brown et al., 2020;</ref><ref type="bibr" target="#b32">Devlin et al., 2019;</ref><ref type="bibr" target="#b14">Brown et al., 2020;</ref><ref type="bibr">OpenAI, 2023)</ref> have limited world knowledge and are not grounded to external environments. To address these shortcomings, recent methods have augmented <ref type="bibr" target="#b95">(Mialon et al., 2023)</ref> LLMs with external resources such as memory stores <ref type="bibr" target="#b45">(Guu et al., 2020)</ref> or pre-defined sequences of prompts to structure reasoning <ref type="bibr" target="#b27">(Creswell et al., 2023;</ref><ref type="bibr">Wu et al., 2022b)</ref>. Parallel work has grounded LLMs by placing them in a feedback loop with the environment, leading to an emerging field of language agents: interactive systems that use LLMs for sequential decision-making <ref type="bibr">(Yang et al., 2023b;</ref><ref type="bibr">Wang et al., 2023b)</ref>. While the earliest agents used the LLM to directly select actions <ref type="bibr" target="#b1">(Ahn et al., 2022;</ref><ref type="bibr">Huang et al., 2022b)</ref>, the latest generation uses a series of LLM calls to reason <ref type="bibr">(Yao et al., 2022b)</ref> or read and write from internal memory <ref type="bibr" target="#b118">(Park et al., 2023)</ref> to improve decision making. Leveraging complex internal processes, this latest generation of cognitive language agents are growing remarkably sophisticated <ref type="bibr">(Wang et al., 2023a</ref>), yet we lack a conceptual framework to characterize or design them.</p><p>We introduce such a framework, drawing parallels with two ideas from the history of computing and artificial intelligence (AI): production systems and cognitive architectures. Production systems generate a set of outcomes by iteratively applying rules <ref type="bibr" target="#b104">(Newell and Simon, 1972)</ref>. They originated as string manipulation systems -an analog of the problem that LLMs solve -and were subsequently adopted by the AI community to define systems capable of complex, hierarchically structured behaviors <ref type="bibr" target="#b105">(Newell et al., 1989)</ref>. To do so, they were incorporated into cognitive architectures that specified control flow for selecting, applying, and even generating new productions <ref type="bibr" target="#b74">(Laird et al., 1987;</ref><ref type="bibr" target="#b72">Laird, 2022;</ref><ref type="bibr" target="#b70">Kotseruba and Tsotsos, 2020)</ref>.</p><p>We suggest a meaningful analogy between production systems and LLMs: just as productions indicate possible ways to modify strings, LLMs define a distribution over changes or additions to text. This suggests that the kinds of controls used with production systems might be equally applicable to LLMs, addressing aspects including memory, grounding, learning, and decision making, among others.</p><p>Figure <ref type="figure">1</ref>: Different uses of large language models (LLMs). A: By default, an LLM takes text as input and outputs text. B: Language agents <ref type="bibr" target="#b1">(Ahn et al., 2022;</ref><ref type="bibr">Huang et al., 2022c)</ref> place the LLM in a direct feedback loop with the external environment by transforming observations into text and interpreting outputs as choosing actions. C: Cognitive language agents <ref type="bibr">(Yao et al., 2022b;</ref><ref type="bibr" target="#b134">Shinn et al., 2023;</ref><ref type="bibr">Wang et al., 2023a)</ref> additionally use the LLM to manage the agent's internal state via processes such as learning and reasoning. In this work, we propose a blueprint to structure such agents.</p><p>The plan for the rest of the paper is as follows. First, we introduce production systems and cognitive architectures in more detail. We then outline how language models are analogous to production systems, and use this connection to reconstrue prompting strategies as forms of control flow. We then introduce Cognitive Architecture for Language Agents (CoALA), applying ideas from cognitive architectures to organize existing language agents. We highlight some of the opportunities this presents for designing new cognitive language agents, and close by considering the implications of this approach for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: From Strings to Symbolic AGI</head><p>We first introduce production systems and cognitive architectures, providing a historical perspective on cognitive science and artificial intelligence: beginning with theories of logic and computation <ref type="bibr" target="#b120">(Post, 1943)</ref>, and ending with attempts to build symbolic artificial general intelligence <ref type="bibr" target="#b105">(Newell et al., 1989)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Production systems for string manipulation</head><p>Production systems provide a basis for symbol manipulation. Intuitively, production systems consist of a set of rules, each specifying a precondition and an action. When the precondition is met, the action can be taken. The idea originates in efforts to characterize the limits of computation. Emil Post <ref type="bibr" target="#b120">(Post, 1943)</ref> proposed thinking about arbitrary logical systems in these terms, where formulas are expressed as strings and the conclusions they license are identified by production rules (as one string "produces" another). This formulation was subsequently shown to be equivalent to a simpler string rewriting system. In such as system, we specify rules of the form X Y Z ? X W Z indicating that the string XY Z can be rewritten to the string XW Z. String rewriting plays a significant role in the theory of formal languages, corresponding to Chomsky's phrase structure grammar <ref type="bibr" target="#b23">(Chomsky, 1956)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Control flow: From strings to algorithms</head><p>By itself, a production system simply characterizes the set of strings that can be generated from a starting point. However, they can be used to specify algorithms if we impose control flow to determine which productions are executed. For example, Markov algorithms are production systems with a priority ordering <ref type="bibr" target="#b92">(Markov, 1954)</ref>. The following algorithm implements division-with-remainder by converting a number written as strokes | into the form Q * R, where Q is the quotient of division by 5 and R is the remainder:</p><formula xml:id="formula_0">* ||||| ? | * * ? -? * ? *</formula><p>where the priority order runs from top to bottom, productions are applied to the first substring matching their preconditions when moving from left to right (including the empty substring, in the last production), and Production systems with control flow were popularized in the AI community by Allen Newell, who was looking for a formalism to capture human problem solving <ref type="bibr" target="#b101">(Newell, 1967;</ref><ref type="bibr" target="#b104">Newell and Simon, 1972)</ref>. Productions were generalized beyond string rewriting to logical operations: preconditions that could be checked against the agent's goals and world state, and actions that should be taken if the preconditions were satisfied. In their landmark book Human Problem Solving <ref type="bibr" target="#b104">(Newell and Simon, 1972)</ref>, Allen Newell and Herbert Simon gave the example of a simple production system to describe the operation of a thermostat: Equipped with logical expressions that capture the internal state of the system, such production systems could be used to express classic search algorithms as well as more complex strategies that people use to solve challenging reasoning problems.</p><formula xml:id="formula_1">(temperature &gt; 70 ? ) ? (temperature &lt; 72 ? ) ? stop temperature &lt; 32 ? ? call</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cognitive architectures: From algorithms to agents</head><p>The success of production systems as cognitive models was paralleled by their increasing use in AI. Large production systems connected to external sensors, actuators, and knowledge bases required correspondingly sophisticated control flow. AI researchers defined "cognitive architectures" that mimicked human cognitionexplicitly instantiating processes such as perception, memory, and planning <ref type="bibr" target="#b0">(Adams et al., 2012)</ref> to achieve flexible, rational, real-time behaviors <ref type="bibr" target="#b140">(Sun, 2004;</ref><ref type="bibr" target="#b102">Newell, 1980;</ref><ref type="bibr" target="#b103">1992;</ref><ref type="bibr" target="#b3">Anderson and Lebiere, 2003)</ref>. This led to applications from psychological modeling to robotics, with hundreds of architectures and thousands of publications (see <ref type="bibr" target="#b70">Kotseruba and Tsotsos (2020)</ref> for a recent survey).</p><p>A canonical example is the Soar architecture (Fig. <ref type="figure" target="#fig_2">2A</ref>). Soar stores productions in long-term memory and executes them based on how well their preconditions match working memory (Fig. <ref type="figure" target="#fig_2">2B</ref>). These productions specify actions that modify the contents of working and long-term memory. We next provide a brief overview of Soar and refer readers to <ref type="bibr" target="#b72">Laird (2022;</ref><ref type="bibr" target="#b71">2019)</ref> for deeper introductions.</p><p>Memory. Building on psychological theories, Soar uses several types of memory to track the agent's state <ref type="bibr" target="#b4">(Atkinson and Shiffrin, 1968)</ref>. Working memory <ref type="bibr" target="#b5">(Baddeley and Hitch, 1974)</ref> reflects the agent's current circumstances: it stores the agent's recent perceptual input, goals, and results from intermediate, internal reasoning. Long term memory is divided into three distinct types. Procedural memory stores the production system itself: the set of rules that can be applied to working memory to determine the agent's behavior. Semantic memory stores facts about the world <ref type="bibr" target="#b85">(Lindes and Laird, 2016)</ref>, while episodic memory stores sequences of the agent's past behaviors <ref type="bibr" target="#b113">(Nuxoll and Laird, 2007)</ref>. Grounding. Soar can be instantiated in simulations <ref type="bibr" target="#b143">(Tambe et al., 1995;</ref><ref type="bibr" target="#b63">Jones et al., 1999)</ref> or real-world robotic systems <ref type="bibr" target="#b75">(Laird et al., 2012)</ref>. In embodied contexts, a variety of sensors stream perceptual input into working memory, where it is available for decision making. Soar agents can also be equipped with actuators, allowing for physical actions and interactive learning via language <ref type="bibr" target="#b97">(Mohan et al., 2012;</ref><ref type="bibr" target="#b96">Mohan and Laird, 2014;</ref><ref type="bibr" target="#b66">Kirk and Laird, 2014)</ref>.</p><p>Decision making. Soar implements a decision loop that evaluates productions and applies the one that matches best (Fig. <ref type="figure" target="#fig_2">2B</ref>). Productions are stored in long-term procedural memory. During each decision cycle, their preconditions are checked against the agent's working memory. In the proposal and evaluation phase, a set of productions is used to generate and rank a candidate set of possible actions.<ref type="foot" target="#foot_0">1</ref> The best action is then chosen.<ref type="foot" target="#foot_1">2</ref> Another set of productions is then used to implement the action -for example, modifying the contents of working memory or issuing a motor command.</p><p>Learning. Soar supports multiple modes of learning. First, new information can be stored directly in long-term memory: facts can be written to semantic memory, while experiences can be written to episodic memory <ref type="bibr" target="#b31">(Derbinsky et al., 2012)</ref>. This information can later be retrieved back into working memory when needed for decision-making. Second, behaviors can be modified. Reinforcement learning <ref type="bibr" target="#b141">(Sutton and Barto, 2018)</ref> can be used to up-weight productions that have yielded good outcomes, allowing the agent to learn from experience <ref type="bibr" target="#b100">(Nason and Laird, 2005)</ref>. Most remarkably, Soar is also capable of writing new productions into its procedural memory <ref type="bibr" target="#b73">(Laird et al., 1986)</ref> -effectively updating its source code.</p><p>Cognitive architectures were used broadly across psychology and computer science, with applications including robotics <ref type="bibr" target="#b75">(Laird et al., 2012)</ref>, military simulations <ref type="bibr" target="#b63">(Jones et al., 1999;</ref><ref type="bibr" target="#b143">Tambe et al., 1995)</ref>, and intelligent tutoring <ref type="bibr" target="#b68">(Koedinger et al., 1997</ref>). Yet they have become less popular in the AI community over the last few decades. This decrease in popularity reflects two of the challenges involved in such systems: they are limited to domains that can be described by logical predicates and require many pre-specified rules to function.</p><p>Intriguingly, LLMs appear well-posed to meet these challenges. First, they operate over arbitrary text, making them more flexible than logic-based systems. Second, rather than requiring the user to specify deterministic productions, they learn a distribution over productions via pre-training on a vast internet corpus. Recognizing this, researchers have begun to use LLMs within cognitive architectures -most typically leveraging their implicit world knowledge <ref type="bibr" target="#b159">(Wray et al., 2021)</ref> to augment traditional symbolic approaches <ref type="bibr" target="#b67">(Kirk et al., 2023;</ref><ref type="bibr" target="#b126">Romero et al., 2023)</ref>. Here, instead, we import principles from cognitive architecture to guide the design of LLM-based agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Language models and agents</head><p>Language modeling is a decades-old endeavor in the NLP and AI communities to develop systems that can generate text given some context <ref type="bibr" target="#b64">(Jurafsky, 2000)</ref>. Formally, language models learn a distribution P (w i |w &lt;i ), where each w is an individual token (word). This model can then generate text by sampling from the distribution, one token at a time. At its core, a language model is a probabilistic input-output system, since there are inherently several ways to continue a text (e.g., "I went to the" ? "market" | "beach" | ...). While earlier attempts at modeling language (e.g., n-grams) faced challenges in generalization and scaling, there has been a recent resurgence of the area due to the rise of Transformer-based <ref type="bibr" target="#b148">(Vaswani et al., 2017)</ref> LLMs with a large number (billions) of parameters (e.g., <ref type="bibr">GPT-4 (OpenAI, 2023)</ref>) and smart tokenization schemes. Modern LLMs are trained to predict the next token on enormous amounts of data, which helps them accumulate knowledge from a large number of input-output combinations and successfully generate human-like text.</p><p>Unexpectedly, training these models on internet-scale text also made them useful for many tasks beyond generating text, such as writing code <ref type="bibr" target="#b79">(Li et al., 2022;</ref><ref type="bibr" target="#b127">Rozi?re et al., 2023;</ref><ref type="bibr" target="#b78">Li et al., 2023)</ref>, modeling proteins <ref type="bibr" target="#b94">(Meier et al., 2021)</ref>, and acting in interactive environments <ref type="bibr">(Yao et al., 2022b;</ref><ref type="bibr" target="#b98">Nakano et al., 2021)</ref>. The latter has led to the rise of "language agents" -systems that use LLMs as a core computation unit to reason, plan, and act -with applications in areas such as robotics <ref type="bibr" target="#b1">(Ahn et al., 2022)</ref>, web manipulation <ref type="bibr">(Yao et al., 2022a;</ref><ref type="bibr" target="#b30">Deng et al., 2023)</ref>, puzzle solving <ref type="bibr">(Yao et al., 2023;</ref><ref type="bibr" target="#b47">Hao et al., 2023)</ref> and interactive code generation <ref type="bibr">(Yang et al., 2023a)</ref>. The combination of language understanding and decision making capabilities is an exciting and emerging direction that promises to bring these agents closer to human-like intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Connections between Language Models and Production Systems</head><p>Based on their common origins in processing strings, there is a natural analogy between production systems and language models. We first develop this analogy. We then review prompting methods, showing that these efforts recapitulate the algorithms and agents based on production systems -and suggesting that cognitive architectures like those developed for production systems may be usefully applied to LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Language models as probabilistic production systems</head><p>In their original instantiation, production systems specified the set of strings that could be generated from a starting point, breaking this process down into a series of string rewriting operations. Language models also define a possible set of expansions or modifications of a string -the prompt provided to the model. <ref type="foot" target="#foot_2">3</ref>For example, we can formulate the problem of completing a piece of text as a production. If X is the prompt and Y the continuation, then we can write this as the production X ? X Y . <ref type="foot" target="#foot_3">4</ref> We might want to allow multiple possible continuations, in which case we have X ? X Y i for some set of Y i . LLMs assign a probability to each of these completions. Viewed from this perspective, the LLM defines a probability distribution over which productions to select when presented with input X, yielding a distribution P (Y i |X) over possible completions <ref type="bibr" target="#b33">(Dohan et al., 2022)</ref>. LLMs can thus be viewed as probabilistic production systems that sample a possible completion each time they are called, e.g., X ??? X Y .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompting Method Production</head><formula xml:id="formula_2">Sequence Zero-shot Q ????? LLM Q A Few-shot (Brown et al., 2020) Q -? Q 1 A 1 Q 2 A 2 Q ????? LLM Q 1 A 1 Q 2 A 2 Q A Zero-shot Chain-of-Thought (Kojima et al., 2022) Q -? Q Step-by-step ????? LLM Q Step-by-step A Retrieval Augmented Generation (Lewis et al., 2020) Q Wiki ---? Q O ????? LLM Q O A Socratic Models (Zeng et al., 2022) Q ????? VLM Q O ????? LLM Q O A Self-Critique (Saunders et al., 2022) Q ????? LLM Q A ????? LLM Q A C ????? LLM Q A C A</formula><p>Table <ref type="table">1</ref>: Conceptual diagram illustrating how prompting methods manipulate the input string before generating completions. Q = question, A = answer, O = observation, C = critique, and ???? denotes sampling from a stochastic production. These pre-processing manipulations -which can employ other models such as vision-language models (VLMs), or even the LLM itself -can be seen as productions. Prompting methods thus define a sequence of productions.</p><p>This probabilistic form offers both advantages and disadvantages compared to traditional production systems. The primary disadvantage of LLMs is their inherent opaqueness: while production systems are defined by discrete and human-legible rules, LLMs consist of billions of uninterpretable parameters. This opaquenesscoupled with inherent randomness from their probabilistic formulation -makes it challenging to analyze or systematically control their behaviors <ref type="bibr" target="#b126">(Romero et al., 2023)</ref>. Nonetheless, their scale and pre-training provide massive advantages over traditional production systems. LLMs pre-trained on large-scale internet data learn a remarkably effective prior over string completions, allowing them to solve a wide range of tasks out of the box <ref type="bibr">(Huang et al., 2022b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Prompt engineering as control flow</head><p>The weights of an LLM define a prioritization over output strings (completions), conditioned by the input string (the prompt). The resulting distribution can be interpreted as a task-specific prioritization of productionsin other words, a simple control flow. Tasks such as question answering can be formulated directly as an input string (the question), yielding conditional distributions over completions (possible answers).</p><p>Early work on few-shot learning <ref type="bibr" target="#b14">(Brown et al., 2020)</ref> and prompt engineering <ref type="bibr">(Wei et al., 2022b;</ref><ref type="bibr" target="#b69">Kojima et al., 2022;</ref><ref type="bibr">Xu et al., 2023c)</ref> found that the LLM could be further biased towards high-quality productions by pre-processing the input string. These simple manipulations -typically concatenating additional text to the input -can themselves be seen as productions, meaning that these methods define a sequence of productions (Table <ref type="table">1</ref>). Later work extended these approaches to dynamic, context-sensitive prompts: for example, selecting few-shot examples that are maximally relevant to the input <ref type="bibr" target="#b87">(Liu et al., 2021)</ref> or populating a template with external observations from video <ref type="bibr" target="#b175">(Zeng et al., 2022)</ref> or databases <ref type="bibr" target="#b77">(Lewis et al., 2020)</ref>. For a survey of such prompting techniques, see <ref type="bibr">Liu et al. (2023b)</ref>.</p><p>Subsequent work used the LLM itself as a pre-processing step, eliciting targeted reasoning to foreground a particular aspect of the problem <ref type="bibr" target="#b6">(Bai et al., 2022;</ref><ref type="bibr">Jin et al., 2022;</ref><ref type="bibr" target="#b39">Ganguli et al., 2023;</ref><ref type="bibr" target="#b91">Madaan et al., 2023;</ref><ref type="bibr" target="#b131">Saunders et al., 2022;</ref><ref type="bibr" target="#b65">Kim et al., 2023;</ref><ref type="bibr" target="#b67">Kirk et al., 2023)</ref> or generate intermediate reasoning steps <ref type="bibr" target="#b142">(Tafjord et al., 2021;</ref><ref type="bibr" target="#b27">Creswell et al., 2023;</ref><ref type="bibr">Yao et al., 2023)</ref> before returning an answer. Chaining multiple calls to an LLM <ref type="bibr">(Wu et al., 2022a;</ref><ref type="bibr">b;</ref><ref type="bibr" target="#b33">Dohan et al., 2022)</ref> allows for increasingly complicated algorithms (Fig. <ref type="figure">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Towards cognitive language agents</head><p>Language agents move beyond pre-defined prompt chains and instead place the LLM in a feedback loop with the external environment (Fig. <ref type="figure">1B</ref>). These approaches first transform multimodal input into text and pass it  <ref type="table">Figure 3</ref>: From language models to language agents. A: Basic structure of an LLM call. Prompt construction selects a template and populates it with variables from working memory. After calling the LLM, the string output is parsed into an action space and executed. An LLM call may result in one or more actions -for example, returning an answer, calling a function, or issuing motor commands. B: Prompt chaining techniques such as Self-Critique <ref type="bibr">(Wang et al., 2022b)</ref> or Selection-Inference <ref type="bibr" target="#b27">(Creswell et al., 2023)</ref> use a pre-defined sequence of LLM calls to generate an output. C: Language agents such as Inner Monologue <ref type="bibr">(Huang et al., 2022c)</ref> and ReAct <ref type="bibr">(Yao et al., 2022b)</ref> instead use an interactive feedback loop with the external environment. Vision-language models (VLMs) can be used to translate perceptual data into text for the LLM to process.</p><p>to the LLM. The LLM's output is then parsed and used to determine an external action (Fig. <ref type="figure">3C</ref>). Early agents interfaced the LLM directly with the external environment, using it to produce high-level instructions based on the agent's state <ref type="bibr" target="#b1">(Ahn et al., 2022;</ref><ref type="bibr">Huang et al., 2022c;</ref><ref type="bibr" target="#b29">Dasgupta et al., 2022)</ref>. Later work developed more sophisticated language agents that use the LLM to perform intermediate reasoning before selecting an action <ref type="bibr">(Yao et al., 2022b)</ref>. The most recent agents incorporate sophisticated learning strategies such as reflecting on episodic memory to generate new semantic inferences <ref type="bibr" target="#b134">(Shinn et al., 2023)</ref> or modifying their program code to generate procedural knowledge <ref type="bibr">(Wang et al., 2023a)</ref>, using their previous experience to adapt their future behaviors.</p><p>These cognitive language agents employ nontrivial LLM-based reasoning and learning (Fig. <ref type="figure">1C</ref>). Just as cognitive architectures were used to structure production systems' interactions with agents' internal state and external environments, we suggest that they can help design LLM-based cognitive agents. In the remainder of the paper, we use this perspective to organize existing approaches and highlight promising extensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Cognitive Architectures for Language Agents (CoALA): A Conceptual Framework</head><p>We present Cognitive Architectures for Language Agents (CoALA) as a framework to organize existing language agents and guide the development of new ones. CoALA positions the LLM as the core component of a larger cognitive architecture (Figure <ref type="figure" target="#fig_3">4</ref>). The agent's internal memory is organized into discrete modules (Section 4.1), and its action space is divided into external and internal actions (Figure <ref type="figure" target="#fig_4">5</ref>):</p><p>? External actions interact with external environments (e.g., control a robot, communicate with a human, navigate a website) through grounding (Section 4.2).</p><p>? Internal actions interact with internal memories. Depending on which memory gets accessed and whether the access is read or write, internal actions can be further decomposed into three kinds: reasoning (update the short-term working memory with LLM; Section 4.4), retrieval (read from long-term memory; Section 4.3), and learning (write to long-term memory; Section 4.5).  Language agents choose actions via decision making, which follows a repeated cycle (Section 4.6, Figure <ref type="figure" target="#fig_3">4B</ref>).</p><p>In each cycle, the agent can use reasoning and retrieval actions to plan. This planning subprocess selects a grounding or learning action, which is executed to affect the outside world or the agent's long-term memory.</p><p>CoALA (Figure <ref type="figure" target="#fig_3">4</ref>) is inspired by the decades of research in cognitive architectures (Section 2.3), leveraging key concepts such as memory, grounding, learning, and decision making. Yet the incorporation of an LLM leads to the addition of "reasoning" actions, which can flexibly produce new knowledge and heuristics for various purposes -replacing hand-written rules in traditional cognitive architectures. It also makes the text the de facto internal representation, streamlining agents' memory modules. Finally, recent advances in vision-language models (VLMs; <ref type="bibr" target="#b2">Alayrac et al., 2022)</ref> can simplify grounding by providing a straightforward translation of perceptual data into text <ref type="bibr" target="#b175">(Zeng et al., 2022)</ref>.</p><p>The rest of this section details key concepts in CoALA: memory, actions (grounding, reasoning, retrieval, and learning), and decision making. For each concept, we use existing language agents (or relevant NLP/RL methods) as examples -or note gaps in the literature to highlight possibilities that remain unexplored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Memory</head><p>Language models are stateless: they do not persist information across calls. In contrast, language agents may store and maintain information internally for multi-step interaction with the world. Under the CoALA framework, language agents explicitly organize information into multiple memory modules, each containing a different form of information. These include short-term working memory and several long-term memories: episodic, semantic, and procedural.</p><p>Working memory. Working memory maintains active and readily available information as symbolic variables for the current decision cycle (Section 4.6). This includes perceptual inputs from grounding, knowledge generated by reasoning, knowledge retrieved from long-term memory, and other core information carried over from the previous decision cycle (e.g., the task instruction). Importantly, the working memory (a data structure) should not be confused with the LLM context (a string). Rather, the LLM input is synthesized from a subset of working memory (e.g., a prompt template and relevant variables). The LLM output is then parsed back into other variables (e.g., an action name and arguments) which are stored back in working memory and used to execute the corresponding action (Figure <ref type="figure">3A</ref>). Besides the LLM, the working memory also interacts with long-term memories and grounding interfaces. It thus serves as the central hub connecting different components of a language agent. Episodic memory. Episodic memory stores experience from earlier decision cycles. This can consist of training input-output pairs <ref type="bibr" target="#b128">(Rubin et al., 2021)</ref>, history event flows <ref type="bibr" target="#b157">(Weston et al., 2014;</ref><ref type="bibr" target="#b118">Park et al., 2023)</ref>, game trajectories from previous episodes <ref type="bibr" target="#b170">(Yao et al., 2020;</ref><ref type="bibr" target="#b147">Tuyls et al., 2022)</ref>, or other representations of the agent's experiences. During the planning stage of a decision cycle, these episodes may be retrieved into working memory to support reasoning. An agent can also write new experiences from working to episodic memory as a form of learning (Section 4.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grounding</head><p>Semantic memory. Semantic memory stores an agent's knowledge about the world and itself. Traditional NLP or RL approaches that leverage retrieval for reasoning or decision making initialize semantic memory from an external database for knowledge support. For example, retrieval-augmented methods in NLP <ref type="bibr" target="#b77">(Lewis et al., 2020;</ref><ref type="bibr" target="#b9">Borgeaud et al., 2022;</ref><ref type="bibr" target="#b19">Chen et al., 2017)</ref> can be viewed as retrieving from a semantic memory of unstructured text (e.g., Wikipedia). In RL, "reading to learn" approaches <ref type="bibr" target="#b10">(Branavan et al., 2012;</ref><ref type="bibr" target="#b99">Narasimhan et al., 2018;</ref><ref type="bibr" target="#b177">Hanjie et al., 2021;</ref><ref type="bibr" target="#b177">Zhong et al., 2021)</ref> leverage game manuals and facts as a semantic memory to affect the policy. While these examples essentially employ a fixed, read-only semantic memory, language agents may also write new knowledge obtained from LLM reasoning into semantic memory as a form of learning (Section 4.5) to incrementally build up world knowledge from experience.</p><p>Procedural memory. Language agents contain two forms of procedural memory: implicit knowledge stored in the LLM weights, and explicit knowledge written in the agent's code. The agent's code can be further divided into two types: procedures that implement actions (reasoning, retrieval, grounding, and learning procedures), and procedures that implement decision making itself (Section 4.6). During a decision cycle, the LLM can be accessed via reasoning actions, and various code-based procedures can be retrieved and executed. Unlike episodic or semantic memory that may be initially empty or even absent, procedural memory must be initialized by the designer with proper code to bootstrap the agent. Finally, while learning new actions by writing to procedural memory is possible (Section 4.5), it is significantly riskier than writing to episodic or semantic memory, as it can easily introduce bugs or allow an agent to subvert its designers' intentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Grounding actions</head><p>Grounding procedures execute external actions and process environmental feedback into working memory as text. This effectively simplifies the agent's interaction with the outside world as a "text game" with textual observations and actions. We categorize three kinds of external environments: Physical environments. Physical embodiment is the oldest instantiation envisioned for AI agents <ref type="bibr" target="#b111">(Nilsson, 1984)</ref>. It involves processing perceptual inputs (visual, audio, tactile) into textual observations (e.g., via pre-trained captioning models), and affecting the physical environments via robotic planners that take language-based commands. Recent advances in LLMs have led to numerous robotic projects <ref type="bibr" target="#b1">(Ahn et al., 2022;</ref><ref type="bibr">Liang et al., 2023a;</ref><ref type="bibr" target="#b136">Singh et al., 2023;</ref><ref type="bibr" target="#b116">Palo et al., 2023;</ref><ref type="bibr" target="#b125">Ren et al., 2023)</ref> that leverage LLMs as a "brain" for robots to generate actions or plans in the physical world. For perceptual input, vision-language models are typically used to convert images to text <ref type="bibr" target="#b2">(Alayrac et al., 2022;</ref><ref type="bibr" target="#b138">Sumers et al., 2023)</ref> providing additional context for the LLM <ref type="bibr" target="#b34">(Driess et al., 2023;</ref><ref type="bibr" target="#b53">Huang et al., 2023;</ref><ref type="bibr" target="#b12">Brohan et al., 2022;</ref><ref type="bibr" target="#b156">2023)</ref>.</p><p>Dialogue with humans or other agents. Classic linguistic interactions allow the agent to accept instructions <ref type="bibr" target="#b158">(Winograd, 1972;</ref><ref type="bibr" target="#b146">Tellex et al., 2011)</ref> or learn from people <ref type="bibr" target="#b107">(Nguyen et al., 2021;</ref><ref type="bibr" target="#b137">Sumers et al., 2022;</ref><ref type="bibr">2021)</ref>. Agents capable of generating language ask for help <ref type="bibr" target="#b125">(Ren et al., 2023;</ref><ref type="bibr">Nguyen et al., 2022b)</ref> or clarification <ref type="bibr" target="#b7">(Biyik and Palan, 2019;</ref><ref type="bibr" target="#b130">Sadigh et al., 2017)</ref> -or entertain or emotionally help people <ref type="bibr" target="#b176">(Zhang et al., 2020;</ref><ref type="bibr" target="#b178">Zhou et al., 2018;</ref><ref type="bibr" target="#b119">Pataranutaporn et al., 2021;</ref><ref type="bibr" target="#b48">Hasan et al., 2023;</ref><ref type="bibr" target="#b90">Ma et al., 2023)</ref>. Recent work also investigates interaction among multiple language agents for social simulation <ref type="bibr" target="#b118">(Park et al., 2023;</ref><ref type="bibr" target="#b62">Jinxin et al., 2023;</ref><ref type="bibr" target="#b40">Gao et al., 2023)</ref>, debate <ref type="bibr" target="#b17">(Chan et al., 2023;</ref><ref type="bibr">Liang et al., 2023b;</ref><ref type="bibr" target="#b35">Du et al., 2023)</ref>, improved safety <ref type="bibr" target="#b57">(Irving et al., 2018)</ref>, or collabrative task solving <ref type="bibr" target="#b122">(Qian et al., 2023;</ref><ref type="bibr" target="#b160">Wu et al., 2023;</ref><ref type="bibr" target="#b51">Hong et al., 2023)</ref>.</p><p>Digital environments. This includes interacting with games <ref type="bibr" target="#b50">(Hausknecht et al., 2020;</ref><ref type="bibr" target="#b26">C?t? et al., 2019;</ref><ref type="bibr" target="#b135">Shridhar et al., 2020;</ref><ref type="bibr">Wang et al., 2022a;</ref><ref type="bibr" target="#b89">Liu et al., 2022)</ref>, APIs <ref type="bibr" target="#b132">(Schick et al., 2023;</ref><ref type="bibr">Yao et al., 2022b;</ref><ref type="bibr" target="#b117">Parisi et al., 2022;</ref><ref type="bibr">Tang et al., 2023b)</ref>, and websites <ref type="bibr" target="#b133">(Shi et al., 2017;</ref><ref type="bibr" target="#b98">Nakano et al., 2021;</ref><ref type="bibr">Yao et al., 2022a;</ref><ref type="bibr" target="#b180">Zhou et al., 2023;</ref><ref type="bibr" target="#b44">Gur et al., 2023;</ref><ref type="bibr" target="#b30">Deng et al., 2023)</ref> as well as general code execution <ref type="bibr">(Yang et al., 2023a;</ref><ref type="bibr" target="#b76">Le et al., 2022;</ref><ref type="bibr" target="#b110">Ni et al., 2023)</ref>. Such digital grounding is cheaper and faster than physical or human interaction. It is thus a convenient testbed for language agents and has been studied with increasing intensity in recent years. In particular, for NLP tasks that require augmentation of external knowledge or computation, stateless digital APIs (e.g., search, calculator, translator) are often packaged as "tools" <ref type="bibr" target="#b117">(Parisi et al., 2022;</ref><ref type="bibr" target="#b132">Schick et al., 2023;</ref><ref type="bibr">Xu et al., 2023a;</ref><ref type="bibr">Tang et al., 2023b;</ref><ref type="bibr" target="#b123">Qin et al., 2023)</ref>, which can be viewed as special "single-use" digital environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Retrieval actions</head><p>In CoALA, a retrieval procedure reads information from long-term memories into working memory. Depending on the information and memory type, it could be implemented in various ways, e.g., rule-based, sparse, or dense retrieval. For example, Voyager <ref type="bibr">(Wang et al., 2023a)</ref> loads code-based skills from a skill library via dense retrieval to interact with the Minecraft world -effectively retrieving grounding procedures from a procedural memory. Generative Agents <ref type="bibr" target="#b118">(Park et al., 2023)</ref> retrieves relevant events from episodic memory via a combination of recency (rule-based), importance (reasoning-based), and relevance (embedding-based) scores. DocPrompting <ref type="bibr">(Zhou et al., 2022a)</ref> proposes to leverage library documents to assist code generation, which can be seen as retrieving knowledge from semantic memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Reasoning actions</head><p>Reasoning allows language agents to process the contents of working memory to generate new information. Unlike retrieval (which reads from long-term memory into working memory), reasoning reads from and writes to working memory. This allows the agent to summarize and distill insights about the most recent observation <ref type="bibr">(Yao et al., 2022b)</ref>, the most recent trajectory <ref type="bibr" target="#b134">(Shinn et al., 2023)</ref>, or information retrieved from long-term memory <ref type="bibr" target="#b118">(Park et al., 2023)</ref>. Reasoning can be used to support learning (by writing the results into long-term memory) or decision-making (by using the results as additional context for subsequent LLM calls).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Learning actions</head><p>Learning occurs by writing information to long-term memory, which includes a spectrum of diverse procedures.</p><p>Updating episodic memory with experience. It is common practice for RL agents to store episodic trajectories to update a parametric policy <ref type="bibr" target="#b8">(Blundell et al., 2016;</ref><ref type="bibr" target="#b121">Pritzel et al., 2017)</ref> or establish a nonparametric policy <ref type="bibr" target="#b36">(Ecoffet et al., 2019;</ref><ref type="bibr" target="#b147">Tuyls et al., 2022)</ref>. For language agents, added experiences in episodic memory may be retrieved later as examples and bases for reasoning or decision making <ref type="bibr" target="#b157">(Weston et al., 2014;</ref><ref type="bibr" target="#b128">Rubin et al., 2021;</ref><ref type="bibr" target="#b118">Park et al., 2023)</ref>.</p><p>Updating semantic memory with knowledge. Recent work <ref type="bibr" target="#b134">(Shinn et al., 2023;</ref><ref type="bibr" target="#b118">Park et al., 2023)</ref> has applied LLMs to reason about raw experiences and store the resulting inferences in semantic memory. For example, Reflexion <ref type="bibr" target="#b134">(Shinn et al., 2023)</ref> uses an LLM to reflect on failed episodes and stores the results (e.g., "there is no dishwasher in kitchen") as semantic knowledge to be attached to LLM context for solving later episodes. Finally, work in robotics <ref type="bibr">(Chen et al., 2023a)</ref> uses vision-language models to build a semantic map of the environment, which can later be queried to execute instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Updating LLM parameters (procedural memory).</head><p>The LLM weights represent implicit procedural knowledge. These can be adjusted to an agent's domain by fine-tuning during the agent's lifetime. Such fine-tuning can be accomplished via supervised or imitation learning <ref type="bibr" target="#b56">(Hussein et al., 2017)</ref>, reinforcement learning (RL) from environment feedback <ref type="bibr" target="#b141">(Sutton and Barto, 2018)</ref>, human feedback (RLHF) <ref type="bibr" target="#b25">(Christiano et al., 2017;</ref><ref type="bibr" target="#b115">Ouyang et al., 2022;</ref><ref type="bibr" target="#b98">Nakano et al., 2021)</ref>, or AI feedback <ref type="bibr" target="#b6">(Bai et al., 2022)</ref>. For example, XTX <ref type="bibr" target="#b147">(Tuyls et al., 2022)</ref> periodically finetunes a small language model on high-scoring trajectories stored in episodic memory, which serves as a robust "exploitation" policy to reach exploration frontiers in the face of stochasity. Recent work <ref type="bibr">(Huang et al., 2022a;</ref><ref type="bibr" target="#b174">Zelikman et al., 2022</ref>) has also shown the potential of finetuned small language models distilling then surpassing larger ones. Fine-tuning the agent's LLM is a costly form of learning; thus, present studies specify learning schedules. However, as training becomes more efficient -or if agents utilize smaller subtask-specific LLMs -it may be possible to allow language agents to autonomously determine when and how to fine-tune their LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Updating agent code (procedural memory).</head><p>CoALA allows agents to update their source code, thus modifying the implementation of various procedures. These can be broken down as follows:</p><p>? Updating reasoning (e.g., prompt templates; <ref type="bibr" target="#b41">Gao et al., 2020;</ref><ref type="bibr">Zhou et al., 2022b)</ref>. For example, APE <ref type="bibr">(Zhou et al., 2022b)</ref> infers prompt instructions from input-output examples, then uses these instructions as part of the LLM prompt to assist task solving. Such a prompt update can be seen as a form of learning to reason.</p><p>? Updating grounding (e.g., code-based skills; <ref type="bibr">Liang et al., 2023a;</ref><ref type="bibr" target="#b37">Ellis et al., 2021;</ref><ref type="bibr">Wang et al., 2023a)</ref>. For example, Voyager <ref type="bibr">(Wang et al., 2023a</ref>) maintains a curriculum library. Notably, current methods are limited to creating new code skills to interact with external environments.</p><p>? Updating retrieval. To our knowledge, these learning options are not studied in recent language agents. Retrieval is usually considered a basic action designed with some fixed implementation (e.g., BM25 or dense retrieval), but research in query/document expansion <ref type="bibr" target="#b112">(Nogueira et al., 2019;</ref><ref type="bibr">Wang et al., 2023c;</ref><ref type="bibr">Tang et al., 2023a)</ref> or retrieval distillion <ref type="bibr" target="#b58">(Izacard et al., 2021</ref>) may be helpful for language agents to learn better retrieval procedures.</p><p>? Updating learning or decision-making. Finally, it is theoretically possible for CoALA agents to learn new procedures for learning or decision making, thus providing significant adaptability.</p><p>In general, however, updates to these procedures are risky both for the agent's functionality and alignment. At present, we are not aware of any language agents that implement this form of learning; we discuss such possibilities more in Section 6.</p><p>While RL agents usually fix one way of learning (e.g., Q-learning, PPO, or A3C) and learn by updating model parameters, language agents can select from a diversity of learning procedures. This allows them to learn rapidly by storing task-relevant language (cheaper and quicker than parameter updates), and leverage multiple forms of learning to compound their self-improvement (e.g., Generative Agents discussed in Section 5).</p><p>Finally, while our discussion has mostly focused on adding to memory, modifying and deleting (a case of "unlearning") are understudied in recent language agents. We address these areas more in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Decision making</head><p>With various actions (grounding, learning, reasoning, retrieval) in the action space, how should a language agent choose which action to apply? This is handled by the decision making procedure, which structures the agent's actions into decision making cycles (or decision cycles for short). In each cycle, language agents use a systematic code-based procedure with the assistance of reasoning and retrieval actions to decide a learning or grounding action (planning stage), then execute the action (execution stage) -then the cycle loops again.</p><p>Planning stage. During planning, reasoning, and retrieval can be flexibly applied to propose, evaluate, and select actions, and these sub-stages could interleave or iterate to build up multi-step simulation before taking an external action <ref type="bibr">(Yao et al., 2023;</ref><ref type="bibr" target="#b47">Hao et al., 2023)</ref>. It also enables agents to iteratively improve candidate solutions -for example, by using the LLM to simulate them, identifying defects, and proposing modifications that address those defects <ref type="bibr" target="#b67">(Kirk et al., 2023;</ref><ref type="bibr" target="#b134">Shinn et al., 2023)</ref>.</p><p>? Proposal. The proposal sub-stage generates one or more action candidates. The usual approach is to use reasoning (and optionally retrieval) to sample one <ref type="bibr">(Huang et al., 2022c)</ref> or more <ref type="bibr" target="#b20">(Chen et al., 2021;</ref><ref type="bibr">Wang et al., 2022b)</ref> actions from the LLM. For simple domains with limited actions, the proposal stage might simply include all actions (e.g., SayCan in Section 5). It is also possible to leverage if-else or while-if code structures <ref type="bibr">(Wang et al., 2023a;</ref><ref type="bibr" target="#b118">Park et al., 2023)</ref>, or more advanced planner code packages such as Planning Domain Definition Language (PDDL; <ref type="bibr" target="#b49">Haslum et al., 2019)</ref> for more informed proposal <ref type="bibr">(Liu et al., 2023a;</ref><ref type="bibr" target="#b28">Dagan et al., 2023)</ref> in well-defined domains.</p><p>? Evaluation. If multiple actions are proposed, the evaluation sub-stage assigns a scalar value to each. This may use heuristic rules, LLM (perplexity) values <ref type="bibr" target="#b1">(Ahn et al., 2022)</ref>, learned values <ref type="bibr" target="#b170">(Yao et al., 2020)</ref>, LLM reasoning <ref type="bibr">(Yao et al., 2023;</ref><ref type="bibr" target="#b47">Hao et al., 2023)</ref>, or some combination. Particularly, LLM reasoning can help evaluate actions by internally simulating their grounding feedback from the external world <ref type="bibr" target="#b47">(Hao et al., 2023;</ref><ref type="bibr">Yang et al., 2023a</ref>).</p><p>? Selection. Given a set of actions and their values, the selection procedure selects an action by argmax, or softmax, or decides to re-iterate to some proposal or evaluate sub-stage.</p><p>Execution stage. The selected action is applied by executing the relevant procedures from the agent's source code. An observation feedback can be made from the external environment, providing feedback from the agent's action, and the cycle loops again.</p><p>Empirically, many early language agents simply use LLMs to propose an action <ref type="bibr" target="#b132">(Schick et al., 2023)</ref>, a sequence of actions <ref type="bibr">(Huang et al., 2022b)</ref>, or evaluate a fixed set of actions <ref type="bibr" target="#b1">(Ahn et al., 2022)</ref> without intermediate reasoning or retrieval. Followup work <ref type="bibr">(Yao et al., 2022b;</ref><ref type="bibr" target="#b134">Shinn et al., 2023;</ref><ref type="bibr">Xu et al., 2023b;</ref><ref type="bibr" target="#b84">Lin et al., 2023;</ref><ref type="bibr">Wang et al., 2023a;</ref><ref type="bibr" target="#b118">Park et al., 2023)</ref> has exploited intermediate reasoning and retrieval to analyze the situation, make and maintain action plans, refine the previous action given the environmental feedback, and leveraged a more complex procedure to propose a single action (still without evaluation and selection). Most recently, research has started to investigate more complex decision making by proposing more than one action, and with iterative proposal and evaluation. These procedures are beginning to resemble classical planning algorithms: for example, Tree of Thoughts <ref type="bibr">(Yao et al., 2023)</ref> leverages LLM to iteratively propose and evaluate "thoughts" in a systematic tree search (DFS/BFS) to return a final solution to a problem. RAP <ref type="bibr" target="#b47">(Hao et al., 2023)</ref> similarly generates partial thoughts and maintains them in a tree structure, using Monto Carlo Tree Search (MCTS; <ref type="bibr" target="#b15">Browne et al., 2012)</ref> and LLM-based simulation to evaluate thoughts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Case Studies</head><p>With variations and ablations of the memory modules, action space, and decision making procedures, CoALA can express a wide spectrum of language agents. Table <ref type="table">2</ref> lists some popular recent methods across diverse domains -from Minecraft to robotics, from pure reasoning to social simulacra. CoALA helps characterize their internal mechanisms and reveal their similarities and differences in a simple and structured way.</p><p>SayCan <ref type="bibr" target="#b1">(Ahn et al., 2022</ref>) grounds a language model to robotic interactions in a kitchen to satisfy user commands (e.g., "I just worked out, can you bring me a drink and a snack to recover?"). Its long-term memory is procedural only (an LLM and a learned value function). The action space is external only -a fixed set of 551 grounding skills (e.g., "find the apple", "go to the table"), with no internal actions of reasoning, retrieval, or learning. During decision making, SayCan evaluates each action using a combination of LLM and learned values, which balance a skill's usefulness and groundedness. SayCan therefore employs the LLM primarily as a stateless single-step planner.</p><p>Long-term External Internal Decision Memory<ref type="foot" target="#foot_4">5</ref> </p><p>Grounding Actions Making SayCan <ref type="bibr" target="#b1">(Ahn et al., 2022)</ref> physical -evaluate ReAct <ref type="bibr">(Yao et al., 2022b)</ref> digital reason propose Voyager <ref type="bibr">(Wang et al., 2023a)</ref> procedural digital reason/retrieve/learn propose Generative Agents <ref type="bibr" target="#b118">(Park et al., 2023)</ref> episodic/semantic digital/agent reason/retrieve/learn propose Tree of Thoughts <ref type="bibr">(Yao et al., 2023)</ref> digital<ref type="foot" target="#foot_5">6</ref> reason propose, evaluate, select</p><p>Table <ref type="table">2</ref>: Some recent language agents cast into the CoALA framework.</p><p>ReAct <ref type="bibr">(Yao et al., 2022b</ref>) is a language agent grounded to various digital environments (e.g., Wikipedia API, text game, website). Like SayCan, it lacks semantic or episodic memory and therefore has no retrieval or learning actions. Its action space consists of (internal) reasoning and (external) grounding. Its decision cycle is fixed to use a single reasoning action to analyze the situation and (re)make action plans, then generates a grounding action without evaluation or selection stages. ReAct can be considered the simplest language agent that leverages both internal and external actions, and is the initial work that demonstrates their synergizing effects: reasoning helps guide acting, while acting provides environmental feedback to support reasoning.</p><p>Voyager <ref type="bibr">(Wang et al., 2023a</ref>) is a language agent grounded to the Minicraft API. Unlike SayCan, which grounds to perception via the learned value function, Voyager's grounding is text-only. It has a long-term procedural memory that stores a library of code-based grounding procedures a.k.a. skills (e.g., "combatZombie", "craftStoneSword"). This library is hierarchical: complex skills can use simpler skills as sub-procedures (e.g., "combatZombie" may call "craftStoneSword" if no sword is in inventory). Most impressively, its action space has all four kinds of actions: grounding, reasoning, retrieval, and learning (by adding new grounding procedures). During a decision cycle, Voyager first reasons to propose a new task objective if it is missing in the working memory, then reasons to propose a code-based grounding procedure to solve the task. In the next decision cycle, if the environmental feedback is reasoned to suggest task completion, a learning action is selected to add the grounding procedure to procedural memory; otherwise, reasoning is used to reflect bugs and refine code, and a grounding action is selected to attempt task solving again. The importance of long-term memory and procedural learning is empirically verified by comparing to baselines like ReAct and AutoGPT and ablations without the procedural memory, where Voyager is shown to better explore areas, master tech tree, and zero-shot generalize to unseen tasks.</p><p>Generative Agents <ref type="bibr" target="#b118">(Park et al., 2023)</ref> is a language agent grounded to a sandbox game in which it interacts with the environment and other agents. Each agent has a long-term episodic memory that stores everyday events in a list and a long-term semantic memory that stores their periodic reflections over the episodic memory (e.g., "I like to ski now."). Its action space also has all four kinds of actions: grounding, reasoning, retrieval, and learning. Notably, it learns by adding new events to episodic memory, and new reflections to semantic memory. During decision making, it retrieves relevant reflections from semantic memory and reasons to make a high-level plan of the day, or with grounding observations, reasons to maintain or adjust the plan.</p><p>Tree of Thoughts (ToT) <ref type="bibr">(Yao et al., 2023)</ref> can be seen as a special kind of language agent with only one external action: submitting a final solution to a reasoning problem (game of 24, creative writing, crosswords puzzle). It has no long-term memory, and only reasoning in its internal action space, but differs from all previous agents in its deliberate decision making. During planning, ToT iteratively proposes, evaluates, and selects "thoughts" (reasoning actions) based on LLM reasoning, and systematically maintains them via a tree search algorithm to enable global exploration as well as local backtrack and foresight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Actionable Insights</head><p>While there have been several recent surveys related to language agents <ref type="bibr" target="#b95">(Mialon et al., 2023;</ref><ref type="bibr" target="#b156">Weng, 2023;</ref><ref type="bibr">Wang et al., 2023b)</ref>, CoALA offers a structured way of thinking about these agents grounded in the well-established research of cognitive architectures. Not every application will require all of CoALA's components, but using concepts from CoALA while designing and describing the system will aid in modularity and clarity. For example, it may be beneficial to consider whether an application requires semantic or episodic memory; whether it should be capable of modifying its semantic memory; and so on. Importantly, such a systematic way of thinking readily leads to several future directions for language agents.</p><p>Working memory and reasoning: thinking beyond LLM prompt engineering. If one only thinks of maintaining the LLM context with string manipulations and parsings, model design is likely to degenerate into low-level trivialities and "prompt engineering" tricks. Instead, the community should think about a structured working memory and systematic "reasoning" actions that update working memory variables. Recent steps in this direction include more systematic prompting frameworks such as LangChain 7 and LlamaIndex 8 , as well as more structural output parsing solutions such as Guidance 9 and OpenAI function calling 10 . Defining and building good working memory modules will be an important direction of future research. These modules could be especially important for industry solutions where LLM reasoning needs to seamlessly integrate and conform with large-scale code infrastructure.</p><p>Long-term memory: thinking beyond retrieval augmentation. Compared to retrieval-augmented language models <ref type="bibr" target="#b45">(Guu et al., 2020;</ref><ref type="bibr" target="#b77">Lewis et al., 2020;</ref><ref type="bibr" target="#b9">Borgeaud et al., 2022)</ref> that only read from human-written corpora, memory-augmented language agents can both read and write self-generated content autonomously. By organically combining existing human knowledge with self-discovered and self-maintained experience, knowledge, and skills in long-term memory, future language agents may more efficiently learn and solve tasks. For example, a future coding agent could maintain human-provided programming knowledge (semantic) such as manuals, textbooks, problems, and examples, as well as its problem solutions and test records (episodic), reflections, and summaries on top of these experiences (semantic), and a gradually expanding code library that stores useful methods, e.g., QuickSort, GCD, LCA (procedural). Similar development is also possible for solving interactive text games, book-level QA, personalized chat, or any task where agents could exploit existing human experiences and explore new ones.</p><p>Learning: thinking beyond in-context learning or finetuning. CoALA's definition of "learning" as long-term memory updates is simple yet versatile. As detailed in Section 4.5, it covers updates to episodic experience, semantic knowledge, LLM weights (finetuning), and various procedural updates that are currently understudied. For example, learning better retrieval procedures could enable agents to better connect memorized information to new scenarios, and recent expansion-based techniques <ref type="bibr" target="#b112">(Nogueira et al., 2019;</ref><ref type="bibr">Wang et al., 2023c;</ref><ref type="bibr">Tang et al., 2023a</ref>) may be readily applied (e.g., reason about "in what situations would this knowledge be useful?", and append the reasoning results to the knowledge to help later connect the knowledge to new situations). Learning new learning and decision procedures can be seen as ways of "meta-learning" and "meta-decision making" for language agents, and are currently understudied due to their difficulty and high risk (see safety discussion in the next paragraph). However, these may be necessary to empower agents to go beyond the limitations of human-provided code. Also, future directions could explore learning smaller models for specific reasoning needs <ref type="bibr" target="#b174">(Zelikman et al., 2022;</ref><ref type="bibr">Huang et al., 2022a;</ref><ref type="bibr" target="#b1">Ahn et al., 2022)</ref>, deleting unneeded memory items for "unlearning" <ref type="bibr">(Nguyen et al., 2022c)</ref>, and various ways to combine multiple forms of learning <ref type="bibr" target="#b147">(Tuyls et al., 2022;</ref><ref type="bibr" target="#b118">Park et al., 2023;</ref><ref type="bibr" target="#b163">Xie et al., 2023)</ref>.</p><p>Action space: thinking beyond external tools or actions. Although "action space" is a standard term in reinforcement learning, it is seldom used for language agents. 11 CoALA argues for defining a clear and task-suitable action space with both internal (reasoning, retrieval, learning) and external (grounding) actions, which will help systematize and inform the agent design. For example, as can be seen in Section 5, the size of the action space yields a tradeoff -a larger action space (e.g., Voyager, Generative Agents) means more agent capabilities, but also a harder decision making problem that requires more crafted decision code.</p><p>Another important future direction is agent safety through the lens of its action space: from the CoALA categorization, it is clear that "learning" actions (especially procedural deletion and modification) could cause internal harm, while "grounding" actions (e.g., "rm" in bash terminal, harmful speech in human dialog, holding a knife in physical environments) could cause external harm. Preliminary safety measures have been 7 https://www.langchain.com. 8 https://www.llamaindex.ai. 9 https://github.com/guidance-ai/guidance. 10 https://openai.com/blog/function-calling-and-other-api-updates. 11 Perhaps the only exception is ReAct <ref type="bibr">(Yao et al., 2022b)</ref>, which explicitly argues to "augment the action space with reasoning". limited to task-specific heuristics (e.g., remove "os" operations in Python <ref type="bibr" target="#b20">(Chen et al., 2021)</ref>, filter keywords in dialog <ref type="bibr" target="#b24">(Chowdhery et al., 2022;</ref><ref type="bibr" target="#b34">Driess et al., 2023)</ref>, limit physical environments to controlled setups <ref type="bibr" target="#b1">(Ahn et al., 2022)</ref>), but as agents are grounded to more complex and multi-facet environments (e.g., navigate both the Internet and city streets) with richer internal mechanisms, it will be necessary to clearly specify and ablate the agent's action space for worst-case scenario prediction and prevention <ref type="bibr">(Yao and Narasimhan, 2023)</ref>.</p><p>Decision making: thinking beyond action generation. We believe one of the most exciting future directions for language agents is decision making: as detailed in Section 4.6, most works are still confined to proposing (or directly generating) a single action. Present agents have just scratched the surface of more deliberate, propose-evaluate-select decision making procedures analogous to classical planning and tree search <ref type="bibr">(Yao et al., 2023;</ref><ref type="bibr" target="#b47">Hao et al., 2023;</ref><ref type="bibr">Liu et al., 2023a;</ref><ref type="bibr" target="#b28">Dagan et al., 2023)</ref>, using toy tasks such as game of 24 or block building. It would be powerful to extend such schemes to more complicated tasks with grounding <ref type="bibr" target="#b123">(Qin et al., 2023)</ref> and long-term memory; enable learning of decision making procedures; and reduce the cost of extensive reasoning to facilitate more deliberate planning (potentially via smaller task-specific models for proposal or evaluation, as discussed above). On the other hand, LLM development might be influenced or even shaped by the increased usage of reasoning toward complex decision making, and better support decision making by solving known issues such as over-confidence and miscalibration <ref type="bibr" target="#b59">(Jiang et al., 2021;</ref><ref type="bibr" target="#b11">Braverman et al., 2020;</ref><ref type="bibr" target="#b22">Chen et al., 2022)</ref>, misalignment with human values or bias <ref type="bibr" target="#b81">(Liang et al., 2021;</ref><ref type="bibr" target="#b38">Feng et al., 2023)</ref>, hallucinations in self-evaluation <ref type="bibr" target="#b134">(Shinn et al., 2023)</ref>, and lack of human-in-the-loop mechanisms in face of uncertainties <ref type="bibr" target="#b106">(Nguyen et al., 2022a;</ref><ref type="bibr" target="#b125">Ren et al., 2023)</ref>. In summary, more powerful and efficient LLMs will enable more deliberate language agents, and the agent-building experiences could in turn inform the improvement of base LLMs in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>In this section, we discuss some conceptual questions raised by our proposal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Internal vs. external actions: what is the boundary between an agent and its environment?</head><p>While humans or robots are clearly separated from their embodied environment, the boundary of language agents has become vaguer as a result of their digital grounding. For example, is a Wikipedia database an internal semantic memory or an external digital environment <ref type="bibr">(Yao et al., 2022b)</ref>? If an agent runs some code and improves it based on the execution feedback before submitting the final code <ref type="bibr" target="#b134">(Shinn et al., 2023;</ref><ref type="bibr">Yang et al., 2023a)</ref>, is the code execution a form of external grounding or internal simulation? If a method consists of proposal and evaluation prompts <ref type="bibr">(Yao et al., 2023)</ref>, should it be considered a single agent with deliberate decision making, or two simpler agents (proposer and evaluator) collaborating for task solving?</p><p>We suggest the boundary question can be answered in terms of controllability and indispensability. For example, Wikipedia is an external environment if constantly modified by other users, but an offline version that only the agent may write to can be considered an internal memory. If an agent explicitly stores a compiler and all needed packages to run code, it could be considered an internal reasoning action. Otherwise, running code in some external machine (that someone may hack) should be considered external grounding. Lastly, if the proposal and evaluation prompts are specifically designed for each other in a particular task, it seems more proper to package them as an indispensable whole; but if both parts are fairly capable of interacting with other agents or environments without always coupling, a multi-agent view is more fit. While these dilemmas are purely conceptual and subjective with respect to existing implementations, such conceptual understanding may be important for systematically designing more capable and complex agents in the future.</p><p>Planning vs. execution: how much should agents plan? Making a call to an LLM is both slow and computationally intensive. Relying on LLMs for decision-making thus requires balancing the cost of planning against the utility of the resulting improved plan. This has analogs to the "value of computation" studied in human metareasoning <ref type="bibr" target="#b83">(Lieder and Griffiths, 2020;</ref><ref type="bibr" target="#b16">Callaway et al., 2022;</ref><ref type="bibr" target="#b42">Gershman et al., 2015)</ref>. The present work fixes a search budget by specifying a depth of reasoning <ref type="bibr">(Yao et al., 2023)</ref>, but studies of humans suggest that they allocate computation adaptively <ref type="bibr" target="#b129">(Russek et al., 2022)</ref>. Future work should develop mechanisms to estimate the utility of planning and modify the decision procedure accordingly, i.e., learning update decision making procedures in the CoALA framework.</p><p>Learning vs. acting: how should agents continuously and autonomously learn? In the CoALA framework, learning is a result action of a decision making cycle just like grounding: the agent deliberately chooses to commit information to long-term memory. This is in contrast to most agents, which simply fix a learning schedule and only use decison making for external actions. Biological agents, however, do not have this luxury: they must balance learning against external actions in their lifetime, choosing when and what to learn <ref type="bibr" target="#b93">(Mattar and Daw, 2018)</ref>. More flexible language agents <ref type="bibr">(Wang et al., 2023a;</ref><ref type="bibr" target="#b118">Park et al., 2023)</ref> would follow a similar design and treat learning on par with external actions. Learning could be proposed as a possible action during regular decision-making, allowing the agent to "defer" it until the appropriate time.</p><p>LLMs vs. code: where should agents rely on each? CoALA agents possess two forms of procedural memory: agent code (which specifies deterministic procedures) and LLM parameters (a large, stochastic production system). Agent code is interpretable and extensible, but inherently brittle and only capable of addressing situations the designer anticipates. In contrast, the LLM's parameters are much less interpretable, but it possesses significant flexibility and is capable of generating zero-shot solutions in completely new contexts <ref type="bibr">(Huang et al., 2022b)</ref>. CoALA thus suggests that good design uses agent code primarily to implement classic, generic planning algorithms -and relies heavily on the LLM for action proposal and evaluation.</p><p>It is also important to bear a developmental perspective for LLMs, for new capabilities emerge with scaling <ref type="bibr">(Wei et al., 2022a)</ref>. For example, earlier language models such as GPT-2 <ref type="bibr" target="#b124">(Radford et al., 2019)</ref> would not enable flexible reasoning as in the CoALA framework and might need to work hand in hand with some learned value function for action proposal and evaluation respectively <ref type="bibr" target="#b170">(Yao et al., 2020)</ref>. While GPT-3 <ref type="bibr" target="#b14">(Brown et al., 2020)</ref> unlocked flexible few-shot and zero-shot reasoning for the first time, it was only until <ref type="bibr">GPT-4 (OpenAI, 2023)</ref> that language agents may more reliably self-evaluate <ref type="bibr" target="#b131">(Saunders et al., 2022;</ref><ref type="bibr" target="#b134">Shinn et al., 2023;</ref><ref type="bibr">Yao et al., 2023)</ref> or self-refine <ref type="bibr" target="#b91">(Madaan et al., 2023;</ref><ref type="bibr">Chen et al., 2023b)</ref> their reasoning. Would the future development of LLMs further reduce the need for coded rules and extra-learned models, and indicate changes to the CoALA framework? As a thought experiment, imagine GPT-N that could "simulate" memory, grounding, learning, and decision making in context: list all the possible actions, deliberately evaluate each one (even by simulating how the world will respond), while maintaining long-term memory explicitly in a very long context. Or even more boldly: can GPT-N just generate the next action by simulating these implicitly in neurons, without any intermediate reasoning in context? While these extreme cases seem unlikely for now, a longer context might downplay the importance of long-term memory and more powerful reasoning for internal evaluation and simulation might bolster planning and weaken the need for grounding feedback. LLMs may keep scaling beyond the fundamental limitations on biological beings like humans <ref type="bibr" target="#b43">(Griffiths, 2020)</ref>. CoALA, and cognitive science more generally, may still help systematically organize tasks where LLMs excel or show deficits -using humans as a gauge and target of alignment -to determine appropriate code-based procedures to complement a given LLM on a given task. Even in the most extreme case where GPT-N could accomplish all of the CoALA mechanisms in neurons, it may be helpful to leverage CoALA as a conceptual guide to discover and interpret GPT-N's implicit circuits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We proposed Cognitive Architectures for Language Agents (CoALA), a conceptual framework to systematically understand and build language agents. Our framework draws inspiration from the rich history of symbolic artificial intelligence and cognitive science and connects decades-old insights to frontier research on large language models. We believe this approach provides a path towards developing more general and human-like artificial intelligence.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>?-?</head><label></label><figDesc>indicates the algorithm halts after executing the rule. For example, given the input 11, this would yield the sequence of productions * ||||||||||| ? | * |||||| ? || * | ? -? || * | which is interpreted as 2 remainder 1. Simple productions can result in complex behavior -Markov algorithms can be shown to be Turing complete.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>for repairs; turn on electric heater (temperature &gt; 70 ? ) ? (furnace off) ? turn on furnace (temperature &gt; 72 ? ) ? (furnace on) ? turn off furnace</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Cognitive architectures augment a production system with sensory groundings, long-term memory, and a decision procedure for selecting actions. A: The Soar architecture, reproduced from Laird (2022). B: Soar's decision procedure uses productions to select and implement actions. These actions may be internal (such as modifying the agent's memory) or external (such as a motor command).</figDesc><graphic url="image-13.png" coords="4,111.97,83.78,287.83,216.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Cognitive architectures for language agents(CoALA). A: CoALA defines a set of interacting modules and processes. The decision procedure executes the agent's source code. This source code consists of procedures to interact with the LLM (prompt templates and parsers), internal memories (retrieval and learning), and the external environment (grounding). B: Temporally, the agent's decision procedure executes a decision cycle in a loop with the external environment. During each cycle, the agent uses retrieval and reasoning to plan by proposing and evaluating candidate learning or grounding actions. The best action is then selected and executed. An observation may be made, and the cycle begins again.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Agents' action spaces can be divided into internal memory accesses and external interactions with the world. Reasoning and retrieval actions are used to support planning.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In more detail, Soar divides productions into two types: "operators," which we refer to as actions, and "rules" which are used to propose, evaluate, and execute operators. Differentiating these is conceptually important for Soar but not language agents, and so we elide the distinction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>If no actions are valid, or multiple actions tie, then an impasse occurs. Soar creates a subgoal to resolve the impasse, resulting in hierarchical task decomposition. We refer the reader to<ref type="bibr" target="#b72">Laird (2022)</ref> for a more detailed discussion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>In this work, we focus on autoregressive LLMs which are typically used to construct language agents. However, bidirectional LLMs trained on the cloze task, such as BERT<ref type="bibr" target="#b32">(Devlin et al., 2019)</ref>, can be seen in a similar light: they define a distribution over in-filling productions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Alternatively, we can treat the prompt as input and take the output of the LLM as the next state, represented by the production X ? Y -a more literal form of rewriting.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>All agents contain some procedural memory (agent code and LLM weights), so here we only list writable procedural memory.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>Special digital grounding with the only external action being submitting a final answer.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>SY and KN acknowledge support from an <rs type="funder">Oracle Collaborative Research</rs> award and the <rs type="funder">National Science Foundation</rs> under Grant No. <rs type="grantNumber">2239363</rs>. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the <rs type="funder">National Science Foundation</rs>. SY is also supported by the <rs type="funder">Harold W. Dodds</rs> Fellowship from Princeton. TS is supported by the <rs type="funder">National Defense Science and Engineering (NDSEG) Graduate Fellowship Program</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_pd4PU8r">
					<idno type="grant-number">2239363</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mapping the landscape of human-level artificial general intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Arel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Furlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Goertzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Samsonovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scheutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlesinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="42" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Do as I can, not as I say: Grounding language in robotic affordances</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.01691</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Flamingo: a visual language model for few-shot learning</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Miech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="23716" to="23736" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Newell test for a theory of cognition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lebiere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="587" to="601" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Human memory: A proposed system and its control processes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Learning and Motivation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="89" to="195" />
			<date type="published" when="1968">1968</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Working memory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Baddeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Learning and Motivation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="47" to="89" />
			<date type="published" when="1974">1974</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mckinnon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08073</idno>
		<title level="m">Constitutional AI: Harmlessness from AI feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Asking easy questions: A user-friendly approach to active reward learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Biyik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Conference on Robot Learning</title>
		<meeting>the 3rd Conference on Robot Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04460</idno>
		<title level="m">Model-free episodic control</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving language models by retrieving from trillions of tokens</title>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2206" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to win by reading manuals in a Monte-Carlo framework</title>
		<author>
			<persName><forename type="first">S</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="661" to="704" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Calibration, entropy rates, and memory in language models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Braverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1089" to="1099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">RT-1: Robotics transformer for real-world control at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carbajal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.06817</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">RT-2: Vision-language-action models transfer web knowledge to robotic control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carbajal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choromanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Driess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.15818</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey of Monte Carlo tree search methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Powley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitehouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Cowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rohlfshagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tavener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samothrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Intelligence and AI in games</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rational use of cognitive resources in human planning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Opheusden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1112" to="1125" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">C.-M</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.07201</idno>
		<title level="m">Towards better llm-based evaluators through multi-agent debate</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Openvocabulary queryable scene representations for real world planning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kappler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11509" to="11522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00051</idno>
		<title level="m">Reading Wikipedia to answer open-domain questions</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P D O</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Teaching large language models to self-debug</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sch?rli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05128</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A close look into the calibration of pre-trained language models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.00151</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Three models for the description of language</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chomsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="113" to="124" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning from human preferences</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Textworld: A learning environment for text-based games</title>
		<author>
			<persName><forename type="first">M.-A</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>K?d?r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kybartas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Games: 7th Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018. 2019</date>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Selection-inference: Exploiting large language models for interpretable logical reasoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Dynamic planning with a llm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lascarides</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.06391</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Collaborating with language models for embodied reasoning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaeser-Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Babayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second Workshop on Language and Reinforcement Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06070</idno>
	</analytic>
	<monogr>
		<title level="m">Towards a generalist agent for the web</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A multi-domain evaluation of scaling in a general episodic memory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Derbinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="193" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT (1)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Saurous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.10342</idno>
		<title level="m">Language model cascades</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Driess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Vuong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03378</idno>
		<title level="m">PALM-E: An embodied multimodal language model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Improving factuality and reasoning in language models through multiagent debate</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14325</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Go-explore: a new approach for hardexploration problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ecoffet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huizinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10995</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dreamcoder: Bootstrapping inductive program synthesis with wake-sleep library learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sabl?-Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation</title>
		<meeting>the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="835" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair nlp models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsvetkov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08283</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The capacity for moral self-correction in large language models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schiefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Luko?i?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hernandez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.07459</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.14984</idno>
		<title level="m">S3: Social-network simulation system with large language model-empowered agents</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15723</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Computational rationality: A converging paradigm for intelligence in brains, minds, and machines</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">6245</biblScope>
			<biblScope unit="page" from="273" to="278" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Understanding human intelligence through human limitations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="873" to="883" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Furuta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Safdari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Faust</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.12856</idno>
		<title level="m">A real-world webagent with planning, long context understanding, and program synthesis</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Retrieval augmented language model pre-training</title>
		<author>
			<persName><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Grounding language to entities and dynamics for generalization in reinforcement learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Hanjie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14992</idno>
		<title level="m">Reasoning with language model is planning with world model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ozel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoque</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.03022</idno>
		<title level="m">Sapien: Affective virtual agents powered by large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">An introduction to the planning domain definition language</title>
		<author>
			<persName><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lipovetzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Magazzeni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Muise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Interactive fiction games: A colossal adventure</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7903" to="7910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K S</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.00352</idno>
		<title level="m">Meta programming for multi-agent collaborative framework</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Large language models can self-improve</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11610</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11176</idno>
		<title level="m">Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Language models as zero-shot planners: Extracting actionable knowledge for embodied agents</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="9118" to="9147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Inner monologue: Embodied reasoning through planning with language models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chebotar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.05608</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Imitation learning: A survey of learning methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Gaber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00899</idno>
		<title level="m">AI safety via debate</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.09118</idno>
		<title level="m">Unsupervised dense information retrieval with contrastive learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">How can we know when language models know? on the calibration of language models for question answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="962" to="977" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">When to make exceptions: Exploring language models as accounts of human moral judgment</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Adauto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>In</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belgrave</surname></persName>
		</author>
		<author>
			<persName><surname>Cho</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Jinxin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiabao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yilei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xingjiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiawen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.12503</idno>
		<title level="m">Cgmi: Configurable general multi-agent interaction framework</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Automated intelligent pilots for combat flight simulation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Coulter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Koss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="27" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Speech &amp; language processing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Pearson Education India</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Language models can solve computer tasks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcaleer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17491</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Interactive task learning for simple games</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Cognitive Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">13-30</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Improving Knowledge Extraction from LLMs for Robotic Task Learning through Agent Analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lindes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06770</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Intelligent tutoring goes to school in the big city</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Koedinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Hadley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="43" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">40 years of cognitive architectures: core cognitive abilities and practical applications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kotseruba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="94" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">The Soar cognitive architecture</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.03854</idno>
		<title level="m">Introduction to Soar</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Chunking in Soar: The anatomy of a general learning mechanism</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Rosenbloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11" to="46" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Soar: An architecture for general intelligence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Rosenbloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="64" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Cognitive robotics using the Soar cognitive architecture</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Kinkade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CogRob @ AAAI</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Coderl: Mastering code generation through pretrained models and deep reinforcement learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Gotmare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="21314" to="21328" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive NLP tasks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>-T. Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rockt?schel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9459" to="9474" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kocetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davaadorj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lamy-Poirier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shliazhko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gontier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Meade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zebaze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lipkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oblokulov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stillerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Abulkhanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zocca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fahmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kunakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhdanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Timor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Contractor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ferrandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Werra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>De Vries</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Starcoder: may the source be with you! ArXiv, abs/2305.06161</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Competition-level code generation with alphacode</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><surname>Gowal</surname></persName>
		</author>
		<author>
			<persName><surname>Alexey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cherepanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Molloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Mankowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Robson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="page" from="1092" to="1097" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Code as policies: Language model programs for embodied control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="9493" to="9500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Towards understanding and mitigating social biases in language models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6565" to="6576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Encouraging divergent thinking in large language models through multi-agent debate</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.19118</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17390</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Toward integrating cognitive linguistics and cognitive language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lindes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Cognitive Modeling (ICCM)</title>
		<meeting>the 14th International Conference on Cognitive Modeling (ICCM)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11477</idno>
		<title level="m">Llm+ p: Empowering large language models with optimal planning proficiency</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06804</idno>
		<title level="m">What Makes Good In-Context Examples for GPT-3 ?</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<idno type="ISSN">0360-0300</idno>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
		</imprint>
	</monogr>
	<note>2023b</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Mind&apos;s eye: Grounded language model reasoning through simulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.05359</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Understanding the benefits and challenges of using large language model-based conversational agents for mental well-being support</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.15810</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Self-refine: Iterative refinement with self-feedback</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hallinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17651</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">The theory of algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Markov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trudy Matematicheskogo Instituta Imeni VA Steklova</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="3" to="375" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Prioritized memory access explains planning and hippocampal replay</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1609" to="1617" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Language models enable zero-shot prediction of the effects of mutations on protein function</title>
		<author>
			<persName><forename type="first">J</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Verkuil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Augmented language models: a survey</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mialon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dess?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nalmpantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rozi?re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.07842</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Learning goal-oriented hierarchical tasks from situated interactive instruction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Acquiring grounded representations of words with situated interactive instruction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Mininger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cognitive Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="113" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Saunders</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.09332</idno>
		<title level="m">Browser-Assisted Question-Answering with Human Feedback</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Deep transfer in reinforcement learning by language grounding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>JAIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Soar-RL: Integrating reinforcement learning with Soar</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Systems Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Studies in problem solving: Subject 3 on the crypt-arithmetic task DONALD+ GERALD= ROBERT</title>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967">1967</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Physical symbol systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="183" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Pr?cis of unified theories of cognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="425" to="437" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Human problem solving</title>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Symbolic architectures for cognition. Foundations of cognitive science</title>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Rosenbloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="93" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">A framework for learning to request rich and contextually useful information from humans</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Daum?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2022-07">July 2022a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Interactive learning from activity description</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">X</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dud?k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shafto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8096" to="8108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">A framework for learning to request rich and contextually useful information from humans</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">X</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="16553" to="16568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-C</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V H</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.02299</idno>
		<title level="m">A survey of machine unlearning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Lever: Learning to verify language-to-code generation with execution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>-T. Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="26106" to="26128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">Shakey the robot</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Note</note>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Document expansion by query prediction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Extending cognitive architecture with episodic memory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Nuxoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1560" to="1564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title/>
		<idno>ArXiv, abs/2303.08774</idno>
	</analytic>
	<monogr>
		<title level="j">OpenAI. Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Towards a unified agent with foundation models</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Palo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Byravan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hasenclever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wulfmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Reincarnating Reinforcement Learning at ICLR 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Parisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12255</idno>
		<title level="m">Talm: Tool augmented language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03442</idno>
		<title level="m">Generative agents: Interactive simulacra of human behavior</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">AI-generated characters for supporting personalized learning and well-being</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pataranutaporn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Danry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Punpongsanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Novy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1013" to="1022" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Formal reductions of the general combinatorial decision problem</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="197" to="215" />
			<date type="published" when="1943">1943</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Neural episodic control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2827" to="2836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.07924</idno>
		<title level="m">Communicative agents for software development</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.16789</idno>
		<title level="m">Facilitating large language models to master 16000+ real-world apis</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bodrova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Takayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Varley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.01928</idno>
		<title level="m">Robots that ask for help: Uncertainty alignment for large language model planners</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Synergistic integration of large language models and cognitive architectures for robust ai: An exploratory analysis</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zimmerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Steinfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomasic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09830</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title level="m" type="main">Code llama: Open foundation models for code</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rozi?re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gloeckle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sootla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rapin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kozhevnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Evtimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grattafiori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Copet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<idno>ArXiv, abs/2308.12950</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">Learning to retrieve prompts for in-context learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.08633</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Time spent thinking in online chess reflects the value of computation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Russek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Acosta-Kane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Opheusden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Active preference-based learning of reward functions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sadigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Dragan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems XIII</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Amato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Srinivasa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ayanian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Kuindersma</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.05802</idno>
		<title level="m">Self-critiquing models for assisting human evaluators</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dess?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cancedda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><surname>Toolformer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04761</idno>
		<title level="m">Language models can teach themselves to use tools</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">World of Bits: An Open-Domain platform for web-based agents</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3135" to="3144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Labash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.11366</idno>
		<title level="m">Reflexion: Language agents with verbal reinforcement learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03768</idno>
		<title level="m">Alfworld: Aligning text and embodied environments for interactive learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Progprompt: Generating situated robot task plans using large language models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Blukis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mousavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11523" to="11530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">How to talk so AI will learn: Instructions, descriptions, and autonomy</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sumers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hadfield-Menell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="34762" to="34775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Distilling internet-scale vision-language models into embodied agents</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sumers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning</title>
		<meeting>the 40th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="32797" to="32818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Learning rewards from linguistic feedback</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Sumers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="6002" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Desiderata for cognitive architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Psychology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="373" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Proofwriter: Generating implications, proofs, and abductive statements over natural language</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3621" to="3634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Intelligent agents for interactive simulation environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tambe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Koss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Rosenbloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schwamb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="15" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title level="m" type="main">Referral augmentation for zero-shot information retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05301</idno>
		<title level="m">ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Understanding natural language commands for robotic navigation and mobile manipulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kollar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1507" to="1514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Tuyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.01251</idno>
		<title level="m">Multi-stage episodic control for strategic exploration in text games</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main">Voyager: An open-ended embodied agent with large language models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mandlekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16291</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<title level="m">A survey on large language model based autonomous agents</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Query2doc: Query expansion with large language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.07678</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.07540</idno>
		<title level="m">Scienceworld: Is your agent smarter than a 5th grader? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<idno type="ISSN">2835-8856</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Survey Certification</note>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<title level="m">Chain of thought prompting elicits reasoning in large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">Llm-powered autonomous agents. lilianweng.github.io</title>
		<author>
			<persName><forename type="first">L</forename><surname>Weng</surname></persName>
		</author>
		<ptr target="https://lilianweng.github.io/posts/2023-06-23-agent/" />
		<imprint>
			<date type="published" when="2023-06">Jun 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">Memory networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Understanding natural language</title>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="191" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<monogr>
		<title level="m" type="main">Language models as a knowledge source for cognitive agents</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.08270</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.08155</idno>
		<title level="m">Enabling next-gen llm applications via multi-agent conversation framework</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Promptchainer: Chaining large language model prompts through visual programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Donsbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI Conference on Human Factors in Computing Systems Extended Abstracts</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">AI chains: Transparent and controllable human-AI interaction by chaining large language model prompts</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2022 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16334</idno>
		<title level="m">Olagpt: Empowering llms with human-like problem-solving abilities</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.04030</idno>
		<title level="m">Gentopia: A collaborative platform for tool-augmented llms</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b165">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18323</idno>
		<title level="m">Rewoo: Decoupling reasoning from observations for efficient augmented language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14688</idno>
		<title level="m">ExpertPrompting: Instructing Large Language Models to be Distinguished Experts</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<title level="m" type="main">Intercode: Standardizing and benchmarking interactive coding with execution feedback</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.14898</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04129</idno>
		<title level="m">Foundation models for decision making: Problems, methods, and opportunities</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Language agents in the digital world: Opportunities and risks. princetonnlp.github.io</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<ptr target="https://princeton-nlp.github.io/language-agent-impact/" />
		<imprint>
			<date type="published" when="2023-07">Jul 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title level="m" type="main">Keep CALM and explore: Language models for action generation in text-based games</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02903</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Webshop: Towards scalable real-world web interaction with grounded language agents</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="20744" to="20757" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03629</idno>
		<title level="m">React: Synergizing reasoning and acting in language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b173">
	<monogr>
		<title level="m" type="main">Tree of thoughts: Deliberate problem solving with large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10601</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">STaR: Bootstrapping reasoning with reasoning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="15476" to="15488" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title level="m" type="main">Socratic models: Composing zero-shot multimodal reasoning with language</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Attarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choromanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Welker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.00598</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Dialogpt: Large-scale generative pre-training for conversational response generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="270" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">SILG: The Multi-domain Symbolic Interactive Language Grounding Benchmark</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Hanjie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="21505" to="21519" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Docprompting: Generating code by retrieving the docs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.13854</idno>
		<title level="m">A Realistic Web Environment for Building Autonomous Agents</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Muresanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.01910</idno>
		<title level="m">Large language models are human-level prompt engineers</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
