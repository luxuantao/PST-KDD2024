<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A New Multiobjective Evolutionary Algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ruhul</forename><surname>Sarker</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Ko-Hsin</forename><surname>Liang</surname></persName>
							<email>liangk@cs.adfa.edu.au</email>
						</author>
						<author>
							<persName><forename type="first">Charles</forename><surname>Newton</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">The University of New</orgName>
								<address>
									<country>South Wales</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">ADFA Campus</orgName>
								<address>
									<postCode>ACT 2600</postCode>
									<settlement>Canberra</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A New Multiobjective Evolutionary Algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0AB838645FE92148F810327B47CF6CAF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Pareto-based approaches have shown some success in designing multiobjective evolutionary algorithms. Their methods of fitness assignment are mainly from the information of dominated and nondominated individuals. On the top of the hierarchy of multiobjective evolutionary algorithms, the Strength Pareto Evolutionary Algorithm (SPEA) has been elaborately designed with this principle in mind. In this paper, we propose a (µ + λ) multiobjective evolutionary algorithm ((µ + λ)MEA), which discards the dominated individuals in each generation. The comparisons of the experimental results demonstrate that the (µ + λ)MEA outperforms SPEA on five benchmark functions with less computational efforts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In multiobjective optimization problems, we define the vector-valued objective function f : R n → R m where m &gt; 1, n is the dimension of the decision vector, x, and m is the dimension of the objective vector, y. For the case of minimization problems, we intend to minimize</p><formula xml:id="formula_0">y = f (x) = (f 1 (x), • • • , f m (x)),</formula><p>where x ∈ R n , and y ∈ R m . A solution y a is said to dominate solution y b if y ai ≤ y bi , ∀i ∈ {1, • • • , m} and y ai &lt; y bi , ∃i ∈ {1, • • • , m}. In most cases, the objective functions are in conflict, because in order to decrease any of the objective functions, we need to increase other objective functions. When we have a solution which is not dominated by any other solution in the feasible space, we call it Pareto-optimal. The set of all Pareto-optimal solutions is also termed the Pareto-optimal set, efficient set or admissible set. Their corresponding vectors are called the nondominated set.</p><p>In <ref type="bibr" target="#b0">[1]</ref>, Fonseca and Fleming categorized the evolutionary based techniques for multiobjective optimization into three approaches, plain aggregating approaches, population-based non-Pareto approaches, and Pareto-based approaches. Recently, a similar but more comprehensive survey was also presented in <ref type="bibr" target="#b1">[2]</ref> by <ref type="bibr">Coello.</ref> Scalarizing the objective vector into a single objective (also called the aggregating function) has the advantage of obtaining a single compromise solution when applying any traditional optimizers or evolutionary algorithms (EAs). However, these approaches cannot deal properly with non-convex Pareto fronts <ref type="bibr" target="#b2">[3]</ref>. In addition, the single solution may not satisfy the decision makers, and the importance of each objective function must be known prior to setting the proper weights for each objective function. Hence solving the multiple objectives concurrently is a favorable option to most decision makers. This demand fits with the EA's characteristic of population. Using evolutionary based approaches to solve multiobjective problems has the merit of generating multiple solutions in one run.</p><p>The early work exploiting the population of EAs to search for multiple nondominated solutions can be dated back to Schaffer's Vector Evaluated Genetic Algorithm (VEGA) <ref type="bibr" target="#b3">[4]</ref>. To properly handle every objective function is the main difficulty of the population-based non-pareto approaches. VEGA uses m subpopulations to optimize each objective independently using proportional selection. These subpopulations, then, are shuffled together to perform crossover and mutation operators. A similar approach was developed by Kursawe <ref type="bibr" target="#b4">[5]</ref>. His multiobjective version of evolution strategies (ESs) applies a probability vector to determine the objective in one of the selection steps.</p><p>The Pareto-based approaches basically use the objective functions to distinguish between the nondominated and dominated solutions in the current population. The fitness assignment of an individual is based on the information from both the nondominated and dominated sets. Goldberg <ref type="bibr" target="#b5">[6]</ref> was the first to suggest a nondominated ranking procedure to decide the fitness of the individuals. Based on his idea, Srinivas and Deb <ref type="bibr" target="#b6">[7]</ref> developed the Nondominated Sorting Genetic Algorithms (NSGA). The nondominated individuals are removed layer by layer from the population. Before removing them, the different ranks are assigned to each layer. The individuals in the first layer would have the best fitness.</p><p>A slightly different scheme was proposed in Fonseca and Fleming's multiobjective EA (FFEA) <ref type="bibr" target="#b7">[8]</ref>. An individual's rank is determined by the number of individuals dominating it. Without using any nondominated ranking methods, the Niched Pareto Genetic Algorithm (NPGA) proposed by Horn, Nafpliotis and Goldberg <ref type="bibr" target="#b8">[9]</ref> directly use a set of randomly picked individuals from the current population and place the best of this subset in the next population. Different from binary tournament selection, the fitness of the two randomly selected individuals is decided according to whether they are dominated by any of the individuals from the comparison set(a set of individuals is also picked from the population). If one individual is dominated by the comparison set, and the other is not, the later is selected for reproduction. If neither or both are dominated by the comparison set, a niched method <ref type="bibr" target="#b9">[10]</ref> is used for selection.</p><p>A common feature of the Pareto-based approaches mentioned above is that the Pareto-optimal solutions in each generation are assigned the same fitness or rank. Some sharing or niche techniques have to be applied in the selection procedure. Recently, Zitzler and Thiele <ref type="bibr" target="#b10">[11]</ref> proposed a Pareto-based method, the Strength Pareto Evolutionary Algorithm (SPEA), which elaborately assigns different fitness to all the individuals including the nondominated ones. The detailed characteristics of this algorithm are discussed in a later section. The comparisons among SPEA and other evolutionary based algorithms were made by solving 9 multiobjective 0/1 knapsack problems <ref type="bibr" target="#b11">[12]</ref> and 6 test functions <ref type="bibr" target="#b12">[13]</ref> constructed by following Deb's guidelines <ref type="bibr" target="#b13">[14]</ref>. In these comparisons, SPEA clearly outperforms the other multiobjective EAs.</p><p>Most recently, Knowles and Corne <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref> proposed a simple Evolution Strategies, (1+1)-ES, known as PAES (Pareto Archived Evolution Strategy), that keeps a record of limited nondominated individuals. The nondominated individuals are accepted for recording based on the degree of crowdiness in their grid (defined regions on the Pareto frontier) location to ensure diversity of individuals in the final solution. The algorithm is strictly confined to local search i.e. it should use a small change (mutation) operator only, and move from a current solution to a nearby neighbour. As they reported, the algorithm works well, specially for the problems of low computational complexity. They also proposed an extension to this basic approach, which took them to some variants of a (µ + λ) -ES. The performance of the algorithm is judged, by solving several test problems, and analyzing the results using a statistical comparison technique. P EAS was also compared with SP EA using the same representation and operators as SP EA on all the test functions.</p><p>A Multiobjective Evolution Strategy (MOBES) was developed by Binh and Korn <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> for solving constrained multiobjective optimization problems. In this method, the decision variables, strategy parameter vector and the objective function vector are considered as the key elements. The detail of this method is not reported here as we are interested in unconstrained problems only.</p><p>In this paper, we develop a Pareto-based (µ + λ) multiobjective evolutionary algorithm where the values of µ vary from generation to generation and λ is equal to µ times a fixed ratio. In each generation, all dominated individuals are discarded. Offspring are only produced by nondominated individuals, stored in an external memory, using recombination and mutation operators. The algorithm is compared to SPEA on five benchmark test functions used in <ref type="bibr" target="#b12">[13]</ref>. We use the concept of 'coverage metric', as stated in Zitler and Thiele <ref type="bibr" target="#b11">[12]</ref>, to judge the performance of our algorithm. The experimental results clearly demonstrate that the (µ + λ) multiobjective evolutionary algorithm outperforms SPEA on all test functions.</p><p>The rest of this paper is organized as follows. Section 2 describes the (µ + λ) multiobjective evolutionary algorithm in detail. The empirical results and discussions are presented in section 3. The performance analysis is provided in section 4. Finally, section 5 concludes the paper with some remarks and future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The (µ + λ) Multiobjective Evolutionary Algorithm</head><p>The (µ + λ) multiobjective evolutionary algorithm, or for short: (µ + λ)MEA, has a very different design from other Pareto-based approaches. It does not use any information from the dominated individuals. In each generation, we only preserve nondominated individuals. The number of generated offspring is the number of the nondominated individuals multiplied by a fixed ratio. Hence, the population size in each generation could be different. However, we limit the number of the nondominated individuals using a nearest neighbour distance function, which can help to disperse the nondominated individuals.</p><p>The (µ + λ) multiobjective evolutionary algorithm is described as follows.</p><p>Step 1: Generate µ init individuals randomly.</p><p>Step 2: Collect non-dominated solutions from the population. The number of non-dominated solutions is µ nd .</p><p>Step 3: If µ nd &gt; µ max , select µ max individuals using the nearest neighbour distance function, and then µ nd = µ max .</p><p>Step 4: Generate µ nd × ν offspring using discrete recombination and Gaussian mutation.</p><p>Step 5: Go to Step 2 if the termination criteria are not met.</p><p>This algorithm uses the concept of the (µ + λ)-ES <ref type="bibr" target="#b18">[19]</ref>. However, µ is the number of non-dominated individuals, µ nd , which varies from generation to generation, and λ is equal to µ nd × ν, where ν is the fixed ratio of offspring and parents in each generation.</p><p>Instead of the binary string implementation normally found in GAs, we use the real number representation in our algorithm. Since many problems in the real world are expressed in real variables, faster computation can be obtained without conversions between different representations. More discussions on binary versus real coding are provided in section 4.</p><p>In Step 3, we control the number of non-dominated individuals so as not to exceed a maximum number, µ max . Hence the generated offspring are under control. To filter better individuals from the non-dominated set, we evenly distribute the individuals on the Pareto front. Using the nearest neighbour distance function the individuals crowds together resulting in a lower fitness value thereby reducing the probability of selection to the next generation. So an individual far away from any other individual will have a better chance of survival. The nearest neighbour distance function is defined as follows.</p><formula xml:id="formula_1">D(x) = min m j=1 { x -x j : x, x j ∈ {x 1 , • • • , x µ nd }} m ,</formula><p>where x = x j . In the case of two objective problems, the above function can be simplified as</p><formula xml:id="formula_2">D(x) = (min x -x i + min x -x j )/2,</formula><p>defining the nearest neighbour distance to be the average of the distance from x to the two closest individuals x i and x j , where x i = x j , and x, x i , x j ∈ {x 1 , • • • , x µ nd }. This rule will allow n or less closely grouped individuals to stay in the population, and expel those more than n. The discrete recombination is most often used in ESs <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. The discrete recombination has also produced good results with real-coded GAs (such as Breeder GA) <ref type="bibr" target="#b21">[22]</ref>. The implementation is that each new individual's objective variable is randomly decided from one of the two pre-selected parents</p><formula xml:id="formula_3">. If parent-1 is (x 1 , • • • , x n ) and parent-2 is (y 1 , • • • , y n ). We generate offspring (z 1 , • • • , z n ), where z i = {x i } or {y i }, ∀i ∈ {1, • • • , n}, x i or y i are chosen with probability 0.5.</formula><p>Parts of the mutation operator have been inspired by the breeder genetic algorithm (BGA) <ref type="bibr" target="#b21">[22]</ref>. For each objective variable, the probability to perform a mutation is p m . We use p m = 1/n. The Gaussian mutation is implemented as follows.</p><formula xml:id="formula_4">z i = x i + 0.1 • (x U i -x L i ) • N (0, 1)</formula><p>, where x U i and x L i are the upper and lower boundaries of variable x i , respectively, and i ∈ {1, • • • , n}. N (0, 1) denotes a Gaussian distributed one-dimensional random number with mean 0 and standard deviation 1. The number 0.1 adopted from BGA is regarded as a fixed step size. Using a fixed step size, we can avoid designing self-adaptive step sizes, which may be a difficult job. For multi-objective problems, the adaptive step sizes may not be adapted well enough to fit different objective spaces. This could be an interesting topic for future research.</p><p>Although the (µ + λ)MEA only keeps a fixed number of nondominated solutions in each generation, it also maintains an external storage to store the nondominated individuals found in the entire optimization run. The size of the external storage is not restricted. The same external storage is applied in SPEA as well. SPEA maintains a main external set used in the evolution process, and a secondary external set used as storage for all the nondominated solutions only. The purpose of keeping all the nondominated solutions is to facilitate the comparisons among EAs by focusing on their offline performance <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>In our study, five numerical multi-objective optimization problems were applied to test the (µ + λ)MEA. These benchmark problems as listed in the Appendix were used by Zitzler, Deb and Thiele <ref type="bibr" target="#b12">[13]</ref>. Since the (µ + λ)MEA is mainly designed for solving numerical problems, we only tested functions T 1 -T 4 and T 6 . The test function T 5 is a deceptive problem with bit string representation, which currently is unsuitable to be solved by the (µ + λ)MEA.</p><p>For the (µ + λ)MEA, the initial population size, µ init , is set to 100, which is a common value found in EAs experiments. The maximum number of parents, µ max , is 20, and the ratio of offspring and parents, ν, is 4. Therefore, the maximum possible number of (µ + λ) in each generation will be limited to 100. Each problem is executed 30 times. The algorithm terminates when 10000 function evaluations are used.</p><p>To evaluate the performance of the (µ + λ)MEA, we compare it with the results of SPEA 1 . We use the same methods of performance measures as applied in <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graphical Presentation and Coverage Comparisons</head><p>It is well accepted that the multiobjective optimization problems require multiple, but evenly distributed, solution points to form a Pareto trade-off front to make them useful to the human decision makers. When comparing two algorithms, these two consequences (number of solution points and their distributions) must be considered in addition to the quality of solutions . However, there are a number of methods available to compare the performance of different algorithms. The Error Ratio and the Generational Distance are used as the performance measure indicators when the Pareto optimal solutions are known <ref type="bibr" target="#b22">[23]</ref>. The Spread measuring techniques express the distribution of individuals over the nondominated region <ref type="bibr" target="#b6">[7]</ref>. The method is based on the chi-square-like deviation form distribution measure, and it requires several parameters to be estimated before calculating the Spread indicator.</p><p>The method of coverage metrics is proposed by Zitzler and Theiele for comparing the performances of different multiobjective evolutionary algorithms <ref type="bibr" target="#b11">[12]</ref>. The method shows whether the outcomes of one algorithm dominate the outcomes of another algorithm without indicating how much better it is. Most recently, Knowles and Corne <ref type="bibr" target="#b15">[16]</ref> proposed a statistical method to compare the performances of two or more algorithms by analyzing the superiority in different regions of the attainment surfaces. However, the concept of attainmentsurf aces and counting the superiority of different regions of the attainment surfaces was first proposed by Fonseca and Fleming <ref type="bibr" target="#b23">[24]</ref> without incorporating any proper statistical analysis.</p><p>We used two methods: (i) graphical presentation for visual inspection and (ii) the method of coverage metrics to show the quantitative dominance. Using the method of coverage metrics, Zitzler and Theiele claimed that their algorithm is the best among the well known multiobjective evolutionary algorithms <ref type="bibr" target="#b11">[12]</ref>. This encourages us to choose the same test problems as Zitzler and Theiele and compare their outcomes with ours using the same comparison technique.</p><p>The first method is the graphical presentation. We unify the outcomes of the first five runs of each test function from each algorithm. The dominated solutions are deleted from the union set, and all the nondominated ones are plotted as shown in Figures <ref type="figure" target="#fig_0">1 to 3</ref>.</p><p>It is clear that the (µ + λ)MEA outperforms SPEA on all 5 test functions. For functions T 1 and T 2 , the Pareto-optimal solutions of the (µ + λ)MEA are closer to the Pareto trade-off surface. Its solution distributions cover almost the whole convex and non-convex Pareto-optimal fronts. The results of function T 3 from the (µ + λ)MEA and SPEA are a bit close. To show the discrepancy, we enlarged the region of closest proximity   located between 0.8 and 0.9 of f 1 and displayed it on the right of Figure <ref type="figure">2</ref>. It is clear that the results of the (µ + λ)MEA are closer to the Pareto-optimal front with similar solution distribution.</p><p>For function T 4 , the (µ + λ)MEA clearly outperforms SPEA. Since the solutions of function T 6 from both algorithms are very close to the Pareto-optimal front, it is difficult to judge from the quality of the solutions. However, for SPEA, there are only 12 solutions found and 6 points are displayed. That is, they group into 6 different areas. Therefore, the solution distribution of SPEA is not satisfactory.</p><p>The second comparison method is to measure the coverage of two solution sets from different algorithms. We say a solution y a covers solution y b when y a dominates y b or y a = y b . The performance measures are represented by the C metric used in <ref type="bibr" target="#b11">[12]</ref>. C(Y ′ , Y ′′ ) is defined as the number of solutions in Y ′′ covered by any solutions in Y ′ divided by the solution number in Y ′′ .</p><p>Figure <ref type="figure" target="#fig_2">4</ref> shows the box plots based on the C metric measured from the results of both algorithms. The box plots for each function are drawn from 30 C values, which are calculated from the 30 algorithm pairs from 30 runs. The box plots demonstrate that (µ + λ)MEA's results covered SPEA except for a few occasions. On the other hand, the answers from SPEA never covered any of the (µ + λ)MEA's solutions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discussions</head><p>In our experiments, the (µ + λ)MEA stopped when 10000 function evaluations were used. For SPEA in <ref type="bibr" target="#b11">[12]</ref>, the population sizes of 80 and 250 generations were applied, which used 20000 function evaluations to finish one run of the experiment. We used half of the number of function evaluations used in SPEA, since the nondominated individuals converged pretty early to the Pareto trade-off surface.</p><p>Figure <ref type="figure" target="#fig_3">5</ref> shows the trace of the nondominated solutions of the (µ + λ)MEA on function T 2 in one run. In this example, the program ended after 367 generations had evolved. At the 200-th generation, 948 function evaluations were used, and one of the Pareto-optimal solutions was (f 1 , f 2 ) = (0, 1.1232). This shows that the individuals can evolve to the Pareto trade-off surface rapidly. One possible reason for this faster search speed is that the (µ + λ)MEA does not save any dominated individuals, which might reduce the possible waste made from the dominated ones. However, two issues are raised. What benefits could be obtained by keeping dominated individuals in the population? That is, what is the probability of a nondominated individual being derived from a dominated individual? Another issue is how harmful will the rejection of the dominated set be. The above questions could be interesting topics for future research. However, when we watched the processes of the (µ + λ)MEA, we often observed that the number of the nondominated individuals was very low in the beginning, sometimes resulting in only one nondominated individual being left in the middle of the process. In the example of Figure <ref type="figure" target="#fig_3">5</ref>, the (1 + λ)MEA (µ = 1) were first appeared in the 186-th generation. The number of nondominated individuals began to increase when the evolved individuals were close to the Pareto trade-off surface.</p><p>We may approximately divide the (µ + λ)MEA into two search stages, the convergent and divergent stages. The convergent stage makes the individuals to rapidly approach the Pareto front. The divergent stage disperses the individuals and maintains a well distributed population. In the above case, 1/10 and 9/10 of the process were dedicated to the convergent and divergent stages, respectively. On the second stage, the ability of the (µ + λ)MEA to find multiple nondominated solutions is mainly driven by the Gaussian mutation. Using the continuous search space, the Gaussian mutation has the advantage of recovering good individuals from the near neighborhood.</p><p>One possible weakness of the (µ + λ)MEA was uncovered in Figure <ref type="figure">2</ref>. A closer inspection of the five discrete Pareto fronts, showed that the solutions are not evenly distributed. Therefore, the search without dominated individuals may not have enough diversity to cover some solution space, especially when the Pareto-optimal set is discretely located.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance Analysis</head><p>Since (µ + λ)MEA performed significantly better than SPEA, it will be beneficial to know what contributes the success of (µ + λ)MEA. The differences between (µ + λ)MEA and SPEA are described as follows.</p><p>Nondominated Solution Limitation: In both algorithms, the number of nondominated solutions in each generation is limited to a given maximum. SPEA uses the clustering methods to prune the exceeding nondominated solutions, and (µ+λ)MEA retains preferable nondominated solutions by way of the nearest neighbor distance function.</p><p>Evolutionary Operators: The evolutionary operators employed by SPEA and (µ + λ)MEA are different. SPEA uses bit string representation, traditional one point crossover, and bit flipping mutation. (µ+λ)MEA uses numerical representation, global discrete recombination and Gaussian mutation with fixed step size control.</p><p>Parent Selection: Another major difference is the way of generating the parent population for the next population. In SPEA, an intermediate population is formed first by binary tournament selection before performing any operators. An individual's fitness is calculated by the strength of covering other individuals. In (µ + λ)MEA, no strength calculation is needed. The nondominated solutions naturally become the parents of the next generation.</p><p>The nondominated solution limitation is a mechanism to distribute the solutions evenly. The algorithm's search ability is mainly contributed by the evolutionary operators and the parent selection schemes. To compare the performances of different evolutionary operators, we can refer Bäck and Schwefel's work <ref type="bibr" target="#b19">[20]</ref> on comparing GAs, ESs and evolutionary programming (EP). The performances of ESs and EP are both better than GAs, where the evolutionary operators have played a significant role. It seems the operators in (µ + λ)MEA provide major roles while outperforming SPEA.</p><p>To investigate which part of (µ + λ)MEA makes more contribution to the search results, two empirical analysis are conducted. The empirical results will clarify the question: is the better performance of (µ + λ)MEA caused by its operators or/and its parent selection schemes?  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Comparison Between Evolutionary Operators</head><p>In the first experiment, two SPEAs with different evolutionary operators are compared. The first version of SPEA is the original SPEA proposed by Zitzler et al. <ref type="bibr" target="#b11">[12]</ref>. The operators are one point crossover and bit flipping mutation. The second version of SPEA replaces the above operators with discrete recombination and Gaussian mutation, which were the same ones used in (µ + λ)MEA. We name the second SPEA as "fastSPEA". Since the binary tournament selection has to be retained (where the strength is used), the discrete recombination can only operate with two individuals (the discrete recombination in (µ + λ)MEA operates with whole population). The experimental setup is the same as the original SPEA in <ref type="bibr" target="#b11">[12]</ref>.</p><p>Since the operators are the only part changed, the comparison between both SPEAs can clearly demonstrate the influence of different operators. We only compare the performances on test functions T 1 and T 4 , since they represent two extreme types of functions, easy (convex) and difficult (multimodal). The comparison methods are the same as used in Section 3. The experimental results are shown in Figures <ref type="figure" target="#fig_4">6</ref> and<ref type="figure" target="#fig_6">7</ref>  Obviously, fastSPEA performs better than SPEA on test function T 1 , and worse on test function T 4 . For test function T 1 , the numerical operators in fastSPEA demonstrated the fast convergence rate. However, these operators made the search trapped in some local minima on the case of test function T 4 . Since the discrete recombination is limited under the binary tournament selection, its performance on multimodal problems was affected. In general, global discrete recombination can provide good results in multimodal problems <ref type="bibr" target="#b21">[22]</ref>. Salomon <ref type="bibr" target="#b24">[25]</ref> explained in his paper why breeder GA performs well on some benchmark problems.</p><p>Summarizing the experimental results, we cannot make any decisive conclusions to the performance of different evolutionary operators. However, from the viewpoint of convergence speed we are certain that the numerical operators are better than traditional GA operators on numerical problems.  The methods of nondominated solution limitation mainly work for solutions distribution. Since the solution of both algorithms are evenly distributed near the Pareto front on T 1 in Figure <ref type="figure" target="#fig_7">8</ref>, we cannot judge which algorithm has better distribution. However, we should have no doubt about the success of both nondominated solution limitation methods.</p><p>Excluding the effect of the nondominated solution limitation, we found that the (µ + λ)MEA's solutions are closer to the Pareto front than fastSPEA. In fact, the C metrics on T 1 in Figure <ref type="figure">9</ref> show that few (µ + λ)MEA's solutions are covered by fastSPEA, and most fastSPEA's solutions are covered by (µ+λ)MEA. We can conclude that (µ + λ)MEA outperforms fastSPEA. Therefore, we may infer that (µ + λ)MEA's parent selection scheme is the major key to its success. The advantages of (µ + λ)MEA's parent selection scheme are two-fold.</p><p>1. No extra fitness calculation is needed. The mechanism of determining nondominated solutions is applied to decide the individual's fitness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>No large population size is maintained. If only one nondominated solution was found in certain generations, the population size would be simply ν. The smaller population size during the run usually saves a lot of unnecessary computation in generating dominated offspring.</p><p>From the empirical studies, we can conclude that (µ + λ)MEA's parent selection scheme plays the major role as an effective and efficient multiobjective evolutionary algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we developed a (µ + λ) multiobjective evolutionary algorithm. Without reserving the dominated individuals, the (µ + λ)MEA appeared to have a very fast search speed. We compared its performance with SPEA using five benchmark functions. The results have shown that the (µ + λ)MEA performs better than SPEA in both objective functions values and search speed. We conducted two empirical analysis to find which part of (µ + λ)MEA makes more contribution to the search results. From the empirical studies, we can conclude that (µ + λ)MEA's parent selection scheme plays a major role to produce quality solutions. Although the fast search speed results from the rejection of the dominated individuals, the search diversity may not be enough for some problems with discrete Pareto-optimality. So more tests on different numerical multiobjective problems will be one area of our future work. To solve discrete or combinatorial problems, the development of other suitable mutation operators is also part of our future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Test function T 1 (left) and test function T 2 (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Test function T 3 (left) and enlarged rectangle of test function T 3 from left (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Box plots based on the C metric from 5 test functions are shown. C(Y SP EA , Y (µ+λ)M EA ) is on the left, and C(Y (µ+λ)M EA , Y SP EA ) is on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The trace of one run of the (µ + λ)MEA on function T 2 is shown, a 3D view on the left and a 2D view on the right. The colour bars note for the number of generations evolved.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Comparison between SPEA and fastSPEA for test function T 1 (left) and test function T 4 (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Box plots based on the C metric from functions T 1 and T 4 are shown. C(Y f astSP EA , Y SP EA ) is on the left, and C(Y SP EA , Y f astSP EA ) is on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparison between fastSPEA and MEA using 5000 function evaluations on test function T 1 (left) and test function T 4 (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>4. 2 Figure 9 :</head><label>29</label><figDesc>Figure 9: Box plots based on the C metric from solving functions T 1 and T 4 with 5000 function evaluations are shown. C(Y f astSP EA , Y (µ+λ)M EA ) is on the left, and C(Y (µ+λ)M EA , Y f astSP EA ) is on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1</head><label></label><figDesc>The test results of SPEA are obtained from "http://www.tik.ee.ethz.ch/∼zitzler/testdata.html" established by Zitzler.</figDesc><table><row><cell></cell><cell>1.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MOES SPEA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MOES SPEA</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f2</cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>f2</cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>f1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>f1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors gratefully acknowledge the support by a UC(UNSW, ADFA) Special Research Grant 1999-2000 awarded to Dr. R. Sarker. Ko-Hsin Liang also thanks Dr. Zitzler for discussion about SPEA. The authors like to thank two unknown referees for their many useful comments and constructive suggestions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Test Functions</head><p>Five benchmark test functions are listed here. For all functions the Pareto-optimal front is formed with g = 1. n is the number of decision vector,x.</p><p>No. Function</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An overview of evolutionary algorithms in multiobjective optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Comparative Survey of Evolutionary-based Multiobjective Optimization Techniques</title>
		<author>
			<persName><forename type="first">C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="269" to="308" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A closer look at drawbacks of minimizing weighted sums of objectives for Pareto set generation in multicriteria optimization problems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dennis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Strictural Optimization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="63" to="69" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiple objective optimization with vector evaluated genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms and their Applications: Proceedings of the First International Conference on Genetic Algorithms</title>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A variant of evolution strategies for vector optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kursawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Manner</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">496</biblScope>
			<biblScope unit="page" from="193" to="197" />
			<date type="published" when="1991">1991</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>in Parallel Problem Solving from Nature -PPSN I</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search, Optimization, and Machine Learning</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison Weslay</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multiobjective Optimization using Nondominated Sorting in Genetic Algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="248" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Genetic Algorithms for Multiobjective Optimization: Formulation, Discussion and Generalization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Genetic Algorithms</title>
		<meeting>the Fifth International Conference on Genetic Algorithms<address><addrLine>San Mateo, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A niched pareto genetic algorithm for multipleobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nafpliotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First IEEE Conference on Evolutionary Computation</title>
		<meeting>the First IEEE Conference on Evolutionary Computation<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="82" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An investigation of niche and spices formation in genetic function optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third international Conference on Genetic Algorithms</title>
		<meeting>the third international Conference on Genetic Algorithms<address><addrLine>California</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="42" to="50" />
		</imprint>
		<respStmt>
			<orgName>George Mason University ; Sat Mateo</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An Evolutionary Algorithm for Multiobjective optimization: The stength pareto approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<date type="published" when="1998">1998</date>
			<publisher>CH-8092 Zurich</publisher>
			<pubPlace>Zurich, Gloriastrasse</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Engineering and Communication Network Lab (TIK), Swiss Federal Institute of Technology (ETH</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiobjective Evolutionary Algorithms: A Comparative Case Study and the Strength Pareto Approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Comparison of multiobjective evolutionary algorithms: Empirical results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="195" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-objective genetic algorithms: Problem difficulties and construction of test problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="205" to="230" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Pareto archived evolution strategy: a new baseline algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="98" to="105" />
			<date type="published" when="1999">1999. 1999</date>
			<publisher>IEEE Service Centre</publisher>
			<pubPlace>Washington D.C</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Approximating the nondominated front using the Pareto archived evolution strategy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="172" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An evolution strategy for the multiobjective optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Binh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Korn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second international Conference on Genetic Algorithms (Mendel96)</title>
		<meeting>the second international Conference on Genetic Algorithms (Mendel96)<address><addrLine>Brno, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="23" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">MOBES: A multiobjective evolution strategy for constrained optimization problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Binh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Korn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third international Conference on Genetic Algorithms (Mendel97)</title>
		<meeting>the third international Conference on Genetic Algorithms (Mendel97)<address><addrLine>Brno, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="176" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Evolution and optimum seeking</title>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An overview of evolutionary algorithms for parameter optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Oxford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Predictive models for the breeder genetic algorithm I. continuous parameter optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Muhlenbein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schlierkamp-Voosen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="49" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Multiobjective Evolutionary Algorithm Test Suites</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lamont</surname></persName>
		</author>
		<editor>J. Carroll, H. Haddad, D. Oppenheim, B. Bryant and G. Lamont</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="351" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the Performance Assessment and Comparison of Stochastic Multiobjective Optimizers</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature-PPSN IV</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Hans-Michael</forename><surname>Voigt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Werner</forename><surname>Ebeling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ingo</forename><surname>Rechenberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hans-Paul</forename><surname>Schwefel</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="584" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Some comments on evolutionary algorithm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="405" to="415" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
