<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online anomaly detection for sensor systems: A simple and efficient approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-08-13">13 August 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
							<email>yuanyao@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering-Systems</orgName>
								<orgName type="institution">USC</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
							<email>absharma@usc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">USC</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leana</forename><surname>Golubchik</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering-Systems</orgName>
								<orgName type="institution">USC</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">USC</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ramesh</forename><surname>Govindan</surname></persName>
							<email>ramesh@usc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">USC</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Online anomaly detection for sensor systems: A simple and efficient approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-08-13">13 August 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">F6F1090F1C6B47D8E91878124CE6EE06</idno>
					<idno type="DOI">10.1016/j.peva.2010.08.018</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Anomaly detection Sensor systems Real-world deployments</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Wireless sensor systems aid scientific studies by instrumenting the real world and collecting measurements. Given the large volume of measurements collected by sensor systems, one problem arises-an automated approach to identifying the ''interesting'' parts of these datasets, or anomaly detection. A good anomaly detection methodology should be able to accurately identify many types of anomaly, be robust, require relatively few resources, and perform detection in (near) real time. Thus, in this paper, we focus on an approach to online anomaly detection in measurements collected by sensor systems, where our evaluation, using real-world datasets, shows that our approach is accurate (it detects over 90% of the anomalies with few false positives), works well over a range of parameter choices, and has a small (CPU, memory) footprint.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Wireless sensor systems have significant potential for aiding scientific studies by instrumenting the real world and collecting measurements, with the aim of observing, detecting, and tracking scientific phenomena that were previous only partially observable or understood. However, one obstacle to achieving the full potential of such systems is the ability to process, in a timely and meaningful manner, the huge amounts of measurements they collect. Given such large volumes of collected measurements, one natural question might be: Can we devise an efficient automated approach for identifying the ''interesting'' parts of these datasets? For instance, consider a marine biology application collecting fine-grained measurements in near real time (e.g., temperature, light, micro-organism concentrations)-one might want to rapidly identify ''abnormal'' measurements that might lead to algal blooms which can have devastating consequences. We can view the identification of such ''interesting'' or ''unexpected'' measurements (or events) in collected data as anomaly detection. In the remainder of the paper, we use the generic term ''anomaly'' for all interesting (typically, other-than-normal) events occurring either on the measured phenomena or the measuring equipment. Automated online (or near real-time) anomaly detection in measurements collected by sensor systems is the focus of this paper.</p><p>Anomalies can have a variety of lengths, magnitudes, and patterns. For instance, Fig. <ref type="figure" target="#fig_1">1</ref>(a) depicts a long-duration, relatively gradual change in sensor reading, whereas Fig. <ref type="figure" target="#fig_3">2</ref>(b) includes several short-duration, quite abrupt changes in sensor readings. Both scenarios correspond to anomalous events and should be accurately detected by an anomaly detection methodology.</p><p>Thus, a good anomaly detection methodology should have the following properties. First, it should be able to accurately identify all types of anomaly as well as normal behavior (i.e., it should have low false negative and false positive rates).  Second, it should be robust, i.e., the methodology should be relatively insensitive to parameter settings as well as pattern changes in the datasets. Third, it should require relatively small amounts of resources, as these are typically limited in sensor systems. That is, to run on sensor systems, it should ideally have low computational complexity, occupy little memory space, and require little transmission power. Last, it is also desirable for a detection algorithm to be able to detect anomalies in real time or near real time. This is particularly important for sensor systems corresponding to temporary deployments (as it might not be as useful to detect anomalies once the deployment is over) and those monitoring hazardous natural phenomena (e.g., the spread of contaminants in aquatic ecosystems), where prompt detection (and reaction) can be essential to reducing loss of life and money. Anomaly detection, in general, has been studied in a number of system contexts, most notably in networking, where several techniques have been proposed for detecting network traffic anomalies <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. While one might take the approach of adapting one (or more) of these techniques to sensor systems, we believe that they do not satisfy all the desirable properties described above, at least in their current form. In Section 6, we provide (a) quantitative results from applying network anomaly detection techniques to data collected by real sensor system deployments, and (b) intuition for why these techniques did not yield good results on such data. Consequently, the properties required of an effective anomaly detection method for sensor data and our experience with applying network traffic anomaly detection techniques to sensor measurements motivated us to explore methods different from those in prior work in network anomaly detection.</p><p>We also note that little exists in the literature on the topic of anomaly detection in sensor system data. Most efforts are focused on the detection of faulty sensor readings, such as those depicted in Fig. <ref type="figure" target="#fig_4">3</ref>(a) and (b)-these are typically shortduration events, with values significantly deviating from the ''normal'' sensor readings <ref type="bibr" target="#b4">[5]</ref>. Often, such sensor data faults are modeled as outliers and can be detected using simple rule-based approaches or by using statistical models to capture the pattern of normal sensor readings and flagging any significantly different samples as faulty <ref type="bibr">[6]</ref>. In this work, we view faulty sensor readings as a special case of anomalies. As illustrated in Section 4, our approach is able to capture such faulty readings, as well as other long-duration, ''gradual'' anomalies such as the one depicted in Fig. <ref type="figure" target="#fig_1">1(a)</ref>.</p><p>To the best of our knowledge, the only efforts focused on anomaly detection in sensor system data are those reported in <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. Briefly, <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> view measurements collected by a sensor system as coming from the same (unknown) distribution and they ''pre-define'' anomalies as outliers. The main focus of that effort, which is an offline approach, is on minimizing the communication overhead (in transmitting data needed for anomaly detection) and corresponding energy consumption. In contrast, we focus on an online approach that, on the fly, builds an adaptive model of ''normal'' data and does not a priori define what is an anomaly. For instance, the approach in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> might only flag the most extreme measurement in Fig. <ref type="figure" target="#fig_1">1(a)</ref> as an anomaly, whereas our approach would flag the entire event (outlined by the dashed rectangle) as an anomaly. We give a more detailed description of <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> and a quantitative comparison in Section 6. In <ref type="bibr" target="#b8">[9]</ref>, a change point detection-based approach is used for detecting distribution changes (e.g., mean, variance, covariances) in sensor measurements. However, (a) this approach assumes knowledge of the (time-varying) probability distribution from which sensor measurements are sampled (information often not available in real-world deployments), and (b) such techniques do not meet (at least in their current form) our efficiency criteria (see <ref type="bibr">Section 6)</ref>.</p><p>In this work, we formulate the problem of anomaly detection in sensor systems as an instance of the problem of identifying unusual patterns in time series data. Of course, one possible direction would then be to construct a time seriesbased approach, e.g., based on <ref type="bibr">[6]</ref>. However, we also did not find this direction to be effective as such techniques are (typically) not well suited for detecting long-duration anomalies. So, we do not pursue this direction further here, but in Section 6, we do illustrate quantitative results corresponding to applying a representative time series-based approach to data collected by real sensor system deployments and provide intuition for why such a technique did not yield good results.</p><p>In contrast, the basic idea behind our approach is to compare the collected measurements against a reference time series. But, to do this efficiently and robustly, the following challenging problems need to be solved: (1) How do we define a reference time series? (2) How do we compare two time series efficiently? (3) What metric do we use in deciding whether two sensor data time series are similar or different? and (4) How do we update the reference time series, to adapt to (normal) changes in sensor data patterns?   We address these challenges by proposing and evaluating an anomaly detection algorithm, termed Segmented Sequence Analysis (SSA) that exhibits the desirable characteristics stated above. Briefly, SSA leverages temporal and spatial correlations in sensor measurements and constructs a piecewise linear model of sensor data time series. This is motivated by <ref type="bibr" target="#b9">[10]</ref>, which focused on searching for known patterns in time series (see Section 6). To detect anomalies, we compare the piecewise linear models of sensor data (collected during a time interval) and a reference model, with significant differences (as determined by a proposed similarity metric) flagged as anomalies. We use data from real-world deployments to evaluate our approach and demonstrate its accuracy, robustness, and efficiency. In summary, our the main contributions are as follows.</p><p>• We propose an approach to anomaly detection in sensor systems that is able to detect anomalies accurately and in an online manner (Section 2).</p><p>• We perform an extensive study using datasets from two real deployments, one consisting of about 30,000 environmental temperature measurements collected by 23 sensor nodes for around 43 days, and the other consisting of more than 10,000 soil temperature, moisture, and air humidity measurements collected by 3 sensor nodes for over 5 months. This study illustrates that our approach is accurate (it detects over 90% of the anomalies with few false positives), works well over a range of parameter choices, and has a small (CPU, memory) footprint (Sections 3 and 4).</p><p>• We show that our (online) SSA-based approach is more accurate than other potential (offline) techniques, <ref type="foot" target="#foot_0">1</ref> which are more computationally intensive (Sections 5 and 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>In this section, we first describe a tiered sensor system architecture that is representative of data collection deployments. We then formulate the problem of anomaly detection in sensor readings as an instance of the problem of identifying unusual patterns in time series data. Lastly, we describe our method for detecting anomalous sensor readings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Sensor systems for data collection</head><p>We consider a typical tiered sensor system <ref type="bibr" target="#b10">[11]</ref> consisting of two tiers: a lower tier of resource-constrained batteryoperated wireless motes with one or more attached sensors (e.g., temperature, humidity, acceleration), and an upper tier of more capable master nodes, each of which has significantly higher computation, storage, and communication capabilities than the motes. Here, we are interested in the class of data collection sensor systems, where each mote (usually) collects periodic sensor data, possibly performs some local processing on the data, and then transfers the resulting data over multiple hops. We model the measurements collected by a sensor m as a time series D m [t], t = 1, 2, . . . . For example, suppose that a sensing system had 20 motes, each collecting data from 3 sensors. Then, we would have a total of 60 time series (3 from each of the 20 motes), and we would represent these as a set {D m [t], m = 1, 2, . . . , 60; t = 1, 2, . . .}.</p><p>In many data collection applications, these time series exhibit a high degree of temporal and spatial correlations due to the nature of the physical phenomenon being monitored (e.g., temperature or light conditions). We leverage such correlations to detect anomalies (interesting events) in the sensor data time series. As noted in Section 1, anomalies have various lengths, magnitudes, and patterns, and a good anomaly detection methodology should be robust to such variations.</p><p>We first describe the building blocks of our approach, where the basis involves building (and continuously updating) a model of the ''normal'' and then determining how similar new sensor measurements are to the ''normal''. We then describe our approach to anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Building blocks</head><p>At a high level, our approach answers the following question: How similar is a time series of sensor measurements to a given ''reference'' time series? Suppose that we are given two time series, D new  A succinct, representative, and robust piecewise linear model of sensor data time series is desirable for online anomaly detection. First, we can compute such a model in near real time (Section 2.3). Second, it enables us to create a data-driven reference model that is easy to update-hence, we do not need prior knowledge about the types of anomaly that the sensor data might contain. Third, because it is succinct, it enables us to compare two different time series efficiently and transmit models with low overhead. Finally, because it is representative of the sensor data patterns, it enables accurate detection of anomalous patterns.</p><p>Due to their usefulness in modeling time series data, linearization-based approaches have also been used in other contexts. For example, <ref type="bibr" target="#b9">[10]</ref> developed an efficient technique to search for occurrences of a known pattern within a time series. However, the problem of searching for a known pattern in time series data is different from anomaly detection because often we do not have any prior information about the patterns exhibited by anomalous sensor readings.</p><p>Linearization error. In order to compute a piecewise linear model, we need to define the linearization error between a sensor data point j and the line segment l covering it. We define this error as the perpendicular distance between the point j and the line l. Accordingly, we define the linearization error ϵ for a piecewise linear model representing a time series {D[t], t = 1, 2, 3, . . . , n}, as the maximum linearization error across all the data points in D[t].</p><p>How many line segments do we use? We also need to determine the number of line segments, k, to use. Intuitively, using a large number of line segments will result in a small linearization error-as explained below, this leads to lower computation cost but larger communication cost. (This trade-off is explored in detail in Section 4.2.)</p><p>We automatically determine the number of line segments in our piecewise linear model based on the maximum allowed linearization error ϵ, which is a (free) parameter in our approach. For a fixed choice of maximum linearization error ϵ, we use a greedy approach to determine the number of line segments needed to represent a time series. We start with the first two data points of the time series and fit a line segment, (say) l 1 , to them. Then we consider the data points one at a time and recompute l 1 using linear least-squares regression to cover a new data point. We compute the distance of the new data point from the line l 1 . If this distance is greater than ϵ, then we start a new line segment, l 2 , such that the distance between the new data point and l 2 is at most ϵ. We keep repeating this process until we exhaust all data points. Note that our approach is suited for both offline and online processing. In an online setting, whenever the sensor collects a new reading, we can either recompute the current line segment to cover it or start a new line segment (depending on the linearization error). We represent the k line segments that constitute a piecewise linear model of a time series using their end points </p><formula xml:id="formula_0">{(X[i], Y [i]), i = 1,</formula><formula xml:id="formula_1">{( X[i], Ŷ [i]), i = 1, 2} and {( X[i], Ỹ [i]), i = 1, 2, 3} such that X[1] = X[1] and X[3] = X[2]</formula><p>, and hence, X[2] &lt; X <ref type="bibr" target="#b1">[2]</ref>. In order to align the two representations, we choose the X values as {X <ref type="bibr" target="#b1">[2]</ref> and the Y <ref type="bibr" target="#b1">[2]</ref> value (corresponding to the sample at time X <ref type="bibr" target="#b1">[2]</ref>) is computed using the equation of the line segment joining Y <ref type="bibr" target="#b0">[1]</ref> and Y <ref type="bibr" target="#b2">[3]</ref>.</p><formula xml:id="formula_2">[1] = X[1] = X[1], X [2] = X[2], X [3] = X[2] = X[3]}. Hence, after alignment, the new representations are {(X[i], Ỹ [i]), i = 1, 2, 3}, and {(X[i], Y [i]), i = 1, 2, 3}, where Y [1] = Ŷ [1], Y [3] = Ŷ</formula><p>We define the difference between the (aligned) piecewise linear representations of two time series D[t] and D[t] as</p><formula xml:id="formula_3">S( D, D) = 1 k k - i=1 |Y [i] -Ỹ [i]|.<label>(1)</label></formula><p>Here, S( D, D) represents the average difference between the Y values of the piecewise linear representations of D[t] and D[t] over the k line segments. We chose this metric because it is efficient to compute, and it indirectly captures the difference between the two time series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Threshold computation.</head><p>We set the threshold γ (for deciding whether S( D, D) is sufficiently large) to the standard deviation of the initial D ref</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[t].</head><p>We remove any Constant anomalies (described in Section 3), before computing the standard deviationintuitively such measurements are not a good indication of variability in sensor data as they typically correspond to faulty data, e.g., due to low voltage supply to the sensor <ref type="bibr" target="#b4">[5]</ref>. Intuitively, the standard deviation is a reasonable indication of the variability in the ''normal'' data. A multiple of standard deviation could also be used, but our more conservative approach already results (Section 3) in a reasonably low false positive rate; more sophisticated (than threshold-based) approaches are part of future efforts.</p><p>Putting it all together. Given a time series of new sensor data, D new</p><p>[t], and a reference time series, D ref [t], our Segmented Sequence Analysis (SSA)-based approach to anomaly detection utilizes the following steps (all detailed above).</p><p>1. Linearization: We apply our linearization technique to obtain the two piecewise linear models {(X new</p><formula xml:id="formula_4">[i], Y new [i])} and {(X ref [i], Y ref [i])}.</formula><p>2. Alignment: We align the two linear representations so that they have the same X values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Similarity computation:</head><p>We compute the similarity, S(D new , D ref ), between the reference model and the model for new sensor data using Eq. ( <ref type="formula" target="#formula_3">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Anomaly detection:</head><p>We detect an anomaly using a simple threshold-based approach. Specifically, if S(D new , D ref ) is greater than a threshold γ , then we conclude that the sensor readings D new [t] contain an anomaly.</p><p>We now describe in detail our SSA-based anomaly detection framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Using SSA on a tiered sensor network</head><p>We perform anomaly detection in a tiered sensor network in two stages-(1) a local step, executed at each mote, followed by (2) an aggregation step, executed at the master nodes. In the local step we exploit temporal correlations (in sensor readings), and in the aggregation step we exploit spatial correlations, as described next.</p><p>Local step. During the local phase (executed at individual motes), each mote m performs the following tasks: <ref type="bibr" target="#b0">(1)</ref>  </p><formula xml:id="formula_5">t] = (1 -α) × D ref [t] + α × D new [t],</formula><p>where Dref [t] denotes the updated reference time series. [t] but with a time lag. Our evaluation results in Section 4 show that this lag is long enough for SSA to identify the anomalous readings. There is a potential downside in using anomalous readings in updating</p><formula xml:id="formula_6">D ref [t].</formula><p>If an anomaly affects a large number of samples, then SSA will fail to detect many of them. We discuss this in detail in Section 4, and show that, for long-duration anomalies, SSA can identify anomalous samples that correspond to the start and end of these anomalies, which is also quite useful.</p><p>For scenarios where the ''normal'' pattern of sensor readings might not be known or might not exhibit any periodicitye.g., sensors deployed for monitoring of birds' nests <ref type="bibr" target="#b10">[11]</ref>, in the absence of any domain expertise, we assume that the sensor readings collected over a large duration (a 24 h period in most cases) capture the normal patterns in the sensor data time series, and start with such a time series as our reference. Clearly, the performance of our local anomaly detection step depends on the quality of the reference data. A reference data that does not capture the normal sensor readings or is corrupted by anomalies can lead to false positives and/or false negatives. In Section 4, using real-world sensor readings for periodic (e.g., ambient temperature) as well as aperiodic (e.g., soil moisture variations) phenomena, we show that our approach for selecting and updating D ref The final set of anomalies is the union of the anomalies detected during the local and aggregation steps. In our current framework, the master node does not provide feedback to its slave motes. Hence, the anomalous readings from mote m detected only by the aggregation step are currently not leveraged to improve the accuracy of the local anomaly detection step. Incorporating a feedback mechanism between the aggregation and local steps is part of future efforts.</p><p>Online fault detection. To achieve online detection, we run the local and aggregation anomaly detection steps periodically, every T minutes. For example, if T = 30 min, we first collect new sensor readings for half an hour and then perform anomaly detection using the framework described above. The anomaly detection interval, T , controls the trade-off between real-time anomaly detection and resource consumption, as discussed in detail in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Hybrid approach</head><p>As noted in Section 2.2, our piecewise linear representation is very succinct-in practice, a small number of line segments is sufficient to capture the essential information (diurnal patterns, trends lasting for a long duration, etc.) in a time series. However, because it is designed to capture significant trends, a piecewise linear representation will mask faults or anomalies that affect a very small number of sensor samples. The top plot in Fig. <ref type="figure" target="#fig_3">2</ref>(b) shows a temperature reading time series from the SensorScope datasets [12], and the bottom plot shows whether each sensor reading was identified as ''normal'' or ''anomalous'' by SSA. While SSA is able to detect instances of long-duration anomalies (marked by circles), it fails to detect the three very short duration anomalies (marked by rectangles in the top plot). To improve the accuracy of SSA on shortduration anomalies, next we propose a hybrid approach.</p><p>Combining SSA with rule-based methods. We can view data faults in sensor readings as short-duration anomalies (refer to Section 6). Thus, it is reasonable to adapt techniques designed for fault detection for identification of short-duration anomalies. Specifically, <ref type="bibr" target="#b12">[14,</ref><ref type="bibr">6]</ref> are representative of such techniques and they consider the following: Short anomalies (a sharp change in the measured sensor readings between two successive samples), Noise anomalies (increase in the variance of sensor readings) and Constant or ''Stuck-at'' anomalies (the sensor reports a constant value). Thus, we use rule-based methods <ref type="bibr">[6]</ref> (originally designed for fault detection) for detection of short-range anomalies in our hybrid approach by adding the following rules. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Short rule:</head><formula xml:id="formula_7">{D[t], t = 1, 2, 3, . . .}. Let V [t] = variance({D[j]} j=t j=t-c+1</formula><p>) be the variance of c consecutive data readings prior to time t. If V [t] is less than a threshold σ c , then we flag the set of samples {D[j]} j=t j=t-c+1 as anomalous. A rule-based method also exists for detecting Noise data faults. But, as shown in Section 4, SSA is accurate at detecting Noise fault anomalies; thus, we do not include the Noise rule as part of our hybrid method.</p><p>To automatically determine the detection thresholds, σ s and σ c , we use the histogram-based approach <ref type="bibr">[6]</ref>. We plot the histogram of the change in sensor readings between two successive samples (for the Short rule) or the variance of c samples (for the Constant rule) and select one of the modes of the histogram as the threshold.</p><p>Thus, in scenarios where both short-duration and long-duration anomalies are expected, we propose a hybrid approach for anomaly detection. Specifically, every T minutes, we use rule-based methods to detect and mark short-duration anomalies, and then use SSA to detect the remaining anomalies. <ref type="foot" target="#foot_1">2</ref> We evaluate our hybrid approach using real-world datasets in Section 4 and show that it is effective at detecting short-duration and long-duration anomalies. Our evaluation also shows that rule-based methods boost the efficacy of SSA only in situations where we are interested in detecting shortduration anomalies along with interesting long-duration events or anomalies (e.g., changes in sensor reading patterns). Hence, in situations where detecting short-duration anomalies is not of interest, the additional complexity of using rulebased methods is not needed. Note that we do not need to remove short-duration anomalies (or data faults) from the data -e.g., by replacing the sensor readings D[j] corrupted by a Short anomaly with the average of its adjacent samples D[j -1] and D[j + 1] -in order for SSA to be able to detect long-duration anomalies. Our evaluation results in Section 4 show that the presence of short-duration anomalies does not impact the accuracy of SSA when it comes to detecting long-duration anomalies.</p><p>Complexity and overhead. Of all the steps in SSA, linearization requires the most computation, with the worst-case complexity being O(n 2 ), where n is the number of measurements accumulated in a time slot of length T . Since we use linear least-squares regression to determine the best-fit line segment, the cost of approximating d (one-dimensional) data points with a line segment is O(d). However, our greedy approach performs a least-squares regression fit every time a new sensor sample is recorded. In the worst case, we may need to perform least-squares regression n times (once for each data point), resulting in O(n 2 ) computational complexity for the linearization step, and hence, for SSA. In practice, SSA is quite efficient, as shown in Section 4 (as n is typically not very large). We note that the rule-based methods used in our hybrid approach are simple and have O(n) computational complexity; thus, they do not increase the overall complexity of the hybrid approach.</p><p>SSA incurs a communication overhead every time a mote conveys its linear model to its master node. Note that a mote needs to convey four data points per line segment-two X [i] values (sample times) and the corresponding two</p><formula xml:id="formula_8">Y [i] values.</formula><p>Since a mote's linear model consists of k line segments, the communication overhead is O(k). Note that this overhead is incurred every T minutes since a mote recomputes its linear model once every T minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental set-up</head><p>Sensor datasets. The sensor data time series used in our evaluations come from the SensorScope [12] and the Life Under Your Feet [13] projects. Both projects represent the state of the art in sensor systems and collect measurements in very different environments. Hence, the two datasets allow us to evaluate SSA on representative and diverse sensor system data.</p><p>In the SensorScope project, large networks of sensors are deployed to collect environmental data such as temperature, humidity, solar radiation, etc. In this paper, we use temperature readings collected from 23 sensors deployed in the Grand St. Bernard pass between Switzerland and Italy in 2007. Each sensor collected samples every 2 min for 43 days. Since the temperature measurements exhibit a diurnal pattern, the sensor data time series are periodic, with the period being 720 data points (collected every 24 h). In what follows, we show results for all 23 sensor data time series. We refer to these time series as SensorScope 1 through SensorScope 23.</p><p>Our second sensor data source is from the Life Under Your Feet project <ref type="bibr">[13]</ref>, which studies soil ecology in a number of locations. We use datasets collected at the Jug Bay Wetland Sanctuary in Anne Arundel County, Maryland, between June 2007 and April 2008. In this deployment, sensors were placed in the nests of box turtles to study the effect of soil temperature and soil moisture on the incubation of turtle eggs. Measurements of soil temperature, soil moisture, box temperature, and box humidity are collected every 20 min for more than 5 months. These measurements exhibit very diverse patterns. For </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly Description Duration</head><p>Change in mean Anomalous readings differ significantly from average value of normal readings (e.g., as in Fig. <ref type="figure" target="#fig_1">1(a)</ref>) Long</p><p>Change in variance Anomalous readings exhibit less or more variability than normal readings (e.g., as in Fig. <ref type="figure" target="#fig_4">3(c</ref>))</p><p>Long &amp; short Short spike Equivalent to Short fault data type <ref type="bibr" target="#b4">[5]</ref> (e.g., as in Fig. <ref type="figure" target="#fig_4">3(a)</ref>) Short</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constant reading</head><p>Sensor reports a constant value over a period of time (e.g., as in Fig. <ref type="figure" target="#fig_4">3(b</ref>))</p><p>Long &amp; short Change in shape Anomalous readings differ in mean and/or variance from normal readings but with shorter duration than Change in mean and Change in variance (e.g., as in Fig. <ref type="figure" target="#fig_4">3(d</ref>))</p><p>Long &amp; short example, as depicted in Fig. <ref type="figure" target="#fig_4">3</ref>(a), the soil moisture data are non-periodic-here the soil moisture readings are close to 8% when it is not raining, but they exhibit a sharp jump followed by a gradual decay when it rains. Hence, for the soil moisture time series, instances of rainfall are the anomalies (or events) of interest that we try to detect using SSA. In contrast, the box humidity datasets are periodic, with a period of 72 data points (or 24 h). The Jug Bay dataset consists of readings from three different sensors. In what follows, we show results for soil moisture readings collected (we refer to them as Soil Moisture 1, Soil Moisture 2, and Soil Moisture 3), as well as the box humidity data time series (we refer to them as Box Humidity 1, Box Humidity 2, and Box Humidity 3).</p><p>Anomalies in the datasets. To the best of our knowledge, there are no publicly available datasets with anomalies already annotated. Thus, to obtain the ground truth, we visually inspected the sensor data time series from the SensorScope and the Jug Bay deployments, to identify long-duration and short-duration anomalies. This is consistent with current practice for other datasets (e.g., Internet traces in <ref type="bibr" target="#b0">[1]</ref>) that lack ground truth. To identify long-duration anomalies, we used the (subjective) criterion of ''what kind of patterns would a human find interesting?''. The short-duration anomalies that we identified resemble sensor data fault types (Short, Noise, and Constant faults) described in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">6]</ref>. We categorize these identified anomalies into the five groups shown in Table <ref type="table" target="#tab_5">1</ref>. We note that this categorization is done for ease of result presentation (in Section 4) only and is no way used in our anomaly detection approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>We now evaluate our SSA-based approach and illustrate its goodness using the following criteria (a comparison with related literature is presented in Section 6).</p><p>• Accuracy: SSA alone detects most long-duration anomalies (plus a significant fraction of the short-duration ones), and our hybrid approach detects both long-duration and short-duration anomalies accurately.</p><p>• Sensitivity: Our results are not sensitive to SSA's parameter, namely to the settings of the linearization period T , and the maximum linearization error ϵ. • Cost: SSA has low computation and memory cost, and hence it can be effectively implemented in sensor systems.</p><p>• Robustness: SSA is robust to the presence of sensor data faults in the reference time series (i.e., there is no need to ''clean'' the data before running SSA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Accuracy evaluation</head><p>We first describe our method's accuracy, using the datasets and the ground truth identification described in Section 3. We use (1) the number of false positives (detecting non-existing anomalies), and (2) the number of false negatives (not being able to detect an anomaly) as our metrics. Specifically, the results in the tables below are presented as follows-the x/y number indicates that x out of y anomalies were detected correctly (corresponding to yx false negatives), and we also indicate the number of corresponding false positives (FP). Note that a long-duration anomaly may consist of many consecutive data points. In this paper, we focus on detecting these events rather than on identifying each and every anomalous data point within an event. (Thus, when 50% or more of the data points of a long-duration anomaly are identified by SSA as anomalous, we consider this to be a successful detection. <ref type="foot" target="#foot_2">3</ref> )</p><p>The accuracy results of our hybrid approach on all datasets are given in Tables <ref type="table" target="#tab_6">2</ref> and<ref type="table" target="#tab_7">3</ref>. Our hybrid method is able to detect long-duration and short-duration anomalies, with a small number of false positives, and often without any false negatives. Most of the false positives are due to the rule-based part of the hybrid approach rather than to the SSA part (as explained below).</p><p>Tables 2 and 3 also show that long-duration anomalies -particularly the Change in mean and Change in shape anomalies -occur quite often in the SensorScope and the Jug Bay datasets (refer to the last row of both tables). For example, over the Previously, others have shown that short-duration anomalies or data faults (short spikes, constant readings, noise faults) are quite prevalent in real-world datasets <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">6]</ref>; this work is the first to demonstrate that long-duration anomalies occur quite often as well. Under our hybrid approach, anomalies can be detected at three different stages-the rule-based methods, the local step in SSA, and the aggregator step in SSA. For both the SensorScope and the Jug Bay datasets, we found that the aggregator step in SSA did not add significantly to the accuracy of SSA. This is because the combination of the rule-based methods and the local step in SSA was able to detect most of the anomalies. We now focus on understanding the contribution to our hybrid approach's accuracy of SSA versus the rule-based methods. The first two rows of Table <ref type="table">4</ref> show the results of applying SSA alone (without the use of rule-based methods) on the Soil Moisture 1 and the SensorScope 1 time series. Based on these results, we make the following observations: (1) SSA is accurate at detecting long-duration anomalies such as Change in average, Change in variance, and Change in shape, and (2) SSA can fail to detect short-duration anomalies such as Short spikes. For example, while it is able to detect more than 70% of the short spikes in Soil Moisture 1, it detects only about 50% of the short spikes in SensorScope 1. This makes sense, as SSA is intended more for longer-duration anomalies.</p><p>The utility of the hybrid approach can be seen, for example, by comparing the Short results for Soil Moisture 1 and SensorScope 1 in Tables <ref type="table" target="#tab_6">2</ref> and<ref type="table" target="#tab_7">3</ref> with those in Table <ref type="table">4</ref>. The hybrid approach outperforms SSA on short-duration anomalies as it uses rule-based methods, designed specifically for short-duration anomalies like Short spikes and Constant readings. However, our hybrid approach incurred a higher false positive rate than SSA, and a detailed inspection of the samples falsely identified as anomalous revealed that this increase was due to the rule-based methods. Prior work <ref type="bibr">[6]</ref> showed that rulebased methods can incur a high false positive rate mainly because the histogram method for determining their fault detection threshold (Section 2.4) does not always identify a good threshold. We also verified this by computing the histogram using the entire dataset, which significantly reduced the false positive rate. However, such an approach would not be online and hence is not used here.</p><p>We also verified that the rule-based methods alone do not provide any benefits in detecting long-duration anomalies. For instance, this can be seen by comparing the results for Soil Moisture 1 and the SensorScope 1 data in Tables <ref type="table" target="#tab_6">2</ref> and<ref type="table" target="#tab_7">3</ref> with those in Table <ref type="table">4</ref>, where our hybrid method performs the same as SSA with respect to detecting long-duration anomalies like Change in average and Change in shape. In fact, the rule-based methods can perform quite poorly when used for identifying long-duration anomalies. The last row of Table <ref type="table">4</ref> shows the results of applying the rule-based methods alone on the Box Humidity 2 data-compare that to the Box Humidity 2 results in Table <ref type="table" target="#tab_7">3</ref>. As expected, the rule-based methods detect the short-duration anomalies (Short spikes and Constant readings), but fail to detect most of the long-duration anomalies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Sensitivity evaluation</head><p>The linearization period T and the maximum linearization error ϵ are the two main parameters in our SSA-based approach. Next, we present an analysis of the sensitivity of our results to these parameter settings. Impact of T . SSA computes the similarity measure S( D, D) every T time units. The smaller the value of T , the more realtime is SSA's anomaly detection. However, if T is too small, there may be too few data points for SSA to accurately capture the pattern of a long-duration anomaly. Thus, T controls the trade-off between (near) real-time anomaly detection and the accuracy of detecting long-duration anomalies.</p><p>To characterize the sensitivity of SSA's accuracy to T , we ran SSA using different values of T . For the SensorScope datasets, we used T values ranging from 30 min (the time to collect 15 data points) to 8 h (the time to collect 240 data points). For the Jug Bay datasets, we varied T from 2 h (the time to collect 6 data points) to 24 h (the time to collect 72 data points).</p><p>We found that changing T 's value did not affect SSA's accuracy with respect to the Change in average and Change in variance anomalies, but it did affect the accuracy with respect to the Change in shape anomalies. We show examples of SSA's performance in detecting instances of the Change in shape anomaly in the SensorScope 2 and Box Humidity 1 time series (for different T values) in Table <ref type="table" target="#tab_8">5</ref>(a) and (b), respectively. Very small T values (corresponding to few data points in a linearization period) result in a significant number of false positives. As T grows, the number of false positives improves and becomes reasonably insensitive to T . The false negative rate is quite insensitive to the value of T , with a small increase for very large values of T . Intuitively, this can be explained as follows. For a small value of T , SSA considers only a few data points at a time, and even small differences in these data points (e.g., due to measurement noise) can cause SSA to misclassify these points as an instance of a Change in shape anomaly, resulting in an increase in the false positive rate. <ref type="foot" target="#foot_3">4</ref> The small increase in false negatives for large values of T is due to very short duration Change in shape anomalies being ''averaged out'' (with a large T ).</p><p>In summary, our evaluation shows that our method is not sensitive to the linearization period T , provided that it is long enough to collect a reasonable number of data points. The main reason for this is that, beyond a certain value of T , our similarity metric S(D new , D ref ) does not change significantly with T , as illustrated next.</p><p>For a fixed T value, we ran SSA on SensorScope 1 and SensorScope 2 separately, and recorded the similarity values (with respect to the reference time series) computed every T time units. For example, for T = 1 h, SSA computes a similarity value for new data points collected every hour using Eq. ( <ref type="formula" target="#formula_3">1</ref>). We then computed the mean and the variance of the differences in the similarity values for different values of T for SensorScope 1 (and separately for SensorScope 2). For example, consider a set of SensorScope 1 data points collected over 2 h. Let α 2 be the similarity value for these data points when T = 2 h, and for T = 1 h, let α 11 and α 12 be the similarity values for data points collected during the first and the second hour, respectively. The mean and variance of the differences in the similarity values for T = 1 h and T = 2 h are computed using the values Table <ref type="bibr">6(a)</ref> shows the results, where |S q [t] -S r [t]| is the difference in similarity values corresponding to T = q h and T = r h and the (x, y) entry is the corresponding mean and variance of that difference. The similarity values for T ≥ 2 are close, but the similarity values for T = 1 h are different from those for T = 2 h. Recall that SSA compares similarity values against a threshold to detect anomalies. Hence (for SensorScope 1 and SensorScope 2), SSA's performance with T = 1 h differs from its performance with T = 2 h; but for T ≥ 2, SSA's performance is insensitive to the choice of T . We observed a similar behavior for the other SensorScope time series. For the Jug Bay dataset, we observed similar behavior for T ≥ 12 h.</p><p>The range of T values over which SSA's performance is insensitive is different for the SensorScope and Jug Bay datasets primarily because of the differences in sampling intervals (2 min for SensorScope and 20 min for Jug Bay). So, it makes sense that it takes much longer to collect a sufficient number of samples in the Jug Bay datasets and hence requires a larger T to achieve robust SSA performance.</p><p>Impact of ϵ. As discussed in Section 2.4, for n data points collected during an interval of length T , the worst-case running time of our linearization algorithm is O(n 2 ). Such worst-case scenarios arise when a small number of line segments are sufficient to model all n data points. That is, in the extreme case where a single line segment is sufficient to cover all the n data points, our greedy approach will be forced to solve larger and larger instances of the least-squares regression problem in each iteration-the first iteration will have 2 samples, the second 3 samples, and the (n -1)th will have n samples, resulting in O(n 2 ) complexity. At the other extreme is the case where each pair of consecutive samples defines a new line segment, leading to O(n) line segments and O(n) computation. The number of line segments, k, used to model a sensor data time series depends on the desired linearization error ϵ. Intuitively, a small value of ϵ will force us to use more line segments, which would lead to a lower computational cost. However, the communication overhead of our approach is O(k). Thus, ϵ controls the trade-off between computational cost and communication overhead (or size of the model).</p><p>We found that in practice (e.g., in SensorScope and Jug Bay datasets) a small value of ϵ results in each line segment covering a small number of points. Intuitively, this happens as typically sensor readings exhibit non-linear patterns (e.g., diurnal or sharp increases in value when an event occurs), and approximating non-linear patterns using line segments results in only a few points being covered by a single line. <ref type="bibr">Table 6(b)</ref> shows the average number of line segments used to model 120 data points collected when T = 4 h, for SensorScope 1 and SensorScope 2, for different ϵ values. As the ϵ value is reduced from 1 to 0.01, the average number of line segments increases from 1.85 (1.98) to 92.55 (86.51) for SensorScope 1 (SensorScope 2). (Note that we can use at most 119 line segments to model 120 data points.) Table <ref type="table" target="#tab_9">6</ref>(b) shows our linearization approaches running time (on a PC with a 2.8 GHz processor with 2 GB of RAM) on the entire time series; as expected, it is smaller for smaller ϵ values.</p><p>Table <ref type="table" target="#tab_9">6</ref>(b) results support our intuition that choosing a small value for ϵ results in faster execution time. However, the overhead of the communication between a mote and its master is O(k) (Section 2.4)-a small value of ϵ reduces the computation time at the expense of a larger communication overhead. In scenarios where the aggregator step does not boost the accuracy of SSA (as is the case with SensorScope and the Jug Bay datasets; Section 4.1), we can either do away with the aggregator step or invoke it less frequently than after every T minutes. This can help us reduce the computational cost of the local step (by selecting a small ϵ) while not incurring a significant communication overhead.</p><p>The choice of ϵ can also determine how well a sensor time series is approximated by our piecewise linear model. Intuitively, we should choose an ϵ value that is very small compared to the threshold γ against which the similarity measure S(D new , D ref ) is compared to detect anomalies (see Section 2). With ϵ ≪ γ , it is unlikely that linearization errors will significantly impact the similarity measure, and hence not impact the accuracy of SSA. <ref type="foot" target="#foot_4">5</ref> In this paper, we conservatively set ϵ = 0.1. We also investigated how ϵ affects SSA's accuracy by trying different values between 0.1 and 1 for it, and found that the accuracy of SSA was the same for the different values of ϵ. As shown in Table <ref type="table" target="#tab_9">6</ref>(b), ϵ = 0.1 achieves a good computational cost versus communication overhead trade-off-choosing a smaller value did not reduce the running time significantly but led to a large increase in the number of line segments k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">CPU and memory usage</head><p>In Section 2.4, we discussed the computation complexity and overhead of SSA. We also measured the running time and memory usage of SSA on a low-end netbook with Atom 1.6 GHz processor and 1.5 GB of RAM. The processing power and  available memory of this netbook are comparable to that of the emerging master class devices used in today's tiered sensor network deployments <ref type="bibr" target="#b10">[11]</ref>. We first ran a monitoring program in the background, and then ran SSA over all 23 time series in the SensorScope datasets. We recorded the running time for each times series. The monitoring program also records the memory usage by SSA every second. We performed two sets of experiments with different linearization period T . In Fig. <ref type="figure" target="#fig_9">4</ref>(a), we show the maximum running time and memory usage of SSA over all the 23 time series. For both T = 60 and 120, SSA takes less than 5 s to process approximately 30,000 samples with a small memory footprint. These results show that the computation and memory requirements of SSA are small and well within the resources available on today's master class devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Robustness evaluation</head><p>Data faults are quite prevalent in real-world sensor system deployments <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">6]</ref> and can be caused by bugs in hardware or software, improper sensor calibration, or due to motes running out of battery power <ref type="bibr" target="#b4">[5]</ref>. Hence, in a real-world scenario, it is quite likely that the reference time series D ref [t] using new sensor data, we do not discard the anomalous readings. With an anomaly-free reference time series initially, as a result of updating it with these anomalous data points, the reference time series may eventually exhibit the same pattern as the anomalous readings. For example, we observed an instance of this problem in a time series from the SensorScope datasets, as described next.</p><p>Fig. <ref type="figure" target="#fig_9">4</ref>(b) (top plot) shows a SensorScope time series with a long-duration Constant reading anomaly that lasted for 6 days. The bottom plot in Fig. <ref type="figure" target="#fig_9">4</ref>(b) shows the readings identified as anomalous by SSA alone and the rule-based methods. SSA is able to correctly identify the samples corresponding to the start and the finish of the Constant reading anomaly but misses most of the ''in-between'' anomalous samples. This is due to our design choice to update D ref [t] using anomalous samples as well. We can see in Fig. <ref type="figure" target="#fig_9">4</ref>(b) (top plot) that after (approximately) 400 successive samples corrupted by the Constant reading anomaly, the reference time series values are quite close to the anomalous readings, and as a result, SSA does not stops flagging the subsequent readings as anomalous. In Section 2, we justified our use of anomalous readings to update D ref</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[t]</head><p>by demonstrating that it helps us ''zoom in'' on samples where the sharp changes in sensor readings happen (see Fig. <ref type="figure" target="#fig_7">2(a)</ref>). However, as this example shows, updating D ref [t] using anomalous readings can cause SSA to miss a large number of samples affected by a long-duration anomaly, and only identify the beginning and end of a long-duration anomalous event. This again motivates the use of our hybrid approach-i.e., for the time series in Fig. <ref type="figure" target="#fig_9">4</ref>(b) (bottom plot), we identify the samples missed by SSA using the Constant rule.</p><p>The SensorScope time series in Fig. <ref type="figure" target="#fig_9">4</ref>(b) (top plot) also contains two instances of Short spikes (that occur before the longduration Constant anomaly). Even though SSA alone fails to detect them, their presence does not impair SSA's ability to detect the long-duration anomaly that occurs later. Hence, we do not need to ''clean'' the time series data before running SSA. We can see in Fig. <ref type="figure" target="#fig_9">4</ref>(b) (top plot) that the Short faults do not affect the reference time series significantly, i.e., SSA is robust to faults.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related work</head><p>Anomaly detection is an area of active research. In this section we briefly survey work most related to ours, organized into four categories. Moreover, we select representative techniques from these categories and quantitatively compare them against our hybrid approach, with results of this comparison presented in Section 6. Anomaly detection in sensor systems. This is not a well-studied area. The only efforts we are aware of that focus on anomaly detection in sensor systems data are <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. Rajasegarar et al. <ref type="bibr" target="#b6">[7]</ref> present a clustering-based method based on the K nearestneighbor algorithm in <ref type="bibr" target="#b6">[7]</ref>, and an SVM-based approach in <ref type="bibr" target="#b7">[8]</ref>. Briefly, these works view measurements collected by a sensor system as coming from the same (unknown) distribution and ''pre-define'' anomalies as outliers, with main focus of these (offline) techniques being on minimizing the communication overhead (in transmitting data needed for anomaly detection) and the corresponding energy consumption. In contrast, we focus on an online approach, without ''pre-defining'' what is an anomaly. However, we do perform a quantitative comparison between our hybrid approach and the clustering-based method in <ref type="bibr" target="#b6">[7]</ref>. The details of this comparison can be found in Section 6.</p><p>Tartakovsky et al. use a change point detection-based approach, CUSUM (Cumulative Sum Control Chart), for quickly detecting distribution changes (e.g., mean, variance, covariances) in sensor measurements <ref type="bibr" target="#b8">[9]</ref>. We do not provide a quantitative comparison between CUSUM and our hybrid approach as we lack sufficient domain knowledge-i.e., the CUSUM-based approach assumes knowledge of the (time-varying) probability distribution from which sensor measurements are sampled, and such information is not provided for the SensorScope and the Jug Bay datasets (and would be quite difficult for us to compute accurately).</p><p>In general, change point detection can identify changes in the parameters of a stochastic process. Often, such changes are anomalous, and hence change point detection techniques have been used for change/outlier detection in time series data <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b14">16]</ref>. However, such existing works (a) assume that the sensor measurements are sampled from a known or easily inferred distribution (e.g., Gaussian), an assumption often not true for real-world datasets, (b) target a specific subset of anomalies, and (c) do not use real-world sensor datasets for evaluation. In addition, existing change point detection-based methods either require a long training phase, or are computationally intensive, or (in some cases) both-hence, they do not meet our efficiency criteria. Moreover, not all changes in a time series might be anomalous, i.e., there could be a change and no anomaly (i.e., a false positive) and vice versa (i.e., a false negative). For example, <ref type="bibr" target="#b13">[15]</ref> flags turning points of a time series from increasing to decreasing-as it is often ''normal'' for a sensor data time series to have periodic behavior, this is (likely) not an anomaly. On the other hand, such an approach would only flag a few turning points, instead of an entire anomalous event, as depicted in Fig. <ref type="figure" target="#fig_1">1(a)</ref>. We believe that change point detection could be a promising approach to anomaly detection, but that it would require significant work to devise an accurate and efficient online anomaly detection method based on such techniques. Fault detection in sensor systems. Short-duration anomalies can be viewed as instances of data faults, errors in measurements, or outliers (see <ref type="bibr" target="#b4">[5]</ref>). Sharma et al. focus on Short spikes, Noise faults, and Constant readings data faults and show that these are quite prevalent in real-world sensor datasets <ref type="bibr">[6]</ref>. They also evaluate the performance of several methods -rulebased methods, a least-squares estimation-based method, Hidden Markov model (HMM)-based method, and a time series analysis (ARIMA model)-based method -that are targeted towards detecting transient sensor data faults. However, these methods perform poorly in detecting long-duration anomalies. e.g., in Section 4.1 we showed that rule-based methods are not sufficient for detecting long-duration anomalies. Other than that, we also compare the ARIMA model-based approach, which works best in case of data faults affecting more than a few samples, against our hybrid approach (with details given in <ref type="bibr">Section 6)</ref>.</p><p>Other approaches to sensor data faults detection include <ref type="bibr" target="#b15">[17]</ref><ref type="bibr" target="#b16">[18]</ref><ref type="bibr" target="#b17">[19]</ref><ref type="bibr" target="#b18">[20]</ref>. However, these are not suited for detecting (unknown) long-duration anomalies due to one or more of the following assumptions they make: (1) the anomalous data pattern is known a priori <ref type="bibr" target="#b15">[17]</ref><ref type="bibr" target="#b16">[18]</ref><ref type="bibr" target="#b17">[19]</ref>, (2) the distribution of normal sensor readings is known <ref type="bibr" target="#b17">[19]</ref>, and (3) focusing on short-duration trends is enough to capture anomalies <ref type="bibr" target="#b18">[20]</ref>. Network anomaly detection. The work in this area includes detecting anomalies such as DDoS attacks, flash crowds, worm propagating, bulk data transfer in enterprise or ISP networks <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. Techniques such as Principal Component Analysis (PCA) <ref type="bibr" target="#b0">[1]</ref> and wavelet analysis <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>, used for detecting network traffic anomalies, are not well suited for online detection in sensor systems primarily because they are computationally intensive and difficult to perform in an online manner. Furthermore, we show that, even in an offline manner, these methods perform poorly in detecting a long-duration anomaly on sensor system data (as detailed in Section 6). Our quantitative study (given in Section 6) indicates that a straightforward application of such techniques, as designed for network anomaly detection, is not very effective on sensor data. Piecewise linear time series models. Piecewise linear models have been used to model time series data in the other contexts (i.e., not for anomaly detection). For example, Keogh developed an efficient technique to search for occurrences of a known pattern within a time series using a piecewise linear representation <ref type="bibr" target="#b9">[10]</ref>. Specifically, for a time series with n points, Keogh's algorithm starts with k =  n 3  line segments and defines a ''goodness of fit'' metric for k line segments as</p><formula xml:id="formula_9">B k = std(e 1 , . . . , e k )</formula><p>, where e i is the average linearization error for line segment i. It then iteratively merges two consecutive line segments until B k cannot be reduced any further; this process is continued until a single line approximates the entire time series. This process ends with a family of piecewise linear models for a single time series-one for each value of</p><formula xml:id="formula_10">k, 1 ≤ k ≤  n 3 </formula><p>. Each linear model has a B k value associated with it, and the one with the smallest B k is selected as the final representation.</p><p>In contrast, our greedy linearization algorithm differs as follows: (1) we start with a single line segment and continue adding more segments, (2) we use a different ''goodness of fit'' criterion (maximum linearization error; see Section 2) and (3) we compute a single representation instead of a family of piecewise linear models. The main reason behind these choices (rather than, for example, using Keogh's algorithm) is computational cost, as our goal is an efficient online approach. Briefly, computing a family of models to find the ''best'' one is wasteful for our purposes, if it takes significantly greater computation. Hence, we opt for our greedy approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Quantitative comparison</head><p>We now present results from a quantitative comparison of our hybrid approach and anomaly detection techniques based on ARIMA models <ref type="bibr">[6]</ref>, PCA <ref type="bibr" target="#b0">[1]</ref>, wavelet decomposition <ref type="bibr" target="#b2">[3]</ref>, and K -means clustering <ref type="bibr" target="#b6">[7]</ref>. As noted above, these techniques have proven to be effective at detecting sensor data faults and network anomalies. However, our evaluation shows that an ''out-of-a-box'' application of these techniques for detecting sensor system anomalies performs poorly. Comparison with the ARIMA-based method. ARIMA (Autoregressive Integrated Moving Average) models are a standard tool for modeling and forecasting time series data with periodicity <ref type="bibr" target="#b19">[21]</ref>, and <ref type="bibr">[6]</ref> leverages temporal correlations in sensor measurements to construct an ARIMA model of sensor data. This model is used to predict the value of future readings, with new sensor readings compared against their predicted value-if the difference between these values is above a threshold (the 95% confidence interval for the predictions) then the new data is marked as anomalous. We compare our hybrid approach against the ARIMA L-step method from <ref type="bibr">[6]</ref>, where the ARIMA model is used to predict the next L sensor readings.</p><p>We first trained the ARIMA model to estimate its parameters using sensor readings (from SensorScope 1 and SensorScope 2) collected over 3 days as training data (a separate training phase was required for SensorScope 1 and SensorScope 2; <ref type="bibr">[6]</ref> also uses training data from 3 days; these are more favorable conditions for ARIMA as SSA uses a shorter period for its reference model). The ARIMA L-step method with L = 24 h flagged 12,135 (of the 30,356 data points in SensorScope 1) as anomalies. Our inspection revealed a total of 107 anomalies that affect more than 7500 data points. While the ARIMA L-step method identified most anomalous samples, it also falsely identified a large number of samples as anomalous. The extremely high number of false positives resulting from the ARIMA L-step method reduces its utility.</p><p>We failed to train ARIMA on SensorScope 2 due to the training data containing a Constant readings anomaly that affects almost two-thirds of the samples. This failure highlights the lack of robustness in ARIMA-based methods to long-duration anomalies in the training data. SSA's counterpart to the ARIMA training phase is the selection of an initial reference time series, and SSA tolerates anomalies in its initial reference time series (see Section 4.4). Comparison with network anomaly detection techniques. Techniques such as Principal Component Analysis (PCA) <ref type="bibr" target="#b0">[1]</ref>, and wavelet analysis <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4]</ref> used for detecting network traffic anomalies are not well suited for online detection in sensor systems primarily because they are computationally intensive and difficult to perform in an online manner. However, one can still ask: How accurately would those techniques perform on sensor system data, i.e., in an offline manner? As a reasonably representative technique, we use the PCA-based approach in <ref type="bibr" target="#b0">[1]</ref>, which collects periodic measurements of the traffic on all network links and splits it into ''normal'' and ''residual'' traffic using PCA. The residual traffic is then mined for anomalies using the Q -statistic test in which L2-norm ‖y‖ 2 of the residual traffic vector y for a link is compared against a threshold. If it is greater than the threshold, then the traffic vector y is declared anomalous <ref type="bibr" target="#b0">[1]</ref>.</p><p>We ran the PCA-based method on the data from SensorScope time series 6, 8, 9, 10, 11, and 12. We chose these as their start and end times are the same. The input to PCA was a data matrix with 6 columns (one for each sensor) and 29,518 rows (the total number of samples collected). Note that the PCA-based method is applied in an offline fashion using the entire time series data from 6 different sensors whereas in our SSA-based hybrid approach, at best, the aggregator step would get access to linear models from 6 sensors during the past T = 4 h only.</p><p>The results for the PCA-based method are summarized in Table <ref type="table" target="#tab_10">7</ref>. It fails to detect most long-duration anomalies (5 out of 38 Change in mean anomalies and 4 out of 67 Change in shape anomalies). It does better at detecting Short spikes but is still not as accurate as our hybrid approach. Thus, even under a best-case scenario (offline with access to the entire time series), the PCA-based method does not perform as well as our hybrid approach. Recall that it identifies anomalies by looking at the L2-norm of the data vector in the residual space. As pointed out in <ref type="bibr" target="#b0">[1]</ref>, the PCA-based method works best when the intensity of an anomaly is large compared to the variability of the normal data. This is not the case with most of the longduration anomalies present in the sensor data analyzed in Table <ref type="table" target="#tab_10">7</ref>. For instance, Fig. <ref type="figure" target="#fig_11">5</ref>(a) shows a Change in mean anomaly in SensorScope 12 time series that the PCA-based method fails to detect. It also shows a Short anomaly (spike) that the PCA-based method is able to detect.</p><p>To further illustrate the impact of anomalies' intensities on the accuracy of a PCA-based method, we injected anomalies (Short, Noise, and Constant) into the time series SensorScope 9, and attempted to detect these injected faults using PCA. The data samples corrupted by Short and Noise anomalies had a higher variance as compared to the normal data whereas, by definition, the variance of the samples corrupted by the Constant anomaly was lower than the normal data. We found that the PCA-based method was able to detect most of the samples corrupted by Short and Noise anomalies, but missed the Constant anomaly. We do not present these here due to lack of space; these results can be found in our technical report <ref type="bibr" target="#b20">[22]</ref>.</p><p>Apart from the intensity of an anomaly, the PCA results might also be impacted by several other factors such as sensitivity of PCA to its parameters and lack of data preprocessing. For instance, <ref type="bibr" target="#b21">[23]</ref> shows that the performance of PCA is sensitive to the number of principal components included in the normal subspace, and the threshold used for anomaly detection. We note that, in our experiments, we did vary the number of principal components in the normal subspace, and Table <ref type="table" target="#tab_10">7</ref> depicts the best results obtained (i.e., those with having only one principal component in the normal space). To our knowledge, the Q -statistic-based technique that we use here is the only known method for automatically deciding the detection threshold. It is also well known that anomalies can contaminate the normal subspace, and hence avoid detection by PCA <ref type="bibr" target="#b21">[23]</ref>. One way to ameliorate this situation can be to preprocess the data to identify and remove large anomalies before applying PCA. However, in our context, defining a large anomaly would itself have required us to introduce another heuristic (with its own shortcomings). We do not pursue this (or other PCA-related improvements) further, as the main goal of our PCA-based evaluation here was to illustrate that, as in the case of network anomaly detection, it is not straightforward to apply PCA to detect anomalies in sensor data. (This partly contributed to our choice of a different approach.) Of course, we do not claim that the PCA-based method cannot be made more effective at detecting sensor data anomalies, but, as noted, this is not the goal of our work here.   To the same end, we also explored wavelet-based methods for detecting sensor data anomalies. We selected the method presented in <ref type="bibr" target="#b2">[3]</ref> as a representative technique. This method first separates a time series of network data (e.g., aggregate byte counts on a link) into low-, medium-, and high-frequency components using wavelet decomposition. To detect anomalies, first a (time-varying) deviation score is computed by combining the local variance of the medium-frequency and highfrequency components. Local variance is defined as the variance of the data falling within a moving time window. The deviation score is then compared against a threshold to detect anomalies.</p><p>We ran the wavelet-based anomaly detection method described above on the same set of data that we used for evaluating the PCA-based method. The results are summarized in Table <ref type="table" target="#tab_11">8</ref>. While the wavelet-based method detects more anomalies as compared to PCA, it does not perform as well as our hybrid approach in detecting long-duration anomalies. In particular, it fails to detect most of the Change in mean and Change in shape anomalies. In our evaluation, this method also incurred a large number of false positives. One possible reason for the wavelet-based method not being very effective on the SensorScope dataset could be that it looks for anomalies in the medium-frequency and high-frequency components of a time series, whereas the long-duration anomalies fall into the low-frequency component. The top plot in Fig. <ref type="figure" target="#fig_11">5</ref>(b) shows a Change in mean anomaly in SensorScope 11 time series that is captured by the low-frequency component shown in the bottom plot. Hence, it is difficult for previously proposed wavelet-based methods that mine for anomalies only in the medium-frequency and high-frequency components <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4]</ref> to detect such anomalies. These approaches can possibly be extended using heuristic(s) that mine for anomalies in the low-frequency component. We do not pursue this (or other improvements to the waveletbased approach) further as, like in the case of PCA, the main goal of our wavelet-based evaluation of sensor data was to demonstrate that a straightforward application of a wavelet-based technique designed for network anomaly detection is not very effective on sensor data. Of course, we do not claim that wavelet-based techniques cannot be made to work on sensor data, but, as noted, that is not the goal of our work here. Comparison with the clustering-based method. We compare our hybrid approach with the clustering-based method in <ref type="bibr" target="#b6">[7]</ref>, which first groups the vector of readings from several sensors into clusters of fixed width. After this, the average inter- cluster distance between a cluster and its K nearest-neighboring clusters is used to determine the abnormal clusters. 6 We ran this method on SensorScope time series 6, 8, 9, 10, 11 and 12. The inputs to the clustering method are vectors of readings with the same time stamp from the 6 time series. We found that the performance of this method depends strongly on the cluster width w, as also noted in <ref type="bibr" target="#b6">[7]</ref>. We tried a large number of w values (from 0.03 to 8) and used the best results found to compare with our method. This method can only identify which data vectors contain anomalies, but cannot identify anomalous readings within a data vector. We determine the number of detections and false negatives as in the PCA-based method; so, it is not possible to report false positives for individual time series. This method did incorrectly flag 18 data vectors as anomalous; the actual number of false positives is between 18 and 108. We give detailed results in Table <ref type="table" target="#tab_12">9</ref> and note that the cluster-based method performs poorly in detecting long-term anomalies such as Change in mean, Change in shape, and Constant. Intuitively, this is because this method is designed to detect outliers and does not exploit temporal correlations within the time series. We can also see that the method has a lot of false negatives in detecting Short spikes. This makes sense as a spike is determined by the corresponding data point's relative position to the previous and next point, but in the cluster-based method all data points are considered as a whole and this temporal relationship is lost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>We have proposed an online anomaly detection approach for sensor system measurements. Our approach utilized piecewise linear models of time series, which are succinct, representative, and robust, and therefore enabled us to (a) compute such models in near real-time, (b) create models without prior knowledge about anomaly types that sensor data might contain, and (c) compare and communicate different time series efficiently. Our extensive evaluation study, using real sensor system deployment data, illustrated that our approach is accurate, robust, and efficient. Future work includes study of (1) dynamic setting of parameters (e.g., the linearization period and the size of the initial reference model), <ref type="bibr" target="#b1">(2)</ref> feedback mechanisms between the local and aggregation steps of our approach, and (3) other techniques that are useful in our hybrid approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Long-duration anomaly. (b) Piecewise linear model for time series data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Dataset with long-duration anomaly and (b) example of a piecewise linear model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Reference time series. (b) Short anomalies (marked by rectangles).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples of anomalies in sensor readings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Soil moisture readings, constant, change in variance and change in shape anomalies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 (</head><label>2</label><figDesc>Fig.2(a) depicts the time series of humidity readings collected by a sensor from the Jug Bay deployment [13] along with two reference time series for it, constructed using T = 12 h (36 data points with one data point collected every 20 min). The reference time series, labeled ''Reference time series (including anomalous readings)'', is computed using both non-anomalous and anomalous readings in D new[t] to update the reference time series, while the ''Reference time series (excluding anomalous readings)'' excludes the anomalous readings in D new[t]. The humidity measurements contain two anomalies-sharp changes in the sensor reading (marked by bounding rectangles in Fig.2(a)) which cause the humidity readings to increase sharply and then decay over time. It is important to detect these sharp changes in sensor readings.As shown in Fig.2(a), excluding the anomalous readings in D new [t] when updating the reference time series causes D ref [t]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>m</head><label></label><figDesc>[t] is robust and works well in practice. Aggregation step. After performing its local step, each mote m sends its linear model, {(X new m [i], Y new m [i]), i = 1, . . . , k}, for the new sensor readings, D new m [t], and the results of its local anomaly detection step to its master node. For each mote m, the master node performs another round of anomaly detection by comparing its linear model against the models from other motes (treating them as reference). Hence, a master node managing n slave motes performs O(n 2 ) model comparisons. The design of our aggregation step is based on the observations from several real-world deployments that often the readings from sensors deployed at different locations are correlated [12]. The aggregation step exploits these spatial correlations to detect additional anomalies (if any) that might not have been detected during the local step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>|α 2 -</head><label>2</label><figDesc>α 11 | and |α 2 -α 12 |. These values capture the difference in the similarity values associated with a set of data points for different T values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a) Running time and memory usage of SSA. (b) Dataset with faulty readings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a) Resource usage of SSA and (b) dataset with faulty readings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>[t] used by SSA may itself contain anomalous readings. Note that, as described in Section 2.3, when updating D ref</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Detection of long duration anomalies: PCA-based and wavelet-based methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>We first look for anomalies in the new sensor readings D new [t], and then use the data points in D</figDesc><table /><note><p>construct or update a reference time series, D ref m [t], for its sensor readings, (2) collect new sensor readings {D new m [t], t = 1, 2, . . . , T } over a period T , (3) construct or update linear models for D new m [t] and D ref m [t], and (4) perform anomaly detection using the SSA-based method (refer to Section 2.2). Reference time series. To construct a reference time series at mote m, D ref m [t], we use the following approach. For physical phenomena such as ambient temperature or humidity variations that exhibit a diurnal pattern, we initially start with a time series D[t] consisting of measurements collected over a period of 24 h, (say) on day 1 of the deployment. Let D new [t] be the new sensor readings collected by mote m over time period T corresponding to (say) 9:00-9:30 a.m. on day 2 of the deployment. For these new readings, we define the data points in D[t] that were collected between 9:00 and 9:30 a.m. (on day 1) as D ref [t]. new [t] to update D ref [t] using weighted averaging. For example, we can use exponential weighted moving averaging to (pointwise) update D ref [t], i.e., Dref [</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>To detect Short anomalies in the time series {D[t], t = 1, 2, 3, . . .}, we keep track of the change in sensor readings between two successive samples, |D[t] -D[t -1]|. If this value is larger than a threshold σ s , then we flag D[t] as anomalous. To detect Constant anomalies we calculate moving variance statistics of time series</figDesc><table><row><cell>Constant rule:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1</head><label>1</label><figDesc>Anomaly categories.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2</head><label>2</label><figDesc>Hybrid method: SensorScope.</figDesc><table><row><cell>Dataset</cell><cell>Change in mean</cell><cell>Change in var</cell><cell>Change in shape</cell><cell>Short</cell><cell>Constant</cell><cell>False positives</cell></row><row><cell>SensorScope 1</cell><cell>3/4</cell><cell>0/0</cell><cell>6/7</cell><cell>90/90</cell><cell>2/2</cell><cell>7</cell></row><row><cell>SensorScope 2</cell><cell>8/8</cell><cell>0/0</cell><cell>6/7</cell><cell>86/86</cell><cell>6/6</cell><cell>6</cell></row><row><cell>SensorScope 3</cell><cell>7/7</cell><cell>2/2</cell><cell>9/10</cell><cell>64/64</cell><cell>5/5</cell><cell>12</cell></row><row><cell>SensorScope 4</cell><cell>5/5</cell><cell>2/2</cell><cell>12/13</cell><cell>220/222</cell><cell>13/13</cell><cell>27</cell></row><row><cell>SensorScope 5</cell><cell>6/6</cell><cell>4/4</cell><cell>9/9</cell><cell>726/819</cell><cell>34/34</cell><cell>0</cell></row><row><cell>SensorScope 6</cell><cell>7/7</cell><cell>0/0</cell><cell>8/10</cell><cell>206/206</cell><cell>1/1</cell><cell>7</cell></row><row><cell>SensorScope 7</cell><cell>8/8</cell><cell>4/4</cell><cell>12/12</cell><cell>555/567</cell><cell>54/54</cell><cell>0</cell></row><row><cell>SensorScope 8</cell><cell>6/6</cell><cell>0/0</cell><cell>9/10</cell><cell>243/243</cell><cell>2/2</cell><cell>4</cell></row><row><cell>SensorScope 9</cell><cell>6/6</cell><cell>2/2</cell><cell>11/12</cell><cell>65/65</cell><cell>23/23</cell><cell>6</cell></row><row><cell>SensorScope 10</cell><cell>5/5</cell><cell>0/0</cell><cell>10/12</cell><cell>46/46</cell><cell>2/2</cell><cell>3</cell></row><row><cell>SensorScope 11</cell><cell>7/7</cell><cell>0/0</cell><cell>8/10</cell><cell>122/122</cell><cell>1/1</cell><cell>6</cell></row><row><cell>SensorScope 12</cell><cell>7/7</cell><cell>0/0</cell><cell>11/13</cell><cell>84/84</cell><cell>13/13</cell><cell>7</cell></row><row><cell>SensorScope 13</cell><cell>8/8</cell><cell>2/2</cell><cell>13/14</cell><cell>250/250</cell><cell>15/15</cell><cell>5</cell></row><row><cell>SensorScope 14</cell><cell>5/5</cell><cell>4/4</cell><cell>5/7</cell><cell>595/633</cell><cell>26/26</cell><cell>19</cell></row><row><cell>SensorScope 15</cell><cell>6/6</cell><cell>2/2</cell><cell>8/9</cell><cell>464/475</cell><cell>24/24</cell><cell>12</cell></row><row><cell>SensorScope 16</cell><cell>4/4</cell><cell>2/2</cell><cell>7/7</cell><cell>120/120</cell><cell>12/12</cell><cell>25</cell></row><row><cell>SensorScope 17</cell><cell>5/5</cell><cell>4/4</cell><cell>6/6</cell><cell>166/166</cell><cell>17/17</cell><cell>13</cell></row><row><cell>SensorScope 18</cell><cell>6/7</cell><cell>2/2</cell><cell>16/18</cell><cell>56/56</cell><cell>9/9</cell><cell>12</cell></row><row><cell>SensorScope 19</cell><cell>3/3</cell><cell>0/0</cell><cell>4/6</cell><cell>98/98</cell><cell>1/1</cell><cell>15</cell></row><row><cell>SensorScope 20</cell><cell>3/3</cell><cell>0/0</cell><cell>3/4</cell><cell>77/78</cell><cell>1/1</cell><cell>9</cell></row><row><cell>SensorScope 21</cell><cell>2/2</cell><cell>1/1</cell><cell>3/4</cell><cell>332/337</cell><cell>26/26</cell><cell>5</cell></row><row><cell>SensorScope 22</cell><cell>3/3</cell><cell>0/0</cell><cell>3/5</cell><cell>88/88</cell><cell>1/1</cell><cell>11</cell></row><row><cell>SensorScope 23</cell><cell>3/3</cell><cell>0/0</cell><cell>4/4</cell><cell>84/84</cell><cell>2/2</cell><cell>17</cell></row><row><cell>Total</cell><cell>121/123</cell><cell>31/31</cell><cell>183/209</cell><cell>4837/4999</cell><cell>290/290</cell><cell>238</cell></row></table><note><p>course of 43 days, a total of 84 instances of Change in mean and 139 instances of Change in shape anomalies occurred in the SensorScope datasets; on average, 2 instances of Change in mean and 3 instances of Change in shape anomalies per day.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3</head><label>3</label><figDesc>Hybrid method: Jug Bay.</figDesc><table><row><cell>Dataset</cell><cell>Change in mean</cell><cell>Change in var</cell><cell>Change in shape</cell><cell>Short</cell><cell>Constant</cell><cell cols="2">False positives</cell></row><row><cell>Soil moisture 1</cell><cell>7/8</cell><cell>1/1</cell><cell>8/10</cell><cell>53/55</cell><cell>1/1</cell><cell>0</cell><cell></cell></row><row><cell>Soil moisture 2</cell><cell>8/9</cell><cell>1/1</cell><cell>9/11</cell><cell>74/74</cell><cell>1/1</cell><cell>2</cell><cell></cell></row><row><cell>Soil moisture 3</cell><cell>5/5</cell><cell>0/0</cell><cell>6/7</cell><cell>42/42</cell><cell>0/0</cell><cell>4</cell><cell></cell></row><row><cell>Box humidity 1</cell><cell>2/2</cell><cell>4/4</cell><cell>18/19</cell><cell>15/15</cell><cell>0/0</cell><cell>2</cell><cell></cell></row><row><cell>Box humidity 2</cell><cell>5/5</cell><cell>7/7</cell><cell>27/28</cell><cell>16/16</cell><cell>2/2</cell><cell>2</cell><cell></cell></row><row><cell>Box humidity 3</cell><cell>3/3</cell><cell>2/2</cell><cell>1/1</cell><cell>17/17</cell><cell>2/2</cell><cell>3</cell><cell></cell></row><row><cell>Total</cell><cell>30/32</cell><cell>15/15</cell><cell>69/76</cell><cell>217/219</cell><cell>6/6</cell><cell>13</cell><cell></cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">SSA versus rule-based methods.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>Dataset</cell><cell>Change in mean</cell><cell>Change in var</cell><cell>Change in shape</cell><cell>Short</cell><cell>Constant</cell><cell>FP</cell></row><row><cell>SSA</cell><cell>Soil moisture 1</cell><cell>7/8</cell><cell>1/1</cell><cell>8/10</cell><cell>40/55</cell><cell>1/1</cell><cell>0</cell></row><row><cell>SSA</cell><cell>SensorScope 1</cell><cell>3/4</cell><cell>0/0</cell><cell>6/7</cell><cell>46/90</cell><cell>1/2</cell><cell>1</cell></row><row><cell>Rule-based</cell><cell>Box humidity 2</cell><cell>2/5</cell><cell>0/7</cell><cell>5/28</cell><cell>16/16</cell><cell>2/2</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5</head><label>5</label><figDesc>Sensitivity test for T : SSA with different T values; Change of shape anomaly.</figDesc><table><row><cell cols="2">(a) SensorScope 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Box humidity 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>T value</cell><cell>0.5</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>8</cell><cell>T value</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>12</cell><cell>24</cell></row><row><cell>Detected</cell><cell>7/7</cell><cell>7/7</cell><cell>6/7</cell><cell>6/7</cell><cell>6/7</cell><cell>Detected</cell><cell>19/19</cell><cell>19/19</cell><cell>19/19</cell><cell>19/19</cell><cell>18/19</cell><cell>18/19</cell></row><row><cell>FP</cell><cell>8</cell><cell>4</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>FP</cell><cell>17</cell><cell>10</cell><cell>6</cell><cell>4</cell><cell>2</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6</head><label>6</label><figDesc>Robustness to parameters.</figDesc><table><row><cell cols="2">(a) Similarity metric as a function of T</cell><cell></cell><cell>(b) Impact of ϵ</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>SensorScope 1</cell><cell>SensorScope 2</cell><cell>ϵ value</cell><cell>SensorScope 1</cell><cell></cell><cell>SensorScope 2</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell># lines</cell><cell>Running time</cell><cell># lines</cell><cell>Running time</cell></row><row><cell>|S 1 [t] -S 2 [t]|</cell><cell>(1.35, 1.40)</cell><cell>(1.28, 2.05)</cell><cell>0.01</cell><cell>92.55</cell><cell>0.08</cell><cell>86.51</cell><cell>0.10</cell></row><row><cell>|S 2 [t] -S 3 [t]|</cell><cell>(0.22, 0.08)</cell><cell>(0.25, 0.12)</cell><cell>0.05</cell><cell>47.49</cell><cell>0.08</cell><cell>50.50</cell><cell>0.11</cell></row><row><cell>|S 3 [t] -S 4 [t]|</cell><cell>(0.25, 0.11)</cell><cell>(0.29, 0.17)</cell><cell>0.10</cell><cell>25.45</cell><cell>0.10</cell><cell>29.39</cell><cell>0.12</cell></row><row><cell>|S 4 [t] -S 6 [t]|</cell><cell>(0.29, 0.14)</cell><cell>(0.30, 0.20)</cell><cell>0.50</cell><cell>3.38</cell><cell>0.34</cell><cell>3.80</cell><cell>0.29</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1.00</cell><cell>1.85</cell><cell>0.46</cell><cell>1.98</cell><cell>0.40</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7</head><label>7</label><figDesc>PCA-based method: SensorScope.</figDesc><table><row><cell>Dataset</cell><cell>Change in mean</cell><cell>Change in var</cell><cell>Change in shape</cell><cell>Short</cell><cell>Constant</cell></row><row><cell>SensorScope 6</cell><cell>1/7</cell><cell>0/0</cell><cell>2/10</cell><cell>45/206</cell><cell>0/1</cell></row><row><cell>SensorScope 8</cell><cell>1/6</cell><cell>0/0</cell><cell>1/10</cell><cell>59/243</cell><cell>0/2</cell></row><row><cell>SensorScope 9</cell><cell>1/6</cell><cell>1/2</cell><cell>0/12</cell><cell>47/65</cell><cell>4/23</cell></row><row><cell>SensorScope 10</cell><cell>0/5</cell><cell>0/0</cell><cell>0/12</cell><cell>31/46</cell><cell>0/2</cell></row><row><cell>SensorScope 11</cell><cell>1/7</cell><cell>0/0</cell><cell>0/10</cell><cell>33/122</cell><cell>0/1</cell></row><row><cell>SensorScope 12</cell><cell>1/7</cell><cell>0/0</cell><cell>1/13</cell><cell>27/84</cell><cell>6/13</cell></row><row><cell>Total</cell><cell>5/38</cell><cell>1/2</cell><cell>4/67</cell><cell>242/766</cell><cell>22/42</cell></row></table><note><p>(a) SensorScope 12: PCA result. (b) SensorScope 11: Wavelet result.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8</head><label>8</label><figDesc>Wavelet-based method: SensorScope.</figDesc><table><row><cell>Dataset</cell><cell>Change in mean</cell><cell>Change in var</cell><cell>Change in shape</cell><cell>Short</cell><cell>Constant</cell><cell>False positive</cell></row><row><cell>SensorScope 6</cell><cell>1/7</cell><cell>0/0</cell><cell>2/10</cell><cell>205/206</cell><cell>1/1</cell><cell>26</cell></row><row><cell>SensorScope 8</cell><cell>1/6</cell><cell>0/0</cell><cell>2/10</cell><cell>243/243</cell><cell>1/2</cell><cell>24</cell></row><row><cell>SensorScope 9</cell><cell>1/6</cell><cell>2/2</cell><cell>3/12</cell><cell>65/65</cell><cell>13/23</cell><cell>42</cell></row><row><cell>SensorScope 10</cell><cell>1/5</cell><cell>0/0</cell><cell>3/12</cell><cell>46/46</cell><cell>0/2</cell><cell>47</cell></row><row><cell>SensorScope 11</cell><cell>1/7</cell><cell>0/0</cell><cell>2/10</cell><cell>122/122</cell><cell>1/1</cell><cell>29</cell></row><row><cell>SensorScope 12</cell><cell>1/7</cell><cell>0/0</cell><cell>3/13</cell><cell>80/84</cell><cell>9/13</cell><cell>22</cell></row><row><cell>Total</cell><cell>6/38</cell><cell>2/2</cell><cell>15/67</cell><cell>761/766</cell><cell>25/42</cell><cell>190</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9</head><label>9</label><figDesc>Cluster-based method: SensorScope.</figDesc><table><row><cell>Dataset</cell><cell>Change in mean</cell><cell>Change in var</cell><cell>Change in shape</cell><cell>Short</cell><cell>Constant</cell></row><row><cell>SensorScope 6</cell><cell>2/7</cell><cell>0/0</cell><cell>4/10</cell><cell>56/206</cell><cell>1/1</cell></row><row><cell>SensorScope 8</cell><cell>3/6</cell><cell>0/0</cell><cell>5/10</cell><cell>54/243</cell><cell>1/2</cell></row><row><cell>SensorScope 9</cell><cell>3/6</cell><cell>1/2</cell><cell>5/12</cell><cell>20/65</cell><cell>5/23</cell></row><row><cell>SensorScope 10</cell><cell>2/5</cell><cell>0/0</cell><cell>5/12</cell><cell>16/46</cell><cell>1/2</cell></row><row><cell>SensorScope 11</cell><cell>3/7</cell><cell>0/0</cell><cell>6/10</cell><cell>49/122</cell><cell>1/1</cell></row><row><cell>SensorScope 12</cell><cell>3/7</cell><cell>0/0</cell><cell>5/13</cell><cell>36/84</cell><cell>3/13</cell></row><row><cell>Total</cell><cell>16/38</cell><cell>1/2</cell><cell>30/67</cell><cell>243/766</cell><cell>12/42</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Most of these were designed in other contexts, but constitute possible directions that could have been taken for sensor system anomaly detection.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>It is possible to combine other detection methods with SSA to design variants of our hybrid approach; for example,[6]  proposes other techniques, such as HMM-based methods, for detecting sensor data faults. However, other methods in[6]  are much more computationally intensive and require a much longer training phase (than our reference model).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Of course, more sophisticated approaches are possible, but, as our results indicate, this simple approach already results in good accuracy and allows us to focus on the evaluation of SSA, without additional complications.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>The Change in average and the Change in variance anomalies occur over longer periods of time; thus, to cause a false positive corresponding to these anomalies, (random) noise would have to affect a much greater number of samples, which is unlikely to happen.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>As discussed in Section 2, we set γ to be equal to the standard deviation of the initial reference time series; γ for the SensorScope and Jug Bay Box Humidity datasets was within the interval<ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7]</ref> and[6,<ref type="bibr" target="#b8">9]</ref>, respectively.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was funded in part by the NSF 0540420, 0120778, and 0917340 grants. We thank the anonymous reviewers and our shepherd, Anirban Mahanti, for helping us improve the paper. We also thank Fei Sha for his valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Diagnosing network-wide traffic anomalies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>ACM SIGCOMM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combining filtering and statistical methods for anomaly detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Soule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Salamatian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Internet Measurement, IMC</title>
		<meeting>the ACM Conference on Internet Measurement, IMC</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A signal analysis of network traffic anomalies</title>
		<author>
			<persName><forename type="first">P</forename><surname>Barford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Plonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Internet Measurement</title>
		<meeting>the Workshop on Internet Measurement</meeting>
		<imprint>
			<publisher>IMW</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wavelet-based real time detection of network traffic anomalies</title>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thareja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Network Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="309" to="320" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sensor network data fault types</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chehade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Balzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zahedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pottie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Sensor Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sensor faults: detection methods and prevalence in real-world datasets</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Golubchik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Sensor Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Distributed anomaly detection in wireless sensor networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rajasegarar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palaniswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bezdek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>ICCS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Quarter sphere based distributed anomaly detection in wireless sensor networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rajasegarar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palaniswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bezdek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>IEEE ICC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Asymptotically optimal quickest change detection in distributed sensor systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tartakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Veeravalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sequential Analysis</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="441" to="475" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Fast similarity search in the presence of longitudinal scaling in time series databases</title>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>ICTAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An easily deployable wireless imaging system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Paek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ImageSense Workshop</title>
		<meeting>ImageSense Workshop</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An SVM-based method [8] comparison is omitted as it assumes that few measurements are anomalous; thus it is unlikely to detect long-duration anomalies such as the Constant anomaly in Fig</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rapid deployment with confidence: calibration and fault detection in environmental sensor networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Balzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rothenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<date type="published" when="2006-04">April 2006</date>
		</imprint>
	</monogr>
	<note>CENS</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Event detection from time series data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Guralnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint estimation of model parameters and outlier effects in time series</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="284" to="297" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards correcting input data errors probabilistically using integrity constraints</title>
		<author>
			<persName><forename type="first">N</forename><surname>Khoussainova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Workshop on Data Engineering and Mobile Access</title>
		<meeting>the ACM Workshop on Data Engineering and Mobile Access</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Declarative support for sensor data cleaning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Jeffery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pervasive Computing</title>
		<meeting>the International Conference on Pervasive Computing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cleaning and querying noisy sensors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Elnahrawy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Workshop on Wireless Sensor Networks and Applications</title>
		<meeting>the ACM International Workshop on Wireless Sensor Networks and Applications</meeting>
		<imprint>
			<publisher>WSNA</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PAQ: time series forecasting for approximate query answering in sensor networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tulone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Wireless Sensor Networks, EWSN</title>
		<meeting>the European Conference on Wireless Sensor Networks, EWSN</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Reinsen</surname></persName>
		</author>
		<title level="m">Time Series Analysis: Forecasting and Control</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Online anomaly detection for sensor systems: a simple and efficient approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Golubchik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-03">March 2010</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, USC</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 10-914</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Yuan Yao is a Ph.D. student in Department of Electrical Engineering-Systems at University of Southern California. He joined USC in 2005. Before that he received both his Bachelor of Science in Computer Science and Bachelor of Science in Measurement and Control Technique degrees in 2004 at Huazhong University of Science and Technology. His research interests include performance modeling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ringberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rexford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diot</surname></persName>
		</author>
		<editor>ACM SIGMETRICS</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Sensitivity of PCA for traffic anomaly detection</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">He received his 5-year Integrated M. Tech degree in Mathematics and Computing from the Indian Institute of Technology, Delhi, India in 2003. His research interests include performance analysis, optimization, and autonomous decision making in large distributed systems such as sensor networks and compute clouds</title>
		<imprint>
			<pubPlace>Los Angeles, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Southern California</orgName>
		</respStmt>
	</monogr>
	<note>Abhishek Sharma is a Ph.D. candidate at the</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Prior to that she was an Assistant Professor and then an Associate Professor at the University of Maryland at College Park and an Assistant Professor at Columbia University. Leana received her Ph.D. from UCLA. She is a past Chair, Vice Chair, and Board of Directors member of ACM SIGMETRICS, and is the current editor of the ACM Performance Evaluation Review. She has served as a program co-chair and general chair of ACM SIGMETRICS, program co-chair of MIS, and a co-chair of HotMetrics</title>
	</analytic>
	<monogr>
		<title level="m">Leana received several awards, including the IBM Faculty Award, the NSF CAREER award, the Okawa Foundation award, and the IBM &amp; NSF Doctoral Fellowships</title>
		<imprint/>
	</monogr>
	<note>Leana Golubchik is an Associate Professor in the Computer Science Department, with a joint appointment in Electrical Engineering. She is a member of the IFIP WG 7.3 and Tau Beta Pi</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m">Ramesh Govindan received his B. Tech. degree from the Indian Institute of Technology at Madras, and his M.S. and Ph.D. degrees from the University of California at Berkeley. He is a Professor in the Computer Science Department at the University of Southern California. His research interests include scalable routing in internetworks, and wireless sensor networks</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
