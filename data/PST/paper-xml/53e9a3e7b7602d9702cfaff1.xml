<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Analog Error-Correcting Codes Based on Chaotic Dynamical Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Brian</forename><surname>Chen</surname></persName>
							<email>bchen@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Research Laboratory of Electronics</orgName>
								<orgName type="institution">Massachusetts In-stitute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Gregory</forename><forename type="middle">W</forename><surname>Wornell</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Research Laboratory of Electronics</orgName>
								<orgName type="institution">Massachusetts In-stitute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Analog Error-Correcting Codes Based on Chaotic Dynamical Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">57B3A8223426A9BDFD40ACA905280691</idno>
					<note type="submission">received February 15, 1997; revised October 23, 1997 and February 13, 1998.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Broadcast channels</term>
					<term>chaotic systems</term>
					<term>errorcorrection codes</term>
					<term>fading channels</term>
					<term>joint source and channel coding</term>
					<term>nonlinear dynamics</term>
					<term>twisted modulation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The properties of chaotic dynamical systems make them useful for channel coding in a variety of practical communication applications. To illustrate this, a novel analog code based on tent map dynamics and having a fast decoding algorithm is developed for use on unknown, multiple, and time-varying signal-to-noise ratio (SNR) channels. This code is shown to be an attractive alternative to both digital codes and linear modulation in such scenarios. Several properties and interpretations of the codes are developed, along with some methods for their optimization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I N MANY communication applications, the information to be transmitted over the channel of interest is inherently analog (i.e., continuous-valued) in nature. Among many examples are speech, audio, or video information. For unreliable channels, the goal is typically to encode the information at the transmitter so as to allow reconstruction at the receiver with the minimum possible distortion. Over the last few decades, there has been an increasing bias toward digital solutions to this problem. A traditional digital approach involves appropriately quantizing the source data and encoding the quantized data using a suitably designed channel code so that the quantized data can be recovered with arbitrarily low probability of error.</p><p>The attractiveness of digital approaches of this type stems largely from the flexibility inherent in digital formats within large interconnected systems. Moreover, Shannon's source-channel separation theorem is frequently invoked to argue that performance need not be sacrificed using a digital approach. Recently, there has been a resurgence of interest in at least partially analog approaches in the form of joint source and channel coding techniques. The motivation for such methods has come primarily from the argument that although a digital approach can be used to achieve the performance of an analog system, the computational complexity of a fully digital approach may be considerably greater.</p><p>However, there is another key reason for considering analog communication techniques-for many important classes of channels that arise in practice, Shannon's theorem does not apply and, in fact, performance is necessarily sacrificed using a digital approach. Such is the case, for example, when the channel is an additive white Gaussian noise (AWGN) channel where the signal-to-noise ratio (SNR) is unknown at the transmitter, or, equivalently, in broadcast scenarios where there are multiple receivers with different SNR's, as well as in low-delay systems operating in the presence of time-selective fading due to multipath propagation.</p><p>In these kinds of settings which arise in, for example, a variety of wireless communication systems, separate source and channel coding is inherently suboptimum. As we will develop, digital approaches are inadequate because their performance depends crucially on being able to choose the proper number of quantization levels, which in turn depends on there being a specific target SNR. Motivated by these observations, in this paper we explore efficient analog coding strategies for scenarios precisely of this type. And while we will derive such codes by exploiting a nonlinear dynamical system theory perspective, we will demonstrate that the algorithms we obtain have important interpretations in the context of both classical analog modulation theory <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> and contemporary errorcorrecting codes <ref type="bibr" target="#b2">[3]</ref>.</p><p>An outline of the paper is as follows. Section II describes the system model of interest and motivates the need for analog solutions. Section III then describes a rather general statespace framework for describing a broad range of analog codes as well as many digital codes, which may be considered special cases of analog codes. Section IV develops an efficient analog code with a fast decoding algorithm and compares its performance with some conventional coding methods. Section V then outlines an approach for the design of broader classes of such codes based on an interpretation of the code developed in Section IV as a multiresolution code, and Section VI contains some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM FORMULATION AND PRELIMINARY OBSERVATIONS</head><p>We consider the transmission of a random continuousvalued source over the stationary unknown AWGN channel depicted in Fig. <ref type="figure" target="#fig_0">1</ref>. <ref type="foot" target="#foot_0">1</ref> In this system the encoder maps each analog source letter into a sequence of length -the bandwidth expansion factor-and of average power</p><formula xml:id="formula_0">(1)</formula><p>The received signal takes the form where the white Gaussian noise process is independent of and has zero mean and variance , so the SNR in the channel is <ref type="bibr" target="#b1">(2)</ref> The variance and, hence, the SNR, is known at the receiver but unknown at the transmitter. The decoder generates an estimate of the transmitted analog symbol from the received data</p><p>In such scenarios the objective is to find source-channel codes with small distortion for a given SNR and bandwidth expansion factor A convenient distortion metric for many applications, and the one on which we will focus in this paper, is mean-square error, i.e., For such problems, digital solutions are suboptimal even when and when the transmitter knows that the variance of the noise takes one of only two possible values, say or</p><p>In fact, we show in Appendix A that, even in this case, transmitting a Gaussian source sequence uncoded achieves a smaller distortion than that obtained by the best separate source and channel coding. See, e.g., <ref type="bibr">Trott [4]</ref> for a broader discussion of the suboptimality of separate source and channel coding in such scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. A CLASS OF ANALOG CODES FOR ERROR PROTECTION</head><p>A rather broad class of encoding strategies for the problem of Section II can be described in the following statespace form. In particular, the message is embedded in an initial state variable , and the corresponding encoding is obtained via iterations of the dynamical system (3a) (3b) where and are appropriately chosen functions. In general, these functions are designed so that the resulting code has both a computationally efficient and practical decoding algorithm, and good error-protection properties. In the sequel we restrict our attention to the case in which the message is uniformly distributed on the unit interval [0,1]. Among candidate maps , those for which the resulting dynamics (3a) are chaotic are particularly attractive for such error-protection applications. Among other important properties <ref type="bibr" target="#b4">[5]</ref>, chaotic systems are globally stable in the sense that state sequences remain bounded, resulting in codes with constant amplitude characteristics. At the same time, such systems possess a local instability in the form of sensitivity to initial conditions-i.e., because the Lyapunov exponent of a chaotic system is positive <ref type="bibr" target="#b5">[6]</ref>, state trajectories corresponding to nearby initial states diverge exponentially fast. In the coding context this sensitivity results in codes with useful distance properties-similar source letters map to very different transmitted sequences and, hence, can be readily distinguished at the receiver.</p><p>From the perspective of the encoding process (3), the decoding problem can be viewed as one of (initial) state estimation, and the sensitivity to initial conditions that characterizes chaotic dynamics is actually advantageous in this estimation. Moreover, for at least some classes of chaotic systems, very efficient recursive state estimation algorithms exist for implementing such decoding.</p><p>Two useful chaotic systems in this class correspond to choosing to be either the symmetric "tent" map function<ref type="foot" target="#foot_1">2</ref> (4)</p><p>or the "mod" map function <ref type="bibr" target="#b4">(5)</ref> It is straightforward to verify that these functions, which are shown in Fig. <ref type="figure" target="#fig_1">2</ref>, lead to state sequences that are uniformly distributed on [0,1] when the initial state is uniformly distributed on [0,1].</p><p>The dynamics of chaotic systems governed by these maps are surprisingly rich. Indeed, the dynamics are equivalent to those of an infinite length binary shift register. In particular, for the mod map, if <ref type="bibr" target="#b5">(6)</ref> is the (nonterminating) binary representation for , then the th iterate has the binary representation These same results apply to the tent map dynamics when Gray quantization encodings of the binary expansions are used. <ref type="foot" target="#foot_2">3</ref>The preceding interpretation of the dynamics implies that through judicious choice of the observation function in (3b), one can obtain a remarkably broad set of codes for mapping to In fact, within this class lie many widely used digital error-correction codes as special cases. To illustrate this, first note that given any binary sequence of bits , there exists an initial state such that Such a has the binary expansion (6) in the case of the mod map and the Gray code binary expansion in the case of the tent map. In turn, given the state , one can obtain every subsequent binary element via <ref type="bibr" target="#b6">(7)</ref> Thus, any digital encoder whose output is a function of the contents of some binary shift register can be represented by a tent map or mod map system with the appropriate choice of observation function Specifically, if the bits in the shift register are and the encoder output is some function , then</p><p>Similarly, one can represent the dynamics of a register that shifts bits at a time with the state evolution function <ref type="foot" target="#foot_3">4</ref>and, hence, convolutional encoders can be obtained from such chaotic systems using piecewise constant observation functions.</p><p>As a simple example, the rate-1/2 four-state convolutional encoder depicted in Fig. <ref type="figure">3</ref> can be expressed in this form with the observation function illustrated in Fig. <ref type="figure">4</ref>; this representation is developed in Appendix B. One can readily generalize this result to show that any rate-, -state convolutional encoder can be represented in the form <ref type="bibr" target="#b8">(9)</ref> where is the -fold iteration of either the tent map or the mod map and is a discrete-valued (piecewise constant) function that maps intervals into one of possible channel inputs.</p><p>While digital codes result from discrete-valued observation functions, a variety of useful analog error-correction codes for the scenario of Section II are obtained by employing an observation function that is continuous valued. In the next section we explore one of the simplest useful examples of such a code and develop its key properties and performance characteristics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. AN ANALOG CODE FROM TENT MAP DYNAMICS</head><p>In this section we focus on the case in which is the linear function <ref type="bibr" target="#b9">(10)</ref> which maps the unit interval onto the interval , yielding a zero-mean channel input with average power . <ref type="foot" target="#foot_4">5</ref> <ref type="foot" target="#foot_5">5</ref> We refer to the corresponding code as the "tent map code" as the resulting code sequence itself obeys a kind of tent map dynamics, with the tent map rescaled and translated to map the interval , rather than [0,1], onto itself. In particular, since is invertible, a direct implementation of the encoder follows as:</p><formula xml:id="formula_2">(11a)</formula><p>where <ref type="foot" target="#foot_6">6</ref>(11b)</p><p>Exploiting the interpretation of the code <ref type="bibr" target="#b10">(11)</ref> as the state trajectory of a chaotic system with the source letter em-bedded in the initial state, we now consider the problem of decoding in the context of state estimation. In particular, using to denote the estimate of based on observation of , the decoded source letter is obtained from While optimal state estimation for chaotic sequences is in general a difficult problem, for the case of tent map dynamics specifically, highly efficient recursive algorithms exist. In particular, Papadopoulos and Wornell <ref type="bibr" target="#b6">[7]</ref> derive the maximumlikelihood (ML) estimator for tent map sequences in stationary AWGN and show that it can be implemented by a forward recursive filtering stage followed by a backward recursive smoothing stage. The forward recursion takes the form</p><formula xml:id="formula_3">(12a) (12b) (12c)</formula><p>where the gain is also computed recursively as developed in [7, eq. ( <ref type="formula">31</ref>)]. In turn, the backward recursion is (12d)</p><p>In <ref type="bibr" target="#b11">(12)</ref> denotes the ML estimate of In terms of the Gray encoding of the source letter, i.e., , the signs are related to the quantization bits via Useful expressions for the mean-square error performance characteristics of the tent map code with ML decoding (12) can be derived and expressed in terms of the bandwidth expansion factor and the SNR. To begin, since , we have <ref type="bibr" target="#b12">(13)</ref> so the mean-square error is given by <ref type="bibr" target="#b13">(14)</ref> where, more generally, While it is tempting to simply use the Cramér-Rao bound approximation <ref type="bibr" target="#b6">[7]</ref> (15) in the calculation of in ( <ref type="formula">14</ref>), this approximation is generally only accurate when <ref type="bibr" target="#b6">[7]</ref>. For , it fails to take into account the nonzero probability of errors in the estimation of the signs An accurate expression for the smoothing error variance can be developed by explicitly accounting for the probability that</p><p>In particular, in Appendix C we show that when the SNR is at least moderately large, the distortion can be  <ref type="formula">16</ref>) establishes a key feature of the distortion-that it decays exponentially with bandwidth to a lower limiting threshold that is SNR-dependent. This behavior, which is consistent with the results of Monte Carlo simulations depicted in Fig. <ref type="figure" target="#fig_3">5</ref> and [7, Fig. <ref type="figure">4</ref>], is rather attractive in comparison with that of other alternative methods, as we now develop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance Bounds on Analog Codes</head><p>To gain perspective on the specific performance of the tent map code, we first develop a lower bound on the meansquare error performance of any analog code. One that is easily derived but, in general, not tight, is obtained from the rate-distortion bound.</p><p>This bound and the associated analysis will allow us to verify that there is always a power-bandwidth regime in which the tent map code yields better performance (i.e., lower distortion) than not only any -ary channel code but also any multiresolution code based on Cover's superposition strategy <ref type="foot" target="#foot_7">7</ref>with finitely many resolutions.</p><p>To develop the bound, we begin by observing that with denoting the channel capacity, the rate-distortion function for Again, we note that the above bound is not tight in general. Indeed, for , no practical coding scheme can achieve this bound over all SNR <ref type="bibr" target="#b1">[2]</ref>.</p><p>However, the rate-distortion bound can be achieved at a specific SNR by separate source and channel coding with digital codes. In particular, with an -ary digital code, the capacity is bounded by , which when combined with (18) yields (20) Note that this bound cannot be approached when our bound exceeds the known SNR channel capacity ; hence, (20) is a useful measure of attainable performance only in the following SNR regime:</p><formula xml:id="formula_4">(21)</formula><p>We stress that, as (20) and (21) reflect, the success of an -ary transmission scheme depends critically on choosing the correct , which in turn requires knowledge of the SNR and is impossible, for example, in a broadcast scenario. By contrast, as (16a) reflects, the lower limiting threshold (16b) for the tent map code tends to zero with increasing SNR.</p><p>The performance bound implied by ( <ref type="formula">19</ref>) is depicted in Fig. <ref type="figure" target="#fig_4">6</ref>, along with the associated performance (20), (21) of digital codes for several specific values of Note that for any finite bandwidth ( ), the tent map codes result in lower distortion than -ary coding, as long as the SNR is higher than some finite lower cutoff SNR. The specific cutoff SNR is determined by comparing ( <ref type="formula">16</ref>)-(20), and corresponds to the intersections of the dashed and respective dotted lines in Fig. <ref type="figure" target="#fig_4">6</ref>.</p><p>Fig. <ref type="figure" target="#fig_4">6</ref> also provides a means for relating tent map code performance to any multiresolution scheme employing Cover's superposition strategy. In particular, such schemes yield an effectively staircase-shaped -SNR characteristic that, again, in general lies strictly above the lower bound (19) represented by the solid curve, as the analysis of Appendix A (and Fig. <ref type="figure" target="#fig_6">10</ref>) also reflects. The gap between the bottom corners of this staircase and the lower bound depend on a variety of factors, including the designed number of resolutions (i.e., Fig. <ref type="figure">7</ref>. The experimentally determined region in the power-bandwidth plane where the tent map code resulted in lower distortion than the repetition code, a form of linear modulation, is marked with 2's. The region where the repetition code resulted in lower distortion is marked with 's. The dashed line is the theoretically predicted boundary. SNR operating points). It is also important to emphasize that when the number of resolutions is finite, this staircase characteristic begins with a vertical drop in distortion at some lower SNR threshold and ultimately ends up being flat beyond some upper SNR threshold. As a result, for such schemes there always exists an SNR beyond which the tent map will provide better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison with Linear Modulation</head><p>Other interpretations of the tent map code yield additional insights. As one example, examining (11b), we see that the tent map code corresponds to nonlinearly modulating a set of orthogonal unit-energy sequences with the source letter In particular, we can express the code in the form</p><formula xml:id="formula_5">(22)</formula><p>where, in this specific case, the orthogonal sequences are simply delayed Kronecker delta functions and the nonlinear modulating functions are</p><p>As such, we can view the tent map code as a contemporary example of the nonlinear or "twisted" modulation schemes developed in the context of analog communication theory <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b11">[12]</ref>. As with other nonlinear modulation schemes, we would expect tent map coding to provide superior performance to linear modulation in the high-SNR regime. In this section we confirm this to be the case.</p><p>Any corresponding linear modulation of can be expressed in the form <ref type="bibr">(23)</ref> where, to meet the power constraint (1), the must satisfy</p><p>With ML decoding, the resulting distortion follows immediately as (24)</p><p>which is larger than (16a) whenever (25)</p><p>The corresponding boundary in the power-bandwidth plane is depicted in Fig. <ref type="figure">7</ref>, together with experimental data validating these results. As we would expect due to the familiar nonlinear capture phenomenon (threshold effect), the tent map code is superior to linear modulation at high SNR or in low-bandwidth regimes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. TENT MAP CODES AS MULTIRESOLUTION CODES</head><p>Tent map codes have a convenient interpretation as multiresolution codes. In particular, since with the observation function <ref type="bibr" target="#b9">(10)</ref> (26) where and , we see that the tent map code can be viewed as the superposition of less significant bit information in [i.e., the second term in (26)] on top of binary phase-shift keying (BPSK) transmission of most significant bit information in</p><p>The performance results of Section IV-A can be interpreted as reflecting that such superposition enables the tent map code to be effective at multiple SNR values.</p><p>More general classes of analog codes can, in principle, be developed by varying the relative protection of the most significant and less significant bit information. Although a full exploration of these possibilities is beyond the scope of this paper, we outline the basic ideas as an illustration of a potentially interesting direction for future research.</p><p>For example, consider codes whose dynamics take the form</p><formula xml:id="formula_6">(27)</formula><p>where is again the tent map and where for some integer parameter At one extreme, when the associated observation function is piecewise-constant as depicted in Fig. <ref type="figure">8</ref>, the result corresponds to simple uncoded -pulse-amplitude modulation (PAM) digital transmission of the quantization of , which can be optimized for a fixed known SNR. However, using the piecewise-linear observation function in Fig. <ref type="figure">8</ref> yields analog codes incorporating less significant bit information, which may improve performance at high SNR but which also represents a noise in the decoding of the most significant bit information. Accordingly, there seems to be a tradeoff-greater may provide better representation of the less significant bit information, while smaller allows higher fidelity decoding of the most significant bit information. decodes appropriately, as shown in Fig. <ref type="figure" target="#fig_5">9</ref>. Assuming without loss of generality that , the pairs of achievable rates are <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11,</ref><ref type="bibr">Sec. 14.1.3]</ref> (35) i.e., if , the receiver can decode bits per channel use and if , the receiver can decode bits per channel use, the bits from the first encoder plus an additional bits. The parameter can be chosen anywhere in [0,1] so that for each value of , we can design a channel code that corresponds to a particular achievable rate pair. Then, since and the Gaussian problem we consider is successively refinable <ref type="bibr" target="#b12">[13]</ref>, we can combine (34) and (35) to find the corresponding set of achievable distortion pairs, specifically, and , so that (36) From (36), we obtain the following lower bounds on and :</p><p>(37) With this scheme, we can not simultaneously achieve both bounds (37) since each value of corresponds to a different channel code. However, both bounds (37) can be achieved simultaneously if, rather than decomposing the encoder into the cascade of a quantizer with a digital channel encoder, we simply transmit the source letter uncoded (but linearly scaled so as to have power ). Indeed, when the information is "decoded" by processing the channel output with the linear minimum mean-square error estimator (38) the resulting distortion is precisely the lower bounds in (37) ). These results are illustrated in Fig. <ref type="figure" target="#fig_6">10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B CONVOLUTIONAL ENCODERS VIA CHAOTIC SYSTEMS</head><p>In the rate-1/2 four-state convolutional encoder depicted in Fig. <ref type="figure">3</ref> the represents a sequence of input bits from a Bernoulli-1/2 process. Two coded bits and are formed from the modulo-2 sums of the contents of the shift register and the input bit, and these coded bits are mapped into one of four channel symbols , , , or For example, , etc. One can produce the sequence with a tent map system by choosing the initial state to be the number whose Gray code binary expansion is and by choosing the observation function to be the piecewise constant function shown in the Fig. <ref type="figure">4</ref>(a) . Similarly, one can produce the sequence with a mod map system by choosing the initial state to be the number whose normal binary expansion is , i.e., <ref type="bibr" target="#b5">(6)</ref>, and by choosing the observation function to be the function shown in Fig. <ref type="figure">4(b)</ref>. One can easily verify that these systems are equivalent to the convolutional encoder in Fig. <ref type="figure">3</ref> by noting that the four intervals labeled with binary labels in Fig. <ref type="figure">4</ref> correspond exactly to the four possible states of the shift register in the convolutional encoder. For example, in the case of the tent map system, if , then either or These correspond to transitions from state 01 to state 11 with output or from state 01 to state 10 with output , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C TENT MAP DISTORTION CALCULATIONS</head><p>In our derivation denotes the bit-error event, i.e., the event that , and</p><p>To facilitate an analysis of the steady-state scenario, we treat the events as effectively mutually independent where is the probability density for conditioned on Thus, since</p><p>we can express (48) as (50</p><formula xml:id="formula_9">)</formula><p>where to obtain the second equality we have again used (46) and to obtain the last equality we have also used (47). Finally, substituting (47) and ( <ref type="formula">50</ref>) into (44) yields (16b). This analytical expression for is compared to empirical measurements from computer simulations in Fig. <ref type="figure" target="#fig_3">5</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Joint source-channel coding of a uniform source over an AWGN channel.</figDesc><graphic coords="2,50.40,59.58,236.40,55.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Tent map and (b) mod map state evolution functions.</figDesc><graphic coords="2,311.10,59.58,240.96,114.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. A rate-1/2 four-state convolutional encoder.</figDesc><graphic coords="3,308.58,59.58,246.00,116.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Distortion threshold (D th ): Empirical data are marked with 2's. Analytically predicted results (16b) are represented by the dotted line. Each empirical data point is obtained by averaging 4 2 10 4 measurements.</figDesc><graphic coords="4,338.88,59.58,185.52,162.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Distortion bounds. The dashed line represents the actual distortion of the tent map code. The solid line represents the bound corresponding to the SNR being known at the transmitter. The dotted lines represent lower bounds when M-ary coding is used. (a) N = 1. (b) N = 2. (c) N = 3. (d) N = 4.</figDesc><graphic coords="5,130.20,206.82,339.84,127.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Coding for the broadcast channel. Two codes are merged together, one for each possible noise variance. SRC ENC 1 is an optimal source encoder with rate R 1 : SRC ENC 2 is an optimal encoder for the residual error of SRC ENC 1 with rate R 2 0 R 1 : CH ENC i are the channel encoders and REC i are the receivers (channel and source decoding combined). Note that REC 2 can recover the bits from both SRC ENC 1 and SRC ENC 2 since ( 2 2 &lt; 2 1 ):</figDesc><graphic coords="8,42.00,59.58,253.20,96.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The achievable distortion pairs when ( 2 1 ; 22 ) = (P=10; P=100):The solid line represents the pairs achievable with separate source and channel coding. The symbol 2 is used to denote the achievable point with direct transmission of the source and linear minimum-mean-square error decoding.</figDesc><graphic coords="8,347.28,59.58,168.72,145.92" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For simplicity of exposition, we restrict our attention to real-valued baseband channels; extensions to more typical complex equivalent baseband channels are straightforward.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Without loss of generality, we restrict our attention to functions f (1) that map the unit interval [0,1] to itself.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The specific Gray code that applies throughout the paper is z[0] = 1 2 + 1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>6 1 i=0 (0 1 2 ) i</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>i j=0 (2b[j] 0 1):<ref type="bibr" target="#b3">4</ref> In general, we use the notation f (k) (1) for the k-fold iteration of a map f (1):</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>This analog code is effectively "systematic" in the sense that one can obtain the message m from one sample x[0] of the code sequence since g(1) is invertible. The other code sequence samples are analog "parity-check" samples.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>We use to denote composition, so that a b (x) 1 = a(b(x)):</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>Such a strategy<ref type="bibr" target="#b7">[8]</ref> is used for optimum transmission of digital streams of differing levels of importance over the broadcast channel. These codes have the property that more important information is encoded for the worst-case SNR, and less important information is encoded and superimposed for users at higher SNR's<ref type="bibr" target="#b8">[9]</ref>,<ref type="bibr" target="#b9">[10]</ref>.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Defense Advanced Research Projects Agency monitored by the Office of Naval Research (ONR) under Contract N00014-93-1-0686, by the Air Force Office of Scientific Research under Grant F49620-96-1-0072, by the ONR under Grant N00014-96-1-0930, and by a National Defense Science and Engineering Graduate Fellowship.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given specification of the SNR range of interest for the AWGN channel of Section II, say, in the form of a probability density for , it is possible, at least in principle, to optimize and so as to obtain the best tradeoff in terms of minimizing distortion. First, using reasoning similar to that used to obtain (40), one can express the distortion in the form <ref type="bibr">(28)</ref> where is now the -bit symbol error probability, is the mean-square error in , and is the mean-square estimation error in , occurring when the estimate of the th symbol is in error.</p><p>To continue this optimization process, one can proceed to express the quantities , , and in (28) in terms of and If a simple slicer is used to estimate the symbols (i.e., most significant bit information) at the receiver, can be approximated as</p><p>where the second approximation applies when is sufficiently large. Next, from the Cramér-Rao bound for the problem, one can obtain the approximation (30) Furthermore, one needs to estimate (31) possibly in a manner similar to that used in our original tent map code.</p><p>Meanwhile, our power constraint (1) implies that and lie in the set (32) Hence, using (29)-( <ref type="formula">31</ref>) in (28), suitable values of and within the set (32) could be obtained from an optimization of the form (33)</p><p>We emphasize that the preceeding discussion is just an outline of one possible generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUDING REMARKS</head><p>We have introduced intriguing analog error-correcting codes that are potentially useful in a variety of applications, examples of which are communication over broadcast channels and lowdelay communication in time-varying fading environments. These analog codes are generated from iterations of a nonlinear state-space system governed by chaotic dynamics, with the analog message embedded in the initial state. We have demonstrated that within this class are practical codes having recursive receiver structures and important performance advantages over conventional codes. We have outlined a method for generalizing and optimizing such codes, although detailed refinement of the method remains as one of a number of rich directions for further research. More generally, these analog codes and the general framework used to describe them have important connections to both modern digital codes and classical analog modulation techniques, the exploration of which is also likely to prove fruitful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A SUBOPTIMALITY OF SEPARATION OF SOURCE AND CHANNEL CODING FOR A CHANNEL WITH UNKNOWN SNR</head><p>We first calculate the minimum distortion that can be achieved through separated source and channel coding, i.e., by quantizing a Gaussian source and channel coding the bits in the quantization with a capacity achieving channel code. The minimum rate in bits per source letter required to be able to transmit the source with maximum distortion is given by [11, eq. (13.24)] (34) Since we require a rate of one channel use per source letter, if is the rate of the channel code in bits per channel use, then</p><p>Since the noise variance is known at the receiver, the channel coding problem is equivalent to coding for a broadcast channel with two noise variances and The receiver determines which is the true noise variance and and equally probable, 8 i.e., for all , and Under these conditions, the smoothing error can be expressed in the following form, with denoting the complement of :</p><p>(40)</p><p>To obtain the first equality, we write an expectation as a weighted sum of conditional expectations, where the conditioning is on the mutually exclusive collectively exhaustive events that either there are no sign errors at indexes or the first sign error is at index for The weights are the corresponding probabilities of these events. To obtain the second equality, we repeatedly use the that given , , as can be seen from (12d). We can rewrite (40) as ( <ref type="formula">41</ref>) where ( <ref type="formula">42</ref>) is a lower threshold in the limit of large for the error variance and where the approximation in (42) is valid when As we'll see when we develop the specific relationship between and SNR, this approximation is valid in the high-SNR regime. 8 Although the bit-error events are unlikely to be strictly independent, the results arising from these assumptions closely match the experimentally observed behavior depicted in Fig. <ref type="figure">5</ref> and [7, Fig. <ref type="figure">4</ref>]. Apparently, the approximation is a good one in that any dependence that may exist among the bit-error events does not significantly impact the calculations in this section.</p><p>Hence, the distortion is given by where to obtain the equality on the first line we have used (46), and that is a uniform density over the interval Hence, is approximately inversely proportional to the square root of SNR, and is therefore small in the high-SNR regime. The result (47), although based on a Gaussian approximation, agrees with empirical measurements <ref type="bibr" target="#b14">[15]</ref>.</p><p>To calculate , note that the effect of is to produce a fairly good estimate of rather than , so that (48) 9 The Q-function is defined according to Professor. During the 1992-1993 academic year, he was on leave at AT&amp;T Bell Laboratories, Murray Hill, NJ, and during 1990 he was a Visiting Investigator at the Woods Hole Oceanographic Institution, Woods Hole, MA. His current research interests include signal processing, wireless and broadband communications, and applications of fractal geometry and nonlinear dynamical system theory in these areas. He is author of the monograph Signal Processing with Fractals: A Wavelet-Based Approach and co-editor of Wireless Communications: Signal Processing Perspectives (Englewood Cliffs, NJ: Prentice-Hall). He is also a Consultant to industry and holds three U.S. patents in the area of communications with another patent pending.</p><p>Dr. Wornell is a member of Tau Beta Pi and Sigma Xi. He is currently serving as Associate Editor for the communications area for IEEE SIGNAL PROCESSING LETTERS, and he serves on the DSP Technical Committee of the IEEE Signal Processing Society. He has received the MIT Goodwin Medal for "conspicuously effective teaching" (1991), the ITT Career Development Chair at MIT (1993), an NSF Faculty Early Career Development Award (1995), an ONR Young Investigator Award (1996), and the MIT Junior Bose Award for Excellence in Teaching (1996).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Principles of Communication Engineering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wozencraft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Jacobs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965">1965</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The behavior of analog communication systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ziv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="587" to="594" />
			<date type="published" when="1970-09">Sept. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Theory and Practice of Error Control Codes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Blahut</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unequal error protection codes: Theory and practice</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Trott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Information Theory Workshop</title>
		<meeting>IEEE Information Theory Workshop<address><addrLine>Dan-Carmel, Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-06">June 1996</date>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Statistical analysis and spectral estimation techniques for one-dimensional chaotic signals</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Isabelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Wornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1495" to="1506" />
			<date type="published" when="1997-06">June 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">One-dimensional iterative maps</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Lauwerier</surname></persName>
		</author>
		<editor>Chaos, A. V. Holden</editor>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Princeton Univ. Press</publisher>
			<pubPlace>Princeton, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation of a class of chaotic signals</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Wornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="312" to="317" />
			<date type="published" when="1995-01">Jan. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Broadcast channels</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="1972-01">Jan. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multiresolution broadcast for digital HDTV using joint source/channel coding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Uz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Select. Areas Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="6" to="23" />
			<date type="published" when="1993-01">Jan. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multilevel codes for unequal error protection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Seshadri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1234" to="1248" />
			<date type="published" when="1993-07">July 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Design of signals for analog communication</title>
		<author>
			<persName><forename type="first">U</forename><surname>Timor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="581" to="587" />
			<date type="published" when="1970-09">Sept. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Successive refinement of information</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H R</forename><surname>Equitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="269" to="275" />
			<date type="published" when="1991-03">Mar. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Rate Distortion Theory: A Mathematical Basis for Data Compression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient communication over additive white Gaussian noise and intersymbol interference channels using chaotic sequences</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brian Chen was born in Warren, MI</title>
		<imprint>
			<date type="published" when="1972">Apr. 1996. 1972</date>
			<biblScope unit="volume">598</biblScope>
		</imprint>
	</monogr>
	<note>He received the B.S.E. degree from the University of</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
