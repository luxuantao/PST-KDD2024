<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combining Deep Learning and Hand-Crafted Features for Skin Lesion Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tomáš</forename><surname>Majtner</surname></persName>
							<email>tomas.majtner@ntnu.no</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science and Media Technology</orgName>
								<orgName type="institution">NTNU Norwegian University of Science and Technology</orgName>
								<address>
									<settlement>Gjøvik</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sule</forename><surname>Yildirim-Yayilgan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science and Media Technology</orgName>
								<orgName type="institution">NTNU Norwegian University of Science and Technology</orgName>
								<address>
									<settlement>Gjøvik</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jon</forename><forename type="middle">Yngve</forename><surname>Hardeberg</surname></persName>
							<email>jon.hardeberg@ntnu.no</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science and Media Technology</orgName>
								<orgName type="institution">NTNU Norwegian University of Science and Technology</orgName>
								<address>
									<settlement>Gjøvik</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Combining Deep Learning and Hand-Crafted Features for Skin Lesion Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">93B055EB1FACC6F2DE2F0C69DA9CFDCF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convolutional Neural Network</term>
					<term>SVM</term>
					<term>RSurf Features</term>
					<term>Local Binary Patterns</term>
					<term>Skin Lesion Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Melanoma is one of the most lethal forms of skin cancer. It occurs on the skin surface and develops from cells known as melanocytes. The same cells are also responsible for benign lesions commonly known as moles, which are visually similar to melanoma in its early stage. If melanoma is treated correctly, it is very often curable. Currently, much research is concentrated on the automated recognition of melanomas. In this paper, we propose an automated melanoma recognition system, which is based on deep learning method combined with so called hand-crafted RSurf features and Local Binary Patterns. The experimental evaluation on a large publicly available dataset demonstrates high classification accuracy, sensitivity, and specificity of our proposed approach when it is compared with other classifiers on the same dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Based on the report from 2011, about 1500 melanoma cases are diagnosed each year in Norway <ref type="bibr" target="#b0">[1]</ref>. The incidence of melanoma in this country is currently among the highest in the world and is still rising. Early diagnosis with rapid evaluation and surgical treatment cure up to 90 % of patients <ref type="bibr" target="#b1">[2]</ref>. This is one of the examples, why the risk of melanoma is considered as a very important worldwide problem. Much research is currently focused on this issue with the aim to help doctors and patients in early melanoma recognition.</p><p>In the simplest form, the presented problem can be expressed as recognition of whether a captured dermoscopic image of skin contains a melanoma lesion or a benign lesion. Examples of these two types of lesions are shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The problem of correct skin lesion recognition is a difficult task. It usually consists of several stages, where the captured image is first preprocessed, a set of features is extracted, and as the last step, the input is classified to one of the pre-defined categories based on the extracted feature set.</p><p>Currently, two different types of feature sets are commonly employed in image recognition. The conventional type is based on the so called hand-crafted features, which are designed by researchers with the aim to capture visual characteristics of an image, typically its colour or texture. Recently, a new type of feature set inspired by biological processes and derived from the Convolutional Neural Network (CNN) <ref type="bibr" target="#b2">[3]</ref> was introduced. In combination with deep learning, these new features tend to outperform hand-crafted features and therefore they have become very popular in computer vision. In this paper, we propose a combination of both types of features to be used for the skin lesion classification problem. We directly compare our results with the results from the recent melanoma classification challenge, which was hosted by the International Skin Imaging Collaboration (ISIC) and organized to support research and development of algorithms for automated diagnosis of melanoma <ref type="bibr" target="#b3">[4]</ref>. The dataset used for this competition contains hundreds of images from different sources and competition results represent state-of-the-art for this classification problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Several rules were established for doctors to help them correctly recognise skin lesions, namely the ABCD rule of dermoscopy or the 7-point checklist <ref type="bibr" target="#b4">[5]</ref>. In automated diagnosis systems, texture and colour features are considered as two fundamental visual characteristics, which are vital for the detection of melanoma. Employing divergence-based colour features was presented in 2015 by Møllersen et al. <ref type="bibr" target="#b5">[6]</ref>. These features are based on the divergence between the distribution of the pixel colour values of a lesion image, and the pixel colour values of either a benign or a melanoma 978-1-4673-8910-5/16/$31.00 ©2016 IEEE model. Several studies have already been done employing texture-based features like generalized co-occurrence matrices <ref type="bibr" target="#b6">[7]</ref>, gradient histograms <ref type="bibr" target="#b7">[8]</ref>, and RSurf features <ref type="bibr" target="#b8">[9]</ref>.</p><p>The combination of texture and colour features for the classification of dermoscopy images was presented by Riaz et al. <ref type="bibr" target="#b9">[10]</ref>. Their texture features consist of a variation of Local Binary Patterns (LBP). For the colour feature extraction, the authors used standard HSV histograms. Methods based on deep learning were also employed for this problem. Codella et al. <ref type="bibr" target="#b10">[11]</ref> present a combination of deep learning, sparse coding, and support vector machine (SVM) learning algorithms for melanoma classification. Their method achieved a classification accuracy of 93.1 % on a dataset containing 2624 clinical cases of melanoma, atypical nevi, and benign lesions. For the classification itself, various approaches have been used for melanoma images. The most common ones include k-NN <ref type="bibr" target="#b11">[12]</ref>, neural network <ref type="bibr" target="#b12">[13]</ref>, fuzzy c-means <ref type="bibr" target="#b13">[14]</ref>, linear discriminant analysis <ref type="bibr" target="#b5">[6]</ref>, and SVM <ref type="bibr" target="#b14">[15]</ref>.</p><p>Our contribution differs from the previous works in several manners. We use the combination of two different SVM classifiers. The first one uses hand-crafted features as input, represented by RSurf features <ref type="bibr" target="#b15">[16]</ref> and Local Binary Patterns <ref type="bibr" target="#b16">[17]</ref>. The second one employs features derived from CNN, where we had inspiration in recent research by Kawahara et al. on deep features for skin lesions <ref type="bibr" target="#b17">[18]</ref>. Both of our classifiers predict the class for each tested image with a certain posterior probability or predicted class score <ref type="bibr" target="#b18">[19]</ref>. These scores are subsequently used to determine the final classification.</p><p>We performed the evaluation on the publicly available dataset provided by ISIC for better comparison of our proposed method with state-of-the-art approaches. The same dataset was used in 2016 for the melanoma classification challenge <ref type="bibr" target="#b3">[4]</ref>. The training part of this dataset contains 900 images (727 images of benign lesions and 173 images of melanoma) and the independent testing part contains 379 images (304 images of benign lesions and 75 images of melanoma). The entire dataset consists of images from various sources with various image distortions and classification tasks, and therefore better simulates real world usage of proposed solutions. Our method is among the top performing approaches in terms of classification accuracy, sensitivity, and specificity. In the subsequent sections of this paper, we introduce each individual component of our method and in the last section we present the classification results and ideas for future development and improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>As we already mentioned, our proposed method combines two different SVM classifiers. The first one is based on RSurf features and LBP. These image descriptors expect greyscale image as the input. Therefore, we first converted the original RGB image to greyscale by considering only the channel with the highest entropy E, which is defined as</p><formula xml:id="formula_0">E(I) = - (p * log 2 p),</formula><p>where I is the examined image and p contains the histogram counts for every intensity value in I. This approach was used in <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b19">[20]</ref> and we chose it because the resulting greyscale image better captures the varying spatial distribution of the intensity values than traditional conversion from RGB to greyscale. Since the dataset images were from different sources and therefore had different resolutions, we also downsampled each of them to speed-up the feature extraction process, thus the resolution in the longest axis does not exceed 800 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. RSurf Features</head><p>The first method we used for image description was introduced in 2014 and is called RSurf features <ref type="bibr" target="#b15">[16]</ref>. Despite the fact that it was designed for images from a different domain, the high potential of RSurf features for melanoma recognition was also demonstrated <ref type="bibr" target="#b8">[9]</ref>. The idea behind this feature set is based on dividing the image into parallel sequences of intensity values from the upper-left corner to the bottom-right corner. In these intensity sequences, all the local intensity maxima and minima are localized. Therefore, intensity values between two extreme points form either non-increasing or non-decreasing intensity sequences. We refer to them as to slopes in further text. In general, one can sequentially scan the image and extract slopes in any direction. It was already recommended in <ref type="bibr" target="#b15">[16]</ref> to scan the image in various directions in order to increase the robustness to rotational differences.</p><p>The set of all slopes extracted from all directions are used to extract slope properties. Four characteristic functions Φ 1 , ..., Φ 4 were originally designed for mapping each slope to a real value. The first function Φ 1 corresponds to the length of the slope, the second function Φ 2 returns the height difference between the highest and the lowest point of the slope, the third function Φ 3 defines the sum of all intensity values, which belong to the slope, and finally the fourth function Φ 4 corresponds to the number of sign changes of the second derivative of the slope. In the end, for each characteristic function, a normalized histogram of function values is built. The concatenation of histogram values from all four characteristic functions forms the feature vector. The schematic visualization of RSurf features is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. From the description one can see that RSurf features can be noise sensitive and therefore the use of Gaussian filter with small σ value is suggested prior to the calculation of the features to suppress the noise in the input image. As it was demonstrated in <ref type="bibr" target="#b15">[16]</ref>, stronger smoothing decreases the classification performance of these features significantly. Therefore, prior to feature extraction, we apply Gaussian filter with σ = 0.5.</p><p>In the slope extraction process, the number of used directions should be determined. For various combinations of directions, we obtained almost identical results, thus this parameter has no significant influence on the results. Therefore, we decided to use the default option of 0 • , 45 • , 90 • , and 135 • , where 0 • represents the horizontal direction.</p><p>Another important parameter is the number of histogram bins used for each characteristic function, which defines the feature vector length. For each characteristic function, the same number of bins is used. The feature vector is a concatenation of all histogram bins from all four characteristic functions. We tested various feature vector lengths and the best results were achieved for 2000 elements, which corresponds to 500 bins for each characteristic function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Local Binary Patterns</head><p>Local Binary Patterns (LBP) were first introduced in 1994 by Ojala et al. <ref type="bibr" target="#b16">[17]</ref>. The idea behind this descriptor is based on the model of texture units, where an input image is described through its texture spectrum. Ojala et al. extended this model and proposed its two-level version, which is now the core of the original LBP.</p><p>The computation of the original LBP consists of several steps. First, each pixel of the image is compared with its 8 immediate neighbours. If the intensity value of the neighbouring pixel is greater than or equal to the value of the examined pixel's intensity, write 1 in the neighbouring pixel. Otherwise, write 0. The described process gives us an eight-digit binary number for each pixel in the image. For convenience, we convert this number to decimal by taking the neighbours in clockwise order from the top-left corner. These decimal numbers are used to form a histogram and in the end, a concatenation of the normalized histogram values gives us the feature vector. Fig. <ref type="figure" target="#fig_3">3</ref> illustrates the process of building the feature vector for the original LBP version.  The original algorithm was further enhanced and in 2002, the basic LBP operator was introduced <ref type="bibr" target="#b20">[21]</ref>. The idea for this operator is based on the assumption that each texture has two complementary aspects, a pattern and its strength. The main innovation is putting no limitation to the size of the neighbourhood (parameter R) or the number of sampling points (parameter P ). Examples of various local circular neighbourhoods defined by these new parameters are shown in Fig. <ref type="figure">4</ref>.</p><formula xml:id="formula_1">P = 8, R = 1 P = 8, R = 2 P = 4, R = 2</formula><p>Fig. <ref type="figure">4</ref>: The circular neighbourhoods with various parameters P and R. The pixel values are bilinearly interpolated, when the sampling point is not in the centre of the pixel.</p><p>In our experiments, we used the version with 8 sampling points (P = 8) and three different radii (R = 1, 3, 5), thus our feature vector length is 3 × 2 8 = 768. This version is typically denoted as LBP R=1,3,5 . LBP has many different variants, which were successfully applied in a number of domains <ref type="bibr" target="#b21">[22]</ref>, including the recent results for melanoma recognition <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. First SVM Classifier</head><p>The first classification is based on SVM classifier with Gaussian kernel and standardized predictors. It combines RSurf features and LBP R=1,3,5 to estimate the class for a given input image as is shown in Fig. <ref type="figure" target="#fig_4">5</ref>. The input feature vector consists of 2768 components. Each image class label is predicted with a certain score representing the posterior probability that an observation belongs in a particular class, given the data <ref type="bibr" target="#b18">[19]</ref>. It can be interpreted as the strength of classification decision and we use it later in our final solution.</p><p>---- We tested this first classifier based on the same protocol as was used in the already referred classification contest <ref type="bibr" target="#b3">[4]</ref>. We used 900 train images to extract features and train the SVM to create the model, and subsequently we use independent 379 test images for evaluation. The independent test set is a guarantee that results are not biased, which is  <ref type="bibr" target="#b23">[24]</ref>. Individual shortcuts of the layers are described in the text.</p><p>a common problem of cross-validation evaluation <ref type="bibr" target="#b24">[25]</ref>. The average precision for the first classifier is 0.405, we achieved the classification accuracy of 0.794 with sensitivity of 0.507, and specificity of 0.866. These results are comparable with the top performing classifiers from the classification challenge, in case these traditional metrics, suggested also in <ref type="bibr" target="#b25">[26]</ref>, are considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Second SVM Classifier (AlexNet)</head><p>The second SVM classifier with Gaussian kernel and standardized predictors uses features derived from CNN. Specifically, we used the AlexNet <ref type="bibr" target="#b2">[3]</ref> proposed by <ref type="bibr" target="#b2">Krizhevsky et al. in 2012</ref>. Authors employed the CNN for the first time for image classification and won the ImageNet Large Scale Visual Recognition Challenge 2012 with significant lead over the other participants. Despite the fact that AlexNet was created for real world images, it was also applied in combination with SVM for melanoma recognition <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b17">[18]</ref>.</p><p>The original version of AlexNet contains five convolutional layers (CONV) and three fully-connected layers (FC). Each of these layers is followed by a point-wise non-linear activation layer called rectified linear units (RELU). There is also a local response normalization layer (LRN), which follows the first two convolutional layers. AlexNet has three max-pooling layers (MAX), two after the LRN layers and the third one following the fifth convolutional layer. The core structure of AlexNet locates between the second and the third maxpooling layers, which contains three convolutional layers, each with 3 × 3 convolution kernels <ref type="bibr" target="#b26">[27]</ref>. More details about the overall structure and design of AlexNet can be found in the publication by Krizhevsky et al. <ref type="bibr" target="#b2">[3]</ref>.</p><p>In our experiments, we used MatConvNet <ref type="bibr" target="#b27">[28]</ref>, which is a MATLAB toolbox implementing Convolutional Neural Networks for computer vision applications. The original RGB input images were used and AlexNet was employed only for calculation of the second fully-connected layer, as it is illustrated in Fig. <ref type="figure" target="#fig_5">6</ref>. This layer has 4096 elements, which corresponds to the same number of neurons. These elements are, in our experiment, considered as the feature vector and they are subsequently used as inputs to SVM. This is a standard approach employed, for example, in <ref type="bibr" target="#b28">[29]</ref>.</p><p>We evaluated the second SVM classifier with the same protocol as the previous one and results are presented in Table <ref type="table" target="#tab_0">1</ref>. Based on this comparison, deep learning features confirm their tendency to outperform hand-crafted features also for this particular dataset. However, it is important to emphasize that in the first SVM classifier based on hand-crafted features, only one colour channel was considered, since the employed texture-based feature extractors expect greyscale image as input. Therefore, the number of input information was not equal in both classifiers. In the case of using only greyscale input for the second classifier based on CNN features, the results will be worse than the results presented for the first classifier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. FINAL EVALUATION AND RESULTS</head><p>As was mentioned before, both of the tested SVM classifiers provide also scores defined as the mean accuracy of the given test data and labels. We use these values to determine, which classifier is more confident about the assigned label. For each tested image, we choose the label with the highest absolute score value. The final classifier is therefore a combination of both principles, the hand-crafted features and the features derived from the deep learning mechanism, as it is illustrated in Fig. <ref type="figure" target="#fig_6">7</ref>.</p><p>Our final classifier has the average precision of 0.473, which is only slight improvement over the previously mentioned results but the classification accuracy is 0.826 with the sensitivity of 0.533 and specificity of 0.898. This performance is among the top state-of-the-art classifiers, as is shown in Table <ref type="table" target="#tab_2">2</ref>, which summarises the results of the melanoma classification challenge. For completeness, we also provide the precisionrecall graph in Fig. <ref type="figure">8</ref> and the ROC curve in Fig. <ref type="figure">9</ref>. The area under the ROC curve is 0.780. Since there are more metrics that could be considered for classification evaluation, it is hard to clearly conclude, which approach is the highest performing one. For different purposes, different approaches maximizing a particular metric could be more appropriate. However, the presented results demonstrate our approach as one of the top performing for melanoma classification. There is still a room for improvement but these first results indicates that with combining handcrafted features with deep learning features we easily build high performing solution for melanoma classification, and therefore this approach is very promising for the future.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION AND FUTURE WORK</head><p>In this paper, we proposed a fully automated melanoma classification approach, which is based on the combination of RSurf features and Local Binary Patterns together with the features derived from a Convolutional Neural Network. Each component of the presented approach was tested on a large publicly available dataset with independent training and testing images. For evaluation purposes, we derived various classifier characteristics but our aim in designing the classifier was maximization of the classification accuracy, sensitivity, and specificity, which were recognized as one of the most important classifier metrics <ref type="bibr" target="#b25">[26]</ref>. Based on the classification accuracy, our approach is the fourth best performing classifier, when compared with state-of-the-art classifiers participating in the melanoma recognition challenge <ref type="bibr" target="#b3">[4]</ref>. These results are very promising and suggest that approaches based on hand-crafted features in combination with features derived from CNN have high potential in melanoma recognition.</p><p>In future work, we will concentrate on creating a new model for MatConvNet, which will be aimed specifically on skin lesion images. Currently, we used the pre-trained AlexNet model <ref type="bibr" target="#b2">[3]</ref>, which is very robust but has some limitations when used in different research domains. Since the dataset used in this article is very large and contains images from different sources, various image distortions and artefacts are also present in images. Therefore, we will aim at creating a robust pre-processing step to eliminate all the possible artefacts and enhance the feature extraction process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: An example of malignant melanoma lesions (a) and benign lesions (b). Images are from ISIC Archive (https://isicarchive.com/).</figDesc><graphic coords="1,306.42,282.33,118.23,88.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: The illustration of RSurf features. (a) parallel sequences, each represented by line dots, (b) slopes of a sequence, (c) 4 histograms, one for each characteristic function.</figDesc><graphic coords="2,305.77,555.31,80.08,64.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: The process of building the feature vector in original LBP variant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: The illustration of the image class estimation by the first SVM classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Fig.6: The illustration of AlexNet combined with SVM, which we used in our experiments. The visualisation was inspired by work of Karnowski<ref type="bibr" target="#b23">[24]</ref>. Individual shortcuts of the layers are described in the text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: The illustration of the structure of our final classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :Fig. 9 :</head><label>89</label><figDesc>Fig. 8: The precision-recall curve for the final classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The comparison between first SVM classifier based on hand-crafted features and second SVM classifier based on AlexNet. AP represents the average precision.</figDesc><table><row><cell></cell><cell>AP</cell><cell>Accuracy</cell><cell>Sensitivity</cell><cell>Specificity</cell></row><row><cell>First SVM</cell><cell>0.405</cell><cell>0.794</cell><cell>0.507</cell><cell>0.866</cell></row><row><cell>Second SVM</cell><cell>0.470</cell><cell>0.805</cell><cell>0.533</cell><cell>0.872</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The comparison of our final classifier with the top ten participants of the melanoma classification challenge<ref type="bibr" target="#b3">[4]</ref> ordered by the classification accuracy. AUC represents the area under the ROC curve.</figDesc><table><row><cell>The challenge results were downloaded from website</cell></row><row><cell>https://challenge.kitware.com/#phase/5667455bcad3a56fac786791 on</cell></row><row><cell>28/06/2016.</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This research has been supported by the Research Council of Norway through project no. 247689 "IQ-MED: Image Quality enhancement in MEDical diagnosis, monitoring and treatment".</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Nasjonale retningslinjer for diagnostikk, behandling og oppfølging av maligne melanomer</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Robsahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Johannesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Oslo: Helsedirektoratet</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Malignant melanoma-diagnosis, treatment and follow-up in Norway</title>
		<author>
			<persName><forename type="first">J</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Bachmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nyakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Helsing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Fjøsne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Maehle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aamdal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Svendsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tidsskrift for den Norske laegeforening: tidsskrift for praktisk medicin, ny raekke</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="2154" to="2159" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C F</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Helba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Halpern</surname></persName>
		</author>
		<idno>abs/1605.01397</idno>
	</analytic>
	<monogr>
		<title level="m">Skin Lesion Analysis toward Melanoma Detection: A Challenge at the International Symposium on Biomedical Imaging (ISBI) 2016, hosted by the International Skin Imaging Collaboration (ISIC)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dermoscopy of pigmented skin lesions: results of a consensus meeting via the Internet</title>
		<author>
			<persName><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chimenti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Talamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Corona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cerroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ferrara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Academy of Dermatology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="679" to="693" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Divergencebased colour features for melanoma detection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Møllersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Hardeberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Godtliebsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Colour and Visual Computing Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A color and texture based hierarchical k-NN approach to the classification of non-melanoma skin lesions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ballerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Color Medical Image Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="63" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two systems for the detection of melanomas in dermoscopy images using texture and color features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Barata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mendonc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Marques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Systems Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="965" to="979" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient Melanoma Detection Using Texture-Based RSurf Features</title>
		<author>
			<persName><forename type="first">T</forename><surname>Majtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yildirim-Yayilgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Hardeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference Image Analysis and Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="30" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Detecting melanoma in dermoscopy images using scale adaptive local binary patterns</title>
		<author>
			<persName><forename type="first">F</forename><surname>Riaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Coimbra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering in Medicine and Biology Society. IEEE</title>
		<imprint>
			<biblScope unit="page" from="6758" to="6761" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning, sparse coding, and SVM for melanoma recognition in dermoscopy images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abedini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Machine Learning in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="118" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recognition of images of finger skin with application of histogram, image filtration and k-NN classifier</title>
		<author>
			<persName><forename type="first">A</forename><surname>Glowacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Glowacz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biocybernetics and Biomedical Engineering</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Novel approaches for diagnosing melanoma skin lesions through supervised and deep learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Premaladha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Systems</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Color approach of melanoma lesion segmentation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Beuren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Facon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Systems, Signals and Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="284" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A support vector machine for decision support in melanoma recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hofmann-Wellenhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Soyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Dermatology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="830" to="835" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">RSurf-The Efficient Texture-Based Descriptor for Fluorescence Microscopy Images of HEp-2 Cells</title>
		<author>
			<persName><forename type="first">T</forename><surname>Majtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stoklasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Svoboda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1194" to="1199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Performance evaluation of texture measures with classification based on Kullback discrimination of distributions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="1994">1994. 1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="582" to="585" />
		</imprint>
	</monogr>
	<note>Computer Vision and Image Processing</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep features to classify skin lesions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bentaieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1397" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Symmetry Extraction in High Sensitivity Melanoma Diagnosis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Guerra-Segura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Travieso-González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Alonso-Hernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ravelo-García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carretero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symmetry</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1061" to="1079" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Maenpaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Computer Vision Using Local Binary Patterns, Computational Imaging and Vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ahonen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Description of Visual Content in Dermoscopy Images Using Joint Histogram of Multiresolution Local Binary Patterns and Local Contrast</title>
		<author>
			<persName><forename type="first">S</forename><surname>Naeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Riaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nisar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Data Engineering and Automated Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="433" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">AlexNet + SVM</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Karnowski</surname></persName>
		</author>
		<idno>24/06/2016</idno>
		<ptr target="https://jeremykarnowski.files.wordpress.com/2015/07/alexnet2.png" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pitfalls of supervised feature selection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smialowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Frishman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="440" to="443" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An overview of melanoma detection in dermoscopy images using image processing and machine learning</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Celebi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.07843</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cross-Level: A Practical Strategy for Convolutional Neural Networks Based Image Classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCF Chinese Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="398" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">MatConvNet: Convolutional Neural Networks for Matlab</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd ACM International Conference on Multimedia</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N.-M</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.01145</idno>
		<title level="m">Vehicle Classification using Transferable Deep Neural Network Features</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
