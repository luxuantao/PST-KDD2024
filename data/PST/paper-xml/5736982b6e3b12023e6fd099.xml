<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DynaMOS: Dynamic Schedule Migration for Heterogeneous Cores</title>
				<funder ref="#_k42aU6V">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">ARM Ltd</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shruti</forename><surname>Padmanabha</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Advanced Computer Architecture Laboratory</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Lukefahr</surname></persName>
							<email>lukefahr@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Advanced Computer Architecture Laboratory</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Reetuparna</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Advanced Computer Architecture Laboratory</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><surname>Mahlke</surname></persName>
							<email>mahlke@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Advanced Computer Architecture Laboratory</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DynaMOS: Dynamic Schedule Migration for Heterogeneous Cores</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/2830772.2830791</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>heterogeneous processors, fine-grained phase prediction,</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>InOrder (InO) cores achieve limited performance because their inability to dynamically reorder instructions prevents them from exploiting Instruction-Level-Parallelism. Conversely, Out-of-Order (OoO) cores achieve high performance by aggressively speculating past stalled instructions and creating highly optimized issue schedules. It has been observed that these issue schedules tend to repeat for sequences of instructions with predictable control and data-flow. An equally provisioned InO core can potentially achieve OoO's performance at a fraction of the energy cost if provided with an OoO schedule. In the context of a fine-grained heterogeneous multicore system composed of a big (OoO) core and a little (InO) core, we could offload recurring issue schedules from the big to the little core, to achieve energyefficiency while maintaining performance.</p><p>To this end, we introduce the DynaMOS architecture. Recurring issue schedules may contain instructions that speculate across branches, utilize renamed registers to eliminate false dependencies, and reorder memory operations. DynaMOS provisions little with an OinO mode to replay a speculative schedule while ensuring program correctness. Any divergence from the recorded instruction sequence causes execution to restart in program order from a previously checkpointed state. On a system capable of switching between big and little cores rapidly with low overheads, DynaMOS schedules 38% of execution on the little on average, increasing utilization of the energy-efficient core by 2.9X over prior work. This amounts to energy savings of 32% over execution on only big core, with an allowable 5% performance loss.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Out-of-Order (OoO) cores are ubiquitous today in mobile phones to servers alike because they can achieve high single-thread performance on general purpose code. Their ability to dynamically resolve dependencies and speculatively issue instructions out of order enables them to maximize both Instruction Level Parallelism (ILP) and Memory Level Parallelism (MLP). Unfortunately, high performance comes at the cost of increased power consumption. Conversely, In-Order (InO) cores have lower complexity, allowing them to be significantly more energy efficient (3.5x) than OoO, but at a slowdown of more than 2x <ref type="bibr" target="#b1">[1]</ref>.</p><p>To address this disparity, researchers have designed heterogeneous multi-core processors <ref type="bibr" target="#b2">[2]</ref> in which an application is mapped to the most efficient core that meets its performance requirements. ARM's big.LITTLE <ref type="bibr" target="#b1">[1]</ref> combines a high-performance big (OoO) core and a lowperformance but energy-efficient little (InO) core. This allows an application to achieve high single-thread performance on the OoO core for phases that can utilize it, and to switch to the energy-efficient InO core for low performance phases <ref type="bibr" target="#b3">[3]</ref>, thereby reducing the overall energy consumption. Prior work has proposed heterogeneous architectures <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7]</ref> that enable fast switching between cores at the granularity of 100s of instructions. This effectively increases the opportunities of using the more energy-efficient little.</p><p>The majority of the performance advantage of an OoO core over an InO core comes from its ability to speculate past stalled loads and other long latency instructions, eliminate false dependencies between instructions, and execute instructions out-of-order. An issue schedule, or schedule, is used to refer to the sequence in which an OoO issues instructions for execution, after resolving dependencies and resource constraints. If a sequence of instructions, or trace, tends to repeat regularly in an application in the same program context, for example loops, it follows that the schedule created by an OoO core also tends to repeat. Dynamically recreating identical schedules for the same trace results in significant wastage of energy. We found that only 19% of the OoO's performance advantage is due to its ability to react to unexpected long latency events, by creating different schedules for the same trace. Ideally, 81% of its performance could be achieved on an similarly provisioned InO core, provided it used a bestcase OoO schedule for each trace and perfectly predictable control-flow. These results corroborate with recent work <ref type="bibr" target="#b8">[8]</ref> that credit the OoO's ability to create good static schedules as the main reason for the performance advantages of OoO over InO.</p><p>In this paper, we propose Dynamic Migration of Outof-order Schedule (DynaMOS ) for a fine-grain, tightly coupled heterogeneous processor with a big (OoO) core and an equally provisioned little (InO) core <ref type="foot" target="#foot_0">1</ref> . Our key idea is to record, or memoize, a schedule by executing an instruction trace on a big core and replay the memoized schedule on the InO core for future iterations of the trace. Since big has optimized these schedules for its architecture, executing them on an equally provisioned little will achieve similar high performance. By recording and replaying trace-schedule pairs, we can offload more execution from the big core to the energy-efficient little core, without compromising performance. Similarly, prior works reuse OoO schedules to reveal energy and/or performance benefits either on the same pipeline <ref type="bibr">[9,</ref><ref type="bibr" target="#b10">10]</ref> or on different, specialized pipelines <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b12">12]</ref>.</p><p>We overcome several design challenges en route to enabling DynaMOS . First, false register dependencies like Write-After-Write (WAW) and Write-After-Read (RAW) are handled by register renaming in OoO cores. In order to preserve program correctness, this renaming must be honored by little. Second, instructions may have been moved across branches in the memoized schedules. If a conditional branch within a trace changes its direction from what was assumed while recording the schedule, the trace must be aborted and reexecuted. Third, loads that have been speculatively moved above older stores that write to the same location need to be detected and handled. Finally, interrupts must be handled precisely.</p><p>To address these problems, we architect two modes of execution for the little core: an InO mode where it executes instructions in program order, and an OinO mode where it executes reordered instructions as per big's schedule. OinO is capable of reading a cached schedule, detecting and resolving false dependencies, and speculatively issuing memory operations. This allows the OinO mode to achieve nearly the same performance as an OoO core<ref type="foot" target="#foot_1">2</ref> , at a fraction of the energy cost.</p><p>This paper makes the following contributions:</p><p>? We observe that repeatability of reordered schedules allows us to offload a significant fraction of big's execution to the more energy-efficient little at a fine-granularity. We outline DynaMOS, an architecture that can detect and memoize traces that have repeatable schedules on the big such that they are readily accessible for execution on little. ? We supplement little with features that empower it to run an OoO schedule, while ensuring correct program behavior and precise exceptions handling. This enables little to nearly achieve big's performance for memoized traces, while maintaining its energy-efficiency. ? DynaMOS achieves 38% utilization of little, with small overheads including an 8% increase in energy of little. Overall, DynaMOS contributes energy savings of 32% as compared to having only a big core, a 2.2x increase over state-of-the-art <ref type="bibr" target="#b5">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MOTIVATION</head><p>A superscalar big's ability to speculatively reorder instructions comes at a cost of bulky structures like reorder buffers, reservation stations and complex issue logic. When there is high variance and uncertainty in behavior of a trace in terms of its data and control-flow, this capability of big helps in creating new optimized schedules in the event of mispredictions. However for the common case, this work is redundant, as reordered schedules are repetitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Memoizable Schedules</head><p>Applications exhibit phased behavior, and by matching these phases to the core that best executes them, energy-efficiency can be improved with a minimal impact on performance.</p><p>Figure <ref type="figure" target="#fig_0">1</ref>(a) illustrates fine-grained phase behavior in a subset of h64ref 's execution, a compute-intensive benchmark from SPECInt 2006 <ref type="bibr" target="#b13">[13]</ref> exhibiting predictable control and data-flow. Each point represents a trace in program order, with 50 instructions on average, that has been partitioned into "Run on big" and "Run on little" categories by an oracle. The oracle observes performances of the traces on big, little and classifies those that show high performance on OoO to run on big and those that show no significant performance advantage on OoO to run on little. An oracle constrained to maintain performance at 95% of big can execute at-most 11% of the application on the more energy-efficient little.</p><p>In Figure <ref type="figure" target="#fig_0">1</ref>(a), the light-colored (x) traces exhibit a memoizable schedule running on big. In Figure <ref type="figure" target="#fig_0">1(b</ref>) DynaMOS migrates all the memoized schedules to the OinO, enabling h264ref to run a majority (77%) of its  execution on little, while maintaining the same performance level. Increased utilization of little achieves proportional energy savings.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows similar opportunities to increase execution on little across the SPEC2006 suite. With a tightly coupled big-little architecture, an oracle that assumes zero switching overhead between the two cores can schedule 25% of execution on the energy-efficient little on average, while maintaining a 5% performance loss target. Supplementing little with an OinO mode for memoized schedules increases this best-case coverage by 2.2x to 80% on average. A trace's schedule on big depends largely on true dependencies between instructions, instruction latencies, and available resources in the pipeline. Unpredictable and unexpected memory and branch behavior within a trace forces the big to dynamically recreate a different optimized schedule for different instances of the trace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Repeatability of OoO Schedules</head><p>Figure <ref type="figure" target="#fig_2">3</ref> shows a histogram of dynamic execution seen across all benchmarks categorized by how repeatable their OoO schedules are, or their memoizability quotient. We define a trace's memoizable quotient as the percentage of its dynamic execution where it exhibited identical schedule. For instance, the category 90-99 on X-axis encapsulates all traces that bear identical schedules for greater than 90% of their run-time. Less than 30% of the execution displays schedules with low memoizability while majority (&gt;70%) can be categorized as having a high memoizable quotient. This tallies with our intuition, considering that majority of a program is spent executing loops and their regular data and control flow causes them to be scheduled in the same way every iteration. Moreover, the figure illustrates that most traces fall in either extremes of the memoizability spectrum, showing potential for accurate, low-cost and dynamic classification schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DYNAMOS DESIGN</head><p>The aim of DynaMOS is to maximize energy efficiency of general purpose applications with an allowable 5% performance loss as compared to execution on big. Our core architecture, based on a Composite Core <ref type="bibr" target="#b4">[4]</ref>, executes a single application thread, and includes both a big OoO and little InO core with the same superscalar width and number of functional units (FU). The idea is to empower the InO core to execute the OoO core's schedule, allowing it to achieve nearly OoO performance at a fraction of the energy consumption.</p><p>A block diagram of DynaMOS 's components is shown in Figure <ref type="figure">4</ref> and is further described as follows:</p><p>? big detects traces with repeatable schedules and stores them in a Schedule Trace-Cache (STC) <ref type="bibr" target="#b14">[14]</ref> (Section 3.3).</p><p>? An online controller <ref type="bibr" target="#b5">[5]</ref> (Section 3.4) observes a sequence of traces in the current context and migrates execution on the little if it predicts that the program is entering a micro-phase where either 1) a significant number of the micro-phase's traces are memoizable or 2) the micro-phase shows minimal performance advantage on the big.</p><p>? little itself can run in one of two modes: InO and OinO. InO mode fetches instructions from the shared instruction cache and executes them in program order. In OinO mode, the core fetches and executes reordered instructions from the STC and commits them atomically (Section 3.2). In case of misspeculations within such a trace, the OinO mode reverts to InO mode and the trace is reexecuted from its start in program order.</p><p>The big core plays three important roles in DynaMOS . First, big determines which traces are memoizable and encodes these traces in the STC . Second, it executes traces that exhibit unpredictable schedules. Lastly, it executes traces that cannot achieve OoO performance in OinO because of architectural constraints. On the other hand, traces that can be run in-order without compromising performance are executed on little in InO mode. Such traces inherently suffer low performance because of low ILP, high branch mispredicts and/or dependent cache misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Terminology</head><p>Before proceeding, we first formally define and expound terminology used consistently in this paper.</p><p>Trace: A trace is a sequence of instructions between two backward branches with a fixed control flow. The use of backward branches captures circular paths such as loops, which are repetitive and have similar program behavior, as well as functions, which require either the call or the return to be a backward branch. A unique trace is identified by a hash of its header PC (the target of the previous backward branch) and the outcomes for all interleaving conditional forward branches (TraceID). This definition is synonymous with previous works <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b15">15]</ref> and represents a sequence of instructions or basic blocks that have a high likelihood of appearing together. Schedule: The big dynamically reorders instructions at the issue stage by selecting the next ready instruction to execute on available resources. A schedule encapsulates the sequence of instructions for a trace in the order they were issued.</p><p>Atomicity: As memoized schedules disobey program order, any trace executed in OinO mode must be treated as an atomic block. Any path divergence in the trace due to a branch misbehavior, exception, or interrupt causes execution of the trace to restart in InO mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">OinO Mode</head><p>DynaMOS extends little with a special mode, OinO, enabling it to achieve high performance, without the high power consumption of big. OinO mode fetches memoized trace schedules from the STC, allowing it to execute reordered instructions in-order. As an in-order pipeline, little does not track the original program order. Therefore, when operating in OinO mode, Dy-naMOS faces the following difficulties in executing and committing out-of-order schedules: 1) False dependencies, i.e., Write-After-Write and Write-After-Read, are handled by Register Renaming in OoO cores. The OinO mode must honor renamed registers in the schedule to maintain correctness (Section 3.2.1).</p><p>2) As traces span multiple basic blocks, its instructions may have been reordered across branches. If a branch within a trace diverges from its recorded direction, OinO may have already speculatively executed some incorrect instructions. Therefore, the pipeline must be rolled back to the correct state in case such misspeculations occur (Section 3.2.1).</p><p>3) Loads may have been speculatively moved before older stores that write to the same location, leading to aliasing. These aliases need to be detected and handled (Section 3.2.3). 4) Precise interrupts should be handled (Section 3.2.4). Note that variance in a schedule's data-flow in OinO mode does not constitute a violation of program order. For example, instructions might have been scheduled around a load that is typically an L1-hit, incurring a 2 cycle latency. If this load misses in the L1 for one instance of the schedule, the OinO pipeline will stall on use until the load is satisfied. This is identical to stalling for a true dependency in InO mode. However, OinO mode lacks the big's ability to rebuild a different dynamic schedule to reorder around the miss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Register Renaming</head><p>In an OoO core, every destination architectural register (AR) is renamed to a new physical register (PR) to eliminate false dependencies. big assigns a free PR from a list and remembers the AR-&gt;PR mapping in a register allocation table. Maintaining a free list of PRs is a time and energy consuming operation. Instead, OinO implements a cheaper renaming scheme as follows.</p><p>The OinO mode provides a fixed pool of PRs to each AR for renaming purposes (Figure <ref type="figure" target="#fig_3">5b</ref>). While encoding a trace schedule, big assigns every AR a suffix, which is an index denoting its unique version number within the trace. All live-in registers are required to have a 0 suffix. Every time the register is written to, the suffix is incremented, while there are free registers in its pool. All further uses of this register are updated to reflect the most recent suffix. We refer to this as Level-1 renaming, and it is done by big. Figure <ref type="figure" target="#fig_3">5a</ref> illustrates an example of this mechanism. The instructions shown in "Original Assembly" depict instructions in program order. In "After Level-1 Renaming", each register is updated to the form Ri.j, where i is the original AR index and j is the suffix. In the example, R2.0 indicates a live-in value to the trace. R2.1 (Inst #1) and R2.2 (Inst #4) denote writes to R2, yielding a total of three versions of AR 2 in this trace. The 3-wide big issues this trace for execution over four cycles as shown under "Issue Order". Level-1 trace encoding ensures correct data-flow across instructions within a trace. However, for the subsequent trace to read its correct live-in values, the current trace's live-outs need to be available int the corresponding suffix 0 registers.</p><p>To maintain correct data-flow across traces seamlessly, the OinO performs Level-2 renaming, using a  modified version of the rotational remap scheme used by DIF <ref type="bibr" target="#b11">[11]</ref>. Each AR is mapped to a fixed size circular buffer of PRs, shown as the Physical Register File (PRF) in Figure <ref type="figure" target="#fig_3">5b</ref>. The head and tail pointers to this buffer are pointed to by the Global Last-Written (GLW) and Local-LW (LLW) registers respectively. On a register read, little reads from the PR pointed to by the modulo addition of the AR's suffix and GLW <ref type="foot" target="#foot_2">3</ref> . The GLW thus represents the index of the 0-suffix PR (livein value to the trace) and the LLW points to the latest index written by the current trace. Each time an AR is written to, the LLW is incremented (modulo add). For example, instructions 1 and 3 in Figure <ref type="figure" target="#fig_3">5a</ref> both write to AR 2, causing the LLW to hold the value 2. At the end of the trace, LLW points to the PR which holds that AR's live-out value.</p><p>On trace completion, an AR's GLW should be updated to its LLW register, so that subsequent traces can calculate the correct index for their live-in registers. Rather than copy the index value from the LLW to the GLW for every AR, we choose to have a ping-pong bit to interchangeably access these two index fields for alternate traces. For example, in Figure <ref type="figure" target="#fig_3">5b</ref>, at the beginning of the first trace, R2's ping-pong bit is cleared and the GLW referenced is 0. At the end of the trace, the LLW is index 2. If the trace completes successfully, R2's ping-pong bit is set and henceforth index 2 is chosen to be the GLW. In case the trace fails, the ping-pong bit is unmodified and the trace restarts in program order, guaranteeing that the most recent value of the AR prior to misspeculated trace execution is read. Only OinO mode can flip an AR's ping-pong bit.</p><p>Our design allows a maximum of 4 PRs per integer and floating point register, and up to 16 PRs for Conditional code registers in the ARM ISA. The constraint that an AR can be mapped to at most a fixed number of PRs forces the trace schedule generation algorithm on big to discard many schedules, limiting achievable energy savings. We investigate OinO's sensitivity to this constraint in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Speculative Trace Start</head><p>Since little is capable of speculative execution, Dy-naMOS allows consecutive traces to start issuing after the previous memoized trace issues, without waiting for its completion. This is subject to the constraint that there are never more than 4 versions of an AR in the pipeline. DynaMOS achieves this by flipping the pingpong bit on successful trace issue, instead of commit. In order to preserve correctness, a Commit-GLW register stores the last successfully committed index of an AR when a trace commits. In case of misspeculation, the ping-pong bit is flipped back, the Commit-GLW is copied to the GLW register, and InO mode takes over execution. This design constrains the number of active traces in the pipeline to at most 2, which is reasonable, since an InO core can't get too far ahead without stalling on a use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Handling Speculative Memory Operations</head><p>OoO cores reorder memory operations to maximize performance. However, executing loads/stores before older stores will lead to erroneous execution if they refer to the same address. The big uses a load/store queue (LSQ) to track in-flight values for the same memory address and detect memory aliasing. As OinO mode executes schedules with reordered memory operations, it must also handle memory aliasing. To this end, Dy-naMOS supplements little with a simplified LSQ.</p><p>However, without knowledge of the original program ordering between memory operations, the LSQ cannot function correctly. The beginning of every trace therefore also includes a fixed size meta-block to hold this information. This block, shown in Figure <ref type="figure" target="#fig_4">6</ref>, contains the relative program sequence number for each memory operation with respect to the first memory operation of the trace. For example, while "Str b" is issued out of program order, its original relative sequence number (2) is recorded into the meta-block.</p><p>In the OinO mode, out-of-order memory operations are allocated entries in little's LSQ by indexing into the structure by their original sequence numbers. Allocating memory operations in program order in the LSQ thus allows memory alias checks to be performed cor- rectly. For example, "Str is inserted into index 2, and aliasing checks are performed for existing younger loads with higher index numbers (to the left), i.e., Ld c at index 4. If a store-to-load alias is detected, the trace aborts and little restarts in InO mode. If no aliases are detected and the trace completes, store values are scheduled to be written to memory and the LSQ is cleared for the following trace.</p><p>As the LSQ index is determined by the sequence number, its size and hence the number of memory operations allowed in a trace is limited. 5 bits are needed to store the relative sequence # per memory operation. For a 32 entry LSQ, this yields a 20B meta-block per trace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Handling Precise Interrupts</head><p>An interrupt in OinO mode, is treated as a misspeculation event, causing a pipeline and LSQ flush. The trace restarts in InO mode which handles the interrupt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Trace Generation and Selection</head><p>To execute a memoized trace in OinO mode, we must first have access to them. big is responsible for determining, building, and storing traces in DynaMOS .</p><p>Firstly, big determines trace boundaries, and calculates a unique TraceID for each trace. Nominally, a trace would include all instructions between two consecutive backward branches. However, it is occasionally necessary to truncate or extend traces due to length constraints. The trace length must be sufficiently long (more than 20 instructions), to allow useful reordering among instructions. Similarly, the trace length is bounded by big's instruction window size, this being the maximum window over which reordering can occur.</p><p>Next, memoizable traces need to be identified and stored. A trace's memoizability quotient is tracked by a 4-bit confidence counter in the Trace Selection Table (Figure <ref type="figure">7</ref>). While learning, big indexes into the table using the header-PC and matches traces with the TraceID. The counter is initialized to 3, increased by 1 when a trace's schedule repeats, and reduced by 3 when a trace In little, when the branch predictor predicts the target to a backward branch (start of a trace), it is looked up in parallel in the Trace Selection Table and the ICache (Figure <ref type="figure">7</ref>). If the In-STC bit is set, blocks are fetched from the STC into OinO's fetch buffer. Otherwise, they are fetched from the ICache and InO mode executes.</p><p>A fill buffer similar to that used in <ref type="bibr" target="#b14">[14]</ref> is used to combine instructions in issue-order on the big. This is validated at commit to ensure only non-speculative instructions within the trace are bundled together and stored into the STC . While writing to the fill buffer, the big encodes each instruction with a renamed register suffix (Section 3.2.1), increasing each register field by 2 bits. The first block of a trace in the STC is pointed to using a set-ID associated with each trace and all other blocks are accessed sequentially. As our traces are of variable lengths, they may span multiple blocks. A special End of Trace marker denotes trace completion.</p><p>For capacity replacements in the STC , first, traces that have been rendered un-memoized due to highly varying schedules and then LRU traces are picked until sufficient space is created for a new trace. To avoid fragmentation of traces, we implement compaction in our STC , based on <ref type="bibr" target="#b16">[16]</ref>. Since writes to this cache happen only on big commits, and are not on the critical path of OinO's fetch, the overheads of compaction do not affect performance. Multiple writes to the STC might be necessary on a replacement, costing energy. But in our experiments with a 4kB STC , replacement happens rarely, amortizing the costs. The strict trace selection algorithm described previously ensures that only beneficial traces occupy the STC , resulting in high hit rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Controller</head><p>We adopt the controller of Padmanabha <ref type="bibr" target="#b5">[5]</ref> to decide which core, big or little, should execute the current trace to maximize efficiency. The controller maximizes energy savings while keeping a constraint on the allowable performance loss (5% as compared to running only on the big). Traces with high ILP and/or MLP are run on big to maximize performance while traces with numerous dependent cache misses and/or branch mispredictions are run on little to gain energy savings.</p><p>The controller needs to make a two-level prediction, i.e., what trace will be seen next and which core should execute it. It uses a combination of history and program context to predict the upcoming trace. A traces preference to a core is determined by its relative performance either core in the past. Measuring performance on the core it actually executed on is easy; a linear regression model (trained offline using SPEC's train data set) is used to estimate its performance on the other core, similar to that in <ref type="bibr" target="#b5">[5]</ref>. Performance metrics of a trace, such as cache misses, branch mispredicts, ILP, MLP, its memoizability quotient and estimated migration overhead, are fed as inputs to this performance model. Overall performance target is maintained by a feedback PI (Proportional-Integral) controller.</p><p>Unfortunately, while DynaMOS can detect memoizable traces that are, on average, 40 instructions long, the underlying architecture is incapable of transitioning between big and little at that granularity. Therefore, we are forced to combine consecutive traces together to form a super-trace, consisting of approximately 300 instructions. A super-trace is deemed memoizable if more than 80% of its instructions are present in the STC . We augment the super-trace prediction mechanism with this information, to give prediction accuracies of 80%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Switching overheads</head><p>DynaMOS adopts the Composite Core <ref type="bibr" target="#b4">[4]</ref> architecture, which tightly couples the big and little cores by enabling shared access to stateful structures, i.e., instruction and data caches, TLBs, and branch predictor. Only the register file has to be explicitly transferred between the cores on migration. This avoids the need to rebuild architectural state when migrating to the other core. Overhead for switching between cores is thus small, consisting of pipeline and store buffer drain of the active core, register file transfer and pipeline refill on the other, totaling 0.1% of execution time. These low overheads allow DynaMOS to switch rapidly between cores when memoized traces are encountered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">METHODOLOGY</head><p>We perform cycle-accurate simulations on the Gem5 simulator <ref type="bibr" target="#b17">[17]</ref> to model performance of the cores and memory, the overheads of switching between the cores, and all the building blocks of DynaMOS. The high performing big core is a deeply pipelined 3-issue superscalar OoO processor with a large ROB and LSQ. Its ability to dynamically reorder instructions allows it to achieve 1.6x higher performance than little on an average for SPEC2006 benchmarks. The energy efficient little is an InO core that has the same superscalar width and FUs as big. This allows OinO to execute OoO schedules ver-  <ref type="bibr" target="#b18">[18]</ref>. A core is assumed to be clock gated when inactive rather than power gated, as power gating adds significant overheads that do not scale at fine-granularity switching. The little pays an extra energy overhead for accessing the LSQ, bigger PRF, and STC when OinO mode is active.</p><p>For our evaluations, we use simpoints <ref type="bibr" target="#b19">[19]</ref> from the SPEC2006 benchmark suite, compiled using gcc with -O2 optimizations for the ARM ISA. A maximum of 5 simpoints comprising of 1 million instructions each were picked from the first 2 billion dynamic instructions for each benchmark. Across 26 benchmarks (all those that compiled and ran on our simulator), we found 108 representative simpoints. Results for each simpoint are weighed and grouped with its parent benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS</head><p>This section provides quantitative benefits of DynaMOS and compares them to oracular knowledge and prior work <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b10">10]</ref>, along with intuitions as to why some benchmarks are more amenable to our technique than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Utilization of Little</head><p>The energy savings attainable by DynaMOS is proportional to the utilization of the little core. Utilization is defined as the fraction of the dynamic program executed on little, and is shown in Figure <ref type="figure" target="#fig_5">8</ref>. DynaMOS tries to maximize this utilization while limiting the slowdown to 5% compared to big. We compare our results to an oracle and identically resourced Composite Core architecture without OinO mode provisions (CC). The oracle assumes perfect knowledge of execution and zero switching overheads, thus providing the most optimistic utilization of little given a performance constraint. It chooses a single best schedule for memoizable traces over the entire application and runs that on the OinO mode. 50% of the application runs on little on average with oracle, of which 43% is executed on OinO mode.</p><p>We see that with practical constraints, DynaMOS is able to run 37% of its instructions on little, which is a  2.9x increase over prior work (13%) <ref type="bibr" target="#b5">[5]</ref>. This is due to OinO mode's comparable performance to the big, allowing more instructions to run on little without incurring additional performance loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmark analyses</head><p>DynaMOS excels for benchmarks like hmmer, bzip2 and h264ref that have high code locality, and recurse heavily in loops with straightforward control and data flow. Contrarily, the inherent lack of memoizability in benchmarks like astar, gcc and gobmk hinders Dy-naMOS ' operation. However, little utilization is maintained because their low ILP and/or predictability allows them to run on InO mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Percentage of memoizable code</head><p>The amount of execution that can be memoized clearly dictates the profitability of DynaMOS . The oracle bar in Figure <ref type="figure" target="#fig_5">8</ref> shows how much of the execution can theoretically be memoized given a performance constraint (Note: Figure <ref type="figure" target="#fig_1">2</ref> in Section 2 shows the same result albeit with no performance constraint). Across the SPEC suite, we see benchmarks showing varied memoizable quotients. For example, the oracle schedules a meager 5% of execution on astar; astar implements a path finding algorithm that reiterates in the same function repeatedly, although dynamic instances take different paths. Hence, though there is code locality, there is no trace locality, disqualifying most of its execution from being memoized. On the other extreme, bzip2 goes through a dominating simpoint phase comprised of only 7 loops, of which 5 can be memoized, showing great potential for OinO execution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Misspeculation overheads</head><p>Schedules that misspeculate have to incur a penalty of abort and replay, negating the benefits of running on OinO. Misspeculations occur when a forward branch in the trace takes the unexpected path or when a memory alias error is detected. Our trace selection algorithm heavily penalizes traces that abort often, so that they are disqualified from being scheduled on OinO, thus minimizing additional penalty cycles. Figure <ref type="figure" target="#fig_6">9</ref> shows the percentage of schedules that abort while in OinO. In gobmk, there can be many traces that spawn from a common header PC. Its high branch misprediction rates <ref type="bibr" target="#b13">[13]</ref> indicate that these traces are not predictably repeatable. Hence, although each individual trace is highly memoizable (as was shown in Figure <ref type="figure" target="#fig_1">2</ref>), the algorithm disqualifies all but 9% of them to run on OinO (Figure <ref type="figure" target="#fig_5">8</ref>). Consequently, only 7.8% of the traces that are finally picked to go on OinO abort, adding a time penalty of 0.3% of total execution.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">OinO's architectural limitations</head><p>Another artifact of our architecture is the limitations on the amount of reordering achievable on OinO. Our schedules are constrained by the number of PRs an AR can be renamed to in the trace body, the number of memory operations allowed, and its size. tion window of 40 instructions, the average trace-size observed empirically, limiting the number of instructions it can reorder over. Next, we limit the number of PRs it can access. We compare these to little with and without OinO mode enabled for the whole program. On average, little with OinO attains 91% of a constrained big's performance. This shows that the 9% of performance loss can be attributed to the inherent lack of memoizable traces in the program, preventing OinO mode from being used. Note that little with OinO gains a speedup of 30% over InO mode, achieving 82% of big's performance on average.</p><p>The oracle classifies 66% of execution as memoizable in cactusADM (Figure <ref type="figure" target="#fig_5">8</ref>). DynaMOS fails to replicate this because the dominant simpoint in cactusADM comprises 3 regular traces that are more than 1000 instructions long. DynaMOS limits the maximum length of traces to 128 instructions and no reordering is allowed around trace boundaries. The unrestrained big can exploit more MLP and ILP by reordering over the entire trace. Figure <ref type="figure" target="#fig_7">10</ref> illustrates that with a limited instruction window big loses 9% performance, dropping further to 85% of unrestrained big with a smaller PRF. On the other extreme, hmmer, has a small dominant loop which has to be unrolled 4 times to reach our minimum trace length, requiring more than 4 PRs to rename to per AR, preventing it from being run on OinO.</p><p>DynaMOS 's optimization of speculatively starting a trace before the previous trace commits (Section 3.2.2), saves the OinO mode 1% performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Energy Savings</head><p>Figure <ref type="figure" target="#fig_8">11</ref> illustrates the energy conserved on Dy-naMOS as compared to running only on big. Overheads due to leakage from the inactive core (which is clockgated) and those imposed by the CC controller <ref type="bibr" target="#b5">[5]</ref> are included. Including OinO mode on little adds around 8% energy overhead to an InO, from accessing a bigger PRF and LSQ, but reduces its run-time significantly. The addition of a 4kB STC adds more leakage overheads, but contributes to lowering of OinO's energy by providing instruction fetch access to a smaller cache. In case of misspeculation however, little faces an energy penalty of accessing instructions from both the caches. Overall, we observe that DynaMOS conserves upto 30% of big's energy, a 2.1x increase from previous work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Performance compared to Big</head><p>DynaMOS attempts to trade-off a user-configurable level of performance to maximize energy efficiency. This allowable performance loss is assumed to be 5% of big for the purpose of this work, which is maintained as shown in Figure <ref type="figure" target="#fig_9">12</ref>. DynaMOS falls short of the target in a few benchmarks; mcf contains traces with loads that frequently miss in the caches. A schedule that has been created assuming a dCache hit latency for the load stalls on little when the load misses. The inability of OinO mode to react to such unexpected behavior and reorder instructions imposes performance loss. A high trace misprediction rate (Figure <ref type="figure" target="#fig_6">9</ref>) also causes slowdown due to the need to rollback and replay. Note that leslie3d and bwaves overshoot the performance target, because the CC predictor overlooks some opportunities to switch to little. More fine tuning of this controller should mitigate this problem.  Unequal issue widths cause inefficient use of DynaMOS ' one-to-one trace mapping, providing modest benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Sensitivity Analyses</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Sensitivity to core configuration</head><p>For our work, the little is configured to be 3-wide superscalar so that memoized schedules from a 3-wide big can be replayed verbatim on OinO. However, this is not essential for correct execution of DynaMOS . Figure <ref type="figure" target="#fig_11">13</ref> illustrates the efficacy of DynaMOS on differently configured systems -particularly with a bigger big and a smaller little. All resources in the cores, including FUs are scaled appropriately. The results are shown relative to the corresponding big in that system. As per our current implementation, if an issue slot in a trace is wider than the issue width of little, it simply splits each slot into 2 or more slots. For example, a 2-wide little splits an issue slot from a 3-wide big into 2 slots of 2 and 1 each, adding bubbles in the pipeline. This inefficiency results in less utilization of OinO, resulting in modest improvements in energy savings achieved by DynaMOS . This can be avoided by adding more intelligence to the trace creating process of big, and packing issue slots as per the width of little.</p><p>Increasing the issue width of an InO core adds less energy than that for an OoO core, because of the relative simplicity of the InO's issue logic. This explains two observations -by virtue of increasing time spent on little, DynaMOS , which uses a 3-wide little saves 30% energy, as compared to that using a 2-wide little to save 20% energy. Second, it is more of an energy win to go to a 3-wide little from a 4-wide big than to a 2-wide little from a 3-wide big. Hence, although little utilization is approximately the same for both configurations shown in figure <ref type="figure" target="#fig_11">13</ref>, more relative energy savings can be achieved with a more aggressive big.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Sensitivity to Size of Schedule Trace-Cache</head><p>The STC size dictates how many schedules are available to OinO when execution migrates to little. Figure <ref type="figure" target="#fig_12">14</ref> illustrates the effects on little's utilization and performance as the STC size varies. As expected, utilization increases as the size increases from 1kB to 4kB because of reduction in capacity misses. Beyond that we observe that utilization plateaus out as most of the required schedules fit in the cache, prompting us to choose a 4kB STC for DynaMOS .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Comparison to Execution Cache</head><p>Research has proposed to conserve energy of the pipeline front-end by caching recurring traces to exploit temporal locality of instructions. We compare DynaMOS to two of the most relevant works in Figure <ref type="figure" target="#fig_3">15</ref>. Loop Caches (LC) <ref type="bibr" target="#b20">[20]</ref> cache encoded or decoded instructions from recurring loops, thus eliminating energy consumed by the fetch and/or decode stages. Execution Caches <ref type="bibr" target="#b10">[10]</ref> exploit memoizability in schedules and conserves energy by bypassing the fetch, decode, rename and issue stages of an OoO pipeline and sending instructions directly to execution. Figure <ref type="figure" target="#fig_3">15</ref> shows that on average adding a 4kB LC to big conserves 4% energy while adding a 4kB EC saves 23% of energy at the cost of 16% loss in performance. Adding a feedback controller similar to that in DynaMOS can constrain performance loss to 5% by limiting the use of EC when performance degradation is observed, subsequently reducing energy savings further to 10% (Big+EC@5% bar). Two rea- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Energy and Area Overheads</head><p>Little is provided with a larger PRF to ensure seamless and inexpensive register renaming. In our implementation it has 128 entries, 4x the existing size. Each AR needs 2 bits each for Committed, Global and Local LWs fields, and 1 ping-pong bit, totaling 7 bits of information with each AR (Section 3.2.1). Little also includes a 32 entry LSQ, increasing its energy by 8%. These bigger structures can be clock-gated when running in InO mode. Adding a 4kB STC adds 0.11mm 2 of area and 10% leakage power overhead to the little. We do not however model the energy overheads of the logic added. The inactive pipeline, which is clock-gated, contributes to the leakage energy overhead. Since our architecture is targeted toward low-power cores, we use low-leakage technology with low operating power, minimizing this overhead to &lt;4%. Prior work <ref type="bibr" target="#b5">[5]</ref> estimates the controller to incur overheads of 1.875kB storage and 0.033W power, while the performance estimation model covers 0.02mm 2 area, and consumes &lt;5uW power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORKS 6.1 Efficiency through Heterogeneity</head><p>Researchers have explored the architecture design space in various dimensions of heterogeneity. These include cores with different sets of microarchitectural parameters <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b22">22]</ref>, specialized hardware for specific codes <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24]</ref>, and heterogeneous ISAs <ref type="bibr" target="#b25">[25]</ref>. Commercial products include ARM's big.LITTLE <ref type="bibr" target="#b1">[1]</ref> and NVidia's Kal-El <ref type="bibr" target="#b26">[26]</ref> which combine high and low performance general purpose cores, and IBM's Cell <ref type="bibr" target="#b27">[27]</ref> and Intel's vPro <ref type="bibr" target="#b28">[28]</ref> which run special code on customized elements.</p><p>The architecture of the heterogeneous multicore dictates the granularity of application migration amongst them. Higher switching costs of coarse-grained heterogeneous systems <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2]</ref> enforce switching granularities of the order of milli-seconds. Novel architectures minimize migration costs by either sharing of structures between cores <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b7">7]</ref> or reducing the distance between them using 3D technology <ref type="bibr" target="#b6">[6]</ref>. Cores <ref type="bibr" target="#b4">[4]</ref> shares access to L1 caches, TLBs, fetch unit and branch predictor between an OoO and InO core.</p><p>Another approach to heterogeneity is to reduce the voltage and frequency of the core (DVFS) to improve the core's energy efficiency at the expense of performance <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b30">30]</ref>. Recent work <ref type="bibr" target="#b31">[31]</ref> shows that microarchitectural heterogeneity, which can altogether eliminate use of energy-intensive structures like the ROB and issue logic helps conserve more energy than DVFS. Nevertheless, DVFS is a complementary technique that can be applied to DynaMOS for additional energy savings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Trace-Based Execution</head><p>Several prior works proposed storing instructions in logical dependency order rather than the order in which they are stored in memory <ref type="bibr" target="#b14">[14]</ref>. They aim to improve efficiency of fetch by grouping instructions that are likely to execute together as a trace in a trace cache.</p><p>Compilers use profile-based static scheduling mechanisms <ref type="bibr" target="#b32">[32]</ref> or run-time binary optimization <ref type="bibr" target="#b33">[33]</ref> to create optimized instruction schedules. Most compilers however, cannot schedule beyond a few basic blocks due to data and control flow unpredictability. Allowing OoO hardware to create the schedule ensures that InO is provided with the best-case schedule for a particular trace for a particular dynamic phase in the program. Software approaches, e.g. Nvidia's Project Denver, dynamically re-compile recurring traces to create highperforming schedules for an InO core. Compared to hardware implementations, such methods react tardily to finer-grained phase changes in applications. Also, recompilation of traces cannot be done indiscriminately, while DynaMOS modifies schedules as needed.</p><p>Industry introduced trace caches as a method to improve performance and energy-efficiency by caching postdecode traces, thus allowing expensive CISC decoders to be turned off <ref type="bibr">[9,</ref><ref type="bibr" target="#b34">34]</ref>. Section 5 compares DynaMOS 's behavior to relevant schemes that exploit temporal locality of instructions to conserve pipeline front-end energy. Villavieja et.al <ref type="bibr" target="#b35">[35]</ref> propose to transition from an OoO core to a VLIW core with all front-end stages turned off when a memoized VLIW schedule is available. In case of highly unpredictable branches, the lack of memoizability forces these works to fall-back on the OoO core. DynaMOS on the other hand, can still gain energy-efficient execution on the InO mode.</p><p>Other works propose using two pipelines: one for trace generation and another for trace execution. Turboscalar <ref type="bibr" target="#b12">[12]</ref> has a thin cold pipeline that discovers ILP over a long instruction window and a fat hot pipeline to exploit this knowledge. Perhaps the work that most closely resembles ours is DIF <ref type="bibr" target="#b11">[11]</ref>. They use a primary OoO engine to create and cache schedules, which are then formatted as a VLIW and made accessible to a secondary VLIW-style accelerator. DIF's aim is to in-crease performance by dynamically increasing the ILP exposed to a narrower superscalar OoO and running it on a wide VLIW machine. Our goal is to trade-off performance for energy-efficiency by exposing ILP to a simpler InO core, allowing the complex OoO to remain idle. Also, our little doesn't rely exclusively on big to provide it with instructions, and is capable of working stand-alone when energy-efficiency is of utmost importance. We leverage two-level renaming that was proposed in this paper, and modify it so that we do not have to generate and store live-out register maps for every trace, which is expensive to do dynamically. The HBA <ref type="bibr" target="#b7">[7]</ref> architecture comprises of a common front-end and register file which feeds into one of either OoO, InO, and VLIW backends. It stores instruction schedules at the granularity of a couple of basic blocks and heuristically decides to run on one of the backends.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>In this paper, we observe that the sequence in which instructions in an OoO pipeline are issued to execution tends to remain similar for repeating traces. OoO cores perform redundant work by recreating the same schedule for every instance of the trace. Based on this insight, we provision an InO core with the ability to read and execute issue schedules recorded by an OoO core. We observe that with equal resources, an InO core can nearly achieve OoO's performance, at a fraction of the energy cost. We propose the DynaMOS architecture, which consists of a tightly-coupled big and little core, wherein execution migrates with low overheads from big to little for traces with either low IPC or with memoized schedules. To this end, little is provisioned with an OinO mode which can execute memoized out-of-order schedules while guaranteeing correctness. DynaMOS was shown to increase little's utilization by 2.9x over prior work, thus saving 32% energy over execution on only big, with an allowable 5% performance loss.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Harnessing heterogeneity for energy-efficiency in h264ref . Each point represents a trace in program order, where the black (+) and gray (x) traces have different and identical issue schedules respectively.</figDesc><graphic url="image-1.png" coords="2,316.81,53.80,259.21,140.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Oracle results estimating the utilization of a little core both without and with memoized schedules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Histogram categorizing program execution based on how memoizable its OoO schedules are (its memoizability quotient). A majority of the dynamic execution falls under the highly memoizable category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Handling false dependencies on OinO with a two-level register renaming scheme, where the Level-1 is done by big and encoded with the schedule and Level-2 is done on the OinO during execution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Memoized memory operations track their original ordering and are inserted into little's LSQ in program order.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Fraction of total execution run on big and little's two modes, at 95% performance relative to all big. The three bars represent the utilization achieved by a Composite Core (CC), an oracle and DynaMOS respectively. DynaMOS achieves better or equal little utilization compared to prior work (wherein the OinO fraction is zero).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Schedules mispredicted on OinO mode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Quantifying the limits imposed to maximum achievable performance on OinO due to its architectural inhibitions, by constraining big similarly</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Energy savings attainable on DynaMOS, compared to only big</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Performance of DynaMOS as compared to only big; Slowdown is maintained around 5%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>-wide Big + 2--wide Li9le) DynaMOS (4--wide Big + 3--wide Li9le) U&gt;liza&gt;on of Li9le Energy savings rela&gt;ve to Big Performance loss rela&gt;ve to Big</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Sensitivity to big and little's architectures. Unequal issue widths cause inefficient use of DynaMOS ' one-to-one trace mapping, providing modest benefits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Benefits of increasing STC size plateau out after 4kB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Fetch in little. A trace header-PC predicted by branch predictor is looked up in Trace Selection Table. If the In-STC bit is set, OinO mode is used. Else InO mode executes. is aborted in the OinO mode on a misspeculation. Note that a trace's schedule can differ slightly over different instances, if, for example, a load hits in the LSQ vs the L1 Cache. If this variation occurs infrequently, and the OoO does not gain significant performance due to the varied schedule, it is still considered memoizable. Traces with a confidence of greater than 7 are considered memoizable and their schedules can written to the STC . Empirically, we find that on average, less than 150 traces need to be stored in the Trace Selection Table for an application (0.3kB of storage).</figDesc><table><row><cell cols="2">(ii) If (In Trace-Cache): SetID</cell><cell cols="3">Cache (STC) (n Instructions) Schedule Trace</cell><cell>Buffer Fetch (iii)</cell><cell>OinO</cell></row><row><cell>(i) Next-Trace Header PC</cell><cell cols="2">Valid (1 bit)</cell><cell>TraceID (5 bits)</cell><cell>SetID (6 bits)</cell><cell>In STC (1 bit)</cell><cell>Memoize Confidence (4 bits)</cell></row><row><cell>(From Branch-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pred)</cell><cell></cell><cell></cell><cell cols="3">Trace Selection Table</cell></row><row><cell>Figure 7:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Experimental Core Parameters batim. The simpler hardware resources of an InO core allow it to consume a lower energy per instruction than the OoO core, saving 60% energy overall. Additionally, its shorter pipeline length affords it a quicker branch misprediction recovery. Table1describes the configurations used in detail. We used the McPAT modeling framework to estimate static and dynamic energy consumption of the core and L1 caches</figDesc><table><row><cell cols="2">Architectural Feature Parameters</cell></row><row><cell>Big backend</cell><cell>3 wide superscalar @ 2GHz</cell></row><row><cell></cell><cell>12 stage pipeline</cell></row><row><cell></cell><cell>128 entry ROB</cell></row><row><cell></cell><cell>180 entry integer register file</cell></row><row><cell></cell><cell>256 entry floating-point register file</cell></row><row><cell>Little backend</cell><cell>3 wide superscalar @ 2GHz</cell></row><row><cell></cell><cell>8 stage pipeline</cell></row><row><cell></cell><cell>180 entry integer register file</cell></row><row><cell></cell><cell>128 entry floating-point register file</cell></row><row><cell>Memory System</cell><cell>32 KB L1 iCache (Shared)</cell></row><row><cell></cell><cell>32 KB L1 dCache (Shared)</cell></row><row><cell></cell><cell>1 MB L2 Cache with stride prefetcher</cell></row><row><cell></cell><cell>2048MB Main Mem</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>DynaMOS 's relative benefit -First, it moves execution over to a different InO core which runs at 30% of big's power when traces are memoizable, while power hungry structures like the ROB, LSQ are active throughout execution in a big with an EC. Second, the InO mode also executes non-memoizable but low performance traces at minimal performance loss. astar, for example, has a low memoizable quotient, and hence schedules are rarely available in the Trace-cache or EC. Still, DynaMOS runs 18% of its code on little in InO mode, yielding 20% more energy savings.</figDesc><table><row><cell>35%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>30%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>25%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>20%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>15%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Big+LoopCache</cell><cell>Big+EC</cell><cell>Big+EC@5%</cell><cell>DynaMOS</cell><cell>Big+LoopCache</cell><cell>Big+EC</cell><cell>Big+EC@5%</cell><cell>DynaMOS</cell></row><row><cell></cell><cell cols="2">Energy savings rel to Big</cell><cell></cell><cell></cell><cell cols="2">Performance loss rel to Big</cell><cell></cell></row><row><cell cols="8">Figure 15: savings and corresponding perfor-</cell></row><row><cell cols="8">mance losses relative to big for a big augmented with a</cell></row><row><cell cols="7">Loop Cache(LC) and Execution Cache(EC) [10]</cell><cell></cell></row><row><cell cols="2">sons contribute to</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We adopt ARM's terminology of big and little for our work, although our InO little has the same issue width and functional units as big</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p><ref type="bibr" target="#b2">2</ref> OinO stands for an InO core appearing to be OoO</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note, if the size of the circular buffer of PR's is a power of 2, this modulo operation can be reduced to a hash using a cheaper XOR operation.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8.">ACKNOWLEDGEMENTS</head><p>This work is supported in part by <rs type="funder">ARM Ltd</rs> and by the <rs type="funder">NSF</rs> under grant <rs type="grantNumber">SHF-1217917</rs>. The authors would like to thank fellow members of the <rs type="institution">CCCP research group</rs>, and the anonymous reviewers for their time, suggestions, and valuable feedback.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_k42aU6V">
					<idno type="grant-number">SHF-1217917</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Big.little processing with arm cortex-a15 &amp; cortex-a7</title>
		<author>
			<persName><forename type="first">P</forename><surname>Greenhalgh</surname></persName>
		</author>
		<ptr target="http://www.arm.com/files/downloads/bigLITTLEFinal.pdf" />
		<imprint>
			<date type="published" when="2011-09">Sept. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Single-isa heterogeneous multi-core architectures for multithreaded workload performance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Farkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2004">2004</date>
			<publisher>IEEE Computer Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Energy-performance tradeoffs in processor architecture and circuit design: a marginal cost analysis</title>
		<author>
			<persName><forename type="first">O</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahesri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="26" to="36" />
			<date type="published" when="2010">2010</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Composite cores: Pushing heterogeneity into a core</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lukefahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Padmanabha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Sleiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dreslinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Trace based phase prediction for tightly-coupled heterogeneous cores</title>
		<author>
			<persName><forename type="first">S</forename><surname>Padmanabha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lukefahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 46th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="445" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rationale for a 3d heterogeneous multi-core processor</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Dwiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B R</forename><surname>Widialaksono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tshibangu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Lipa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><surname>Franzon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">migration</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The heterogeneous block architecture</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fallin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-03">March 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discerning the dominant out-of-order performance advantage: is it speculation or dynamism?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcfarlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zilles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGPLAN Notices</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="241" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Trace based instruction caching</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Krick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Upton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">786</biblScope>
			<date type="published" when="2000">Jan. 25 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Execution cache-based microarchitecture for power-efficient superscalar processors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Talpes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="26" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Very Large Scale Integration (VLSI) Systems</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploiting instruction level parallelism in processors by caching scheduled groups</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hopkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th Annual International Symposium on Computer Architecture</title>
		<meeting>of the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="13" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Turboscalar: a high frequency high ipc microarchitecture</title>
		<author>
			<persName><forename type="first">B</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCA</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="36" to="44" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Performance characterization of spec cpu benchmarks on intel&apos;s core microarchitecture based processor</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Phansalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mericas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Indukuru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPEC Benchmark Workshop</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Trace cache: a low latency approach to high bandwidth instruction fetching</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th annual ACM/IEEE international symposium on Microarchitecture</title>
		<meeting>the 29th annual ACM/IEEE international symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="24" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Putting the fill unit to work: Dynamic optimizations for trace cache microprocessors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Friendly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th Annual International Symposium on Computer Architecture</title>
		<meeting>of the 25th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="173" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Performance and power optimization through data compression in network-on-chip architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nicopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Yousif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 14th International Symposium on</title>
		<title level="s">High Performance Computer Architecture</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008. 2008</date>
			<biblScope unit="page" from="215" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The gem5 simulator</title>
		<author>
			<persName><forename type="first">N</forename><surname>Binkert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mcpat: an integrated power, area, and timing modeling framework for multicore and manycore architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<idno>MICRO-42. 42</idno>
	</analytic>
	<monogr>
		<title level="m">nd Annual IEEE/ACM International Symposium on</title>
		<editor>
			<persName><surname>Microarchitecture</surname></persName>
		</editor>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Energy and Performance Improvements in Microprocessor Design Using a Loop Cache</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kursun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Cher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2008 International Conference on Computer Design</title>
		<meeting>of the 2008 International Conference on Computer Design</meeting>
		<imprint>
			<date type="published" when="2008-10">Oct. 2008</date>
			<biblScope unit="page" from="280" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Core architecture optimization for heterogeneous chip multiprocessors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 15th International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>of the 15th International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A unified view of non-monotonic core selection and application steering in heterogeneous chip multiprocessors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Navada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Wadhavkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on Parallel architectures and compilation techniques</title>
		<meeting>the 22nd international conference on Parallel architectures and compilation techniques</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="133" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Conservation cores: reducing the energy of mature computations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goulding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bryksin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lugo-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="205" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Single-chip heterogeneous computing: Does the future include custom logic, fpgas, and gpgpus?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Milder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Harnessing isa diversity: Design of a heterogeneous-isa chip multiprocessor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Venkat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Variable smp -a multi-core cpu architecture for low power and high performance</title>
		<author>
			<persName><surname>Nvidia</surname></persName>
		</author>
		<ptr target="http://www.nvidia.com/content/PDF/" />
	</analytic>
	<monogr>
		<title level="m">tegra white papers/ Variable-SMP-A-Multi-Core</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>CPU-Architecture-for-LowPower-and-High-Performance</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Introduction to the cell multiprocessor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Kahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Hofstee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Maeurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shippy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4.5</biblScope>
			<biblScope unit="page" from="589" to="604" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">2nd generation intel core vpro processor family</title>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="http://www.intel.com/content/dam/doc/white-paper/performance-2nd-generation-core-vpro-family-paper.pdf" />
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An analysis of efficient multi-core global power management policies: Maximizing performance for a given power budget</title>
		<author>
			<persName><forename type="first">C</forename><surname>Isci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 39th Annual International Symposium on Microarchitecture</title>
		<meeting>of the 39th Annual International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2006-12">Dec. 2006</date>
			<biblScope unit="page" from="347" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A dynamic compilation framework for controlling microprocessor energy and performance</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Connors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 38th annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="271" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Heterogeneous microarchitectures trump voltage scaling for low-power cores</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lukefahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Padmanabha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dreslinski</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Parallel architectures and compilation</title>
		<meeting>the 23rd international conference on Parallel architectures and compilation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="237" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The superblock: an effective technique for vliw and superscalar compilation</title>
		<author>
			<persName><forename type="first">W.-M</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Warter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bringmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Ouellette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Hank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kiyohara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Haab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Journal of Supercomputing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="229" to="248" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Increasing the size of atomic instruction blocks using control flow assertions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Crum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual ACM/IEEE international symposium on Microarchitecture</title>
		<meeting>the 33rd annual ACM/IEEE international symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="303" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Micro-operation cache: A power aware frontend for variable instruction length isa</title>
		<author>
			<persName><forename type="first">B</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ronen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orenstien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Almog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="801" to="811" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Very Large Scale Integration (VLSI) Systems</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Yoga: A hybrid dynamic vliw/ooo processor</title>
		<author>
			<persName><forename type="first">C</forename><surname>Villavieja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miftakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<idno>No. 2014-001</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">HPS Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
