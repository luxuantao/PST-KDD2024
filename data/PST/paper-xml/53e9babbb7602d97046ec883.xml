<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combining Global and Local Surrogate Models to Accelerate Evolutionary Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Yew</roleName><forename type="first">Zongzhao</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Soon</forename><surname>Ong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Prasanth</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andy</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
						</author>
						<author role="corresp">
							<persName><roleName>Associate Member, IEEE</roleName><forename type="first">Kai</forename><forename type="middle">Yew</forename><surname>Lum</surname></persName>
							<email>kaiyewlum@nus.edu.sg</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<postCode>639798</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Engineering Sciences</orgName>
								<orgName type="laboratory">Design Group</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<postCode>SO17 1BJ</postCode>
									<settlement>Southampton</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Temasek Laboratories</orgName>
								<orgName type="institution">National University of Singa-pore</orgName>
								<address>
									<postCode>119260</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Combining Global and Local Surrogate Models to Accelerate Evolutionary Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E5A2C076A9ED26A58A938923A4D6D67B</idno>
					<idno type="DOI">10.1109/TSMCC.2005.855506</idno>
					<note type="submission">received September 30, 2004; revised February 22, 2005, and March 31, 2005. This work was supported by NTU/SCE under Grant CE-SUG</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Aerodynamic shape design</term>
					<term>evolutionary optimization</term>
					<term>global and local surrogate model</term>
					<term>genetic algorithm</term>
					<term>Gaussian process</term>
					<term>radial basis function</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a novel surrogate-assisted evolutionary optimization framework for solving computationally expensive problems. The proposed framework uses computationally cheap hierarchical surrogate models constructed through online learning to replace the exact computationally expensive objective functions during evolutionary search. At the first level, the framework employs a data-parallel Gaussian process based global surrogate model to filter the evolutionary algorithm (EA) population of promising individuals. Subsequently, these potential individuals undergo a memetic search in the form of Lamarckian learning at the second level. The Lamarckian evolution involves a trust-region enabled gradient-based search strategy that employs radial basis function local surrogate models to accelerate convergence. Numerical results are presented on a series of benchmark test functions and on an aerodynamic shape design problem. The results obtained suggest that the proposed optimization framework converges to good designs on a limited computational budget. Furthermore, it is shown that the new algorithm gives significant savings in computational cost when compared to the traditional evolutionary algorithm and other surrogate assisted optimization frameworks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>E VOLUTIONARY algorithms (EAs) have been success- fully applied to many complex engineering design optimization problems in recent years. Their popularity lies in ease of implementation and their ability to converge close to the global optimal design. However, EAs typically require thousands of function evaluations to locate a near-optimal solution. Hence, when EAs are applied to problems involving high fidelity simulation codes, the high computational cost involved poses a serious impediment to their successful application. This is primarily because a single exact fitness function evaluation (involving the analysis of a complex engineering system based on high fidelity simulation codes) often consumes many minutes to hours, or even days, of CPU time. One promising way to significantly reduce the computational cost of EAs is to employ com-putationally cheap surrogate models in place of computationally expensive exact fitness evaluations <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b4">[5]</ref>. By leveraging surrogate models, the computational burden can be greatly reduced since the efforts involved in building the surrogate model and optimization using it are much lower than the standard approach of directly coupling the simulation codes with the optimizer.</p><p>In this paper, we present a surrogate-assisted evolutionary optimization framework which combines both global and local surrogate models for solving computationally expensive problems. The present work is motivated by the lack of a suitable multilayer surrogate-assisted evolutionary optimization framework for solving computationally expensive problems. In other words, we show how multiple surrogate models can be combined to accelerate EA search. The first level of the proposed optimization framework involves a strategy that employs a dataparallel Gaussian process (DPGP) surrogate model to identify the promising individuals in the EA population. The DPGP approach was devised to reduce the high computational cost associated with standard Gaussian process (GP) modeling <ref type="bibr" target="#b5">[6]</ref>. Subsequently, the promising individuals undergo Lamarckian learning based on a trust-region enabled gradient-based search strategy that accelerates local search using computationally cheap radial basis function (RBF) surrogate models. Lamarckian learning forces the genotype to reflect the result of improvement by replacing the locally improved individual back into the population to compete for reproductive opportunities.</p><p>The remainder of this paper is organized as follows. Section II presents a brief review of the surrogate assisted EAs described in the literature. Section III introduces the proposed surrogateassisted evolutionary optimization framework for solving computationally expensive problems. Results obtained from numerical studies on a series of benchmark test functions are presented and discussed in Section IV. Section V presents the application of the proposed surrogate-assisted EA to a realworld aerodynamic shape design problem. Finally, Section VI summarizes our main conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Various techniques for the construction of surrogate models, often also referred to as metamodels or approximation models, have been used in engineering design optimization. Among these techniques, polynomial regression (PR), artificial neural network (ANN), radial basis function (RBF), and Gaussian process (GP) [also referred to as Kriging, or design and analysis of computer experiments (DACE)] models are among some of the most prominent and commonly used techniques. Empirical studies of a number of these approximation methods have been made available recently. Among these methods, the RBF and GP methods were shown to perform best under multiple modeling criteria in <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b8">[9]</ref>.</p><p>Apart from the techniques used to construct surrogate models, there has been a growing body of research focusing on the development of new EA frameworks for solving computationally expensive problems on a limited computational budget <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>. Most existing approaches in this area replace the expensive exact objective function with a global surrogate model of the fitness landscape constructed from a limited number of data points that hopefully mimics the entire search landscape. These data points are usually obtained during one or more generations of a classical evolutionary search. Subsequently, the surrogate model is updated online, based on the new data points generated as the search evolves.</p><p>Keane and Petruzzelli <ref type="bibr" target="#b10">[11]</ref> employed variable-fidelity analysis models in the context of genetic algorithm-based optimization of aircraft wings. Ratle <ref type="bibr" target="#b1">[2]</ref> examined a simple strategy for integrating GAs with Kriging models. It uses a heuristic convergence criterion to determine when an approximate model should be updated. The same problem was revisited by El-Beltagy et al. <ref type="bibr" target="#b12">[13]</ref>, where the balance between the concerns of optimization with design of experiments was addressed. Jin et al. <ref type="bibr" target="#b13">[14]</ref> coupled EAs with neural network-based surrogate and proposed an empirical criterion to switch between the expensive and approximate models during the search. In Song et al. <ref type="bibr" target="#b4">[5]</ref>, a real-coded GA coupled with Kriging was demonstrated on firtree structural optimization using a 3σ principle. A strategy for coupling EAs with local search based on a quadratic response surface model was considered in Liang et al. <ref type="bibr" target="#b14">[15]</ref>.</p><p>In practice, due to the curse of dimensionality, accurate global models become increasingly difficult to construct for problems with large numbers of variables. To circumvent these limitations, online local surrogate models have been considered in place of global models in the evolutionary search <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Ong et al. proposed a trust-region approach in the hybrid evolutionary search to interleave use of the exact objective and constraint functions with computationally cheap local surrogate models during Lamarckian learning <ref type="bibr" target="#b0">[1]</ref>. Further, the use of gradient information to improve the approximation accuracy of surrogate-assisted EAs was also considered in <ref type="bibr" target="#b11">[12]</ref>. The local learning technique represents an instance of the transductive inference paradigm, which has been the focus of recent research in statistical learning theory <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EVOLUTIONARY OPTIMIZATION FRAMEWORK COMBINING BOTH GLOBAL AND LOCAL SURROGATE MODELS</head><p>In Section III, we present the essential ingredients of the proposed evolutionary optimization framework combining both global and local surrogate models for solving computationally expensive problems on a limited computational budget. In particular, we consider the general bound constrained nonlinear programming problem of the form Minimize: f (x)</p><formula xml:id="formula_0">Subject to: x l ≤ x ≤ x u (1)</formula><p>where f (x) is a scalar-valued objective function, x ∈ R d is the vector of continuous design variables, and x l and x u are vectors of lower and upper bounds, respectively. In this work, we are interested in cases where the evaluation of f (x) is computationally expensive, and it is desired to obtain a near-optimal solution on a limited computational budget. It is worth noting that the present algorithm may be easily extended to constrained problems by adopting either an augmented Lagrangian or a penalty function approach. The readers are referred to the authors' earlier work in <ref type="bibr" target="#b0">[1]</ref> on how this extension may be achieved.</p><p>For the sake of readability, the proposed hierarchical surrogate-assisted evolutionary optimization framework involves four phases, which are outlined below.</p><p>1) Phase 0 {Initialization}: At the first step, a population of design points is initialized either randomly or using design of experiments techniques such as Latin hypercube sampling. These design points are evaluated using the exact objective function. The exact fitness values obtained are then archived in a central database together with the design vectors. After some initial period of time (for instance, after three generations of standard EA search), a data-parallel Gaussian process (DPGP) modeling method is devised to construct a surrogate model that represents the global trends of the entire fitness landscape, using the top ranking q archived design points of the database as training data.  hence termed here a local surrogate model. If an improved solution is found in the Lamarckian learning process, the genotype is forced to reflect the result of improvement by placing the locally improved individual back into the population to compete for reproductive opportunities. Subsequently, results of any new exact fitness obtained during the Lamarckian learning process are added into the central database, facilitating possible updating of surrogate models through online learning. 4) Phase 3 {Standard EA Operations}: The population then proceeds with the standard EA operators of crossover, mutation, etc. This process of hierarchical surrogate-assisted EA search is continued until the computational budget is exhausted or a user-specified termination criterion is met.</p><p>The basic steps of the proposed evolutionary optimization framework combining both global and local surrogate models for solving computationally expensive problems are listed in Fig. <ref type="figure" target="#fig_0">1</ref>. We next describe Phases 1 and 2 in greater detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Global Search Strategy</head><p>The global search strategy is designed to identify search regions that contain better quality solutions, here represented by the superior individuals in a EA population. An obvious and commonly used technique is to use a surrogate model to preevaluate the entire population of individuals based on the approximated fitness value <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>.</p><p>The choice of global surrogate model in the present framework should be one that is capable of modeling any complex global trends of the exact fitness landscape accurately. A statistically rigorous approximation is the idea of Bayesian interpolation or regression, which is also referred to as Gaussian process (GP) approximation in the neural networks literature, and Kriging in the geostatistics literature. It is generally recognized as a powerful tool for accurately modeling complex landscapes. Since a GP model possesses the aforementioned features, it makes good sense to use it as a global surrogate model. Besides the mean fitness prediction, statistical error estimates can be readily obtained from the Gaussian process approximation, which can be potentially exploited during evolutionary search; see, for example, <ref type="bibr" target="#b19">[20]</ref>. In the present work, the probability of improvement (PoI) <ref type="bibr" target="#b20">[21]</ref> predicted by the GP global surrogate model is used as the preselection criterion to prescreen the population of promising individuals in our global search strategy. This may help to prevent premature convergence to a false global optimum, especially on multimodal and high dimensional problems. Nevertheless, a major disadvantage of the GP approximation method is that model construction and, in particular, hyperparameter tuning, can be rather time consuming when compared to other commonly used approximation methods.</p><p>We now briefly describe the GP modeling technique used here for global surrogate model construction. In addition, the preselection criterion based on the PoI is discussed.</p><p>Let D = {x i , t i }, i = 1, . . . , n denote the training dataset, where x i ∈ R d is an input design vector and t i ∈ R is the corresponding target value. The GP surrogate model assumes the presence of an unknown true modeling function f (x) and an additive noise term v to account for anomalies in the observed data. Thus</p><formula xml:id="formula_1">t(x) = f (x) + v.</formula><p>(</p><formula xml:id="formula_2">)<label>2</label></formula><p>The standard analysis requires the specification of prior probabilities on the modeling function and the noise model. From a stochastic process viewpoint, the collection t = {t 1 , t 2 , . . . , t n } is called a Gaussian process if every subset of t has a joint Gaussian distribution. More specifically</p><formula xml:id="formula_3">P (t | C, {x n }) = 1 Z exp - 1 2 (t -µ) T C -1 (t -µ) (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where C is a covariance matrix parameterized in terms of hyperparameters θ, i.e., C ij = k(x i , x j ; θ) and µ is the process mean. The Gaussian process is characterized by this covariance structure since it incorporates prior beliefs both about the true underlying function as well as the noise model. In the present study, we use the following exponential covariance model:</p><formula xml:id="formula_5">k(x i , x j ) = e -(x i -x j ) T Θ(x i -x j ) + θ d+1 (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where Θ = diag{θ 1 , θ 2 , . . . , θ d } ∈ R d×d is a diagonal matrix of undetermined hyperparameters, and θ d+1 ∈ R is an additional hyperparameter arising from the assumption that noise in the dataset is Gaussian (and output dependent). We shall henceforth use the symbol θ to denote the vector of undetermined hyperparameters; i.e., θ = {θ 1 , θ 2 , . . . , θ d+1 }.</p><p>In practice, the undetermined hyperparameters are tuned to the data using the evidence maximization framework. Once the hyperparameters have been estimated from the data, predictions can be readily made for a new testing point. To illustrate this, assume that t n represents the set of n targets, C n the corresponding covariance matrix and that the process to be modeled has zero mean, i.e., µ = 0. Given a new point x n+1 , it can be shown that the prediction t n+1 has a conditional probability distribution given by</p><formula xml:id="formula_7">P (t n+1 | D, C, x n+1 ) = 1 Z exp - (t n+1 -tn+1 ) 2 2σ 2<label>(5)</label></formula><p>where</p><formula xml:id="formula_8">tn+1 = k T n+1 (x)C -1 n t n (6)</formula><p>and</p><formula xml:id="formula_9">σ 2 n+1 = k(x n+1 , x n+1 ; θ)k T n+1 (x)C -1 n k n+1 (7)</formula><p>where tn+1 and σ 2 n+1 are the predicted posterior mean and variance, respectively, and</p><formula xml:id="formula_10">k n+1 = {k(x n+1 , x 1 ), k(x n+1 , x 2 ), . . . , k(x n+1 , x n )} ∈ R n .</formula><p>Hence, tn+1 is the mean prediction at point x n+1 , σ n+1 is the standard deviation of t n+1 and provides a measure of the confidence at point x n+1 . In other words, the Gaussian process approach results in a surrogate model which is a Gaussian random field.</p><p>From a computational perspective, the search for an optimal GP regressor under the evidence maximization framework <ref type="bibr" target="#b21">[22]</ref> involves solving the following nonlinear maximum-likelihood estimation (MLE) problem to determine the most probable hyperparameters θ MP for the given data:</p><formula xml:id="formula_11">θ MP = min θ L(θ)<label>(8)</label></formula><p>where</p><formula xml:id="formula_12">L(θ) = - 1 2 log detC n - 1 2 t T n C -1 n t N - n 2 log2π<label>(9)</label></formula><p>is the negative log likelihood function.</p><p>The main computational cost involved in constructing GP surrogate models occurs in the MLE phase. Since computing L(θ) and its gradient generally involves computing and decomposing a dense n × n covariance matrix (O(n 3 ) operations) at each iteration, training the GP model can be prohibitively expensive, even for moderately sized data (e.g., a few thousand data points). It is worth noting that an approximation method requiring high computational cost has limited utility in a surrogate-assisted evolutionary optimization framework.</p><p>The computational bottleneck in standard GP modeling can be alleviated by employing a data-parallel approach, which makes it possible to deal with datasets containing tens of thousands of points at modest computational cost <ref type="bibr" target="#b5">[6]</ref>. Since a Gaussian stochastic process is completely specified by its covariance function, training a GP involves considering a parameterized covariance function and determining its hyperparameters θ such that the log likelihood of the data is maximized. We next outline a compactly supported covariance function to facilitate dataparallel GP learning.</p><p>To illustrate our approach, let us assume the existence of p disjoint and spatially localized subsets of the training data, say C 1 , C 2 , . . . , C p . This partitioning of data can be readily achieved using the greedy load balancing clustering algorithm proposed by Choudhury et al. <ref type="bibr" target="#b5">[6]</ref>. Given such a partitioning, the following covariance model can be employed to model the data: <ref type="bibr" target="#b9">(10)</ref> where x i , x j ∈ R d are input vectors, δ ij is the Kronecker delta function, θ is a set of hyperparameters and c : c(x) → 1, 2, . . . , p is an assignment function which maps the input point x to one of p available clusters. Then, the covariance function in ( <ref type="formula" target="#formula_12">9</ref>) can be immediately written for cluster i as</p><formula xml:id="formula_13">k(x i , x j ; c(x i ), c(x j ), θ) = δ c(x i ),c(x j ) k(x i , x j ; θ)</formula><formula xml:id="formula_14">k(x 1 , x 2 ; c( • ), θ) = k(x 1 , x 2 ; θ), c(x i ) = c(x j ) = i = 0, otherwise<label>(11)</label></formula><p>where θ i denotes the set of hyperparameters for the local model trained on the ith cluster. Consider the case when p = 2; i.e., when the data has been partitioned into two disjoint spatially localized subsets. Then, using <ref type="bibr" target="#b10">(11)</ref>, the covariance matrix can be written as</p><formula xml:id="formula_15">K = K 11 0 0 K 22<label>(12)</label></formula><p>where K ii ∈ R n i ×n i contains correlation terms explicitly from the ith cluster which consists of n i points. Since in this case the determinant of the covariance matrix K can be written as the product of determinants of the blocks K 11 and K 22 , the log likelihood can be split into individual log likelihoods for the two partitions, i.e.,</p><formula xml:id="formula_16">L(θ) = L(θ 1 ) + L(θ 2 ).<label>(13)</label></formula><p>From the preceding discussion, it is clear that the use of a compactly supported covariance function naturally leads to a data-parallel learning approach to GP approximation, and hence provides a means to handle large datasets. In general, it is often the case that the predictive capability may reduce when an increasing number of clusters are used <ref type="bibr" target="#b5">[6]</ref>. However, this degradation in performance is often very small and acceptable given the significant savings in computational cost.</p><p>As previously mentioned, the Gaussian process approach results in a random field approximation of the analysis code. Using the output mean prediction t(x) and standard deviation σ(x) of GP model, a variety of preselection criteria for the selection of promising individuals may be formulated to accelerate evolutionary optimization search. An obvious and common preselection criterion is to use the mean prediction for exploiting the knowledge of the GP model to find the promising individuals. However, this may lead to premature convergence in many cases due to the inevitable limitations on the accuracy of a global surrogate model constructed using a few data points. Hence, there is also a need to explore new areas of search space for a more thorough global search. To circumvent this problem, Torczon and Trosset <ref type="bibr" target="#b22">[23]</ref> proposed minimizing the merit function f M = t(x)ασ(x). The first term in the merit function ensures exploration of regions in the design space that are likely to have better solutions, whereas the second term favors those points at which the predictions are likely to have maximum error. The parameter α, in some sense, balances the tradeoff between local exploitation and global exploration. An alleged disadvantage of this approach is that the user has to choose an appropriate fixed value of α or develop a sensible strategy for adapting this parameter as the search progresses.</p><p>Here, we consider using the probability of improvement instead of the merit function, since previous work in <ref type="bibr" target="#b18">[19]</ref> suggests that it performs well. To illustrate the approach used here, consider the case when it is aimed to solve a minimization problem. Let t -denote the smallest value of all the outputs in the training dataset used to construct the GP surrogate. Subsequently, it is intended to use the surrogate model to predict a new point x * at which the output is likely to be lower than t -. The PoI at the point x * (i.e., the probability that the surrogate prediction at x * is lower than t -) can be readily computed from the posterior mean t(x * ) and standard deviation σ(x * ) as follows:</p><formula xml:id="formula_17">PoI(x * ) = Φ t --t(x * ) σ(x * )<label>(14)</label></formula><p>where Φ( • ) is the normal cumulative distribution function. Fig. <ref type="figure" target="#fig_1">2</ref> shows the characteristics of the PoI preselection criterion for a one-dimensional test function. It may be noted from the figure that the PoI criterion is able to correctly identify the region in which the true objective function must be sampled to drive f (x) below t -. The points identified by maximizing PoI(x) can be appended to the baseline training dataset to update the surrogate model (and consequently the PoI criterion). Increasing the number of training points in such a stagewise fashion improves the ability of the PoI criterion to correctly locate the region in which the optimum lies. Note here that this statistical criterion is only used to filter the individuals in an EA population-as discussed later, a local search strategy is employed to identify the best solution in the vicinity of an individual. We also mention here the possibility of employing alternative statistical measures such as the expected improvement criterion proposed by Jones et al. <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Local Search Strategy</head><p>The local search strategy is designed to work with a locally trained system that adjusts to the local properties of the training data in each area of the input space. The surrogate model is constructed using only the m neighboring data points in the database nearest to the design point of interest, because the neighboring points are likely to have more impact than remote ones <ref type="bibr" target="#b2">[3]</ref>.</p><p>The surrogate model used by the local search strategy is built dynamically for every filtered and nonduplicated individual. Since local surrogate models will probably be built thousands of times during the overall search, computational efficiency is a major concern. This consideration motivates the use of RBF local surrogate models, which can be efficiently applied to approximate multiple-input multiple-output data, particularly when a few hundred data points are used for training. The RBF model also has found to offer reasonable accuracy as well as fast training. Since computational efficiency is the major concern, the RBF model is suitable for the local search strategy of the proposed optimization framework.</p><p>Let D = {x i , t i }, i = 1, . . . , n denote the training dataset, where x i ∈ R d and t i ∈ R are the input and output, respectively. Then the local surrogate models are interpolating radial basis function networks of the form</p><formula xml:id="formula_18">t(x) = n i=1 α i K( x -x i ),<label>(15)</label></formula><p>where K( xx i ) : R d → R is a RBF and α = {α 1 , α 2 , . . . , α n } ∈ R n denotes the vector of weights. Typical choices for the kernel include linear splines, cubic splines, multiquadrics, thin plate splines, and Gaussian functions <ref type="bibr" target="#b23">[24]</ref>. We propose the use of linear splines; i.e., xc i , to construct surrogate models since our earlier study <ref type="bibr" target="#b0">[1]</ref> suggests that this kernel is capable of providing models with good generalization capability at a low computational cost. Further, our local search strategy embeds a feasible sequential quadratic programming (FSQP) optimizer within a trust-region framework, which ensures convergence to the local optimum of the exact computationally expensive objective function <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b24">[25]</ref>. More specifically, for each nonduplicated individuals among the top ranking η% in the population, the local search strategy proceeds with a sequence of trust-region subproblems of the form</p><formula xml:id="formula_19">Minimize : f k x + x k c (16) Subject to : x ≤ Ω k (<label>17</label></formula><formula xml:id="formula_20">)</formula><p>where k = 0, 1, 2, . . . , k max , f (x) is the approximation function corresponding to the objective function f (x). x k c and Ω k are the starting point and the trust-region radius used for local search at iteration k, respectively.</p><p>For each subproblem (or during each trust-region iteration), surrogate models of the exact fitness function; viz., f k (x) are created dynamically. The m nearest neighbors of the initial point, x k c , are extracted from the archived database of design points evaluated thus far using the exact analysis codes. The criterion used to determine the similarity between design points is the simple Euclidean distance metric. These points are then used to construct local surrogate models of the exact objective function.</p><p>The surrogate models thus created are used to facilitate the necessary fitness function estimations in the local searches. During local search, we initialize the trust-region Ω using the minimum and maximum values of the design points used to construct the surrogate models. After each iteration, the trust-region radius Ω k is updated based on a measure which indicates the accuracy of the surrogate model at the kth local optimum x k lo . After computing the exact values of the fitness function at this point, the figure of merit ρ k is calculated as</p><formula xml:id="formula_21">ρ k = f x k c -f x k lo f (x k c ) -f x k lo . (<label>18</label></formula><formula xml:id="formula_22">)</formula><p>The above equations provide a measure of the actual versus predicted change in the exact fitness function values at the kth local optimum. The value of ρ k is then used to update the trustregion radius as follows <ref type="bibr" target="#b25">[26]</ref>:</p><formula xml:id="formula_23">Ω k+1 = 0.25Ω k , if ρ k ≤ 0.25 = Ω k , if 0.25 &lt; ρ k ≤ 0.75 = ξΩ k , if ρ k ≥ 0.75<label>(19)</label></formula><p>where</p><formula xml:id="formula_24">ξ = 2, if x k lo -x k c ∞ = Ω k or ξ = 1, if x k lo -x k c ∞ &lt; Ω k .</formula><p>The trust-region radius Ω k is reduced if the accuracy of the surrogate, measured by ρ k is low. Ω k is doubled if the surrogate is found to be accurate and the kth local optimum x k lo lies on the trust-region bounds. Otherwise, the trust-region radius remains unchanged.</p><p>The exact solutions of the objective functions at the kth local optimum are combined with the existing neighboring data points to generate new surrogate models in the subsequent trust-region iterations. The initial point for iteration k + 1 is defined by</p><formula xml:id="formula_25">x k+1 c = x k lo , if ρ k &gt; 0 = x k c , if ρ k ≤ 0. (<label>20</label></formula><formula xml:id="formula_26">)</formula><p>The trust-region process for an individual terminates when the maximum number of trust-region iterations permissible, k max , chosen by the user, is reached. Lamarckian learning then proceeds if the k max local optimum solution obtained is an improvement over that of the initial individual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PERFORMANCE ANALYSIS</head><p>In Section IV, we analyze the performance of the proposed evolutionary optimization framework. Since a genetic algorithm (GA) is used here in the empirical studies, we also refer to the algorithm proposed in the present work as surrogate-assisted genetic algorithm with global and local search strategy (SAGA-GLS). We evaluate the performances of the SAGA-GLS algorithm against a traditional GA, and two surrogate-assisted evolutionary optimization algorithms that were recently introduced in the literature <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>. These are representatives of surrogate-assisted evolutionary algorithm with global-search strategy (SAGA-GS) or local-search strategy (SAGA-LS).</p><p>At each search generation, the SAGA-GS employs the standard RBF or GP surrogate model to screen the entire population of individuals. The predefined top ranking η% individuals in the EA population then undergo exact evaluations. In contrast to <ref type="bibr" target="#b2">[3]</ref>, the SAGA-GS we employed in our study involves using the computationally cheap DPGP and estimates the ranking of the individuals based on their probability of improvements rather than merely using the mean prediction. On the other hand, the SAGA-LS we considered corresponds to the earlier work of the authors <ref type="bibr" target="#b0">[1]</ref> that evolves the solution of each individual in the spirit of Lamarckian learning using local RBF surrogates.</p><p>A standard GA is employed with population size of 50, uniform crossover, and mutation operators at probabilities 0.6 and 0.001, respectively. A stochastic universal sampling algorithm is used for selection. However, apart from the standard GA settings, the two user-specified parameters of the SAGA-LS are 1) maximum number of nearest neighboring data points used to construct the local surrogate model m max , and 2) maximum trust region iterations k max . In our numerical studies, we set m max and k max to 100 and 3, respectively. In SAGA-GS and SAGA-GLS, the maximum number of training design points (i.e., q max ) and clusters for constructing the global surrogate model using DPGP are configured as 2000 and 4, respectively. It is worth noting that in the surrogate assisted algorithms, all design points in the database will be used for constructions of global or local surrogate models, if the training design points are lower than the maximum number configured, i.e., q max or m max . In addition, all configurations used in this study were values suggested in earlier studies <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b26">[27]</ref>.</p><p>The results obtained from our empirical studies on a range of benchmark test functions, i.e., two unimodal test functions (Sphere and Rosenbrock test function) and three multimodal test functions (Ackley, Griewank, and Rastrigin test function) are presented in Figs. <ref type="figure" target="#fig_2">3</ref><ref type="figure">4</ref><ref type="figure">5</ref><ref type="figure" target="#fig_4">6</ref><ref type="figure" target="#fig_5">7</ref>. All benchmark test functions used in the study are of 20 dimensions and have a single global minimum at zero (see Appendix I for greater details of the test functions). Note that the results presented are averaged over 20 simulation runs conducted with a limited computational budget of (6 × 10 3 ) exact objective function evaluations.</p><p>From the results obtained in Figs. <ref type="figure" target="#fig_2">3</ref><ref type="figure">4</ref><ref type="figure">5</ref><ref type="figure" target="#fig_4">6</ref><ref type="figure" target="#fig_5">7</ref>, it is clear that all the surrogate-assisted evolutionary optimization algorithms considered here are capable of searching more efficiently than the standard GA on the benchmark problems under a limited computational budget. Further, both SAGA-LS and SAGA-GLS    appear to converge much faster and yield improved solution quality as compared to SAGA-GS on all the benchmark problems. This makes sense since Memetic algorithms, i.e., EAs that employ local search heavily such as SAGA-LS and SAGA-GLS, are generally well-known to search more effectively and efficiently. The superiority of SAGA-LS and SAGA-GLS are more evident on unimodal benchmark problems.</p><p>It is worth noting that SAGA-GLS converges significantly faster than the SAGA-LS on unimodal problems. For instance, we observed that SAGA-GLS converges correctly to the global minimum of the exact objective function in Fig. <ref type="figure" target="#fig_2">3</ref> within the limited computational budget. This outcome may be easily explained. Since the Sphere problem is a smooth, symmetric function and unimodal, it makes perfect sense to use the Lamarckian learning process in SAGA-GLS or SAGA-LS involving any gradient-based local search. However, in contrast to SAGA-LS, only the η% top ranking individuals among the entire EA population in SAGA-GLS undergo the Lamarckian learning process, thus providing significant computational cost savings.</p><p>Consider next the complex multimodal benchmark problems. On multimodal functions, the number of local minima increases exponentially with the problem dimensions; often they present hills and valleys with misleading local optima. Any gradient-based optimization algorithm would easily become stuck in a local minima. Hence, performance studies of surrogate-assisted EAs on multimodal problems reflect the algorithm's ability to escape from poor local optima and head toward the global optimum. Figs. 5-7 illustrate the search performances of GA, SAGA-GS, SAGA-LS, and SAGA-GLS on the Ackley, Griewank, and Rastrigin multimodal benchmark test functions, respectively. From these figures, SAGA-GLS is once again demonstrated to accelerate the evolutionary search significantly faster than GA, SAGA-GS, or SAGA-LS on all of the multimodal problems considered. For the Ackley function, we observed that the SAGA-GLS is capable of converging correctly to the global minimum of the exact objective function even though there are thousands of local minima in the entire search space (see Fig. <ref type="figure">5</ref>). This indicates the robustness of the SAGA-GLS in preventing premature convergence.</p><p>Overall, the results obtained also imply that the SAGA-GLS is not only capable of identifying the better quality individuals in each EA population (via its global search strategy), but at the same time its intrinsic local search strategy can also exploit these filtered individuals effectively and efficiently. This combination of the global and local search strategies in the SAGA-GLS is the key reason for the improvements in search quality at a significantly lower computational budget than existing surrogate-assisted EAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. AERODYNAMIC SHAPE DESIGN OPTIMIZATION</head><p>In Section V, we apply the SAGA-GLS to efficient aerodynamic shape design. In particular, we consider the parametric design optimization of a 2-D airfoil structure with minimum drag-over-lift ratio, i.e., D/L.</p><p>The drag D and lift L on an airplane are the components of the total aerodynamic force parallel and vertical to the direction of flight, respectively, as shown in Fig. <ref type="figure" target="#fig_6">8(a)</ref>. The importance of the D/L ratio in design can be understood, for example, in two airplane performance considerations <ref type="bibr" target="#b27">[28]</ref>. First, the engine thrust required for level and unaccelerated flight, that is, cruise, is given by</p><formula xml:id="formula_27">T cruise = (weight of aircraft) × D/L (21)</formula><p>Second, an airplane in a power-off gliding flight will descent at an angle-θ gliding given by tan θ gliding = D/L <ref type="bibr" target="#b21">(22)</ref> In both cases, it is obvious that the smaller the ratio D/L, the better the performance. In the first case, a small ratio means less engine power is required for cruising flight, thus saving fuel. In the second case, low drag over lift entails a safer gliding flight in the case of engine failure. While the drag and lift forces on an airplane are determined by various body components, the contribution of the wings is dominant. This motivates the development of an approach for designing airfoil geometries by minimizing the D/L ratio.</p><p>In an airfoil shape optimization problem using computational fluid dynamics, the drag and lift forces can be obtained by calculating the flow field around the airfoil under prescribed operating conditions, defined by the Mach number which represents the incident flow rate, and the angle of attack [see Fig. <ref type="figure" target="#fig_6">8(a)</ref>]. Ignoring friction, the flow is governed by the 2-D Euler equations</p><formula xml:id="formula_28">∂w ∂t + ∂f 1 ∂z 1 + ∂f 2 ∂z 2 = 0<label>(23)</label></formula><p>with t as the time variable</p><formula xml:id="formula_29">w =    ρ ρu 1 ρu 2 ρE    f 1 =    ρu 1 ρu 2 1 + p ρu 1 u 2 ρu 1 H    f 2 =    ρu 2 ρu 1 u 2 ρu 2 2 ρu 2 H    (24)</formula><p>where ρ is the density, u 1 and u 2 are the flow velocity components in the Cartesian space with coordinates z 1 and z 2 , p is the pressure, E is the total specific energy, and H is the total specific enthalpy. Moreover, the pressure is given by p</p><formula xml:id="formula_30">= (γ -1)ρ(E -(1)/(2)u 2 1 -(1)/(2)u 2 2 )</formula><p>, where γ is the specific heat <ref type="bibr" target="#b28">[29]</ref>.</p><p>Thus, the drag D and lift L are simply the components opposite the direction of flight u ∞ , and the direction perpendicular to flight τ ∞ , respectively, of the resultant force due to pressure acting along the contour C of the airfoil [see Fig. <ref type="figure" target="#fig_6">8(b)</ref>]. They are given by the following integrals:</p><formula xml:id="formula_31">D = C p(σ) n(σ). u ∞ dσ (25) L = C p(σ) n(σ). τ ∞ dσ. (<label>26</label></formula><formula xml:id="formula_32">)</formula><p>Fig. <ref type="figure">9</ref>. Airfoil geometry characterized using 24-parameter Hicks-Henne functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Optimization Setup</head><p>The optimization problem considered here is to achieve an airfoil design for an optimized drag-to-lift ratio profile for constant operating conditions of Mach 0.5 and angle of attack AOA = 2.0 • . The geometry of the airfoil is represented using 24-parameter Hicks-Henne functions <ref type="bibr" target="#b29">[30]</ref>, as illustrated in Fig. <ref type="figure">9</ref>.</p><p>For the airfoil problem we consider, a single exact computational fluid dynamics (CFD) analysis takes approximately 20 min to compute on a Pentium III processor. In comparison, surrogate model construction using linear splines RBF takes less than a second to compute, while building the DPGP model takes no more than a minute on a typical workstation. When dealing with computationally expensive problems that cost many minutes of CPU time per function evaluation, this training cost may be regarded as insignificant.</p><p>We conduct the parametric design of the airfoil using all three evolutionary optimization frameworks, i.e., standard GA, SAGA-LS, and SAGA-GLS. It is worth noting that the SAGA-GS algorithm was omitted for the sake of brevity since it has been shown as inferior to SAGA-LS and SAGA-GLS. Apart from using a population size of 20 (due to the immense computational cost), all other parameters are kept the same as in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optimization Results</head><p>The design histories of the aerodynamic 2-D airfoil optimization problem using standard GA, SAGA-LS, and SAGA-GLS frameworks are presented in Fig. <ref type="figure" target="#fig_7">10</ref>. Using a population of 20 initial design points based on Latin hypercube sampling, these designs are evaluated using the exact CFD analysis code. All three EA frameworks proceed with the standard GA operations using the exact CFD analysis code for the first three generations. Hence, they share the same search history at the initial search phase. This initial phase represents the period where the SAGA-LS and SAGA-GLS forms its database of past design points for constructing surrogate models later during search.</p><p>Clearly, the results in Fig. <ref type="figure" target="#fig_7">10</ref> indicate that both SAGA-GLS and SAGA-LS arrived at better airfoil designs than the standard GA, while incurring significantly lower computational costs. Moreover, SAGA-GLS was shown to accelerate the evolutionary search much faster as compared to both standard GA and SAGA-LS, producing improved design much earlier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>For computationally expensive optimization problems, the use of a surrogate model helps to greatly reduce the number of exact fitness evaluations by exploiting the information contained in the search history. In this paper, we present a novel surrogate-assisted evolutionary optimization framework that combines both global and local surrogate models. The algorithm makes use of the global surrogate model and a probability of improvement preselection criterion to rank the promising individuals in the EA population. A surrogate-assisted Lamarckian learning approach is then applied to these promising individuals to accelerate evolutionary search.</p><p>Experimental studies are presented for a number of unimodal and multimodal benchmark test functions to study the effect of changing various user-specified parameters introduced in this framework. Results are also presented for a real-world aerodynamic shape design problem. The empirical results were compared with those obtained using a standard GA and other surrogate-assisted EAs. The results obtained suggest that the proposed optimization framework is capable of solving computationally expensive optimization problems more efficiently than the standard GA, SAGA-GS, and SAGA-LS on a limited computational budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX I TEST PROBLEMS</head><p>A. Sphere Test Function</p><formula xml:id="formula_33">f (x) = n i=1</formula><p>x 2 i , -5.12 ≤ x i ≤ 5.12, i = 1, 2, . . . , n.</p><p>( </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Outline of the proposed evolutionary optimization framework combining both global and local surrogate models.</figDesc><graphic coords="3,57.07,68.33,221.10,348.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Characteristics of the PoI criterion when the GP model is trained on points generated by a one-dimensional function.</figDesc><graphic coords="5,44.95,68.33,245.30,199.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Convergence trends of the GA, SAGA-GS, SAGA-LS, and SAGA-GLS framework for the Sphere function.</figDesc><graphic coords="7,46.51,68.30,242.20,176.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Convergence trends of the GA, SAGA-GS, SAGA-LS, and SAGA-GLS framework for the Rosenbrock function.</figDesc><graphic coords="7,46.09,296.88,243.10,180.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Convergence trends of the GA, SAGA-GS, SAGA-LS, and SAGA-GLS framework for the Griewank function.</figDesc><graphic coords="7,307.67,68.24,246.00,180.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Convergence trends of the GA, SAGA-GS, SAGA-LS, and SAGA-GLS framework for the Rastrigin function.</figDesc><graphic coords="7,308.21,289.39,244.90,181.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Forces acting on an airplane and airfoil. (a) Airplane. (b) Airfoil.</figDesc><graphic coords="8,313.11,68.31,226.60,196.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Convergence trends of the GA, SAGA-LS, and SAGA-GLS framework for the aerodynamic shape design problem.</figDesc><graphic coords="9,307.96,68.31,245.30,182.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>-2.048 ≤ x i ≤ 2.048, i = 1, 2, . . . , n -1.<ref type="bibr" target="#b27">(28)</ref> </figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>)</cell></row><row><cell cols="3">B. Rosenbrock Test Function</cell><cell></cell><cell></cell><cell></cell></row><row><cell>n-1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>f (x) =</cell><cell cols="2">100 × x i+1 -x 2 i</cell><cell cols="4">2 + (1 -x i ) 2</cell></row><row><cell>i=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">C. Ackley Test Function</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">f (x) = 20 + e -20e -0.2 1 n</cell><cell cols="2">n i =1</cell><cell>x 2 i -e</cell><cell>1 n</cell><cell>n i =1</cell><cell>cos 2πx i</cell></row><row><cell></cell><cell>n</cell><cell cols="2">x 2 i /4000 -</cell><cell>n</cell><cell cols="2">cos(x i / √</cell><cell>i)</cell></row><row><cell></cell><cell>i=1</cell><cell></cell><cell></cell><cell cols="2">i=1</cell></row><row><cell></cell><cell cols="2">-600 ≤ x</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p>-32.768 ≤ x i ≤ 32.768, i = 1, 2, . . . , n. (29)</p>D. Griewank Test Function</p>f (x) = 1 + i ≤ 600, i = 1, 2, . . . , n. (30) E. Rastrigin Test Function f (x) = 10n + n i=1</p>x 2 i -10 cos(2πx i ) -5.12 ≤ x i ≤ 5.12, i = 1, 2, . . . , n. (31)</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This work is a collaboration between Nanyang Technological University, the University of Southampton, and Temasek Laboratories. The authors would like to thank the following research centers for their support in this work: Center for Multimedia and Network Technology (CEMNET), Parallel and Distributed Computing Center (PDCC) of Nanyang Technological University and Computational Engineering and Design Center in the University of Southampton.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Following this, he taught at Oxford University, Oxford, U.K., before being appointed Professor of computational engineering at University of Southampton, Southampton, U.K., in 1996. He is also the Chair of the Computational Engineering and Design Group (CEDG), University of Southampton. His research interests lie in computational engineering methods in design spanning, including design optimization, including stochastic and evolutionary methods, response surface methods for data modeling, design of experiment methods, and e-Science and grid-based computing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kai Yew Lum</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evolutionary optimization of computationally expensive problems via surrogate modeling</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Inst. Aero</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="687" to="696" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Astron. J.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Accelerating evolutionary algorithms using fitness function models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ratle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Problem Solving from Nature</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="87" to="96" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Design of optimal aerodynamic shapes using stochastic optimization methods and computational intelligence</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Giannakoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Rev. J. Progress Aerosp. Sci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="43" to="76" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Inexact information aided, low-cost, distributed genetic algorithms for aerodynamic shape optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Karakasis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Giotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Giannakoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Numer. Meth. Fluids</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1149" to="1166" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Shape optimisation of turbine blade firtrees</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">School Eng. Sci., Univ. Southampton</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Southampton, U.K.</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A data-parallel approach for large-scale Gaussian process modeling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd SIAM Int. Conf. Data Mining</title>
		<meeting>2nd SIAM Int. Conf. Data Mining<address><addrLine>Arlington, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A comparison of approximation modelling techniques: Polynomial versus interpolating models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Guinta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th AIAA/USAF/NASA/ISSMO Symp. Multidisciplinary Analysis and Optimization</title>
		<meeting>7th AIAA/USAF/NASA/ISSMO Symp. Multidisciplinary Analysis and Optimization<address><addrLine>St. Louis, MO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-09">Sep. 1998</date>
			<biblScope unit="volume">98</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">New approaches to conceptual and preliminary aircraft design. A comparative assessment of a neural network formulation and a response surface methodology</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Daberkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Mavris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AIAA, World Aviation Conf</title>
		<meeting>AIAA, World Aviation Conf<address><addrLine>Anaheim, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-09">Sep. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparative studies of metamodeling techniques under multiple modeling criteria</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Simpson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Struct. Multidiscipl. Optim</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A comprehensive survey of fitness approximation in evolutionary computation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="12" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Aircraft wing design using GA-based multi-level strategies</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petruzzelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th AIAA/USAF/NASA/ISSMO Symp. Multidisciplinary Analysis Optimization</title>
		<meeting>8th AIAA/USAF/NASA/ISSMO Symp. Multidisciplinary Analysis Optimization<address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-09">2000-4937. Sep. 2000</date>
			<biblScope unit="page">171</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Global convergence unconstrained and bound constrained surrogate-assisted evolutionary search in aerodynamic shape design</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEE Congr. Evolutionary Computation CEC&apos;03</title>
		<meeting>IEE Congr. Evolutionary Computation CEC&apos;03<address><addrLine>Canberra, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1856" to="1863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Metamodelling techniques for evolutionary optimization of computationally expensive problems: Promise and limitations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>El-Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Genetic and Evol. Comput. Conf. (GECCO&apos;99)</title>
		<meeting>IEEE Genetic and Evol. Comput. Conf. (GECCO&apos;99)<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-07">Jul. 1999</date>
			<biblScope unit="page" from="196" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A framework for evolutionary optimization with approximate fitness functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evolutionary search of approximated n-dimensional landscapes</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Newton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Knowl.-Based Intell. Eng. Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="172" to="183" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Transductive inference for estimating values of functions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Accelerating evolutionary algorithms with Gaussian proofs fitness function models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Büche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. C, Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="194" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evolution strategies assisted by Guassian processes with improved pre-selection criterion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ulmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Streichert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr<address><addrLine>Canberra, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page" from="692" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Metamodel-assisted evolution strategies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Emmerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oezdemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Giannakoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PPSN VII</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>PPSN VII</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2439</biblScope>
			<biblScope unit="page" from="361" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient global optimization of expensive black-box functions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schonlau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Welch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optim</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="455" to="492" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bayesian interpolation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="415" to="447" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>Available: citeseer.ist.psu.edu/article/ mackay91bayesiari.html</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using approximations to accelerate engineering design optimization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Torczon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Trosset</surname></persName>
		</author>
		<idno>no. TR-93-33</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th AIAA/USAF/NASA/ISSMO Symposium on Multidisciplinary Analysis and Optimization</title>
		<meeting>7th AIAA/USAF/NASA/ISSMO Symposium on Multidisciplinary Analysis and Optimization<address><addrLine>St. Louis, MO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-09">Sep. 1998</date>
			<biblScope unit="volume">98</biblScope>
		</imprint>
	</monogr>
	<note>Available: citeseer.ist.psu.edu/torczon98using.html</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Neural Networks for Pattern Recognition</title>
		<meeting><address><addrLine>London, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford Univ. Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convergence of trust region augmented lagrangian methods using variable fidelity approximation data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Renaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Struct. Optim</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">34</biblScope>
			<biblScope unit="page" from="141" to="156" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A trust region framework for managing the use of approximation models in optimization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alexandrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torczon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Struct. Optim</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="23" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchical surrogate-assisted evolutionary optimization framework</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr. Evolutionary Computation CEC&apos;04, Special Session on Learning and Approximation in Design Optimization</title>
		<meeting>IEEE Congr. Evolutionary Computation CEC&apos;04, Special Session on Learning and Approximation in Design Optimization<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
			<biblScope unit="page" from="1586" to="1593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D J</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Introduction to Flight, 4th ed.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">An Introduction to Computational Fluid Dynamics-The Finite Volume Methods</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Malalasekera</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>White Plains, NY: Longman</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Wing design by numerical optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Henne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Aircraft</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="407" to="412" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
