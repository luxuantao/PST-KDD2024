<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">What&apos;s in an image? * Towards the computation of the &apos;&apos;best&apos;&apos; view of an object</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-09-01">1 September 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Oleg</forename><surname>Polonsky</surname></persName>
							<email>olegp@cs.technion.ac.il</email>
						</author>
						<author>
							<persName><forename type="first">Giuseppe</forename><surname>Patané</surname></persName>
							<email>patane@ge.imati.cnr.it</email>
						</author>
						<author>
							<persName><forename type="first">Silvia</forename><surname>Biasotti</surname></persName>
							<email>biasotti@ge.imati.cnr.it</email>
						</author>
						<author>
							<persName><forename type="first">Craig</forename><surname>Gotsman</surname></persName>
							<email>gotsman@eecs.harvard.edu</email>
						</author>
						<author>
							<persName><forename type="first">Michela</forename><surname>Spagnuolo</surname></persName>
							<email>spagnuolo@ge.imati.cnr.it</email>
						</author>
						<author>
							<persName><forename type="first">Imati</forename><forename type="middle">/</forename><surname>Cnr Genova</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">What&apos;s in an image? * Towards the computation of the &apos;&apos;best&apos;&apos; view of an object</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-09-01">1 September 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">5532856C020D085E0D6924B608EB15A3</idno>
					<idno type="DOI">10.1007/s00371-005-0326-y</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visualization</term>
					<term>View entropy</term>
					<term>Scene composition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There are many possible 2D views of a given 3D object and most people would agree that some views are more aesthetic and/or more "informative" than others. Thus, it would be very useful, in many applications, to be able to automatically compute these "best" views. Although all measures of the quality of a view will ultimately be subjective, hence difficult to quantify, we propose some general principles which may be used to address this challenge. In particular, we describe a number of different ways to measure the goodness of a view, and show how to optimize these measures by reducing the size of the search space.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The real world consists of three-dimensional objects. The human visual system, however, is limited by optics to view only their two-dimensional images. Stereo vision and perspective only partially overcome this limitation. Thus, a significant component of the geometric information about a 3D object is lost during the viewing transformation. This unfortunate fact is also reflected in traditional computer graphics applications, where we commonly see rendered 2D images. Although all the information about the 3D shape is known a priori (i.e., before the image rendering), much is lost when the shape is projected onto the image plane, and the amount of preserved information depends on the eye (camera) position relative to the shape in that particular view.</p><p>In this paper, we focus on the quantification and measurement of the visual information present in an image of a 3D object with the aim of finding optimal, or nearlyoptimal, views. It should be emphasized that the notion of the goodness of a view may depend on the particular visual task or application. For example, in an illustrated manual of work tools, people may prefer views where the tool is drawn in the typical position, as used by the machine operator. Object recognition tasks performed by a robot may require a totally different view to achieve best performance. Nonetheless, we believe that there exists some common basis for all these visual problems.</p><p>Answering these questions presents a significant challenge in the field of visualization and shape understanding. A solution would be useful in several applications such as automatic camera positioning in CAD, thumbnail generation for large 3D databases, automatic scene composition, technical illustration, and object recognition.</p><p>In this paper we propose the following methodology: define a view descriptor which attaches a score to a view of the object, taking into account its visible geometry (Sect. 3). Then, compute the value of this descriptor for a small number of candidate views (Sect. 4). We consider the view with the highest score to be the most informative. We describe a number of such descriptors, and show how to optimize them efficiently over the viewing sphere. We compare the views generated by these descriptors and discuss their performance (Sects. 5 and 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous work</head><p>The question "What is a good view of an object ?" dates back to the Greeks and Romans, who proposed some simple rules of thumb, e.g., the golden ratio, the rule of thirds, the rule of fifths, etc. <ref type="bibr" target="#b12">[13]</ref>.</p><p>In the 1930s, the mathematician Birkhoff <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> tried to quantify the notion of an object's beauty. He defined the beauty B of an object as B = O/C, where O is order, and C is complexity. He tested this formula on simple geometric figures, but was unable to provide a general notion of order and complexity.</p><p>In the computer vision community, good views are presumed to be ones that make an object more readily recognizable by humans. Many automatic object recognition techniques in vision and robotics are based on theories from human visual perception. Currently, there are two main competing theories: Marr <ref type="bibr" target="#b17">[18]</ref> and Biederman <ref type="bibr" target="#b3">[4]</ref> describe a theory of recognition-by-components (or structural description), maintaining that human vision represents objects as 3D entities consisting of 3D components, and this representation is viewpoint-independent. The second theory is multiple-view description (Bülthoff et al. <ref type="bibr" target="#b7">[8]</ref>, Koenderink <ref type="bibr" target="#b15">[16]</ref>), stating that the object is best represented and processed as a set of 2D images from different viewpoints, connected in a so-called aspect graph. This is a graph defined such that the vertices correspond to equivalence classes of views and edges join one view with another if the two differ by a single visual event. Unfortunately, the complexity of the aspect graph for line drawings containing n lines has been shown to be O(n 6 ), which is quite prohibitive. Weinshall and Werman <ref type="bibr" target="#b26">[27]</ref> give a theoretical proof of equivalence between view stability and view likelihood for a given aspect and show that this view can be computed from the aspect's autocorrelation matrix using principal components analysis (PCA) <ref type="bibr" target="#b13">[14]</ref>.</p><p>Tarr and Kriegman <ref type="bibr" target="#b24">[25]</ref> have conducted psychophysical experiments investigating the influence of the aspect of an object on the quality of recognition. The experiments reveal that humans are indeed sensitive to certain types of visual events captured by the aspect graphs. One interesting consequence of other psychophysical experiments is that for many models, there exist a small number of views which seem to be preferred by most people. Palmer et al. <ref type="bibr" target="#b20">[21]</ref> and Blanz et al. <ref type="bibr" target="#b6">[7]</ref> call these views canonical views and show that they often correspond to the classical three-quarter view of the object. According to Blanz et al. <ref type="bibr" target="#b6">[7]</ref>, canonical views are stable, and expose as many salient and significant features as possible.</p><p>In the field of computer graphics, Gooch et al. <ref type="bibr" target="#b12">[13]</ref> try to use the results of Blanz et al. <ref type="bibr" target="#b6">[7]</ref> to perform automatic scene composition, where finding the viewpoint is one of the three stages of the composition process (i.e., image format, viewpoint, and shape layout). They start from the three-quarter view (determined manually) and then optimize it to find the most stable view, where stability means to eliminate coincident silhouette lines. More specifically, they maximize the sum of squared distances between all silhouette midpoints, ignoring silhouette visibility.</p><p>Probably the first attempt to compute good views in computer graphics was made by Kamada and Kawai <ref type="bibr" target="#b14">[15]</ref>. They treat objects drawn in wire-frame in an orthogonal projection. A degenerate projection is one for which an edge is projected to a point, or a polygon is projected to a line. The objective is to minimize such degeneracies, and the optimal viewpoint is called general position. The complexity of the analytical solution is O(n 3 log n), but this does not take occlusions into account. The work of Gómez et al. <ref type="bibr" target="#b11">[12]</ref> is similar in spirit to <ref type="bibr" target="#b14">[15]</ref>, incorporating perspective projections. Various "niceness" criteria are defined: regularity, simplicity, minimum crossing, and monotonic projections. Barral et al. <ref type="bibr" target="#b1">[2]</ref> add coefficients to the formulae of <ref type="bibr" target="#b14">[15]</ref> to cope with perspective projection, and introduce other heuristic balance coefficients, but admit that it is difficult to determine optimal weights for the different components.</p><p>Plemenos and Benayada <ref type="bibr" target="#b21">[22]</ref> introduce the term visible projected area. They assume that a good view is that which maximizes the number of visible triangles and the visible projected surface area. These two measures are weighted and summed to an objective function and the optimal value is heuristically searched for by hierarchically subdividing the viewing sphere surrounding the scene. This measure does not take into account at all the amount of invisible (occluded) surface area.</p><p>Vázquez et al. <ref type="bibr" target="#b25">[26]</ref> extend the measure of Plemenos and Benayada <ref type="bibr" target="#b21">[22]</ref> to operate on a per-face basis. This gives more detailed information on the view. A "probability" is associated with each face, defined as the fraction of its visible projected area relative to the total visible projected area. These probabilities are then combined using the information-theoretic entropy function. The cost function, called viewpoint entropy, is defined to be the entropy of this distribution. Hence, a good view is one for whom the faces are exposed as uniformly as possible. Note, however, that this cost function does not either take into account the behavior of the occluded surfaces. Additionally, Stoev and Straßer <ref type="bibr" target="#b23">[24]</ref> point out that the method of Vázquez et al. generates flat views for scenes where all the normals point in similar directions (e.g., digital terrain models). As a result, the good view direction (maximal viewpoint entropy) typically is vertical; so although the number of visible triangles and the projected area are maximized, most of depth information is lost. Their pro-posed workaround is to add to the cost function another (weighted) term which measures the maximal depth in the frame.</p><p>In the field of robotics, Arbel and Ferrie <ref type="bibr" target="#b0">[1]</ref> and Roberts and Marshall <ref type="bibr" target="#b22">[23]</ref> attempt to find good views that simplify object recognition. The approach in <ref type="bibr" target="#b0">[1]</ref> is based on a learning process for entropy maps on the viewing sphere, where each entropy value indicates the expected ambiguity of recognition. During the recognition process, these maps are navigated in order to minimize the chance of expected ambiguities. Roberts and Marshall <ref type="bibr" target="#b22">[23]</ref> select a minimal number of views that allow adequate representation for every face of the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">View descriptors</head><p>In this section, we describe a number of ways to measure the goodness of a view of an object. The objective function that measures this is called a view descriptor, and the best view is that which maximizes this function. Our descriptors are based on the following principles.</p><p>The first principle is to exploit an accepted measure of geometric complexity for a 3D shape. This could be based on various features in the shape, its surface area, its curvature distribution, etc., and is obviously view-independent. The view descriptor would then assign to a view a score which is the contribution to the complexity from the portion of the shape which is visible in that view (see paragraphs on Surface area entropy, Visibility ratio and Curvature entropy). So, in effect, the best view is that which exposes as much of the geometric complexity of the object as possible.</p><p>The second principle is to define descriptors which are based on inherently view-dependent features. Examples are object silhouettes and critical points (see paragraphs Silhouette entropy and Topological complexity).</p><p>Here again we would like to expose as much of these features as possible.</p><p>A third principle is to build a descriptor which, instead of assigning values to the primitive elements of the 3D model (e.g., vertices, faces, and edges), assigns values to larger portions of the model which have some semantic meaning. Such portions of the model may be obtained from segmentation algorithms (see paragraph Surface entropy of semantic parts). This affords a higher level visual appreciation of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Surface area entropy.</head><p>The first descriptor that we examined measures geometric complexity of an object as its surface area. Each face is assigned a probability: the fraction of its visible projected area relative to the total visible projected area and the descriptor value is the entropy of this distribution. We computed these probabilities at image precision by rendering each face with a distinct color, and counting the number of pixels of each color. This is essentially the viewpoint entropy method proposed by Vázquez et al. <ref type="bibr" target="#b25">[26]</ref>. The ranking of some views by this descriptor are shown in Fig. <ref type="figure" target="#fig_0">1</ref>. In this figure, and those related to the other descriptors, we restrict our attention to a small number of candidate views generated by a filtering procedure, as described in Sect. 4.</p><p>Visibility ratio. The previous descriptor did not take into account the behavior of the invisible portions of the surface, so it might prefer a view of the object in which most of its surface area is occluded. A descriptor which does take this into account is the ratio between the 3D surface area that is visible in the image, and the total 3D surface area. This seeks to expose as much of the surface area as possible. The ranking of some views by this descriptor are shown in Fig. <ref type="figure">2</ref>.</p><p>Curvature entropy. Surface area is a very simple measure of shape complexity. A more sophisticated one, as proposed by Page et al. <ref type="bibr" target="#b19">[20]</ref>, is the entropy of the Gaussian curvature distribution over the entire surface of the object. We define the curvature entropy descriptor to be the entropy of the curvature distribution over the visible portion of the surface. The curvature at a vertex v is estimated by the standard angle-deficit approximation, as in <ref type="bibr" target="#b19">[20]</ref>: where θ i and A i are the apex angles and areas in the one ring of triangles incident on v, respectively. The ranking of some views by this descriptor are shown in Fig. <ref type="figure">3</ref>. The previous descriptors were based on view-independent measures of shape complexity. We now define descriptors which are inherently view-dependent. piction of the shape of a 3D model, and, for this reason, are often used in non-photorealistic rendering. Silhouettes are also view-dependent. A simple version of this descriptor measures the total length of all silhouette edges in the image plane. Since this cannot be done reliably in image space, we computed the visible silhouette edges in object space analytically and calculated the length of their projected versions. The ranking of some views by this descriptor are shown in Fig. <ref type="figure" target="#fig_2">4</ref>.</p><formula xml:id="formula_0">C(v) = 2π -i θ i 3 i A i ,<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Silhouette length. Silhouettes (sometime called occluding contours) seem to provide an accurate and compact de-</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Silhouette entropy.</head><p>A more sophisticated silhouette-based descriptor uses silhouette entropy instead of total length, where the entropy of a curve is defined as the entropy of In the discrete version, we compute the entropy of all turning angles between adjacent silhouette edges. In some cases, spurious silhouette edge crossings can make the result quite unstable. The ranking of some views by this descriptor are shown in Fig. <ref type="figure" target="#fig_3">5</ref>.</p><p>Topological complexity. Another approach was motivated by the fact that the critical points of a 3D surface are highly informative. These may be considered features of the surface. Assuming that the boundary of the object is a smooth closed manifold surface S in R 3 , we may use the height function h n along any direction n and compute the number of its critical points (i.e., minima, maxima, and saddles) on S. A classical theorem from differential topology <ref type="bibr" target="#b18">[19]</ref> states that the alternating sum of the number of minima, maxima, and saddles is constant, and is related to the Euler characteristic χ of S, namely:</p><formula xml:id="formula_1">maxima -saddles + minima = 2(1 -g) = χ, (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where g is the genus of S. However the total number of critical points (maxima+saddles+minima) depends on the direction n, so this quantity could be useful for discriminating among different view directions (when used as n).</p><p>The direction that maximizes this number seems to be the most informative. The result ( <ref type="formula" target="#formula_1">2</ref>) is valid not only for Morse functions on the surface, but also for C 0 functions, using the extension proposed in <ref type="bibr" target="#b2">[3]</ref>. Therefore, it can be applied even if the height function has degenerate critical points. The ranking of some views by this descriptor are shown in Fig. <ref type="figure">6</ref>. Surface entropy of semantic parts. It is possible to apply the surface area entropy method to geometric elements larger than the primitive elements (e.g., vertices, faces) of a 3D mesh. One way to achieve this is to use semantically important segments of the model. The probability of each segment is defined to be the visible projected area of this segment relative to the visible projected area of the entire model. There exist many mesh segmentation algorithms and the descriptor will depend critically on the segmentation method. In our experiments, we used the method proposed by Dey et al. <ref type="bibr" target="#b8">[9]</ref>, which seems to be able to identify parts of the model which are semantically meaningful (e.g., nose, ears, neck, etc. for a head model). The ranking of some views by this descriptor are shown in Fig. <ref type="figure">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Sampling the view space</head><p>Given a view descriptor measuring the "goodness" of a view as a function of viewing direction, the problem is then to find the global, or even local, maximum of this function over the viewing sphere. Since the search space is a continuum containing an infinite number of points, we have used two different strategies to reduce the search to an exhaustive search on a small but reasonable set of candidate views. In this section, we describe two methods to generate these candidate views.</p><p>For many inputs, nature dictates an up direction, which should be respected in any view, certainly in the best one. So, for example, an animal should not be rendered upside down, rather standing on its feet. Noticing that the best view has a degree of freedom of 2D rotation in the image plane (since this will not change the value of any of the descriptors), it is possible to exploit this degree of freedom to cause all views to have the correct 2D orientation after the optimal view has been computed.</p><p>Three-quarter views. Palmer et al. <ref type="bibr" target="#b20">[21]</ref> experimentally observed the existence of what they call canonical views of an object. These are views that most humans prefer to look at the object from, and they seem to be quite welldefined in practice. Inspired by the structural description theories, Blanz et al. <ref type="bibr" target="#b6">[7]</ref> state that these canonical views are typically three-quarter views of the objects. Gestalt psychologists explain that this is a view where the front, top, and side of the object are simultaneously visible. This also explains why these views are preferred by humans: we simply prefer to see simultaneously all three dimensions of the shape. In particular, Marr <ref type="bibr" target="#b17">[18]</ref> states that the object's primary axis of elongation should be clearly visible. We use three-quarter views as candidate views. We start by approximating the shape by an oriented box, thus establishing a local Cartesian frame defined by the three axes of the box. Three-quarter views then correspond to the vectors whose components are the eight combinations of (±1, ±1, ±1) in this coordinate system. As pointed out by Weinshall and Werman <ref type="bibr" target="#b26">[27]</ref>, these views are the most stable views of the box approximating the object, thus hopefully a good approximation for stable views of the object itself.</p><p>To compute an approximating box for the object, we use the three principle directions generated by PCA of the object geometry, relative to the centroid of the point cloud. The PCA method has some nice properties, such as robustness and stability; furthermore, it has been successfully used in computer graphics for object matching and aligning and normalization purposes (e.g., see <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>). Finally, we note that the eight vectors are computed ignoring occlusion, which will be taken into account later by the descriptors.</p><p>Normal clustering. Another way to compute candidate views of an object is to detect clusters in the set of vertex normals. Again we ignore occlusions. This effectively defines the sides of the object to be those directions that a large number of normals point towards. This is motivated by the assumption that the more the normals point in some direction, the more the object's surface is visible from that direction. More precisely, for each vertex v we approximate its unit normal by averaging the normal vectors of the triangles incident on v; each normal vector defines a point on the unit sphere (i.e., the Gauss map). Then, we cluster the points on the unit sphere using an iterative version of PCA <ref type="bibr" target="#b13">[14]</ref>, thus achieving a set of clusters. An interesting view is defined as the center of mass of these points (or equivalently, normal vectors) of each cluster. The resulting view directions seem to be quite stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental results</head><p>To compare the performance of the various descriptors, we applied them to a set of 3D objects which seem to be representative. For each object we computed a relatively small number of candidate views based on the two methods described in Sect. 4 and for each such view, computed the value of the various descriptors described in Sect. 3, and ranked them in decreasing order (from left to right), as depicted in Figs. <ref type="figure" target="#fig_0">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure" target="#fig_2">4</ref><ref type="figure" target="#fig_3">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>. The objective was to see whether those views which ranked highest according to some descriptors were indeed those which are most informative to a human observer.</p><p>The three-quarter view and normal clustering sample the view space by considering the geometry and normals, respectively. The main difference between these two methods is the number of candidates generated. This is constant (i.e., eight) for the first method and essentially unbounded for the second method. In practice, we choose the 15 to 30 most significant clusters to emerge from the PCA. Three-quarter views are marked by a black dot in Figs. <ref type="figure" target="#fig_0">1</ref><ref type="figure">2</ref><ref type="figure">3</ref><ref type="figure" target="#fig_2">4</ref><ref type="figure" target="#fig_3">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>. It seems that all the view descriptors prefer mostly the normal clustered views over the three-quarter views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and discussion</head><p>The problem of finding a good view for an object seems to be quite difficult. It is becoming painfully obvious that there is no panacea. No one descriptor does a perfect job. It is probably possible to improve the descriptors described here and fine-tune them a little more, but we do not believe that this will be significant. However, since each descriptor does a reasonably good job on a majority of inputs, we are confident that it is possible to combine them to amplify the advantage that each has. Possible combinations are linear, where the optimal weights will have to be determined by some learning process, or non-linear, e.g., by a voting process.</p><p>Once the descriptors have been decided on, an efficient algorithm must compute the view on the unit sphere which optimizes this measure. At first glance, this seems to be a difficult problem, since there exists a continuum of possible viewpoints. A gradient-descent optimization over the viewing sphere could work, but it would be very slow and not guarantee a global maximum. Hence we reduce the problem to a search over a (possibly large but) finite set of candidate viewpoints but, consequently, we might miss the best view. It would be useful to be able to prove that the particular measure we use can be maximal only at the candidate views. As we have shown, possible candidates are three-quarter views or normals, but it is not obvious that the optimal view must indeed be one of these.</p><p>A very recent paper by Lee et al. <ref type="bibr" target="#b16">[17]</ref> defines the most informative view as that which maximizes the visible saliency of an object. The saliency is defined using a multi-scale curvature measure. A gradient-descent algorithm is used to optimize this measure over the viewing sphere. Using a multi-scale measure (as opposed to single scale) seems to be useful, and it might be possible to enhance our descriptors to accommodate this type of information as well. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Four top-ranking (left to right) views among candidate views according to the surface area entropy descriptor. Black dots indicate a three-quarter view (otherwise it is a normal clustered view)</figDesc><graphic coords="3,309.74,66.07,229.84,221.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Four top-ranking (left to right) views among candidate views according to the visibility ratio descriptor</figDesc><graphic coords="4,56.06,65.53,229.84,215.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Four top-ranking (left to right) views among candidate views according to the silhouette length descriptor. Black dots indicate a three-quarter view (otherwise it is a normal clustered view)</figDesc><graphic coords="4,313.94,66.21,221.33,180.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Four top-ranking (left to right) views among candidate views according to the silhouette entropy descriptor. Black dots indicate a three-quarter view (otherwise it is a normal clustered view)</figDesc><graphic coords="4,303.98,478.61,241.05,179.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Four top-ranking (left to right) views among candidate views according to the topological complexity descriptor. Black dots indicate a three-quarter view (otherwise it is a normal clustered view)</figDesc><graphic coords="5,56.06,463.11,229.42,194.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>OLEG POLONSKY received a B.Sc. in Computer Science in 2000 from the Technion -Israel Institute of Technology. Currently he is a graduate student in the same department and a member of the Technion Center for Graphics and Geometric Computing (CGGC). His research interests include 3D computer graphics and visualization. GIUSEPPE PATAN É received a Ph.D. in "Mathematics and Applications" from the University of Genova (2005) and a Post-Laurea Degree Master in "Application of Mathematics to Industry" from the "F. Severi National Institute for Advanced Mathematics" -University of Milano (2000). Currently, he is a Research Fellow in the Shape Modelling Group at IMATI-CNR, Genova, Italy. His research interests include numerical linear algebra, surface approximation, parameterization, and analysis. SILVIA BIASOTTI graduated in Mathematics from the University of Genova in 1998. Since then, she has been on the staff of the Shape Modelling Group at IMATI-CNR Genova. She received a Ph.D. in Mathematics and Applications at the University of Genova in May 2004. Her research interests include computational topology, shape abstraction and skeleton representation of polyhedral surfaces.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank our colleagues at the Max-Planck-Institut für Informatik (MPII) who contributed to this paper. Thanks also to Tamal Dey for making available his segmentation software for our experiments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* This work is supported by the EU Network of Excellence AIM@SHAPE IST NoE No 506766.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Viewpoint selection by navigation through entropy maps</title>
		<author>
			<persName><forename type="first">T</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Ferrie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision</title>
		<meeting>the International Conference on Computer Vision<address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09-25">20-25 September 1999</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="248" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scene understanding techniques using a virtual camera</title>
		<author>
			<persName><forename type="first">P</forename><surname>Barral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dorme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Plemenos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics 2000</title>
		<editor>
			<persName><forename type="first">A</forename><surname>De Sousa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Torres</surname></persName>
		</editor>
		<meeting>Eurographics 2000<address><addrLine>Interlaken, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-08">August 2000</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="20" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Computational topology methods for shape modelling applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Biasotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Universitá degli Studi di Genova</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Dissertation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Recognition-by-components: A theory of human image understanding</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bierderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Rev</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="147" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Aesthetic Measure</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Birkhoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1933">1933</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mathematics of aesthetics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Birkhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">The World of Mathematics</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Newman</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="1956">1956</date>
			<publisher>Simon and Schuster</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What object attributes determine canonical views?</title>
		<author>
			<persName><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tarr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bülthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="575" to="599" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">How are three-dimensional objects represented in the brain?</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Bülthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Edelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Tarr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="247" to="260" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Shape segmentation and matching with flow discretization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Giesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goswami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Algorithms and Data Structures</title>
		<meeting>the Workshop on Algorithms and Data Structures<address><addrLine>Ottawa, Ontario, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08-01">30 July-1 August 2003</date>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Directed search in a 3D objects database using SVM</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ar</surname></persName>
		</author>
		<idno>HPL-2000-20R1</idno>
	</analytic>
	<monogr>
		<title level="j">HP Labs</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Content based retrieval of VRML objects: an iterative and interactive approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Eurographics Workshop on Multimedia</title>
		<meeting>the 6th Eurographics Workshop on Multimedia<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-09">September 2001</date>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nice perspective projections</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hurtado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sellarès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Toussaint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Commun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="387" to="400" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Artistic composition for image creation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gooch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reinhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Moulding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics Workshop on Rendering Techniques</title>
		<meeting>Eurographics Workshop on Rendering Techniques<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-06">June 2001</date>
			<biblScope unit="page" from="83" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Principal Component Analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A simple method for computing general position in displaying three-dimensional objects</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Graph. Image Process</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="56" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The internal representation of solid shape with respect to vision</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Van Doorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cyber</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="216" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mesh saliency</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="659" to="666" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<pubPlace>Freeman, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Milnor</surname></persName>
		</author>
		<title level="m">Morse Theory</title>
		<meeting><address><addrLine>NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Shape analysis algorithm based on information theory</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koschan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Sukumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Roui-Abidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Abidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Image Processing</title>
		<meeting>the IEEE International Conference on Image Processing<address><addrLine>Barcelona, Catalonia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-09-18">14-18 September 2003</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="229" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Canonical perspective and the perception of objects</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Attent. Perform. IX</title>
		<imprint>
			<biblScope unit="page" from="135" to="151" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Intelligent display in scene modeling. New techniques to automatically compute good views</title>
		<author>
			<persName><forename type="first">D</forename><surname>Plemenos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Benayada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of GraphiCon</title>
		<imprint>
			<date type="published" when="1996-07">July 1996</date>
			<pubPlace>St. Petersburg, Russia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Viewpoint selection for complete surface coverage of three dimensional objects</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference<address><addrLine>Southampton, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A case study on automatic camera placement and motion for visualizing historical data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Stoev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Straßer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="545" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">What defines a view?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tarr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1981" to="2004" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Viewpoint selection using viewpoint entropy</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VMV</title>
		<meeting>VMV<address><addrLine>Stuttgart, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-11-23">21-23 November 2001</date>
			<biblScope unit="page" from="273" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On view likelihood and stability</title>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="108" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
