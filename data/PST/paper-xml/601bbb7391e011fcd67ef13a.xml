<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MANA: Microarchitecting an Instruction Prefetcher</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-02-02">2 Feb 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>EPFL, Switzerland</roleName><forename type="first">Ali</forename><surname>Ansari</surname></persName>
							<email>ali.ansari@epfl.ch@epfl</email>
						</author>
						<author>
							<persName><forename type="first">Fatemeh</forename><surname>Golshan</surname></persName>
							<email>fgolshan@ce.sharif.edu</email>
						</author>
						<author>
							<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Sharif University of Technology</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">PEJMAN LOTFI</orgName>
								<orgName type="institution" key="instit2">KAMRAN, Institute for Research in Fundamental Sciences (IPM)</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Sharif University of Technology</orgName>
								<orgName type="institution" key="instit2">Iran and Institute for Research in Fundamental Sciences (IPM)</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Fatemeh Golshan</orgName>
								<orgName type="institution">Sharif University of Technology</orgName>
								<address>
									<addrLine>Azadi Avenue</addrLine>
									<postCode>1015</postCode>
									<settlement>Lausanne, Tehran</settlement>
									<country>Switzerland, Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Pejman Lotfi-Kamran, Institute for Research in Funda-mental Sciences (IPM)</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Sharif University of Technology</orgName>
								<address>
									<addrLine>Azadi Avenue</addrLine>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Institute for Research in Fundamental Sciences (IPM)</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MANA: Microarchitecting an Instruction Prefetcher</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-02-02">2 Feb 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2102.01764v1[cs.AR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>processors</term>
					<term>frontend bottleneck</term>
					<term>instruction prefetching</term>
					<term>instruction cache</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>L1 instruction (L1-I) cache misses are a source of performance bottleneck. Sequential prefetchers are simple solutions to mitigate this problem; however, prior work has shown that these prefetchers leave considerable potentials uncovered. This observation has motivated many researchers to come up with more advanced instruction prefetchers. In 2011, Proactive Instruction Fetch (PIF) showed that a hardware prefetcher could effectively eliminate all of the instruction-cache misses. However, its enormous storage cost makes it an impractical solution. Consequently, reducing the storage cost was the main research focus in the instruction prefetching in the past decade.</p><p>Several instruction prefetchers, including RDIP and Shotgun, were proposed to offer PIF-level performance with significantly lower storage overhead. However, our findings show that there is a considerable performance gap between these proposals and PIF. While these proposals use different mechanisms for instruction prefetching, the performance gap is largely not because of the mechanism, and instead, is due to not having sufficient storage. Prior proposals suffer from one or both of the following shortcomings: (1) a large number of metadata records to cover the potential, and (2) a high storage cost of each record. The first problem causes metadata-miss, and the second problem prohibits the prefetcher from storing enough records within reasonably-sized storage.</p><p>In this paper, we make the case that the key to designing a powerful and cost-effective instruction prefetcher is choosing the right metadata record and microarchitecting the prefetcher to minimize the storage. We find that high spatial correlation among instruction accesses leads to compact, accurate, and minimal metadata records. We also show that chaining these records is an effective way to enable robust and timely prefetching. Based on the findings, we propose MANA, which offers PIF-level performance with 15.7× lower storage cost. MANA outperforms RDIP and Shotgun by 12.5 and 29%, respectively. We also evaluate a version of MANA with no storage overhead and show that it offers 98% of the peak performance benefits.</p><p>CCS Concepts: • Computer systems organization → Architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Instruction cache misses are a well-known source of performance degradation when the limitedcapacity L1 instruction (L1-I) cache cannot capture a large number of instruction blocks 1 demanded by a processor <ref type="bibr">[7, 10, 12, 14, 20, 24, 27, 35?</ref> ]. In modern processors, the address generator is responsible for filling the fetch queue, which is a queue of addresses expected to be demanded by the processor. The fetch engine looks up the L1-I cache to extract the instructions of the addresses in the fetch queue. These instructions are decoded and sent to the core backend for execution. While modern processors support out-of-order execution, instruction supply to the core backend is still in-order. Therefore, if the instruction at the head of the fetch queue misses in the L1-I cache, the core will no longer be fed by new instructions until the missing instruction arrives at the L1-I cache, which results in performance degradation. However, the fetch engine may continue to fetch the remaining addresses in the fetch queue from the L1-I.</p><p>Instruction prefetching is a technique to address this problem. An instruction prefetcher predicts the future cache misses and sends prefetch requests to fill the cache before demand requests arrive. The most common instruction prefetchers are sequential prefetchers that, upon activation, send prefetch requests for a few subsequent blocks <ref type="bibr" target="#b44">[47,</ref><ref type="bibr" target="#b53">56]</ref>. While sequential prefetchers are used in commodity processors <ref type="bibr" target="#b22">[25,</ref><ref type="bibr" target="#b39">42,</ref><ref type="bibr" target="#b43">46,</ref><ref type="bibr" target="#b44">47]</ref>, prior work has shown that such prefetchers leave a significant fraction of instruction misses uncovered, and hence, there is a substantial opportunity for improvement <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b29">32,</ref><ref type="bibr" target="#b31">34]</ref>.</p><p>Sequential prefetchers' limitations motivated researchers to propose more sophisticated prefetchers. Proactive Instruction Fetch (PIF) is a pioneer that showed a hardware instruction prefetcher could eliminate most of the instruction cache misses <ref type="bibr" target="#b18">[21]</ref>. However, the proposed prefetcher is impractical because of its high storage cost. Nonetheless, PIF motivated many researchers to develop effective and storage-efficient prefetchers <ref type="bibr" target="#b5">[8,</ref><ref type="bibr" target="#b23">26,</ref><ref type="bibr" target="#b25">28,</ref><ref type="bibr" target="#b29">[32]</ref><ref type="bibr" target="#b30">[33]</ref><ref type="bibr" target="#b31">[34]</ref>.</p><p>We evaluate Return-Address-Stack Directed Instruction Prefetcher (RDIP) <ref type="bibr" target="#b29">[32]</ref>, Shotgun <ref type="bibr" target="#b30">[33]</ref>, and PIF, as the three state-of-the-art prefetchers that use entirely different approaches for instruction prefetching. We show that PIF offers considerably higher speedup as compared to the other two prefetchers. Our findings indicate that the inefficiency of the competitors is mainly because of the metadata-miss as a result of not having enough storage. If the storage budget is unlimited, they offer almost the same level of performance. These results suggest that designing a strong instruction prefetcher is mainly about the storage-efficiency of the prefetcher.</p><p>In this paper, we argue that designing a strong instruction prefetcher needs considering the following. (1) Prefetchers create and store metadata records and prefetch accordingly. These metadata records should carefully be chosen to minimize the number of distinct records. The small number of such records enables a prefetcher to experience a high hit ratio in its metadata storage. (2) Along with the small number of distinct records, each record should need as few bits as possible. This feature enables a prefetcher to store a larger number of records when a specific storage budget is provided.</p><p>Based on the guideline, we introduce MANA prefetcher, which benefits from spatial correlation. Not only spatial correlation offers compact metadata records, but also the number of distinct records is small. We also find that chaining spatial-metadata records provides a space-efficient way to take advantage of temporal correlation among spatial records to maximize the benefit. We organize the metadata storage so that MANA stores as few records as possible, and each record requires a minimal storage cost. The low storage cost enables MANA to achieve over 92% of the performance potential with only 15 KB of storage, considerably outperforming RDIP and Shotgun. Moreover, MANA can prefetch for smaller L1-I caches to eliminate the storage overhead as compared to the baseline design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>This section introduces primary instruction prefetchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Temporal Prefetchers</head><p>Temporal prefetching is based on the fact that the sequence of instruction cache accesses or misses is repetitive, and hence, predictable <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b19">22]</ref>. Consequently, temporal instruction prefetchers record and replay the sequence to eliminate future instruction cache misses. Temporal Instruction Fetch Streaming (TIFS) <ref type="bibr" target="#b19">[22]</ref> records and replays the sequence of misses and offers adequately good results. However, PIF <ref type="bibr" target="#b18">[21]</ref> offers a more significant improvement as compared to TIFS by recording and replaying the sequence of instruction accesses.</p><p>Temporal prefetchers have two main components: a history in which the sequence is recorded, and an index table that determines the last location of every address (more precisely trigger address as we discuss shortly) in the history. Such a structure imposes a high storage cost, which is the main shortcoming of temporal prefetchers <ref type="bibr" target="#b8">[11,</ref><ref type="bibr" target="#b10">13]</ref>. As an example, PIF requires more than 200 KB storage budget per core to work effectively. As providing such ample storage is not feasible, researchers proposed techniques to reduce the storage cost.</p><p>Shared History Instruction Fetch (SHIFT) <ref type="bibr" target="#b25">[28]</ref> shares PIF's metadata among cores and virtualizes <ref type="bibr" target="#b13">[16]</ref> it in the last-level cache (LLC). In multi-core processors, when cores execute the same application, the sequence that is created by one core can be used for others as well. As a result, it is not necessary to use a dedicated metadata table for each core. Sharing and virtualizing PIF's metadata in the LLC reduced prefetcher's storage cost from more than 200 KB per core to a total of 240 KB virtualized in an 8 MB LLC<ref type="foot" target="#foot_0">2</ref> . However, the results show that sharing and virtualizing the metadata in the LLC degrades the performance boost of SHIFT as compared to PIF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">RAS Directed Instruction Prefetcher (RDIP)</head><p>Return-Address-Stack Directed Instruction Prefetcher (RDIP) <ref type="bibr" target="#b29">[32]</ref> is proposed to offer PIF-level performance with a significantly lower storage cost. RDIP observes that the current state of the return-address-stack (RAS) can give an accurate representation of the program's state. To exploit this observation, RDIP XORs the four top entries of the RAS and calls it a signature. Then it assigns the observed instruction cache misses to the corresponding signature. Finally, it stores these misses in a set-associative table that is looked up using the signature. RDIP reduces the per-core storage to over 60 KB. While RDIP requires considerably lower storage as compared to PIF, it still needs a significant storage budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">BTB-Directed Prefetchers</head><p>Branch Target Buffer (BTB)-directed prefetchers are advertised as metadata-free prefetchers. Fetch Directed Instruction Prefetcher (FDIP) <ref type="bibr" target="#b41">[44]</ref> is the pioneer of such prefetchers. The main idea is to decouple the fetch engine from the branch predictor unit. This way, the branch predictor unit goes ahead of the fetch stream to discover the instruction blocks that will be demanded shortly. The prefetcher checks if any of those blocks are missing and prefetches them. For this goal, BTB-directed prefetchers use a deep queue of discovered instructions named Fetch Target Queue (FTQ). FTQ is used to fill the gap between the fetch engine and the branch prediction unit. The prefetcher makes progress instruction by instruction, finds branch instructions by looking up the BTB, consults the branch predictor to determine their target, and inserts the instructions into the FTQ. The instructions at the head of the FTQ are the demand instructions. The remaining entries, on the other hand, enable the prefetch engine to look up the cache and prefetches the missing ones.</p><p>The main bottleneck of BTB-directed prefetchers is BTB misses <ref type="bibr" target="#b30">[33,</ref><ref type="bibr" target="#b31">34]</ref>. To correctly go far ahead of the fetch stream, such a prefetcher needs to detect the branches and predict their target. BTB is the component that is used to detect branch instructions. The branches' directions can be identified using a branch predictor. Kumar et al. investigated the effect of these two components on BTB-directed instruction prefetching <ref type="bibr" target="#b31">[34]</ref>. They showed that while the branch predictor's accuracy is not important, BTB misses can significantly limit BTB-directed prefetchers' efficiency. Hence, their proposal, Boomerang, not only prefetches for the L1-I caches but also the BTB.</p><p>Boomerang uses a basic block-oriented BTB. The main advantage of this BTB type is that the target of each branch is the starting address of a basic block. As a result, Boomerang can detect BTB misses. Moreover, Boomerang uses an instruction pre-decoder to detect branch instructions and extract their targets. By detecting the BTB misses and extracting them from the instruction blocks, Boomerang can prefill BTB to continue going ahead of the fetch stream.</p><p>With Boomerang, BTB misses are still a bottleneck <ref type="bibr" target="#b30">[33]</ref>. Boomerang stalls on a BTB miss and waits until it is resolved. However, resolving a BTB miss requires the instruction block that holds the missing BTB entry to be present in the cache. Otherwise, Boomerang should fetch that block, and then, pre-decode it to extract the required BTB entry and fill in the BTB. As fetching an instruction block takes considerable clock cycles, in workloads with very large instruction footprints in which instruction block and BTB misses are frequent, Boomerang does not offer a considerable performance boost <ref type="bibr" target="#b30">[33]</ref>.</p><p>To address this problem, Kumar et al. proposed a new BTB organization within Shotgun prefetcher <ref type="bibr" target="#b30">[33]</ref> to offer two advantages on top of Boomerang. First, Shotgun prefetches for L1-I without the need to hold all the basic blocks of the instruction cache blocks in the BTB. Moreover, the new BTB covers a larger address space than conventional BTB's. Shotgun has three distinct BTB structures, one for unconditional branches (U-BTB), the other one for conditional branches (C-BTB), and the last one for function and trap returns (RIB). The idea is that unconditional branches determine the global control flow of a program. Consequently, Shotgun uses a large part of its BTB to hold unconditional branches. Moreover, Shotgun stores two footprints for each unconditional branch that show which instruction blocks are accessed around that branch and its target. Using these modifications, Shotgun offers better performance, mainly on workloads with larger instruction footprints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATION</head><p>We compare RDIP, Shotgun, and PIF to determine their advantages and disadvantages. We, then, discuss why we need to develop a new instruction prefetcher and how this prefetcher should be to address the shortcomings of the prior work. The details of the competing approaches, the simulated core, and the benchmarks are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance Comparison</head><p>Figure <ref type="figure">1</ref> compares the performance improvement of RDIP, Shotgun, and PIF over a baseline without a prefetcher. For RDIP and Shotgun, along with the authors-proposed configuration, we evaluate a configuration with infinite storage. Moreover, we evaluate an implementation of PIF in which the history buffer has 5 K entries while it has 32 K entries in the authors-proposed configuration. Results reveal three essential facts. First, PIF outperforms RDIP and Shotgun with a large gap. It means that the reduction in storage in RDIP and Shotgun is achieved at the cost of losing considerable speedup. Second, RDIP and Shotgun considerably fill this gap when infinite storage is available to them. As such, the performance gap in the original configuration is because RDIP and Shotgun are incapable of holding the large number of records that they require to prefetch effectively. Finally, PIF loses performance when the history buffer is reduced. It means that PIF needs a large history buffer to exploit the potential. On the other hand, Shotgun needs to store basic blocks in its BTBs. Shotgun discovers basic blocks one after another and inserts them into the FTQ and prefetches the blocks associated with those basic blocks. As a result, the prefetching record of Shotgun is a basic block, and BTB should be large enough to accommodate the basic blocks. To hold these basic blocks, Shotgun uses three BTBs that hold 2 K entries altogether. However, Shotgun attempts to prefill its BTBs to compensate for its relatively small BTBs. Nevertheless, Figure <ref type="figure">1</ref> shows that even with the prefilling mechanism, the metadata-miss problem is still a considerable bottleneck.</p><p>Finally, PIF benefits from spatial regions. Each spatial region consists of a block address, called a trigger, and a footprint that shows the bitmap of accessed blocks around the trigger. Using the footprint, PIF can detect the accessed blocks by keeping a single bit for each block at the cost of storing the full address of the trigger. PIF writes these spatial regions in a long circular history. Moreover, it uses an index table that records the latest entry of the history buffer in which a particular spatial region is recorded. PIF suggests an index table with 8 K entries that are organized as a 4-way set-associative structure and a 32 K-entry history buffer that is a circular buffer to hold the required prefetching records.</p><p>Figure <ref type="figure" target="#fig_0">2</ref> shows the number of distinct records that are observed for each prefetcher. In other words, we count the number of signatures for RDIP, basic blocks for Shotgun, and spatial regions' trigger addresses for PIF. It can easily be inferred that RDIP and Shotgun have a significantly larger number of distinct prefetching records. Comparing these values to the number of entries that are suggested for RDIP's Miss Table and Shotgun's BTBs, we conclude that these approaches need orders of magnitude more entries to obtain the full potential. Moreover, we observe that PIF has a significantly smaller number of distinct records. The absolute value is close to 5 K on average, and an 8 K-entry index table can accommodate the records.</p><p>While Figure <ref type="figure" target="#fig_0">2</ref> suggests that PIF has fewer distinct prefetching records, its design cannot exploit this advantage. Figure <ref type="figure">1</ref> shows that by decreasing the number of history-buffer entries from 32 K to 5 K, the obtained speedup shrinks from 42.5% to 32%. This result corroborates a similar study in prior work <ref type="bibr" target="#b25">[28]</ref>. The reason is that multiple instances of a spatial record may be written in PIF's history buffer. Consequently, while the number of distinct records is about 5 K, the history buffer should be much larger to hold all of the records successfully. Note that a version of PIF that has a 5 K-entry index table and a 5 K-entry history buffer requires 59 KB, which is still significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Size of Prefetching Records</head><p>Not only the number of distinct records but also the size of each record influences the storage overhead. In this section, we take a look at the records of various prefetchers. To make a fair and consistent comparison, we assume that prefetchers deal with a 46-bit address space.</p><p>RDIP: Each entry in RDIP's Miss Table consists of a signature tag and three trigger addresses, each having an 8-bit footprint. As signatures are 32-bit long, and Miss Table is a 4 K-entry, 4-way set-associative structure, each signature tag is 22-bit long. On the other hand, each trigger address is 40 bits. Summing up altogether, the total storage cost of each Miss Table entry is 166 bits (over 20 bytes).</p><p>Shotgun: Shotgun associates its required information with the BTB and states that it is a metadata-free prefetcher. Nevertheless, to have a powerful Shotgun prefetcher, there is no other way than increasing the BTB size. Unfortunately, BTB is a storage-hungry component as it requires two instruction addresses, the branch address, and the branch target. While Shotgun proposes three separate BTBs and they have some differences, we consider U-BTB in this study, as it is the largest BTB of Shotgun.</p><p>Considering a 2 K-entry BTB that is organized as a 4-way set-associative structure, the tag of the basic-block address needs 37 bits. The target address is 46 bits. Moreover, an entry needs 5 bits for the basic block's size and 1 bit for the branch type. Finally, Shotgun adds two Call and Return footprints to a BTB entry, and each footprint is 8 bits. Altogether, every BTB entry requires 105 bits (over 13 bytes).</p><p>PIF: Each entry of the index table has a spatial-region tag and a pointer to a 32 K-entry history buffer. As the trigger address of each spatial region is a block address, a spatial-region tag is 29-bit long. Moreover, the pointer requires 15 bits to index a 32 K-entry history buffer. As a result, 44 bits should be used for an entry in the index table. Moreover, every entry of the history buffer is a spatial region. A spatial region needs 40 bits for the trigger address and 8 bits for the footprint. As a result, 48 bits are used for an entry in the history buffer. The sum of the number of bits of entries in the index table and history buffer is 92 bits (over 11 bytes). This study shows that due to having a large number of distinct records and the high storage cost of each record, prior prefetchers either do not offer the full potential or need an impractically large storage budget. Figure <ref type="figure">3</ref> experimentally verifies this conclusion by showing the speedup of these prefetchers when we change the storage budget from 8 to 256 KB. The reported speedup is the average across all 50 benchmarks (See Section 5). We assume that the baseline design has a 2 K-entry BTB. In the case of Shotgun, we use the storage budget to enlarge the BTB.</p><p>Generally, Shotgun and PIF offer a very close performance improvement across different storage budgets. However, Figure <ref type="figure">3</ref> shows that RDIP lags behind the other prefetchers in all studied storage budgets. Finally, comparing Figure <ref type="figure">3</ref> and Figure <ref type="figure">1</ref> reveals that even a 256 KB storage budget is not sufficient for RDIP to reach its full potential, which is offered by RDIP infinite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Spatial Regions, a Common Feature</head><p>All of the three prefetchers use a structure similar to PIF's spatial regions. RDIP's Miss Table and Shotgun's U-BTB both have footprints to encode the prefetch candidates associated with the trigger. Such a structure is used because accessed or missed blocks have high spatial correlations, and a footprint can encode the blocks in a lightweight manner. However, surprisingly, none of the prior work used a simple table to record spatial-region footprints while the table is looked up by the trigger address.</p><p>RDIP, Shotgun, and PIF not only successfully detect the current spatial region but also have the ability to find the successor spatial regions. By providing this feature, the prefetcher can (a) prefetch the trigger address of spatial regions and (b) offer excellent timeliness. Providing this feature contributed to many of the complexities of these prefetchers. RDIP associates the current signature's misses to the prior signature. As a result, the prefetched misses are one signature (or equivalently, one call or return) ahead of the fetch stream. Shotgun follows basic blocks one after another to reach the successive U-BTB or RIB hit to prefetch the corresponding footprints. PIF writes the sequence of spatial regions in its history buffer, and consequently, the successive spatial regions are the subsequent entries in the history buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">What Should be Done?</head><p>We know that the spatial region is an excellent prefetching record because of the high spatial correlation among accesses, the compactness of the footprint, and the fewer number of distinct spatial regions' trigger addresses as compared to other record types (See Figure <ref type="figure" target="#fig_0">2</ref>). Consequently, a prefetcher that uses spatial regions as its prefetching records does not suffer from the two crucial limitations of prior work. Moreover, prior work suffered from the mechanism of identifying the subsequent spatial regions. Unfortunately, a spatial region by itself does not identify the next spatial region. In Section 4.4, we discuss how this feature can be provided without the need for complicated and storage-hungry approaches used in the prior work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MANA PREFETCHER</head><p>MANA creates the spatial regions using a spatial region creator and stores them in a set-associative table named MANA_Table. Each spatial region is also associated with a pointer to another MANA_Table entry in which its successor is recorded. A pointer is sufficient to benefit from temporal correlations, as prior temporal prefetchers showed that recently-accessed addresses tend to recur <ref type="bibr" target="#b16">[19,</ref><ref type="bibr" target="#b18">21,</ref><ref type="bibr" target="#b19">22,</ref><ref type="bibr" target="#b51">54,</ref><ref type="bibr" target="#b52">55]</ref>. To reduce the storage cost, MANA exploits this observation that there are a small number of distinct high-order-bits patterns. This phenomenon is because the code base of a program has a high spatial locality and is much smaller than the size of the physical memory <ref type="bibr" target="#b6">[9,</ref><ref type="bibr" target="#b12">15]</ref>. Consequently, instead of recording the complete trigger address that is the largest field of spatial regions, MANA uses the pointers to the observed high-order-bits patterns that need a considerably fewer number of bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Spatial Region Creator</head><p>Spatial Region Creator (SRC) is responsible for creating MANA's prefetching records. Spatial regions consist of a trigger address and a footprint that shows which instruction blocks are observed in the neighborhood of the trigger address. SRC tracks the retire-order instruction stream and extracts its instruction blocks. If the current instruction block is different from the last observed instruction block, SRC attempts to assign this new instruction block to a spatial region. SRC has a queue of spatial regions named Spatial Region Queue (SRQ). After detecting a new instruction block, SRC compares this instruction block with SRQ entries. If this block falls in the address space covered by one of the SRQ entries, SRC sets the corresponding bit in that spatial-region footprint. Otherwise, SRC dequeues an item from SRQ, creates a new spatial region whose trigger address is the new instruction block, resets the footprint, and enqueues it in the SRQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MANA_Table</head><p>When SRC dequeues an entry from SRQ to enqueue a new spatial region, the evicted spatial region is inserted into MANA_Table. MANA_Table stores the spatial regions and uses a set-associative structure with Least Recently Used (LRU) replacement policy that is looked up by the trigger address of the spatial region. Upon an insertion, if a spatial region hit occurs, the spatial region's footprint is updated with the latest footprint. Otherwise, the LRU entry is evicted, and the new spatial region is inserted into MANA_Table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Finding the Next Spatial Region</head><p>We include in MANA_Table's prefetching record a pointer to another entry of MANA_Table to provide a sufficient lookahead to prefetch subsequent spatial regions. Whenever a spatial region is inserted into MANA_Table, MANA records its location. By knowing this location, when MANA records a new entry in the table, the pointer of the last recorded spatial region is set to the location of the new entry. Using these pointers, MANA can chase the spatial regions one after another by iteratively going from a spatial region to its successor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Trigger Address is too Long!</head><p>Considering a 46-bit address space and a 4 K-entry 4-way set-associative MANA_Table, each record requires a 30-bit trigger-address tag, an 8-bit footprint, and a 12-bit pointer to the successor. The 8-bit footprint is derived from prior work <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b25">28,</ref><ref type="bibr" target="#b30">33]</ref>. However, in Section 6.1.1, we choose the appropriate footprint type for MANA. To further reduce the storage cost, we observe that there is a considerable similarity between the high-order bits of the instruction blocks, and there are a few distinct patterns due to the high spatial locality of the code base of programs. As a result, we divide the trigger address tag into two separate parts, a partial tag, and the rest of the high-order bits.</p><p>We store the partial tag in MANA_Table and the rest of the bits in a separate structure. The division of tag should be done in a way to minimize the storage overhead. If we devote more bits for the partial tag, we will have fewer high-order-bits patterns (HOBPs), but we need to store longer partial tags in MANA_Table. On the contrary, if we devote a fewer number of bits to the partial tag field, we will encounter more distinct HOBPs. In the evaluation section, we show how to divide the tag to minimize the overhead.</p><p>MANA stores HOBPs in a set-associative table named high-order-bits patterns' table (HOBPT). Every new observed HOBP is inserted into HOBPT. Moreover, each MANA_Table record has a HOBP index, which points to a HOBPT entry in which the corresponding HOBP is recorded.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Example</head><p>Figure <ref type="figure" target="#fig_2">4</ref> shows how MANA records the spatial regions. The configuration of MANA is for illustrative purposes. The actual configuration is determined through sensitivity analyses in Section 6. The shown process has six steps. SRQ holds two spatial regions whose footprints contain four instruction blocks ahead of the trigger address. The figure also shows the state of HOBPT and MANA_Table.</p><p>We represent a spatial region as '(A, XXXX)' where 'A' is the trigger address, and 'XXXX' is the footprint of the following four blocks. In the beginning, SRQ is empty. SRC tracks the block address of the retired instructions. In the first step, the retired instruction belongs to block A. SRC looks up SRQ, and as it is empty, SRC finds no match. As a result, SRC creates a new spatial region which is '(A, 0000)'. In Step 2, the retired instruction is from block A+1. SRC looks up SRQ and finds out that A+1 falls in the address space covered by '(A, 0000)' and sets the corresponding bit in its footprint. In the next step, the observed instruction block is B that does not fall in any of the already created spatial regions. Consequently, SRC creates a new spatial region and enqueues it in the SRQ. In Step 4, similar to Step 2, another bit is set in the spatial region's footprint, whose trigger address is A. In Step 5, SRC cannot match the instruction block with any of the SRQ entries. Moreover, SRQ is full. As a result, it dequeues an entry from SRQ to provide a space for the new spatial region. SRC inserts '(C, 0000)' into SRQ. Moreover, the evicted spatial region is sent to MANA_Table. Similarly, in Step 6, '(D, 0000)' is enqueued in SRQ, and '(B, 0000)' is evicted and stored in MANA_Table.</p><p>We now describe how spatial regions are placed in MANA_Table. For simplicity, we consider a direct-mapped MANA_Table with 256 entries. Suppose that the address of instruction block A is 0x1FFCAB32. Due to MANA_Table's structure, the eight lower-order bits of A are used to determine the table index in which this spatial region should be stored. Because the lower-order bits are 0x32 or 50 in decimal number representation, as the figure shows, this spatial region is inserted into the 50th entry of the table. MANA_Table exploits the commonality among the high-order bits of the instruction block addresses. This means that MANA compares the 16 high-order bits of A with the observed patterns in HOBPT. As MANA finds a match in the first entry of HOBPT, zero is recorded in the HOBP index field of MANA_Table. This way, instead of keeping 16 bits for higher-order bits, we need only four bits assuming that HOBPT keeps 16 distinct patterns. Moreover, we use an 8-bit partial tag to store the remaining bits of the trigger address tag that are not stored in HOBPT. Figure <ref type="figure" target="#fig_2">4</ref> shows how an instruction cache block address can be constructed by combining the HOBP index, the partial tag, and the set number in which a record is stored.</p><p>MANA also updates the successor pointer. When MANA inserts '(A, 1100)' into MANA_Table, it also stores the table index in which this record is inserted (i.e., 50). Later on, when MANA inserts the next record '(B, 0000)' in the 120th row of MANA_Table, it also goes to row 50 and sets the successor pointer to 120. It means that when MANA prefetches the instruction blocks recorded in '(A, 1100)', it can easily prefetch '(B, 0000)' by following the pointer. After setting the successor pointer, MANA updates its last inserted record from 50 to 120.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Replaying</head><p>MANA takes advantage of the stream address buffer (SAB), which is previously used by prior temporal prefetchers <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b25">28,</ref><ref type="bibr" target="#b26">29]</ref>, to prefetch for the L1-I cache. SAB is a fixed-length sequence of spatial regions that are created by chasing the spatial regions one after another from the pointers that are stored in MANA_Table. Moreover, SAB has a pointer to the MANA_Table entry that the last spatial region is fetched from and inserted into SAB.</p><p>SAB has three goals. First, it enables MANA to go sufficiently ahead of the retire-order instruction stream to issue timely prefetches. Second, SAB helps MANA to know the instruction blocks that are already prefetched and the current lookahead of them. Finally, by tracking the spatial regions that are already prefetched, SAB enables MANA to eliminate redundant and repetitive prefetch requests.</p><p>MANA attempts to have a fixed lookahead ahead of the fetch stream to prefetch the trigger address of the successor spatial regions and also to have timeliness. This lookahead is defined as the number of spatial regions that MANA prefetches ahead when it observes an instruction cache block. MANA tracks the fetch stream and extracts its instruction block addresses. If the block address falls in the address space that is covered by a spatial region in a SAB, MANA checks the number of spatial regions that are prefetched after the matched spatial region, and hence, are inserted into SAB. If this number is lower than the lookahead, MANA chases the spatial regions using SAB's pointer to MANA_Table to have sufficient lookahead. If MANA finds no SAB associated with the block address, it considers the instruction block as the trigger address of a spatial region and looks up MANA_Table to find the corresponding spatial region. If MANA_Table finds a match, MANA evicts the LRU SAB entry (if it has multiple SABs) and creates a new SAB by inserting the found spatial regions into SAB and chasing its successor pointer to find the next spatial region. MANA repeats this process until the number of inserted spatial regions into SAB reaches the predefined lookahead depth. Finally, MANA extracts the instruction blocks that are encoded in the footprint of the inserted spatial regions and prefetches them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Simulation Framework</head><p>To evaluate our proposal, we use ChampSim simulator [1] with the configurations shown in Table <ref type="table" target="#tab_3">1</ref>. We made substantial changes to ChampSim to accurately model the frontend of a processor. Among them, we model BTB in ChampSim, which is not modeled in the baseline implementation. Moreover, we simulate BTB miss and branch direction/target misprediction stalls in the address generation component as a result of modeling BTB <ref type="foot" target="#foot_1">3</ref> . Furthermore, we model wrong-path fetches when a taken BTB miss or a branch direction/target misprediction happens. Modeling the wrong-path fetches is important as they may pollute the cache hierarchy if they eventually become useless. Or they may become useful as observed in <ref type="bibr" target="#b31">[34]</ref>, and hence, lower the usefulness of a prefetcher. The evaluated prefetchers are triggered on instruction or block addresses touched in the wrong-path, which affects their behavior. We find these changes are crucial to have a fair and accurate evaluation of the competing prefetchers in the context of ChampSim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmarks</head><p>We use public benchmarks that are provided by the first instruction prefetching championship (IPC-1) [2]. This package contains 50 benchmarks, including eight for the clients' execution, as well as 35 for servers, and seven from SPEC. While we execute all 50 benchmarks, as it is not possible to show all the results, we selected ten benchmarks that represent various observed behaviors. Moreover, we report the average of the ten selected benchmarks as well as the average of all 50 benchmarks.</p><p>Each benchmark is executed for 50 million instructions to warm up the system, including the caches, the branch predictor, and prefetchers' metadata. The rest of the instructions (i.e., 50 million instructions) are used to collect the evaluation metrics, including Instruction Per Cycle (IPC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Competing Proposals</head><p>baseline: Table <ref type="table" target="#tab_3">1</ref> summarizes our baseline core's configuration. All performance improvements are measured against this baseline.  <ref type="table">,</ref> where each entry holds three trigger addresses and the associated footprint of the observed instruction cache misses. All the parameters are chosen based on the original proposal <ref type="bibr" target="#b29">[32]</ref>. This prefetcher imposes 83 KB storage to the baseline design with no instruction prefetcher.</p><p>Shotgun: We model Shotgun <ref type="bibr" target="#b30">[33]</ref> with a 1.5 K-entry U-BTB, a 128-entry C-BTB, and a 512-entry RIB, as suggested in the original proposal. Moreover, Shotgun uses a 64-entry instruction cache prefetch buffer and a 32-entry BTB prefetch buffer. Shotgun imposes 6 KB storage cost to the baseline design; 4 KB comes from the prefetch buffers, and the rest is because of the changes made to the BTB. PIF: PIF <ref type="bibr" target="#b18">[21]</ref> records the sequence of spatial regions in a circular history buffer of 32 K spatial regions. To find a record in the history buffer, PIF uses an index table that holds pointers to history buffer's entries. We model a 4-way set-associative index table with 2 K sets, as in the original proposal. PIF imposes over 236 KB of storage overhead to the baseline design. As in the original proposal, the temporal compactor contains eighteen spatial regions, the lookahead is five, and four SABs are used where each one tracks seven consecutive spatial regions <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b25">28]</ref>.</p><p>MANA: MANA stores the spatial regions in a 4 K-entry table of 1 K sets. Each MANA_Table record consists of 7 bits to indicate the HOBP index, a 2-bit partial tag, an 8-bit footprint, and a 12-bit pointer to the successor spatial region. Moreover, it uses a 128-entry, 8-way set-associative HOBPT. MANA needs a 15 KB storage budget for its metadata.</p><p>Minimum Latency (MinLat) L1-I: MinLat L1-I is used to show the potential of instruction prefetching. In MinLat L1-I, lower levels of the caching hierarchy spend a single cycle when they serve instruction blocks' requests.</p><p>MinLat L1-I + Perfect BTB: In this implementation, an ideal BTB is also used along with the MinLat L1-I that only faces compulsory misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">BTB Prefilling</head><p>In recent proposals, the instruction prefetching problem is twisted to BTB prefilling problem to offer a unified solution to the frontend bottleneck <ref type="bibr" target="#b26">[29,</ref><ref type="bibr" target="#b30">33,</ref><ref type="bibr" target="#b31">34]</ref>. The main idea is that an instruction block has the required information to fill in the missing BTB entries. A simple instruction pre-decoder decodes the fetched and prefetched blocks to extract the branches. Then, these branches are inserted into the BTB to avoid BTB misses. In our evaluation, we assume that RDIP, PIF, and MANA also benefit from this BTB prefilling mechanism. It also provides a more fair comparison with Shotgun as it benefits from BTB prefilling mechanism in its design. However, in section 6.2.3, we evaluate competing proposals only based on their instruction prefetching abilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Parameter Selection</head><p>We start with an initial MANA prefetcher and run sensitivity analyses to tune the parameters. In the initial MANA, the lookahead is five, SRQ size is eighteen, there are four SABs, each having twelve entries. Prior work has shown that this configuration successfully exploits the potential <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b25">28]</ref>. Moreover, MANA_Table holds 4 K entries in a 4-way set-associative structure. We start with a 4 K-entry table because we found MANA creates less than 4 K distinct records, on average<ref type="foot" target="#foot_2">4</ref> . As a result, we expect that such a table can hold the required prefetching records.</p><p>6.1.1 Spatial Region Type. The spatial region type determines the length of the spatial region's footprint and the instruction cache blocks that are encoded into it. We use (X, Y) notation to represent a spatial region that holds X blocks behind and Y blocks ahead of the trigger block. Such a spatial region holds X+Y+1 instruction blocks. Note that the trigger block is held implicitly and does not need to have a dedicated bit in the footprint. Some pieces of prior work have used (2, 6) spatial regions <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b29">32,</ref><ref type="bibr" target="#b30">33]</ref>. However, we examine different spatial regions to find the best performing one. Figure <ref type="figure" target="#fig_3">5</ref> shows MANA's speedup when (0, 4), (0, 6), (0, 8), (1, 7), and (2, 6) spatial regions are used. Results show that the gap between these regions is negligible. However, (0, 8) performs slightly better than the other types. As such, we use this region type in the rest of the evaluation. We note that (0, 4) can be a good design choice as well. It offers competitive speedup and requires four fewer bits, which provides a storage-saving opportunity. 6.1.2 SRQ Length. The next parameter that we are going to set is SRQ length. A longer SRQ holds the spatial regions for a more extended period. It enables SRC to better associate the observed instruction blocks to the already created spatial regions in SRQ. However, a longer SRQ imposes more search overhead. Figure <ref type="figure">6</ref> shows MANA's speedup when we change SRQ length from four to eighteen. As expected, increasing SRQ length improves speedup. However, we choose an 8-entry SRQ to have a more practical and simpler search process. Fig. <ref type="figure">6</ref>. Speedup of various SRQ sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Prefetching Lookahead.</head><p>We analyze the effect of various lookaheads on the MANA prefetcher.</p><p>Figure <ref type="figure" target="#fig_4">7</ref> shows the obtained speedup when the lookahead is 1, 2, 3, 5, and 7. The results show that the lookahead of one lags significantly behind the others. Consequently, the pointer to the successor spatial region is necessary to offer good speedup. Moreover, changing the lookahead from two to seven makes small differences.</p><p>While the lookahead of one only offers 24% speedup, comparing Figure <ref type="figure" target="#fig_4">7</ref> and Figure <ref type="figure">1</ref> reveals that even MANA with the lookahead of one outperforms RDIP and Shotgun. When lookahead is one, MANA does not need the ability to chase the spatial regions. As a result, we can remove the pointer to the successor region field from MANA_Table to reduce the storage overhead. Moreover, it does not need a full tag because MANA only prefetches the instruction blocks that are in the proximity of the trigger address. MANA needs the HOBP index, the partial tag, and the set number to create the trigger address of the spatial region when it chases the pointers. However, when the lookahead is one, MANA looks up MANA_Table using a trigger address that is completely known. Just to determine that an entry is in the table or not, MANA needs a partial tag. We find that the 8-bit partial tag is sufficient to separate MANA_Table hits from misses. This way, each MANA_Table record contains an 8-bit partial tag and an 8-bit footprint, eliminating the need for a HOBP index. Considering a 4 K-entry MANA_Table, 24% speedup can be achieved using only 8 KB of storage.</p><p>We also evaluate the coverage and overprediction of MANA when its lookahead varies from one to seven. A larger lookahead may offer better speedup but may cause lots of useless prefetches because of going too far ahead of the execution stream. Figure <ref type="figure">8</ref> clearly shows this effect. In this figure, miss coverage, non_covered misses, untimely prefetches, and overprediction are shown. Miss coverage shows the fraction of misses that are eliminated by a prefetcher. The encountered misses are divided into two separate categories. The first type includes those misses that MANA did not send a prefetch for, and the second type contains cache misses that a prefetch has been sent for, but the demand arrived before the prefetch reply. The overprediction is the number of useless prefetches to the number of baseline misses and is used to evaluate prefetchers' accuracy <ref type="bibr" target="#b20">[23]</ref>.</p><p>Figure <ref type="figure">8</ref> shows that increasing the lookahead from one to two improves the miss-coverage from 40% to 61%. The considerable better miss coverage is because when lookahead is one, MANA is not able to prefetch the trigger address blocks, and it can only prefetch the footprint. However, when the lookahead is two, MANA can also prefetch the trigger address of the successor spatial regions. However, by going from one to two, the untimely prefetches have been increased from 5% to 13%. It means that MANA issues more prefetch requests, but they are not sufficiently timely to completely hide the fetch access latency. Going from two to three mitigates this problem: the untimely prefetch requests are decreased from 13% to 9%, and the miss-coverage reaches 69%. Increasing the lookahead from three to five and seven only makes negligible differences to the miss-coverage and the untimely prefetches. However, the overprediction increases significantly.</p><p>Based on Figure <ref type="figure" target="#fig_4">7</ref> and 8, we set MANA's lookahead to three in the rest of the evaluation as it offers a right balance between the obtained speedup and the overprediction. Avrg. All</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L1-I</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Misses (%)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Miss Coverage Untimely Prefetches Non_covered Misses Overprediction</head><p>Fig. <ref type="figure">8</ref>. Effect of lookahead on MANA miss coverage.</p><p>6.1.4 SAB Count and Length. In section 4.6, we described how MANA uses SAB to issue or filter the prefetch requests. A single stream whose length is at least equal to the lookahead is the smallest possible SAB configuration. However, tracking multiple SABs or a longer SAB may be helpful because of successfully capturing the recently prefetched spatial regions. Prior work has suggested using four SABs that each one tracks seven <ref type="bibr" target="#b18">[21]</ref> or twelve <ref type="bibr" target="#b25">[28]</ref> spatial regions. However, we find a negligible difference between different configurations both in terms of performance improvement and the ability to filter redundant prefetches. We use a single SAB tracking five spatial regions to have a simple and practical design.</p><p>6.1.5 MANA_Table Size. Figure <ref type="figure">9</ref> shows the speedup of MANA for various MANA_Table sizes.</p><p>In prior experiments, MANA_Table had 4 K entries in a 4-way set-associative structure. In this part, we still use a 4-way set-associative table but vary the number of entries from 1 K to 16 K. Figure <ref type="figure">9</ref> shows that a 4 K-entry table offers considerably better results as compared to 1 K-and 2 K-entry tables. Moreover, increasing the table size to 8 K and 16 K only offers a small improvement. Consequently, we set the number of MANA_Table entries in the rest of the evaluation to 4 K. Fig. <ref type="figure">10</ref>. Effect of MANA_Table's associativity on speedup 6.1.7 High-Order-Bits Patterns. In Section 4.4, we described how the storage requirements of MANA could be reduced by using a partial tag and the commonality of HOBPs. Table <ref type="table" target="#tab_6">2</ref> shows how changing the partial tag's length affects MANA's storage requirements. In this study, we assume that HOBPT is large enough to accommodate all observed patterns. We can infer that MANA requires lower storage when the partial tag's length is two. In this configuration, HOBPT needs to store up to 128 distinct HOBPs, which needs 0.44 KB. Moreover, every MANA_Table entry contains a 7-bit HOBP index to HOBPT. Altogether, HOBPT and MANA_Table will require 14.94 KB storage. To provide a fair comparison, in Figure <ref type="figure">11</ref>, we also evaluate two other prefetchers: Shogtun (+16 KB) and MANA Aggressive. Shotgun's BTB structures require 23.7 KB storage <ref type="bibr" target="#b30">[33]</ref>. As MANA imposes 15 KB storage overhead to the baseline design, we enlarge Shotgun's BTBs to 40 KB to provide the same storage to Shotgun as MANA's. This design is shown as Shotgun (+16 KB). Despite increasing the size of BTBs, Shotgun (+16 KB) still lags behind MANA. Moreover, to have a fair comparison with PIF, we also evaluate an aggressive implementation of MANA shown as (MANA Aggr.) in which, similar to PIF, the lookahead is five, the SRQ length is eighteen, the number of SABs is four, and each SAB tracks seven consecutive spatial regions. Besides, as PIF's index table holds 8 K pointer to the history buffer, we enlarge MANA_Table to have an equal number of entries. This configuration needs 30 KB storage. Figure <ref type="figure">11</ref> shows that such an implementation has almost no gap with PIF. It means that the gap between MANA and PIF is due to our policy to set practical design parameters, and the aggressive implementation offers the level of performance that PIF offers while requires 7.8× less storage.</p><p>6.2.2 Miss Coverage. Figure <ref type="figure" target="#fig_6">12</ref> shows how competing prefetchers perform in terms of covering the L1-I cache misses. RDIP covers a smaller fraction of misses and also has significant untimely prefetches that result in lower performance improvement. On the other hand, we see a considerably large miss coverage from Shotgun despite its poor performance improvement. The reason is that Shotgun stalls feeding the fetch engine when a BTB miss occurs. In such cases, Shotgun triggers its BTB prefilling mechanism that requires bringing the blocks into the L1-I cache and then, feeding the pre-decoder with the arriving instructions to extract the missing branches. After resolving the BTB miss, the basic block is fed into the FTQ and in the next step, it is consumed by the fetch engine. Consequently, these blocks hit in the cache, resulting in a high miss coverage; however, the fetch engine is stalled for a considerable amount of time to resolve the BTB miss, which hurts performance. This observation also corroborates a similar study <ref type="bibr" target="#b3">[6]</ref>. PIF has better miss coverage as compared to MANA which is also translated to its better speedup. Moreover, it has a higher overprediction since it has a higher prefetching depth as compared to MANA.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Instruction Prefetching Abilities.</head><p>In prior experiments, all competing designs could prefill the BTB to gain performance by eliminating the BTB misses. In this section, we compare them solely based on their instruction prefetching abilities. In other words, all designs have a 2 K-entry BTB that will not be prefilled. As BTB prefilling is vital for Shotgun because of its very small C-BTB, we provide two separate BTBs to evaluate Shotgun in this section: a 2 K-entry BTB is used to drive the fetch engine that will not be prefilled similar to its competitors, and Shotgun's BTBs that are only used for L1-I prefetching and benefit from BTB prefilling. Results are shown in Figure <ref type="figure">13</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">MANA with a Smaller Cache Size</head><p>In this section, we use MANA to prefetch for a smaller cache-size. This study has two goals. First, by decreasing the size of the L1-I cache, the number of misses increases, and hence, puts more pressure on the prefetcher. Moreover, if the prefetcher still offers good speedup when it is used with a smaller cache-size, we can reduce the instruction cache size to provide space for MANA prefetcher. However, this design increases the traffic between the L1-I and L2 caches. Moreover, we expect the L2 external bandwidth usage does not change as almost all of the prefetch requests are served by the L2. To provide quantitative analyses, we show the speedup and the L1-I and L2 external bandwidth usage when MANA is used to prefetch for a 16 KB and an 8 KB L1-I cache. By external bandwidth usage, we mean the number of fetch and prefetch requests that are sent to the lower level of the cache hierarchy to the number of fetch requests that are sent when we have used a 32 KB cache with no prefetcher. Figure <ref type="figure" target="#fig_7">14</ref> shows that when we decrease the L1-I cache size, MANA still offers good speedup. The speedup is 35% and 33% for 16 KB and 8 KB caches, respectively. Note that MANA is designed to be independent of what is going on in L1-I caches. In other words, MANA does the same independent of the L1-I cache. The offered speedup on 16 KB cache is very close to the speedup obtained by the conventional 32 KB cache. So, we can use MANA with a 16 KB cache to avoid imposing storage overhead. This way, the design imposes no storage overhead while offers almost the same performance as MANA with a 32 KB cache. As expected, however, the external bandwidth usage increases by decreasing the L1-I size. Figure <ref type="figure" target="#fig_9">15</ref> shows that the external bandwidth usage of 16 K and 8 K L1-I caches increases by 2× and 2.65×, respectively. While the L1-I external bandwidth increases, as it is the bandwidth between L1 and L2 within the chip, it is beneficial to trade it for significant performance improvement. On the other hand, the L2 external bandwidth usage does not change (slightly decreases in some cases) by decreasing the L1-I cache size. We find that almost all of the L1-I requests are served by the L2 cache (no extra traffic). Moreover, L1-I requests regularly promote the instruction cache blocks in the L2 cache to the most recently used (MRU) position, helping them to stay a longer period in the L2 cache, resulting in lower L2 external traffic in some cases.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>Many pieces of prior work showed that the frontend bottleneck is a major source of performance degradation <ref type="bibr" target="#b0">[3,</ref><ref type="bibr" target="#b1">4,</ref><ref type="bibr" target="#b5">8,</ref><ref type="bibr" target="#b14">17,</ref><ref type="bibr" target="#b21">24,</ref><ref type="bibr" target="#b27">30,</ref><ref type="bibr" target="#b33">36,</ref><ref type="bibr" target="#b40">43,</ref><ref type="bibr" target="#b47">50]</ref>. A myriad of proposals suggested prefetchers to address this problem <ref type="bibr">[5, 18, 21, 22, 26, 28, 29, 32-34, 37, 40, 44, 45, 48, 49, 52, 57, 58]</ref>.</p><p>Some of these proposals are branch predictor-directed prefetchers and leverage the branch predictor unit to run ahead of the fetch stream to discover the missed blocks and prefetch them <ref type="bibr" target="#b15">[18,</ref><ref type="bibr" target="#b30">33,</ref><ref type="bibr" target="#b31">34,</ref><ref type="bibr" target="#b37">40,</ref><ref type="bibr" target="#b41">44,</ref><ref type="bibr" target="#b42">45,</ref><ref type="bibr" target="#b46">49,</ref><ref type="bibr" target="#b49">52]</ref>.</p><p>Discontinuity prefetcher <ref type="bibr" target="#b45">[48]</ref> uses a sequential prefetcher to eliminate sequential misses and then records the remaining cache misses in a discontinuity table. Using the discontinuity table, it prefetches the discontinuity misses. Nonetheless, this prefetcher demands a large storage budget as each discontinuity entry consists of two distinct cache block addresses.</p><p>Code-layout optimization is another way to tackle the L1-I miss problem <ref type="bibr" target="#b36">[39,</ref><ref type="bibr" target="#b38">41]</ref>. In these techniques, the program is profiled, and a control flow graph (CFG) is created. By chaining the most frequently executed control-flow changes in the CFG, the layout of the program is optimized. Code-layout optimization works well for workloads, where the control-flow changes are mostly static and can be determined at compile time.</p><p>Some pieces of prior work inserted prefetching instructions into the program code <ref type="bibr" target="#b2">[5,</ref><ref type="bibr" target="#b5">8,</ref><ref type="bibr" target="#b23">26,</ref><ref type="bibr" target="#b34">37,</ref><ref type="bibr" target="#b35">38,</ref><ref type="bibr" target="#b50">53]</ref>. These proposals use an offline or online program-profiling to choose where the prefetching instructions should be added.</p><p>Confluence <ref type="bibr" target="#b26">[29]</ref> is the first proposal that offers a unified solution to address both instruction cache, and BTB misses. It used a pre-decoder to extract the branch instructions from the fetched or prefetched blocks to fill in the BTB. Confluence used SHIFT <ref type="bibr" target="#b25">[28]</ref> as its instruction prefetcher; however, its idea can be applied to any other instruction prefetcher. In this work, we used Confluence's notion along with competing prefetchers to eliminate the BTB misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>Prior work used various prefetchers to eliminate instruction cache misses; however, as shown in this paper, they either do not offer the full potential or require excessive storage. We showed that prior proposals suffer from requiring a large number of prefetching records to offer their full potential and the high storage cost of these records. In this paper, we made a case that designing an effective and cost-efficient instruction prefetcher is about choosing the right metadata record and microarchitecting the prefetcher to minimize the storage requirement. Given these insights, we introduced MANA prefetcher. With only 15 KB storage, MANA offers a level of performance close to the best performing and highly storage-hungry instruction prefetcher. Moreover, MANA significantly outperforms all prior prefetchers when they have the same storage budget.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Number of distinct prefetching records.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Overview of MANA recording spatial regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Speedup of various region types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Effect of lookahead on speedup of MANA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Miss coverage of competing prefetchers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Speedup of MANA for various L1-I cache sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>L2C L1-I L2C L1-I L2C L1-I L2C L1-I L2C L1-I L2C L1-I L2C L1-I L2C L1-I L2C L1-I L2C L1-I L2C L1-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. L1-I and L2 external bandwidth usage when MANA prefetches for various L1-I cache sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Evaluation Parameters RDIP<ref type="bibr" target="#b29">[32]</ref> uses the top four entries of RAS to create the signatures. Moreover, we model a 4 K-entry, 4-way set-associative Miss Table</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Core</cell><cell>14 nm, a single 4 GHz OoO core 352-entry ROB, 128-entry Load Queue, 72-entry Store Queue</cell></row><row><cell>Fetch Unit</cell><cell>32 KB, 8-way, 64B block size, 4-cycle latency hashed-perceptron branch predictor [51], 2K-entry Branch Target Buffer, 8-entry MSHRs</cell></row><row><cell>L1-D Cache</cell><cell>48 KB, 12-way, 64B block, 5-cycle latency, 16-entry MSHRs, next-line prefetcher</cell></row><row><cell>L2 Cache</cell><cell>512 KB, 8-way, 10-cycle latency, Signature Path Pattern (SPP) [31] prefetcher</cell></row><row><cell cols="2">Last Level Cache 2 MB, 16-way, 20-cycle latency, 64-entry MSHRs</cell></row><row><cell>RDIP:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 .</head><label>2</label><figDesc>Effect of partial-tag length on MANA's storage requirements.In this section, we compare MANA prefetcher against state-of-the-art proposals.6.2.1 Performance Improvement. Figure11shows the speedup of competing prefetchers. This figure reveals that MANA significantly outperforms RDIP and Shotgun and has only a small gap with PIF. RDIP, Shotgun, PIF, and MANA provide 22, 6.5, 42, and 38% speedup on top of a baseline design without any prefetcher. It clearly shows how MANA outperforms its competitors with a large gap or offer competitive performance improvement with significantly smaller storage. Comparing MANA with MinLat L1-I + Perfect BTB, we conclude that MANA offers 92% of the performance that can be obtained by MinLat L1-I + Perfect BTB.</figDesc><table><row><cell cols="4">Partial Tag Bits HOBP Index Bits HOBPT Storage MANA_Table Storage</cell><cell>Sum</cell></row><row><cell>0</cell><cell>9</cell><cell>1.88 KB</cell><cell>14.5 KB</cell><cell>16.38 KB</cell></row><row><cell>1</cell><cell>8</cell><cell>0.9 KB</cell><cell>14.5 KB</cell><cell>15.4 KB</cell></row><row><cell>2</cell><cell>7</cell><cell>0.44 KB</cell><cell>14.5 KB</cell><cell>14.94 KB</cell></row><row><cell>5</cell><cell>5</cell><cell>0.1 KB</cell><cell>15 KB</cell><cell>15.1 KB</cell></row><row><cell>8</cell><cell>3</cell><cell>0.02 KB</cell><cell>15.5 KB</cell><cell>15.52 KB</cell></row><row><cell>11</cell><cell>3</cell><cell>0.02 KB</cell><cell>17 KB</cell><cell>17.02 KB</cell></row><row><cell cols="2">6.2 Comparison with Prior Work</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Comparing MinLat L1-I in this figure and MinLat L1-I + Perfect BTB in Figure11, we can see how much eliminating BTB misses is crucial to have a high performance instruction supply. Moreover, we see Shotgun offers near the same level of performance when we compare its results in Figures11 and 13. It means that a conventional 2 K-entry BTB that does not benefit from BTB prefilling is as strong as Shotgun's BTBs where its small C-BTB is aggressively prefilled, in terms of driving the fetch engine. RDIP, Shotgun, PIF, and MANA offer 13, 7, 25, and 21% speedup where MinLat L1-I offers 25% that is very close to PIF. It can be seen that for some traces like server 12, PIF outperforms MinLat L1-I. It is because a powerful instruction prefetcher can completely hide the miss latency while the MinLat L1-I faces some delays to process the fetch requests in the lower levels of the memory hierarchy.</figDesc><table><row><cell></cell><cell>RDIP</cell><cell></cell><cell cols="2">Shotgun</cell><cell></cell><cell>PIF</cell><cell></cell><cell>MANA</cell><cell></cell><cell cols="2">MinLat L1-I</cell></row><row><cell></cell><cell>2.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Speedup</cell><cell>1.4 1.6 1.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>client</cell><cell>client</cell><cell>server</cell><cell>server</cell><cell>server</cell><cell>server</cell><cell>server</cell><cell>server</cell><cell>spec</cell><cell>spec</cell><cell>Avrg.</cell><cell>Avrg.</cell></row><row><cell></cell><cell>2</cell><cell>7</cell><cell>1</cell><cell>11</cell><cell>12</cell><cell>16</cell><cell>30</cell><cell>36</cell><cell>gcc-3</cell><cell>x264-1</cell><cell>10</cell><cell>All</cell></row><row><cell></cell><cell cols="10">Fig. 13. Speedup of competing proposals when BTB prefilling is disabled.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">SHIFT's storage cost is proportional to the LLC size.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">The baseline implementation only models branch direction misprediction stalls.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">In Figure2, we show that PIF creates</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">K records, on average. MANA creates a smaller number of distinct records because instead of a decoupled spatial and temporal compactors used in PIF, it uses a coupled approach in its SRC that helps it to more efficiently create its spatial regions.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DBMSs on a Modern Processor: Where does Time Go</title>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Very Large Data Bases (VLDP)</title>
				<meeting>the 25th International Conference on Very Large Data Bases (VLDP)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="266" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploring Predictive Replacement Policies for Instruction Cache and Branch Target Buffer</title>
		<author>
			<persName><forename type="first">Samira</forename><surname>Mirbagher Ajorpaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elba</forename><surname>Garza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangam</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Call Graph Prefetching for Database Applications</title>
		<author>
			<persName><forename type="first">Murali</forename><surname>Annavaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jignesh</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
		<idno type="DOI">10.1145/945506.945509</idno>
		<ptr target="https://doi.org/10.1145/945506.945509" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="412" to="444" />
			<date type="published" when="2003-11">2003. Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Divide and Conquer Frontend Bottleneck</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 47th Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Memory Hierarchy for Web Search</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2018.00061</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2018.00061" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the 24th IEEE International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="643" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">AsmDB: understanding and mitigating front-end stalls in warehouse-scale computers</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nayana</forename><forename type="middle">Prasad</forename><surname>Nagendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoun</forename><forename type="middle">Kyu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trivikram</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture</title>
				<meeting>the 46th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="462" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reducing writebacks through in-cache displacement</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aydin</forename><surname>Faraji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyed</forename><surname>Armin Vakil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farid</forename><surname>Ghahani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Samandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note>TODAES)</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast data delivery for many-core processors</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abbas</forename><surname>Mazloumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farid</forename><surname>Samandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmood</forename><surname>Naderan-Tahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Modarressi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="1416" to="1429" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An efficient temporal data prefetcher for L1 caches</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="99" to="102" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domino temporal data prefetcher</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="131" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bingo spatial data prefetcher</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehran</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="399" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Evaluation of hardware data prefetchers on server processors</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyedali</forename><surname>Tabaeiaghdaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamidreza</forename><surname>Zare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.08828</idno>
		<title level="m">Die-Stacked DRAM: Memory, Cache, or MemCache?</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predictor Virtualization</title>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Burcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1346281.1346301</idno>
		<ptr target="https://doi.org/10.1145/1346281.1346301" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
				<meeting>the 13th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="157" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Detailed Characterization of a Quad Pentium Pro Server Running TPC-D</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-L</forename><surname>Larriba-Pey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Knighten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youjip</forename><surname>Won</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCD.1999.808414</idno>
		<ptr target="https://doi.org/10.1109/ICCD.1999.808414" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Design (ICCD)</title>
				<meeting>the IEEE International Conference on Computer Design (ICCD)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="108" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Instruction prefetching using branch prediction information</title>
		<author>
			<persName><forename type="first">I-Cheng K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Chieh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><forename type="middle">N</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings International Conference on Computer Design VLSI in Computers and Processors</title>
				<meeting>International Conference on Computer Design VLSI in Computers and Processors</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="593" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Proactive Instruction Fetch</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ferdman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Clearing the Clouds: A Study of Emerging Scale-Out Workloads on Modern Hardware</title>
		<author>
			<persName><forename type="first">Almutaz</forename><surname>Michael Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stavros</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Djordje</forename><surname>Alisafaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><forename type="middle">Daniel</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
				<meeting>the 17th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Proactive Instruction Fetch</title>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Michael Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 44th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Temporal Instruction Fetch Streaming</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 41th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Harnessing Pairwise-Correlating Data Prefetching With Runahead Metadata</title>
		<author>
			<persName><forename type="first">Fatemeh</forename><surname>Golshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehran</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="130" to="133" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Database Servers on Chip Multiprocessors: Limitations and Opportunities</title>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ippokratis</forename><surname>Pandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naju</forename><forename type="middle">G</forename><surname>Mancheril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Biennial Conference on Innovative Data Systems Research (CIDR)</title>
				<meeting>the 3rd Biennial Conference on Innovative Data Systems Research (CIDR)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="79" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers</title>
		<author>
			<persName><forename type="first">Jouppi</forename><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="364" to="373" />
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">pTask: A Smart Prefetching Scheme for OS Intensive Applications</title>
		<author>
			<persName><forename type="first">Prathmesh</forename><surname>Kallurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Smruti</surname></persName>
		</author>
		<author>
			<persName><surname>Sarangi</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2016.7783706</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2016.7783706" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 49th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Profiling a Warehouse-scale Computer</title>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Pablo</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
		<idno type="DOI">10.1145/2749469.2750392</idno>
		<ptr target="https://doi.org/10.1145/2749469.2750392" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 42nd Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SHIFT: Shared History Instruction Fetch for Lean-core Server Processors</title>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 46th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="272" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Confluence: Unified Instruction Supply for Scale-out Servers</title>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2830772.2830785</idno>
		<ptr target="https://doi.org/10.1145/2830772.2830785" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 48th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="166" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Performance Characterization of a Quad Pentium Pro SMP Using OLTP Workloads</title>
		<author>
			<persName><forename type="first">Kimberly</forename><surname>Keeton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><forename type="middle">Qiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">C</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><forename type="middle">E</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 25th Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Path confidence based lookahead prefetching</title>
		<author>
			<persName><forename type="first">Jinchun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Al Narasimha Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeshan</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><surname>Chishti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">RDIP: Return-Address-Stack Directed Instruction Prefetching</title>
		<author>
			<persName><forename type="first">Aasheesh</forename><surname>Kolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Blasting Through the Front-End Bottleneck with Shotgun</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Nagarajan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173162.3173178</idno>
		<ptr target="https://doi.org/10.1145/3173162.3173178" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
				<meeting>the 23rd International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="30" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Boomerang: A Metadata-Free Architecture for Control Flow Delivery</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Chieh</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Nagarajan</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2017.53</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2017.53" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the IEEE International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="493" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Understanding and Designing New Server Architectures for Emerging Warehouse-Computing Environments</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichuan</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandrakant</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 35th Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="315" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An Analysis of Database Workload Performance on Simultaneous Multithreaded Processors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><forename type="middle">André</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">J</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><forename type="middle">M</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sujay</surname></persName>
		</author>
		<author>
			<persName><surname>Parekh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 25th Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cooperative Prefetching: Compiler and Hardware Support for Effective Instruction Prefetching in Modern Processors</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.1998.742780</idno>
		<ptr target="https://doi.org/10.1109/MICRO.1998.742780" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 31st Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="182" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Architectural and Compiler Support for Effective Instruction Prefetching: A Cooperative Approach</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<idno type="DOI">10.1145/367742.367786</idno>
		<ptr target="https://doi.org/10.1145/367742.367786" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="71" to="109" />
			<date type="published" when="2001-02">2001. Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Profile Guided Code Positioning</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Pettis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.1145/93542.93550</idno>
		<ptr target="https://doi.org/10.1145/93542.93550" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</title>
				<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Wrong-path Instruction Prefetching</title>
		<author>
			<persName><forename type="first">Jim</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Mudge</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.1996.566459</idno>
		<ptr target="https://doi.org/10.1109/MICRO.1996.566459" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 29th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="165" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Code Layout Optimizations for Transaction Processing Workloads</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>André Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Larriba-Pey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Geoffrey</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1145/379240.379260</idno>
		<ptr target="https://doi.org/10.1145/379240.379260" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 28th Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fetching Instruction Streams</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oliverio</surname></persName>
		</author>
		<author>
			<persName><surname>Santana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Josep L Larriba-Pey</surname></persName>
		</author>
		<author>
			<persName><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2002.1176264</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2002.1176264" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 35th Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="371" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Performance of Database Workloads on Shared-Memory Systems with Out-of-Order Processors</title>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarita</forename><forename type="middle">V</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz André</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><surname>Barroso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
				<meeting>the 8th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fetch Directed Instruction Prefetching</title>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Reinman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the 32nd Annual ACM/IEEE International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Optimizations enabled by a decoupled front-end architecture</title>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Reinman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="338" to="355" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Enlarging Instruction Streams</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oliverio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1109/TC.2007.70742</idno>
		<ptr target="https://doi.org/10.1109/TC.2007.70742" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers (TC)</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1342" to="1357" />
			<date type="published" when="2007-10">2007. Oct. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sequential Program Prefetching in Memory Hierarchies</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1109/C-M.1978.218016</idno>
		<ptr target="https://doi.org/10.1109/C-M.1978.218016" />
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="7" to="21" />
			<date type="published" when="1978-12">1978. Dec. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Effective Instruction Prefetching in Chip Multiprocessors for Modern Commercial Applications</title>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Spracklen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santosh</forename><forename type="middle">G</forename><surname>Abraham</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2005.13</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2005.13" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the 11th IEEE International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Branch History Guided Instruction Prefetching</title>
		<author>
			<persName><forename type="first">Viji</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><forename type="middle">S</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">J</forename><surname>Charney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Puzak</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2001.903271</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2001.903271" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the 7th IEEE International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A Detailed Comparison of Two Transaction Processing Workloads</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Stets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><surname>Barroso</surname></persName>
		</author>
		<idno type="DOI">10.1109/WWC.2002.1226492</idno>
		<ptr target="https://doi.org/10.1109/WWC.2002.1226492" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Workshop on Workload Characterization (WWC)</title>
				<meeting>the IEEE International Workshop on Workload Characterization (WWC)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Merging path and gshare indexing in perceptron branch prediction</title>
		<author>
			<persName><forename type="first">David</forename><surname>Tarjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Skadron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on architecture and code optimization</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="280" to="300" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Instruction Cache Prefetching Using Multilevel Branch Prediction</title>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">V</forename><surname>Veidenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1007/BFb0024203</idno>
		<ptr target="https://doi.org/10.1007/BFb0024203" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium of High-Performance Computing (ISHPC)</title>
				<meeting>the International Symposium of High-Performance Computing (ISHPC)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="51" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Guided Region Prefetching: A Cooperative Hardware/Software Approach</title>
		<author>
			<persName><forename type="first">Zhenlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">C</forename><surname>Weems</surname></persName>
		</author>
		<idno type="DOI">10.1145/859618.859663</idno>
		<ptr target="https://doi.org/10.1145/859618.859663" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 30th Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="388" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Practical Off-chip Meta-data for Temporal Memory Streaming</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2009.4798239</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2009.4798239" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th IEEE International Symposium on High-Performance Computer Architecture (HPCA</title>
				<meeting>the 15th IEEE International Symposium on High-Performance Computer Architecture (HPCA</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Temporal Streaming of Shared Memory</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jangwoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA.2005.50</idno>
		<ptr target="https://doi.org/10.1109/ISCA.2005.50" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 32nd Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Instruction Prefetching of Systems Codes with Layout Optimized for Reduced Cache Misses</title>
		<author>
			<persName><forename type="first">Chun</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
		<idno type="DOI">10.1145/232973.233001</idno>
		<ptr target="https://doi.org/10.1145/232973.233001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the 23rd Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="271" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Analyzing the Worst-Case Execution Time for Instruction Caches with Prefetching</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Embedded Computing Systems (TECS</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Execution History Guided Instruction Prefetching</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Haga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Barua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Supercomputing (ICS)</title>
				<meeting>the International Conference on Supercomputing (ICS)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
