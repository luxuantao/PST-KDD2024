<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exact Diffusion for Distributed Optimization and Learning -Part I: Algorithm Development</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kun</forename><surname>Yuan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bicheng</forename><surname>Ying</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaochuan</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
						</author>
						<title level="a" type="main">Exact Diffusion for Distributed Optimization and Learning -Part I: Algorithm Development</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8D399141AF8F9A4915BB053E6EACC709</idno>
					<idno type="DOI">10.1109/TSP.2018.2875898</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TSP.2018.2875898, IEEE Transactions on Signal Processing This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TSP.2018.2875898, IEEE Transactions on Signal Processing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>distributed optimization</term>
					<term>diffusion</term>
					<term>consensus</term>
					<term>exact convergence</term>
					<term>left-stochastic matrix</term>
					<term>doublystochastic matrix</term>
					<term>locally-balanced policy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work develops a distributed optimization strategy with guaranteed exact convergence for a broad class of left-stochastic combination policies. The resulting exact diffusion strategy is shown in Part II <ref type="bibr" target="#b1">[2]</ref> to have a wider stability range and superior convergence performance than the EXTRA strategy. The exact diffusion method is applicable to locally-balanced left-stochastic combination matrices which, compared to the conventional doubly-stochastic matrix, are more general and able to endow the algorithm with faster convergence rate, more flexible step-size choices and improved privacy-preserving properties. The derivation of the exact diffusion strategy relies on reformulating the aggregate optimization problem as a penalized problem and resorting to a diagonallyweighted incremental construction. Detailed stability and convergence analyses are pursued in Part II [2] and are facilitated by examining the evolution of the error dynamics in a transformed domain. Numerical simulations illustrate the theoretical conclusions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION AND MOTIVATION</head><p>This work deals with deterministic optimization problems where a collection of N networked agents operate cooperatively to solve an aggregate optimization problem of the form:</p><formula xml:id="formula_0">w o = arg min w∈R M J o (w) = N k=1 J k (w).<label>(1)</label></formula><p>In this formulation, each risk function J k (w) is convex and differentiable, while the aggregate cost J o (w) is stronglyconvex. Throughout the paper, we assume the network is undirected. All agents seek to determine the unique global minimizer, w o , under the constraint that agents can only communicate with their neighbors. This distributed approach is robust to failure of links and/or agents and scalable to the network size. Optimization problems of this type find applications K. Yuan and B. Ying are with the Department of Electrical Engineering, University of California, Los Angeles, CA 90095 USA. Email:{kunyuan, ybc, xiaochuanzhao}@ucla.edu. X. Zhao is now with Goldman Sachs, NY. A. H. Sayed is with the School of Engineering, Ecole Polytechnique Federale de Lausanne (EPFL), Switzerland. Email: ali.sayed@epfl.ch. This work was supported in part by NSF grants CCF-1524250 and ECCS-1407712. A short conference version of the results from Parts I and II appear in the short conference publication <ref type="bibr" target="#b0">[1]</ref>. in a wide range of areas including wireless sensor networks <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b5">[6]</ref>, multi-vehicle and multi-robot control systems <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, cyber-physical systems and smart grid implementations <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b11">[12]</ref>, distributed adaptation and estimation <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b16">[17]</ref>, distributed statistical learning <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref> and clustering <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>.</p><p>There are several classes of distributed algorithms that can be used to solve problem <ref type="bibr" target="#b0">(1)</ref>. In the primal domain, implementations that are based on gradient-descent methods are effective and easy to implement. There are at least two prominent variants under this class: the consensus strategy <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b29">[30]</ref> and the diffusion strategy <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b16">[17]</ref>. There is a subtle but critical difference in the order in which computations are performed under these two strategies. In the consensus implementation, each agent runs a gradient-descent type iteration, albeit one where the starting point for the recursion and the point at which the gradient is approximated are not identical. This construction introduces an asymmetry into the update relation, which has some undesirable instability consequences (described, for example, in Secs. 7.2-7.3, Example 8.4, and also in Theorem 9.3 of <ref type="bibr" target="#b13">[14]</ref> and Sec. V.B and Example 20 of <ref type="bibr" target="#b12">[13]</ref>). The diffusion strategy, in comparison, employs a symmetric update where the starting point for the iteration and the point at which the gradient is approximated coincide. This property results in a wider stability range for diffusion strategies <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Nevertheless, when sufficiently small step-sizes are employed to drive the optimization process, both types of strategies (consensus and diffusion) are able to converge exponentially fast, albeit only to an approximate solution <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b26">[27]</ref>. Specifically, it is proved in <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b30">[31]</ref> that both the consensus and diffusion iterates under constant step-size learning converge towards a neighborhood of square-error size O(µ 2 ) around the true optimizer, w o , i.e., w k,i 2 = O(µ 2 ) as i → ∞, where µ denotes the step-size and w k,i denotes the error at agent k and iteration i relative to w o . Since we are dealing with deterministic optimization problems, this small limiting bias is not due to any gradient noise arising from stochastic approximations; it is instead due to the inherent structure of the consensus and diffusion updates as clarified in the sequel.</p><p>Another important family of distributed algorithms are those based on the distributed alternating direction method of multipliers (ADMM) <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref> and its variants <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref>. These methods treat problem <ref type="bibr" target="#b0">(1)</ref> in both the primal and dual domains. It is shown in <ref type="bibr" target="#b33">[34]</ref> that distributed ADMM with constant parameters will converge exponentially fast to the exact global solution w o . However, distributed ADMM solutions are computationally more expensive since they necessitate the solution of optimal sub-problems at each iteration. Some useful variations of distributed ADMM <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref> may alleviate the computational burden, but their recursions are still more difficult to implement than consensus or diffusion.</p><p>In more recent work <ref type="bibr" target="#b37">[38]</ref>, a modified implementation of consensus iterations, referred to as EXTRA, is proposed and shown to converge to the exact minimizer w o rather than to an O(µ 2 )-neighborhood around w o . The modification has a similar computational burden as traditional consensus and is based on adding a step that combines two prior iterates to remove bias. Motivated by <ref type="bibr" target="#b37">[38]</ref>, other variations with similar properties were proposed in <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b42">[43]</ref>. These variations rely instead on combining inexact gradient evaluations with a gradient tracking technique. The resulting algorithms, compared to EXTRA, have two information combinations per recursion, which doubles the amount of communication variables compared to EXTRA, and can become a burden when communication resources are limited.</p><p>The current work is motivated by the following considerations. The result in <ref type="bibr" target="#b37">[38]</ref> shows that the EXTRA technique resolves the bias problem in consensus implementations. However, it is known that traditional diffusion strategies outperform traditional consensus strategies. Would it be possible then to correct the bias in the diffusion implementation and attain an algorithm that is superior to EXTRA (e.g., an implementation that is more stable than EXTRA)? This is one of the contributions in this two-part work; Parts I and II <ref type="bibr" target="#b1">[2]</ref>. In this first part, we develop a bias-free diffusion strategy that will be shown in Part II <ref type="bibr" target="#b1">[2]</ref> to have a wider stability range than EXTRA consensus implementations. Achieving these objectives is challenging for several reasons. First, we need to understand the origin of the bias in diffusion implementations. Compared to the consensus strategy, the source of this bias is different and still not well understood. In seeking an answer to this question, we will initially observe that the diffusion recursion can be framed as an incremental algorithm to solve a penalized version of (1) and not (1) directly -see expression (72) further ahead. In other words, the local diffusion estimate w k,i , held by agent k at iteration i, will be shown to approach the solution of a penalized problem rather than w o , which causes the bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Contributions</head><p>We have four main contributions in this article and the accompanying Part II <ref type="bibr" target="#b1">[2]</ref> relating to: (a) developing a distributed algorithm (which we refer to as exact diffusion) that ensures exact convergence based on the diffusion strategy; (b) showing that exact diffusion has wider stability range and enhanced performance than EXTRA <ref type="bibr" target="#b37">[38]</ref>; (c) showing that exact diffusion works for the larger class of locally balanced (rather than only doubly-stochastic) matrices; and (d) showing that neither EXTRA nor exact diffusion can be extended to the general directed network by constructing counter examples, which helps illustrate the significance of the locally balanced conditions.</p><p>More specifically, we will first show in this article how to modify the diffusion strategy such that it solves the real problem (1) directly. We shall refer to this variant as exact diffusion. Interestingly, the structure of exact diffusion will turn out to be very close to the structure of standard diffusion. The only difference is that there will be an extra "correction" step added between the usual "adaptation" and "combination" steps of diffusion -see the listing of Algorithm 1 further ahead. It will become clear that this adapt-correct-combine (ACC) structure of the exact diffusion algorithm is more symmetric in comparison to the EXTRA recursions. In addition, the computational cost of the "correction" step is trivial. Therefore, with essentially the same computational efficiency as standard diffusion, the exact diffusion algorithm will be able to converge exponentially fast to w o without any bias. Secondly, we will show in Part II <ref type="bibr" target="#b1">[2]</ref> that exact diffusion has a wider stability range than EXTRA. In other words, there will exist a larger range of step-sizes that keeps exact diffusion stable but not the EXTRA algorithm. This is an important observation because larger values for µ help accelerate convergence.</p><p>Our third contribution is that we will derive the exact diffusion algorithm, and establish its convergence property for the class of locally balanced combination matrices (see Definition 1). This class does not only include symmetric doubly-stochastic matrices as special cases, but it also includes a range of widely-used left-stochastic policies as explained further ahead. First, we recall that left-stochastic matrices are defined as follows. Let a k denote the weight that is used to scale the data that flows from agent to k. Let A ∆ = [a k ] ∈ R N ×N denote the matrix that collects all these coefficients. The entries on each column of A are assumed to add up to one so that A is left-stochastic, i.e., it holds that</p><formula xml:id="formula_1">A T 1 N = 1 N , or N =1 a k = 1, ∀ k = 1, • • • , N.<label>(2)</label></formula><p>The matrix A will not be required to be symmetric. For example, it may happen that a k = a k . Using these coefficients, when an agent k combines the iterates {ψ ,i } it receives from its neighbors, that combination will correspond to:</p><formula xml:id="formula_2">w k,i+1 = N =1 a k ψ ,i ,</formula><p>where</p><formula xml:id="formula_3">N =1 a k = 1.<label>(3)</label></formula><p>Obviously, w k,i+1 is a convex combination of {ψ ,i }.</p><p>It should be emphasized that condition <ref type="bibr" target="#b1">(2)</ref>, which is repeated in <ref type="bibr" target="#b2">(3)</ref>, is different from all previous algorithms studied in <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, which require A to be symmetric and doubly stochastic (i.e., each of its columns and rows should add up to one). For undirected networks, although symmetric doubly-stochastic matrices are commonly used, balanced left-stochastic policies can have significant practical value -they can speed up convergence, permit a more relaxed selection of the step-size parameter, reach better mean-square-error (MSE) performance over adaptive networks, and enjoy better privacy-preserving propertiessee the extended discussions in Sec. II-C.</p><p>We also explain in this work the significance of the proposed locally balanced conditions. If the combination matrix does not satisfy these conditions, we show that one can construct counter examples where both exact diffusion and EXTRA diverge for any given step-size (see Sec. V). This implies an interesting conclusion: exact diffusion and EXTRA may not always work for general directed networks (see the discussions in Secs. II-D and V). This seems to be a disadvantage in comparison with DIGing-based methods <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b42">[43]</ref>, which are designed for directed network. However, for scenarios where the locally balanced condition is satisfied, exact diffusion is shown in simulations (later in Fig. <ref type="figure" target="#fig_6">3</ref> of Part II <ref type="bibr" target="#b1">[2]</ref>) to operate over a wider range of step-sizes and is more communication efficient than DIGing methods <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b42">[43]</ref> (recall that in DIGing there are two information combinations per iteration).</p><p>In this Part I we derive the exact diffusion algorithm, while in Part II <ref type="bibr" target="#b1">[2]</ref> we establish its convergence properties and prove its stability superiority over the EXTRA algorithm. This article is organized as follows. In Section II we review the standard diffusion algorithm, introduce locally-balanced left-stochastic combination policies, and establish several of their properties. In Section III we identify the source of bias in standard diffusion implementations. In Section IV we design the exact diffusion algorithm to correct for the bias. In Section V we illustrate the importance of the locally-balanced condition on the combination policies by showing that divergence can occur if it is not satisfied. Numerical simulations are presented in Section VI.</p><p>Notation: Throughout the paper we use diag{x 1 , • • • , x N } to denote a diagonal matrix consisting of diagonal entries x 1 , • • • , x N , and use col{x 1 , • • • , x N } to denote a column vector formed by stacking x 1 , • • • , x N . For symmetric matrices X and Y , the notation X ≤ Y or Y ≥ X denotes Y -X is positive semi-definite. For a vector x, the notation x 0 denotes that each element of x is non-negative, while the notation x 0 denotes that each element of x is positive. For a matrix X, we let range(X) denote its range space, and null(X) denote its null space. The notation</p><formula xml:id="formula_4">1 N = col{1, • • • , 1} ∈ R N .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DIFFUSION AND COMBINATION POLICIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Standard Diffusion Strategy</head><p>To proceed, we will consider a more general optimization problem than (1) by introducing a weighted aggregate cost of the form:</p><formula xml:id="formula_5">w = arg min w∈R M J (w) = N k=1 q k J k (w),<label>(4)</label></formula><p>for some positive coefficients {q k }. Problem (1) is a special case when the q k are uniform, i.e., q 1 = q 2 = . . . = q N , in which case w = w o . Note also that the aggregate cost J (w) is strongly-convex when J o (w) is strongly-convex.</p><p>To solve problem (4) over a connected network of agents, we consider the standard diffusion strategy <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b14">[15]</ref>:</p><formula xml:id="formula_6">ψ k,i = w k,i-1 -µ k ∇J k (w k,i-1 ),<label>(5)</label></formula><formula xml:id="formula_7">w k,i = ∈N k a k ψ ,i ,<label>(6)</label></formula><p>where {µ k } N k=1 are positive step-sizes, and the {a k } N =1,k=1</p><p>are nonnegative combination weights satisfying</p><formula xml:id="formula_8">∈N k a k = 1.<label>(7)</label></formula><p>Moreover, N k denotes the set of neighbors of agent k, and ∇J k (•) denotes the gradient vector of J k relative to w. It follows from <ref type="bibr" target="#b6">(7)</ref> that A = [a k ] ∈ R N ×N is a left-stochastic matrix. It is assumed that the network graph is connected, meaning that a path with nonzero combination weights can be found linking any pair of agents. It is further assumed that the graph is strongly-connected, which means that at least one diagonal entry of A is non-zero <ref type="bibr" target="#b13">[14]</ref> (this is a reasonable assumption since it simply requires that at least one agent in the network has some confidence level in its own data). In this case, the matrix A will be primitive. This implies, in view of the Perron-Frobenius theorem <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b43">[44]</ref>, that there exists an eigenvector p satisfying Ap = p, 1 T N p = 1, p 0. (8) We refer to p as the Perron eigenvector of A. Next, we introduce the vector q</p><formula xml:id="formula_9">∆ = col{q 1 , q 2 , . . . , q N } ∈ R N ,<label>(9)</label></formula><p>where q k is the weight associated with J k (w) in (4). To guarantee the convergence of recursion ( <ref type="formula" target="#formula_6">5</ref>) and ( <ref type="formula" target="#formula_7">6</ref>), we let the constant scalar β and step-sizes µ k be chosen such that <ref type="formula" target="#formula_10">10</ref>) is not restrictive and can be satisfied for any left-stochastic matrix A through the choice of the parameter β and the step-sizes. Note that β should satisfy</p><formula xml:id="formula_10">q = β diag{µ 1 , µ 2 , • • • , µ N }p. (<label>10</label></formula><formula xml:id="formula_11">) Remark 1. (Scaling) Condition (</formula><formula xml:id="formula_12">β = q k p k 1 µ k<label>(11)</label></formula><p>for all k. To make the expression for β independent of k, we parameterize (select) the step-sizes as</p><formula xml:id="formula_13">µ k = q k p k µ o<label>(12)</label></formula><p>for some small µ o &gt; 0. Then, β = 1/µ o , which is independent of k, and relations <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b10">(11)</ref> are satisfied.</p><p>Remark 2. (Perron entries) Expression <ref type="bibr" target="#b11">(12)</ref> suggests that agent k needs to know the Perron entry p k in order to run the diffusion strategy ( <ref type="formula" target="#formula_6">5</ref>)-( <ref type="formula" target="#formula_7">6</ref>). As we are going to see in the next section, the Perron entries are actually available beforehand and in closed-form for several well-known leftstochastic policies (see, e.g., expressions <ref type="bibr" target="#b17">(18)</ref>, <ref type="bibr" target="#b21">(22)</ref>, and (27) further ahead). For other left-stochastic policies for which closed-form expressions for the Perron entries may not be available, these can be determined iteratively by means of the power iteration -see, e.g., the explanation leading to future expression <ref type="bibr" target="#b37">(38)</ref>.</p><p>It was shown by Theorem 3 in <ref type="bibr" target="#b30">[31]</ref> that under <ref type="bibr" target="#b9">(10)</ref>, the iterates w k,i generated through the diffusion recursion ( <ref type="formula" target="#formula_6">5</ref>)-(6) will approach w , i.e., lim sup</p><formula xml:id="formula_14">i→∞ w -w k,i 2 = O(µ 2 max ), ∀ k = 1, • • • , N,<label>(13)</label></formula><p>where <ref type="formula" target="#formula_14">13</ref>) implies that the diffusion algorithm will converge to a neighborhood around w , and that the square-error bias is on the order of O(µ 2 max ).</p><formula xml:id="formula_15">µ max = max{µ 1 , • • • , µ N }. Result (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Combination Policy</head><p>Result ( <ref type="formula" target="#formula_14">13</ref>) is a reassuring conclusion: it ensures that the squared-error is small whenever µ max is small; moreover, the result holds for any left-stochastic matrix. Moving forward, we will focus on an important subclass of left-stochastic matrices, namely, those that satisfy a mild local balance condition (we shall refer to these matrices as balanced leftstochastic policies) <ref type="bibr" target="#b44">[45]</ref>. The balancing condition turns out to have a useful physical interpretation and, in addition, it will be shown to be satisfied by several widely used leftstochastic combination policies. The local balance condition will help endow networks with useful properties to ensure exact convergence to w without any bias. In this way, we will be able to propose distributed optimization strategies with exact convergence guarantees for this class of left-stochastic matrices, while EXTRA <ref type="bibr" target="#b37">[38]</ref> is limited to (the less practical) doubly-stochastic policies.</p><p>Definition 1 (LOCALLY BALANCED POLICIES). Let p denote the Perron eigenvector of a primitive left-stochastic matrix A, with entries {p }. Let P = diag(p) correspond to the diagonal matrix constructed from p. The matrix A is said to satisfy a local balance condition if it holds that</p><formula xml:id="formula_16">a k p k = a k p , k, = 1, • • • , N<label>(14)</label></formula><p>or, equivalently, in matrix form:</p><formula xml:id="formula_17">P A T = AP. (<label>15</label></formula><formula xml:id="formula_18">)</formula><p>Relations of the form <ref type="bibr" target="#b13">(14)</ref> are common in the context of Markov chains. They are used there to model an equilibrium scenario for the probability flux into the Markov states <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>, where the {a k } represent the transition probabilities from states to k and the {p } denote the steady-state distribution for the Markov chain.</p><p>We provide here an interpretation for <ref type="bibr" target="#b13">(14)</ref> in the context of multi-agent networks by considering two generic agents, k and , from an arbitrary network, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The coefficient a k is used by agent k to scale information arriving from agent . Therefore, this coefficient reflects the amount of confidence that agent k has in the information arriving from agent . Likewise, for a k . Since the combination policy is not necessarily symmetric, it will hold in general that a k = a k . However, agent k can re-scale the incoming weight a k by p k , and likewise for agent , so that the local balance condition <ref type="bibr" target="#b13">(14)</ref> requires each pair of rescaled weights to match each other. We can interpret a k to represent the (fractional) amount of information flowing from to k and p k to represent the price paid by agent k for that information. Expression ( <ref type="formula" target="#formula_16">14</ref>) is then requiring the information-cost benefit to be equitable across agents.</p><p>It is worth noting that the local balancing condition ( <ref type="formula" target="#formula_16">14</ref>) is satisfied by several important left-stochastic policies, as illustrated in four examples below. Thus, let for agent k. Then condition <ref type="bibr" target="#b9">(10)</ref> becomes</p><formula xml:id="formula_19">τ k = µ k /µ max</formula><formula xml:id="formula_20">q = βµ max diag{τ 1 , τ 2 , • • • , τ N }p, (<label>16</label></formula><formula xml:id="formula_21">) where τ k ∈ (0, 1].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Policy 1 (Hastings rule)</head><p>The first policy we consider is the Hastings rule. Given {q k } N k=1 and {µ k } N k=1 , we select a k as <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b47">[48]</ref>:</p><formula xml:id="formula_22">a k =              µ k /q k max{n k µ k /q k , n µ /q } , if ∈ N k \{k}, 1 - m∈N k \{k} a mk , if = k, 0, if / ∈ N k . (<label>17</label></formula><formula xml:id="formula_23">)</formula><p>where</p><formula xml:id="formula_24">n k ∆ = |N k | (the number of neighbors of agent k).</formula><p>It can be verified that A is left-stochastic, and that the entries of its Perron eigenvector p are given by</p><formula xml:id="formula_25">p k ∆ = q k /µ k N =1 q /µ &gt; 0.<label>(18)</label></formula><p>Let</p><formula xml:id="formula_26">β = N =1 q /µ = 1 µ max N =1 q /τ &gt; 0.<label>(19)</label></formula><p>Using ( <ref type="formula" target="#formula_22">17</ref>) and <ref type="bibr" target="#b17">(18)</ref>, it is easy to verify that</p><formula xml:id="formula_27">a k p k = 1 β max{n k µ k /q k , n µ /q } = a k p . (<label>20</label></formula><formula xml:id="formula_28">) If = k, it is obvious that (14) holds. If / ∈ N k , then k / ∈ N . In this case, a k p k = a k p = 0.</formula><p>Furthermore, we can also verify that when {q k } N k=1 and {µ k } N k=1 are given, {a k } are generated through <ref type="bibr" target="#b16">(17)</ref>, and β is chosen as in <ref type="bibr" target="#b18">(19)</ref>, then condition (10) is satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Policy 2 (Averaging rule)</head><p>The second policy we consider is the popular average combination rule where a k is chosen as</p><formula xml:id="formula_29">a k = 1/n k , if ∈ N k , 0, otherwise. (<label>21</label></formula><formula xml:id="formula_30">)</formula><p>The entries of the Perron eigenvector p are given by</p><formula xml:id="formula_31">p k = n k N m=1 n m -1 .<label>(22)</label></formula><p>With ( <ref type="formula" target="#formula_29">21</ref>) and ( <ref type="formula" target="#formula_31">22</ref>), it clearly holds that</p><formula xml:id="formula_32">a k p k = N m=1 n m -1 = a k p ,<label>(23)</label></formula><p>which implies <ref type="bibr" target="#b13">(14)</ref>.</p><p>We can further verify that when µ k is set as</p><formula xml:id="formula_33">µ k = q k n k µ o , ∀ k = 1, 2, • • • , N<label>(24)</label></formula><p>for some positive constant step-size µ o and β is set as</p><formula xml:id="formula_34">β = N m=1 n m µ o &gt; 0,<label>(25)</label></formula><p>then condition (10) will hold.</p><p>Policy 3 (Relative-degree rule) The third policy we consider is the relative-degree combination rule <ref type="bibr" target="#b48">[49]</ref> where a k is chosen as</p><formula xml:id="formula_35">a k = n m∈N k n m -1 , if ∈ N k , 0, otherwise,<label>(26)</label></formula><p>and the entries of the Perron eigenvector p are given by</p><formula xml:id="formula_36">p k = n k m∈N k n m N k=1 n k m∈N k n m . (<label>27</label></formula><formula xml:id="formula_37">)</formula><p>With ( <ref type="formula" target="#formula_35">26</ref>) and ( <ref type="formula" target="#formula_36">27</ref>), it clearly holds that</p><formula xml:id="formula_38">a k p k = n k n N k=1 n k m∈N k n m = a k p ,<label>(28)</label></formula><p>which implies <ref type="bibr" target="#b13">(14)</ref>.</p><p>We can further verify that when µ k is set as</p><formula xml:id="formula_39">µ k = q k n k m∈N k n m µ o , ∀ k = 1, 2, • • • , K,<label>(29)</label></formula><p>and β is set as</p><formula xml:id="formula_40">β = N k=1 n k m∈N k n m µ o ,<label>(30)</label></formula><p>then condition (10) will hold.</p><p>Policy 4 (Doubly stochastic policy) If matrix A is primitive, symmetric, and doubly stochastic, its Perron eigenvector is p = 1 N 1 N . In this situation, the local balance condition (14) holds automatically.</p><p>Furthermore, if we assume each agent employs the step-size µ k = q k N µ o for some positive constant step-size µ o , it can be verified that condition <ref type="bibr" target="#b9">(10)</ref> holds with β = 1/µ o .</p><p>(31) There are various rules to generate a primitive, symmetric and doubly stochastic matrix. Some common rules are the Laplacian rule, maximum-degree rule, Metropolis rule and other rules that listed in Table <ref type="table">14</ref>.1 in <ref type="bibr" target="#b13">[14]</ref>.</p><p>Policy 5 (Other locally-balanced policies) For other leftstochastic-policies for which closed-form expressions for the Perron entries need not be available, the Perron eigenvector p can be learned iteratively to ensure that the step-sizes µ k end up satisfying <ref type="bibr" target="#b11">(12)</ref>. Before we explain how this can be done, we remark that since the combination matrix A is leftstochastic in our formulation, the power iteration employed in push-sum implementations cannot be applied since it works for right-stochastic policies. We proceed instead as follows.</p><p>Since A is primitive and left-stochastic, it is shown in <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b49">[50]</ref> that</p><formula xml:id="formula_41">lim i→∞ A i = p1 T N . (<label>32</label></formula><formula xml:id="formula_42">)</formula><p>This relation also implies</p><formula xml:id="formula_43">lim i→∞ (A T ) i = 1 N p T .<label>(33)</label></formula><p>Now let e k be the k-th column of the identity matrix I N ∈ R N ×N . Furthermore, let each agent k keep an auxiliary variable z k,i ∈ R N with each z k,-1 initialized to e k . We also introduce</p><formula xml:id="formula_44">Z i ∆ = col{z 1,i , z 2,i , • • • , z N,i } ∈ R N 2 ,<label>(34)</label></formula><formula xml:id="formula_45">A ∆ = A ⊗ I N . (<label>35</label></formula><formula xml:id="formula_46">) By iterating Z i according to Z i+1 = A T Z i ,<label>(36)</label></formula><p>we have lim</p><formula xml:id="formula_47">i→∞ Z i = lim i→∞ (A T ) i+1 Z -1 = lim i→∞ [(A T ) i+1 ⊗ I N ]Z -1 (33) = (1 N p T ⊗ I N )Z -1 = [(1 N ⊗ I N )(p T ⊗ I N )]Z -1 . (<label>37</label></formula><formula xml:id="formula_48">) Since Z -1 = col{e 1 , • • • .e N }, it can be verified that (p T ⊗ I N )Z -1 = p.</formula><p>Substituting into (37), we have lim i→∞ z k,i = p. In summary, it holds that</p><formula xml:id="formula_49">lim i→∞ z k,i (k) = p k (<label>38</label></formula><formula xml:id="formula_50">)</formula><p>where z k,i (k) is the k-th entry of the vector z k,i . Therefore, if we set</p><formula xml:id="formula_51">µ k,i = q k µ o z k,i (k) ,<label>(39)</label></formula><p>then it follows that</p><formula xml:id="formula_52">lim i→∞ µ k,i = q k µ o /p k .<label>(40)</label></formula><p>Finally, to guarantee z k,i (k) &gt; 0 for i = 0, 1, 2, • • • , it is enough to assume a kk &gt; 0 for each agent k = 1, 2, • • • , N , i.e., each agent has to assign positive weight to itself. We illustrate in Fig. <ref type="figure" target="#fig_1">2</ref> the relations among the classes of symmetric doubly-stochastic, balanced left-stochastic, and left-stochastic combination matrices. It is seen that every symmetric doubly-stochastic matrix is both left-stochastic and balanced. We indicated earlier that the EXTRA algorithm was derived in <ref type="bibr" target="#b37">[38]</ref> with exact convergence properties for symmetric doubly-stochastic matrices. Here, in the sequel, we shall derive an exact diffusion strategy with exact convergence guarantees for the larger class of balanced left-stochastic matrices (which is therefore also applicable to symmetric doubly-stochastic matrices). We will show in Part II <ref type="bibr" target="#b1">[2]</ref> that the exact diffusion implementation has a wider stability range than EXTRA consensus; this is a useful property since larger step-sizes can be used to attain larger convergence rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Value of balanced left-stochastic policies</head><p>For undirected networks, though it is quite common to employ symmetric and doubly-stochastic combination policies such as in <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, balanced leftstochastic policies can still be of great value. Some of the key benefits of these policies are as follows.</p><p>First, balanced left-stochastic policies can speed up convergence. For example, in highly unbalanced networks (e.g., the coauthorship network) where the degrees of neighboring nodes differ drastically, the averaging rule enables faster convergence than doubly-stochastic policies (see the discussions in Sec. VI-C). The second scenario where balanced left-stochastic policies help is when the Lipschitz constant associated with each local cost function differs drastically among nodes -the Lipschitz constants δ in some nodes are much larger than the other nodes. Note that δ can be regarded as an importance measure of node , and it is helpful for agent k to assign more (less) weights to neighboring node if δ is large (small). One such weighting policy is the Hastings rule</p><formula xml:id="formula_53">a k =              1/δ k max{n k /δ k , n /δ } , if ∈ N k \{k}, 1 - m∈N k \{k} a mk , if = k, 0, if / ∈ N k .<label>(41)</label></formula><p>which is balanced left-stochastic. The Hastings rule (41) performs similar to importance sampling in the machine learning literature <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref> where data samples with larger magnitude are assigned larger sampling probability. We illustrate the benefit of the Hastings rule (41) in Sec. VI-C. Second, balanced left-stochastic policies enable more flexible step-size choices -each agent k can choose a different local step-size µ k . For example, suppose each agent k sets a proper local step-size µ k , the exact convergence can be guaranteed if the combination policy is generated according to the Hastings rule <ref type="bibr" target="#b16">(17)</ref>, see the explanation in Policy 1. In contrast, EXTRA with a doubly-stochastic matrix has to enforce that all agents choose the same step-size µ. Note that such flexible step-size choices have many benefits. It avoids the communication costs to coordinate step-sizes. Moreover, each agent can choose step-sizes purely according to its own local cost functions. If the Lipschitz constant associated with the gradient of J k (w) is small (or large), agent k can set a relatively large (or small) step-size, which can speed up the converge of the algorithm. The works <ref type="bibr" target="#b41">[42]</ref> and <ref type="bibr" target="#b42">[43]</ref> also propose methods that enable the use of different local stepsizes in each agent. These methods employ a gradient-tracking technique to correct the bias incurred by uncoordinated stepsizes, and hence double the amount of communication variables compared to exact diffusion.</p><p>Third, balanced left-stochastic policies can have better privacy-preserving properties than doubly-stochastic policies.</p><p>For example, the averaging rule ( <ref type="formula" target="#formula_29">21</ref>) can be constructed from the agent's own degree, and no neighbors' degree is required. In contrast, the doubly-stochastic matrices generated by the maximum-degree rule or Metropolis rule <ref type="bibr" target="#b13">[14]</ref> will require agents to share their degrees with neighbors.</p><p>Fourth, it is shown in Chapters 12 and 15 of <ref type="bibr" target="#b13">[14]</ref> that the Hastings rule and the relative-degree rule (see <ref type="bibr" target="#b25">(26)</ref>) achieve better mean-square-error (MSE) performance over adaptive networks than doubly-stochastic policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Role of the locally balanced condition</head><p>One may wonder whether exact convergence can be guaranteed for general left-stochastic matrices that are not necessarily balanced (i.e., whether the convergence property can be extended beyond the middle elliptical area in Fig. <ref type="figure" target="#fig_1">2</ref>). It turns out that one can provide examples of combination matrices that are left-stochastic (but not necessarily balanced) for which exact convergence occurs and others for which exact convergence does not occur (see, e.g., the examples in Section V and Figs. 9 and 10). In other words, exact convergence is not always guaranteed beyond the balanced class. This conclusion is another useful contribution of this work; it shows that there is a boundary inside the set of left-stochastic matrices within which convergence can be always guaranteed (namely, the set of balanced matrices).</p><p>It is worth noting that the recent works <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref> extend the EXTRA method to the case of directed networks by employing a push-sum technique. These extensions do not require the local balancing condition but they establish convergence only if the step-size parameter falls within an interval (c lower , c upper ) where c lower and c upper are two positive constants. However, it is not proved in these works whether this interval is feasible, i.e., whether c upper &gt; c lower . In fact, we will construct examples in Section V for which both exact diffusion and push-sum EXTRA will diverge for any step-size µ. In other words, both exact diffusion and EXTRA methods need not work well for directed networks. This is a disadvantage in comparison with DIGing-based methods <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b42">[43]</ref>.</p><p>In summary, when locally-balanced policies is employed, exact diffusion is more communication efficient and also more stable than other techniques including DIGing methods (because the communicated variables required in each iteration of DIGing is twice as much as that in exact diffusion) and EX-TRA. However, just like EXTRA, the exact diffusion strategy is applicable to undirected (rather than directed) graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Useful Properties</head><p>We now establish several useful properties for primitive leftstochastic matrices that satisfy the local balance condition <ref type="bibr" target="#b13">(14)</ref>. These properties will be used in the sequel.</p><p>Lemma 1 (PROPERTIES OF AP -P + I N ). When A satisfies the local balance condition <ref type="bibr" target="#b13">(14)</ref>, it holds that the matrix AP -P + I N is primitive, symmetric, and doubly stochastic.</p><p>Proof: With condition ( <ref type="formula" target="#formula_16">14</ref>), the symmetry of AP -P +I N is obvious. To check the primitiveness of AP -P + I N , we need to verify two facts, namely, that: (a) at least one diagonal entry in AP -P + I N is positive, and (b) there exists at least one path with nonzero weights between any two agents. It is easy to verify condition (a) because A is already primitive and P &lt; I N . For condition (b), since A is connected and all diagonal entries of P are positive, then if there exists a path with nonzero coefficients linking agents k and under A, the same path will continue to exist under AP . Moreover, since all diagonal entries of -P + I N are positive, then the same path will also exist under AP -P +I N . Finally, AP -P +I N is doubly stochastic because</p><formula xml:id="formula_54">1 T N (AP -P + I N ) = p T -p T + 1 T N = 1 T N ,<label>(42)</label></formula><formula xml:id="formula_55">(AP -P + I N ) 1 N = p -p + 1 N = 1 N . (<label>43</label></formula><formula xml:id="formula_56">)</formula><p>Lemma 2 (NULLSPACE OF P -AP ). When A satisfies the local balance condition <ref type="bibr" target="#b13">(14)</ref>, it holds that P -AP is symmetric and positive semi-definite. Moreover, it holds that null(P -AP ) = span{1 N }, (44) where null(•) denotes the null space of its matrix argument.</p><p>Proof: Let λ k denote the k-th largest eigenvalue of AP -P + I N . Recall from Lemma 1 that AP -P + I N is primitive and doubly stochastic. Therefore, according to Lemma F.4 from <ref type="bibr" target="#b13">[14]</ref> (or Lemma 5 in Appendix B) it holds that</p><formula xml:id="formula_57">1 = λ 1 &gt; λ 2 ≥ λ 3 ≥ • • • ≥ λ N &gt; -1,<label>(45)</label></formula><p>It follows that the eigenvalues of AP -P are non-positive so that P -AP ≥ 0.</p><p>Note further from (45) that the matrix AP -P + I N has a single eigenvalue at one with multiplicity one. Moreover, from <ref type="bibr" target="#b42">(43)</ref> we know that the vector 1 N is a right-eigenvector associated with this eigenvalue at one. Based on these two facts, we have (AP -P + I N ) x = x ⇐⇒ x = c1 N (46) for any constant c. Relation ( <ref type="formula">46</ref>) is equivalent to</p><formula xml:id="formula_58">(AP -P ) x = 0 ⇐⇒ x = c1 N ,<label>(47)</label></formula><p>which confirms <ref type="bibr" target="#b43">(44)</ref>. (48) Moreover, for any block vector</p><formula xml:id="formula_59">X = col{x 1 , x 2 , • • • , x N } ∈ R M N in the nullspace of P -AP with entries x k ∈ R M , it holds that (P -AP)X = 0 ⇐⇒ x 1 = x 2 = • • • = x N .<label>(49)</label></formula><p>Proof: Since P -AP + I N has a single eigenvalue at 1 with multiplicity one, we conclude that (P -AP + I N ) ⊗ I M will have an eigenvalue at 1 with multiplicity M . Next we denote the columns of the identity matrix by</p><formula xml:id="formula_60">I M = [e 1 , e 2 , • • • , e N ]</formula><p>where e k ∈ R M . We can verify that 1 N ⊗ e k is a right-eigenvector associated with the eigenvalue 1 because</p><formula xml:id="formula_61">[(P -AP + I N ) ⊗ I M ][1 N ⊗ e k ] = [(P -AP + I N )1 N ] ⊗ e k = 1 N ⊗ e k .<label>(50)</label></formula><p>Now since any two vectors in the set {1 N ⊗ e k } M k=1 are mutually independent, we conclude that (P -AP)X = 0 ⇐⇒ (P -AP +</p><formula xml:id="formula_62">I M N )X = X ⇐⇒ X ∈ span{[1 N ⊗ e 1 , • • • , 1 N ⊗ e M ]} ⇐⇒ X ∈ span{1 N ⊗ I M }.</formula><p>(51) These equalities establish <ref type="bibr" target="#b47">(48)</ref>. From <ref type="bibr" target="#b47">(48)</ref> we can also conclude <ref type="bibr" target="#b48">(49)</ref> because</p><formula xml:id="formula_63">X ∈ span{1 N ⊗ I M } ⇒ X = (1 N ⊗ I M ) • x = col{x, x, • • • , x}<label>(52)</label></formula><p>from some x ∈ R M . The direction "⇐" of ( <ref type="formula" target="#formula_59">49</ref>) is obvious.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 3 (REAL EIGENVALUES).</head><p>When A satisfies the local balance condition <ref type="bibr" target="#b13">(14)</ref>, it holds that A is diagonalizable with real eigenvalues in the interval (-1, 1], i.e.,</p><formula xml:id="formula_64">A = Y ΛY -1 , (<label>53</label></formula><formula xml:id="formula_65">) where Λ = diag{λ 1 (A), • • • , λ N (A)} ∈ R N ×N , and 1 = λ 1 (A) &gt; λ 2 (A) ≥ λ 3 (A) ≥ • • • ≥ λ N (A) &gt; -1. (<label>54</label></formula><formula xml:id="formula_66">)</formula><p>Proof: According to the local balance condition (15), P A T is symmetric. Using the fact that P &gt; 0 is diagonal, it holds that</p><formula xml:id="formula_67">P -1 2 AP 1 2 = P -1 2 (AP )P -1 2 ,<label>(55)</label></formula><p>which shows that the matrix on the left-hand side is symmetric. Therefore, P -1 2 AP 1 2 can be decomposed as</p><formula xml:id="formula_68">P -1 2 AP 1 2 = Y 1 ΛY T 1 ,<label>(56)</label></formula><p>where Y 1 is an orthogonal matrix and Λ is a real diagonal matrix. From (56), we further have that</p><formula xml:id="formula_69">A = P 1 2 Y 1 ΛY T 1 P -1 2 . (<label>57</label></formula><formula xml:id="formula_70">)</formula><p>If we let Y = P 1 2 Y 1 , we reach the decomposition <ref type="bibr" target="#b52">(53)</ref>. Moreover, since A is a primitive left-stochastic matrix, according to Lemma F.4 from <ref type="bibr" target="#b13">[14]</ref> (or Lemma 5 in Appendix B), the eigenvalues of A satisfy <ref type="bibr" target="#b53">(54)</ref>.</p><p>For ease of reference, we collect in Table <ref type="table">I</ref> the properties established in Lemmas 1 through 3 for balanced primitive leftstochastic matrices A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Properties of balanced primitive left-stochastic matrices A</head><p>A is diagonalizable with real eigenvalues in (-1, 1]; A has a single eigenvalue at 1; AP -P + IN is symmetric, primitive, doubly-stochastic; P -AP is positive semi-definite; null(P -AP ) = span(1N ); null(P -AP) = span{1N ⊗ IM }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PENALIZED FORMULATION OF DIFFUSION</head><p>In this section, we employ the properties derived in the previous section to reformulate the unconstrained optimization problem (4) into the equivalent constrained problem (70), which will be solved using a penalized formulation. This derivation will help clarify the origin of the O(µ 2 max ) bias from <ref type="bibr" target="#b12">(13)</ref> in the standard diffusion implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Constrained Problem Formulation</head><p>To begin with, note that the unconstrained problem ( <ref type="formula" target="#formula_5">4</ref>) is equivalent to the following constrained problem:</p><formula xml:id="formula_71">min {w k } N k=1 q k J k (w k ), s.t. w 1 = w 2 = • • • = w N . (<label>58</label></formula><formula xml:id="formula_72">)</formula><p>Now we introduce the block vector</p><formula xml:id="formula_73">W ∆ = col{w 1 , • • • , w N } ∈ R N M and J (W) ∆ = N k=1 q k J k (w k ),<label>(59)</label></formula><p>With ( <ref type="formula" target="#formula_59">49</ref>) and (59), problem ( <ref type="formula" target="#formula_71">58</ref>) is equivalent to</p><formula xml:id="formula_74">min W∈R N M J (W), s.t. 1 2 (P -AP) W = 0.<label>(60)</label></formula><p>Problem (60) has no explicit relation with the diffusion algorithm. To make such relation clear, we transform problem (60) into another form. From Lemma 2, we know that P -AP is symmetric and positive semi-definite. Therefore, we can decompose</p><formula xml:id="formula_75">P -AP 2 = U ΣU T ,<label>(61)</label></formula><p>where Σ ∈ R N ×N is a non-negative diagonal matrix and U ∈ R N ×N is an orthogonal matrix. If we introduce the symmetric square-root matrix</p><formula xml:id="formula_76">V ∆ = U Σ 1/2 U T ∈ R N ×N , (62) then it holds that P -AP 2 = V 2 . (<label>63</label></formula><formula xml:id="formula_77">) Let V ∆ = V ⊗ I M so that P -AP 2 = V 2 . (<label>64</label></formula><formula xml:id="formula_78">) Lemma 4 (NULLSPACE OF V ). With V defined as in (62), it holds that null(V ) = null(P -AP ) = span{1 N }.<label>(65)</label></formula><p>Proof: To prove null(V ) = null(P -AP ), it is enough to prove (P -AP )x = 0 ⇐⇒ V x = 0. (66) Indeed, notice that</p><formula xml:id="formula_79">(P -AP )x = 0 ⇒ V 2 x = 0 ⇒ x T V T V x = 0 ⇒ V x 2 = 0 ⇒ V x = 0.</formula><p>(67) The reverse direction "⇐" in (66) is obvious. Remark 3. (Nullspace of V) Similar to the arguments in <ref type="bibr" target="#b47">(48)</ref> and ( <ref type="formula" target="#formula_59">49</ref>), we have null(V) = null(P -AP) = span{1 N ⊗ I M }, (68) and, hence,</p><formula xml:id="formula_80">VX = 0 ⇐⇒ (P -AP)X = 0 ⇐⇒ x 1 = • • • = x N . (<label>69</label></formula><formula xml:id="formula_81">)</formula><p>With (69), problem (60) is equivalent to min</p><formula xml:id="formula_82">W∈R N M J (W), s.t. VW = 0.<label>(70)</label></formula><p>In this way, we have transformed the original problem (4) to the equivalent constrained problem (70).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Penalized Formulation</head><p>There are many techniques to solve constrained problems of the form (70). One useful and popular technique is to add a penalty term to the cost function and to consider instead a penalized problem of the form:</p><formula xml:id="formula_83">min W∈R N M J (W) + 1 α VW 2 , (<label>71</label></formula><formula xml:id="formula_84">)</formula><p>where α &gt; 0 is a penalty parameter. Problem (71) is not equivalent to (70) but is a useful approximation. The smaller the value of α is, the closer the solutions of problems ( <ref type="formula" target="#formula_82">70</ref>) and ( <ref type="formula" target="#formula_83">71</ref>) become to each other <ref type="bibr" target="#b54">[55]</ref>- <ref type="bibr" target="#b56">[57]</ref>. We now verify that the diffusion strategy ( <ref type="formula" target="#formula_6">5</ref>)-( <ref type="formula" target="#formula_7">6</ref>) follows from applying an incremental technique to solving the approximate penalized problem (71), not the real problem (70). It will then become clear that the diffusion estimate w k,i cannot converge to the exact solution w of problem (4) (or (70)). Since (64) holds, problem (71) is equivalent to</p><formula xml:id="formula_85">min w∈R N M J (W) + 1 2α W T (P -AP)W.<label>(72)</label></formula><p>This is an unconstrained problem, which we can solve using, for example, a diagonally-weighted incremental algorithm, namely,   </p><formula xml:id="formula_86">ψ i = W i-1 -αP -1 ∇J (W i-1 ), W i = ψ i -αP -1 1 α (P -AP)ψ i ,<label>(73)</label></formula><p>The above recursion can be simplified as follows. Assume we select α</p><formula xml:id="formula_87">∆ = β -1 , (<label>74</label></formula><p>) where β is the same constant used in relation <ref type="bibr" target="#b9">(10)</ref>. Recall from ( <ref type="formula" target="#formula_26">19</ref>), ( <ref type="formula" target="#formula_34">25</ref>), ( <ref type="formula" target="#formula_40">30</ref>) and ( <ref type="formula">31</ref>) that β = O(1/µ max ) and hence α = O(µ max ). Moreover, from the definition of J (W) in (59), we have</p><formula xml:id="formula_88">∇J (W) =    q 1 ∇J 1 (w 1 )</formula><p>. . .</p><formula xml:id="formula_89">q N ∇J N (w N )   <label>(75)</label></formula><p>Using <ref type="bibr" target="#b9">(10)</ref>, namely, q k = βµ k p k , (76) we find that</p><formula xml:id="formula_90">αP -1 ∇J (W i-1 ) =    µ 1 ∇J 1 (w 1,i-1 )</formula><p>. . .</p><formula xml:id="formula_91">µ N ∇J N (w K,i-1 )    . (<label>77</label></formula><formula xml:id="formula_92">)</formula><p>We further introduce the aggregate cost (which is similar to (59) but without the weighting coefficients):</p><formula xml:id="formula_93">J o (W) ∆ = N k=1 J k (w k ),<label>(78)</label></formula><p>and note that <ref type="formula" target="#formula_91">77</ref>) and ( <ref type="formula" target="#formula_94">79</ref>), the first recursion in (73) can be rewritten as</p><formula xml:id="formula_94">∇J o (W) =    ∇J 1 (w 1 ) . . . ∇J N (w N )    . (<label>79</label></formula><formula xml:id="formula_95">) Let M ∆ = diag{µ 1 , µ 2 , • • • , µ N } ⊗ I M . Using (</formula><formula xml:id="formula_96">ψ i = W i-1 -M∇J o (W i-1</formula><p>).</p><p>(80) For the second recursion of (73), it can be rewritten as</p><formula xml:id="formula_97">W i = A T ψ i (<label>81</label></formula><formula xml:id="formula_98">)</formula><p>because AP = PA T . Relations (80)-( <ref type="formula" target="#formula_97">81</ref>) are equivalent to ( <ref type="formula" target="#formula_6">5</ref>)-( <ref type="formula" target="#formula_7">6</ref>). Specifically, if we collect all iterates from across all agents into block vectors {W i , ψ i }, then ( <ref type="formula" target="#formula_6">5</ref>)-( <ref type="formula" target="#formula_7">6</ref>) would lead to (80)-( <ref type="formula" target="#formula_97">81</ref>). From this derivation, we conclude that the diffusion algorithm ( <ref type="formula" target="#formula_6">5</ref>)-( <ref type="formula" target="#formula_7">6</ref>) can be interpreted as performing the diagonally-weighted incremental construction (73) to solve the approximate penalized problem (72). Since this construction is not solving the real problem ( <ref type="formula" target="#formula_5">4</ref>), there exists a bias between its fixed point and the real solution w . As shown in <ref type="bibr" target="#b12">(13)</ref>, the size of this bias is related to µ max . When µ max is small, the bias is also small. This same conclusion can be seen by noting that a small µ max corresponds to a large penalty factor 1/α under which the solutions to problems ( <ref type="formula" target="#formula_5">4</ref>) and (70) approach each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DEVELOPMENT OF EXACT DIFFUSION</head><p>We now explain how to adjust the diffusion strategy ( <ref type="formula" target="#formula_6">5</ref>)-( <ref type="formula" target="#formula_7">6</ref>) to ensure exact convergence to w . Instead of solving the approximate penalized problem (72), we apply the primaldual saddle point method to solve the original problem (70) directly. We continue to assume that the combination policy A is primitive and satisfies the local balancing condition <ref type="bibr" target="#b13">(14)</ref>.</p><p>To solve (70) with saddle point algorithm, we first introduce the augmented Lagrangian function:</p><formula xml:id="formula_99">L a (W, Y) = J (W) + 1 α Y T VW + 1 2α VW 2 (64) = J (W)+ 1 α Y T VW+ 1 4α W T (P-PA T )W, (<label>82</label></formula><formula xml:id="formula_100">)</formula><p>where</p><formula xml:id="formula_101">Y = col{y 1 , • • • , y N } ∈ R N M is the dual variable. The standard primal-dual saddle point algorithm has recursions    W i = W i-1 -α∇ W L a (W i-1 , Y i-1 ), Y i = Y i-1 + α 1 α VW i = Y i-1 + VW i . (<label>83</label></formula><formula xml:id="formula_102">)</formula><p>The first recursion in (83) is the primal descent while the second recursion is the dual ascent. Now, instead of performing the descent step directly as shown in the first recursion in (83), we perform it in an incremental manner. Thus, let</p><formula xml:id="formula_103">D(W) ∆ = 1 4α W T (P-PA T )W, C(W, Y) ∆ = 1 α Y T VW, (84) so that L a (W, Y i-1 ) = J (W) + D(W) + C(W, Y i-1</formula><p>).</p><p>(85) The diagonally incremental recursion that corresponds to the first step in (83) is then:</p><formula xml:id="formula_104">         θ i = W i-1 -αP -1 ∇J (W i-1 ), φ i = θ i -αP -1 ∇D(θ i ) = I M N + A T 2 θ i = A T θ i , W i = φ i -αP -1 ∇ W C(φ i , Y i-1 ) = φ i -P -1 VY i-1 ,<label>(86)</label></formula><p>where in the second recursion of (86) we introduced</p><formula xml:id="formula_105">A ∆ = (I M N + A)/2. (<label>87</label></formula><formula xml:id="formula_106">)</formula><p>We know from ( <ref type="formula" target="#formula_65">54</ref>) that the eigenvalues of A are positive and lie within the interval (0, 1]. In (86), if we substitute the first and second recursions into the third one, and also recall (77) that αP -1 ∇J (W i-1 ) = M∇J o (W i-1 ), then we get</p><formula xml:id="formula_107">W i = A T W i-1 -M∇J o (W i-1 ) -P -1 VY i-1 . (<label>88</label></formula><formula xml:id="formula_108">)</formula><p>Replacing the first recursion in ( <ref type="formula" target="#formula_101">83</ref>) with ( <ref type="formula" target="#formula_107">88</ref>), the previous primal-dual saddle point recursion (83) becomes</p><formula xml:id="formula_109">   W i = A T W i-1 -M∇J o (W i-1 ) -P -1 VY i-1 Y i = Y i-1 + VW i (89)</formula><p>Recursion ( <ref type="formula">89</ref>) is the primal-dual form of the exact diffusion recursion we are seeking. For the initialization, we set y -1 = 0 and W -1 to be any value, and hence for i = 0 we have</p><formula xml:id="formula_110">   W 0 = A T W -1 -M∇J o (W -1 ) , Y 0 = VW 0 .<label>(90)</label></formula><p>We can rewrite (89) in a simpler form by eliminating the dual variable Y from the first recursion. For i = 1, 2, • • • , from (89) we have</p><formula xml:id="formula_111">W i -W i-1 = A T W i-1 -W i-2 -M ∇J o (W i-1 )-∇J o (W i-2 ) -P -1 V(Y i-1 -Y i-2 ).</formula><p>(91) From the second step in (89) we have</p><formula xml:id="formula_112">P -1 V(Y i-1 -Y i-2 ) = P -1 V 2 W i-1<label>(64)</label></formula><formula xml:id="formula_113">= P -1 P -PA T 2 W i-1 = I M N -A T 2 W i-1 .<label>(92)</label></formula><p>Substituting (92) into (91), we arrive at <ref type="formula">93</ref>) is the primal version of the exact diffusion.</p><formula xml:id="formula_114">W i =A T 2W i-1 -W i-2 -M ∇J o (W i-1 )-∇J o (W i-2 ) (93) Recursion (</formula><p>We can rewrite (93) in a distributed form that resembles (5)-( <ref type="formula" target="#formula_7">6</ref>) more closely, as listed below in Algorithm 1, where we denote the entries of A by a k . It is observed in Algorithm 1 that the exact diffusion strategy resembles ( <ref type="formula" target="#formula_6">5</ref>)-( <ref type="formula" target="#formula_7">6</ref>) to great extent, with the addition of a "correction" step between the adaptation and combination step. In the correction step, the intermediate estimate ψ k,i is "corrected" by removing from it the difference between w k,i-1 and ψ k,i-1 from the previous iteration. Moreover, it is also observed that the exact and standard diffusion strategies have essentially the same computational complexity, apart from 2M (M is the dimension of w k,i ) additional additions per agent in the correction step of the exact implementation. Also, there is one combination step in each iteration, which reduces the communication cost by </p><formula xml:id="formula_115">Set ψ k,-1 = w k,-1 . Setting: Let µ k = q k µo/p k . Repeat for i = 0, 1, 2, • • • ψ k,i = w k,i-1 -µ k ∇J k (w k,i-1 ),<label>(adaptation) (94)</label></formula><formula xml:id="formula_116">φ k,i = ψ k,i + w k,i-1 -ψ k,i-1 ,<label>(correction) (95)</label></formula><formula xml:id="formula_117">w k,i = ∈N k a k φ ,i . (combination)<label>(96)</label></formula><p>about one half in comparison to recent DIGing-based works <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b42">[43]</ref>.</p><p>One can directly run Algorithm 1 when the Perron entries {p k } are known beforehand, as explained in Section II-B. When this is not the case, we can blend iteration (36) into the algorithm and modify it as follows.</p><p>Algorithm 1' Exact diffusion strategy when p is unknown</p><formula xml:id="formula_118">Setting: Let A = (I N + A)/2, and w k,-1 arbitrary. Set ψ k,-1 = w k,-1 ,</formula><p>and z k,-1 = e k .</p><p>Repeat</p><formula xml:id="formula_119">for i = 0, 1, 2, • • • z k,i = ∈N k a k z ,i-1 , (power iteration) (97) ψ k,i = w k,i-1 - q k µo z k,i (k) ∇J k (w k,i-1 ),<label>(adaptation) (98)</label></formula><formula xml:id="formula_120">φ k,i = ψ k,i + w k,i-1 -ψ k,i-1 ,<label>(correction) (99)</label></formula><formula xml:id="formula_121">w k,i = ∈N k a k φ ,i .<label>(combination) (100)</label></formula><p>V. SIGNIFICANCE OF BALANCED POLICIES</p><p>The stability and convergence properties of the exact diffusion strategy (94)-(96) will be examined in detail in Part II <ref type="bibr" target="#b1">[2]</ref>. There we will show that exact diffusion is guaranteed to converge for all balanced left-stochastic matrices for sufficiently small step-sizes. The local balancing property turns out to be critical in the sense that convergence may or may not occur if we move beyond the set of balanced policies. We can illustrate these possibilities here by means of examples. The two examples discussed in the sequel highlight the importance of having balanced combination policies for exact convergence.</p><p>Thus, consider the primal recursion of the exact diffusion algorithm (93), where A is a general left-stochastic matrix. We subtract W from both sides of (93), to get the error recursion</p><formula xml:id="formula_122">i = A T 2 W i-1 -W i-2 +M ∇J o (W i-1 )-∇J o (W i-2 ) ,<label>(101) where</label></formula><formula xml:id="formula_123">W i = W -W i . When ∇J k (w) is twice-differentiable,</formula><p>we can appeal to the mean-value theorem from Lemma D.1 in <ref type="bibr" target="#b13">[14]</ref>, which allows us to express each difference</p><formula xml:id="formula_124">∇J k (w k,i-1 ) -∇J k (w ) = - 1 0 ∇ 2 J k w -r w k,i-1 dr w k,i-1 .<label>(102)</label></formula><p>If we let</p><formula xml:id="formula_125">H k,i-1 ∆ = 1 0 ∇ 2 J k w -r w k,i-1 dr ∈ R M ×M ,<label>(103)</label></formula><p>and introduce the block diagonal matrix:</p><formula xml:id="formula_126">H i-1 ∆ = diag{H 1,i-1 , H 2,i-1 , • • • , H N,i-1 }, (104) then we can rewrite ∇J o (W i-1 ) -∇J o (W ) = -H i-1 W i-1 . (105) Notice that ∇J o (W i-1 )-∇J o (W i-2 ) = ∇J o (W i-1 )-∇J o (W )+∇J o (W )-∇J o (W i-2 ) (105) = H i-2 W i-2 -H i-1 W i-1 .</formula><p>(106) Combining ( <ref type="formula" target="#formula_122">101</ref>), (106) and the fact W i-1 = W i-1 , we have</p><formula xml:id="formula_127">W i W i-1 = (F-G i-1 ) W i-1 W i-2 ,<label>(107)</label></formula><p>where</p><formula xml:id="formula_128">F ∆ = 2A T -A T I M N 0 ∈ R 2M N ×2M N ,<label>(108)</label></formula><formula xml:id="formula_129">G i-1 ∆ = A T MH i-1 -A T MH i-2 0 0 ∈ R 2M N ×2M N .<label>(109)</label></formula><p>In the next two examples, we consider the simple case where the dimension M = 1, q k = 1 for k ∈ {1, • • • , N }, and the step-size M = µP -1 , where</p><formula xml:id="formula_130">P = diag{p 1 , • • • , p N } ∈ R N ×N .<label>(110)</label></formula><p>In this situation, the matrix F -G i-1 reduces to</p><formula xml:id="formula_131">F-G i-1 = A T (2I N -µP -1 H i-1 ) -A T (I N -µP -1 H i-2 ) I N 0 .</formula><p>(111) Moreover, we also assume H i is iteration independent, i.e.,</p><formula xml:id="formula_132">H i = H, ∀ i = 1, 2, • • • (112)</formula><p>This assumption holds for quadratic costs J k (w). Under the above conditions, we have</p><formula xml:id="formula_133">(F -G i-1 ) 1 N 1 N = A T 1 N 1 N = 1 N 1 N ,<label>(113)</label></formula><p>which implies that λ 1 = 1 is one eigenvalue of F -G i-1 no matter what the step-size µ is. However, since W 0 is initialized as VY 0 and, hence, lies in range(V), the eigenvalue λ 1 = 1 will not influence the convergence of recursion (107) (the detailed explanation is spelled out in Sections II and III of Part II <ref type="bibr" target="#b1">[2]</ref>). Let {λ k } 2N k=2 denote the remaining eigenvalues of F -G i-1 , and introduce</p><formula xml:id="formula_134">ρ(F -G i-1 ) ∆ = max{|λ 2 |, |λ 3 |, • • • , |λ 2N |}.</formula><p>(114) It is ρ(F -G i-1 ) that determines the convergence of recursion (107): the exact diffusion recursion (107) will diverge if ρ(F -G i-1 ) &gt; 1, and will converge if ρ(F -G i-1 ) &lt; 1. It can be verified that A is primitive, left-stochastic but not balanced. For such A, its Perron eigenvector p can be calculated in advance, and hence P is also known. Also, H i-1 is assumed to satisfy P -1 H i-1 = diag{20, 1, 1, 1} ∈ R 4×4 (116) Substituting the above A and P H i-1 into F -G i-1 shown in (111), it can be verified that ρ(F -G i-1 ) &gt; 1 (117) for any step-size µ &gt; 0. The proof is given in Appendix A by appealing to the Jury test for stability. In the top plot in Fig. <ref type="figure" target="#fig_10">9</ref>, we show the spectral radius ρ(F -G i-1 ) for step-sizes µ ∈ [1e -6 , 3]. It is observed that ρ(F -G i-1 ) &gt; 1.</p><p>By following similar arguments, we can find a counter example such that EXTRA will also diverge for any step-size µ &gt; 0, even if we assume the Perron eigenvector p is known in advance. For example, if </p><formula xml:id="formula_135">A =       0.</formula><formula xml:id="formula_136">H i-1 = diag{20, 1, 1, 1, 1} ∈ R 5×5 ,<label>(119)</label></formula><p>one can verify that EXTRA will diverge for any µ &gt; 0 by following the arguments in Appendix A. As a result, the pushsum based algorithms <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref> that extend EXTRA to nonsymmetric networks cannot always converge. This example indicates that the stability range (c lower , c upper ) provided in <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref> may not always be feasible. </p><p>It can be verified that A is primitive and not balanced. Also, i-1 is assumed to satisfy P -1 H i-1 = diag{10, 10, 10, 10, 10} ∈ R 5×5 .</p><p>(121) Substituting the above A and P -1 H i-1 into (111), it can be verified that ρ(F) = 0.9923. Therefore, when µ is sufficiently small, F will dominate in F -G i-1 and ρ(F -G i-1 ) &lt; 1. The simulations in Fig. <ref type="figure" target="#fig_11">10</ref> confirm this fact. In particular, it is observed that ρ(F -G i-1 ) &lt; 1 when µ &lt; 0.2. As a result, the exact diffusion will converge when µ &lt; 0.2 under this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. NUMERICAL EXPERIMENTS</head><p>In this section we illustrate the performance of the proposed exact diffusion algorithm. In all figures, the y-axis indicates the relative error, i.e., W i -  </p><formula xml:id="formula_138">W o 2 / W 0 -W o 2 , where W i = col{w 1,i , • • • , w N,i } ∈ R N M and W o = col{w o , • • • , w o } ∈ R N M .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Distributed Least-squares</head><p>In this experiment, we focus on solving the least-squares problem over the network shown in 3:</p><formula xml:id="formula_139">w o = arg min w∈R M 1 2 N k=1 U k w -d k 2 . (<label>122</label></formula><formula xml:id="formula_140">)</formula><p>where the network size N = 20 and the dimension M = 30. Each entry in both U k ∈ R 50×30 and d k ∈ R 50 is generated from the standard Gaussian distribution N (0, 1). We compare the convergence behavior of standard diffusion and the exact diffusion algorithm in the simulation. The leftstochastic matrix A is generated through the averaging rule (see <ref type="bibr" target="#b20">(21)</ref>), and each agent k employs step-size µ k = µ o /n k (see <ref type="bibr" target="#b23">(24)</ref>) where µ o is a small constant step-size. The convergence of both algorithms is shown in Fig. <ref type="figure" target="#fig_7">4</ref>, where we set µ o = 0.01. It is observed that the standard diffusion algorithm converges to a neighborhood of w o on the order O(µ 2 o ), while the exact diffusion converges exponentially fast to the exact solution w o . This figure confirms that exact diffusion corrects the bias in standard diffusion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Distributed Logistic Regression</head><p>We next consider a pattern classification scenario. Each agent k holds local data samples {h k,j , γ k,j } L j=1 , where h k,j ∈ R M is a feature vector and γ k,j ∈ {-1, +1} is the corresponding label. Moreover, the value L is the number of local samples at each agent. All agents will cooperatively solve the regularized logistic regression problem over the network in Fig. <ref type="figure" target="#fig_6">3</ref>:</p><formula xml:id="formula_141">w o = arg min w∈R M N k=1 1 L L =1 ln 1+exp(-γ k, h T k, w) + ρ 2 w 2 .</formula><p>(123) In the experiments, we set N = 20, M = 30, and L = 50. For local data samples {h k,j , γ k,j } L j=1 at agent k, each h k,j is generated from the standard normal distribution N (0; 10I M ). To generate γ k,j , we first generate an auxiliary random vector w 0 ∈ R M with each entry following N (0, 1). Next, we generate γ k,j from a uniform distribution U(0, 1). If γ k,j ≤ 1/[1 + exp(-(h k,j ) T w 0 )] then γ k,j is set as +1; otherwise γ k,j is set as -1. We set ρ = 0.1.</p><p>We still compare the convergence behavior of the standard diffusion and exact diffusion. The left-stochastic matrix A is generated through the averaging rule, and each agent k employs step-size µ k = µ o /n k . The convergence of both algorithms is shown in Fig. <ref type="figure" target="#fig_8">5</ref>. The step-size µ o = 0.05. It is also observed that the exact diffusion corrects the bias in standard diffusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Benefits of balanced left-stochastic policies</head><p>In this subsection we illustrate one of the benefits of balanced left-stochastic combination matrices -they can speed up the convergence.</p><p>In the first experiment, we consider a network with a highly unbalanced topology as shown in Fig. <ref type="figure">6</ref>. Nodes 1 and 2 are "celebrities" with many neighbors, while the other 48 nodes just have two neighbors each. Such a network topology is quite common in social networks.</p><p>Interestingly, both the maximum degree rule and the Metropolis rule will generate the same doubly-stochastic combination matrix for this network. Let L be the Laplacian matrix associated with that network, then the generated doublystochastic combination matrix is A = I -L/49.</p><p>(124) This combination matrix A merges information just slightly better than the identity matrix I because the term L/49 is quite small, which is not efficient. In contrast, the normal agent k (where 3 ≤ k ≤ 50) will assign 1/3 to incoming information from agents 1 and 2 if the averaging rule is used, which combines information more efficiently and hence leads to faster convergence. In Fig. <ref type="figure" target="#fig_12">7</ref>, we compare exact diffusion and EXTRA methods over the distributed leastsquare problem (122). The experimental setting is the same as in Sec. VI-A except for the combination rules. Exact diffusion employs the left-stochastic matrix generated by the averaging rule while EXTRA employs a doubly-stochastic combination matrix (recall that EXTRA <ref type="bibr" target="#b37">[38]</ref> has convergence guarantees only for doubly-stochastic matrices). The stepsizes are carefully chosen such that each algorithm reaches its fastest convergence. As expected, it is observed that exact diffusion with the averaging rule is almost three times faster than EXTRA with doubly-stochastic combination matrices.</p><p>In the second experiment, we consider the distributed leastsquare problem (122) and assume the Lipschitz constants associated with each local cost function differs drastically. In this experiment, we set N = 20, and the network topology is the same as in Fig. <ref type="figure" target="#fig_6">3</ref>. Among all nodes, we assume for 4 random nodes that the local data U k and d k are generated from N (0, 100) while in the remaining nodes they are generated from N (0, 1). Under such setting, each local Lipschitz constant is quite different. We again compare the convergence between exact diffusion and EXTRA where the combination rule for exact diffusion is generated according to the Hastings rule (41) while EXTRA employs the Metropolis combination matrix, which is doubly stochastic. Fig. <ref type="figure">8</ref> depicts the convergence for each algorithm. Again, the step-sizes are carefully chosen such that each algorithm reaches its fastest convergence. As expected, it is observed that exact diffusion with Hastings rule is almost four times faster than EXTRA with the doubly-stochastic matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Exact Diffusion for General Left-Stochastic A</head><p>In this subsection we test exact diffusion for the general left-stochastic A shown in Section V. In Fig. <ref type="figure" target="#fig_10">9</ref> we test the setting of Example 1 in which A is in the form of (115) and H is (116). We introduce ρ = ρ(F -G i-1 ). In the top plot, we illustrate how ρ varies with step-size µ. In this plot, the step-size varies over [10 -6 , 3], and the interval between two consecutive µ is 10 -6 . It is observed that ρ &gt; 1 for any µ ∈ [10 -6 , 3], which confirms with our conclusion that exact diffusion will diverge for any step-size µ under the setting in Example 1. In the bottom plot of Fig. <ref type="figure" target="#fig_10">9</ref> we illustrate the standard diffusion converges to a neighborhood of w o on the order of O(µ 2 ) for µ = 0.01, while the exact diffusion diverges.  In Fig. <ref type="figure" target="#fig_11">10</ref> we test the setting of Example 2 in which A is in the form of (120) and H is of (121). In the top plot, we illustrate how ρ varies with µ. It is observed that ρ &lt; 1 when µ &lt; 0.2, which implies that the exact diffusion recursion (107) will converge when µ &lt; 0.2. In the bottom figure, with µ = 0.001 it is observed that exact diffusion will converge exactly to w o . Figures. 9 and 10 confirm that general leftstochastic A cannot always guarantee convergence to w o .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUDING REMARKS This work developed a diffusion optimization strategy with guaranteed exact convergence for a broad class of combination</head><p>The strategy is applicable to the locally-balanced left-stochastic combination matrices which are able to endow the algorithm with faster convergence rate, more flexible step-size choices and better privacy-preserving properties compared to doubly-stochastic combination matrices. Part II <ref type="bibr" target="#b1">[2]</ref> of this work establishes analytically, and by means of examples and simulations, the superior convergence and stability properties of exact diffusion implementations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A PROOF OF (117)</head><p>The characteristic polynomial of F -G i-1 is given by Q(λ) = (λ -1)D(λ), where D(λ) = (127) It is easy to observe from (125) that λ = 1 is one eigenvalue of F -G i-1 . As mentioned in (113) and its following paragraph, this eigenvalue λ = 1 does not influence the convergence of recursion (107) because of the initial conditions. It is the roots of D(λ) that decide the convergence of the exact diffusion recursion (107). Now we will prove that there always exists some root that stays outside the unit-circle no matter what the step-size µ is. In other words, D(λ) is not stable for any µ.</p><p>Since D(λ) is a 7-th order polynomial, its roots are not easy to calculate directly. Instead, we apply the Jury stability  <ref type="formula">134</ref>) and (136), we conclude that when 0 &lt; µ &lt; 0.1265, (137) conditions (1), ( <ref type="formula" target="#formula_1">2</ref>) and (3) will be satisfied simultaneously. Moreover, with the help of Matlab, we can also verify that the step-size range (137) will also meet conditions ( <ref type="formula" target="#formula_5">4</ref>  <ref type="formula">138</ref>) and (139), it is observed that the intersection of these three ranges is empty, which implies that there does not exist a value for µ that makes all conditions (1)-( <ref type="formula">8</ref>) hold. Therefore, we conclude that D(λ) is not stable for any step-size µ.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of the local balance condition (14).</figDesc><graphic coords="4,361.39,53.14,148.40,70.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the relations among the classes of symmetric doubly-stochastic, balanced left-stochastic, and left-stochastic combination matrices.</figDesc><graphic coords="5,333.53,471.24,204.12,99.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Corollary 1 (</head><label>1</label><figDesc>NULLSPACE OF P -AP ). Let P ∆ = P ⊗I M and A ∆ = A ⊗ I M . When A satisfies the local balance condition (14), it holds that null(P -AP) = null (P -AP ) ⊗ I M = span{1 N ⊗ I M }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1</head><label>1</label><figDesc>Exact diffusion strategy for agent kSetting: Let A = (I N + A)/2, and w k,-1 arbitrary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Example 1 (</head><label>1</label><figDesc>Diverging case). Consider the following leftstochastic matrix A:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Example 2 (</head><label>2</label><figDesc>Converging case). Consider the following leftstochastic matrix A:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Network topology used in the simulations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Convergence comparison between standard diffusion and exact diffusion for the distributed least-squares (122).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Convergence comparison between standard diffusion and exact diffusion for distributed logistic regression (123).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .Fig. 7 .Fig. 8 .</head><label>678</label><figDesc>Fig. 6. A highly unbalanced network topology.</figDesc><graphic coords="13,93.65,65.94,157.85,138.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Exact diffusion under the setting of Example 1 in Section V. Top: ρ &gt; 1 no matter what value µ is. Bottom: Convergence comparison between diffusion and exact diffusion when µ = 0.01.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Exact diffusion under the setting of Example 2 in Section V. Top: ρ &lt; 1 when µ &lt; 0.2. Bottom: Convergence comparison between standard diffusion and exact diffusion when µ = 0.001.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>7 k=0a</head><label>7</label><figDesc>k λ k (125) and a 7 = 32, a 6 = 384µ -128, a 5 = 682µ 2 -1512µ+248,a 4 = 429µ 3 -2458µ 2 + 2712µ -288, a 3 = 80µ 4 -1346µ 3 + 3672µ 2 -2692µ + 210,(126)a 2 = -240µ 4 + 1649µ 3 -2904µ 2 + 1593µ -98, a 1 = 240µ 4 -976µ 3 + 1260µ 2 -552µ + 28, a 0 = -80µ 4 + 244µ 3 -252µ 2 + 92µ -4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 11 .( 3 )</head><label>113</label><figDesc>Fig. 11. The Jury table for the 7-th order system.</figDesc><graphic coords="14,354.59,53.14,162.00,118.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>( 7 )( 8 )</head><label>78</label><figDesc>) |b 0 | &gt; |b 6 |, (5) |c 0 | &gt; |c 5 | and (6) |d 0 | &gt; |d 4 |. Now we check the last two conditions. |e 0 | &gt; |e 3 |. To guarantee this condition, the step-size µ is required to satisfy 0.0438 &lt; µ &lt; 0.1265. (138) |f 0 | &gt; |f 2 |. To guarantee this condition, the step-size µ is required to satisfy 0 &lt; µ &lt; 0.0412. (139) Comparing (137), (</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1053-587X (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TSP.2018.2875898, IEEE Transactions on Signal Processing</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROPERTIES OF STOCHASTIC MATRIX</head><p>For the reader's convenience, we restate one of the main results from Lemma F.4 from <ref type="bibr" target="#b13">[14]</ref> here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 5 (PROPERTIES OF STOCHASTIC MATRIX).</head><p>Let A be an N × N left or doubly-stochastic matrix. The spectral radius of A is equal to one, ρ(A) = 1. It follows that all eigenvalues of A lie inside the unit disc, i.e.,|λ(A)| ≤ 1. The matrix A may have multiple eigenvalues with magnitude equal to one.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Exact diffusion strategy for optimization by networked agents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUSIPCO, Kos island</title>
		<meeting>EUSIPCO, Kos island<address><addrLine>Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">Sep. 2017</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">pages</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exact dffusion for distributed optimization and learning -Part II: Convergence analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.05142</idno>
	</analytic>
	<monogr>
		<title level="m">Submitted for publication, Also available as</title>
		<imprint>
			<date type="published" when="2017-02">Feb. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Instrumenting the world with wireless sensor networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pottie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</title>
		<meeting>IEEE International Conference on Acoustics, Speech, and Signal essing (ICASSP)<address><addrLine>Salt Lake City, UT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2033" to="2036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Distributed parameter estimation for monitoring diffusion phenomena using physical models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krishnamachari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C J</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Sensor and Ad Hoc Communications and Networks (SECON)</title>
		<meeting>IEEE Conference on Sensor and Ad Hoc Communications and Networks (SECON)<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="460" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detection, classification, and tracking of targets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Sayeed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="17" to="29" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey on sensor networks</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Akyildiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sankarasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cayirci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="102" to="114" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Information consensus in multivehicle cooperative control</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Beard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Atkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Control Systems Magazine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="71" to="82" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multirobot active target tracking with combinations of relative observations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Roumeliotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="678" to="695" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Toward a smart grid: power delivery for the 21st century</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Wollenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Power and Energy Magazine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="34" to="41" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed demand management in smart grid with a congestion game</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ibars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Giupponi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Smart Grid Communications (SmartGridComm)</title>
		<meeting>IEEE International Conference on Smart Grid Communications (SmartGridComm)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="495" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cloud-based demand response for smart grid: Architecture and distributed algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thottan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Smart Grid Communications (SmartGridComm)</title>
		<meeting>IEEE International Conference on Smart Grid Communications (SmartGridComm)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="398" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Monitoring and optimization for power grids: A signal processing perspective</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kekatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gatsis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="107" to="128" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adaptive networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2014-04">April 2014</date>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="460" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptation, learning, and optimization over networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="311" to="801" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Diffusion adaptation strategies for distributed optimization and learning over networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4289" to="4305" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the learning behavior of adaptive networks-Part I: Transient analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3487" to="3517" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the learning behavior of adaptive networks-Part II: Performance analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3518" to="3548" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dual averaging for distributed optimization: convergence analysis and network scaling</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="592" to="606" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dictionary learning over distributed models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Towfic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1001" to="1016" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A sparsity promoting adaptive algorithm for distributed learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chouvardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slavakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kopsinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Theodoridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5412" to="5425" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed clustering and learning over networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3285" to="3300" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Diffusion LMS over multitask networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2733" to="2748" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distributed subgradient methods for multi-agent optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="61" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gossip algorithms for distributed signal processing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rabbat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Scaglione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1847" to="1864" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convergence rate analysis of distributed gossip (linear parameter) estimation: Fundamental limits and tradeoffs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="674" to="690" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distributed parameter estimation in sensor networks: Nonlinear observation models and imperfect communication</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3575" to="3605" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the convergence of decentralized gradient descent</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1835" to="1854" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Consensus filters for sensor networks and distributed sensor fusion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olfati-Saber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Shamma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Decision and Control (CDC)</title>
		<meeting>IEEE Conference on Decision and Control (CDC)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="6698" to="6703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast distributed average consensus algorithms based on advection-diffusion processes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sardellitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Giona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barbarossa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="826" to="842" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Running consensus in wireless sensor networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Braca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Matta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Information Fusion</title>
		<meeting>IEEE International Conference on Information Fusion<address><addrLine>Cologne, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distributed pareto optimization via diffusion strategies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="220" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Distributed sparse linear regression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mateos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bazerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5262" to="5276" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">D-ADMM: A communication-efficient distributed algorithm for separable optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Püschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2718" to="2723" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the linear convergence of the ADMM in decentralized consensus optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1750" to="1761" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">DLM: Decentralized linearized alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="4051" to="4064" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-agent distributed optimization via inexact consensus ADMM</title>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="482" to="497" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DQM: Decentralized quadratically approximated alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mokhtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="5158" to="5173" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">EXTRA: An exact first-order algorithm for decentralized consensus optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="944" to="966" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">NEXT: In-network nonconvex optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Lorenzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scutari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal and Information Processing over Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="120" to="136" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Achieving geometric convergence for distributed optimization over time-varying graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.03218</idno>
		<imprint>
			<date type="published" when="2016-07">Jul. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Harnessing smoothness to accelerate distributed optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Control of Network Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Augmented distributed gradient methods for multi-agent optimization under uncoordinated constant stepsizes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Soh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Decision and Control (CDC)</title>
		<meeting><address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2055" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Geometrically convergent distributed optimization with uncoordinated step-sizes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Uribe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05877</idno>
		<imprint>
			<date type="published" when="2016-09">Sep. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The Perron-Frobenius theorem: some of its applications</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Suel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="62" to="75" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning under Imperfections by Networked Agents</title>
		<imprint>
			<date type="published" when="2014-09">Sep. 2014</date>
		</imprint>
	</monogr>
	<note>UCLA</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Equilibrium distributions for an open migration process</title>
		<author>
			<persName><forename type="first">P</forename><surname>Whittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="page" from="567" to="571" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markov</forename><surname>Chains</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Monte carlo sampling methods using Markov chains and their applications</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Hastings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Diffusion strategies for distributed Kalman filtering and smoothing</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Cattivelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on automatic control</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2069" to="2084" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distributed optimization over time-varying directed graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="601" to="615" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Needell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1017" to="1025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Stochastic optimization with importance sampling for regularized loss minimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">ExtraPush for convex smooth decentralized optimization over directed networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02942</idno>
		<imprint>
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">On the linear convergence of distributed optimization over directed graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.02149</idno>
		<imprint>
			<date type="published" when="2015-10">Oct. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex Optimization</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<title level="m">Practical Methods of Optimization</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Adaptive penalty-based distributed stochastic convex optimization</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Towfic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Sayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="3924" to="3938" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A simplified stability criterion for linear discrete systems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Jury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IRE</title>
		<meeting>the IRE</meeting>
		<imprint>
			<date type="published" when="1962">1962</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1493" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
