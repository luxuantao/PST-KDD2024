<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Global Context Enhanced Social Recommendation with Hierarchical Graph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Huance</forename><surname>Xu</surname></persName>
							<email>cshuance.xu@mail.scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">South China University of Technology</orgName>
								<orgName type="institution" key="instit2">§ JD Finance America Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
							<email>chaohuang75@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">South China University of Technology</orgName>
								<orgName type="institution" key="instit2">§ JD Finance America Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lianghao</forename><surname>Xia</surname></persName>
							<email>cslianghao.xia@mail.scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">South China University of Technology</orgName>
								<orgName type="institution" key="instit2">§ JD Finance America Corporation</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Xing</surname></persName>
							<email>hao.xing@vipshop.com</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">VIPS Research</orgName>
								<orgName type="institution" key="instit2">Baidu inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
							<email>yindawei@acm.org</email>
						</author>
						<title level="a" type="main">Global Context Enhanced Social Recommendation with Hierarchical Graph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social recommendation which aims to leverage social connections among users to enhance the recommendation performance. With the revival of deep learning techniques, many efforts have been devoted to developing various neural networkbased social recommender systems, such as attention mechanisms and graph-based message passing frameworks. However, two important challenges have not been well addressed yet: (i) Most of existing social recommendation models fail to fully explore the multi-type user-item interactive behavior as well as the underlying cross-relational inter-dependencies. (ii) While the learned social state vector is able to model pair-wise user dependencies, it still has limited representation capacity in capturing the global social context across users. To tackle these limitations, we propose a new Social Recommendation framework with Hierarchical Graph Neural Networks (SR-HGNN). In particular, we first design a relation-aware reconstructed graph neural network to inject the cross-type collaborative semantics into the recommendation framework. In addition, we further augment SR-HGNN with a social relation encoder based on the mutual information learning paradigm between low-level user embeddings and high-level global representation, which endows SR-HGNN with the capability of capturing the global social contextual signals. Empirical results on three public benchmarks demonstrate that SR-HGNN significantly outperforms state-ofthe-art recommendation methods. Source codes are available at: https://github.com/xhcdream/SR-HGNN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Recommender systems have play an important role in meeting user's personalized interests and alleviating the information overload for various applications, ranging from e-commence platforms <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b21">[22]</ref>, content provider <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b33">[34]</ref> to online review systems <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b36">[37]</ref>. With the prevalence of social networks in real-life online applications <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b23">[24]</ref>, a key line of research work seeks to boost the recommendation performance via exploiting the users' social relationships (e.g., online friends) <ref type="bibr" target="#b16">[17]</ref>. In social recommender systems, users' social ties serve as the important side information to provide connectivity information and semantic relatedness between users, and thus are utilized to enhance transitional recommendation models in yielding better results <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b44">[45]</ref>.</p><p>The core challenge of exploring social information in recommender systems is: how to incorporate user-user relationships into the collaborative filtering scenario with interactive pattern learning between users and items <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b34">[35]</ref>. Conventional social-aware recommendation methods have made *Corresponding author: Yong Xu.</p><p>significant process to regularize the matrix factorization framework with social information of users <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b38">[39]</ref>. Recently, the immense success of deep learning techniques has witnessed some research work on the exploration of neural network structures to enhance recommender systems with social signals. Specifically, there are several attempts which adopt attentive memory network for attending to certain parts when performing relation encoding among users <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. For example, Chen et al. <ref type="bibr" target="#b2">[3]</ref> introduced a transfer neural network to model the interplay between the social and item interaction domain. Additionally, the social influence among users have been approximated with a neural diffusion scheme through the layer-wise propagation of user embeddings <ref type="bibr" target="#b34">[35]</ref>. In view of recent advancements of graph neural networks, a handful of graph-based message passing structures have been developed to aggregate relation structural information over the constructed graph with users and items <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b42">[43]</ref>.</p><p>Despite the effectiveness of the above solutions, two important challenges have not been well addressed yet. First, practical recommendation scenarios may involve different types of user-item interactive behaviors, such as users' different ratings over items in online review systems, or different activities of customers (e.g., browse, purchase) in e-commerce sites <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b37">[38]</ref>. However, most of existing social recommender systems either ignore the multi-type nature of user-item interactions, or assume that different types of relation edges between users and items share the same representation space (e.g., learning with categorical one-hot encoding <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> or continuous valuebased linear transformation <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b32">[33]</ref>). Such relation heterogeneity could provide auxiliary behavior semantics that can hardly be comprehensively captured by current social-aware recommendation models. While intuitively useful to integrate multi-type user-item interactions into the learning of user preference, it is non-trivial to deal with it well. In particular, the complex dependencies across different interactions, making it difficult to distill the desired relation-aware collaborative signals with the joint incorporation of high-order connectivity from both user and item dimensions.</p><p>Second, the current designed embedding functions of users' social information, lack an effective encoding of high-order relational structures, which is latent in user-user relations to reveal the social similarity across users <ref type="bibr" target="#b39">[40]</ref>. To be more specific, most of current methods fuse cross-user relations from direct neighbourhood <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> and can hardly capture the high-order social influence between users. While GraphRec <ref type="bibr" target="#b5">[6]</ref> proposes to design graph structure-based neural network to aggregate relations between connected users, it only embeds the social signals into latent representation space with local proximity, due to the heavy computational cost in performing higherorder message passing over the social graph of users <ref type="bibr" target="#b0">[1]</ref>. Hence, how to jointly capture the local and global contextual signals of users' relationships in the recommendation framework remains a significant challenge.</p><p>Present Work. In light of aforementioned challenges, we propose a new Social Recommendation model with Hierarchical Graph Neural Network (SR-HGNN). In the two-phase recommendation framework, we propose to handle user-item interaction heterogeneity through a relation-aware reconstructed graph neural module. This graph neural network architecture automatically extracts the multi-relation collaborative signals from user-item interactions. We further supercharge the relation-aware graph learning framework with the global information to reconstruct the cross-domain (user-user and user-item) relations, during the embedding process of the graph neural network as constraints.</p><p>Additionally, SR-HGNN captures users' social relations by advancing the graph-based neural relation encoder, to jointly capture local and global relational structures between users. The global context enhanced social encoder not only learns the low-level patch embeddings of users from their social neighbors, but also derives the high-level contextual signals of the social graph to augment the user representation process under a global graph-structured mutual information maximization architecture. Our SR-HGNN generalizes the paradigm of mutual information estimation <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b27">[28]</ref> from feature vector space to the social graph-based user relation modeling, which injects hierarchical social similarities into relation learning via discriminating corrupted social structures.</p><p>The contributions of this paper are highlighted as follows:</p><p>• We highlight the critical importance of preserving both global structure of social dependencies and multi-typed interactive patterns between users and items in social recommendation task. Towards this goal, we propose SR-HGNN, a new social recommender system with hierarchically structured graph neural networks.</p><p>• In SR-HGNN framework, we propose a relation-aware reconstructed graph neural module to i) encode the collaborative signal in the form of multi-type user-item relations, and ii) inject the social-aware multi-relational information into the embedding process via reconstructing the global connectivities between users and items.</p><p>• To fully explore the global structural contexts of social connections, we further propose to capture the users' dependencies with graph-level mutual information maximization. This designed social relation encoder uniforms feature representation spaces from both low-level (locally) to highlevel (globally) social contextual signals.</p><p>• Experimental results on three real-world datasets show the superiority of our SR-HGNN framework over various baselines in yeilding better reccommendation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PRELIMINARIES AND PROBLEM DEFINITION</head><p>We begin with some necessary notations and then formally present the our studied social recommendation problem. We consider a recommendation scenario where a group of M users U = {u 1 , ..., u m , ..., u M } and a set of N items V = {v 1 , ..., v n , ..., v N }. We further define relevant inputs as below: Definition 1: User Social Graph G s . We define the user social graph G s = {U, E s } to represent the users' social relationships, where U (u m ∈ U ) and E s denotes the set of user nodes and edges between them. In specific, if two users u m and u m are socially connected, there exists an edge between u m and u m in the constructed user social graph G s .</p><p>Definition 2: Multi-Type Interaction Graph G r . With the consideration of different interactions between users and items, a multi-typed interaction graph is defined as G r = {U, V, E r }, where V represents the set of item nodes. Furthermore, E r denotes multiple types of interactive relations (e.g., different ratings or activities) between user u m and item v n .</p><p>Problem Statement. Based on the aforementioned definitions, the studied social recommendation problem is formally defined as follows: Input: the user-user social relation data represented with user social graph G s and the user-item interaction data exhibited with the multi-type interaction graph G r . Output: A predictive function which aims to estimate the unknown multi-typed user-item interactive relations in graph G r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODOLOGY</head><p>In this section, we elaborate the technical details of our developed SR-HGNN framework. We first describe our relationaware reconstructed graph neural network to capture the multityped user-item interactions. Then, we present the designed social dependency encoding framework which contextualizes the relation-aware collaborative signal modeling architecture with the global social context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multi-Typed User-Item Interactive Relation Learning</head><p>To learn the multi-interactive collaborative signals, we develop a relation-aware message-passing architecture (as shown in Figure <ref type="figure" target="#fig_0">1</ref>) between users and items with the differentiation of different user-item interactive relations. In particular, we first decompose the item vertex of multi-type interaction graph G r into multiple sub-nodes: v n → (v n,1 , ..., v n,K ), where K is the number of interaction types. Each sub-node v n,k is connected to the corresponding user u m with the k-th type of user-item relation. By doing so, the multi-typed relations between user and item are reflected on the updated graph G r = {U, V , E r } with the total number of (M + N × K) vertices. 1) Embedding Propagation Module: To encode collaborative similarity across users and items, we design a messagepassing graph neural network to leverage the multi-relation user-item interaction graph G r for embedding propagation. In general, the message passing architecture consists of two key components: message construction and message aggregation.</p><p>Message Construction Phase. We define our message passing from user u m ∈ U to his interacted relation-specific item v n,k ∈ V as follows:</p><formula xml:id="formula_0">m um←v n,k = f (x v n,k , λ k m,n )<label>(1)</label></formula><p>where f (•) is the message encoding function. x v n,k is the input feature representation corresponds to n-th item node interacted with u m given the k-th interaction type. λ k m,n denotes the decay factor for the propagation between u m and v n,k . In our SR-HGNN, we define encoding function f (•) as below:</p><formula xml:id="formula_1">m um←v n,k = 1 |J m ||J n,k | (x v n,k • W 1 )<label>(2)</label></formula><p>where J m represents the set of item sub-nodes interacted with user u m , and J n,k denotes the set of users that are connected with v n,k . .</p><formula xml:id="formula_2">W 1 ∈ R dv n,</formula><p>Similarly, we define the message encoding function from user u m to item sub-node v n,k as follows:</p><formula xml:id="formula_3">m v n,k ←um = 1 |J m ||J n,k | (x um • W 2 ⊕ H * • W 3 )<label>(3)</label></formula><p>H * ∈ R M ×d H denotes the social-aware user representations which are learned from our designed social dependency encoding framework (as elaborated in Section III-B).</p><formula xml:id="formula_4">W 2 ∈ R du m × d 2 and W 3 ∈ R d H × d 2 are trainable transformation matrices.</formula><p>Message Aggregation Phase. After obtaining the information from interacted users/items, we define our message aggregation function as follows:</p><formula xml:id="formula_5">E um = δ m um←um + (n,k)∈Jm m um←v n,k E v n,k = δ m v n,k ←v n,k + um∈J n,k m v n,k ←um<label>(4)</label></formula><p>δ(•) is defined as the PReLU activation function. m um←um and m v n,k ←v n,k respectively represents the self-propagated information for u m and v n,k with the formal definitions:</p><formula xml:id="formula_6">m um←um = 1 |J m | (x um • W 2 ⊕ H * • W 3 ) m v n,k ←v n,k = 1 |J n,k | (x v n,k • W 1 )<label>(5)</label></formula><p>Based on the aforementioned message passing and aggregation functions, we will present how to incorporate highorder relationships across users and items, into our multi-typed interactive relation learning framework. We formally define our high-order propagation process as:</p><formula xml:id="formula_7">m (l) um←v n,k = λ k m,n (E (l−1) v n,k W (l) 1 ) m (l) um←um = 1 |J m | (E (l−1) um W (l)</formula><p>2 )</p><formula xml:id="formula_8">m (l) v n,k ←um = λ k m,n (E (l−1) um W (l)</formula><p>2 )</p><formula xml:id="formula_9">m (l) v n,k ←v n,k = 1 |J n,k | (E (l−1) v n,k W (l) 1 )</formula><p>l is the index of graph neural network layers L. The propagation can be rewrote with the matrix form based on the (l−1)-th order node representation E (l−1) and weight matrix W (l) from the l-th layer as follows:</p><formula xml:id="formula_10">E (l−1) W (l) ∈ R (M +N K)×d = E (l−1) um • W (l) 2 E (l−1) v n,k • W (l) 1<label>(6)</label></formula><p>We generate the final embeddings of user u m and item subnode v n,k with the following concatenate operation:</p><formula xml:id="formula_11">E um = (E (1) um ⊕ E (2) um ⊕ • • • ⊕ E (L) um ) E v n,k = (E (1) v n,k ⊕ E (2) v n,k ⊕ • • • ⊕ E (L) v n,k )<label>(7)</label></formula><p>the overall item representation E vn is aggregated over the set of {E vn,1 , ..., E v n,K } with the mean pooling operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Reconstruction-based Context Incorporation:</head><p>To inject the social-aware cross-relational signals into our multityped user-item interaction encoding architecture, we augment our graph-based message passing module with the exploration of both global social (user-user) and multi-interactive (useritem) contexts. In specific, we incorporate the cross-domain reconstruction constrains (i.e., adjacent matrices interacts with item v n with the k-th behavior relation, we will sample the corresponding negative samples v n,k − from other non-interacted (K − 1) relations. For the reconstruction of user-user social relations A s , the negative instance u m − is sampled from his non-connected users. Formally, we present the reconstruction-based context incorporation as follows:</p><formula xml:id="formula_12">A s ∈ R M ×M of graph G s and A r ∈ R M ×KN of graph G r ) into</formula><formula xml:id="formula_13">s Ar m,n,k = δ((E um ⊕ E v n,k )V 1 + b r )W 4 L r = − 1 ψ(A r ) (m,n,k + )∈Or log σ(s Ar m,n,k + − s Ar m,n,k − ) s As m,m = δ((E um ⊕ E u m )V 2 + b s )W 5 L s = − 1 ψ(A s ) (m,m + )∈Os log σ(s As m,m + − s As m,m − ) (8)</formula><p>where V 1 , V 2 , W 4 and W 5 are learnable weight matrices. b r , b s are bias terms. ψ(A r ), ψ(A s ) indicates the number of non-zero elements in A r and A s , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Global Context Enhanced Social Dependency Modeling</head><p>To jointly capture the local and global social dependencies, we further develop a mutual information-based graph learning module to distill the hierarchical social similarity in the user embedding space. We build our social relation encoding module upon a dual-stage graph learning architecture (as shown in model architecture Figure <ref type="figure" target="#fig_1">2</ref>).</p><p>We first design our graph-structured message propagation layer, to generate node-level latent representation h um ∈ R d of each individual user u m , where d indicates the hidden state dimensionality. We define the local information encoding function over the user social graph G s as follows:</p><formula xml:id="formula_14">H = δ(A s , HW l s ) = δ( D− 1 2 s Âs D− 1 2 s HW s )<label>(9)</label></formula><p>where δ(•) denotes the non-linear activation function Parametric ReLU <ref type="bibr" target="#b8">[9]</ref> and H ∈ R M ×d corresponds to the encoded representations of all users. To inject the self-propagated signals, the identity matrix I s is added into the adjacent matrix A s (constructed from graph G s ) to generate Âs , Âs = A s +I s .</p><p>A symmetric normalization strategy is applied in performing the neighboring information aggregation with the operation of</p><formula xml:id="formula_15">D− 1 2 s Âs D− 1 2</formula><p>s , where Ds represents the diagonal node degree matrix of Âs .</p><p>After learning the node-level user embeddings H ∈ R M ×d encoded from social structured graph, our next step is to obtain the graph-level representation over the social graph G s . We first define graph-level aggregation function η: R M ×d → R d with the consideration of node degrees as follows: Inspired by the paradigm of mutual information maximization in feature representation <ref type="bibr" target="#b27">[28]</ref>, we enhance our social relation embeddings with the exploration of mutual information between node-level user embedding H and graphlevel representation r s . To encode the mutual relations in social graph G s and follow this paradigm, we propose to train a discriminator to differentiate positive samples and negative samples from social graph G s with the preservation of connected topological structure. Specifically, positive samples are denoted as (h um , r s ), and negative instances ( h um , r s ) are generated following the node shuffling strategy to associate each user with fake feature vectors H 0 with one-hot encoding. Then, we feed the generated positive (h um , r s ) and negative instances ( h um , r s ) into our defined discriminator function φ(•):</p><formula xml:id="formula_16">r s = σ M m=1 H m • b m,m M m=1 M m =1 a m,m<label>(</label></formula><formula xml:id="formula_17">R d × R d → R. φ(h um , r s ) = σ(h T um • W 6 • r s )<label>(11)</label></formula><p>where discriminator function φ(•) aims to generate a probability score of user u m belongs to graph G s given the corresponding representations (h um , r s ). W 6 ∈ R d×d is the learnable transformation matrix. We further define our mutual information-based loss as follows:</p><formula xml:id="formula_18">L mu = − 1 N pos + N neg Npos i=1 ρ(h um , r s ) • logφ(h um , r s ) + Nneg i=1 ρ( h um , r s ) • log[1 − φ( h um , r s )]<label>(12)</label></formula><p>where N pos and N neg denotes the number of positive and negative samples, respectively. ρ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Learning Process of SR-HGNN</head><p>In the prediction layer, we incorporate the learned latent representations of user and item (E um , E vn ) into Multilayer Perceptron module, which is formally represented as follows:</p><formula xml:id="formula_19">E * um,vn = E um ⊕ E vn rm,n = ReLU (V 3 • E * um,vn + b 1 ) • V 4 + b 2<label>(13)</label></formula><p>where V 3 ∈ R 2d×d , V 4 ∈ R d×1 are learned transformation matrices, and b 1 , b 2 are bias terms. We define the loss in our prediction layer as:</p><formula xml:id="formula_20">L p = 1 2 M m=1 N n=1 I m,n (r m,n − rm,n ) 2<label>(14)</label></formula><p>where I m,n is the indicator function, i.e., I m,n = 1 if user u m is interacted with item v n and I m,n = 0 otherwise. rm,n represents the explicit feedback between u m and v n corresponding to the different types of user-item relations. After incorporating the reconstruction factors stated in Section III-A2, we define our joint loss function as below: </p><formula xml:id="formula_21">L = L p + ω 1 L r + ω 2 L s + ω r Θ 2 F<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EVALUATION</head><p>To evaluate our SR-HGNN, we perform extensive experiments with three real-world recommendation datasets. Particularly, we aim to answer the following research questions:</p><p>• RQ1: How is the performance of SR-HGNN when competing with various state-of-the-art recommendation methods?</p><p>• RQ2: What kind of benefit the developed key components in SR-HGNN (e.g., mutual information-based social relation encoder and relation-aware reconstructed graph neural module) can bring for social recommendation?</p><p>• RQ3: How does SR-HGNN perform w.r.t different interaction sparsity levels as compared to competitive methods?</p><p>• RQ4: How do different hyperparameter settings affect the recommendation performance of our SR-HGNN model?</p><p>• RQ5: How is the model scalability of SR-HGNN?</p><p>A. Experimental Settings 1) Data Description: We conduct performance validation with three real-world datasets: Epinions, Ciao and Douban. Table <ref type="table">I</ref> summarizes the statistics of these three datasets. Epinions and Ciao. Epinions and Ciao data is collected from the popular social networking-based consumer review site Epinions <ref type="bibr" target="#b5">[6]</ref> and Ciao <ref type="bibr" target="#b6">[7]</ref>, respectively. In these sites, users can establish social ties (who-trust-whom) with others, and interact with different items based on different rating scores (ranging from 1 to 5 and 1 as increment). We regard each rating score as an individual type of user-item interaction.</p><p>Douban. This data is collected from the most popular Chinese online review platform: Douban. It is also a social networking platform which allows users to create connection with others based on their common interest. The rating interactions share the same score scales with Epinions and Ciao data.  <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Following the same settings in <ref type="bibr" target="#b5">[6]</ref>, we set the data percentage for training, validation and test set with x%, (1 − x%)/2, (1 − x%)/2, respectively, where validation set is used for hyperparameter tuning. In our experiments, we set x% as (60%, 80%) to investigate the model performance with different input data ratio of user-item interactions.</p><p>3) Methods for Comparison: We compare the SR-HGNN with state-of-the-art methods from different research lines: Probabilistic Matrix Factorization Method. We first consider the representative matrix factorization-based method.</p><p>• PMF <ref type="bibr" target="#b20">[21]</ref>: it is a matrix factorization based probabilistic model which learns latent user/item feature vectors given their zero-mean spherical Gaussian priors. Conventional Social Recommendation Techniques. We include several conventional social recommendation approaches which unify the user-item interaction and social relationships.</p><p>• SocialMF <ref type="bibr" target="#b13">[14]</ref>: this method incorporates the trust propagation in the matrix factorization architecture, to capture the social phenomenon in the recommendation scenario.</p><p>• SoRec <ref type="bibr" target="#b18">[19]</ref>: it integrates the social network between users and the user-item interaction matrix in the recommendation process, based on probabilistic matrix factorization.</p><p>• SoReg <ref type="bibr" target="#b19">[20]</ref>: it uses the user relations as the social regularization terms to constrain the matrix factorization objective.</p><p>• TrustMF <ref type="bibr" target="#b38">[39]</ref>: this approach fuses users' interactive behavior and trust relationships to conduct recommendations, by utilizing the matrix factorization to learn user embeddings in terms of their trust relationships. Graph Neural Network Collaborative Filtering Models. We further compare SR-HGNN with two state-of-the-art recommendation models which augment the collaborative filtering architecture with graph-based neural techniques.</p><p>• STAR-GCN <ref type="bibr" target="#b45">[46]</ref>: it introduces a stack of graph convolutional encoder-decoder to learn latent factors between users and items, with the reconstruction of masked embeddings.</p><p>• NGCF+SN <ref type="bibr" target="#b29">[30]</ref>: NGCF is a state-of-the-art graph neural network-augmented collaborative filtering model under a message passing architecture. In order to incorporate the social network information into NGCF, we perform the embedding propagation on the integrative user-item and user-user relation graph, with the utilization of graph convolutional network to capture the high-order connectivity. Attentive Social Recommender Systems. We further compare SR-HGNN with another line of social recommendation models which utilizes attention mechanism to encode the latent relationships between users and items.</p><p>• SAMN <ref type="bibr" target="#b1">[2]</ref>: it proposes a two-phase attention framework to capture relationships between users and identify the underlying informative signals from user's neighbors.</p><p>• EATNN <ref type="bibr" target="#b2">[3]</ref>: this approach is built upon an attention-based transfer neural network to adaptively learn the interplay relationships between the social and item domain. Social Recommendation with Graph Neural Networks. Finally, we compare SR-HGNN with graph neural networkbased social-aware recommendation framework.</p><p>• GraphRec <ref type="bibr" target="#b5">[6]</ref>: it proposes a graph neural network model for social recommendation by aggregating social relations based on attention mechanism. • DiffNet <ref type="bibr" target="#b34">[35]</ref>: this recommendation method designs a layerwise influence diffusion module to capture the influence propagation patterns between users in a recursive manner. 4) Parameter Settings: We implement our SR-HGNN with Pytorch and utilize Adam as the optimizer for model parameter inference. The hidden state dimensionality d r of our relation-aware graph neural module is tuned from the range of <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr">64,</ref><ref type="bibr">128]</ref>. To achieve the trade-off between the social regularized representation and multi-relation encoding process <ref type="bibr" target="#b10">[11]</ref>, the embedding size d H in the mutual information-based social relation encoder is searched from the range of <ref type="bibr">[250,</ref><ref type="bibr">500,</ref><ref type="bibr">100,</ref><ref type="bibr">1500,</ref><ref type="bibr">2000]</ref>. The batch size is chosen from [1024, 2048, 4096, 8192] and the model optimization is performed with the learning rate of 1e −3 . In our experiments, the early stopping is adopted to terminate the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Comparison (RQ1)</head><p>In table II, we present the performance of all compared methods on three datasets, in terms of RMSE and MAE. In all cases, we can observe that SR-HGNN consistently outperforms different types of baselines by a significant margin. We attribute such improvement to the joint modeling of global social dependencies between users and multi-typed relations with respect to different user-item interactions. The performance is followed by GraphRec which models user-item relationships based on graph neural network. This verifies the utility of performing propagation information across users and items under a graph-structured learning framework. However, GraphRec fails to capture global social context when modeling social dependency-aware user's preference.</p><p>Among various baselines, we can observe that: by incorporating the social signals into the state-of-the-art neural graph collaborative filtering architecture (i.e., NGCF+SN), under a message passing framework with the relation heterogeneity  and high-order connectivity over user-item graph, it could achieve competitive performance as compared to some deep social recommeder systems (e.g., SAMN and EATNN). This observation therefore points to the positive effect of modeling user-user and user-item graph-structured collaborative relations in the embedding function. The performance gap between attentive recommendation methods and graph neural network enhanced models also sheds light on the limitation of aggregating cross-domain dependencies with a weighted summation scheme. The potential reason lies in the failure to consider the high-level insights due to the hierarchical interdependencies across users and items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Model Ablation and Effectiveness Analyses (RQ2)</head><p>To investigate the component-wise effect in our joint learning SR-HGNN framework, we consider different model variant settings from three perspectives and analyze their effects:</p><p>1) Global Social Relation Encoder: To evaluate the effectiveness of our mutual information-based graph neural module in capturing global social dependencies, we first replace our social relation encoder with two representative graph neural network architectures: graph convolutional network <ref type="bibr" target="#b26">[27]</ref> SR-HGNN gcn and graph attention network <ref type="bibr" target="#b31">[32]</ref> SR-HGNN gat . The results are presented in Figure <ref type="figure" target="#fig_4">3</ref>. It is clear to see that: while GCN and GAT have obtained promising results in fusing feature information between dependent users, our SR-HGNN could further boost the model accuracy through maximizing the mutual information between local and global representations of user dependence.</p><p>2) Reconstruction-based Context Incorporation: We further validate the impact of incorporating the reconstruction constrains (i.e., social-aware multi-relational information: reconstruction constrains L r and L s ) into our embedding learning process of users and items. Particularly, we generate the variant SR-HGNN w/o−rec without the context reconstruction component. The results in Table <ref type="table" target="#tab_4">III</ref> show the benefit of the designed reconstructed graph neural module which endows SR-HGNN with the capability of characterizing overall crossdomain relational knowledge. 3) Multi-Typed Interactive Relation Learning: Finally, we evaluate the influence of two key factors: i) multi-typed user-item interactions; and ii) social information among users.</p><p>Accordingly, we generate four variants corresponding to these two dimensions: single-type interaction modeling with or without social information-SR-HGNN s+s , SR-HGNN s−s ; multitype interaction modeling with or without social information-SR-HGNN m+s , SR-HGNN m−s . From evaluation results in Figure <ref type="figure" target="#fig_5">4</ref>, we summarize two key observations:</p><p>• We can first notice that the positive effect of social information in improving the recommendation performance. • The integration of multi-typed user-item relational structures with the recommendation framework could augment the learning process of complex user's preference.</p><p>D. Performance w.r.t Interaction Sparsity Levels (RQ3)</p><p>We perform experiments to investigate the representation ability of our SR-HGNN in handling inactive users that interact with a limited number of items. As shown in Figure <ref type="figure" target="#fig_6">5</ref>, the recommendation performance is evaluated with respect to different interaction data sparsity levels. Specifically, we split target user instances into three groups with the increasing sparsity level, and keeping the number of interactions within each group to be equal. From the comparison results with several representative baselines, we can observe that SR-HGNN consistently outperforms competitive methods with different data sparsity levels. Moreover, larger performance gain can also be achieved by SR-HGNN in forecasting preference of sparse users on Douban dataset. These observations demonstrate that SR-HGNN is capable of effectively modeling relations from social and behavioral context modalities, to alleviate the data scarcity issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Hyperparameter Study (RQ4)</head><p>We investigate the influence of hyperparameters in our SR-HGNN framework. To integrate results on different datasets with different performance scales into the same figure, we set y-axis as the performance variation ratio compared to the best performance. Figure <ref type="figure">6</ref> shows the evaluation results. We summarize the key observations as follows:</p><p>Effect of dimensionality. We separately evaluate the effects of d and d H , which corresponds to the hidden state dimensionality of our relation-aware reconstructed graph neural module and global social relation encoder. With the consideration of different dimension scales and concatenate operations, d and d H is tuned with different embedding size ranges. We can observe that a larger value of hidden state dimensionality does not necessarily lead to better performance, due to the overfitting issue. We set d and d H as <ref type="bibr" target="#b15">(16,</ref><ref type="bibr">64,</ref><ref type="bibr">128)</ref> and (1000, 500, 1500) corresponding to Ciao, Epinions, Douban data, to achieve the best performance.</p><p>Effect of graph neural network depth. Increasing the depth L of our relation-aware reconstructed graph neural module could improve the recommendation results. SR-HGNN with 2 and 3 embedding propagation layers obtain better performance as compared to the model which considers first-order relational structure only. We attribute such improvement to the highorder non-linearities brought by stacking more propagation In our experiments, most compared baselines are evaluated using their released source codes. We can observe that SR-HGNN could achieve competitive efficiency as compared to most neural network-based social recommder systems. We also examine the convergence property of the SR-HGNN. Figure <ref type="figure">7</ref> shows that the prediction accuracy as a function of the number of epochs. We could notice that SR-HGNN converges much smoother and faster than other state-of-the-art baselines in most cases, and performance is improved with more iterations. This observation also suggests the good efficiency of our social recommender system with hierarchical graph neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RELATED WORK</head><p>This section discuss the research work which is related to our studied problem from the following aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Deep Collaborative Filtering Techniques</head><p>Deep neural networks bring powerful representation and generalization ability for collaborative filtering recommendation techniques <ref type="bibr" target="#b46">[47]</ref>. For example, NeurMF <ref type="bibr" target="#b9">[10]</ref> replaced the inner-product operation with Multilayer Perceptron to learn non-linear relations between user and item embeddings. Inspired by the recent developments of graph neural networks, NGCF <ref type="bibr" target="#b29">[30]</ref> and STAR-GCN <ref type="bibr" target="#b45">[46]</ref> proposed to perform embedding propagation in the user-item integration graph. In addition, graph embedding technique has been leveraged to unify collaborative filtering with attention mechanism for pairwise user-item relation fusion <ref type="bibr" target="#b28">[29]</ref>. However, these models cannot well take the social relational information into consideration. Considering user-item interactive behavior tend to be influenced by other relevant users, this work incorporates social relations for recommendation by jointly modeling of multiplex user-item interactions and user-user social dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Social-aware Recommender Systems</head><p>Social recommendation aims at modeling the social signals among users to improve the recommender systems, with the    consideration that users' interactions over items can be affected their friends <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b30">[31]</ref>. Previous work has made significant progress in incorporating social relationships into the matrix factorization framework with various integration schemes. For example, Ma et al. <ref type="bibr" target="#b18">[19]</ref> performed the factor analysis based on the probabilistic matrix factorization. Yang et al. <ref type="bibr" target="#b38">[39]</ref> built a matrix factorization model on the trust network of users based on their opinion propagation relationships. With the utilization of cross-domain user relations, multiple relations across heterogeneous networks were explored in <ref type="bibr" target="#b14">[15]</ref>. With the advancement of deep learning techniques in revolutionizing recommender systems, many deep neural network models have been developed to jointly map user-item interactions and social relations between users into a shared latent space <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b42">[43]</ref>. Among various algorithms, attention mechanism has served as an effective tool for relation aggregation. In particular, attentive memory mechanism has been utilized to learn influence strength among users in the social recommendation framework <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b3">[4]</ref>. Fan et al. <ref type="bibr" target="#b6">[7]</ref> proposed a random walk-based hierarchical attention network to select most relevant information from user's social neighbors. Furthermore, motivated by the idea of graph neural network for aggregating feature information from node's neighbors in a network structure, several attempts aim at aggregating user relations with graph attention encoder <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b24">[25]</ref>. However, most of existing deep social recommender systems perform user aggregation via modeling the local behavioral similarity between users, which lacks an effective encoding of the collaborative signals between users in a comprehensive global space. To fill this gap, this work aggregates global contextual signals by exploring high-order relationships among users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Graph Neural Network for Recommendation</head><p>Inspired by the promising results of graph neural network in learning dependence of graph structured data <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b43">[44]</ref>, another research line seeks to capture the user-item relationships with graph neural networks <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b45">[46]</ref>. For example, Wang et al. <ref type="bibr" target="#b29">[30]</ref> proposed a graph relation encoder via the message passing between users and items for collaborative filtering. A stacked graph convolutional recommendation network was proposed to learn the masked user and item embeddings under a encoder-decoder architecture <ref type="bibr" target="#b45">[46]</ref>. PinSage <ref type="bibr" target="#b40">[41]</ref> applied the graph convolutional network in the user embedding generation process. Different from these models, SR-HGNN augments the graph-based recommendation with the exploration of global contextual signals, based on the mutual information learning between low-level individual representations and high-level graph structure embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we proposed SR-HGNN, to generalize graph neural network into social-aware collaborative filtering architecture, for jointly incorporating global dependencies between users and relation-aware users' preference over different items. In SR-HGNN, we design a mutual information-contextualized social relation encoder which is capable of capturing global social dependencies among users. Based on the insight of multityped user-item interactions, we endow the graph-structured collaborative relation modeling to exploit the cross-interactive behavior dependencies. Our experiments show that SR-HGNN consistently outperforms state-of-the-art social recommender systems. Future work includes incorporating external textual information of items (e.g., users' reviews or items textual descriptions) into the social recommendation framework to encode richer semantic signals. In addition, another line of future work lies in applying the developed SR-HGNN framework to other types of social-aware recommendation datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The model architecture of multi-typed user-item interactive relation learning in SR-HGNN framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The model architecture of the global social dependency encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>10) where r s ∈ R d×1 indicates the fused global latent representation of graph G s . σ denotes the sigmoid activation function. Furthermore, b m,m and a m,m represents the element in the degree matrix Ds and adjacent matrix Âs , respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>ω 1 and ω 2</head><label>2</label><figDesc>are parameters to the losses from different modules and prevent the overfitting issue. ω r and Θ denotes the regularization term and model parameters, respectively. The training process is elaborated in Algorithm 1.D. Complexity Analysis of SR-HGNNNext, we analyze the complexity of the proposed SR-HGNN model. The embedding propagation module that learns graphbased representations costs O((M + KN ) × d 2 ) computations for the message construction phase, and O(N × K × M × d) calculations for the message aggregation phase. By taking advantage of the sparse matrix-multiplication, the cost of the second phase is reduced to O(ψ(A r ) × d), where ψ(A r ) denotes the number of user-item interactions. For the purpose of dimensionality reduction, (M +KN )×d is typically smaller than ψ(A r ). Hence, the two phases cost O(ψ(A r ) × d).The reconstruction-based context incorporation utilizes O(d 2 ) operations for each user-item pair, so O(ψ(A r ) × d 2 ) is required for the reconstruction. Analogously, we can find out the complexity of reconstructing the user-user interaction is O(ψ(A s )×d 2 ). Totally, the complexity of the multi-typed useritem interactive relation learning is O((ψ(A r ) + ψ(A s )) × d 2 ), which is close to the common graph neural networks considering small d. The mutual information learning based social modeling propagates information in a similar way, and also costs O(ψ(A s ) × d) complexity for calculation. The efficiency of our SR-HGNN is validated in the experiments by comparing the running time of our model with several state-of-the-arts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Ablation study on our mutual information-based graph neural module for social dependencies learning in terms of RMSE and MAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Ablation study on the effectiveness of the multi-typed user-item interactions and users' social information in terms of RMSE and MAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Performance comparison w.r.t interaction sparsity levels, where background bars denote the number of users that falls into the specific interaction sparsity level, and the corresponding performance is represented by the lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Figure 6. Hyper-parameter study in terms of RMSE and MAE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>k ×dr is the weight matrix, where d v n,k and d r represents the latent dimensionality of x v n,k and the</figDesc><table><row><cell cols="3">propagation module, respectively. Based on the convolutional</cell></row><row><cell cols="3">operation, λ k m,n reflects that the influence strength of v n,k over</cell></row><row><cell cols="3">u m is inversely proportional to the number of u m 's connected</cell></row><row><cell>nodes, i.e., λ k m,n =</cell><cell>√</cell><cell>1 |Jm||J n,k |</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>: multi-typed user-item interaction graph Gr, user-user social graph Gs user-item interaction tensor, sample number s, maximum epoch number E1, E2, loss weights ω1, ω2, ωr, learning rate η Output: trained parameters in Θ 1 Initialize all parameters in Θ 2 for e = 1 to E1 do Calculate the high-order embeddings Eu m , Ev n,k according to Eq 1 to Eq 7</figDesc><table><row><cell>3</cell><cell>Calculate the graph-level representation of Gs according</cell></row><row><cell></cell><cell>to Eq 9 to Eq 10</cell></row><row><cell>4</cell><cell>Calculate the mutual information-based loss Lmu</cell></row><row><cell></cell><cell>according to Eq 12</cell></row><row><cell>5</cell><cell>for θ in the social dependency modeling module do</cell></row><row><cell>6</cell><cell>θ = θ − η • ∂Lmu/∂θ</cell></row><row><cell>7</cell><cell>end</cell></row><row><cell>8 end</cell><cell></cell></row><row><cell cols="2">9 for e = 1 to E2 do</cell></row><row><cell>10</cell><cell></cell></row><row><cell>11</cell><cell>Draw a mini-batch of (s Ar m,n,k + , s Ar m,n,k − ) and</cell></row><row><cell></cell><cell>(s As m,m + , s As m,m − ) for reconstruction</cell></row><row><cell></cell><cell>F</cell></row><row><cell>15</cell><cell>for θ in the interaction modeling graph neural network</cell></row><row><cell></cell><cell>do</cell></row><row><cell>17</cell><cell>end</cell></row><row><cell>18 end</cell><cell></cell></row><row><cell cols="2">19 return all parameters Θ</cell></row></table><note>•) is an indicator function where ρ(h um , r s ) = 1 and ρ( h um , r s ) = 1 corresponds to positive and negative instance during the training phase. By minimizing the loss L mu (maximizing the mutual information between local node-level and global graph-level representations), we could generate the enhanced user representations H * ∈ R M ×d H with the preservation of global social context. Algorithm 1: Learning Process of SR-HGNN Input12 Calculate the reconstruction loss Lr, Ls according to Eq 8 13 Calculate the prediction loss Lp according to Eq 14 14 L = Lp + ω1Lr + ω2Ls + ωr Θ 2 16 θ = θ − η • ∂L/∂θ</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table II PERFORMANCE</head><label>II</label><figDesc>COMPARISON OF ALL METHODS ON THREE DATASETS IN TERMS OF RMSE AND MAE.</figDesc><table><row><cell>Data</cell><cell></cell><cell cols="2">Train Metrics</cell><cell>PMF</cell><cell>SocialMF</cell><cell>SoReg</cell><cell>SoRec</cell><cell cols="3">TrustMF STA-GCN NGCF+SN</cell><cell>DiffNet</cell><cell cols="2">SAMN EATNN GraphRec SR-HGNN</cell></row><row><cell>Ciao</cell><cell></cell><cell>80% 60%</cell><cell cols="2">RMSE 1.0664 MAE 0.8281 RMSE 1.0908 MAE 0.8424</cell><cell>1.0657 0.8321 1.0714 0.8378</cell><cell>1.0782 0.8593 1.0855 0.8420</cell><cell>1.0526 0.8135 1.0692 0.8276</cell><cell>1.0518 0.8113 1.0678 0.8262</cell><cell>1.0295 0.7687 1.0461 0.7932</cell><cell>1.0306 0.7781 1.0445 0.7877</cell><cell>1.0369 0.7723 1.0585 0.7935</cell><cell>1.0543 1.0313 0.7890 0.7667 1.0924 1.0742 0.8116 0.7973</cell><cell>0.9687 0.7382 0.9921 0.7592</cell><cell>0.9507 0.7189 0.9624 0.7318</cell></row><row><cell cols="2">Epinions</cell><cell>80% 60%</cell><cell cols="2">RMSE 1.1692 MAE 0.9187 RMSE 1.1873 MAE 0.9380</cell><cell>1.1494 0.8730 1.1692 0.8973</cell><cell>1.1576 0.8797 1.1789 0.9184</cell><cell>1.1477 0.8732 1.1649 0.8847</cell><cell>1.1314 0.8642 1.1553 0.8757</cell><cell>1.0946 0.8582 1.1183 0.8843</cell><cell>1.1022 0.8650 1.1173 0.8758</cell><cell>1.1095 0.8438 1.1241 0.8534</cell><cell>1.1366 1.1187 0.8671 0.8545 1.1899 1.1385 0.8995 0.8663</cell><cell>1.0581 0.8074 1.0678 0.8297</cell><cell>1.0326 0.7983 1.0411 0.8081</cell></row><row><cell>Douban</cell><cell></cell><cell>80% 60%</cell><cell cols="2">RMSE 0.7551 MAE 0.5964 RMSE 0.7674 MAE 0.6063</cell><cell>0.7427 0.5866 0.7589 0.5983</cell><cell>0.7508 0.5937 0.7624 0.6074</cell><cell>0.7352 0.5844 0.7459 0.5924</cell><cell>0.7287 0.5752 0.7377 0.5826</cell><cell>0.7370 0.5802 0.7531 0.5909</cell><cell>0.7234 0.5698 0.7305 0.5760</cell><cell>0.7387 0.5793 0.7524 0.5885</cell><cell>0.7350 0.7447 0.5777 0.5809 0.7483 0.7619 0.5879 0.5934</cell><cell>0.7257 0.5690 0.7348 0.5787</cell><cell>0.7141 0.5645 0.7220 0.5705</cell></row><row><cell>0.96</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.90 0.92 0.94 RMSE</cell><cell cols="2">SR-HGNNgcn SR-HGNNgat SR-HGNN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table III ABLATION</head><label>III</label><figDesc>TEST ON THE IMPACT OF THE RECONSTRUCTION-BASED CONTEXT INCORPORATION IN TERMS OF RMSE AND MAE.</figDesc><table><row><cell>Model</cell><cell>Metric</cell><cell>Ciao</cell><cell cols="2">Epinions Douban</cell></row><row><cell>SR-HGNN w/o−rec</cell><cell cols="2">RMSE 0.9506 MAE 0.7203</cell><cell>1.0378 0.8012</cell><cell>0.7162 0.5668</cell></row><row><cell>SR-HGNN w−rec</cell><cell cols="2">RMSE 0.9478 MAE 0.7169</cell><cell>1.0354 0.7995</cell><cell>0.7149 0.5650</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table IV MODEL</head><label>IV</label><figDesc>SCALABILITY STUDY WITH RUNNING TIME (SECONDS).We finally investigate the model efficiency of our SR-HGNN. Table IV presents the computational cost of training (with each individual epoch) for SR-HGNN and several deep neural network-based baselines on three different datasets.</figDesc><table><row><cell>Model</cell><cell cols="3">Ciao Epinions Douban</cell></row><row><cell>NGCF+SN</cell><cell>3</cell><cell>12</cell><cell>63</cell></row><row><cell>DiffNet</cell><cell>2</cell><cell>3</cell><cell>10</cell></row><row><cell>SAMN</cell><cell>3</cell><cell>6</cell><cell>20</cell></row><row><cell>EATNN</cell><cell>1</cell><cell>2</cell><cell>5</cell></row><row><cell>GraphRec</cell><cell>112</cell><cell>380</cell><cell>3600</cell></row><row><cell>SR-HGNN</cell><cell>5</cell><cell>15</cell><cell>78</cell></row><row><cell cols="4">layers. Additionally, the slight performance degradation can be</cell></row><row><cell cols="4">noticed as L increases since the deeper graph neural network</cell></row><row><cell>tend to overfit.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">F. Model Efficiency Study (RQ5)</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for their constructive feedback and comments. This work is supported by National Nature Science Foundation of China (61672241), Major Project of National Social Science Foundation of China (18ZDA062), Natural Science Foundation of Guangdong Province (2016A030308013), Science and Technology Program of Guangdong Province (2019A050510010).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Harutyunyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social attentional memory network: Modeling aspect-and friend-level differences in recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="177" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An efficient adaptive transfer neural network for social-aware recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="225" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Social boosted recommendation with folded bipartite network embedding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Samwalker: Social recommendation with informative sampling strategy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="228" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph neural networks for social recommendation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep social collaborative filtering</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recsys</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="305" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural multi-task recommendation from multi-behavior data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1554" to="1557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Topic-aware social sensing with arbitrary source dependency graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPSN</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Online purchase prediction via multi-scale modeling of behavior dynamics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2613" to="2622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A matrix factorization technique with trust propagation for recommendation in social networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recsys</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Social recommendation across multiple relational domains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1422" to="1431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Discrete social recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="208" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Social recommendation with an essential preference space</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sorec: social recommendation using probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="931" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recommender systems with social regularization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A dual heterogeneous graph attention network to improve long-tail performance for shop search in e-commerce</title>
		<author>
			<persName><forename type="first">X</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3405" to="3415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Salience and market-aware skill extraction for job targeting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Influential node tracking on dynamic social network: An interchange greedy approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="359" to="372" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sessionbased social recommendation via dynamic graph attention networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="555" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-representation fusion network for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="267" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Graph convolutional matrix completion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<title level="m">Deep graph infomax. ICLR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unified collaborative filtering over graph embeddings</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural graph collaborative filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning personalized preference of strong and weak ties for social recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1601" to="1610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Social recommendation with optimal limited attention</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1518" to="1527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Npa: Neural news recommendation with personalized attention</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2576" to="2584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A neural influence diffusion model for social recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="235" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Socialgcn: An efficient graph convolutional network based model for social recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural tensor factorization for temporal interaction learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="537" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multiplex behavioral relation learning for recommendation via memory augmented transformer network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2397" to="2406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Social collaborative filtering by trust</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">TPAMI</biblScope>
			<biblScope unit="page" from="1633" to="1647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fast network embedding enhancement via high order proximity approximation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3894" to="3900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generating reliable friends via adversarial training to improve social recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="768" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Enhance social recommendation with adversarial graph convolutional networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Heterogeneous graph neural network</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="793" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Collaborative user network embedding for social recommender systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="228" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Star-gcn: Stacked and reconstructed graph convolutional networks for recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Quaternion collaborative filtering for recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
