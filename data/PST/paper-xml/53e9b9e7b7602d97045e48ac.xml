<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differential evolution based on covariance matrix learning and bimodal distribution parameter setting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-02-03">3 February 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yong</forename><surname>Wang</surname></persName>
							<email>ywang@csu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Central South University</orgName>
								<address>
									<postCode>410083</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Han-Xiong</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Systems Engineering and Engineering Management</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">State Key Laboratory of High Performance Complex Manufacturing</orgName>
								<orgName type="institution">Central South University</orgName>
								<address>
									<postCode>410083</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tingwen</forename><surname>Huang</surname></persName>
							<email>tingwen.huang@qatar.tamu.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">Texas A&amp;M University at Qatar</orgName>
								<address>
									<postCode>5825</postCode>
									<settlement>Doha</settlement>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Long</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Central South University</orgName>
								<address>
									<postCode>410083</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Differential evolution based on covariance matrix learning and bimodal distribution parameter setting</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-02-03">3 February 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">0DDB5A9E059704F5ECC0A8C10DBD8C80</idno>
					<idno type="DOI">10.1016/j.asoc.2014.01.038</idno>
					<note type="submission">Received 19 April 2013 Received in revised form 21 December 2013 Accepted 28 January 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Differential evolution Global numerical and engineering optimization Covariance matrix learning Bimodal distribution parameter setting</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differential evolution (DE) is an efficient and robust evolutionary algorithm, which has been widely applied to solve global optimization problems. As we know, crossover operator plays a very important role on the performance of DE. However, the commonly used crossover operators of DE are dependent mainly on the coordinate system and are not rotation-invariant processes. In this paper, covariance matrix learning is presented to establish an appropriate coordinate system for the crossover operator. By doing this, the dependence of DE on the coordinate system has been relieved to a certain extent, and the capability of DE to solve problems with high variable correlation has been enhanced. Moreover, bimodal distribution parameter setting is proposed for the control parameters of the mutation and crossover operators in this paper, with the aim of balancing the exploration and exploitation abilities of DE. By incorporating the covariance matrix learning and the bimodal distribution parameter setting into DE, this paper presents a novel DE variant, called CoBiDE. CoBiDE has been tested on 25 benchmark test functions, as well as a variety of real-world optimization problems taken from diverse fields including radar system, power systems, hydrothermal scheduling, spacecraft trajectory optimization, etc. The experimental results demonstrate the effectiveness of CoBiDE for global numerical and engineering optimization. Compared with other DE variants and other state-of-the-art evolutionary algorithms, CoBiDE shows overall better performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Differential evolution (DE), proposed by Storn and Price <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> in 1995, has become a hotspot in the community of evolutionary computation. Similar to other evolutionary algorithms (EAs), DE is a population-based optimization algorithm. In DE, each individual in the population is called a target vector. DE produces a mutant vector by making use of the mutation operator, which perturbs a target vector using the difference vector of other individuals in the population. Afterward, the crossover operator is applied to the target vector and the mutant vector to generate a trial vector. Finally, the trial vector competes with its target vector for survival according to their objective function values. Due to some advantages, e.g., simple structure, ease of implementation, and fast convergence speed, DE has been widely applied to some fields of science and engineering, such as cluster analysis <ref type="bibr" target="#b2">[3]</ref>, robot control <ref type="bibr" target="#b3">[4]</ref>, controller design <ref type="bibr" target="#b4">[5]</ref>, and graph theory <ref type="bibr" target="#b5">[6]</ref>.</p><p>It is noteworthy that in DE, the crossover operator depends mainly on the coordinate system and the distribution information of the population is usually unreasonably ignored. Moreover, the crossover operator of DE can be considered as a discrete recombination <ref type="bibr" target="#b6">[7]</ref>, and thus, the interactions among variables have not been systematically studied. As a result, DE often loses its effectiveness and advantages when solving problems with high variable correlation.</p><p>In addition, DE is sensitive to its two main control parameters: the scaling factor F and the crossover control parameter CR. These two control parameters have a significant impact on the performance of DE. Moreover, different control parameter settings show different characteristics <ref type="bibr" target="#b7">[8]</ref>. For example, a larger F is effective for global search; however, a smaller F can accelerate the convergence. On the other hand, a larger CR results in higher diversity of the population, since the trial vector will inherit more information from the mutant vector. However, a smaller CR focuses on local exploitation since the target vector will contribute more information to the trial vector. Indeed, it is still an open issue to choose suitable settings of F and CR to balance the exploration and exploitation of DE during the evolution.</p><p>Based on the above considerations, in this paper, we present a novel DE, referred as CoBiDE, including two main components: covariance matrix learning and bimodal distribution parameter setting. In CoBiDE, the covariance matrix learning establishes a coordinate system according to the current population distribution, and then the crossover operator is applied according to the coordinate system thus built to generate the trial vector. Furthermore, in CoBiDE, both F and CR are produced according to a bimodal distribution composed of two Cauchy distributions, the aim of which is to balance the global exploration and the local exploitation during the evolution. CoBiDE has been tested on 25 benchmark test functions developed for the 2005 IEEE Congress on Evolutionary Computation (IEEE CEC2005) <ref type="bibr" target="#b8">[9]</ref>, as well as a variety of real-world application problems <ref type="bibr" target="#b9">[10]</ref>. The experimental results suggest that the performance of CoBiDE is better than that of four other DE variants and three other state-of-the-art EAs.</p><p>The remainder of this paper is organized as follows. Section 2 briefly introduces DE and its operators. Section 3 reviews the related work and four main research directions of DE. Then, CoBiDE is presented in Section 4. The experimental results are given in Section 5. Section 6 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Differential evolution (DE)</head><p>DE is a population-based heuristic search algorithm. Similar to other EAs, DE contains three basic operators: mutation, crossover, and selection. Firstly, DE produces an initial population by randomly sampling several points (each point is called a target vector) from the search space: P 0 = { x i,0 = (x i,1,0 , x i,2,0 , . . ., x i,D,0 ), i = 1, 2, . . ., NP}</p><p>where NP denotes the population size and D denotes the number of variables. At each generation G, a mutant vector v i,G = (v i,1,G , v i,2,G , . . ., v i,D,G ) (i ∈ 1, 2, . . ., NP) is produced by the mutation operator for each target vector x i,G . Afterward, the crossover operator is implemented on the mutant vector and the target vector to generate a trial vector u i,G = (u i,1,G , u i,2,G , . . ., u i,D,G ) (i ∈ 1, 2, . . ., NP). The crossover operator and the mutation operator together are called trial vector generation strategy. The selection operator of DE is based on a one-to-one competition between the target vector and the trial vector.</p><p>Next, the mutation, crossover, and selection operators are introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Mutation operator</head><p>The commonly used mutation operator can be formulated as follows:</p><formula xml:id="formula_1">v i,G = x r1,G + F • ( x r2,G -x r3,G ) (2)</formula><p>where r1, r2, and r3 are mutually different integers randomly chosen from <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">NP]</ref> and also different from i, and F is the scaling factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Crossover operator</head><p>The crossover operator combines the mutant vector v i,G with the target vector x i,G to generate a trial vector u i,G : u i,j,G = v i,j,G , if rand j (0, 1) ≤ CR or j = j rand x i,j,G , otherwise <ref type="bibr" target="#b2">(3)</ref> where j rand is a random integer between 1 and D, resulting in the trial vector being different from the target vector by at least one dimension, rand j (0, 1) is a uniformly distributed random number between 0 and 1, and CR is the crossover control parameter.</p><p>Based on Eq. ( <ref type="formula" target="#formula_18">3</ref>), it is clear that the trial vector is a vertex of the hyper-rectangle defined by the mutant and target vectors <ref type="bibr" target="#b10">[11]</ref>. Moreover, since the information of the trial vector is provided by the mutant vector or the target vector, the crossover operator is dependent on the coordinate system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Selection operator</head><p>The selection operator of DE adopts a one-to-one competition between the target vector x i,G and the trial vector u i,G . If the objective function value of the trial vector is less than or equal to that of the target vector, then the trial vector will survive into the next generation, otherwise, the target vector will enter the next generation:</p><formula xml:id="formula_2">x i,G+1 = u i,G , if f ( u i,G ) ≤ f ( x i,G ) x i,G , otherwise<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The related work</head><p>During the past fifteen years, DE has attracted much attention by the researchers <ref type="bibr" target="#b11">[12]</ref>. The current studies of DE mainly focus on the following four aspects: (1) improving the trial vector generation strategy, (2) adapting the control parameter setting, (3) hybridizing with other techniques, and (4) integrating multiple trial vector generation strategies with multiple control parameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Improving the trial vector generation strategy</head><p>Fan and Lampinen <ref type="bibr" target="#b12">[13]</ref> proposed a trigonometric mutation operator and embedded it into DE to design a new method called TDE. In TDE, a probability parameter M t is utilized to balance the trigonometric mutation operator and the original mutation operator of DE. The trigonometric mutation can be considered as a local search operator, which is able to enhance the convergence velocity of DE. The performance of TDE has been evaluated on two test functions and two practical problems.</p><p>Zhang and Sanderson <ref type="bibr" target="#b13">[14]</ref> presented an improved current-tobest/1 operator, called current-to-pbest/1, which can be formulated as follows:</p><formula xml:id="formula_3">v i,G = x i,G + F i • ( x p best,G -x i,G ) +F i • ( x r1,G -x r2,G ), i ∈ {1, 2, . . ., NP}<label>(5)</label></formula><p>where x p best,G is randomly chosen from the best 100p% individuals in the current population, and p is chosen from (0, 1]. Moreover, the previously generated offspring, which cannot survive into the next population, have been stored into a predefined archive. The individual x r2,G in Eq. ( <ref type="formula" target="#formula_3">5</ref>) is randomly chosen from the union of the archive and the current population. As analyzed in <ref type="bibr" target="#b13">[14]</ref>, the advantages of the current-to-pbest/1 operator are twofold: (1) the information of multiple best individuals can balance the greediness of the mutation and the diversity of the population, and (2) the difference between the recently explored inferior individuals and the current population may represent promising directions toward the global optimum.</p><p>Das et al. <ref type="bibr" target="#b14">[15]</ref> proposed a neighborhood-based mutation operator, which contains two parts: global neighborhood-based mutation and local neighborhood-based mutation. In the method proposed by Das et al. <ref type="bibr" target="#b14">[15]</ref>, two trial vectors are produced by the global and local neighborhood-based mutation. Moreover, these two trial vectors are combined to form the actual trial vector by using a weight factor. Clearly, the main aim of the neighborhood-based mutation operator is to balance the exploration and exploitation abilities of DE. This mutation operator has been tested on 24 benchmark test functions and two real-world problems and shown very competitive results.</p><p>After recognizing that the trial vector generated by the crossover operator is just a vertex of the hyper-rectangle defined by the mutant and target vectors, Wang et al. <ref type="bibr" target="#b10">[11]</ref> employed orthogonal crossover <ref type="bibr" target="#b15">[16]</ref> to make a systematic and rational search in the hyper-rectangle defined by the mutant and target vectors, and proposed a generic framework to enhance the search ability of DE. The experimental results have demonstrated that this framework can be used to improve the performance of different variants of DE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Adapting the control parameter setting</head><p>Liu and Lampinen <ref type="bibr" target="#b16">[17]</ref> designed a fuzzy adaptive DE (FADE) based on fuzzy logic controller. In FADE, the mean square roots of differences of the objective function values and the population members during the successive generations are treated as the inputs of the fuzzy logic controller, and the outputs are the values of F and CR. The experimental results have shown that FADE outperforms the classic DE on problems with high dimensionality. The main weakness of FADE lies in its complicated implementation due to fuzzy adapting.</p><p>Brest <ref type="bibr" target="#b17">[18]</ref> proposed a DE with self-adaptive parameter control (jDE). In jDE, the control parameters F and CR are encoded into the chromosome and participate in the evolution. Each individual in the population is assigned an initial control parameter setting: F i = 0.5 and CR i = 0.9 (i = 1, 2, . . ., NP). During the evolution, jDE regenerates F i and CR i according to the uniform random distributions U(0.1, 0.9) and U(0, 1) with probabilities 1 and 2 , respectively. One of the main advantages of jDE is that its implementation is very simple. In <ref type="bibr" target="#b17">[18]</ref>, 21 test functions have been used to assess the performance of jDE.</p><p>In JADE proposed by Zhang and Sanderson <ref type="bibr" target="#b13">[14]</ref>, for each target vector, the scaling factor F is generated by the Cauchy distribution C( F , 0.1), and the crossover control parameter CR obeys the normal distribution N( CR , 0.1). In addition, JADE uses the following equations to update F and CR :</p><formula xml:id="formula_4">F = (1 -c) • F + c • mean L (S F ) (6) CR = (1 -c) • CR + c • mean A (S CR )<label>(7)</label></formula><p>where c controls the rate of parameter adaptation, S F and S CR are the sets of all successful scaling factor F and crossover control parameter CR at each generation, respectively, and mean A (•) and mean L (•) are the usual arithmetic mean and the Lehmer mean, respectively. The above parameter adaptation has the capability to adapt parameters to appropriate values, and thus, improves the robustness of DE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Hybridizing with other techniques</head><p>Noman and Iba <ref type="bibr" target="#b6">[7]</ref> proposed a crossover-based adaptive local search operator to enhance the convergence rate of DE. In this method, simplex crossover <ref type="bibr" target="#b18">[19]</ref> is applied to the best individual and two other individuals of the population at each generation before implementing DE. This method does not add any additional complexity or any additional parameter. Moreover, it exhibits a higher convergence velocity compared with the original DE.</p><p>Opposition-based DE (ODE) is proposed by Rahnamayan et al. <ref type="bibr" target="#b19">[20]</ref>, which employs opposition-based learning to generate the initial population and new solutions. The experimental results suggest that opposition-based learning is a very effective way to speed up the convergence of DE. Concretely, ODE is on average 44% faster than the original DE on 58 test functions.</p><p>Sun et al. <ref type="bibr" target="#b20">[21]</ref> combined DE with estimation of distribution algorithm (EDA), and proposed DE/EDA. In DE/EDA, one part of the trial vector is generated in the DE way, and the other part of the trial vector is sampled from the constructed probability distribution model. As a result, DE/EDA can not only utilize the global statistical information derived from EDA, but also use the differential information provided by DE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Integrating multiple trial vector generation strategies with multiple control parameter settings</head><p>Recently, some researchers investigated the idea of integrating multiple trial vector generation strategies with multiple control parameter settings in DE. The main motivation is that different strategies along with different parameter settings may be suitable to different problems <ref type="bibr" target="#b7">[8]</ref>.</p><p>Qing et al. <ref type="bibr" target="#b7">[8]</ref> proposed a self-adaptive DE (SaDE), in which both trial vector generation strategies and control parameter settings are self-adapted according to the previous information. SaDE establishes a strategy candidate pool which contains four trial vector generation strategies. At each generation, one trial vector generation strategy is chosen for one individual. In addition, SaDE assigns different control parameter settings for different individuals. SaDE has been used to solve a suite of 26 test functions and the experimental results are very promising.</p><p>Mallipeddi et al. <ref type="bibr" target="#b21">[22]</ref> proposed a DE with ensemble of control parameter settings and trial vector generation strategies (EPSDE). EPSDE involves a pool of distinct trial vector generation strategies and a pool of values for each control parameter. During the evolution, a trial vector generation strategy and a control parameter setting are chosen based on their success experience in the past generations to create a trial vector. As a result, the successful combination of strategy and parameter setting has a higher probability to produce the trial vector. Since the strategies and the parameter settings in a pool have distinct properties, EPSDE exhibit distinct performance characteristics during different stages of the evolution.</p><p>During the past fifteen years, DE researchers have obtained some important experiences about choosing trial vector generation strategies and control parameter settings, which will be very useful for designing more effective DE. Motivated by the above consideration, Wang et al. <ref type="bibr" target="#b22">[23]</ref> investigated whether the performance of DE can be improved by combining several trial vector generation strategies with several different control parameter settings, which exhibit different characterizes, and proposed a composite DE, named CoDE. CoDE combines three trial vector generation strategies with three control parameter settings in a random way to produce the trial vectors. The performance of CoDE has been evaluated on 25 benchmark test functions developed for IEEE CEC2005 <ref type="bibr" target="#b8">[9]</ref>.</p><p>Gong et al. <ref type="bibr" target="#b23">[24]</ref> used four trial vector generation strategies proposed in <ref type="bibr" target="#b13">[14]</ref> to form the strategy candidate pool and designed two adaptive methods to choose a suitable trial vector generation strategy for a problem at hand. In addition, the parameter adaptation mechanism proposed by Gong et al. <ref type="bibr" target="#b23">[24]</ref> is similar to that proposed in <ref type="bibr" target="#b13">[14]</ref>. The experimental results on 20 test functions and two realworld problems have verified that the method proposed in <ref type="bibr" target="#b23">[24]</ref> is able to adaptively determine a more suitable strategy for a specific problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proposed approach</head><p>In this section, we propose a novel DE, named CoBiDE. CoBiDE contains two main components: covariance matrix learning and bimodal distribution parameter setting. Next, the implementation of the above two main components will be introduced in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Covariance matrix learning</head><p>As mentioned previously, the crossover operator of DE is dependent mainly on the coordinate system, and the distribution information of the population, which could reflect the landscape of the problem to a certain extent <ref type="bibr" target="#b11">[12]</ref>, is usually ignored during the evolution. Indeed, the statistical properties of the population (such as mean value, variance, and covariance) can be utilized to represent the distribution of the population. In particular, the covariance matrix composed of variance and covariance reflects the diversity of the population and the interactions among the variables. Hence, systemically utilizing the covariance matrix should be very useful for relaxing the dependence of DE on the coordinate system and loosing the interactions among the variables.</p><p>Based on the above analysis, covariance matrix learning is proposed in this paper, the aim of which is to establish an Eigen coordinate system with loose variable correlation for the crossover operator. Fig. <ref type="figure" target="#fig_0">1</ref> shows the differences between the crossover operator in the original coordinate system (Fig. <ref type="figure" target="#fig_0">1(a)</ref>) and the crossover operator in the Eigen coordinate system (Fig. <ref type="figure" target="#fig_0">1(b)</ref>) for a problem with variable correlation. Suppose that the Eigen coordinate system (i.e., ox 1 x 2 ) is obtained after analyzing the distribution of the population. From Fig. <ref type="figure" target="#fig_0">1</ref>, it is clear that crossover in the Eigen coordinate system is more promising to find the global optimum, since the trial vectors generated by the crossover in the Eigen coordinate system may be more close to the global optimum than the trial vectors created by the crossover in the original coordinate system.</p><p>In this paper, the covariance matrix learning includes two core techniques: Eigen decomposition of the covariance matrix and the coordinate transformation. The purpose of the former is to obtain Eigen vectors which can serve as the axial orientations of the Eigen coordinate system. In addition, the latter transforms the trial vectors into the original coordinate system, after implementing the crossover operator according to the Eigen coordinate system. The procedure of the covariance matrix learning is introduced as follows.</p><p>Step 1. Compute the covariance matrix C of the top ps•NP individuals in the current population, and apply Eigen decomposition to C as follows:</p><formula xml:id="formula_5">C = BD 2 B T<label>(8)</label></formula><p>where B and B T are orthogonal matrices and D is a diagonal matrix composed of Eigen values. Note that each column of B is an Eigen vector of the covariance matrix C.</p><p>Step 2. Update the target vector and the mutant vector in the Eigen coordinate system by making use of B T :</p><formula xml:id="formula_6">x i,G = B -1 x i,G = B T x i,G<label>(9)</label></formula><formula xml:id="formula_7">v i,G = B -1 v i,G = B T v i,G<label>(10)</label></formula><p>Step 3. Apply the crossover operator to x i,G and v i,G , and create a trial vector u i,G in the Eigen coordinate system:</p><formula xml:id="formula_8">u i,j,G = v i,j,G , if rand j (0, 1) ≤ CR or j = j rand x i,j,G , otherwise<label>(11)</label></formula><p>Step 4. Transform u i,G into the original coordinate system by taking advantage of B:</p><formula xml:id="formula_9">u i,G = B u i,G<label>(12)</label></formula><p>where u i,G is the trial vector in the original coordinate system.</p><p>During the evolution, due to the randomness of the distribution of the population, if all the individuals in the population are used to compute the covariance matrix, the covariance matrix will be disturbed by such randomness and, as a result, the Eigen coordinate system constructed may not be quite reasonable. Therefore, in Step 1, we use the ps•NP individuals with the minimum objective function values in the population to compute the covariance matrix, where ps is in the interval [0, 1]. Remark 1. CMA-ES <ref type="bibr" target="#b24">[25]</ref>, BLXPCA <ref type="bibr" target="#b25">[26]</ref>, and BLXICA <ref type="bibr" target="#b25">[26]</ref> have a similar motivation to use statistical information based on the covariance matrix. However, there are some differences between CoBiDE and them. In CoBiDE, the parameter ps is introduced to compute the covariance matrix of the top ps•NP individuals in the current population, while CMA-ES adopts a weighted method to compute the covariance matrix. In addition, all the individuals in the population are used to compute the covariance matrix in BLX-PCA and BLXICA. On the other hand, CMA-ES, BLXPCA, and BLXICA use Eigen values and Eigen vectors obtained by the Eigen decomposition of the covariance matrix simultaneously. However, because of the properties of crossover in DE, the proposed approach only uses Eigen vectors to construct an appropriate coordinate system, and Eigen values are not used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 2.</head><p>Recently, several methods which hybridize DE with CMA-ES <ref type="bibr" target="#b24">[25]</ref> have been proposed. For example, DE performs the global exploration and CMA-ES is used as a local search engine in <ref type="bibr" target="#b26">[27]</ref>. In <ref type="bibr" target="#b27">[28]</ref>, CMA-ES and a hybrid DE are executed serially. Moreover, two populations are utilized, one for CMA-ES and the other for the hybrid DE. LaTorre et al. <ref type="bibr" target="#b28">[29]</ref> presented a multiple offspring sampling framework to combine a restart CMA-ES <ref type="bibr" target="#b29">[30]</ref> with DE. In this framework, the average fitness increment is adopted as a quality function to update the participation ratios of the restart CMA-ES and DE. There are two major differences between CoBiDE and the above three methods. Firstly, DE is not coupled with CMA-ES in CoBiDE. Indeed, CoBiDE only exploits the statistical information provided by the covariance matrix of the population. Secondly, in CoBiDE the statistical information provided by the covariance matrix is embedded into DE to strengthen the crossover operator. However, in the above three methods, CMA-ES is independent of DE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Bimodal distribution parameter setting</head><p>In this subsection, bimodal distribution parameter setting is proposed for the scaling factor F and the crossover control parameter CR. It is necessary to emphasize that the proposed bimodal distribution parameter setting is inspired by <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b22">[23]</ref>. In addition, like <ref type="bibr" target="#b17">[18]</ref>, the parameters F and CR are encoded into each target vector x i,G , i.e., F i,G and CR i,G correspond to each x i,G . Moreover, if the trial vector u i,G can successfully enter the next population, then F i,G+1 = F i,G and CR i,G+1 = CR i,G ; otherwise, F i,G+1 and CR i,G+1 are generated for the next generation according to the bimodal distribution parameter setting.</p><p>The bimodal distribution for F i,G (i ∈ {1, . . ., NP}) is composed of two Cauchy distributions as follows:</p><formula xml:id="formula_10">F i,G = randc i (0.65, 0.1), if rand(0, 1) &lt; 0.5 randc i (1.0, 0.1), otherwise<label>(13)</label></formula><p>where rand(0, 1) is a uniformly distributed random number between 0 and 1, and randc i (a, b) is a random number obeying a Cauchy distribution with location parameter a and scale parameter b. If the value of F i,G is larger than 1.0, then is truncated to 1.0; and if the value of F i,G is less than 0.0, then is regenerated according to Eq. ( <ref type="formula" target="#formula_10">13</ref>). Crossover in the original coordinate system (i.e., ox1x2) and in the Eigen coordinate system (i.e., ox 1 x 2 ), where x i,G is a target vector in the population, v i,G is its mutant vector, and the square points denote the possible trial vectors.</p><p>The crossover control parameter CR i,G (i ∈ {1, . . ., NP}) is generated using the bimodal distribution composed of two Cauchy distributions as follows:</p><formula xml:id="formula_11">CR i = randc i (0.1, 0.1), if rand(0, 1) &lt; 0.5 randc i (0.95, 0.1), otherwise<label>(14)</label></formula><p>where rand(0, 1) is a uniformly distributed random number between 0 and 1, and randc i (a,b) is a random number obeying a Cauchy distribution with location parameter a and scale parameter b. If the value of CR i,G is larger than 1.0, then is truncated to 1.0; and if the value of CR i,G is less than 0.0, then is truncated to 0.0. The scaling factor F has the capability to control the search range of the mutation operator. In CoBiDE, two Cauchy distributions with the same probability (i.e., 0.5) are used for the setting of F. It is necessary to note that, Cauchy distribution with a higher location parameter (i.e., 1.0) tends to produce a bigger value for F which emphasizes the global exploration; however, Cauchy distribution with a relatively lower location parameter (i.e., 0.65) aims at producing a slightly smaller value for F, which focuses on the local exploitation.</p><p>On the other hand, two Cauchy distributions with the same probability (i.e., 0.5) are designed for the setting of CR. The Cauchy distribution with a bigger location parameter (i.e., 0.95) means that the trial vector may inherit more information from the mutant vector, which encourages the diversity of the population and the exploration. On the contrary, the Cauchy distribution with a smaller location parameter (i.e., 0.1) signifies that the trial vector may be quite similar to the target vector. In this case, the search will put emphasis on the neighbor of the parent population, which can accelerate the convergence.</p><p>Based on the above analysis, the use of Eqs. ( <ref type="formula" target="#formula_10">13</ref>) and ( <ref type="formula" target="#formula_11">14</ref>) is able to achieve an effective tradeoff between the exploration and exploitation. In addition, the scale parameter in both Eqs. ( <ref type="formula" target="#formula_10">13</ref>) and ( <ref type="formula" target="#formula_11">14</ref>) is set to 0.1, which results in the values of F and CR being located in the relatively small neighborhood of the location parameter with a higher probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Framework of CoBiDE</head><p>By combining the covariance matrix learning with the bimodal distribution parameter setting, CoBiDE is presented. The pseudocode of CoBiDE has been shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>At each generation, for each target vector x i,G , a mutant vector v i,G is generated by making use of the mutation operator (i.e., Eq. ( <ref type="formula">2</ref>)). Afterward, if the predefined parameter pb is larger than a random number between 0 and 1, the crossover operator according to the covariance matrix learning is utilized to produce a trial vector u i,G , otherwise, the crossover operator according to the original coordinate system is exploited to produce a trial vector u i,G . Moreover, during the evolution, each target vector has its control parameter setting and the control parameter setting is dynamically adapted based on Eqs. ( <ref type="formula" target="#formula_10">13</ref>) and ( <ref type="formula" target="#formula_11">14</ref>).</p><p>In the above procedure, we use the parameter pb to adjust the effect of the covariance matrix learning on the performance. The main reason is the following. Although the covariance matrix learning is an effective way to alleviate the dependence of DE on the coordinate system and the interactions among the variables, it is a relatively deterministic and greedy mechanism due to the use of some best individuals of the population to compute the covariance matrix, and as a result, the performance of the algorithm might degrade for some complex problems. Note that the crossover operator according to the original coordinate system has no bias to any special search directions. Consequently, the crossover operator is implemented in the original coordinate system with a probability (1-pb) to encourage the diversity of the population. With respect to CoBiDE, combining these two kinds of crossover can achieve a good tradeoff between diversity and convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental study</head><p>CoBiDE was tested on 25 benchmark test functions developed for IEEE CEC2005 <ref type="bibr" target="#b8">[9]</ref>. These 25 benchmark test functions can be divided into four classes:</p><p>(1) Unimodal functions F 1 -F 5 .</p><p>(2) Basic multimodal functions F 6 -F 12 .</p><p>(3) Expanded multimodal functions F 13 -F 14 . (4) Hybrid composition functions F 15 -F 25 .</p><p>Among the above test functions, F 1 and F 9 are separable functions and the others are non-separable functions. Some test functions are rotated using orthogonal matrices to make variables correlated with each other, and the global optima of some test functions are shifted so as to not at the center of the search space. x in the population according to Eq. ( <ref type="formula" target="#formula_0">1</ref>3) and Eq. ( <ref type="formula" target="#formula_11">14</ref>), respect ively; (6) While FES&lt;MAX_FES <ref type="bibr" target="#b6">(7)</ref> 1 G P ;</p><p>(8) For i=1:NP <ref type="bibr" target="#b8">(9)</ref> App ly the mutat ion o perator (i.e., Eq. ( <ref type="formula">2</ref>)) to produce a mu tant vector , i G v for the target vector , i G</p><p>x ;</p><p>(10 )</p><formula xml:id="formula_12">r o F d n E (11 )</formula><p>If rand(0,1) &lt;pb /* ran d(0 ,1) denotes a uniformly distribut ed random number between 0 and 1 */ <ref type="bibr" target="#b11">(12 )</ref> For i=1:NP <ref type="bibr" target="#b12">(13 )</ref> Implement the crossov er opera tor accord ing to the covariance matrix lea rning (i.e., Eqs. ( <ref type="formula" target="#formula_5">8</ref>)-( <ref type="formula" target="#formula_9">12</ref>)), and produce a trial vecto r ,</p><formula xml:id="formula_13">i G u ; (14 ) r o F d n E (15 )</formula><p>Else <ref type="bibr" target="#b15">(16 )</ref> For i=1 :NP <ref type="bibr" target="#b16">(17 )</ref> Implement the crossov er op erator acc ording to the original coordinate system (i.e., Eq. ( <ref type="formula" target="#formula_18">3</ref>)), and produce a trial vector</p><formula xml:id="formula_14">, i G u ; (18 )</formula><p>End For <ref type="bibr" target="#b18">(19 )</ref> End If <ref type="bibr" target="#b19">(20 )</ref> For i=1 :NP <ref type="bibr" target="#b20">(21 )</ref> Evaluate the objective func tion value of ,</p><formula xml:id="formula_15">i G u ;<label>(22 ) If , , ( ) ( )</label></formula><formula xml:id="formula_16">i G i G f u f x (23 ) 1 G P = 1 , G i G P u ; (24 ) Fi,G+1=Fi,G and CRi,G+1=CRi,G; (25 ) Else (26 ) 1 G P = 1 , G i G P x ;<label>(27 )</label></formula><p>Generate Fi,G+1 and CRi,G+1 according to Eq. ( <ref type="formula" target="#formula_10">13</ref>) and Eq. ( <ref type="formula" target="#formula_11">14</ref>) for the next generati on; <ref type="bibr" target="#b27">(28 )</ref> End If <ref type="bibr">(</ref>  composed of 10 sub-functions. The details of these 25 benchmark test functions have been given in <ref type="bibr" target="#b8">[9]</ref>.</p><p>In our experiments, the dimension (D) of each test function was set to 30 and each test function was independently run 25 times with 300,000 function evaluations (FES) as the termination criterion. All the experiments are performed on a computer with 2.4 GHz Dual-core Processor and 4.0 GB of RAM in Windows XP. The population size NP in CoBiDE was set to 60, pb = 0.4, and ps = 0.5.</p><p>In this section, the mean and standard deviation of the function error value (f ( x)f ( x * )) were calculated over 25 independent runs for each test function, where x is the best solution in the population when the algorithm terminates and x * is the global optimal solution. Wilcoxon's rank sum test at a 0.05 significance level was performed to test the statistical significance of the experimental results between two algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Comparison with other DE variants</head><p>CoBiDE was compared with four other DE variants: JADE <ref type="bibr" target="#b13">[14]</ref>, jDE <ref type="bibr" target="#b17">[18]</ref>, SaDE <ref type="bibr" target="#b7">[8]</ref>, and CoDE <ref type="bibr" target="#b22">[23]</ref>. These four algorithms have been briefly introduced in Section 3. JADE and jDE adopt self-adaptive parameter setting, and SaDE uses the normal distribution N(0.5, 0.3) to produce the scaling factor F and adjusts the crossover control parameter CR in a self-adaptive way. For the above four algorithms, we used the same parameter settings as given in their original papers. The experimental results of CoBiDE and other four algorithms are summarized in Table <ref type="table" target="#tab_2">1</ref>. It is necessary to emphasize that the experimental results of JADE, jDE, SaDE, and CoDE were directly taken from <ref type="bibr" target="#b22">[23]</ref> to ensure the comparison fair.</p><p>Table <ref type="table" target="#tab_2">1</ref> also records the Cohen's d effect size <ref type="bibr" target="#b30">[31]</ref> (within parentheses), which is a simple measure for quantifying the difference between two groups of data. The Cohen's d effect size is independent of the sample size. In general, we call a "small" effect if an effect size is between 0.2 and 0.3, a "medium" effect if an effect size is around 0.5, and a "large" effect if an effect size is from 0.8 to infinity <ref type="bibr" target="#b30">[31]</ref>. Concretely, for F 3 the effect size is equal to 1.63 when comparing JADE with CoBiDE, which means that the performance difference between JADE and CoBiDE is large and that JADE exhibits performance improvement. In contrast, for F 11 the effect size is equal to -10.36 when comparing JADE with CoBiDE, which means that the performance difference between JADE and CoBiDE is also large and that JADE shows performance deterioration. It is necessary to note that for some test functions, the differences between both the mean and the standard deviation are equal to 0 when comparing CoBiDE with another algorithm and, as a result, the corresponding effect size is denoted as NaN in Table <ref type="table" target="#tab_2">1</ref>. "-", "+", and "≈" denote that the performance of the corresponding algorithm is worse than, better than, and similar to that of CoBiDE, respectively. According to the last three lines of Table <ref type="table" target="#tab_2">1</ref>, overall CoBiDE is the best among the five algorithms. For five unimodal functions, CoBiDE is ranked the second, and for basic multimodal functions and hybrid composition functions, CoBiDE is more reliable than others. The superior performance of CoBiDE stems from two aspects: (1) the bimodal distribution parameter setting is capable of motivating the population toward promising directions, and (2) the covariance matrix learning is able to accelerate the convergence by exploiting the information provided by some potential individuals.</p><p>In addition, we also performed the multiple-problem Wilcoxon's test <ref type="bibr" target="#b31">[32]</ref> to check the behaviors of the above five algorithms. It is necessary to emphasize that the multiple-problem Wilcoxon's test was accomplished in this paper by using the KEEL software <ref type="bibr" target="#b32">[33]</ref>. Table <ref type="table" target="#tab_3">2</ref> summarizes the statistical analysis results. From Table <ref type="table" target="#tab_3">2</ref>, we can see that CoBiDE provides higher R+ values than R-values in all the cases. According to the Wilcoxon's test at ˛ = 0.05, the significant differences can be observed in two cases (i.e., CoBiDE vs jDE and CoBiDE vs SaDE). When ˛ = 0.1, the significant differences can be observed in three cases (i.e., CoBiDE vs jDE, CoBiDE vs SaDE, and CoBiDE vs CoDE), which means that To further detect the significant differences between CoBiDE and the four competitors, the Friedman's test was carried out, in which Bonferroni-Dunn's procedure was used as a post hoc procedure. Again, the Friedman's test was implemented based on the KEEL software <ref type="bibr" target="#b32">[33]</ref>. Table <ref type="table" target="#tab_4">3</ref> summarizes the ranking of the five algorithms obtained by the Friedman's test. As shown in Table <ref type="table" target="#tab_4">3</ref>, CoBiDE has the best ranking among the five algorithms on 25 test functions.</p><p>Since all the five compared algorithms are the DE variants, one may be interested in the execution time of them on different test functions. To this end, we recorded the average runtime of each algorithm on each test function over 25 independent runs in Table <ref type="table" target="#tab_6">4</ref>. In order to compare the average runtime, we used the acceleration rate (AR). For each test function, AR is equal to the average runtime of CoBiDE divided by the average runtime of another algorithm. AR &gt; 1 and AR &lt; 1 mean that CoBiDE is faster and slower than another corresponding algorithm, respectively. The last row of Table <ref type="table" target="#tab_6">4</ref> gives the average AR values. According to the average AR values, it is evident that JADE and jDE are faster than CoBiDE. In contrast, SaDE and CoDE are slower than CoBiDE. Moreover, based on our observation, the average AR values are 0.69 and 0.53 for 12 test functions (i.e., F 1 -F 10 , F 13 , and F 14 ) when comparing CoBiDE with JADE and jDE, respectively. For these 12 test functions, the computational cost of the function evaluation is relatively cheap, and thus, the computing of the covariance matrix leads to the additional burden of the runtime of CoBiDE. However, for the other 13 test functions (i.e., F 11 -F 12 and F 15 -F 25 ), the average AR values are 0.89 and 0.88 when comparing CoBiDE with JADE and jDE, respectively. For these 13 test functions, since the function evaluation is time-consuming, the overhead of computing the covariance matrix in CoBiDE seems to be trivial. Under these conditions, CoBiDE, JADE, and jDE have the similar average runtime. It is necessary to point out that we directly run the codes of the other four algorithms provided by the developers and the programming techniques of the developers also have a significant effect on the runtime.</p><p>The evolution of the mean function error values of the five algorithms in some typical test functions has been shown in Figs. <ref type="figure">3</ref> and<ref type="figure" target="#fig_3">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with other state-of-the-art EAs</head><p>CoBiDE was also compared with three other EAs: CLPSO <ref type="bibr" target="#b33">[34]</ref>, CMA-ES <ref type="bibr" target="#b24">[25]</ref>, and GL-25 <ref type="bibr" target="#b34">[35]</ref>. CLSPO, proposed by Liang et al., is an improved version of particle swarm optimization (PSO). In CLPSO, a novel learning strategy is proposed, in which all other particles' historical best information is used to update a particle's veloc-    respectively, and (2) their performance is very competitive. Table <ref type="table" target="#tab_7">5</ref> summarizes the experimental results of CoBiDE and the above three algorithms. The parameter settings of CLPSO, CMA-ES, and CLPSO were the same as in their original papers and the experimental result of them were directly taken from <ref type="bibr" target="#b22">[23]</ref> to make the comparison fair.</p><p>From Table <ref type="table" target="#tab_7">5</ref>, it is evident that, overall, CoBiDE is the best among the four compared algorithms in a statistically significant fashion. </p><formula xml:id="formula_17">F1 0.00E+00 ± 0.00E+00≈ 1.58E-25 ± 3.35E-26- 5.60E-27 ± 1.76E-26- 0.00E+00 ± 0.00E+00 F2 8.40E+02 ± 1.90E+02- 1.12E-24 ± 2.93E-25+ 4.04E+01 ± 6.28E+01- 1.60E-12 ± 2.90E-12 F3 1.42E+07 ± 4.19E+06- 5.54E-21 ± 1.69E-21+ 2.19E+06 ± 1.08E+06- 7.26E+04 ± 5.64E+04 F4 6.99E+03 ± 1.73E+03- 9.15E+05 ± 2.16E+06- 9.07E+02 ± 4.25E+02- 1.16E-03 ± 2.74E-03 F5 3.86E+03 ± 4.35E+02- 2.77E-10 ± 5.04E-11+ 2.51E+03 ± 1.96E+02- 8.03E+01 ± 1.51E+02 Basic multimodal functions F6 4.16E+00 ± 3.48E+00- 4.78E-01 ± 1.32E+00- 2.15E+01 ± 1.17E+00- 4.13E-02 ± 9.21E-02 F7 4.51E-01 ± 8.47E-02- 1.82E-03 ± 4.33E-03≈ 2.78E-02 ± 3.62E-02- 1.77E-03 ± 3.73E-03 F8 2.09E+01 ± 4.41E-02- 2.03E+01 ± 5.72E-01+ 2.09E+01 ± 5.94E-02- 2.07E+01 ± 3.75E-01 F9 0.00E+00 ± 0.00E+00≈ 4.45E+02 ± 7.12E+01- 2.45E+01 ± 7.35E+00- 0.00E+00 ± 0.00E+00 F10 1.04E+02 ± 1.53E+01- 4.63E+01 ± 1.16E+01≈ 1.42E+02 ± 6.45E+01- 4.41E+01 ± 1.29E+01 F11 2.60E+01 ± 1.63E+00- 7.11E+00 ± 2.14E+00- 3.27E+01 ± 7.79E+00- 5.62E+00 ± 2.19E+00 F12 1.79E+04 ± 5.24E+03- 1.26E+04 ± 1.74E+04- 6.53E+04 ± 4.69E+04- 2.94E+03 ± 3.93E+03 Expanded multimodal functions F13 2.06E+00 ± 2.15E-01+ 3.43E+00 ± 7.60E-01- 6.23E+00 ± 4.88E+00- 2.64E+00 ± 1.13E+00 F14 1.28E+01 ± 2.48E-01- 1.47E+01 ± 3.31E-01- 1.31E+01 ± 1.84E-01- 1.23E+01 ± 4.90E-01</formula><p>Hybrid composition functions</p><formula xml:id="formula_18">F15 5.77E+01 ± 2.76E+01+ 5.55E+02 ± 3.32E+02- 3.04E+02 ± 1.99E+01+ 4.04E+02 ± 5.03E+01 F16 1.74E+02 ± 2.82E+01- 2.98E+02 ± 2.08E+02- 1.32E+02 ± 7.60E+01- 7.38E+01 ± 3.66E+01 F17 2.46E+02 ± 4.81E+01- 4.43E+02 ± 3.34E+02- 1.61E+02 ± 6.80E+01- 7.25E+01 ± 2.02E+01 F18 9.13E+02 ± 1.42E+00- 9.04E+02 ± 3.01E-01- 9.07E+02 ± 1.48E+00- 9.03E+02 ± 1.05E+01 F19 9.14E+02 ± 1.45E+00- 9.16E+02 ± 6.03E+01- 9.06E+02 ± 1.24E+00- 9.03E+02 ± 1.04E+01 F20 9.14E+02 ± 3.62E+00- 9.04E+02 ± 2.71E-01+ 9.07E+02 ± 1.35E+00- 9.04E+02 ± 5.95E-01 F21 5.00E+02 ± 3.39E-13≈ 5.00E+02 ± 2.68E-12- 5.00E+02 ± 4.83E-13≈ 5.00E+02 ± 4.62E-13 F22 9.72E+02 ± 1.20E+01- 8.26E+02 ± 1.46E+01+ 9.28E+02 ± 7.04E+01- 8.62E+02 ± 2.80E+01 F23 5.34E+02 ± 2.19E-04- 5.36E+02 ± 5.44E+00- 5.34E+02 ± 4.66E-04- 5.34E+02 ± 1.30E-04 F24 2.00E+02 ± 1.49E-12- 2.12E+02 ± 6.00E+01- 2.00E+02 ± 5.52E-11- 2.00E+02 ± 2.85E-14 F25 2.00E+02 ± 1.96E+00+ 2.07E+02 ± 6.07E+00≈ 2.17E+02 ± 1.36E-01- 2.10E+02 ± 7.73E-01 - 19 16 23 + 3 6 1 ≈<label>3 3 1</label></formula><p>"-", "+", and "≈" denote that the performance of the corresponding algorithm is worse than, better than, and similar to that of CoBiDE, respectively.</p><p>Specifically, CoBiDE outperforms CLPSO on 19 test functions and is worse than CLPSO on three test functions. CMA-ES surpasses CoBiDE on three unimodal functions; however, CoBiDE is significantly better than CMA-ES on three other types of test functions.</p><p>Compared with GL-25, CoBiDE shows better and worse performance on 23 test functions and one test function, respectively. In addition, some interesting phenomena can be observed according to the experimental results in Table <ref type="table" target="#tab_7">5</ref>. For separable functions (i.e., F 1 and F 9 ), the performance of CLPSO is significantly better than that of the other algorithms except for CoBiDE. Moreover, CLPSO also outperforms the other algorithms on F 15 which is separable near the global optimum <ref type="bibr" target="#b8">[9]</ref>. The superiority of CLPSO in separable functions is mainly due to the dimension-wise updating rules for velocity and position in PSO. CMA-ES performs quite well on some unimodal functions, which means the convergence speed of CMA-ES is very fast. Moreover, CMA-ES outperforms the other algorithms on test functions with high condition numbers, i.e., F 3 and F 22 . It is because CMA-ES has the capability to adapt the population distribution according to the landscape of test functions. However, the performance of CMA-ES is not good when solving some multimodal functions, especially for test functions with noise, i.e., F 4 and F 17 . Therefore, we can conclude that CMA-ES is sensitive to the noise. In contrast, CoBiDE shows the best performance on test functions with noise.</p><p>Tables <ref type="table" target="#tab_8">6</ref> and<ref type="table" target="#tab_9">7</ref> also present the statistical analysis results according to the multiple-problem Wilcoxon's test and the Friedman's   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">The effectiveness of the two components in CoBiDE</head><p>As mentioned previously, CoBiDE includes two main components: the covariance matrix learning and the bimodal distribution parameter setting. The aim of this subsection is to verify the effectiveness of the above two components. To this end, two additional experiments were executed for 25 benchmark test functions. In the first experiment, CoBiDE only adopts the covariance matrix learning and the bimodal distribution parameter setting is not used (denoted as CoBiDE-1). In this case, like <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20]</ref>, F and CR were fixed to 0.5 and 0.9 during the evolution, respectively. In addition, in the second experiment, CoBiDE only adopts the bimodal distribution parameter setting and the covariance matrix learning is ignored (denoted as CoBiDE-2). It is necessary to note that for CoBiDE-2,  Step 19 in Fig. <ref type="figure">3</ref> can be eliminated and only the crossover operator of the original DE (i.e., Eq. ( <ref type="formula" target="#formula_18">3</ref>)) is employed.</p><p>For each test function, 25 independent runs were implemented and the maximum number of FES was set to 300,000. The experimental results of CoBiDE-1, CoBiDE-2, and CoBiDE have been shown in Table <ref type="table" target="#tab_10">8</ref>.</p><p>From Table <ref type="table" target="#tab_10">8</ref>, CoBiDE surpasses CoBiDE-1 on 18 test functions. We attribute the above phenomenon to the fact that the fixed parameter setting could not adjust the search behavior to suit different landscapes, and that the bimodal distribution parameter setting is more effective to balance the exploration and exploitation during the evolution. In addition, CoBiDE-1 outperforms CoBiDE on three test functions (i.e., F 4 , F 13 , and F 19 ). According to our further experiments, we found out that the parameter setting of F = 0.5 and CR = 0.9 provides best or near-best performance for these three test functions, which means that the above parameter setting happens to be very suitable for these three test functions.</p><p>In addition, compared with CoBiDE, CoBiDE-2 shows worse performance on 13 test functions, and cannot show better performance on any test functions. It is not difficult to understand, since the covariance matrix learning is not dependent on the coordinate system when implementing the crossover operator. As a result, it has the capability to adapt the search according to different landscapes. Moreover, once some potential regions have been located, it can accelerate the convergence speed and enhance the convergence accuracy of the population for different kinds of test functions, due to the use of the population information to construct more suitable coordinate system. It is also interesting to note that for 12 test functions (F 1 , F 8 -F 10 , F 12 -F 13 , F 15 , F 20 -F 23 , and F 25 ), the performance differences between CoBiDE and CoBiDE-2 are marginal. These 12 test functions can be divided into two categories: F 1 and F 9 belong to the first category, and the remaining 10 test functions belong to the second category. For F 1 and F 9 , both CoBiDE and CoBiDE-2 can consistently reach the global optimum, and thus, "-", "+", and "≈" denote that the performance of the corresponding algorithm is worse than, better than, and similar to that of CoBiDE, respectively. the performance differences between CoBiDE and CoBiDE-2 are not significant. In addition, since CoBiDE might be easily trapped into a local optimum and the covariance matrix learning cannot help the population jump out of the local optimum, the insignificant performance differences occur for CoBiDE and CoBiDE-2 on the remaining 10 test functions.</p><p>From Table <ref type="table" target="#tab_10">8</ref>, we can conclude that the above two components can benefit each other to enhance the performance of DE. Indeed, the bimodal distribution parameter setting achieves high reliability and the covariance matrix learning results in fast convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Sensitivity in relation to the parameters pb and ps</head><p>CoBiDE contains two parameters pb and ps. The former controls the computational resource assigned to the covariance matrix learning and the latter controls the number of individuals for computing the covariance matrix.</p><p>In order to investigate the sensitivity of the above two parameters, we tested CoBiDE with different pb: 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, and 1, and different ps: 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, and 1.0. Seven test functions (i.e., F 3 , F 4 , F 6 , F 9 , F 10 , F 13 , and F 14 ) were selected to test the performance of CoBiDE with different combinations of pb and ps. These test functions involve shifted problems, problems with noise, rotated problems, and high conditioned problems. The dimension was set to 30 for all the test functions and the maximum number of FES was set to 300,000. Fig. <ref type="figure" target="#fig_5">5</ref> shows the average function error values of CoBiDE with different combinations of pb and ps.</p><p>Generally speaking, a larger value of pb may discourage the diversity of the population, however, if the value of pb is too small, the covariance matrix learning cannot play its role in solving problems with high variable correlation. On the other hand, if ps is set to a larger value, the randomness of the population may cause side effect on the computation of the covariance matrix. However, if the value of ps is too small, the chosen individuals cannot reflect the statistical information of the population. Therefore, moderate values should be chosen for these two parameters in order to achieve competitive performance.</p><p>From Fig. <ref type="figure" target="#fig_5">5</ref>, we can observe that, actually, CoBiDE is not sensitive to these two parameters, and that pb and ps can be chosen from a relatively large range to achieve competitive performance for CoBiDE. In general, the value of pb is recommended in the interval [0.2, 0.7] and the value of ps is recommended in the interval [0.3, 0.7].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Real-world application problems</head><p>Besides the above 25 benchmark test functions, eight real-world engineering optimization problems chosen from different fields including radar system, power systems, hydrothermal scheduling, spacecraft trajectory optimization, etc., were used to evaluate the performance of CoBiDE in this subsection. These eight real-world engineering optimization problems (denoted as P 1 -P 8 in this paper) are problems T01, T06, T08, T10.1, T11.4, T12.1, T12.2, and T13 collected for the 2011 IEEE Congress on Evolutionary Computation (IEEE CEC2011) <ref type="bibr" target="#b9">[10]</ref>, respectively, which exhibit different complex characteristics and are very difficult to solve. For each problem, 25 independently runs were implemented with 150,000 FES as the termination criterion. The parameter settings of CoBiDE were the same with those for the 25 benchmark test functions, i.e., NP = 60, pb = 0.4, and ps = 0.5. In addition, the parameter settings of JADE, jDE, SaDE, and CoDE were the same as in their original papers.</p><p>Table <ref type="table" target="#tab_11">9</ref> summarizes the mean and standard deviation of the objective function values over 25 independent runs for each problem. In order to have statistically sound conclusions, Wilcoxon's rank sum test at a 0.05 significance level was conducted on the "-", "+", and "≈" denote that the performance of the corresponding algorithm is worse than, better than, and similar to that of CoBiDE, respectively. By making use of the KEEL software <ref type="bibr" target="#b32">[33]</ref>, the multipleproblem Wilcoxon's test and the Friedman's test have been implemented. The experimental results have been summarized in Tables <ref type="table" target="#tab_12">10</ref> and<ref type="table" target="#tab_13">11</ref>. As shown in Table <ref type="table" target="#tab_12">10</ref>, CoBiDE shows higher R+ values than R-values in all the cases. Moreover, the p values less than 0.05 and 0.1 in three cases (i.e., CoBiDE vs JADE, CoBiDE vs jDE, and CoBiDE vs SaDE). In addition, CoBiDE has the best ranking according to Table <ref type="table" target="#tab_13">11</ref>.</p><p>Therefore, the above experimental results verify the potential of CoBiDE in the real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>During the past fifteen years, differential evolution (DE) which is an efficient and robust evolutionary algorithm has become a hotspot in the community of evolutionary computation. In order to improve the performance of DE, CoBiDE, a DE variant based on covariance matrix learning and bimodal distribution parameter setting, is presented in this paper.</p><p>In CoBiDE, Eigen decomposition is applied to the covariance matrix computed according to the current population, the purpose of which is to establish an Eigen coordinate system for the crossover operator. The covariance matrix learning relaxes the dependence of DE on the coordinate system to a certain degree and improves the performance on problems with high variable correlation. Moreover, the bimodal distribution parameter setting is introduced for the scaling factor F and the crossover control parameter CR. The bimodal distribution for both F and CR is composed of two Cauchy distributions. CoBiDE has been tested on 25 benchmark test functions developed for IEEE CEC2005 and eight complex real-world engineering optimization problems collected for IEEE CEC2011. The experimental results suggest that the performance of CoBiDE is better than that of four other DE variants and three other stateof-the-art EAs. The experimental results also verify that both the covariance matrix learning and the bimodal distribution parameter setting are critical for CoBiDE. Finally, the parameter sensitivity of CoBiDE has been studied experimentally.</p><p>The Matlab source code of CoBiDE can be downloaded from Y. Wang's homepage: http://ist.csu.edu.cn/YongWang.htm</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Crossover in the original coordinate system (i.e., ox1x2) and in the Eigen coordinate system (i.e., ox 1 x 2 ), where x i,G is a target vector in the population, v i,G is its mutant</figDesc><graphic coords="5,113.45,55.64,357.60,185.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Pseudocode of CoBiDE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>ity. CMA-ES, proposed by Hansen and Ostermeier, is an evolution strategy (ES) based on completely derandomized self-adaptation. GL-25, proposed by Garcia-Martinez et al., is a global and local realcoded genetic algorithm (GA) based on parent-centric crossover operators. The reasons of the selection of these three algorithms in comparison are twofold: (1) CLPSO, CMA-ES, and GL-25 represent the state-of-the-art in PSO, ES, and GA, respectively. According to the Google Scholar Citation, as of December 20, 2013, the number of citations of CLPSO, CMA-ES, and GL-25 is 1011, 1332, and 81</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Evolution of the mean function error values derived from JADE, jDE, SaDE, CoDE, and CoBiDE versus the number of FES on F9, F10, F11, F12, F13, F14, F16, and F17.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>F 9 Fig. 5 .</head><label>95</label><figDesc>Fig. 5. The average function error values of CoBiDE with different combinations of pb and ps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. (Continued ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Moreover, F 4 and F 17 are used to test the robustness of the algorithm on noise. F 15 -F 25 are hybrid composition functions which are Inpu t: NP: the number of individ ual s con tained by the pop ulatio n MAX_FES: maximum number of func tion ev alu ations pb: the probability to execute DE according to the covariance matrix learning ps: the proportion of the individuals chosen from the current population to calculate the covariance matrix</figDesc><table><row><cell>(1) G=0;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2) Generate an initial populati on 0 P</cell><cell>1,0 { , , x</cell><cell>x</cell><cell>NP</cell><cell>,0</cell><cell>}</cell><cell>by randomly sampli ng from the search space;</cell></row><row><cell cols="7">(3) Evaluate the objective function values of each individual (i.e., each target vector) in P0;</cell></row><row><cell cols="7">(4) FES=NP; /* FES records the number of function evaluations */</cell></row><row><cell cols="7">(5) Generate the initial scaling factor Fi,0 and crossover control parameter CRi,0 ( {1, , } i NP ) for each target vector</cell><cell>i</cell><cell>,0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>the indi vid ual with the smallest objecti ve function value in the populatio n</figDesc><table><row><cell>29 )</cell><cell>n E</cell><cell>d</cell><cell>F</cell><cell>o</cell><cell>r</cell></row><row><cell>(30 )</cell><cell cols="5">FES=FES+NP;</cell></row><row><cell>(31 )</cell><cell cols="5">G=G+1;</cell></row><row><cell cols="4">(32 ) End While</cell><cell></cell><cell></cell></row><row><cell>Output:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Experimental results of JADE, jDE, SaDE, CoDE, and CoBiDE over 25 independent runs on 25 test functions of 30 variables with 300,000 FES. "Mean Error" and "Std Dev" indicate the average and standard deviation of the function error values obtained in 25 runs, respectively. Wilcoxon's rank sum test at a 0.05 significance level is performed between CoBiDE and each of JADE, jDE, SaDE, and CoDE. The effect size is shown in the parentheses.</figDesc><table><row><cell>Function</cell><cell></cell><cell>JADE Mean Error ± Std Dev</cell><cell>jDE Mean Error ± Std Dev</cell><cell>SaDE Mean Error ± Std Dev</cell><cell>CoDE Mean Error ± Std Dev</cell><cell>CoBiDE Mean Error ± Std Dev</cell></row><row><cell></cell><cell>F1</cell><cell>0.00E+00 ± 0.00E+00≈ (NaN)</cell><cell>0.00E+00 ± 0.00E+00≈ (NaN)</cell><cell>0.00E+00 ± 0.00E+00≈ (NaN)</cell><cell>0.00E+00 ± 0.00E+00≈ (NaN)</cell><cell>0.00E+00 ± 0.00E+00</cell></row><row><cell></cell><cell>F2</cell><cell>1.07E-28 ± 1.00E-28+ (0.80)</cell><cell>1.11E-06 ± 1.96E-06-(-0.82)</cell><cell>8.26E-06 ± 1.65E-05-(-0.72)</cell><cell>1.69E-15 ± 3.95E-15+ (0.80)</cell><cell>1.60E-12 ± 2.90E-12</cell></row><row><cell>Unimodal functions</cell><cell>F3</cell><cell>8.42E+03 ± 7.26E+03+ (1.63)</cell><cell>1.98E+05 ± 1.10E+05-(-1.46)</cell><cell>4.27E+05 ± 2.08E+05-(-2.37)</cell><cell>1.05E+05 ± 6.25E+04-(-0.56)</cell><cell>7.26E+04 ± 5.64E+04</cell></row><row><cell></cell><cell>F4</cell><cell>1.73E-16 ± 5.43E-16+ (0.61)</cell><cell>4.40E-02 ± 1.26E-01-(-0.49)</cell><cell>1.77E+02 ± 2.67E+02-(-0.96)</cell><cell>5.81E-03 ± 1.38E-02-(-0.48)</cell><cell>1.16E-03 ± 2.74E-03</cell></row><row><cell></cell><cell>F5</cell><cell>8.59E-08 ± 5.23E-07+ (0.77)</cell><cell>5.11E+02 ± 4.40E+02-(-1.33)</cell><cell>3.25E+03 ± 5.90E+02-(-7.51)</cell><cell>3.31E+02 ± 3.44E+02-(-0.96)</cell><cell>8.03E+01 ± 1.51E+02</cell></row><row><cell></cell><cell>F6</cell><cell>1.02E+01 ± 2.96E+01-(-0.50)</cell><cell>2.35E+01 ± 2.50E+01-(-1.35)</cell><cell>5.31E+01 ± 3.25E+01-(-2.36)</cell><cell>1.60E-01 ± 7.85E-01-(-0.22)</cell><cell>4.13E-02 ± 9.21E-02</cell></row><row><cell></cell><cell>F7</cell><cell>8.07E-03 ± 7.42E-03-(-1.09)</cell><cell>1.18E-02 ± 7.78E-03-(-1.68)</cell><cell>1.57E-02 ± 1.38E-02-(-1.40)</cell><cell>7.46E-03 ± 8.55E-03-(-0.88)</cell><cell>1.77E-03 ± 3.73E-03</cell></row><row><cell></cell><cell>F8</cell><cell>2.09E+01 ± 1.68E-01-(-0.70)</cell><cell>2.09E+01 ± 4.86E-02-(-0.76)</cell><cell>2.09E+01 ± 4.95E-02-(-0.76)</cell><cell>2.01E+01 ± 1.41E-01+ (2.16)</cell><cell>2.07E+01 ± 3.75E-01</cell></row><row><cell>Basic multimodal functions</cell><cell>F9</cell><cell>0.00E+00 ± 0.00E+00≈ (NaN)</cell><cell>0.00E+00 ± 0.00E+00≈ (NaN)</cell><cell>2.39E-01 ± 4.33E-01-(-0.80)</cell><cell>0.00E+00 ± 0.00E+00≈ (NaN)</cell><cell>0.00E+00 ± 0.00E+00</cell></row><row><cell></cell><cell>F10</cell><cell>2.41E+01 ± 4.61E+00+ (1.69)</cell><cell>5.54E+01 ± 8.46E+00-(-1.43)</cell><cell>4.72E+01 ± 1.01E+01≈ (-0.62)</cell><cell>4.15E+01 ± 1.16E+01≈ (-0.12)</cell><cell>4.41E+01 ± 1.29E+01</cell></row><row><cell></cell><cell>F11</cell><cell>2.53E+01 ± 1.65E+00-(-10.36)</cell><cell>2.79E+01 ± 1.61E+00-(-11.83)</cell><cell>1.65E+01 ± 2.42E+00-(-4.81)</cell><cell>1.18E+01 ± 3.40E+00-(-2.21)</cell><cell>5.62E+00 ± 2.19E+00</cell></row><row><cell></cell><cell>F12</cell><cell>6.15E+03 ± 4.79E+03-(-0.75)</cell><cell>8.63E+03 ± 8.31E+03-(-0.89)</cell><cell>3.02E+03 ± 2.33E+03≈ (-0.02)</cell><cell>3.05E+03 ± 3.80E+03≈ (-0.03)</cell><cell>2.94E+03 ± 3.93E+03</cell></row><row><cell>Expanded multimodal</cell><cell>F13</cell><cell>1.49E+00 ± 1.09E-01+ (1.46)</cell><cell>1.66E+00 ± 1.35E-01+ (1.24)</cell><cell>3.94E+00 ± 2.81E-01-(-1.61)</cell><cell>1.57E+00 ± 3.27E-01+ (1.31)</cell><cell>2.64E+00 ± 1.13E+00</cell></row><row><cell>functions</cell><cell>F14</cell><cell>1.23E+01 ± 3.11E-01≈ (0)</cell><cell>1.30E+01 ± 2.00E-01-(-1.91)</cell><cell>1.26E+01 ± 2.83E-01-(-0.77)</cell><cell>1.23E+01 ± 4.81E-01≈ (0)</cell><cell>1.23E+01 ± 4.90E-01</cell></row><row><cell></cell><cell>F15</cell><cell>3.51E+02 ± 1.28E+02+ (0.56)</cell><cell>3.77E+02 ± 8.02E+01+ (0.41)</cell><cell>3.76E+02 ± 7.83E+01≈ (0.43)</cell><cell>3.88E+02 ± 6.85E+01≈ (0.27)</cell><cell>4.04E+02 ± 5.03E+01</cell></row><row><cell></cell><cell>F16</cell><cell>1.01E+02 ± 1.24E+02-(-0.30)</cell><cell>7.94E+01 ± 2.96E+01-(-0.17)</cell><cell>8.57E+01 ± 6.94E+01-(-0.21)</cell><cell>7.37E+01 ± 5.13E+01≈ (0.00)</cell><cell>7.38E+01 ± 3.66E+01</cell></row><row><cell></cell><cell>F17</cell><cell>1.47E+02 ± 1.33E+02-(-0.80)</cell><cell>1.37E+02 ± 3.80E+01-(-2.16)</cell><cell>7.83E+01 ± 3.76E+01≈ (-0.20)</cell><cell>6.67E+01 ± 2.12E+01+ (0.29)</cell><cell>7.25E+01 ± 2.02E+01</cell></row><row><cell></cell><cell>F18</cell><cell>9.04E+02 ± 1.03E+00≈ (-0.14)</cell><cell>9.04E+02 ± 1.08E+01≈ (-0.10)</cell><cell>8.68E+02 ± 6.23E+01≈ (0.80)</cell><cell>9.04E+02 ± 1.04E+00-(-0.14)</cell><cell>9.03E+02 ± 1.05E+01</cell></row><row><cell>Hybrid composition functions</cell><cell>F19 F20 F21</cell><cell>9.04E+02 ± 8.40E-01≈ (-0.14) 9.04E+02 ± 8.47E-01≈ (0) 5.00E+02 ± 4.67E-13≈ (0)</cell><cell>9.04E+02 ± 1.11E+00≈ (-0.14) 9.04E+02 ± 1.10E+00≈ (0) 5.00E+02 ± 4.80E-13≈ (0)</cell><cell>8.74E+02 ± 6.22E+01≈ (0.66) 8.78E+02 ± 6.03E+01+ (0.62) 5.52E+02 ± 1.82E+02-(-0.41)</cell><cell>9.04E+02 ± 9.42E-01-(-0.14) 9.04E+02 ± 9.01E-01-(0) 5.00E+02 ± 4.88E-13≈ (0)</cell><cell>9.03E+02 ± 1.04E+01 9.04E+02 ± 5.95E-01 5.00E+02 ± 4.62E-13</cell></row><row><cell></cell><cell>F22</cell><cell>8.66E+02 ± 1.91E+01≈ (-0.17)</cell><cell>8.75E+02 ± 1.91E+01-(-0.55)</cell><cell>9.36E+02 ± 1.83E+01-(-3.19)</cell><cell>8.63E+02 ± 2.43E+01≈ (-0.04)</cell><cell>8.62E+02 ± 2.80E+01</cell></row><row><cell></cell><cell>F23</cell><cell>5.50E+02 ± 8.05E+01-(-0.29)</cell><cell>5.34E+02 ± 2.77E-04-(0)</cell><cell>5.34E+02 ± 3.57E-03-(0)</cell><cell>5.34E+02 ± 4.12E-04-(0)</cell><cell>5.34E+02 ± 1.30E-04</cell></row><row><cell></cell><cell>F24</cell><cell>2.00E+02 ± 2.85E-14≈ (0)</cell><cell>2.00E+02 ± 2.85E-14≈ (0)</cell><cell>2.00E+02 ± 6.20E-13≈ (0)</cell><cell>2.00E+02 ± 2.85E-14≈ (0)</cell><cell>2.00E+02 ± 2.85E-14</cell></row><row><cell></cell><cell>F25</cell><cell>2.11E+02 ± 7.92E-01-(-1.30)</cell><cell>2.11E+02 ± 7.32E-01-(-1.36)</cell><cell>2.14E+02 ± 2.00E+00-(-2.69)</cell><cell>2.11E+02 ± 9.02E-01-(-1.21)</cell><cell>2.10E+02 ± 7.73E-01</cell></row><row><cell>-</cell><cell></cell><cell>9</cell><cell>16</cell><cell>16</cell><cell>11</cell><cell></cell></row><row><cell>+</cell><cell></cell><cell>7</cell><cell>2</cell><cell>1</cell><cell>4</cell><cell></cell></row><row><cell>≈</cell><cell></cell><cell>9</cell><cell>7</cell><cell>8</cell><cell>10</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Results of the multiple-problem Wilcoxon's test for JADE, jDE, SaDE, CoDE, and CoBiDE at a 0.05 significance level and at a 0.1 significance level. Unimodal functions F 1 -F 5 : JADE exhibits the best performance on five unimodal functions among the five algorithms. Evidently, the greedy mutation operator, i.e., current-to-pbest/1, results in the fast convergence speed and high convergence precision of JADE under these conditions. CoBiDE is outperformed by JADE on four test functions and surpasses jDE, SaDE, and CoDE on four, four, and three test functions, respectively. jDE and SaDE cannot show better performance than CoBiDE on any test functions and CoDE performs better than CoBiDE on only one test function. Therefore, the performance of CoBiDE is the second best in terms of these five unimodal functions. (2) Basic multimodal functions F 6 -F 12 : Clearly, CoBiDE has the best performance on this kind of test functions. CoBiDE has an edge</figDesc><table><row><cell>Algorithm</cell><cell>R+</cell><cell>R-</cell><cell>p-Value</cell><cell>˛ = 0.05</cell><cell>˛ = 0.1</cell></row><row><cell>CoBiDE vs JADE</cell><cell>209.0</cell><cell>116.0</cell><cell>0.206006</cell><cell>No</cell><cell>No</cell></row><row><cell>CoBiDE vs jDE</cell><cell>263.0</cell><cell>37.0</cell><cell>0.001183</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>CoBiDE vs SaDE</cell><cell>252.5</cell><cell>72.5</cell><cell>0.014889</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>CoBiDE vs CoDE</cell><cell>213.0</cell><cell>87.0</cell><cell>0.069634</cell><cell>No</cell><cell>Yes</cell></row><row><cell cols="6">The last three lines of Table 1 summarize the experimental</cell></row><row><cell>results:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(1)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>over JADE, jDE, SaDE, and CoDE on five, six, five, and three test functions, respectively. JADE and CoDE are statistically better than CoBiDE on one test function, and jDE and SaDE cannot outperform CoBiDE on any test functions. The outstanding performance of CoBiDE can be attributed to its capability to balance the exploration and exploitation. (3) Expanded multimodal functions F 13 -F 14 : The mean function error values of all the algorithms are of the same order of magnitude on F 13 and F 14 . JADE and CoDE are statistically better than CoBiDE. CoBiDE exhibits the similar performance with jDE. In addition, CoBiDE outperforms SaDE on these two test functions. (4) Hybrid composition functions F 15 -F 25 : The solution of these 11 test functions is much more difficult than that of other test functions. For these 11 test functions, the results provided by the five algorithms are far way from the global optima. However, from Table 1, we can still observe that the performance of CoBiDE is superior to that of the other four algorithms according to the Wilcoxon's rank sum test.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Ranking of JADE, jDE, SaDE, CoDE, and CoBiDE according to the statistical test of the Friedman test.</figDesc><table><row><cell>Algorithm</cell><cell>Ranking</cell></row><row><cell>CoBiDE</cell><cell>2.08</cell></row><row><cell>CoDE</cell><cell>2.64</cell></row><row><cell>JADE</cell><cell>2.84</cell></row><row><cell>SaDE</cell><cell>3.64</cell></row><row><cell>jDE</cell><cell>3.8</cell></row><row><cell cols="2">CoBiDE is significantly better than jDE, SaDE, and CoDE on 25 test</cell></row><row><cell>functions at ˛ = 0.1.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Comparison of the average runtime (in s) of JADE, jDE, SaDE, CoDE, and CoBiDE for each test function. AR denotes the acceleration rate and the last row of the table represents the average AR.</figDesc><table><row><cell>Function</cell><cell></cell><cell>JADE</cell><cell>jDE</cell><cell>SaDE</cell><cell>CoDE</cell><cell>CoBiDE</cell></row><row><cell></cell><cell>F1</cell><cell>3.74</cell><cell>2.43</cell><cell>39.14</cell><cell>8.93</cell><cell>4.91</cell></row><row><cell></cell><cell>F2</cell><cell>3.77</cell><cell>2.82</cell><cell>35.65</cell><cell>9.53</cell><cell>5.64</cell></row><row><cell>Unimodal functions</cell><cell>F3</cell><cell>3.82</cell><cell>2.83</cell><cell>36.51</cell><cell>12.49</cell><cell>5.26</cell></row><row><cell></cell><cell>F4</cell><cell>3.83</cell><cell>3.07</cell><cell>32.63</cell><cell>9.89</cell><cell>5.91</cell></row><row><cell></cell><cell>F5</cell><cell>4.59</cell><cell>3.74</cell><cell>36.21</cell><cell>11.12</cell><cell>6.28</cell></row><row><cell></cell><cell>F6</cell><cell>3.36</cell><cell>2.37</cell><cell>34.31</cell><cell>9.29</cell><cell>5.07</cell></row><row><cell></cell><cell>F7</cell><cell>3.48</cell><cell>2.73</cell><cell>32.36</cell><cell>8.28</cell><cell>5.03</cell></row><row><cell></cell><cell>F8</cell><cell>4.14</cell><cell>3.52</cell><cell>36.36</cell><cell>12.33</cell><cell>5.94</cell></row><row><cell>Basic multimodal functions</cell><cell>F9</cell><cell>3.47</cell><cell>2.69</cell><cell>35.40</cell><cell>9.82</cell><cell>5.36</cell></row><row><cell></cell><cell>F10</cell><cell>4.07</cell><cell>3.21</cell><cell>35.50</cell><cell>9.98</cell><cell>5.31</cell></row><row><cell></cell><cell>F11</cell><cell>67.34</cell><cell>67.31</cell><cell>109.46</cell><cell>80.76</cell><cell>70.74</cell></row><row><cell></cell><cell>F12</cell><cell>19.56</cell><cell>19.23</cell><cell>52.92</cell><cell>28.66</cell><cell>24.40</cell></row><row><cell>Expanded multimodal</cell><cell>F13</cell><cell>4.22</cell><cell>3.23</cell><cell>33.65</cell><cell>10.03</cell><cell>6.57</cell></row><row><cell>functions</cell><cell>F14</cell><cell>5.00</cell><cell>4.28</cell><cell>39.34</cell><cell>13.74</cell><cell>7.21</cell></row><row><cell></cell><cell>F15</cell><cell>152.24</cell><cell>155.58</cell><cell>245.17</cell><cell>179.93</cell><cell>171.61</cell></row><row><cell></cell><cell>F16</cell><cell>158.03</cell><cell>152.60</cell><cell>215.81</cell><cell>175.75</cell><cell>169.60</cell></row><row><cell></cell><cell>F17</cell><cell>149.77</cell><cell>153.18</cell><cell>222.27</cell><cell>209.18</cell><cell>165.98</cell></row><row><cell></cell><cell>F18</cell><cell>162.03</cell><cell>160.15</cell><cell>227.57</cell><cell>230.69</cell><cell>176.28</cell></row><row><cell>Hybrid composition functions</cell><cell>F19 F20 F21</cell><cell>163.59 162.14 159.13</cell><cell>155.65 158.16 155.38</cell><cell>212.93 226.92 227.15</cell><cell>193.63 186.80 178.51</cell><cell>180.76 177.43 183.83</cell></row><row><cell></cell><cell>F22</cell><cell>204.95</cell><cell>203.20</cell><cell>277.54</cell><cell>233.41</cell><cell>222.01</cell></row><row><cell></cell><cell>F23</cell><cell>158.61</cell><cell>157.33</cell><cell>242.07</cell><cell>183.79</cell><cell>180.15</cell></row><row><cell></cell><cell>F24</cell><cell>104.40</cell><cell>107.61</cell><cell>199.99</cell><cell>128.66</cell><cell>125.99</cell></row><row><cell></cell><cell>F25</cell><cell>120.10</cell><cell>115.51</cell><cell>215.87</cell><cell>136.15</cell><cell>131.38</cell></row><row><cell>Average AR</cell><cell></cell><cell>0.80</cell><cell>0.72</cell><cell>3.77</cell><cell>1.45</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Experimental results of CLPSO, CMA-ES, GL-25, and CoBiDE over 25 independent runs on 25 test functions of 30 variables with 300,000 FES. "Mean Error" and "Std Dev" indicate the average and standard deviation of the function error values obtained in 25 runs, respectively. Wilcoxon's rank sum test at a 0.05 significance level is performed between CoBiDE and each of CLPSO, CMA-ES, and GL-25.</figDesc><table><row><cell>Function</cell><cell>CLPSO Mean Error ± Std Dev</cell><cell>CMA-ES Mean Error ± Std Dev</cell><cell>GL-25 Mean Error ± Std Dev</cell><cell>CoBiDE Mean Error ± Std Dev</cell></row><row><cell>Unimodal functions</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Results of the multiple-problem Wilcoxon's test for CLPSO, CMA-ES, GL-25, and CoBiDE at a 0.05 significance level and at a 0.1 significance level.</figDesc><table><row><cell>Algorithm</cell><cell>R+</cell><cell>R-</cell><cell>p-Value</cell><cell>˛ = 0.05</cell><cell>˛ = 0.1</cell></row><row><cell>CoBiDE vs CLPSO</cell><cell>257.0</cell><cell>43.0</cell><cell>0.001834</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>CoBiDE vs CMA-ES</cell><cell>241.5</cell><cell>83.5</cell><cell>0.032428</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>CoBiDE vs GL-25</cell><cell>279.5</cell><cell>20.5</cell><cell>0.000193</cell><cell>Yes</cell><cell>Yes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc>Ranking of CLPSO, CMA-ES, GL-25, and CoBiDE according to the statistical test of the Friedman test. It can be seen from Table6that CoBiDE obtains higher R+ values than R-values in all the cases. Furthermore, the p values of all the cases are less than 0.05. On the other hand, the experimental results in Table7indicate that CoBiDE has the best ranking among the four compared algorithms. In summary, the above comparison clearly demonstrates that CoBiDE is significantly better than the three competitors.</figDesc><table><row><cell>Algorithm</cell><cell>Ranking</cell></row><row><cell>CoBiDE</cell><cell>1.62</cell></row><row><cell>CMA-ES</cell><cell>2.6</cell></row><row><cell>CLPSO</cell><cell>2.84</cell></row><row><cell>GL-25</cell><cell>2.94</cell></row><row><cell>test, respectively.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8</head><label>8</label><figDesc>Experimental results of CoBiDE-1, CoBiDE-2, and CoBiDE over 25 independent runs on 25 test functions of 30 variables with 300,000 FES. "Mean Error" and "Std Dev" indicate the average and standard deviation of the function error values obtained in 25 runs, respectively. Wilcoxon's rank sum test at a 0.05 significance level is performed between CoBiDE and each of CoBiDE-1 and CoBiDE-2.</figDesc><table><row><cell>Function</cell><cell></cell><cell>CoBiDE-1 Mean Error ± Std Dev</cell><cell>CoBiDE-2 Mean Error ± Std Dev</cell><cell>CoBiDE Mean Error ± Std Dev</cell></row><row><cell></cell><cell>F1</cell><cell>1.54E-28 ± 1.35E-28-</cell><cell>0.00E+00 ± 0.00E+00≈</cell><cell>0.00E+00 ± 0.00E+00</cell></row><row><cell></cell><cell>F2</cell><cell>3.95E-12 ± 5.32E-12≈</cell><cell>2.07E-06 ± 3.69E-06-</cell><cell>1.60E-12 ± 2.90E-12</cell></row><row><cell>Unimodal functions</cell><cell>F3</cell><cell>3.25E+05 ± 1.84E+05-</cell><cell>2.46E+05 ± 1.45E+05-</cell><cell>7.26E+04 ± 5.64E+04</cell></row><row><cell></cell><cell>F4</cell><cell>5.43E-04 ± 1.28E-03+</cell><cell>6.39E-02 ± 6.77E-02-</cell><cell>1.16E-03 ± 2.74E-03</cell></row><row><cell></cell><cell>F5</cell><cell>7.58E+02 ± 5.56E+02-</cell><cell>1.29E+02 ± 2.67E+02-</cell><cell>8.03E+01 ± 1.51E+02</cell></row><row><cell></cell><cell>F6</cell><cell>4.09E+01 ± 3.60E+01-</cell><cell>1.66E+00 ± 1.02E+00-</cell><cell>4.13E-02 ± 9.21E-02</cell></row><row><cell></cell><cell>F7</cell><cell>2.05E-02 ± 1.79E-02-</cell><cell>3.64E-03 ± 6.78E-03-</cell><cell>1.77E-03 ± 3.73E-03</cell></row><row><cell></cell><cell>F8</cell><cell>2.10E+01 ± 3.81E-02-</cell><cell>2.07E+01 ± 3.74E-01≈</cell><cell>2.07E+01 ± 3.75E-01</cell></row><row><cell>Basic multimodal functions</cell><cell>F9</cell><cell>1.56E+01 ± 7.56E+00-</cell><cell>0.00E+00 ± 0.00E+00≈</cell><cell>0.00E+00 ± 0.00E+00</cell></row><row><cell></cell><cell>F10</cell><cell>1.38E+02 ± 5.78E+01-</cell><cell>4.70E+01 ± 1.34E+01≈</cell><cell>4.41E+01 ± 1.29E+01</cell></row><row><cell></cell><cell>F11</cell><cell>1.62E+01 ± 1.24E+01-</cell><cell>7.82E+00 ± 2.95E+00-</cell><cell>5.62E+00 ± 2.19E+00</cell></row><row><cell></cell><cell>F12</cell><cell>4.35E+03 ± 4.16E+03-</cell><cell>3.45E+03 ± 3.14E+03≈</cell><cell>2.94E+03 ± 3.93E+03</cell></row><row><cell>Expanded multimodal</cell><cell>F13</cell><cell>1.14E+01 ± 4.47E+00+</cell><cell>2.74E+00 ± 1.00E+00≈</cell><cell>2.64E+00 ± 1.13E+00</cell></row><row><cell>functions</cell><cell>F14</cell><cell>1.31E+01 ± 2.46E-01-</cell><cell>1.25E+01 ± 5.39E-01-</cell><cell>1.23E+01 ± 4.90E-01</cell></row><row><cell></cell><cell>F15</cell><cell>3.82E+02 ± 1.12E+02≈</cell><cell>3.76E+02 ± 8.31E+01≈</cell><cell>4.04E+02 ± 5.03E+01</cell></row><row><cell></cell><cell>F16</cell><cell>1.16E+02 ± 7.27E+01-</cell><cell>1.03E+02 ± 9.07E+01-</cell><cell>7.38E+01 ± 3.66E+01</cell></row><row><cell></cell><cell>F17</cell><cell>2.41E+02 ± 5.64E+01-</cell><cell>7.90E+01 ± 1.90E+01-</cell><cell>7.25E+01 ± 2.02E+01</cell></row><row><cell></cell><cell>F18</cell><cell>9.06E+02 ± 1.45E+00-</cell><cell>9.04E+02 ± 2.76E-01-</cell><cell>9.03E+02 ± 1.05E+01</cell></row><row><cell>Hybrid composition functions</cell><cell>F19 F20 F21</cell><cell>9.01E+02 ± 2.10E+01+ 9.05E+02 ± 1.38E+00-5.24E+02 ± 8.31E+01-</cell><cell>9.04E+02 ± 2.62E-01-9.04E+02 ± 2.55E-01≈ 5.00E+02 ± 8.84E-14≈</cell><cell>9.03E+02 ± 1.04E+01 9.04E+02 ± 5.95E-01 5.00E+02 ± 4.62E-13</cell></row><row><cell></cell><cell>F22</cell><cell>8.84E+02 ± 1.65E+01-</cell><cell>8.56E+02 ± 2.75E+01≈</cell><cell>8.62E+02 ± 2.80E+01</cell></row><row><cell></cell><cell>F23</cell><cell>5.50E+02 ± 8.05E+01-</cell><cell>5.34E+02 ± 3.53E-04≈</cell><cell>5.34E+02 ± 1.30E-04</cell></row><row><cell></cell><cell>F24</cell><cell>2.00E+02 ± 2.90E-14≈</cell><cell>2.00E+02 ± 1.03E-12-</cell><cell>2.00E+02 ± 2.85E-14</cell></row><row><cell></cell><cell>F25</cell><cell>2.10E+02 ± 5.84E-01≈</cell><cell>2.10E+02 ± 4.61E-01≈</cell><cell>2.10E+02 ± 7.73E-01</cell></row><row><cell>-</cell><cell></cell><cell>18</cell><cell>13</cell><cell></cell></row><row><cell>+</cell><cell></cell><cell>3</cell><cell>0</cell><cell></cell></row><row><cell>≈</cell><cell></cell><cell>4</cell><cell>12</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9</head><label>9</label><figDesc>Experimental results of JADE, jDE, SaDE, CoDE, and CoBiDE over 25 independent runs on eight real-world engineering optimization problems with 150,000 FES. "Mean Value" and "Std Dev" indicate the average and standard deviation of the objective function values obtained in 25 runs, respectively. Wilcoxon's rank sum test at a 0.05 significance level is performed between CoBiDE and each of JADE, jDE, SaDE, and CoDE. Problem JADE Mean Value ± Std Dev jDE Mean Value ± Std Dev SaDE Mean Value ± Std Dev CoDE Mean Value ± Std Dev CoBiDE Mean Value ± Std Dev</figDesc><table><row><cell>P1</cell><cell>4.63E-01 ± 8.04E-01-</cell><cell>3.49E-01 ± 6.80E-01-</cell><cell>0.00E+00 ± 0.00E+00≈</cell><cell>4.06E-01 ± 2.03E+00-</cell><cell>0.00E+00 ± 0.00E+00</cell></row><row><cell>P2</cell><cell>1.17E+00 ± 1.00E-01-</cell><cell>1.35E+00 ± 7.59E-02-</cell><cell>1.09E+00 ± 2.39E-01-</cell><cell>6.82E-01 ± 1.09E-01-</cell><cell>5.97E-01 ± 1.01E-01</cell></row><row><cell>P3</cell><cell>2.04E+03 ± 4.89E+02-</cell><cell>2.04E+03 ± 4.50E+02-</cell><cell>6.48E+03 ± 7.69E+03-</cell><cell>1.95E+03 ± 4.97E+02≈</cell><cell>1.74E+03 ± 3.49E+02</cell></row><row><cell>P4</cell><cell>5.24E+04 ± 4.92E+02≈</cell><cell>5.78E + 04 ± 3.74E + 03-</cell><cell>5.61E + 04 ± 1.51E + 04≈</cell><cell>5.22E + 04 ± 4.99E + 02≈</cell><cell>5.23E + 04 ± 6.27E + 02</cell></row><row><cell>P5</cell><cell>1.32E+05 ± 5.09E+03≈</cell><cell>1.32E+05 ± 2.44E+03-</cell><cell>1.32E+05 ± 1.66E+03-</cell><cell>1.42E+05 ± 2.43E+03-</cell><cell>1.28E+05 ± 1.21E+03</cell></row><row><cell>P6</cell><cell>9.40E+05 ± 3.47E+03≈</cell><cell>9.74E+05 ± 2.30E+04-</cell><cell>9.76E+05 ± 1.26E+05-</cell><cell>9.50E+05 ± 4.37E+04-</cell><cell>9.39E+05 ± 1.97E+03</cell></row><row><cell>P7</cell><cell>1.01E+06 ± 1.74E+05≈</cell><cell>1.37E+06 ± 1.40+05-</cell><cell>1.37E+06 ± 2.02E+05-</cell><cell>1.11E+06 ± 6.68E+04-</cell><cell>9.52E+05 ± 2.37E+04</cell></row><row><cell>P8</cell><cell>1.74E+01 ± 2.12E+00-</cell><cell>1.88E+01 ± 1.48E+00-</cell><cell>1.56E+01 ± 1.85E+00-</cell><cell>1.39E+01 ± 2.21E+00≈</cell><cell>1.43E+01 ± 1.75E+00</cell></row><row><cell>-</cell><cell>4</cell><cell>8</cell><cell>6</cell><cell>5</cell><cell></cell></row><row><cell>+</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell></cell></row><row><cell>≈</cell><cell>4</cell><cell>0</cell><cell>2</cell><cell>3</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10</head><label>10</label><figDesc>Results of the multiple-problem Wilcoxon's test for JADE, jDE, SaDE, CoDE, and CoBiDE at a 0.05 significance level and at a 0.1 significance level.</figDesc><table><row><cell>Algorithm</cell><cell>R+</cell><cell>R-</cell><cell>p-Value</cell><cell>˛ = 0.05</cell><cell>˛ = 0.1</cell></row><row><cell>CoBiDE vs JADE</cell><cell>36.0</cell><cell>0.0</cell><cell>0.007812</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>CoBiDE vs jDE</cell><cell>36.0</cell><cell>0.0</cell><cell>0.007812</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>CoBiDE vs SaDE</cell><cell>28.0</cell><cell>0.0</cell><cell>0.015626</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>CoBiDE vs CoDE</cell><cell>30.0</cell><cell>6.0</cell><cell>0.10938</cell><cell>No</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11</head><label>11</label><figDesc>Ranking of JADE, jDE, SaDE, CoDE, and CoBiDE according to the statistical test of the Friedman test. From the experimental results shown in Table 9, we can see that JADE, jDE, SaDE, and CoDE cannot outperform CoBiDE on any problems, and that CoBiDE surpasses JADE, jDE, SaDE, and CoDE on four, eight, six, and five problems, respectively, which indicates that overall, CoBiDE performs significantly better than the four competitors on eight complex real-world engineering optimization problems.</figDesc><table><row><cell>Algorithm</cell><cell>Ranking</cell></row><row><cell>CoBiDE</cell><cell>1.3125</cell></row><row><cell>CoDE</cell><cell>2.625</cell></row><row><cell>JADE</cell><cell>3.3125</cell></row><row><cell>SaDE</cell><cell>3.625</cell></row><row><cell>jDE</cell><cell>4.125</cell></row><row><cell>experimental results.</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors sincerely thank the anonymous reviewers for their constructive and helpful comments and suggestions.</p><p>This research was supported in part by the National Natural Science Foundation of China under Grant 61273314, 51175519 and 61175064, in part by the Hong Kong Scholars Program, in part by the China Postdoctoral Science Foundation under Grant 2013M530359, in part by RGC of Hong Kong (CityU: 116212), and in part by the Program for New Century Excellent Talents in University under Grant NCET-13-0596. This research was made possible by NPRP grant # 4-1162-1-181 from the Qatar National Research Fund (a member of Qatar Foundation). The statements made herein are solely the responsibility of the author[s].</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Differential evolution-a simple and efficient adaptive scheme for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
		<idno>TR-95- 012</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic clustering using an improved differential evolution algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part A</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="218" to="236" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Memetic compact differential evolution for Cartesian robot control</title>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mininno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="54" to="65" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fixed-structure H∞ controller synthesis based on differential evolution with level comparison</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using differential evolution for a subclass of graph theory problems</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Greenwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1190" to="1192" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accelerating differential evolution using an adaptive local search</title>
		<author>
			<persName><forename type="first">N</forename><surname>Noman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="125" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with strategy adaptation for global numerical optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="398" to="417" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Problem definitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nanyang Technol. Univ</title>
		<imprint>
			<date type="published" when="2005">2005005. 2005</date>
			<pubPlace>Singapore, Tech; May, IIT Kanpur, India</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for CEC 2011 competition on testing evolutionary algorithms on real world optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Jadavpur University and Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Enhancing the search ability of differential evolution through orthogonal crossover</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="153" to="177" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Differential evolution: a survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="31" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A trigonometric mutation operator to differential evolution</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="129" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">JADE: adaptive differential evolution with optional external archive</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="945" to="958" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Differential evolution using a neighborhood-based mutation operator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="526" to="553" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An orthogonal genetic algorithm with quantization for global numerical optimization</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="53" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<title level="m">A fuzzy adaptive differential evolution algorithm, Soft Computing -A Fusion of Foundations, Methodologies and Applications</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="448" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Self-adapting control parameters in differential evolution: a comparative study on numerical benchmark problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boskovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="646" to="657" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-parent recombination with simplex crossover in real coded genetic algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tsutsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Higuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Conference</title>
		<meeting>the Genetic and Evolutionary Conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Opposition-based differential evolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Tizhoosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M A</forename><surname>Salama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="79" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">EDA: a new evolutionary algorithm for global optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P K</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><surname>De/</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="249" to="262" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with ensemble of parameters and mutation strategies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">K</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tasgetiren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1679" to="1696" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Differential evolution with composite trial vector generation strategies and control parameters</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Enhanced differential evolution with adaptive strategies for numerical optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="397" to="413" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Part B</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Completely derandomized self-adaptation in evolution strategies</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ostermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="195" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A crossover operator using independent component analysis for real-coded genetic algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Congress on Evolutionary Computation</title>
		<meeting>IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="643" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hybrid differential evolution with covariance matrix adaptation for digital filter design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Walczak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Symposium on Differential Evolution (SDE)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A hybrid CMA-ES and HDE optimisation algorithm with application to solar energy potential</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kämpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="738" to="745" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pe ña, Evaluating the multiple offspring sampling framework on complex continuous optimization functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Latorre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muelas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.1007/s12293-013-0120-8</idno>
		<ptr target="http://dx.doi.org/10.1007/s12293-013-0120-8" />
	</analytic>
	<monogr>
		<title level="m">Memetic Computing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A restart CMA evolution strategy with increasing population size</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12293-013-0120-8</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1769" to="1776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<title level="m">Statistical Power Analysis for the Behavioral Sciences</title>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Earlbaum Associates</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A study on the use of non-parametric tests for analyzing the evolutionary algorithms&apos; behaviour: a case study on the CEC&apos;2005 special session on real parameter optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Heuristics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="617" to="644" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">KEEL: a software tool to assess evolutionary algorithms to data mining problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Alcalá-Fdez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Del Jesus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Garrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Otero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bacardit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Rivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="307" to="318" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Global and local real-coded genetic algorithms based on parent-centric crossover operators</title>
		<author>
			<persName><forename type="first">C</forename><surname>Garcia-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1088" to="1113" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
