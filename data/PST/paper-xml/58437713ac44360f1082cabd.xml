<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">De-identification for privacy protection in multimedia content: A survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-06-01">1 June 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Slobodan</forename><surname>Ribaric</surname></persName>
							<email>slobodan.ribaric@zemris.fer.hr</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Electrical Engineering and Computing</orgName>
								<orgName type="institution">University of Zagreb</orgName>
								<address>
									<settlement>Zagreb</settlement>
									<country key="HR">Croatia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aladdin</forename><surname>Ariyaeeinia</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Hertfordshire</orgName>
								<address>
									<settlement>Hatfield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikola</forename><surname>Pavesic</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">University of Ljubljana</orgName>
								<address>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">De-identification for privacy protection in multimedia content: A survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-06-01">1 June 2016</date>
						</imprint>
					</monogr>
					<idno type="MD5">2E40A9881079604B4971C0EED76A9DB9</idno>
					<idno type="DOI">10.1016/j.image.2016.05.020</idno>
					<note type="submission">Received 30 July 2015 Received in revised form 30 May 2016 Accepted 31 May 2016</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Privacy Multimedia De-identification Biometric identifiers Soft biometric identifiers Non-biometric identifiers</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Privacy is one of the most important social and political issues in our information society, characterized by a growing range of enabling and supporting technologies and services. Amongst these are communications, multimedia, biometrics, big data, cloud computing, data mining, internet, social networks, and audio-video surveillance. Each of these can potentially provide the means for privacy intrusion. Deidentification is one of the main approaches to privacy protection in multimedia contents (text, still images, audio and video sequences and their combinations). It is a process for concealing or removing personal identifiers, or replacing them by surrogate personal identifiers in personal information in order to prevent the disclosure and use of data for purposes unrelated to the purpose for which the information was originally obtained. Based on the proposed taxonomy inspired by the Safe Harbour approach, the personal identifiers, i.e., the personal identifiable information, are classified as non-biometric, physiological and behavioural biometric, and soft biometric identifiers. In order to protect the privacy of an individual, all of the above identifiers will have to be de-identified in multimedia content. This paper presents a review of the concepts of privacy and the linkage among privacy, privacy protection, and the methods and technologies designed specifically for privacy protection in multimedia contents. The study provides an overview of de-identification approaches for non-biometric identifiers (text, hairstyle, dressing style, license plates), as well as for the physiological (face, fingerprint, iris, ear), behavioural (voice, gait, gesture) and soft-biometric (body silhouette, gender, age, race, tattoo) identifiers in multimedia documents.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent advances in audio-recording devices, cameras, web technology and signal processing have greatly facilitated the efficacy of audio and video surveillance, primarily for the benefit of security and law enforcement. This technology is now widely exploited in a variety of scenarios to capture audio-video recordings of people in public environments, either for immediate inspection (e.g., abnormal behaviour recognition, identification and tracking of people in real time) or for storage, and subsequent data analysis and sharing. Capabilities in the field are further supported through continued progress in a number of relevant areas, including smart, multi-camera networks <ref type="bibr" target="#b0">[1]</ref>, wireless networks of multispectral image sensors, drones equipped with camera, audiosensor arrays, distributed intelligence and awareness, and distributed processing power <ref type="bibr" target="#b1">[2]</ref>.</p><p>Whilst it is clear that there are justifiable reasons for sharing multimedia data acquired in such ways (e.g. for law enforcement, forensics, bioterrorism surveillance, disaster prediction), there is also a strong need to protect the privacy of innocent individuals who are inevitably "captured" in the recordings. In order to recognise the growing scale of this surveillance and its effects on privacy, it is worth noting that, for instance, there are more than forty-eight hundred government surveillance cameras in Washington, D.C. <ref type="bibr" target="#b2">[3]</ref> and over 4 million closed-circuit television (CCTV) cameras deployed in the United Kingdom. The average citizen in London is caught on CCTV cameras about 300 times a day <ref type="bibr" target="#b3">[4]</ref>. The problem associated with this is further exacerbated by lack of compliance with the relevant data-protection legislation. According to a study in <ref type="bibr" target="#b4">[5]</ref>, this is the case for over 80% of the CCTV systems deployed in London's business space.</p><p>An additional and growing feature of the privacy problem in today's networked society is the advent of technologies such as "Google Street View" and "EveryScape", social networks, biometrics, multimedia, big data, and data mining. These provide an additional framework for the invasion of an individuals' privacy. In <ref type="bibr" target="#b5">[6]</ref>, Angwin analyzed relations among privacy, security and freedom in a world of relentless electronic surveillancefrom Google to NSA. Angwin has concluded that we are living in the world of indiscriminate tracking where institutions are stockpiling data about individuals at an unprecedented pace. This indiscriminate tracking is powered by "the technology we love so much"powerful desktops, laptops, tablets, smart-phones and web services.</p><p>In view of the above issues, considerable research has now been directed towards approaches for the preservation of privacy and personal information. The main facet of efforts in this area, which is also the focus of this paper, is concerned with the development of methods for the de-identification of individuals captured in multimedia content (text, audio, still images, animation, video, and their combination). In order to provide an appropriate basis for the analysis presented here, the next section details the definition of privacy, and its social and legal aspects as well as its significance in today's society. The subsequent sections then present a survey of de-identification in multimedia content. The scope of the study is broad and covers methods for dealing with non-biometric, biometric physiological and behavioural identifiers, and soft biometric identifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Privacy</head><p>There is no single definition of the term "privacy". The meaning of privacy depends on legal, political, societal, cultural and sociotechnological contexts <ref type="bibr">[7]</ref>. From the legal point of view, the first definition of privacy was given by Brandeis and Warren more than 120 years ago <ref type="bibr" target="#b6">[8]</ref>. They defined privacy as "the right to be let alone", with respect to the acquisition and dissemination of information concerning the person, particularly through unauthorized publication, photography or other media. Also, according to Brandeis and Warren, the person should be protected from investigation and seizures that invade a sphere of individual solitude deemed reasonable by society. Additionally, the person has "the right to be let alone" with respect to fundamental decisions concerning his or her intimate relationships or aspects of life.</p><p>Westin defines privacy as the claim of an individual to determine what information about himself or herself should be known to others <ref type="bibr" target="#b7">[9]</ref>. Based on the various usages of the word "privacy", there are many different conceptions of privacy and they can be classified into six general types <ref type="bibr" target="#b8">[10]</ref>: (i) the right to be let alone; (ii) limited access to the selfthe ability to protect oneself from unwanted access by others; (iii) secrecythe concealment of certain matters from others; (iv) control over personal information; (v) personhoodthe protection of one's personality, individuality and dignity; (vi) intimacycontrol over, or limited access to, one's intimate aspects of life.</p><p>Depending on the social contexts and/or real life situations, privacy, in general, can be divided into a number of separate, but related, concepts <ref type="bibr" target="#b9">[11]</ref>: (i) informational privacythe right of the individual to limit access to personal information which could be used in any way to identify an individual; (ii) intentional privacythe right of the individual to prevent or forbid further communication of observed events or exposed features (e.g., publishing photos or video footage); (iii) decisional privacythe right of the individual to make decisions regarding his life without any undue interference; (iv) spatial privacythe right of the individual to have his own personal spaces which cannot be violated without his explicit consent. If we include some physical and socio-technological contexts in the above classification, we can talk about: (i) information privacy, which involves the establishment of rules governing the collection and handling of personal data such as medical and tax records and credit information; (ii) the privacy of communications, which covers the security and privacy of mail, telephone, e-mail and other forms of communication; (iii) bodily privacy, which concerns the protection of people's physical selves against invasive procedures such as genetic tests, drug testing and cavity searches; (iv) territorial privacy, which concerns the setting of limits on intrusion into domestic and other environments, such as the workplace or public space. This includes searches, video surveillance and ID checks.</p><p>An in-depth and comprehensive insight into the theory of privacy, existing attempts to conceptualize privacy and different definitions of privacy from the standpoint of jurists, philosophers and sociologists are given in the book <ref type="bibr" target="#b8">[10]</ref>.</p><p>Let us illustrate the need for privacy and personal data protection with three examples of privacy violation. Case 1 describes a situation in which privacy is violated due to the inadequate protection of the face as a biometric identifier. Case 2 describes a situation in which privacy is violated and abused due to the low level of protection of stored personal documents with biometric identifiers and other personal identifiable information. Case 3 deals with the potential abuse of a facial recognition system used in public places.</p><p>Case 1: A person attempted suicide by slitting his wrists with a knife in a street. A CCTV surveillance camera was recording him, and the person monitoring the camera notified the police. The person was saved and transported to hospital. Some months later, the Council issued two photographs of the person taken from the CCTV footage for publication in an article about the preventative benefits of CCTV. The person's face was not specifically masked and he could be identified by people who knew him. Extracts from the CCTV footage were also shown on regional television in which the person's face had been masked at the Council's request.</p><p>Epilogue: The person sought judicial review of the Council's decision to release the CCTV footage without his consent. His application was rejected and this decision was upheld by the Court of Appeal with the explanation that there was no violation of privacy because "actions were already in the public domain" and revealing the footage "simply distributed a public event to a wider public." The applicant applied to the European Court of Human Rights and it concluded that "the disclosure by the Council therefore constituted a serious interference with his right to respect for private life. There were no relevant or sufficient reasons to justify the disclosure by the Council without obtaining the applicant's consent or ensuring as far as possible that his identity was masked." The Court therefore awarded him damages for his distress due to violation of his privacy <ref type="bibr">[12]</ref>.</p><p>Case 2: An identity thief using a stolen photocopy of an ID card and VAT number signed two contracts in a web shop with a mobile service provider and picked up two smart-phones. The person whose identity was stolen reported the case to the police and the Personal Data Protection Agency (PDPA).</p><p>Epilogue: PDPA made an inspection and requested contracts, delivery reports and a copy of the submitted ID. After discrepancies were found in the contracts (a fake signature) and negligence in the delivery procedures (the ID was not checked), the mobile service provider admitted its mistakes and cancelled the contracts. Police caught the gang with this modus operandi. One of the gang members was an insider in the mobile service provider company.</p><p>Case 3: In 2001, the police in Tampa, USA, used face scanning and facial recognition software to scan and capture images of football fans at the Super Bowl, without the knowledge of the people involved <ref type="bibr" target="#b11">[13]</ref>.</p><p>Epilogue: The use of facial recognition systems in public places was banned. Why? Different organizations could use faces captured by a facial recognition system to discover places that a person had visited or to scan different large databases in order to profile and/or socially control a person.</p><p>Privacy violations described in Cases 1 and 3 could be prevented by de-identification of biometric identifiers, while violation in Case 2 could be prevented by storing personal documents in appropriate safe manner.</p><p>The main focus of this paper is the de-identification of biometric identifiers in multimedia documents for privacy protection. It is therefore interesting to view some of the main concerns related to the use of biometrics <ref type="bibr" target="#b9">[11]</ref>: (i) biometric data can be collected and shared without the user's knowledge and permission; (ii) biometric data which have been collected for some specific purposes can later be used for other unintended or unauthorized purposes. This is referred to as "functional creep"; (iii) biometric data can be copied or removed from the user and used for secondary purposes; (iv) biometric data can be used to reveal sensitive personal information, such as gender, race, and ethnicity, but also mental and health status; (v) biometric data can be used to pinpoint, locate and track individuals. Even more, by associating biometric data with non-biometric identifiers (name, address, ID and passport number) it can lead to covert surveillance, profiling and social control; (vi) biometric data can be exposed to external attacks due to improper storage and/or transmission.</p><p>The biometric templates of an individual may be stolen, modified and shared, and privacy and security may be compromised. There are three aspects of privacy protection of individuals regarding biometric template protection <ref type="bibr" target="#b12">[14]</ref>: (i) irreversibilityit should be computationally hard to reconstruct the original biometric template from the stored reference data; (ii) unlinkabilitydifferent biometric templates cannot be linked to each other or to the individual who is the source of both; and (iii) confidentialityprotection of the user's biometric template against unauthorized access or disclosure. Recently, efforts have been made to standardize biometric template protection. There are four main biometric template protection schemes: (i) extracting and storing a mathematical sketch of a biometric template; (ii) fuzzy commitment in which a biometric feature vector is bound to a secret message; (iii) encrypting the biometric features at enrolment; and (iv) cancellable or revocable biometrics where the template is transformed using a secret transformation at enrolment, and stored in the system. Recognition is based on matching between a test template which is obtained by using the correct transformation and the transformed version of the enrolment template. Cancellable biometric includes cancellable face <ref type="bibr" target="#b13">[15]</ref>, fingerprint <ref type="bibr" target="#b14">[16]</ref>, iris <ref type="bibr" target="#b15">[17]</ref>, voice <ref type="bibr" target="#b16">[18]</ref> and other biometric modalities. A detailed and comprehensive overview of cancellable biometrics and biometric cryptosystems is given in <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b18">20]</ref>.</p><p>Privacy issues and ethical and legal issues related to privacy and multimedia in different contexts, environments and scenarios are subjected to detailed discussion <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b20">22]</ref>. In <ref type="bibr" target="#b19">[21]</ref>, privacy protection based on reversible cryptographic obscuration is presented. Additionally, privacy issues in scenarios with multimedia (video and audio) surveillance are considered. The author describes a scenario where a surveillance device intercepts sound and the surveillance constitutes a search. In such a case, the police or government institutions must first obtain a warrant prior to the installation of the device (according to US Title I of the Electronic Communications Privacy Act). Bharucha et al. <ref type="bibr" target="#b20">[22]</ref> discuss the ethical implications of real-time multimedia surveillance technology for the privacy and dignity of long-term care residents, personnel and care processes. The authors de-identified privacy sensitive data (face and voice) of all stakeholders (residents, professional and non-professional staff, administrative staff, families and visitors), but only after the filming was completed. This is a weak point of the approach, because third parties may gain access to the recordings before the participants are de-identified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Phases of contemporary privacy development</head><p>After consideration of privacy at the political and socio-cultural and organizational level and describing a privacy baseline <ref type="bibr">(period 1945-1960)</ref>, Westin <ref type="bibr" target="#b7">[9]</ref> introduced three phases of contemporary privacy development as follows.</p><p>i) The first era of contemporary privacy development, <ref type="bibr">(period 1961-1979)</ref>, which is characterized by the rise of information privacy as an explicit social, political, and legal issue of the high-technology age. In 1973, a US government advisory committee initially proposed a set of principles to protect the privacy of personal data in recordkeeping systems named Fair Information Practices (FIPs) <ref type="bibr" target="#b21">[23]</ref>.  <ref type="bibr" target="#b21">[23]</ref>. These laws were consistent with FIPs. ii) The second era of contemporary privacy development, <ref type="bibr">(period 1980-1989)</ref>. Technologically, this was a period of enhanced computer and telecommunications performance, but without fundamental changes in information-society relationships bearing on privacy; iii) The third era of contemporary privacy development, <ref type="bibr">(period 1990-now)</ref>. This is the period when privacy became a firstlevel social and political issue in Europe and the US, assumed global proportions, and was impacted by 9/11 and its aftermath.</p><p>The main framework for privacy and personal data protection in the European Union is The 1995 Data Protection Directive of the European Union (Directive 95/46/EC) <ref type="bibr" target="#b22">[24]</ref>. It is an operating basic model for handling personal data that demands the deployment of appropriate technical and organisational measures to protect private information in the course of transferring or processing personal data. This legal requirement along with ethical responsibilities has restricted data sharing and utilisation, while various organisations may require the use of such data for research, business, academic, security and many other purposes. In July 2008, the Information Commissioner's Office (ICO) commissioned a review of the 1995 EU Data Protection Directive (95/46/EC) <ref type="bibr" target="#b23">[25]</ref>. This was motivated by the fact that since the introduction of the Directive, the world had witnessed dramatic changes in the way personal data was accessed, processed and used. At the same time, the general public had become increasingly aware of the potential for their personal data to be abused.</p><p>The terrorist attacks on September 11, 2001 have had significant impacts on privacy, information law and its practice in the US <ref type="bibr" target="#b24">[26]</ref>. Here is the list of the main important acts: USA Patriot Act (2001), Homeland Security Act (2002), Intelligence Reform and Terrorism Prevention Act (2004.), Real ID Act (2005) and NSA Warrantless Surveillance <ref type="bibr">(2005)</ref>.</p><p>There is an everlasting debate between experts in the field of security and privacy experts about security-privacy balance. They are all aware that there must be a balance between privacy and security because it guarantees foundations of our freedom and democracy. In contemporary times, the balance has shifted towards the security side of scale <ref type="bibr" target="#b2">[3]</ref>. The intensity of electronic (dragnet) surveillance at the US state level and local levels, after September 11, 2011, may be illustrated by increasing the budget of Federal intelligence agency from $27 billion (prior to the attacks) to $75 billion in 2013 <ref type="bibr" target="#b5">[6]</ref>.</p><p>A comparison of US and European approaches to privacy legislation is given in <ref type="bibr" target="#b25">[27]</ref><ref type="bibr" target="#b26">[28]</ref><ref type="bibr" target="#b27">[29]</ref>. Summarizing the comparison, we can state that: (i) while data protection and privacy are fundamental rights in the EU and are also applicable in the law enforcement context, there is no equivalent protection in the US <ref type="bibr" target="#b27">[29]</ref>; (ii) the basic EU data protection principles such as restrictions on the further use and dissemination of data collected in a law enforcement context, purpose limitation or time limits on data retention do not exist at all or exist only rudimentarily in the US; (iii) in EU law, fundamental rights cover all persons targeted by law enforcement and surveillance measures, regardless of their nationality while US law distinguishes between US and non-US citizens.</p><p>Note that in October 2015, the European Court of Justice struck down a 15-year-old agreement known as the Safe Harbour, which was an attempt to bridge differing approaches to data protection in Europe and the US. The Court concluded the data of Europeans are exposed to allegedly indiscriminate surveillance by the US government. The General Data Protection Regulation <ref type="bibr" target="#b28">[30]</ref>, adopted by the European Parliament in April 2016, represents the reform of EU data protection rules and covers the following main areas: protection of personal data, data transfers outside the EU, data protection on social networks and Big Data services. It was an essential step to strengthen citizens' fundamental rights in the digital age and facilitate business by simplifying rules for companies in the Digital Single Market.</p><p>The time period from 2001 until now is characterized by technologies such as internet, wireless communications, datamining software based on large data-warehousing applications, cloud computing, drones with video camera and other sensors, the increased use of law-enforcement video-camera systems in public places, and along with the adoption of biometric identification systems by many governments and private organizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Common criteria for information technology security evaluation and privacy-enhancing technologies</head><p>There is a strong linkage among privacy, privacy protection and technologies designed specifically for privacy protection. The common framework for privacy, privacy protection and technologies is the multipart standard Common Criteria for Information Technology Security Evaluation <ref type="bibr" target="#b29">[31]</ref> and Privacy-Enhancing Technologies <ref type="bibr" target="#b30">[32,</ref><ref type="bibr" target="#b31">33]</ref>. Privacy-Enhancing Technologies (PETs) have been developed to protect internally stored personal data that might be privacy-sensitive. It stands for a coherent system of information and communications technology (ICT) measures that protect privacy by eliminating or reducing personal data, or by preventing unnecessary and/or undesired processing of personal data, all without losing the functionality of the information system <ref type="bibr" target="#b30">[32]</ref>. An extension of PETs has resulted in a more substantial approach called Privacy by Design (PbD). PbD is a concept developed in the 90s <ref type="bibr" target="#b32">[34]</ref>. It combines the principles of Fair Information Practices and a proactive approach to protecting privacy by embedding it into the design specifications of technologies, business practices, and physical infrastructures. A typical example of a system to which PbD has been applied is the De-Identification Camera <ref type="bibr" target="#b33">[35]</ref> (Section 5.2).</p><p>For the benefit of discussions in this paper, below, we provide the definition of a set of key terms. i) personal information is any information relating to a person, ii) personal identifiable information (or personal identifiers) is the personal information, which allow his or her identification, iii) privacy concerns exist wherever personal information containing personal identifiers is captured in multimedia content (text, still images, audio and video sequences, and their combination), and iv) preservation of the privacy of persons captured in multimedia content necessitates the de-identification of all of their personal identifiers (we use the term a personal identifier recognition to denote biometric-based person identification or verification based on a personal identifier), e.g. gate recognition means gait-based person identification or verification.</p><p>Modern computer technologies such as biometrics, cloud computing, ambient intelligence, data-mining, internet services, social networks and audio-video surveillance are privacy intrusive because they allow collecting, extracting, observing, transferring and storing of personal identifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">De-identification and irreversible de-identification</head><p>De-identification in multimedia content is defined as the process of concealing or removing personal identifiers, or replacing them with surrogate personal identifiers in multimedia content, in order to prevent the disclosure and use of data for purposes unrelated to the purpose for which the information was originally obtained. It is no doubts that de-identification is one of the basic methods for protecting privacy, while permitting other uses of personal information.</p><p>The terms de-identification and anonymization are often used interchangeably, but some experts make the difference between them. De-identification refers to the reversible process of removing or obscuring any personally identifiable information from individual records in a way that minimizes the risk of unintended disclosure of the identity of individuals and information about them. It involves the provision of additional information to enable the extraction of the original identifiers by, for instance, an authorized body. Anonymization refers to the process of data deidentification that produces data where individual records cannot be linked back to an original as they do not include the required translation variables to do so <ref type="bibr" target="#b34">[36]</ref>. It is a one-directional (irreversible) process and does not allow the original identifiers to be obtained from de-identified data. In this paper we use the term de-identification for both approaches, but in some cases we emphasize whether it is a case of reversible or irreversible process. In either case, the de-identification process is required to be of sufficient effectiveness, regardless of whether the recognition attempts are made by humans or by machines. Moreover, in many cases, the process of de-identification has also to preserve the data utility, naturalness and intelligibility <ref type="bibr">[37,</ref><ref type="bibr" target="#b35">38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Taxonomy of the identifiers in multimedia content</head><p>The following proposed taxonomy of the identifiers in multimedia content that have to be de-identified in order to protect privacy is inspired by the Safe Harbour approach <ref type="bibr" target="#b36">[39]</ref>. According to this approach, which constitutes the guiding principles for deidentification in healthcare applications, there are 18 types of identifiers that have to be de-identified in order to cover the identity of the recipients of health-care services (patients). These are names; all geographic subdivisions smaller than a state; all elements of dates (except year) for dates directly related to an individual; telephone and facsimile numbers; electronic-mail addresses; social security numbers; medical record numbers; healthplan beneficiary numbers; account numbers; certificate/license numbers; vehicle identifiers and serial numbers including license-plate numbers; device identifiers and serial numbers; internet universal resource locators (URLs); internet protocol (IP) address numbers; biometric identifiers; including fingerprints and voiceprints; full-face photographic images and any comparable images; and any other unique identifying number, characteristic, or code, unless otherwise permitted by the Privacy Rule for re-identification <ref type="bibr" target="#b37">[40]</ref>.</p><p>Based on the above types of personal identifiers, the identity information extracted from multimedia content can be classified as follows.</p><p>i) Non-biometric identifiers including text context, speech context, licence plate, specific socio-political and environmental context, dressing style, and hairstyle; ii) Biometric identifiers are the distinctive, measurable, generally unique and permanent personal characteristics used to identify individuals. In the following, they are usually categorized as physiological (face, iris, ear, fingerprint) versus behavioural (voice, gait, gesture, lip-motion, stile of typing), iii) Soft biometric identifiers provide some vague physical, behavioural or adhered human characteristic that is not necessarily permanent or distinctive (height, weight, eye colour, silhouette, age, gender, race, moles, tattoos, birthmarks, scars) <ref type="bibr" target="#b38">[41,</ref><ref type="bibr" target="#b39">42]</ref>. In most cases soft biometric identifiers alone cannot provide a reliable personal identification, but they can be used for improving the performance of recognition <ref type="bibr" target="#b39">[42,</ref><ref type="bibr" target="#b40">43]</ref>, or to classify people into particular categories, which is also privacy intrusive. Fig. <ref type="figure" target="#fig_0">1</ref>. shows the taxonomy of identifiers in multimedia content, which is adopted as a logical basis for structuring discussions in the remainder of this paper.</p><p>It is worth noting that very often multimedia content may simultaneously include biometric, soft-biometric and non-biometric identifiers, which all have to be de-identified in order to protect the privacy of individuals. This can be referred to as multimodal deidentification.</p><p>Detecting and concealing or removing or replacing personal identifiers in multimedia content is an interdisciplinary challenge that incorporates such scientific areas as natural-language processing, text processing, image processing, pattern recognition, machine learning, speech analysis, video tracking and biometrics.</p><p>In the next sections we provide an overview of de-identification of non-biometric identifiers (Section 4), physiological biometric identifiers (Section 5), behavioural biometric identifiers (Section 6), and soft-biometric identifiers (Section 7). Besides the solutions for de-identification, we also discuss the unsolved problems and challenges related to de-identification, assessment of privacy level protection, naturalness and usability of de-identified multimodal contents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">De-identification of non-biometric identifiers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Text de-identification</head><p>Research on de-identification was initiated with text-based personal healthcare records (PHRs). The approach in this application area involves the removal of a number of specific categories of information from the text file, and replacing them with realistic surrogate information <ref type="bibr" target="#b41">[44]</ref><ref type="bibr" target="#b42">[45]</ref><ref type="bibr" target="#b43">[46]</ref>. The automated de-identification of text-based PHRs is focused on both highly-structured type-specific records and/or free-text medical records with a highly variable structure. The de-identification methods are based on templates and specialized knowledge of the context for replacing personal health information (PHI) in medical records, or on a complex combination of dictionaries and text-analysis algorithms. Recently, approaches based on a combination of machine learning, heuristics and statistical methods, as well as pattern-matching are used <ref type="bibr" target="#b41">[44]</ref>.</p><p>Reversible de-identification is commonly used in the protection of personal data in health-care and biomedical research <ref type="bibr" target="#b44">[47]</ref>. An overview of this de-identification challenge of PHR, the data and the annotation process, the evaluation metrics, and a discussion on the nature of the de-identification systems and the identification of directions for future research are given in <ref type="bibr" target="#b45">[48]</ref>. In the context of text de-identification, it is worth noting that medical imagery, which consists of header information, typically in a DICOM (Digital Imaging and Communications in Medicine) format, and image data generated by imaging devices, contains privacy sensitive information in both header and image data. Privacy sensitive information of medical image data can be illustrated by the fact that it is possible to reconstruct a person's face using three-dimensional models generated from computed tomography (CT) and magnetic resonance (MR) imaging <ref type="bibr" target="#b46">[49]</ref>. By using a multimodal deidentification approach, the text sensitive information in the DI-COM header has to be removed or replaced with surrogate information, while image data have to be de-identified by methods based on reversible privacy filters (see Sections 5.2 and 5.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Hairstyle and dressing style de-identification</head><p>Hairstyle and dressing style carry identity-revealing information <ref type="bibr" target="#b47">[50]</ref><ref type="bibr" target="#b48">[51]</ref><ref type="bibr" target="#b49">[52]</ref><ref type="bibr" target="#b50">[53]</ref> and they can be used to classify people into different categories. There is also the problem called "a pair-wise constraint" identification <ref type="bibr" target="#b51">[54]</ref>, which means that people can determine that two de-identified face portraits in a video belong to the same person by using clothing, hairstyle, dress style or other cues as alternative information, and so there is a risk of exposing a person's identity. Alternative information that can be useful for identity revealing includes speech context, specific social and political context, and the environment. Relatively little research work has been done in the area of removing or hiding hairstyle and dressing style, as well the above mentioned contexts for deidentification purposes <ref type="bibr" target="#b52">[55,</ref><ref type="bibr" target="#b53">56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">License plate de-identification</head><p>Web services like Google Street View and EveryScape systematically gather and share large-scale images of public places. The gathered images of public places in their original forms contain privacy sensitive information, such as the faces of individuals and car license numbers on license plates. According to the Safe Harbour approach, this information is among 18 types of identifiers that have to be de-identified in order to conceal the identity of an individual. In <ref type="bibr" target="#b54">[57]</ref>, the authors focus on the detection of faces and license plates in Google Street View footage, while the de-identifications are simply done by blurring the detected locations (see Section 5.1). A simplified version of the face detector based on a fast sliding-window approach over a range of window sizes is used for the detection of license plates. The detector employs the linear combination of a heterogeneous set of feature detectors, which are based on families of features of varying complexity, encompassing simple but fast features such as bit features, as well as more expensive but more informative features such as Gabor wavelets. The separated detectors for US and EU plates are trained by minimizing the objective function. They belong to a large family of sliding window detectors, such as Schneiderman-Kanade <ref type="bibr" target="#b55">[58]</ref> and Viola-Jones detectors <ref type="bibr" target="#b56">[59]</ref>. The authors report that a completely automatic system has detected and sufficiently blurred 94-96% of the license plates in evaluation sets sampled from Google Street View imagery.</p><p>In <ref type="bibr" target="#b57">[60]</ref>, a method named inhomogeneous principal component blur (IPCB) is proposed. It adaptively blurs different pixels of a license plate by taking into account the prior distribution of sensitive information. Based on the assumption that not all information in the license plate region is privacy sensitive, the authors propose a preservative license plate de-identification method to balance privacy protection and quality preservation. For example, the state name is usually less sensitive than the license numbers, so only the plate's area with the license numbers should be de-identified. Therefore, selectively blurring or masking only the license number area minimizes the unwanted degradation of the original image and improves its naturalness. The blurring is based on the Principal Component Analysis (PCA) approachthe original plate's area is substituted by a reconstructed area that is obtained by applying a smaller number of eigenvectors. The proposed method is reversible: a de-identified plate can be recovered by knowing the coefficients of each principal component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">De-identification of physiological biometric identifiers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Face de-identification in still images</head><p>The main physiological biometric identifier in multimedia content, requiring de-identification for privacy preservation is the face <ref type="bibr" target="#b58">[61]</ref>. The early research into face de-identification was focused on face still images, and recommended the use of ad-hoc approaches such as "black box", "blurring" and "pixelation" of the image region occupied by the face <ref type="bibr" target="#b59">[62,</ref><ref type="bibr" target="#b60">63]</ref>. In the black-box approach, after the face detection and face localization in the image, the face region is simply substituted by a black (or white) rectangle, elliptical or circular cover. Blurring (Fig. <ref type="figure" target="#fig_1">2b</ref>); the experiments were performed on the cmu-pie-database [64] is a simple method based on smoothing the face in an image with Gaussian filters using a variety of sufficiently large variances. By applying different variances, different levels of blurred images of the face are obtained <ref type="bibr" target="#b59">[62]</ref>. Pixelation (Fig. <ref type="figure" target="#fig_1">2c</ref>) consists of reducing the resolution (sub-sampling) of a face region. Naive methods such as blurring and pixelation might prevent a human from recognising subjects in the image, but they cannot thwart recognition systems.</p><p>An effective approach that subverts naive de-identification methods is called parrot recognition <ref type="bibr" target="#b62">[66]</ref>. Instead of comparing the de-identified images to the original images, parrot recognition is based on comparing probe (de-identified) images with gallery images, where the same distortion is applied as in the probe images. It is shown that such an approach drastically improves the recognition rate, i.e. it reduces the level of privacy protection <ref type="bibr" target="#b62">[66]</ref>. To achieve an improved level of privacy protection, more sophisticated approaches have been proposed. In <ref type="bibr" target="#b63">[67]</ref>, an eigenvectorbased de-identification method is described. The original face is substituted by a reconstructed face that is obtained by applying a smaller number of eigenfaces. As a result, the face details are lost and the de-identified image becomes harder to recognise. In the same paper, the privacy-operating characteristic (POC) is introduced and used to show, quantitatively, the trade-off between privacy and security. The eigenvector-based method easily produces very unnatural images, but still keeps some of the facial characteristics that can be used for automatic recognition.</p><p>In recent years, advances in biometric identification have inspired researchers in the field of de-identification. Examples are the face de-identification methods referred to as k-Same <ref type="bibr" target="#b64">[68]</ref>, k-Same-Select <ref type="bibr" target="#b65">[69]</ref> and Model-based k-Same <ref type="bibr" target="#b66">[70]</ref>. By applying the k-Same algorithm, to the given person-specific set of images, where each person is represented by no more than one image, a set of deidentified images is computed. Each de-identified image It has been shown that the best-possible success rate for a facerecognition algorithm linking a de-identified face image to the correct face image in the set I is 1/k <ref type="bibr" target="#b64">[68]</ref>. The procedure based on the k-Same algorithm is irreversible, guarantees probable privacy (1/k), but very often results in "ghosting" artefacts in de-identified images due to image misalignment or an expression variant of the faces present in the k images from set I. In order to improve the data utility and the naturalness of the de-identified face images, the k-Same-Select is proposed <ref type="bibr" target="#b65">[69]</ref>. The algorithm partitions the input set of face images into mutually exclusive subsets using the data-utility function and applies the k-Same algorithm independently to the different subsets. The data utility function is usually selected to preserve the gender or a facial expression in the de-identified Due to the use of the k-Same algorithm, k-Same-Select guarantees that the resulting face set is k-anonymized <ref type="bibr" target="#b67">[71]</ref>. For both algorithms, there are two main problems: they operate on a closed set I, and the determination of the proper privacy constraint k. In order to produce de-identified images of much better quality and preserve the data utility, the Model-based k-Same algorithms <ref type="bibr" target="#b66">[70]</ref> are proposedone of which is based on Active Appearance Models (AAMs) <ref type="bibr" target="#b68">[72]</ref> and another based on the model that is the result of mixtures of identity and non-identity components obtained by factorizing the input images. Modifications to the k-Same Select algorithm, in order to improve the naturalness of the deidentified face images (by retaining face expression) and privacy protection, are proposed in <ref type="bibr" target="#b69">[73,</ref><ref type="bibr" target="#b70">74]</ref>.</p><p>In <ref type="bibr" target="#b71">[75]</ref>, the authors proposed a reversible privacy-preserving photo sharing architecture which ensures privacy and preserves the usability and convenience of online photo sharing. The architecture takes into account the content and context of a photo and utilizes a Secure JPEG framework. Visual privacy in a JPEG can be protected by using: (i) naive de-identification where the reconstruction of an original image is performed by extracting from a JPEG header, decrypting and placing back the original pixels; (ii) scrambling, which modifies the original values of the pixels and the discrete cosine transform (DCT) coefficients in a reversible way. The proposed architecture is convenient for privacy protection in social networks and photo hosting platforms (Facebook, Pinterest, Instagram).</p><p>In <ref type="bibr" target="#b72">[76]</ref>, a morphing-based visual privacy protection method is described. The morphing is performed by using a set of face key points (eyes, nose, mouth), both original source and target images, the interpolation of some pixels between the key points, and dividing both images using Delaunay triangulation. Subsequently, for each pixel in the final (morphed) face image, the pixel's value is computed as a weighted sum of intensities between the corresponding pixels in both images. By using an inverse of morphing (unmorphing), the protected face image can be recovered. The method was tested on a subset of a FERET database and demonstrates that morphed faces retain the likeness of a face while making them unrecognizable. The same authors <ref type="bibr" target="#b73">[77]</ref> used a geometrical transformation or warping for face de-identification. The warping is performed in the following steps: (i) select a set of key  points (facial features) in the face image (eyes, nose, mouth) and several points around the detected facial features and the sides of the face; (ii) change the coordinates of these points to the destination coordinates by adding or subtracting a random value with a weight which determines the warping strength; (iii) compute the transformation matrix based on the original and destination coordinates. By using the inverse transformation, the original face can be estimated. The warping was tested on a Yale dataset (165 faces of 15 subjects). The test showed that the naturalness and privacy level of protection depend on the warping strength.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Face de-identification in video surveillance systems</head><p>Due to tremendous development and use of visual technologies such as CCTVs, visual sensor networks and camera phones, the term the visual privacy is introduced. It determines relationship between collection and dissemination of visual information, the public expectation of privacy, and the legal and ethical issues surrounding them.</p><p>A valuable review of visual privacy and visual privacy protection methods is given in <ref type="bibr" target="#b35">[38]</ref>. Authors classified the methods for privacy protection of individuals appearing in videos into five large categories: (i) interventionpreventing someone to capture private visual data from the environment; (ii) blind vision -image or video processing in an anonymous way; (iii) secure processingprocess visual information in a privacy respectful way; (iv) redactionmethods based on image filtration, encryption and ksame family algorithms, object/people removal, visual abstraction/ object replacement, and (v) data hidingsteganography and watermarking-based methods.</p><p>Most of the described methods in Section 5.1 are applicable for the de-identification of still, frontal facial images or facial images in a television broadcast, but not necessarily suitable for use with video-surveillance systems. The reasons are: (i) such privacyprotection schemes degrade the visual quality needed for security; (ii) they do not preserve the naturalness of the de-identified moving images; (iii) most of them modify the surveillance videos in an irreversible fashion; (iv) real-time processing is required <ref type="bibr" target="#b51">[54]</ref>.</p><p>Special attention in the field of privacy protection is now being devoted to automatic face de-identification in video surveillance systems because of their privacy-intrusive characteristics <ref type="bibr" target="#b4">[5]</ref>. The process of automatic face de-identification in videos includes face detection, face tracking and face masking. Currently, there are two main approaches to face detection <ref type="bibr" target="#b74">[78]</ref>: the feature-based approach and the image-based approach. The feature-based approach uses low-level analyses (based on edges, colour, grey-level, motion), feature analyses (facial feature extraction, face detection based on anthropometric measures, statistical-based grouping of facial features in face-like constellations), and active shape models (snakes, deformable templates, point distributed models). The image-based approach detects faces via a learning procedure that classifies examples into face and non-face prototype classes. The main methods are linear subspace methods, neural networks, and statistical methods. A useful overview of the face-detecting methods in images and videos is given in <ref type="bibr" target="#b75">[79]</ref>.</p><p>In the time period 1998-2005. there were face-detector candidates for use in videos as follows: neural network based detector <ref type="bibr" target="#b76">[80]</ref>, Schneiderman-Kanade detector <ref type="bibr" target="#b55">[58]</ref>, Viola-Jones detector <ref type="bibr" target="#b56">[59]</ref>, local edge orientation histograms based (EOH) <ref type="bibr" target="#b77">[81]</ref>, and histograms of oriented gradients <ref type="bibr" target="#b78">[82]</ref>.</p><p>In <ref type="bibr" target="#b51">[54]</ref>, a detector based on the combination of background subtraction, bag-of-segments features and a Support Vector Machine (SVM) is described. The authors reported 92% accuracy for SVM classifier trained with 1500 examples, in a test set consisting of 1000 examples.</p><p>More recently, new methods have been proposed for face detection, pose estimation and landmark localization in the wild. Pose estimation and face landmark localization are important to preserve naturalness de-identified videos. In <ref type="bibr" target="#b79">[83]</ref>, a unified model for face detection, pose estimation and landmark localization using a mixture of trees with a shared pool of part templates is described. The authors compared the results of face detection of proposed approach with OpenCV frontal and profile Viola-Jones detector, Boosted frontal and profile face detector, deformable part model (DPM) and commercial systems (Google Picasa's face detector, face.com). The proposed method significantly outperform popular detectors currently in use, and are on par with commercial systems trained with billions of examples, such as Google Picasa and face.com. In <ref type="bibr" target="#b80">[84]</ref>, the multiple registered image channels are computed using linear and non-linear transformations (e.g. gradient histograms, colour (including grayscale, RGB, HSV and CIE-LUV), gradient magnitude, Gabor filters, and Difference of Gaussian (DoG) filters) of the input image. In the next step, features are extracted from each channel using sums over local rectangular regions. These local sums and features, based on Haar-like wavelets, their various generalizations, and local histograms, are efficiently computed by using multiple sums and integral images. The proposed method combines the richness and diversity of information from image channels with the computational efficiency of the Viola and Jones detection. In <ref type="bibr" target="#b81">[85,</ref><ref type="bibr" target="#b82">86]</ref>, in order to avoid the computational bottleneck of many modern detectors, i.e. the construction of an image pyramid, the authors proposed fast method for object detection based on approximation of multi-resolution image features, instead of their computing explicitly. Based on such an approach, the authors demonstrated on pedestrian detection tasks (INRIA, ETH, and TUD-Brussels databases) that speedup for 1-2 orders of magnitude was achieved compared to state-of-the-art detection performance (6 fps on 640  480 image resolution).</p><p>Face tracking is the process of locating a moving human face (or multiple human faces) in a sequence of frames. In the case of multiple human faces, the process should be capable of discriminating and tracking individual faces in the given video. Tracking is based on features such as segmented regions, skincolour models <ref type="bibr" target="#b83">[87]</ref>, local binary patterns (LBP) <ref type="bibr" target="#b84">[88]</ref>, a combination of LBP and skin-colour information <ref type="bibr" target="#b85">[89]</ref>, a combination of shape and texture information <ref type="bibr" target="#b86">[90]</ref>, and histogram-based Mean-Shift features <ref type="bibr" target="#b87">[91]</ref>. Face tracking includes the prediction of a face location in the next image frame based on the motion model or the information obtained from the previous consecutive frames. Kalman filters and particle filters are normally used for predictions. On the basis of this prediction, the face tracking can be treated as a local search problem where the features are locally searched within a search window instead of the entire image. In order to increase the tracking speed, an adaptive search window is used. Its size may grow with the square of the maximum velocity of the face.</p><p>The combination of face detection and tracking, i.e. the combination of the spatial and temporal correspondence between frames, can improve the effectiveness of the localization of faces. An example of such an approach is applying a bi-directional tracking algorithm that combines face detection, tracking and background subtraction <ref type="bibr" target="#b51">[54]</ref>. The effectiveness of the face detection and tracking is very important because the face has to be detected and de-identified in each frame of the videos. If the face cannot be detected even in only one frame (and so is not deidentified), it leads to a major degradation in the privacy protection.</p><p>Each localized and traced face region in each frame has to be de-identified by some effective means. A possible method for this purpose is masking. Some approaches to face masking for privacy protection in video-surveillance systems follow techniques that are used in still-face images.</p><p>In <ref type="bibr" target="#b88">[92]</ref>, privacy filters with varying strength degrees, based on simple approaches such as masking, blurring, pixelation, warping and morphing, are applied on the FERET database to investigate the influence of the filters' strength parameters on the performance of PCA-, Linear Discriminant Analysis (LDA), LBP-based face recognition algorithms. The authors concluded that the morphing filter is the best choice among the tested privacy filters. In <ref type="bibr" target="#b89">[93]</ref>, a cartooning privacy filter, which converts raw images into abstracted frames where the privacy revealing details are removed, is described. Cartooning applied on pre-selected privacy sensitive regions of interest (ROIs) demonstrated an acceptable level of privacy protection while maintaining a good utility level.</p><p>An alternative approach to face de-identification, especially popular in the video-surveillance domain, is based on distortion applied to the face image by using transform-domain scrambling methods. For example, in <ref type="bibr" target="#b90">[94,</ref><ref type="bibr" target="#b91">95]</ref>, the authors have proposed two scrambling methods for video coding standard H.264/AVCone of the most commonly used formats for the recording, compression, and distribution of video content. Both methods scramble the quantized transform coefficient of each 4  4 block of the region of interest by pseudo-randomly flipping their sign, or by applying a random permutation of the coefficients. These two methods are fully reversiblethe authorized user, by using a secret encryption key, can reverse the scrambling process and recover the image of the face.</p><p>It is important to note that, the last few years have witnessed considerable attention towards real-time, privacy-protection video systems. Examples of systems in this category are Respectful Cameras <ref type="bibr" target="#b92">[96]</ref>, PrivacyCam <ref type="bibr" target="#b93">[97]</ref>, TrustCam <ref type="bibr" target="#b94">[98]</ref>, and the De-Identification Camera <ref type="bibr" target="#b33">[35]</ref>. In the Respectful Cameras system, users who wish to be protected wear colour markers (hats or vests) that are tracked and the faces of such users are masked in real time. The tracker is based on a 9-dimensional colour space and the combination of a particle filter and a probabilistic AdaBoost algorithm. Because of the type of markers used, the system is well suited to dynamic scenes. An elliptical white cover is used to hide the faces of users.</p><p>The DSP-based PrivacyCam <ref type="bibr" target="#b93">[97]</ref> system implements the realtime Privacy through an Invertible Cryptographic Obscuration (PICO) process that consists of five basic steps: (i) capture of the image with a camera; (ii) detection of the region of interest (face detection, skin detection, motion detection); (iii) exchanging public key, generating session key, and storing the secured key along with the protected region information; (iv) selective encryption of the region (human face region) to be protected. The face is protected by scrambling the coefficients used for the JPEG image encoding. The TrustCam prototype system <ref type="bibr" target="#b94">[98]</ref> consists of a network of trustworthy cameras and a control station. Each camera is equipped with an individual Trusted Platform Module (TPM) that is used for the data encryption to hide the identity of individuals captured in a video.</p><p>The De-Identification Camera <ref type="bibr" target="#b33">[35]</ref> is an example of real-time privacy protection at the sensor level. The de-identification pipeline in this case consists of the background segmentation (motion detection), person detection based on histograms of gradients (HOG) <ref type="bibr" target="#b78">[82]</ref>, tracking based on Mean-Shift, segmentation of an image based on a bounding box that forms the video tube for each person in real time, and a de-identification transform applied to the video tube. The real-time de-identification transform uses two types of "naive" procedures: the Gaussian blur of pixels inside a bounding box, and the binarization of the pixels inside the bounding box. Note that the De-Identification Camera performs de-identification of the whole human figure. Due to the scrambling of the coefficients, or using "naive" de-identification techniques, all the above-described systems produce de-identified videos that do not preserve the naturalness of the original videos.</p><p>A more sophisticated privacy protection in videos is obtained by replacing a face with a generic face. The preliminary results of such an approach applied to video sequences are shown in <ref type="bibr" target="#b66">[70]</ref>. Recently, in order to improve the naturalness and utility of a deidentified video, the adoption of de-identification methods for still images is proposed in <ref type="bibr" target="#b95">[99]</ref>. Normally, the faces captured in a video sequence are of varied poses. Such variations may range from a full left profile to a full right profile (yaw angle from  90to 90) and a pitch from  90to 90, while the roll is usually more restricted. Following the idea from k-Same-Select <ref type="bibr" target="#b65">[69]</ref>, where images are grouped before de-identification to preserve the facial expression and the gender, the proposed approach groups the face images into a person-specific set of images according to their poses. Each person-specific set is represented by an active appearance model. A raw face image is matched with each of the active appearance models of a person-specific set of images. The model with the best matching based on shape and texture is chosen to represent the pose of the raw face image. Then, from the images in the selected person-specific set of images, one image is chosen to replace the texture of the raw image. The shape of the de-identified face image remains the same as that detected during the model fitting, but the texture is changed. Note that in order to enhance the privacy protection, instead of using the most similar appearance for the raw image, the appearance of an image that is far enough (q-far based on the Euclidean distance) is used <ref type="bibr" target="#b95">[99]</ref>. The proposed de-identification method is irreversible. Fig. <ref type="figure">5</ref>. illustrates the above-described approach.</p><p>In <ref type="bibr" target="#b53">[56]</ref>, the authors give the general framework of de-identification by describing different scenarios of video capturing (casual videos, public surveillance and private surveillance videos), criteria for de-identification and methods of subverting the deidentification. They proposed a method of de-identification that consists of three modules: Detect-and-track, Segmentation and De-identification. The detect-and-track module combines a HOGbased person detector and a robust tracking algorithm. The tracking algorithm uses a patch-based recognition approach: the object is divided into multiple spatial patches and each of them is Fig. <ref type="figure">5</ref>. Illustration of the q-far de-identification method <ref type="bibr" target="#b95">[99]</ref>: a) original image; b) de-identified image q 35; c) image used for the face swapping.</p><p>tracked by a voting mechanism based on the histogram of the corresponding image patch <ref type="bibr" target="#b52">[55]</ref>. The system uses the bounding boxes of the person in every frame and forms a video tube across time. Each detected person in a video has his or her own video tube. The segmentation of the video tube is performed by using the so-called fixed-size voxels (x  y  t) in the spatial (x, y) and temporal (t) domains. The result of the segmentation is the classification of the voxels into two classes: foreground and background. The de-identification is performed on foreground voxels by applying the exponential blur of pixels in the voxel or line integral convolution. The implemented system was tested on standard databases like CAVIAR and BEHAVE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">De-identification in drone-based surveillance systems</head><p>Drones (RPAS -Remotely Piloted Aircraft Systems or UAV -Unmanned Aerial Vehicles) are aircraft without a human pilot on board, which are guided by a remote pilot. Drones normally carry video camera(s), but they can be equipped with high power zoom, thermal, night vision, Wi-Fi sensors, and microphones. They might also have the capability of recording and storing images or video footage and uploading the images/video to the internet.</p><p>Micro-drones (of a weight up to 2 kg) and small drones or minidrones (of a weight up to 20/25 kg) are widely used in leisure time and in commercial applications, such as video surveillance and inspection, and photography, on account of their affordable prices (from a few hundred to more than twenty thousand Euro). Due to the drones' characteristics (a mobile view in 3D, the fact that they are often non-detectable, have the ability to observe a scene in detail and access different locations, and follow an object of interest), their video surveillance scenarios can be considerably different from those associated with "classic" CCTV surveillance systems. As a consequence, new issues for the risk of privacy and data protection have arisen, especially when drones are used in illegal, unsafe or irresponsible ways. Typical examples of privacy violation are situations where a drone is very close to a room or bathroom window, or when it captures images of people in their gardens. Although privacy expectations are greatly reduced in public places, the non-governmental use of a drone to capture images and other information taken while an individual is in a public place could nonetheless constitute an invasion of privacy. Some national agencies for privacy and data protection, as well as bodies of the European Parliament, the USA, Australia, Canada and other countries are intensively working on documents related to the privacy and data protection implications of the (civil) use of drones <ref type="bibr" target="#b96">[100]</ref><ref type="bibr" target="#b97">[101]</ref><ref type="bibr" target="#b98">[102]</ref>.</p><p>The problem of drone-based surveillance and its effects on privacy, from the ethical and legal aspects, have been elaborated in papers <ref type="bibr" target="#b99">[103]</ref><ref type="bibr" target="#b100">[104]</ref><ref type="bibr" target="#b101">[105]</ref>. The common conclusion is that, based on current trends of technological development, law enforcement interests, political pressure and pressure from industry, and the lack of legal safeguards, it is clear that drones pose a looming threat to privacy and policy, and therefore regulatory responses are necessary. Regarding the ethical issue, it is assumed that the actions of drones are subject to ethical evaluation based on the actions of the person controlling the drone, the intentions of that person and the consequences produced by the drone. This raises privacy and ethical concerns, including issues of safety, discrimination, and the potential dehumanisation of the person or persons surveilled.</p><p>Additionally, in the absence of a comprehensive legislative framework, there is a need for a more flexible approachone that proactively provides strong privacy protection and stimulates innovation in a win-win manner. In short, the subject of drones is one that is ripe for the attention of Privacy by Design. Until now, little has been done on the technical aspects of privacy protection for mini drone-based surveillance scenarios. In <ref type="bibr" target="#b102">[106]</ref>, the authors tested the five privacy filters: blurring, pixelation, masking, morphing <ref type="bibr" target="#b72">[76]</ref> and warping <ref type="bibr" target="#b73">[77]</ref> for privacy protection using their own video data set of typical drone-based sequences taken in a parking area. The dataset contains 38 video footages (16-24 s) captured in full HD resolution, captured by the mini-drone Phantom 2 Vision . Privacy filters were applied, depending on the video surveillance scenarios, on the following manually annotated privacy sensitive ROIs: body silhouette, facial region, accessories (bag, backpack), license plate and video capture information (video format, resolution, frame rate). For an assessment of the tradeoff between privacy protection and the intelligibility of the deidentified videos, for each privacy filter and its different strength level, the authors used a crowdsourcing approach <ref type="bibr" target="#b103">[107]</ref>. In our opinion, there are many problems related to de-identification for drone-based surveillance scenarios: automatically real-time and robust detection and localization of privacy sensitive ROIs, realtime adaptive adjustment of filter parameters due to changing the perspective view of the on-board camera, simultaneously using different types and sizes of privacy filters for different privacy sensitive ROIs, and a trade-off among intelligibility, privacy protection and naturalness. The above problems should be solved in the Privacy-by-Design approach. In <ref type="bibr" target="#b104">[108]</ref>, a simple false colouring method of an entire frame or ROI was applied for privacy protection in short clips captured by a surveillance mini-drone dataset. False colouring preserves privacy without compromising pleasantness and intelligibility, and it is applicable for a real-time system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Fingerprint de-identification</head><p>Fingerprint still images as multimedia documents, at first glance, should not be a focus of interest in this paper for two reasons. First, in many situations fingerprint recognition is categorized as an overt biometric application, i.e. a person is cooperative and aware that he or she is being subjected to recognition <ref type="bibr" target="#b105">[109]</ref>. Second, in the centre of our interest are multimedia documents mainly collected at a distance. However, there are two important reasons which have prevailed in the decision to include fingerprints. First, based on the Biometric Market Report <ref type="bibr" target="#b106">[110]</ref>, fingerprint-based biometric systems are the leading biometric technology in terms of market share. Consequently, with the widespread applications of fingerprint techniques in recognition systems, the privacy protection of the fingerprint becomes an extremely important issue. Second, according to the newest reports of ongoing research <ref type="bibr" target="#b107">[111]</ref>, it is possible to detect fingerprints by shining polarized light onto a person's hand at a distance of up to two meters and analyzing the reflection using two cameras configured to detect different polarizations. Based on the captured fingerprint image, it is possible to identify a person at a distance. This could be a privacy threat in the near future.</p><p>It is worth noting that fingerprints, besides identification information, carry additional private, sensitive information. Based on fingerprints, one can make an inference about gender <ref type="bibr" target="#b108">[112]</ref>, ethnicity <ref type="bibr" target="#b109">[113]</ref>, diseases such as Huntington's chorea and Parkinson's <ref type="bibr" target="#b110">[114]</ref> and Alzheimer's <ref type="bibr" target="#b111">[115]</ref>, and others.</p><p>In traditional fingerprint-based recognition systems, fingerprint templates can be the subject of different types of attack: from a sensor (fake finger), through a feature extraction module, to a database with stored templates.</p><p>Fingerprint still images may be de-identified with the usual deidentification procedures such as black box, blurring, pixelation, replacement by a synthetic fingerprint <ref type="bibr" target="#b105">[109]</ref> or by applying privacy filters based on image morphing and/or block scrambling. In addition, feature perturbation and noninvertible feature transforms <ref type="bibr" target="#b112">[116]</ref>, as well as watermarking techniques, are used for hiding biometric templates <ref type="bibr" target="#b113">[117]</ref>.</p><p>In order to protect the privacy of a fingerprint database for the authentication system, instead of an original fingerprint image, a binary thinned fingerprint image is used in the enrolment phase <ref type="bibr" target="#b114">[118]</ref>. Additionally, the user identity is hidden in the thinned fingerprint image based on a data embedding key. Data are hidden by adding some boundary pixels in the thinned fingerprint. The template with a hidden identity is stored in an online database for user authentication. During the fingerprint matching process, first the added boundary pixels are removed and the original thinning fingerprint is recovered and then it is used for matching with the live thinning fingerprint. The same authors proposed a method for protecting fingerprint privacy based on a combination of two fingerprints captured from two different fingers of the same person <ref type="bibr" target="#b115">[119]</ref>. From one fingerprint image, the minutia positions are extracted, while the orientation is taken from the other fingerprint. The reference points are extracted from both fingerprint images. Based on these extracted features, the combined minutia template is generated and stored in the database. The complete minutiae feature of a single fingerprint is protected, and an attacker is unable to reconstruct the complete minutiae feature of a single fingerprint. By using the reconstruction approach, it is possible to convert the combined minutiae template into a synthetic real-look fingerprint image <ref type="bibr" target="#b115">[119]</ref>. A similar approach to fingerprint de-identification is proposed in <ref type="bibr" target="#b116">[120]</ref>. It is based on mixing two fingerprint images in order to generate a new cancellable fingerprint image, which looks like a plausible fingerprint (Fig. <ref type="figure" target="#fig_5">6</ref>).</p><p>Methods used for privacy enhancement based on different types of distortion of original biometric templates at the signal or feature level may also be applied to hide soft-biometric identifiers (gender, ethnicity) and/or medical information in fingerprint templates. In <ref type="bibr" target="#b117">[121]</ref>, the authors describe a relatively simple method of fingerprint de-identification for gender estimation. The proposed approach is based on image filtering in the frequency domain. The linear filtering process applies blurring by attenuating the high-frequency content. Certain frequency components are suppressed, while others are amplified. The de-identified fingerprint image is obtained by using the inverse of the Fourier transform. Experiments have shown that the gender estimation accuracy in de-identified fingerprint images for 100 users is reduced from the initial 88.7% (original fingerprints) to 50.5%.</p><p>To the best of our knowledge, apart from <ref type="bibr" target="#b115">[119,</ref><ref type="bibr" target="#b117">121]</ref>, there has been no research to evaluate the degree of protection of medical or other privacy sensitive information for such distorted fingerprints and its impact on the identification performance. In <ref type="bibr" target="#b115">[119]</ref>, the authors report that the recognition system based on a virtual fingerprint obtained by the combination of two different fingerprints achieved a relatively low error rate with FRR 0.4% and FAR 0.1%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Iris de-identification</head><p>Iris represents an important biometric identifier and it enables an efficient approach to reliable, non-invasive identification of people due to its utmost cross-person variability, and minimal within-person variability across time <ref type="bibr" target="#b118">[122,</ref><ref type="bibr" target="#b119">123]</ref>. Most iris-recognition systems require users' cooperation to collect images of adequate quality. Due to the small size of the iris (about 10 mm in diameter) and the required typical resolution between 100 and 200 pixels across the iris diameter, the images are captured at a relatively close standoff (i.e. between 15 and 50 cm), where the standoff is the camera-to-subject-iris distance. A short overview of the main iris-recognition systems and their comparison is given in <ref type="bibr" target="#b120">[124]</ref>. Most commercial iris-recognition systems operate at a standoff between 0.1 and 0.45 m, with a verification time of 2-7 s <ref type="bibr" target="#b120">[124,</ref><ref type="bibr" target="#b121">125]</ref>. However, the Iris at a Distance (IAD) system developed recently provides the capability to identify a person at a range of more than 1 m in less than a second <ref type="bibr">[126]</ref>.</p><p>The recent iris-recognition technology is oriented to reducing the need for subject cooperation, reducing the time of image acquisition and increasing the distance between the sensor and the person <ref type="bibr" target="#b121">[125,</ref><ref type="bibr" target="#b122">[127]</ref><ref type="bibr" target="#b123">[128]</ref><ref type="bibr" target="#b124">[129]</ref><ref type="bibr" target="#b125">[130]</ref><ref type="bibr" target="#b126">[131]</ref><ref type="bibr" target="#b127">[132]</ref>. For example, in <ref type="bibr" target="#b126">[131]</ref> the authors introduced the IAD prototype system, which is capable of acquiring an iris image at 30 m standoff and perform iris recognition (Fig. <ref type="figure" target="#fig_6">7</ref>.).</p><p>Based on the characteristics of the current iris-recognition systems at a distance, and expected future advances in the field, it can be concluded that iris de-identification for privacy protection is a growing problem. An additional complexity to note is that most IAD systems combine face and iris image acquisition. Therefore, both biometric identifiers have to be simultaneously de-identified, i.e. a multimodal de-identification has to be applied.</p><p>To date, however, research into iris de-identification for privacy protection has been rather limited. A rare study related to deidentification of the eye areas, and thus the iris, is presented in <ref type="bibr" target="#b128">[133]</ref>. The proposed system for the reversible de-identification of an eye region consists of two modules: an automatic eye-detection module and a privacy-enabling encoder module. The automatic eye-detection module in real time locates the human-eye region by a combination of colour-based and Haar-like/GentleBoost methods. The input to the privacy-enabling encoder module is the pixel location information of both eyes in the given input frame. Based on a JPEG XR encoder the macrobloks consisting of 16  16 pixels of located eye region are scrambled. The privacy-enabling JPEG XR encoder utilized three encryption techniques (Random Level Shift, Random Permutation, Random Sign Inversion) to transform the coefficients of frequency sub-bands on a macroblock basis. The de-identified images, due to scrambling, lose their original naturalness, but they prevent iris recognition. Also, depending of the dimensions of the scrambling block, the proposed scheme successfully prevents any correct face identification. Fig. <ref type="figure" target="#fig_7">8</ref> depicts the organization of the eye region scrambling module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Ear de-identification</head><p>Despite the fact that the face and iris, in addition to fingerprints, are the most used in biometric technologies for person recognition, they both have a number of drawbacks. Face-based biometrics can fail due to the changes in head pose, facial expressions, the growth of a beard, hair styles, the presence of obstacles (glasses, scarf, or collar), cosmetics, aging, and/or changing the illumination conditions in unconstrained environments. An iris is stable and consistent over time, but due to the relatively small dimension it requires a high-resolution camera and a long-distance Near-infrared (NIR) illuminator for image acquisition at a distance. Therefore, a human ear is offered as an alternative physiological biometric identifier for non-invasive person identification or verification at a distance. In <ref type="bibr" target="#b129">[134,</ref><ref type="bibr" target="#b130">135]</ref>, comprehensive surveys on two-dimensional (2D) and three-dimensional (3D) ear recognition are presented. These studies have covered over 80 publications on ear detection and recognition in the period 2007-2012.</p><p>A 2D ear image can be easily acquired from a distance, even without the cooperation of the subject. This fact makes ear-based recognition systems also interesting for applications in intelligent video-surveillance systems <ref type="bibr" target="#b131">[136]</ref><ref type="bibr" target="#b132">[137]</ref><ref type="bibr" target="#b133">[138]</ref>. Until now, ear-recognition systems were successfully tested in controlled indoor conditions <ref type="bibr" target="#b129">[134]</ref>. There are some unsolved problems in automatic ear recognition relating to the disruptive factors present in real-life scenes, like pose variations, scaling, varying lighting conditions, and hair occlusion, and these open up new research areas.</p><p>Despite the relatively long period of research in the field of automatic ear-based person recognition and its maturity, as far as we know, there are no existing commercial 2D or 3D ear-based biometric systems for automatic person identification or verification. This is the main reason for lack of research in the field of ear de-identification for privacy protection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">De-identification of behavioural biometric identifiers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Voice de-identification</head><p>Such biometric identifiers as the face, iris and ear refer to the visual identity of a person. However, in addition to a visual identity, a person has an audio identity. This is based on the speech signal, which carries privacy-sensitive information such as gender, age, emotional state, health status, level of education, origin and the identity of the speaker. The human voice is a unique pattern that identifies an individualthere are no two individuals that sound identical <ref type="bibr" target="#b134">[139]</ref>. Voice is a significant modality that can be used effectively by humans and machines for the recognition of individuals. Applications and services such as audio-video surveillance, speech-based services, life-log systems and telephonebased services enable person identification based on voice, and therefore flag the importance of privacy protection.</p><p>The human voice is usually classified as a behavioural identifier in the field of biometrics <ref type="bibr" target="#b135">[140,</ref><ref type="bibr" target="#b136">141]</ref>, but it is a hybrid of physiological and behavioural identifiers. A voice pattern is determined by physiological properties, such as vocal folds, vocal tract shapes, and the characteristics of the excitation source (lungs, trachea), but it also conveys behavioural characteristics: rhythm, intonation, vocabulary, particular accent and pronunciation pattern, and talking style.</p><p>Voice-recognition systems (i.e. voice-based person identification or verification systems or speaker recognition systems; see Section 2) are classified as text-dependent (or fixed-text) and textindependent (or free-text) systems <ref type="bibr" target="#b134">[139]</ref>. Text-dependent systems are suitable for cooperative users and require the speaker to say a certain phrase. Text-independent systems have no such request and any speech can be captured and analysed in order to verify or identify a user. The text-independent voice recognition systems that require low-level or even no user cooperation are particularly interesting from the privacy point of view. In <ref type="bibr" target="#b137">[142]</ref>, a text-independent privacy-preserving speaker verification system based on a password matching principle is proposed. The process of authentication is based on a client-server model, where the speaker verification system has the role of server, and the user executes a client program on a network-enabled computation device (e.g. computer or smart-phone). The authentication system does not observe the (raw) speech input provided by the user. Instead, speech input is represented in the form of 2496-  dimensional supervectors (64  39, where 64 is the number of components of the Gaussian Mixture Model (GMM) and 39 is the dimension of the Mel Frequency Cepstral Coefficients (MFCC)based feature vector) on which the cryptographic hash function is applied. The speech samples, needed for matching in the verification phase, are stored in the same form in the internal storage of the system. So, the speech samples are irreversibly obfuscated from the system and this one-way transformation preserves the privacy of a user's speech utterances.</p><p>Voice de-identification is based on the principles of voice transformation (VT). Voice transformation refers to modifications of the non-linguistic characteristics of a given utterance without affecting its textual content. The non-linguistic information of speech signals, such as voice quality and voice individuality, may be controlled by VT <ref type="bibr" target="#b138">[143]</ref>, which is based on three types of voice modifications <ref type="bibr" target="#b139">[144]</ref>: source, filter and their combination. Source modifications include time-scale, pitch and energy modifications, while filter modifications refer to a modification that changes the magnitude response of the vocal tract system. Voice conversion <ref type="bibr" target="#b140">[145]</ref><ref type="bibr" target="#b141">[146]</ref><ref type="bibr" target="#b142">[147]</ref> is a special form of VT where the characteristics of a source speaker's voice are mapped to those of a specific (target) speaker. Voice conversion may be text-dependent or text-independent. In the first case, during the learning phase a parallel corpora (training material of source and target speaker uttering the same text) is required. This is the main limitation of using such an approach for voice de-identification in real-world applications.</p><p>Text-independent voice conversion <ref type="bibr" target="#b143">[148]</ref><ref type="bibr" target="#b144">[149]</ref><ref type="bibr" target="#b145">[150]</ref> does not require parallel corpora in the learning phase and it is more realistic for speaker-privacy protection.</p><p>One of the earliest proposed voice-conversion methods that can be used for de-identification is described in <ref type="bibr" target="#b141">[146]</ref>. The authors present a text-dependent voice-conversion method based on vector quantization and spectral mapping. The method produces a mapping codebook that shows correspondences between the codebook of the source and target speaker. The voice-conversion method consists of two sets: a learning step and a conversionsynthesis step. During the learning step, based on the parallel corpora, the mapping codebooks for several acoustic parameters that describe a mapping between the vector spaces of two speakers are generated. The synthesized speech from using the mapping codebooks is generated in the conversion-synthesis step. The evaluation of the proposed method (for male-to-female and male-to-male conversion) is performed subjectively.</p><p>Voice de-identification for the privacy protection of life-log video <ref type="bibr" target="#b146">[151,</ref><ref type="bibr" target="#b147">152]</ref> is based on voice distortion by altering the pitch by the Pitch-Scale Synchronous Overlap and Add (PitchScale SOLA) method. The distortion is accomplished in two steps, i.e. by time stretching the audio signal, and then re-sampling it to obtain the original length.</p><p>In <ref type="bibr" target="#b148">[153]</ref>, the authors propose a transformation of the speaker's voice that enables the secure transmission of information via voice without revealing the identity of the speaker to unauthorized listeners. Owing to the transmitted key, which allows the authorized listeners to perform back-transformation, the voice deidentification is reversible. The authors use a strategy for deidentifying these results in the speech of various speakers to be transformed to the same synthetic (target) voice. They use the GMM-mapping based VT to convert a relatively small set of source speakers (24 males) to a syntactic voice. The proposed VT system has training and a testing or transformation phase. During the training phase a parallel corpora of utterances is used. The authors tested different voice-transformation strategies (standard GMMmapping-based voice transformation, de-duration voice transformation, double voice transformation, and transterpolated voice transformation). The best results for de-identification are obtained with transterpolated voice transformation (100% de-identification rate for the GMM-based the voice-identification system, and 87.5% for Phonetic voice-identification system). In <ref type="bibr" target="#b149">[154]</ref>, the same authors present voice de-identification via voice transformation, similar to <ref type="bibr" target="#b148">[153]</ref>, but de-identification with larger groups of speakers is easier and it can keep the de-identified voices distinguishable from each other, which contributes to its naturalness. They reported a 97.7% de-identification rate for male and 99% for female speakers.</p><p>A novel scheme for voice de-identification, where a set of precalculated voice transformations based on GMM mapping is used to de-identify the speech of a new speaker, is presented in <ref type="bibr" target="#b150">[155]</ref>. The scheme enables the online de-identification of speakers whose speech has not been used in the training phase to build a voice transformation. The scheme uses automatic voice identification within the set that is used to build pre-calculated voice transformations to select the appropriate transform, which is then used to de-identify the speech of the new user. The approach avoids the need for a parallel corpus, even for training of the initial set of transformations based on GMM mapping, and it was inspired by an approach that is used for face de-identification (e.g., k-Same). The preliminary experiments showed that the proposed scheme produces de-identified speech, which has satisfactory levels of naturalness and intelligibility, and a similar de-identification rate in comparison with previous VT systems <ref type="bibr" target="#b148">[153,</ref><ref type="bibr" target="#b149">154]</ref>.</p><p>In <ref type="bibr" target="#b151">[156]</ref>, an approach to voice de-identification based on a combination of diphone recognition and speech synthesis is proposed. De-identification is performed in two steps. First, the input speech is recognized with a diphone-based recognition system and converted into phonetic transcription. In the second step, phonetic transcription is used by a speech synthesis subsystem to produce a new speech. With this approach, the acoustic models of the recognition and synthesis subsystems are completely independent and a high level of protection of speaker identity is ensured. Two different techniques for speech synthesis are used: one is Hidden Markov Model (HMM)-based and one is based on the diphone Time-Domain Pitch Synchronous Overlap and Add (TD-PSOLA) technique. Since every user's speech utterance is converted into the speech of the same speaker (whose data were used during the training phase of the synthesis subsystem), the described process of de-identification is irreversible. The system is applicable in different scenarios where users either want to conceal their identity or are reluctant to transmit their natural speech through the communication channel. The proposed voice deidentification system runs in real time and is language dependent and text independent. The obtained de-identified speech was evaluated for intelligibility and evaluated in speaker recognition experiments by a state-of-art speaker recognition system (i-vector/Probabilistic LDA). The experiments showed that the speaker recognition system was unable to recognize the true speaker identities from the de-identified speech with a performance better than chance, while the de-identified speech was intelligible in most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Gait and gesture de-identification</head><p>Gait is defined as a manner of walking and represents a behavioural biometric characteristic <ref type="bibr" target="#b152">[157,</ref><ref type="bibr" target="#b153">158]</ref>. Gait, as a body gesture, which is usually a motion without meaning, conveys information that can be used for person identification or for diagnostics. Besides the dynamics of individual walking, gait includes information about individual appearance, such as silhouette, leg length, height, even age, and gender <ref type="bibr" target="#b154">[159,</ref><ref type="bibr" target="#b155">160]</ref>. By introducing visual surveillance systems in people's daily lives, and owing to the development of computer-vision techniques, it is possible to recognize non-cooperating individuals at a distance based on their walking characteristics.</p><p>In general, there are two basic approaches to gait recognition: sensor-based and video-based. In sensor-based recognition the individuals are cooperative and have tactile and wearable sensors. This approach is normally used in medicine for diagnosis of patients' health status. In a video-based gait-recognition approach, optical cameras are used to obtain the videos of the walking individual(s) <ref type="bibr" target="#b156">[161]</ref>. There are two common categories of automatic video-based gait recognition <ref type="bibr" target="#b157">[162]</ref>: model-based and appearancebased (or model-free) approaches. Model-based approaches <ref type="bibr" target="#b155">[160,</ref><ref type="bibr" target="#b158">163,</ref><ref type="bibr" target="#b159">164]</ref> rely on the identification of specific gait parameters in the gait sequence and extract the motion of the human body by means of fitting their models to the input gait sequence. Such models are view and scale invariant, but require high-quality gait sequences. Model-free approaches <ref type="bibr" target="#b160">[165]</ref><ref type="bibr" target="#b161">[166]</ref><ref type="bibr" target="#b162">[167]</ref> do not require structural models of human motion. They establish a correspondence between successive frames in the video sequence based upon a prediction or estimation of the features related to position, velocity, shape, texture, and colour. One of the most popular approaches to gait recognition is silhouette-based gait recognition <ref type="bibr" target="#b160">[165,</ref><ref type="bibr" target="#b162">167,</ref><ref type="bibr" target="#b163">168]</ref>. In <ref type="bibr" target="#b160">[165]</ref>, the authors proposed a simple baseline method for person identification based on the body silhouette and the gait, which provides a lower bound against which to evaluate more complicated procedures.</p><p>A gait recognition process typically consists of the following phases: capturing the walking sequence, background subtraction, feature extraction, and recognition where the extracted gait features are compared with gait features that are stored in a database.</p><p>The performance of gait recognition systems is evaluated on the HumanID challenge database using different ranks (rank-1 and rank-5) <ref type="bibr" target="#b164">[169]</ref>. The experiments have shown that for the baseline algorithm, for twelve experiments, the average recognition rate for rank 1 was 40.95%, while it was 64.54% for rank 5. The different gait-recognition algorithms, based on the HMM, LDA, and Gabor filter approaches, achieved rank-1 recognition rates from 42% to 60%, and for rank 5 it was from 65% to 78%.</p><p>Based on the state of the art for gait recognition systems, their characteristics and performances, we can conclude that gait-based technologies can be used for biometric-based person verification in controlled environments. It is technically unfeasible for largescale surveillance systems to record all the gait parameters of individuals in public places, as well as to identify them by searching in a database <ref type="bibr" target="#b157">[162]</ref>.</p><p>Very few studies have been directly geared towards gait deidentification. The study in <ref type="bibr" target="#b165">[170]</ref> presents an automated videosurveillance system designed to ensure the efficient and selective storage of data, to provide a means for enhancing privacy protection, and to secure visual data against malicious attacks. The approach to the privacy enhancement of captured video sequences is based on two main steps: the first step is performed by the salient motion detector, which finds ROIs (corresponding mainly to moving individuals), and the second step applies to those regions with a procedure of information concealment based on a scrambling technique described in <ref type="bibr" target="#b91">[95]</ref>. The DCT-based scrambling is applied to each ROI, represented by a rough binary mask, which covers a silhouette of the moving individual, so the gait information is obscured. Image regions corresponding to the involved individuals in the scene are distorted, while the scene still remains comprehensible. Owing to the reversible scrambling procedure, the authorized user can get a clear video sequence and reveal all the privacy details by using the embedding and scrambling keys. The de-identified videos, due to the scrambling procedure, do not preserve the naturalness of the original videos.</p><p>In <ref type="bibr" target="#b52">[55,</ref><ref type="bibr" target="#b53">56]</ref>, gait de-identification based on two de-identification transformations, i.e.(for the definition of voxel see Section 5.2), and line integral convolution (LIC) is proposed. These two kinds of smooth temporal blurring of the space-time boundaries of an individual aim to remove any gait information.</p><p>Gestures are defined as the movement of a body part (fingers, hands, arms, head, or face) or a whole body that is made with or without the intension meaning something <ref type="bibr" target="#b166">[171,</ref><ref type="bibr" target="#b167">172]</ref>. For example, the expressive and meaningful motion of fingers or hands conveys meaningful information to another human, or it can be used for interacting with a real or virtual environment (virtual reality, augmented reality).</p><p>The fact that gestures vary between individuals can be exploited for person recognition <ref type="bibr" target="#b168">[173,</ref><ref type="bibr" target="#b169">174]</ref>. From the gesture-recognition point of view there is a problem because gestures vary for the same individuals at different instances. The approaches to the tracking, analysis and recognition of gestures in video <ref type="bibr" target="#b170">[175]</ref> enable the effective interaction with the environment, but can also be used for people verification or identification.</p><p>To date, there have only been a few attempts to develop biometric verification systems based on hand-gesture recognition <ref type="bibr" target="#b168">[173,</ref><ref type="bibr" target="#b169">174,</ref><ref type="bibr" target="#b171">176,</ref><ref type="bibr" target="#b172">177]</ref>.</p><p>As far as we know, there has been no research into the problem of hand gesture de-identification. The problem of gesture de-identification in video surveillance is similar to the problem of gait deidentification and can be solved by approaches similar to those used for gait.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">De-identification of soft biometric identifiers</head><p>Soft biometric identifiers are physical, behavioural or adhered human characteristics of the person that provide some information about the person, but lack the distinctiveness and permanence to sufficiently differentiate any two persons <ref type="bibr" target="#b39">[42]</ref>. However, soft biometric identifiers, as ancillary information, can be combined by biometric identifiers to improve the overall recognition, particularly when recognition system is designed to work in accordance with the less constrained scenarios including recognition at a distance <ref type="bibr" target="#b173">[178]</ref>.</p><p>There are four main modalities of using soft biometric identifiers for: i) person identification or verification based on the measured soft biometric identifiers <ref type="bibr" target="#b173">[178]</ref>, ii) person identification or verification based on verbal descriptions of soft biometric identifiers <ref type="bibr" target="#b40">[43]</ref>, iii) person identification or verification in a biometric system based on the fusion of soft biometric identifiers and physiological and/or behavioural biometric identifiers in order to ensure better accuracy of the recognition process <ref type="bibr" target="#b39">[42]</ref>, iv) retrieval of large biometric databases <ref type="bibr" target="#b174">[179,</ref><ref type="bibr" target="#b175">180]</ref>.</p><p>Regardless of the above-described modalities of using soft biometric identifiers, it is obvious that soft biometric identifiers, such as silhouette, gender, race, moles, tattoos, birthmarks, and scars, carry privacy-intrusive information about individuals, and have to be de-identified in a multimedia document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Body silhouette de-identification</head><p>The body silhouette is an important soft biometric identifier and it can help the recognition process (on its own or in combination with other biometric identifiers, e.g. gait). In addition to recognition, body silhouettes are used for people re-identification, i.e. tracking people across multiple cameras with non-overlapping fields of view in surveillance applications <ref type="bibr" target="#b176">[181]</ref>.</p><p>To the best of our knowledge there are only a few papers on body silhouette de-identification. In <ref type="bibr" target="#b52">[55,</ref><ref type="bibr" target="#b53">56]</ref>, the authors showed that the masking of a silhouette is relatively easy, through the use of dilatation or Gaussian blurring. The Gaussian blurring of the silhouette is also used for the de-identification of individuals in activity videos (Fig. <ref type="figure" target="#fig_8">9</ref>.) <ref type="bibr" target="#b177">[182]</ref>. In <ref type="bibr" target="#b53">[56]</ref>, it has been shown that a combination of line integral convolution (LIC) and the exponential blurring of pixels of a voxel gives the best results for silhouette deidentification.</p><p>An approach to reversible body de-identification in video is based on distortion applied to the ROI which contains the silhouette of an individual by using transform-domain scrambling methods proposed in <ref type="bibr" target="#b90">[94,</ref><ref type="bibr" target="#b91">95]</ref> (see Section 5.2). Fig. <ref type="figure" target="#fig_0">10</ref>. illustrates the result of the body de-identification by the scrambling method described in <ref type="bibr" target="#b90">[94]</ref>.</p><p>An interesting approach to silhouette de-identification is described in <ref type="bibr" target="#b178">[183]</ref>, it involves replacing a person with another one from a dataset gallery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Gender, age, race and ethnicity de-identification</head><p>In literature, there are many papers related to the automatic recognition of gender, age, race and ethnicity, but relatively little is done on their de-identification in multimedia content. Information about gender, age, race and ethnicity is usually obtained from facial images <ref type="bibr" target="#b179">[184]</ref><ref type="bibr" target="#b180">[185]</ref><ref type="bibr" target="#b181">[186]</ref><ref type="bibr" target="#b182">[187]</ref><ref type="bibr" target="#b183">[188]</ref> and/or a speaker utterance <ref type="bibr" target="#b184">[189]</ref>, gait and silhouette <ref type="bibr" target="#b153">[158]</ref>, and silhouetted face profiles <ref type="bibr" target="#b185">[190]</ref>. In <ref type="bibr" target="#b53">[56]</ref>, the authors have mentioned that the masking of race and gender is a difficult problem. However, they agreed that it is possible to mask skin colour (which is closely related to race) using different colour transformations at the price of destroying the naturalness of the de-identified videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Scars, marks and tattoos de-identification</head><p>Scars, marks and tattoos (SMT) are imprints on skin that provide more discriminative information than age, height, gender, and race to identify a person <ref type="bibr" target="#b186">[191]</ref>. In <ref type="bibr" target="#b187">[192]</ref>, the authors have showed that facial marks, such as freckles, moles, scars and pockmarks can improve automatic face recognition and retrieval performance. For example, the experimental face-recognition system based on a combination of Active Appearance Models (AAMs) to locate and segment a facial image on eyes, nose, and mouth regions, and Laplacian-of-Gaussian (LoG) and morphological operators to detect facial marks, has improved the rank-1 identification accuracy of a state-of-the-art face recognition system from 92.96% to 93.90% on the FERET database and from 91.88% to 93.14% on the Mugshot database.</p><p>A methodology for detecting SMT found in unconstrained imagery normally encountered in forensics scenarios is described in <ref type="bibr" target="#b188">[193]</ref>. As far as we know, there are no published papers related to de-identification of scars and marks.</p><p>Tattoos are not only popular in particular groups, such as motorcyclists, sailors, and members of criminal gangs, they have become very popular in the wider population. In fact, about 24% of people aged from 18 to 50 in the USA have at least one tattoo, and this number is increasing <ref type="bibr" target="#b189">[194]</ref>.</p><p>Tattoos are primarily used for Content-based Image Retrieval (CBIR) in law-enforcement applications <ref type="bibr" target="#b190">[195,</ref><ref type="bibr" target="#b191">196]</ref>, but based on the visual appearance of tattoos and their location on a body <ref type="bibr" target="#b189">[194]</ref>, they can be used for person recognition, as well as for suspect and victim identification in forensics.</p><p>The main features used for tattoo recognition are Scale Invariant Feature Transform (SIFT) features <ref type="bibr" target="#b186">[191,</ref><ref type="bibr" target="#b188">193]</ref>, active contours and so-called glocal featureslocal features that contain global information regarding colour and edge orientation <ref type="bibr" target="#b192">[197]</ref>.</p><p>There are no published papers related to SMT de-identification, except <ref type="bibr" target="#b193">[198]</ref>. The experimental system for tattoo localization and de-identification for privacy protection <ref type="bibr" target="#b193">[198]</ref> was intended to be used for still images, but it was also tested for videos. The system consists of the following modules: skin and ROI detection, feature extraction, tattoo database, matching, tattoo detection, skin swapping, and quality evaluation. An image or a sequence of frames obtained by a colour camera is an input to the skin and ROI detection module. Uncovered body parts like the head, neck, hands, legs or torso are detected in two phases. In the first phase, skin-colour cluster boundaries are obtained by a pixel-based method through a series of decision rules in the RGB colour space. In the second phase, geometrical constraints are used to eliminate skin-like colour regions that do not belong to the uncovered bodypart areas. The SIFT features are extracted from a ROI in the feature-extraction module. The SIFT features are matched with Fig. <ref type="figure" target="#fig_0">10</ref>. Result of the body silhouette de-identification by the scrambling method described in <ref type="bibr" target="#b90">[94]</ref>.</p><p>template SIFT features from the tattoo database. Experimentally, 24 tattoos with at least two tattoos from each of the eight classes of tattoos labelled in the ANSI/NIST-ITL 1-2000 standard are used. Each tattoo in the tattoo database has an average of 56 template SIFT features, so the tattoo database consists of 1338 SIFT features. The de-identification process is performed in the skin-swapping module in such a way that the original tattoo's region is replaced by pixels from a surrounding, non-tattoo region. After replacement, a median filter is applied to the de-identified area. With this procedure, the authors try to hide the tattoo location and its visual appearance, and preserve the naturalness of the de-identified image (Fig. <ref type="figure" target="#fig_9">11.</ref>).</p><p>The experiments have shown that tattoo localization based on SIFT features gave satisfactory results in well-controlled conditions, such as lighting, high tattoo resolution, and no motion blur. For tattoos with a low-quality visual appearance, the SIFT features have to be combined with some region segmentation based on a combination of colour, gradient and/or texture methods. For surveillance applications, by using skin-and tattoo-area tracking based on a spatial and temporal correspondence between the frames, tattoo detection, localization and de-identification can be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Discussion</head><p>In spite of the huge efforts of various academic research groups, institutions and companies, research in the field of de-identification and multimodal de-identification in multimedia content is still in its infancy. Relatively little has been done in the field of deidentification of non-biometric identifiers, except in the field of text and license plate de-identification. To avoid "pair-wise constraint" identification <ref type="bibr" target="#b51">[54]</ref> and the classification of individuals in categories (which can be treated as privacy invasive), additional efforts have to be made in the field of dressing style and hairstyle de-identification (initial and pioneering efforts have been made only to conceal hairstyles and hair colour <ref type="bibr" target="#b194">[199]</ref>). The problem of selectively concealing or removing the context-sensitive information or objects from the environment which can be used to reveal the identity of a person is still open. This could be solved in the near future by using a knowledge-based approach for modelling a specific environment and situation to detect additional ROIs and to obscure them.</p><p>At first glance, it looks as though the problem of license plate de-identification has been solved in web services like Google Street View and EveryScape, but the main problem is plate detection in video footages. According to some recent reports <ref type="bibr" target="#b54">[57]</ref>, undetected license plates amount to between 4% and 6%. The percentage is too high, so it is difficult to claim that de-identification of license plates has been successful. It is important to stress that computer vision techniques for the detection and tracing of object(s) of interest have to be improved and made reliable and robust. Privacy protection in web services like Google Street View and EveryScape is a typical example of the open problem of multimodal de-identification where multiple ROIs (e.g. faces, body silhouettes, license plates) have to be detected and obscured. For example, Google reports that its completely automatic system is able to blur 89% of faces, which means that many faces remain unblurred in Google Street View video footages <ref type="bibr" target="#b54">[57]</ref>.</p><p>In the field of face de-identification in still images, irreversible naive methods such as "blurring" and "pixelation" of the image region occupied by the face may protect the identity from the human observer, but these naive methods may be subverted by a machine applying so-called parrot recognition.</p><p>The irreversible de-identification methods referred to as k-Same, k-Same-Select and Model-based k-Same algorithms for face de-identification guarantee theoretical probable privacy (1/k), where k is the number of the closest face images to the raw face image in the person specific set. Reversible privacy-preserving methods for photo sharing applications, and morphing-based visual privacy protection, as well as scrambling-based methods, are convenient for privacy protection in social networks and photo hosting platforms. The state-of-the-art of face de-identification methods in still images enables a balance between privacy and naturalness, and simultaneously offers preservation of data utility (e.g. facial expression, age).</p><p>De-identification of the face in video surveillance systems is far from a complete solution. The problem lies not in the de-identification of ROIs, but in computer vision algorithms for the detection and localization of face(s) in video sequences. Despite recently intensive research in computer vision, numerous problems still remain to be solved in automatic face detection. These include issues such as the detection of the face under different illumination conditions, bad lighting conditions, different head positions, the presence of structural components (e.g., glasses, sunglasses, beards, moustaches), and occlusions. The unsolved problems are the detection of faces in crowd scenes and real-time de-identification. Privacy might be compromised in video sequences if the face detection algorithm fails in a single frame, so one of the directions of research is the development of robust and effective algorithms for privacy protection that can efficiently cope with situations when computer vision algorithms fail <ref type="bibr" target="#b35">[38,</ref><ref type="bibr" target="#b195">200]</ref>.</p><p>De-identification in drone-based surveillance systems deserves special attention due to specific problems which are, in a computer vision sense, very close to Moving-Camera-Moving Object (MCMO) problems and different scenarios in comparison with "classic" CCTV surveillance. There are open problems in the detection of several ROIs (face, body silhouette, accessories, different positions and sizes) in dynamic scenes. Due to the complex problem of de-identification in drone-based surveillance systems, it is expected that the Privacy-by-Design approach has to be applied together with strict laws regarding the use of drones. The de-identification of fingerprint still images is important in two respects: (i) privacy protection of the fingerprint as a biometric template in authentication systems; (ii) hidden privacy sensitive information (e.g. gender, ethnicity, health status) which can be revealed from the fingerprint pattern. Regarding the first aspect, there are already standards and architectures for biometric template protection. For the de-identification of other privacy sensitive information, different de-identification methods based on privacy filters or generating syntactic fingerprints can be used. The same methods employed for fingerprint template protection can be used for iris template protection in authentication systems. In the near future, we can expect surveillance systems capable of acquiring an iris image at a distance of more than 30 m and performing the identification of an individual. There is therefore a need for iris de-identification. Pioneering research work in this direction based on scrambling an eye region has been conducted. The Iris at a Distance systems are also capable of acquiring a face, which leads to multimodal de-identification.</p><p>Due to the development of relatively low-cost, high-resolution, video cameras and telescopic equipment, we can expect ear-based recognition and tracking in semi-or non-controlled outdoors conditions. This will lead to the need for research and development of ear de-identification methods in order to protect the privacy of individuals. Most ear-recognition systems use the combination of a profile face and ear detection. Therefore, in the near future, ear de-identification will be a multimodal de-identification problemthe face and the ear have to be de-identified simultaneously.</p><p>There are several challenges in the field of online voice or speaker de-identification, such as de-identification in an environment with background noise, voice de-identification in situations where there are multiple individuals speaking simultaneously, which leads to crosstalk and overlapped speech. Additional efforts have to be made to develop more sophisticated voice de-identification systems with "personalized" multi-target voices and the preservation of the emotional expression of a speaker.</p><p>Approaches to gait and gesture de-identification are mainly based on scrambling techniques and the temporal blurring of the space-time boundaries of an individual. The main problem with gait and gesture de-identification in a video-surveillance system (which may be feasible in the near future) is how to obscure the characteristics of an individual's movement and/or walking patterns, and at the same time preserve the usability and naturalness of the de-identified video. As far as we know, there are no published research reports on gesture de-identification.</p><p>In spite of the fact that soft biometric identifiers do not offer enough distinctive information to differentiate any two individuals, certain types of these identifiers (e.g. SMT, body silhouette, gender, age, race, birthmarks) carry private, sensitive and intrusive information on individuals, and therefore should be hidden or removed from multimedia content.</p><p>De-identification of soft biometric identifiers, such as the body silhouette, is based on naive privacy filters, reversible filters based on scrambling methods, or replacing a person with another one from a dataset gallery. The precondition for successful body silhouette de-identification is foreground (i.e. body silhouette) detection in videos. But, due to complex environments, non-stationary background motion, illumination variation, and camera vibration, detection is still far from perfect. In addition, the problem of masking the temporal variation of a body silhouette in such a way as to preserve the naturalness of de-identified videos remains unresolved.</p><p>The masking of soft biometric identifiers such as race, ethnicity and gender in video surveillance applications, is a difficult problem. Experts agree that it is possible to mask these identifiers, but at the cost of destroying the naturalness of the de-identified videos.</p><p>Preliminary research has been carried out in the field of tattoo de-identification in still images, but there are many unsolved problems: the localization of tattoos in the images of complex scenes, the localization of tattoos with a low-quality visual appearance and images taken under different angles of view.</p><p>Due to recent advances in multi-sensor acquisition and recording devices and remote surveillance systems, there is a need for the research and development of multimodal de-identification methods that simultaneously hide, remove or substitute different types of personal identifiers from multimedia content. A solution to the problem of multimodal de-identification still remains a major challenge.</p><p>Important aspects of de-identification are metrics in measuring privacy protection in multimedia content, the utility or intelligibility and naturalness or/and pleasantness of the de-identified data, as well as the evaluation protocol <ref type="bibr" target="#b196">[201]</ref>. There is not yet a common framework for the evaluation and assessment of these components in de-identified multimedia contents. Researchers are primarily focusing on the evaluation of privacy protection, intelligibility, pleasantness and the trade-off between privacy protection and utility/intelligibility for privacy filters applied on face regions in images and video sequences (FERET database, PEViD-HD and PEViD-UHD datasets <ref type="bibr" target="#b72">[76,</ref><ref type="bibr" target="#b88">92]</ref>). The evaluation of privacy protection and the trade-off between privacy protection and utility/intelligibility are usually performed by objective methods (PCA-, LDA-and LBP-based automatic face recognition) and subjective evaluation <ref type="bibr" target="#b91">[95,</ref><ref type="bibr" target="#b197">202]</ref> based on crowdsourcing <ref type="bibr" target="#b103">[107]</ref>, or by experts (video-analytics technology and privacy protection solution developers, or law enforcement personnel). Ongoing research activities regarding privacy protection and its evaluation in surveillance systems are presented in MediaEval workshops, established as an independent benchmarking initiative in 2010 (http:// www.multimediaeval.org/).</p><p>The assessment of the de-identification of behavioural biometric identifiers is mainly devoted to privacy protection and to the intelligibility of de-identified speech <ref type="bibr" target="#b198">[203]</ref>.</p><p>Due to the social, legal and political importance of privacy protection, de-identification also requires a platform for studies of the legal, ethical and social aspects of de-and re-identification in multimedia content and social network sites, as well as the strong cooperation of experts in the technical and social sciences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion</head><p>Privacy is one of the most important social and political issues in any free society. In our networked society, which is characterized by technologies and services such as internet, wireless communication, social networks, biometrics, multimedia, big data, data-mining, and audio and video surveillance, and drone-based surveillance, the problem of the privacy protection of individuals has become a major challenge for experts from law, political, ethical and technical domains. De-identificationa process of concealing, removing or substituting personal identifiers in multimedia contentis a method for protecting privacy. In this paper, we try to give an up-to-date review of de-identification methods for privacy protection in multimedia content. Based on proposed taxonomy of personal identifiers present in multimedia documents we have presented de-identification of non-biometric, physiological, behavioural biometric identifiers, and soft-biometric identifiers. Regarding the trends in the surveillance technology, we have announced some new directions in the de-identification research: de-identification of iris and fingerprints captured at distance, gait and gesture de-identification, and multimodal de-identification which combines non-biometric, physiological, behavioural and soft-biometric identifiers. We have pointed out the problems of detecting and removing or hiding social and environmental privacy sensitive context in multimedia contents, as well as open problems of metrics and protocols for evaluation and assessment of privacy protection, intelligibility, and naturalness or/and pleasantness in de-identified multimedia contents.</p><p>This paper covers mainly the technical aspects of de-identification. But, due to the social, legal and political importance of privacy protection, we are aware that real solutions for de-identification, which are acceptable to both users and the law enforcement organisations in a networked society, will have to be based on the collective effort of experts from the fields of law, ethics, sociology and psychology as well as technical experts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Taxonomy of identifiers in multimedia content.</figDesc><graphic coords="5,86.51,471.46,432.00,261.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Naive methods of face de-identification: a) Original image; b) Blurring: s 2  18; c) Pixelation: parameter p 12 [65].</figDesc><graphic coords="6,130.73,606.27,324.00,126.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>is represented by an average face image of the k closest face images from the person-specific set of images. The k closest face images in the person specific set are replaced by the same k de-identified face images. The k-Same algorithm selects the k closest images based on Euclidean distances in the image space or in the PCA coefficient space. Fig. 3. illustrates the k-Same algorithm (k 4) where for a person-specific set of face images I (which consists of 12 original images), the set of de-identified face images D is computed. The set D consists of 12/k identical face images, where each image is represented as an average of the k 4 closest original images. Fig. 4. gives an example of k-Same de-identification for value k 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of k-Same algorithm (modified from [68]). As an example it should be noted that the original images I 1 , I 4 , I 6 and I 9 are represented with the same de-identified face image D 1 ; Ia person-specific set of face images; Da set of de-identified face images; a sum of the k closest face images from a personspecific set of images I.</figDesc><graphic coords="7,60.04,439.31,216.00,258.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. k-Same de-identification: a) Original image; b) De-identified image for k  6; [65].</figDesc><graphic coords="7,329.05,58.62,216.00,132.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Mixing fingerprints: a) Original fingerprint; b) Transformation function -fingerprint from a different finger; c) a new mixed fingerprint image that obscures the identity of the original fingerprint [120].</figDesc><graphic coords="11,140.54,567.72,324.00,156.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. a) The IAD prototype system; b) View of the eye at 30 m by Iris Image Acquisition Camera [131].</figDesc><graphic coords="12,50.23,58.62,216.00,134.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Eye region scrambling module [133].</figDesc><graphic coords="12,50.23,229.89,216.00,271.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. De-identification of individuals in activity videos depicting: a) walking; b) jumping in place actions after 2D Gaussian filtering [182].</figDesc><graphic coords="15,140.54,58.62,324.00,149.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Tattoo de-identification; a) An example of a still image obtained by a colour camera; b) Extracted SIFT features; c) De-identified tattoo still frame<ref type="bibr" target="#b193">[198]</ref>.</figDesc><graphic coords="16,76.71,58.62,432.00,120.70" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>S. Ribaric et al. / Signal Processing: Image Communication 47 (2016) 131-151</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work has been supported by the Croatian Science Foundation under project 6733 De-identification for Privacy Protection in Surveillance Systems (DePPSS). It is also the result of activities in COST Action IC1206 "De-identification for Privacy Protection in Multimedia Content".</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Wireless smart camera networks for the surveillance of public spaces</title>
		<author>
			<persName><forename type="first">K</forename><surname>Abas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Porto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Obraczka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="37" to="44" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Survey on contemporary remote surveillance systems for public safety</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Raty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man., Cybern. -Part C</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="493" to="515" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Nothing to Hide</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Solove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Yale University Press</publisher>
			<pubPlace>New Haven &amp; London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Privacy in video surveillance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="168" to="169" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Privacy protection in a video surveillance system</title>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Protecting Privacy in Video Surveillance</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="35" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Dragnet Nation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Angwin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>St. Martin&apos;s Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Right to Privacy</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Brandeis</surname></persName>
		</author>
		<idno>02.06. 14</idno>
		<ptr target="http://readingnewengland.org/app/books/righttoprivacy/" />
	</analytic>
	<monogr>
		<title level="j">Harv. Law Rev. IV</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Social and political dimensions of privacy</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Westin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soc. Psychol. Study Social. Issues</title>
		<imprint>
			<biblScope unit="page" from="431" to="453" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Understanding Privacy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Solove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Campisi</surname></persName>
		</author>
		<title level="m">Security and privacy in biometrics: towards a holistic approach</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Campisi</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
	<note>Privacy and Security in Biometrics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Court European Court of Human Rights, Date of Judgment 28</title>
		<ptr target="http://www.worldlii.org/eu/cases/ECHR/2003/44.html" />
	</analytic>
	<monogr>
		<title level="m">EMLR 287</title>
		<imprint>
			<date type="published" when="2003-01">Jan 2003</date>
		</imprint>
	</monogr>
	<note>accessed 04.11.15</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Expanding Surveillance State: Why Colorado Should Scrap the Plan to Map Every Driver&apos;s Face and Should Ban Facial Recognition in Public Places</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krause</surname></persName>
		</author>
		<ptr target="https://www.i2i.org/articles/8-2001.PDF" />
	</analytic>
	<monogr>
		<title level="s">Issue Paper Number</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
	<note>accessed 04.11.15</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Standardization of biometric template protection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Multimed</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="94" to="99" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cancelable biometric filters for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V K</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Khosla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition (ICPR)</title>
		<meeting>the International Conference on Pattern Recognition (ICPR)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="922" to="925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generating cancelable fingerprint templates</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ratha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chikkerur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="561" to="572" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Combining cryptography with biometrics effectively</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1081" to="1088" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cancelable voiceprint templates based on knowledge signatures</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Electronic Commerce and Security</title>
		<meeting>the International Symposium on Electronic Commerce and Security</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="412" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A survey on biometric cryptosystems and cancelable biometrics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rathgeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Uhl</surname></persName>
		</author>
		<ptr target="http://jis.eurasipjournals.com/content/2011/1/3" />
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Inf. Secur</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
	<note>accessed 10.01.15</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cancelable biometrics: a review</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ratha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="54" to="65" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PICO: privacy through invertible cryptographic obscuration</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/NSF Workshop on Computer Vision Interact</title>
		<meeting>the IEEE/NSF Workshop on Computer Vision Interact</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ethical considerations in the conduct of electronic surveillance research</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bharucha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wactlar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Dew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Law, Med. Ethic</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Gellman</surname></persName>
		</author>
		<idno>05.06.15</idno>
		<ptr target="//www.bobgellman.com/rg-docs/rg-FIPShistory.pdf" />
		<title level="m">Fair Information Practices: A Basic History</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Directive 95/46/EC of the European Parliament and of the Council of 24 October</title>
		<idno>CELEX:31995L0046:en:HTML</idno>
		<ptr target="http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?ur" />
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note>accessed 10.01.15</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Review of EU Data Protection Directive: Summary</title>
		<author>
			<persName><forename type="first">N</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Graux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Valeri</surname></persName>
		</author>
		<idno>02.07.13</idno>
		<ptr target="https://ico.org.uk/media/about-the-ico/documents/1042347/review-of-eu-dp-directive-summary.pdf" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Privacy and power: computer databases and metaphors for information privacy, 53 Stan</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Solove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">L. Rev</title>
		<imprint>
			<biblScope unit="volume">1393</biblScope>
			<biblScope unit="page" from="1393" to="1461" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Privacy legislation: a comparison of the US and European approaches</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hinde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Secur</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="378" to="387" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">U.S. and EU privacy policy: comparison of regulatory approaches</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Movius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Journal. Commun</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="169" to="187" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A Comparison Between US and EU Data Protection Legislation for Law Enforcement Purposes</title>
		<author>
			<persName><forename type="first">F</forename><surname>Boehm</surname></persName>
		</author>
		<idno>17.11.15</idno>
		<ptr target="http://www.europarl.europa.eu/RegData/etudes/STUD/2015/536459/IPOL_STU%282015%29536459_EN.pdf" />
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>European Parliament</publisher>
			<biblScope unit="page" from="1" to="81" />
			<pubPlace>Brussels</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Reform of EU Data Protection Rules</title>
		<ptr target="http://ec.europa.eu/justice/data-protection/reform/index_en.htm" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>accessed 04.05.16</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<idno>08.07.13</idno>
		<ptr target="https://www.niap-ccevs.org/Documents_and_Guidance/cc_docs/cc_users_guide.pdf" />
		<title level="m">Common Criteria for Information Technology Security Evaluation</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Van Blarkom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Borking</surname></persName>
		</author>
		<title level="m">Handbook of Privacy and Privacy-Enhancing Technologies, College Bescherming Persoonsgegevens</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">G E</forename><surname>Olk</surname></persName>
		</editor>
		<meeting><address><addrLine>The Hague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Langendrfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Piotrowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peter</surname></persName>
		</author>
		<ptr target="//www.ics.uci.edu/$steffenp/files/langendoerfer2008privacy.pdf" />
		<title level="m">Privacy Enhancing Techniques: A Survey and Classification</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
	<note>accessed 29.11.15</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Cavoukian</surname></persName>
		</author>
		<idno>07.11.15</idno>
		<ptr target="https://www.privacybydesign.ca" />
		<title level="m">Privacy by Design</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The de-identification camera</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mrityunjay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Natlional Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics</title>
		<meeting>the 3rd Natlional Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="192" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Practical Implications of Sharing Data: A Primer on Data Privacy, Anonymization, and De-Identification</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Nelson</surname></persName>
		</author>
		<ptr target="http://thotwave.com/wp-content/uploads/2015/09/data_sharing_privacy_anonymization_and_de-identification_rev_13.pdf" />
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visual privacy protection methods: a survey</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Padilla-Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Chaaraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Florez-Revuelta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert. Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4177" to="4195" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Recommendation-based De-Identification, A Practical Systems Approach Towards De-identification of Unstructured Text in Healthcare</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bhagwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grandison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Maltzahn</surname></persName>
		</author>
		<idno>15.07.14</idno>
		<ptr target="//www.almaden.ibm.com/cs/people/tgrandison/SPE2012-ReDid.pdf" />
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="155" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><surname>Hipaa</surname></persName>
		</author>
		<ptr target="http://www.hhs.gov/ocr/hipaa" />
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bag of soft biometrics for person identification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dantcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Velardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>D'angelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J. -L</forename><surname>Dugelay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimed. Tools Appl</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="739" to="777" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Soft biometric traits for personal recognition systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Dass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nandakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Biometric Authentication</title>
		<meeting>the International Conference on Biometric Authentication</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="731" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Soft biometrics; human identification using comparative descriptors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Stevenage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1216" to="1228" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automated de-identification of free-text medical records</title>
		<author>
			<persName><forename type="first">I</forename><surname>Neamatullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Douglass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reisner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viallarroel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Med. Inform. Decis. Mak</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">32</biblScope>
			<biblScope unit="page" from="1" to="73" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Replacing personally-identifying information in medical records, the Scrub system</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AMIA Annual Fall Symposium</title>
		<meeting>the AMIA Annual Fall Symposium</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="333" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Computational disclosure control: a primer on data privacy protection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">216</biblScope>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Tools for De-Identification of Personal Health Inf</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Willison</surname></persName>
		</author>
		<idno>05.05</idno>
		<ptr target="//www.ehealthinformation.ca/wp-content/uploads/2014/08/deid.pdf" />
	</analytic>
	<monogr>
		<title level="j">Can. Health Infoway</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evaluating the state-of-the-art in automatic de-identification</title>
		<author>
			<persName><forename type="first"></forename><surname>Uzuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="550" to="563" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Garfinkel</surname></persName>
		</author>
		<idno type="DOI">10.6028/NIST.IR.8053</idno>
		<idno>17.12.15</idno>
		<ptr target="http://dx.doi.org/10.6028/NIST.IR.8053" />
	</analytic>
	<monogr>
		<title level="j">NISTIR 8053 De.-Identif. Personal. Inf</title>
		<imprint>
			<biblScope unit="page" from="1" to="54" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Attribute and simile classifiers for face verification</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the 12th IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="365" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Method of human hair for hair sketching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Classified</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Congress on Image Signal Process. (CISP)</title>
		<meeting>the Congress on Image Signal Process. (CISP)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="109" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Real-time clothing recognition in surveillance videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th IEEE International Conference on Image Processing</title>
		<meeting>the 18th IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2937" to="2940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Solving a dress problem for a human model recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Society of Instruents Controls and Engineering (SICE)</title>
		<meeting>the Society of Instruents Controls and Engineering (SICE)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="210" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Protecting personal identification in video</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Protecting Privacy in Video Surveillance</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="115" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">De-identification for Privacy Protection in Surveillance Videos</title>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">49</biblScope>
			<pubPlace>Hyderabad</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Center for Visual Information Technology International Institute of Information Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master of Science Thesis</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Person de-identification in videos</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="299" to="310" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Large-scale privacy protection in google street view</title>
		<author>
			<persName><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdulkader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 12th International Conference on Computer Vision</title>
		<meeting>the IEEE 12th International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2373" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A statistical method for 3D object detection applied to faces and cars</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schneiderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), I</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), I</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Preservative license plate de-identification for privacy protection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Document Analysis and Recognition (ICDAR)</title>
		<meeting>the International Conference on Document Analysis and Recognition (ICDAR)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="468" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Handbook of Face Recognition</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Greenberg The effects of filtered video on awareness and privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer Support. Coop. Work., Phila</title>
		<meeting>the ACM Conference on Computer Support. Coop. Work., Phila</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Blur filtration fails to preserve privacy for home -based video conferencing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Neustaedter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Human. Interact</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An overview of face de-identification in still images and videos</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ribaric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pavesic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)</title>
		<meeting>the 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Model-based face de-identification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision. Pattern Recognit. Workshop (CVPRW)</title>
		<meeting>the Conference on Computer Vision. Pattern Recognit. Workshop (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="161" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Privacy operating characteristic for privacy protection in surveillance applications</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ratha</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3546</biblScope>
			<biblScope unit="page" from="869" to="878" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>Audio-and Video-Based Biometric Person Authentication</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Preserving privacy by de-identifying facial images</title>
		<author>
			<persName><forename type="first">E</forename><surname>Newton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Malin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="232" to="243" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Integrating utility into face deidentification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Airoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Malin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PET -Privacy Enhancing Technologies 2005</title>
		<title level="s">Lecture Notes in Computer Science (LNCS)</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Danezis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3856</biblScope>
			<biblScope unit="page" from="227" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Face de-identification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Protecting Privacy in Video Surveillance</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="129" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">k-anonymity: a model for protecting privacy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Uncertain., Fuzziness Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="557" to="570" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Active appearance models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="681" to="685" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Retaining expressions on deidentified faces</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ariyaeeinia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Bennett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Spec. Sess. Biom., Forensics, De.-Identif. Priv. Prot. (BiForD)</title>
		<imprint>
			<biblScope unit="page" from="27" to="32" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Face de-identification with perfect privacy protection, ibid</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Privacy-preserving photo sharing based on a secure JPEG</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Workshop on Security Priv. Big Data Secur</title>
		<meeting>the 3rd International Workshop on Security Priv. Big Data Secur</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="185" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Using face morphing to protect privacy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Advanced Video Signalbased Surveillance</title>
		<meeting>the IEEE International Conference on Advanced Video Signalbased Surveillance</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="208" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Using warping for privacy protection in video surveillance</title>
		<author>
			<persName><forename type="first">P</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Internationl Conference on Digital Signal Processing</title>
		<meeting>the 18th Internationl Conference on Digital Signal Processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Face detection: a survey</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hjelmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Low</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision. Image Underst</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="236" to="274" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Detecting faces in images: a survey</title>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="58" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Neural network-based face detection</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Rowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="38" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Learning Object Detection from a Small Number of Examples: the Importance of Good Features Proc</title>
		<author>
			<persName><forename type="first">K</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf. Comput. Vision. Pattern Recognit. (CVPR)</title>
		<imprint>
			<publisher>IEEE Comput. Soc</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Face detection, pose estimation, and landmark localization in the wild</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Comput. Vision. Pattern Recognit</title>
		<meeting>Conf. Comput. Vision. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2879" to="2886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Dollr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<title level="m">Integral channel features Proc. Br. Mach. Vision. Conf. (BMVC)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">The fastest pedestrian detector in the west</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dollr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Br. Mach. Vision. Conference (BMVC)</title>
		<meeting>the Br. Mach. Vision. Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Fast feature pyramids for object detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dollr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Appel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Per</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1532" to="1545" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
		<title level="m">A real-time face tracker in: Proceedings of the 3rd IEEE Workshop on Applicatioin on Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Real-time and multi-view face tracking on mobile platform</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustic, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustic, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1485" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Zuo-yong A new face tracking algorithm based on local binary pattern and skin color information</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chuan-Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Science and Computer Technology</title>
		<meeting>the International Symposium on Computer Science and Computer Technology</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="657" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">An effective shape-texture weighted algorithm for multi-view face tracking in videos</title>
		<author>
			<persName><forename type="first">W.-P</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-M</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Congress on Image Signal Processing</title>
		<meeting>the Congress on Image Signal Processing</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="156" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Real-time tracking of non-rigid objects using mean shift</title>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2000">2, 2000</date>
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Towards optimal distortion-based visual privacy filter</title>
		<author>
			<persName><forename type="first">P</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Image Processing (ICIP)</title>
		<meeting>the IEEE International Conference on Image Processing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="6051" to="6055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Adaptive cartooning for privacy protection in camera networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Erdely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Barat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rinner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th IEEE International Conference on Advanced Video Signal Based Surveillance (AVSS)</title>
		<meeting>the 11th IEEE International Conference on Advanced Video Signal Based Surveillance (AVSS)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="26" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Scrambling for privacy protection in video surveillance systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dufaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1168" to="1174" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">A framework for the validation of privacy protection solutions in video surveillance</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dufaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Multimedia and Expo (ICME)</title>
		<meeting>the IEEE International Conference on Multimedia and Expo (ICME)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Respectful cameras: detecting visual markers in real-time to address privacy concerns</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schiff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meingast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Mulligan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Protecting Privacy in Video Surveillance</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="65" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">PrivacyCam: a privacy preserving camera using uCLinux on the Blackfin DSP</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chattopadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">TrustCAM: security and privacy-protection for an embedded smart camera based on trusted computing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rinner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</title>
		<meeting>the 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="593" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">An approach to the de-identification of faces in different poses</title>
		<author>
			<persName><forename type="first">B</forename><surname>Samarzija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ribaric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Spec. Sess. Biom., Forensics, De.-Identif. Priv. Prot. (BiForD)</title>
		<imprint>
			<biblScope unit="page" from="21" to="26" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Privacy and data protection implications of the civil use of drones</title>
		<author>
			<persName><forename type="first">O</forename><surname>Marzocchi</surname></persName>
		</author>
		<idno>13.11.15</idno>
		<ptr target="//www.europarl.europa.eu/RegData/etudes/IDAN/2015/519221/IPOL_IDA%282015%29519221_EN.pdf" />
	</analytic>
	<monogr>
		<title level="j">PE</title>
		<imprint>
			<biblScope unit="volume">519</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">The regulation of the impact of civilian drones on behavioural privacy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Law Secur. Rev</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="286" to="305" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Surveillance, then and now: securing privacy in public spaces</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cavoukian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Priv. Comm. Ont</title>
		<imprint>
			<biblScope unit="page" from="1" to="64" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Ethical issues with use of drone aircraft</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Int. Symp. Ethic-. Sci., Technol. Eng</title>
		<imprint>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Observations from above: unmanned aircraft systems and privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Villasenor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harv. J. Law Public Policy</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="458" to="517" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Privacy and Drones: Unmanned Aerial Vehicles (2012) 1-30 https</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cavoukian</surname></persName>
		</author>
		<idno>24.11.15</idno>
		<ptr target="//www.ipc.on.ca/images/Resources/pbd-drones.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Privacy in mini-drone based video surveillance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bonetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ramponi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th IEEE Int. Conf. Work. Autom. Face Gesture Recognit. (FG)</title>
		<meeting>11th IEEE Int. Conf. Work. Autom. Face Gesture Recognit. (FG)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Crowdsourcing approach for evaluation of privacy filters in video surveillance</title>
		<author>
			<persName><forename type="first">P</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Multimedia 2012 Workshop Crowdsourcing Multimedia</title>
		<meeting>the ACM Multimedia 2012 Workshop Crowdsourcing Multimedia</meeting>
		<imprint>
			<publisher>CrowdMM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">MediaEval 2015 Drone Protect Task: Privacy Protection in Surveillance Systems Using False Coloring</title>
		<author>
			<persName><forename type="first">S</forename><surname>ifti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Akyz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Mediaev. Workshop</title>
		<imprint>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Maltoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Malo</surname></persName>
		</author>
		<title level="m">Handbook of Fingerprint Recognition</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Prabhakar</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Next Generation Biometric Market-Forecasts &amp; Analysis</title>
		<author>
			<persName><surname>Marketsandmarkets</surname></persName>
		</author>
		<idno>www.marketsandmarkets.com (accessed 15.11.15</idno>
		<imprint>
			<date type="published" when="2014">2014  2020. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title/>
		<author>
			<persName><surname>Technologyreview</surname></persName>
		</author>
		<ptr target="https://www.technologyreview.com/s/422400/fingerprints-go-the-distance" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>accessed 07.12.15</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Fingerprint -based gender classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Badawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahfouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tadross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jantz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Image Process., Comput. Vision., Pattern Recognit</title>
		<meeting>Int. Conf. Image ess., Comput. Vision., Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="41" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Multimodal biometrics for identity, state-of-the-art</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dessimoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Richiardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Champod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Drygajlo</surname></persName>
		</author>
		<idno>PFS 341  08. 05</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">156</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Res. Report.</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Fingerprint patterns in Huntington&apos;s Chorea and Parkinson&apos;s disease</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barbeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Trudeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Coiteux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canad. Med. Ass. J</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="514" to="515" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Weinreb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fingerprint patterns in Alzheimer&apos;s Disease</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="50" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Enhancing security and privacy in biometrics-based authentication systems</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ratha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Syst. J</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="614" to="634" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Hiding biometric data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Uludag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1494" to="1498" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Kot Privacy protection of fingerprint database using lossless data hiding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Multimedia Expo (ICME)</title>
		<meeting>the IEEE International Conference on Multimedia Expo (ICME)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1293" to="1298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Fingerprint combination for privacy protection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Secur</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="350" to="360" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename></persName>
		</author>
		<idno>17.12.15</idno>
		<ptr target="http://biometrics.nist.gov/cs/08_tuesday_ross_VC-MIX-ING_IBPC2014.pdf" />
	</analytic>
	<monogr>
		<title level="j">Biometrics Images Enhancing Priv. Secur</title>
		<imprint>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Removing gender signature from fingerprints</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lugini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marasco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cukic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dawson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Spec. Sess. Biom., Forensics, De.-identifications Priv. Prot. (BiForD)</title>
		<imprint>
			<biblScope unit="page" from="63" to="67" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">How iris recognition works</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="31" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Iris recognition: an emerging biometric technology</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Wildes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1348" to="1363" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">A survey on prominent iris recognition systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A D</forename><surname>Durai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information and Communication Embedded System (ICICES)</title>
		<meeting>the International Conference on Information and Communication Embedded System (ICICES)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="191" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Iris on the move: acquisition of images for iris recognition in less constrained environments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Matey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Naroditsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kolczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Loiacono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mangru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tinker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Zappia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1936" to="1947" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Iris Recognition at a Distance, AVBPA 2005</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bogoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wildes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science (LNCS</title>
		<imprint>
			<biblScope unit="volume">3546</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Self-adaptive iris image acquisition system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">6944</biblScope>
			<biblScope unit="page" from="6" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Stand-off Iris recognition system</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Amitha Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Abramovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd IEEE International Conference on Biometrics: Theory, Application and System (BTAS)</title>
		<meeting>the 2nd IEEE International Conference on Biometrics: Theory, Application and System (BTAS)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Eagle-eyes: a system for iris recognition at a distance</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bashir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Casaverde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Technol. Homel. Secur</title>
		<meeting>the IEEE Conference on Technol. Homel. Secur</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="426" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Design and implementation of a long range iris recognition System</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>De Villar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Ives</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Matey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Rec. 44th Asilomar Conf. Signals, Syst. Comput. (ASILOMAR)</title>
		<meeting>Conf. Rec. 44th Asilomar Conf. Signals, Syst. Comput. (ASILOMAR)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1770" to="1773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title level="m" type="main">Automatic eye-level height system for face and iris recognition systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Abiantun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Khosla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="155" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">A novel eye region based privacy protection scheme</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Plataniotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1845" to="1848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">A survey on ear biometrics Article 22</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abaza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A F</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Ear biometrics: a survey of detection, feature extraction and recognition methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pflug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Busch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Biom</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="114" to="129" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Ear detection based on skin-color and contour information</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-C</forename><surname>Mu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Machine Learning and Cybernetics</title>
		<meeting>the 6th International Conference on Machine Learning and Cybernetics</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2213" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Automatic ear detection for online biometric applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hanmandlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kuldeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics</title>
		<meeting>the 3rd National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="146" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Fast learning ear detection for real-time surveillance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abaza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A F</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th IEEE International Conference on Biometrics: Theory, Application Systems (BTAS) 2010</title>
		<meeting>the 4th IEEE International Conference on Biometrics: Theory, Application Systems (BTAS) 2010</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">An overview of text-independent speaker recognition: from features to supervectors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kinnunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="40" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pankanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ratha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Senior</surname></persName>
		</author>
		<title level="m">Guide to Biometrics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Speaker recognition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics, Personal Identification in Networked Society</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bolle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Pankanti</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="165" to="189" />
			<date type="published" when="1999">1999</date>
			<publisher>Dordrech</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Privacy-preserving speaker verification as password matching</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1849" to="1852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Voice transformation: a survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Stylianou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="3585" to="3588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Voice recognition algorithms using Mel Frequency Cepstral Coefficient (MFCC) and Dynamic Time Warping (DTW) techniques</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Muda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Elamvazuthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="138" to="143" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Voice conversion: state-of-the-art and future work, Fortschritte der Akust</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sundermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Voice conversion through vector quantization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kuwabara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="655" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Upperman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Osdol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno>14.12.14</idno>
		<ptr target="http://ftpmirror.your.org/pub/misc/cd3wd/1006/Methods_for_Voice_Conversion_electr_physics_cnx_x10252_.pdf" />
		<title level="m">Methods for Voice Conversion</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">A first step towards textindependent voice conversion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sundermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bonafonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Spoken Langanges and Processing</title>
		<meeting>the International Conference on Spoken Langanges and Processing</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Text-independent cross-language voice conversion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sundermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bonafonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Non-parallel training for voice conversion by maximum likelihood constrained adoption</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mouchtaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Spiegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Privacy Protection For Life-log System</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chaudhari</surname></persName>
		</author>
		<ptr target="http://uknowledge.uky.edu/gradschool_theses/491" />
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Lexington</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Kentucky</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
	<note>Paper 491. accessed 06.12.14</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Privacy protection for life-log system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><forename type="middle">S</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Workshop on Signal Processing Application Public Security Forensics (SAFE)</title>
		<meeting>the IEEE Workshop on Signal Processing Application Public Security Forensics (SAFE)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Voice converging: speaker de-identification by voice transformation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="3909" to="3912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Speaker de-identification via voice transformation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Workshop Automatic Speech Recognition and Understanding</title>
		<meeting>the IEEE Workshop Automatic Speech Recognition and Understanding</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="529" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Online Speaker De-identification Using Voice Transformation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pobar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ipsic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Spec. Sess. Biom., Forensics, De.-Identif. Priv. Prot. (BiForD)</title>
		<imprint>
			<biblScope unit="page" from="33" to="36" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Speaker deidentification using diphone recognition and speech synthesis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Justin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Struc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dobrisek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vesnicer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ipsic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mihelic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th IEEE International Conference on Work. Automatic Face Gesture Recognition (FG)</title>
		<meeting>the 11th IEEE International Conference on Work. Automatic Face Gesture Recognition (FG)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Automated Biometrics, Technology and Systems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Automatic gait recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cunado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Stevenage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics, Personal Identification in Networked Society</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Bolle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Pankanti</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="231" to="249" />
			<date type="published" when="1999">1999</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<title level="m">Gender Classification in Human Gait Using Support Vector Machine, ACIVS 2005, Lecture Notes in Computer Science (LNCS)</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3708</biblScope>
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Gait analysis for recognition and classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Automatic Face Gesture and Recognition (FG)</title>
		<meeting>the IEEE International Conference on Automatic Face Gesture and Recognition (FG)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="148" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">A Survey of Advances in Biometric Gait Recognition, CCBR 2011</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science (LNCS)</title>
		<imprint>
			<biblScope unit="volume">7098</biblScope>
			<biblScope unit="page" from="150" to="158" />
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Gait recognition: a challenging signal processing technology for biometric identification</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Boulgouris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hatzinakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Plataniotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="78" to="90" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">On automated model-based extraction and analysis of gait</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Wagg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Automatic Face Gesture Recognition (FG)</title>
		<meeting>the IEEE International Conference on Automatic Face Gesture Recognition (FG)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Automatic extraction and description of human gait models for recognition purposes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cunado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision. Image Underst</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Silhouette-based human identification from body shape and gait</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th IEEE International Conference on Automatic Face and Gesture Recognition (FG)</title>
		<meeting>the 5th IEEE International Conference on Automatic Face and Gesture Recognition (FG)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="351" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">General tensor discriminant analysis and Gabor features for gait recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1700" to="1715" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">What image information is important in silhouette-based gait recognition?</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Veres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<idno>II-776-II-782</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Soc. Conf. Comput. Vision. Pattern Recognit</title>
		<meeting>IEEE Comput. Soc. Conf. Comput. Vision. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Silhouette analysis-based gait recognition for human identification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1505" to="1518" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">The human ID gait challenge problem: data sets, performance, and analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="162" to="177" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Security and privacy protection for automated video surveillance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Baaziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Padilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petngang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Signal Process</title>
		<meeting>IEEE Int. Symp. Signal ess</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="17" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Gesture recognition: a survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Acharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man. Cybern. -PartC: Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="324" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">An overview of gesture recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kallel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bouhlel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications</title>
		<meeting>the 6th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="20" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Identity verification system using hand gesture information</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lentsoane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Van Wyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Van Wyk</surname></persName>
		</author>
		<idno>12.04.16</idno>
		<ptr target="http://www.prasa.org/proceedings/2006/pra-sa06-13.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Symposium on Pattern Recognition Society of South Africa</title>
		<meeting>the 17th International Symposium on Pattern Recognition Society of South Africa</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Identity Verification System Using Hand Gesture Information</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lentsoane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">202</biblScope>
		</imprint>
		<respStmt>
			<orgName>Magister Technologiae: Electronic Engineering, Department Of Electrical Engineering. Faculty of Engineering, Tshwane University of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Tracking, analysis, and recognition of human gestures in video</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Betke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kollios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Athitsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tai-Peng</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference Document on Analysis, and Recognition (ICDAR)</title>
		<meeting>the 8th International Conference Document on Analysis, and Recognition (ICDAR)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="806" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">A biometric authentication model using hand gesture images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fister</surname></persName>
		</author>
		<idno type="DOI">10.1186/1475-925X-12-111</idno>
		<ptr target="https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-12-111" />
	</analytic>
	<monogr>
		<title level="j">Biomed. Eng. OnLine</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>accessed 24.06.14</note>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Hand gesture recognition: an overview</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Premaratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vial</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Int. Conf. Broadband Netw. Multimed. Technol. (BNMT)</title>
		<imprint>
			<biblScope unit="page" from="63" to="69" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Soft biometrics and their application in person recognition at a distance</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vera-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Secur</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="464" to="475" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Large-scale civilian biometric systems issues and feasibility</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Waymann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Card. Tech./Secur. Tech. ID</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Face matching and retrieval using soft biometrics</title>
		<author>
			<persName><forename type="first">U</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Secur</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="406" to="415" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">People re-identification by classification of silhouettes based on sparse representation</title>
		<author>
			<persName><forename type="first">D.-N</forename><forename type="middle">T</forename><surname>Congl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Achard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khoudour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Image Processing and Theory Tools Applications (IPTA)</title>
		<meeting>the 2nd International Conference on Image Processing and Theory Tools Applications (IPTA)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Person de-identification in activity videos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ivasic-Kos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tefas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Spec. Sess. Biom., Forensics, De.-Identif. Priv. Prot. (BiForD)</title>
		<imprint>
			<biblScope unit="page" from="63" to="68" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Digital privacy: replacing pedestrians from Google street view images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nodari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vanetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st Int. Conf. Pattern Recognit</title>
		<meeting>21st Int. Conf. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2889" to="2893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Adapting gender and age recognition system for mobile platforms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Chinese Conference Intelligent Visual Surveillance (IVS)</title>
		<meeting>the 3rd Chinese Conference Intelligent Visual Surveillance (IVS)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="93" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">A new automatic recognition system of gender, age and ethnicity</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth World Congress Intelligent Control. Automation (WCICA)</title>
		<meeting>the Sixth World Congress Intelligent Control. Automation (WCICA)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="9988" to="9991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">A study on automatic age estimation using a large database</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the 12th IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1986" to="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Robust gender recognition for real-time surveillance system</title>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Multimedia Expo (ICME) 2010</title>
		<meeting>the IEEE International Conference on Multimedia Expo (ICME) 2010</meeting>
		<imprint>
			<biblScope unit="page" from="191" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Race recognition using local descriptors</title>
		<author>
			<persName><forename type="first">G</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alenezy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Aboalsamh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP)</title>
		<imprint>
			<biblScope unit="page" from="1525" to="1528" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Emotion-inspired age and gender recognition systems</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">T</forename><surname>-C. Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th IEEE International Midwest Symposium on Circuits Systems (MWSCAS)</title>
		<meeting>the 55th IEEE International Midwest Symposium on Circuits Systems (MWSCAS)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="662" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Gender and ethnicity identification from silhouetted face profiles</title>
		<author>
			<persName><forename type="first">U</forename><surname>Tariq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th IEEE International Conference on Image Processing</title>
		<meeting>the 16th IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2441" to="2444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Scars, marks and tattoos (SMT): soft biometric for suspect and victim identification</title>
		<author>
			<persName><forename type="first">J.-E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Biom. Symp. (BSYM)</title>
		<meeting>Biom. Symp. (BSYM)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Facial marks: soft biometric for face recognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th IEEE International Conference on Image Processing</title>
		<meeting>the 16th IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="37" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Detecting and classifying scars, marks, and tattoos found in the wild</title>
		<author>
			<persName><forename type="first">B</forename><surname>Heflin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th IEEE International Conference on Biometrics: Theory, Application and Systems (BTAS)</title>
		<meeting>the 5th IEEE International Conference on Biometrics: Theory, Application and Systems (BTAS)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Tattoos body piercing United States.: a national dataset</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Laumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Derick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Acad. Dermatol</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="413" to="421" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Large-scale tattoo image retrieval</title>
		<author>
			<persName><forename type="first">D</forename><surname>Manger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Computer Robotics and Vision</title>
		<meeting>the 9th Conference on Computer Robotics and Vision</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="454" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Image retrieval in forensics: tattoo image database application</title>
		<author>
			<persName><forename type="first">J.-E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Multimed</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="49" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Matching and retrieval of tattoo images: active contour CBIR and glocal image features</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Acton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)</title>
		<meeting>the IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="21" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">An experimental tattoo de-identification system for privacy protection in still images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marcetic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ribaric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Struc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pavesic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Spec. Sess. Biom., Forensics, De.-Identif. Priv. Prot. (BiForD)</title>
		<imprint>
			<biblScope unit="page" from="57" to="62" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Automatic hair color deidentification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Prinosil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krupka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Riha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Green Computing and Internet of Things (ICGCIoT)</title>
		<meeting>the International Conference on Green Computing and Internet of Things (ICGCIoT)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="732" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Adaptive Transformation for Robust Privacy Protection in Video Surveillance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Atrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Multimedia</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Security and privacy protection in visual sensor networks: a survey Article no</title>
		<author>
			<persName><forename type="first">T</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rinner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">An objective and subjective evaluation of content-based privacy protection of face images in video surveillance systems using JPEG XR</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>De Neve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Plataniotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Ro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Effective Surveillance for Homeland Security</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Flammini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Setola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Franceschetti</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="111" to="140" />
			<date type="published" when="2013">2013</date>
			<publisher>CRC Press/Taylor &amp; Francis</publisher>
			<pubPlace>Milton Park</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Intelligibility Assessment of the De-identified Speech Obtained Using Phoneme Recognition and Speech Synthesis Systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Justin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Miheli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dobriek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Artificial Intelligence (LNAI)</title>
		<imprint>
			<biblScope unit="volume">8655</biblScope>
			<biblScope unit="page" from="529" to="536" />
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
