<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Light Speed Arbitration and Flow Control for Nanophotonic Interconnects</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dana</forename><surname>Vantrease</surname></persName>
							<email>danav@cs.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Univ of Wisconsin -Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Binkert</surname></persName>
							<email>binkert@hp.com</email>
							<affiliation key="aff1">
								<orgName type="institution">HP Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Schreiber</surname></persName>
							<email>rob.schreiber@hp.com</email>
							<affiliation key="aff2">
								<orgName type="institution">HP Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mikko</forename><forename type="middle">H</forename><surname>Lipasti</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Univ of Wisconsin -Madison</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Light Speed Arbitration and Flow Control for Nanophotonic Interconnects</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A8BCEC7D4589C64F29A5BDA8D4E23717</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C.1.2 [Computer Systems Organization]: Multiprocessors</term>
					<term>Interconnection architectures Design</term>
					<term>Performance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>By providing high bandwidth chip-wide communication at low latency and low power, on-chip optics can improve manycore performance dramatically. Optical channels that connect many nodes and allow for single cycle cache-line transmissions will require fast, high bandwidth arbitration.</p><p>We exploit CMOS nanophotonic devices to create arbiters that meet the demands of on-chip optical interconnects. We accomplish this by exploiting a unique property of optical devices that allows arbitration to scale with latency bounded by the time of flight of light through a silicon waveguide that passes all requesters.</p><p>We explore two classes of distributed token-based arbitration, channel based and slot based, and tailor them to optics. Channel based protocols allocate an entire waveguide to one requester at a time, whereas slot based protocols allocate fixed sized slots in the waveguide. Simple optical protocols suffer from a fixed prioritization of users and can starve those with low priority; we correct this with new schemes that vary the priorities dynamically to ensure fairness. On a 64-node optical interconnect under uniform random single-cycle traffic, our fair slot protocol achieves 74% channel utilization, while our fair channel protocol achieves 45%. Ours are the first arbitration protocols that exploit optics to simultaneously achieve low latency, high utilization, and fairness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Arbitration</head><p>When several packet sources simultaneously request the right to send on a channel, an arbiter must select one and grant access. The arbitration should provide high utilization and fair sharing with low arbitration latency, at low power and hardware costs.</p><p>Arbitration will be frequent. In a cache coherent many-core system, messages are small (cache-line size or less). Areaefficient nanophotonic waveguides and dense wavelength division multiplexing enable very wide channels, which can transmit a cache line in one or two cycles. Therefore, nearly every channel will need arbitration on nearly every cycle.</p><p>Arbitration should be fast. The time to arbitrate should not add unnecessarily or excessively to the message transfer time. In our protocols, the latency of arbitration exactly matches the latency of communication, since both use the same mechanisms.</p><p>Arbitration should be effective. It should yield high utilization of the channel. End-to-end flow control can further improve bandwidth utilization by avoiding failed transmissions due to receive buffer overflows. To address this, we devise methods to allow flow control information (buffer space reservations, or credits) to be piggybacked on the arbitration signals with little overhead.</p><p>Arbitration must be fair. Sources with equal needs should receive equal service, and none should starve. Bias in arbitration can cause longer queueing delay for packets from an unfairly treated source. We ensure fairness by dynamically adjusting the arbitration priorities when the system detects an imbalance in service.</p><p>The protocols we examine are all based on the use of an optical token that signifies temporary ownership of a single channel, i.e. the right to modulate certain wavelengths on certain waveguides. In its simplest form, the token is a short, single wavelength light pulse, in effect a binary "1", that travels at the speed of light in silicon (about 10 cm/nsec) through an arbitration waveguide. Interested sources attempt to read the token by removing the light, changing the "1" to a "0"; disinterested sources do not and the token propagates unperturbed. In this way our protocols take full advantage of an important property of photonic switching devices: inac- tive nodes have no effect on the latency or power of messages that bypass them. Only the nodes that are participating (by actively requesting) in an arbitration are visible. Electronic arbitration protocols, as well as other optical protocols (all of which convert to electrical signals at each node), incur some latency for each node, whether interested or not. That disinterested nodes are effectively not present greatly lowers arbitration latency.</p><p>The latency of our arbiters-meaning the time between availability of a buffer at a destination and communication of this fact to a sender-is dictated by the length of the optical waveguides and the time of flight of a token through them. Since chip area is essentially fixed as core count grows with Moore's Law, each core in an N -core chip has area proportional to 1/N and has length and width proportional to 1/ √ N . Our waveguides follow a path that visits all N cores, like the one shown in Figure <ref type="figure" target="#fig_0">1</ref>; they therefore scale in length as N ×width of one core = O( √ N ). When N = 64 on a 576mm 2 chip with a 5GHz clock, flight time is 8 cycles. Electronic token arbiters delay the token at each node and therefor have higher latency.</p><p>The latency and power advantages of keeping the token in the optical domain at all times during arbitration come at some cost. Because optical tokens cannot be delayed, they cannot be inspected or modified as they are passing a node without removing the light from the waveguide and converting the signal to an electronic one. If the light is to be placed back on the waveguide, it must be delayed to the next clock edge. To take advantage of the fast movement of tokens in optics, they should only be removed when a node will in fact use the token. This means that nodes must use local information alone to decide whether or not a given token should be removed. So if, for example, a node is interested in two channels but can only transmit on one, it cannot claim both (by removing their respective tokens) and then release one without affecting (by delaying or consuming) the released token. Our protocols cope with these limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">An On-chip Optical Network</head><p>We apply our single-channel arbitration protocols for control of an optical interconnect that provides a dedicated, singledestination, multiple-source communication channel to each node, called a Multiple Write, Single Read (MWSR) interconnect in the Firefly terminology proposed by Pan, et al. <ref type="bibr" target="#b20">[21]</ref>. The MWSR interconnect is a common optical interconnect  architecture because it deals well with unidirectional wavepipelined technology. Our arbiters may be applied to any optical MWSR, including <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>. In addition, our arbiters are general enough to be applied to optical broadcast buses <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26]</ref>. In Section 5, we employ these protocols asynchronously on each channel of an MWSR.</p><p>In an MWSR, any node may write to a given channel but only one node (the destination or home node) may read from the channel. Optical data packets traverse the channels in a wave-pipelined, or latchless, manner from a single source to a single destination. Packets are fixed in both temporal and spatial extent. Several short packets may occupy the same channel simultaneously in moving slots. Time of flight varies with differing source-destination distance.</p><p>Firefly uses a Single Writer Multiple Reader (SWMR) interconnect, which is a dual to MWSR. In an SWMR, exactly one node may write to a given channel, but any node may read from the channel. Figure <ref type="figure" target="#fig_1">2</ref> contrasts these interconnects and shows how both provide full connectivity. An SWMR benefits from not requiring any arbitration on the part of the sender. The extra complexity, which is not present in MWSR, is that the sender must communicate to the receiver that a message is destined for it. The receiver then activates its respective detectors, which read the packet (and happen to also destroy the optical signal in the process). Firefly broadcasts a head flit to identify the designated receiver of each packet; this costs bandwidth and needs specially designed and relatively expensive broadcast waveguides and optical broadcast power.</p><p>Proposed SWMR designs may experience flow control problems, while MWSRs naturally demonstrate a degree of flow control. An MWSR node can receive at most one flit in a network cycle and as long as it can drain packets at this rate there can be no issues of flow control. On the other hand, an SWMR node may receive upto n flits in a network cycle-a much harder drain-rate to maintain. This paper shows how flow-control may be piggybacked onto arbitration in a MWSR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Power</head><p>In Section 6 we report on an experimental evaluation of the utilization, latency, and fairness of these protocols for a 64-node optical MWSR interconnect under synthetic workloads and for benchmark applications. Finally, we estimate the power used by each of our arbiters.</p><p>In summary, we make these contributions:</p><p>• We present an arbitration mechanism that for the first time satisfies all of the requirements of arbitration: it provides high channel utilization, fairly across all sources, and adds little to communication latency;</p><p>• Our mechanism takes full advantage of and copes with the limitations of optical technology described above;</p><p>• Our mechanism achieves very low latency because its tokens remain in the optical domain until consumed and used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">OPTICAL ARBITRATION</head><p>We consider optical communication structures comprised of silicon ring resonators and silicon waveguides. Waveguides confine laser light, which travels from a light source, unidirectionally, and with negligible losses. Multiple wavelengths can use the same waveguide, with no interference between them. Rings are tuned during fabrication to a particular wavelength by controlling their dimensions. When placed next to a waveguide, a ring can be used to modulate or to detect light of its particular wavelength on that waveguide, or to divert (switch) the light from one waveguide to another. The modulation, detection, and diversion functions are controlled by applying an electrical signal to the ring, which brings it into or out of resonance with its specific wavelength. We assume modulation occurs on both clock edges of the clock. Functioning ring resonators have been demonstrated <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>An activated ring detector removes all the light in the process of detecting it, thus implementing a destructive read. When the detector is inactive, the light passes the ring unperturbed. Thus, an activated detector detects a light signal if no upstream (towards the light source) detector is activated. The output of the detector is therefore a logical function of the state of all of the upstream detectors; this wired-or-like combinational operation is performed without any delay other than the time of flight of light in the waveguide.</p><p>In the simplest approach to optical arbitration, presented in Figure <ref type="figure" target="#fig_2">3</ref>, a one-bit-wide pulse of monochromatic light travels down an arbitration waveguide. The presence of this light represents the availability of a resource: it is a token. Each node has a detector on this waveguide. Nodes that want to use the channel activate their detectors (solid-and cross-dotted rings); the other nodes do not activate theirs (empty dotted rings). At most one node can detect the token (solid dotted ring), because reading the token removes the light from the waveguide. As a result, a node detecting a token wins exclusive use of the channel. In our protocols, it uses the channel for some fixed period.</p><p>In an optical channel, modulated light, hence information, travels in one direction and arrives with slight but increasing delays at each node in sequence. To deal with this, it has been proposed <ref type="bibr" target="#b25">[26]</ref> to send an optical clock signal through a parallel waveguide so that clock edges arrive in phase with modulated light. Nodes synch their local electronic clocks to the arriving optical clock, thereby avoiding any skew between the local clock and the optical signals. Where a signal path returns to the node at which the optical clock is generated, the data could arrive out of phase with the clock. We call this point the "dateline." By designing a waveguide whose length is an integral number of clock cycles, or by positioning a retimer at the dateline, we eliminate such a phase shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">OPTICAL ARBITRATION PROTOCOLS</head><p>We describe our channel based, and slot based protocols which we will call Token Channel and Token Slot. We let T denote the time of flight, in cycles, that it takes for an optical token to complete a full circuit from injection at its home node to detection at the same home node assuming it is not removed by an intervening node. In other words, T is the number of clocks it takes the token to complete a round trip along the blue path of Figure <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Token Channel</head><p>Optical Token Channel is inspired by the 802.5 Token Ring LAN standard <ref type="bibr" target="#b1">[2]</ref>. Figure <ref type="figure" target="#fig_3">4</ref> shows the operation of Token Channel. There is a single token circulated per channel. The token is passed from requester to requester, entirely skipping nonrequesters that lie between. When a node removes and detects a token it has exclusive access to the corresponding channel and may begin sending (one or more) packets some number of cycles later. The sooner it begins transmitting, the better the utilization of the data channel. In Token Channel, no more than one source can use the channel at any one time: the segment of the data channel from the home node to the token holder carries no data, while the segment from the token holder back to the home node carries light modulated by the token holder. The sender may hold the token (and use the channel) for up to some fixed maximum number H ≥ 1 of packets. When a sender has many packets in its queue for one receiver, it helps considerably to send more than one.</p><p>When a source first turns on its detector for an otherwise idle channel, it waits on average T /2 cycles for arrival of the token. When a single source wants to send a long sequence of packets on an otherwise idle channel, it transmits H packets at a time and waits the full flight time T for the reinjected token to return. The Token Slot arbiter of the next section reduces these token wait times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Token Slot</head><p>Token Slot is based on a slotted-ring arbitration protocol <ref type="bibr" target="#b21">[22]</ref>. It divides the channel into fixed-size, back-to-back slots and circulates tokens in one-to-one correspondence to slots.</p><p>P0 injects its token onto the arbitration waveguide. It passes by P1 unperturbed. P2 requests the token.</p><p>P2 seizes the token.</p><p>P2 reinjects the token, and the token travels back to the home node (P0). The home node (P0) injects tokens in one-to-one correspondence for the slots.</p><p>P2 requests and seizes one of P0's token as it passes by.</p><p>The token P2 previously seized is represented by the absence of light traveling by P3. One packet occupies one slot. A source waits for arrival of a token, removes the token, and modulates the light in the corresponding single-packet slot. The token precedes the slot by some fixed number of cycles which are used to set up the data for transmission. The slot is occupied (by modulated light, i.e. data) until it gets to the destination, which removes the data, freeing the slot; the destination reinjects a fresh token along with new unmodulated light. Figure <ref type="figure" target="#fig_4">5</ref> shows the Token Slot layout and its operation.</p><p>Compared with Token Channel, Token Slot reduces the average source wait time significantly and increases channel bandwidth utilization in our experiments. In the single-source scenario above, the one active source can claim all tokens, using the channel continuously at full bandwidth. In Token Channel, the token holder is the only possible sender (there is only one token in the system), whereas in Token Slot, there are multiple tokens, and there can be multiple sources simultaneously sending at different points on the waveguide.</p><p>Unlike Token Channel, which requires each node to have reinjection capabilities on the arbitration wavelength, in Token Slot only the destination needs reinjection capability. Thus, Token Slot requires fewer resources and less power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Timing</head><p>In Token Channel, after sending one or more packets, the sender reinjects a token into the arbitration waveguide in parallel with the last clock edge of its most recent transmission. If the sender cannot reinject the token at this time, so that the token lags the end of the data packets, then a data channel "bubble" results, wasting channel bandwidth. In this paper, we assume that the token can be reinjected one clock after it is removed. We intentionally chose an aggressive target to push the limits of arbitration. Early SPICE models of the analog circuitry indicate that the target is feasible.</p><p>If injecting on the trailing clock edge is too soon, a possible fix is to narrow the data channel, increasing the serialization delay of a data packet so as to cover the time needed to read, process, and reinject the token. Adding more channels could then compensate for this narrowing. Our studies indicate that halving the bandwidth and doubling the channels drops the maximum achievable throughput of Token Channel to 26% under uniform traffic, tripling and dividing by three further drops it to 18%, vs. 45% for a single channel.</p><p>We assume the node can detect a token and deactivate its detector before the next token arrives. If the ring resonator cannot respond to the token before the next token arrives, then one or more following tokens may be inadvertently claimed. Arbitration pipelining <ref type="bibr" target="#b19">[20]</ref> can hide this effect. For example, if the ring resonators have a k-cycle latency, then for each data channel, k arbitration channels that have tokens every k th slot may be employed. Since a new arbitration is started before the last one has completed, the status of the last arbitration is unknown leaving the new arbitration to speculate on whether or not it will win. Pipelining the arbitration makes the reinjection latency less critical but has a significant impact on performance. On uniform traffic, when using two-and three-cycle detectors and speculating that previous arbitrations were not won, throughput is 76% and 64% in contrast to 87% for a one-cycle arbiter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FLOW CONTROL AND FAIRNESS</head><p>Arbitration for the interconnect is only half of the story when it comes to communicating data from source to destination. Flow control is the other half of the story: it guarantees that an outgoing packet has a receive-buffer entry allocated for its arrival at the destination. By managing flow rate, it prevents buffer overflow at the destination, avoiding the complexity and overhead of negative acknowledgements and retransmissions. In this section, we add credit-based flow control to the Token Channel and Token Slot protocols.</p><p>To be useful, a protocol must provide some guarantees of fairness. At a minimum, a fair protocol will not starve any contending user. We show here how to modify both Token Channel and Token Slot to provide fairness while retaining the advantages of fully optical implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Flow Control</head><p>The idea is simple: the home node emits credit-filled tokens to communicate the number of available entries to source nodes. A node that removes a credit-bearing token (conveying one or more credits) is guaranteed that there are available entries at the destination.</p><p>Token Channel encodes flow control information in the token. The token is enlarged to contain a binary encoding of the number of buffer entries available at the home node. When a node detects the token, it only transmits on the data channel if there are credits available. It then marks its reservation by decrementing the number of credits in the token, and reinjects the diminished token. The token eventually returns home, at which point the home node increments the credits to reflect entries that have become available since the token's last visit. The home emits the enriched token.</p><p>Token Slot encodes flow control information simply by emitting a token only when a buffer entry is available. Thus, each token signifies a single credit and, if a node removes a token, it has also reserved an entry at the destination. When the entry is relinquished, the home emits a token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fairness</head><p>In the two protocols of the previous section, the home node emits credits. Nodes close to home have priority over nodes farther downstream in obtaining them. If emitted tokens do not have enough credits to reach distant requesters, these requesters risk starvation. This problem with token protocols is well known; it has been addressed in electronic systems with modifications that cause relatively well served senders to sit on their hands for awhile and give someone else a chance <ref type="bibr" target="#b16">[17]</ref>.</p><p>Here we modify the optical token protocols discussed above, retaining their latency advantages, and providing, by a similar back-off mechanism, fair treatment to underserved senders.</p><p>Suppose that the aggregate demand for a channel's bandwidth is less than both its inherent maximum bandwidth and the rate at which the home node frees buffer slots. Simple protocols, for example token slot, can fairly satisfy all this demand. The fairness issue surfaces when the aggregate demand by all senders exceeds this maximum achievable service rate. (In practice, full input buffers will throttle the senders so that their aggregate packet insertion rate approaches, but never exceeds, this rate.)</p><p>The max-min protocol <ref type="bibr" target="#b3">[4]</ref> is a well-accepted notion of what the goal should be in this situation. In max-min, senders that need little service get all they can use. All remaining senders, which get somewhat less service than they might be able to use, get equal service.</p><p>Max-min is a worthy goal, but is difficult to achieve exactly in an online, low latency, distributed arbiter. There is no generally accepted metric for measuring the deviation between an achieved service profile and the max-min goal. We instead present the data visually, providing a clear picture of the extent to which we have approximated the max-min goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Fair Token Channel</head><p>Fair protocols such as iSLIP <ref type="bibr" target="#b17">[18]</ref> implement rotating priority schemes that distribute service in some sort of cyclic manner to competing requesters. We propose to mitigate the unfair behavior of Token Channel with Fast Forward (FF) tokens that implicitly do the same sort of approximately cyclic service allocation when this is needed. When the home node injects an FF token (rather than a regular token), the token travels in its own waveguide, bypassing previously served senders. At some point along the waveguide (as described below), the FF token changes into a regular token and is available for arbitration. By fast forwarding these FF tokens downstream, nodes far from the home node are given higher priority than nodes close to home.</p><p>FF tokens are emitted onto a FF waveguide, which is concentric with the arbitration waveguide. The FF waveguide is used to both notify the home node that a node is starving and to supply a credit-filled token to that starving node. When a potential source node removes the token and finds it empty of credits, it declares itself to be a victim of starvation. It does not reinject the empty token on the arbitration waveguide, but rather puts it on the FF waveguide (see Figure <ref type="figure" target="#fig_5">6</ref>). Only the home node activates its detector, and so the token quickly returns (in at most T cycles) to the home node, which replenishes it with any newly available credits. Moreover, the arrival of the token at the home node via the FF channel causes the home to send the token back out again on the FF channel. The node that discovered the empty token will have activated its FF channel detector, so the replenished token will take a direct route back to that node. This not only removes the credit bias in favor of nodes near the home node, but has the added bonus of reducing the time needed to refresh an empty token with new credits. Our experiments do show a significant bandwidth improvement compared with simple Token Channel from this effect. Note that the opportunity to remove an empty token propagates cyclically, which is a key to the fairness of Channel FF.</p><p>P2 wins P0's Token from the arbitration waveguide, but does not use the channel because there happens to be no credits left.</p><p>P2 fast forwards the token to P0, past any other possible outstanding downstream requesters (e.g. P3). P2 also activates its detector on the FF waveguide.</p><p>When credits become available again, P0 injects its token onto the FF Waveguide. P2 is expecting the token, as shown by the active detector. It removes the token, sends, and function returns to normal.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Fair Token Slot</head><p>The simple Token Slot protocol is inherently unfair: it gives higher priority to nodes closest to the home. To ensure fairness we must make sure that every node having sufficiently high demand is treated nearly equally. Proposed electronic protocols do so using a SAT token that traverses in the direction opposite the token path and moves at most one node per clock <ref type="bibr" target="#b16">[17]</ref>. In this section, we provide a low latency protocol, Fair Slot, that achieves this goal in a fully optical implementation. As with Channel-FF, Fair Slot detects starvation (a node that isn't receiving adequate service) and then services all underserved nodes, once each, in some sequence before returning to normal function.</p><p>Here we describe the implementation of Fair Slot on a single channel (shown in Figure <ref type="figure" target="#fig_7">8</ref>). In an MWSR system, each channel independently implements this algorithm.</p><p>The essential idea is to switch between simple Token Slot and an alternative that allocates credits to senders in a cyclic manner. During periods of little load, we use the simple protocol. When higher load causes some senders to receive less service than they need, the protocol switches to providing fixed quanta of credits and bandwidth to the underserved senders, once each cyclically, before returning to the simple protocol.</p><p>In Fair Slot, senders can be in one of three possible states: satisfied, hungry, and suspended. A sender must traverse the state diagram from satisfied to hungry to suspended cyclically (as shown in Figure <ref type="figure" target="#fig_6">7</ref>). The entire channel goes through alternating phases of plenty and famine, the famine state being triggered by notification to the home node that there is at least one hungry sender. The presence of a hungry sender is communicated back to the home node using an optical N OR (as in Figure <ref type="figure" target="#fig_2">3</ref>, any hungry node removes all the light from the hunger waveguide) allowing the home node to detect whether or not there is any hungry sender. When a hungry sender is detected by the home node, the channel enters the famine mode. The channel state of famine vs. plenty is communicated to the nodes using a separate broadcast waveguide so that all nodes can read it with no delay or reinjection.</p><p>Arrival of the famine signal changes the local (per node) channel status from plenty to famine. We call a token a famine token or a plenty token according to the accompanying channel state. Only a hungry node may grab a famine token. Other nodes (both satisfied and suspended) let them pass by. Any node can take a plenty token.</p><p>A satisfied node becomes hungry according to a local criterion. This can be the presence of an old packet (a packet is old if it has been in the system longer than some threshold) or when its input queue length exceeds some threshold. In either case, there will be an upper bound, L, on the number of packets in the queue of a node that becomes hungry.</p><p>The system is in Plenty mode. P1 is blocking P2 from winning P0's tokens. P2 diverts on the Hungry WG.</p><p>P0 detects no light on the Hungry WG and broadcasts on the Broadcast WG, putting the system into Famine mode. Node P1 passes on all famine tokens, allowing P2 to seize a token.</p><p>P2 becomes satisfied and releases the Hungry WG. P0 detects light on the Hungry WG, and stops broadcasting, returning the system to Plenty mode. Execution returns to normal. When a node enters hunger for a given channel, it marks all packets in its input queue for that channel. A hungry node grabs any arriving tokens until these marked packets are flushed. Any packets that arrive after the onset of hunger can join the queue, but they aren't sent during this period of hunger. Once it sends the last of the marked packets, the node de-asserts hunger and goes into suspended state.</p><p>A node in suspended state passes on all famine tokens. When the first plenty token arrives, the node transitions to satisfied; it can also grab the token if it wishes. On the next clock it can transition to hungry if it meets the criterion.</p><p>No node can remain forever hungry. To see this, suppose node h becomes hungry. It asserts its hunger and this signal must reach the home node, which transitions to famine mode if not already in it. By the current famine we shall mean the epoch of consecutive cycles, including the clock cycle at which h's hunger signal arrives at home, over which the home node emits famine tokens. The famine tokens of the current famine may be taken by other hungry nodes upstream of h. No one of these will take more than L of these tokens in the current famine, as any node that takes L must have flushed its buffer (keeping newly arrived packets in the queue) and hence have gone into suspension. Node h will therefore eventually receive enough packets to flush the marked packets from it input queue, suspend, and de-assert its hunger.</p><p>No node returns to hungry state before all nodes that were hungry when it became hungry leave hunger. To see this, note that the transition from suspended to satisfied requires the arrival of the broadcast that the system has transitioned to the plenty state. The home node generates this signal only when the or-ed hunger signal goes low. This cannot happen until all nodes that were hungry when the given node became hungry have suspended and de-asserted it.</p><p>When the last node goes from hungry to suspended and deasserts hunger, there is a delay of up to T cycles before home gets the word. The famine tokens generated by home will be wasted as there are no hungry senders left to take them. This has a small impact on utilization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">MWSR ARBITRATION</head><p>We evaluate the proposed optical arbiters for a N = 64node, optical MWSR interconnect. The MWSR requires 64 arbiters to arbitrate for the 64 channels. In systems using dense wavelength-division multiplexing, each channel would be assigned a unique wavelength, and all could share the same arbitration waveguides. Examples of fully connected MWSR arbiters are shown in Figure <ref type="figure">9</ref>. We consider here some engineering and scalability issues that arise when arbitrating for several channels in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Engineering Simultaneous Arbitration</head><p>Virtual output queues (VOQs) allow sources with requests destined for differing destinations to make these requests independently <ref type="bibr" target="#b24">[25]</ref>. All our experiments employ VOQs.</p><p>While arbitration for one channel can occur independently of all others, no one requesting node can simultaneously transmit on all data channels because of limited per-node power. If we impose an upper bound on the number of channels that can be used simultaneously by a single sender for transmission, then how many concurrent transmissions should a sender attempt to gain in arbitration? A requester that arbitrates and wins more channels than it can use will waste unused slots and bandwidth. In Token Channel, each extra win sacrifices the immediate transmission opportunity; the requester can hold the extra tokens until it can transmit, or can reinject them; in either case this causes a channel bubble. In Token Slot, each extra token won causes the corresponding slot to go unused. Bounding the number of requests a requester may nominate (turn on detectors) reduces the likelihood of overwinning.</p><p>We explored the space of how many requests to nominate and how many to use with random traffic experiments. In Token Slot, being zealously conservative of bandwidth by nominating only one request and transmitting on at most one channel actually restricts the maximum achievable throughput to Token Channel Token Slot Figure <ref type="figure">9</ref>: Arbiters for 4-channel MWSR 58% of full channel utilization. This is due to head-of-line blocking: the nominated request prevents another outstanding request from trying for a channel, even when the channel it needs is idle. This occurs despite the presence of VOQs. Karol, Hluchyj, and Morgan <ref type="bibr" target="#b11">[12]</ref> explain this analytically, deriving a limit of 2 -√ 2 = 0.586 on utilization. At the other extreme, nominating and using up to N requests is overkill (nodes generate at most a limited number of requests per clock) and has impractical power costs. We found that nominating for all nonempty VOQs (we can have up to 8), but using at most 2 is a good power and performance point in our search space. We observe roughly 5% of tokens are wasted by this aggressive nomination strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL SETUP AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>The MWSR we model operates at double data rate using a 5 GHz Clock. It has single cycle, cache-line-sized packets and optical path length T = 8 cycles. We assume that eight single-cycle, 64-byte non-overlapping packets can simultaneously share one channel. Table <ref type="table" target="#tab_1">1</ref> shows the simulated configuration.</p><p>In order to test the proposed optical arbiters under a variety of traffic conditions, we use the SPLASH-2 workloads <ref type="bibr" target="#b26">[27]</ref>. A 1024-thread version of SPLASH-2 is simulated: each node consists of an L2 cache and four multithreaded processors (with private L1 caches) running four threads each. The SPLASH-2 workloads model requests to and replies from memory and are trace-driven with L2 misses supplied by the COT-SON simulator <ref type="bibr" target="#b8">[9]</ref>. To ensure forward progress, responses (which are of higher priority than requests) may arbitrate regardless of the starvation-state of the system. Only requests participate in fairness throttling, since fairness of responses follows from fairness of requests For each simulation, we warm up the model and then track and measure a fixed number of requests.</p><p>We also use the synthetic Uniform and Hotspot traffic models. To isolate the performance of the arbiter, these synthetic workloads consisted of one-way traffic only and do not model memory. For these, we report the aggregate achieved packet delivery rate, the latency, and the delivery rate seen by the least serviced sender, all as a function of the offered load. The network is capable of delivering up to 64 packets, one per destination node, on every cycle. For Uniform, the destination for every packet is chosen randomly with uniform probability. An offered load of 1 means that there is, on average, for each For HotSpot, node 0 is the destination of all requests. Node 0's channel can sustain at most one request per cycle. Thus, an offered load of o for HotSpot means that at every cycle, each node generates a request with probability o/(63).</p><p>We perform our experiments with the M5 simulator framework <ref type="bibr" target="#b4">[5]</ref> to model the interconnect, including memory and queueing at the ports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance</head><p>We measured performance attained with five different arbiters, The first is called Baseline and is an optical channeltoken protocol that delays the token by a half-cycle at each node, regardless of whether or not the node wants the channel. It is motivated by earlier work of Ha and Pinkston <ref type="bibr" target="#b9">[10]</ref> and Kodi and Louri <ref type="bibr" target="#b13">[14]</ref>, who considered VCSEL-based technology with an electronic hop at each node. The others are our Token Channel (with H = 1), Token Channel w/ FF (with H = 1, as used in Corona <ref type="bibr" target="#b25">[26]</ref>), Token Slot, and Fair Slot arbiters.</p><p>As shown in Figure <ref type="figure" target="#fig_8">10</ref>(a) &amp; (b), the Baseline proposal has low bandwidth potential and high latency solely because the tokens must be repeated at every node. The baseline only achieves 32% utilization in our Hotspot simulations, because our token can have at most 16 credits and the full round trip for a fully utilized token is at least 16 + (N -16)/2 + 8 = 48 cycles. Token Channel does little better on Hotspot; it saturates under a higher load but its bandwidth eventually drops off to the level of the baseline. The bandwidth drop seen in Hotspot is actually a result of credits becoming scarce and a zero-credit token being delayed by losing requesters. In fact, Token Channel behaves exactly like baseline at high loads because every node requests the token. Fast forwarding tokens, intended to improve the fairness of Token Channel, here improves performance, because the FF waveguide quickly returns zero-credit tokens to the home node. The average token round trip drops from 48 cycles to 26 cycles under heavy load. Both variants of Token Channel, however, use a single token, repeatedly delayed in flight by senders, which causes its on-board credit count to be updated infrequently and to therefore carry increasingly stale information.</p><p>The data of Figure <ref type="figure" target="#fig_8">10</ref>   iest achievable offered load. But Token Slot is unfair, as Figure <ref type="figure" target="#fig_8">10</ref>(f) shows: the least-served sender starves once the aggregate demand exceeds the channel capacity. Fair Slot, which removes this unfairness, is able to achieve 90% channel utilization: 10% of available tokens (bandwidth) go unused when the system transitions modes. In HotSpot at full load, every node always has a packet available for the destination. For Uniform, Fair Slot achieves 74% utilization at maximum load: only a faction of senders have a packet available for the destination due to small shared input queues.</p><p>Figures <ref type="figure" target="#fig_8">10(e</ref>) and 10(f) give a closer look at how well Channel with FF and Fair Slot ensure fairness. The service given to the least-serviced sender indicates whether or not there is a starvation problem. At low loads, fairness questions do not arise -all demand is satisfied. For Uniform, all protocols remain fair even at high load. The combination of input queue size and credit availability ensure that starvation can not happen with uniform traffic. In Hotspot, at high loads, the simple protocols become unfair. Token Slot is efficient and fair below network saturation, but falls over beyond that point. Fair Slot and Channel w/ FF avoid starvation at all measured loads. They are fair: the bandwidth seen by the least served sender is close to an equal share of the aggregate bandwidths shown in Figures <ref type="figure" target="#fig_8">10(a</ref> In order to confirm that Fair Slot achieves excellent arbitration latency and channel utilization with excellent fairness, we   tried a more complex test case. We generated single-channel traffic in which half of senders have random, small demands, and half have random, heavy demand such that the total demand is 4 times the channel's bandwidth. Figure <ref type="figure" target="#fig_11">11</ref> shows achieved bandwidth: on the left, where demand is assigned to senders in increasing order, and on the right where demand is randomly assigned to senders. In both cases, the low-demand senders get all the bandwidth they need. The high demand senders are treated nearly equally, except that the two closest to the home node get more service than they deserve. But none starves, and the allocation is quite close to a max-min allocation of the aggregate achieved bandwidth. The figures also show the max-min allocation of the full channel bandwidth; the difference between the achieved service and the max-min service is caused by less than full channel utilization and the extra service for the two closest senders. Finally, Figure <ref type="figure" target="#fig_12">12</ref> shows results from running 1024-threaded instances of SPLASH-2 benchmarks. Some of the workloads, such as Barnes, use the interconnect little and are indifferent to the arbitration policy.</p><p>We have presented performance results for a 64-node arbiter. Because of its scaling properties, we believe the arbiter can scale as far as an MWSR interconnect can scale. At some point, the propagation time of a transmission becomes intolerable and a hierarchical MWSR, with arbitration at each level, will be necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">POWER MODEL</head><p>There are two main contributors to power consumption: the laser and the rings.</p><p>Laser power comes from a static off-chip source. The laser power must overcome losses due to electrical-optical conversion inefficiencies as well as transmission losses in the waveguide. All losses target the 17nm process and were calculated with a link-loss approaching using prior results <ref type="bibr" target="#b27">[28]</ref> and numerical simulations.</p><p>Ring resonators are the other major power budget contributor. All rings in the system must be electrically or thermally adjusted (or "trimmed") to compensate for fabrication error. Trimming helps to keep off-resonance rings in their untuned range (approximately one-half mode spacing from resonance). A ring is brought into resonance by further adjusting its index of refraction. Finally, a modulating ring will dissipate extra power, as it needs a charge of 3 × 10 -14 C/pulse at 5 GHz <ref type="bibr" target="#b0">[1]</ref>. The ring resonators also contribute to the laser power calculation; for example, we account for the slight attenuation when a signal passes by an off-resonance ring.</p><p>Figure <ref type="figure" target="#fig_13">13</ref>(a) demonstrates power estimates for a 64-node arbiter. Power numbers were derived using the values in Table 2. We assumed worst-case power consumption under the condition that every node was arbitrating to its full extent. We modeled two values of m, where m corresponds to the maximum number of outstanding requests a node may nominate. Bars for m = 16 represent the model we arrived at in Section 5, while m = 64 represent an aggressive model where every node may have a nomination for each and every other node. All arbiters, except the baseline, show sensitivity to the increased activity of the ring resonators when we vary m. The baseline is insensitive to this change because all nodes must repeat all tokens, regardless of outstanding nominations.</p><p>Ring Trim and Ring Resonance power dominates all configurations. Ring trim stays constant while we vary m, because the ring count also stays constant. Allowing more rings to resonate, by increasing m, linearly affects the ring resonance power.   Configurations that have fewer rings (as inferred by the height of the Ring Trim Power bar) and that have lower values of m consume the least amount of power. Fairness comes at a cost, because the protocols require more resources to be added and thus more power consumed. Nonetheless, Fair Slot consumes less than half of the power of Channel w/ FF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">RELATED WORK</head><p>Ha and Pinkston <ref type="bibr" target="#b9">[10]</ref> and Kodi and Louri <ref type="bibr" target="#b13">[14]</ref>, advocated token-based protocols to arbitrate for optical off-chip MWSR interconnects. They processed tokens electrically at each node by converting the optical signal to an electrical signal, processing the token, and converting it back to an optical signal. Marsan et. al <ref type="bibr" target="#b16">[17]</ref> propose a collisionless arbitration strategy for optical LAN and MAN MWSRs that relies on inspecting channel slot headers, a technique analogous to re-questing tokens. The authors above targeted off-chip interconnects, which have latency and bandwidth requirements different from on-chip interconnects.</p><p>An optical arbiter, which like our proposal communicates reservations with light, can be found in Qiao and Melhem <ref type="bibr" target="#b22">[23]</ref>. Requesting nodes send optical pulses downstream while detecting pulses that may be coming from an upstream requester. At the end of an arbitration, a successful requester detects no light (no requesters) from upstream.</p><p>Our investigation focused on arbitrating for channels individually, rather than allocating all channels in bulk. Allocation approaches to optical interconnects include Minkenberg et. al <ref type="bibr" target="#b18">[19]</ref> and Krishnamurthy, Franklin, &amp; Chamberlain <ref type="bibr" target="#b15">[16]</ref>. These approaches use centralized electrical allocators that perform matchings with heuristic, iterative algorithms.</p><p>In Section 1 we discussed why SWMR interconnects do not require arbitration and at what cost. Our proposals are not directly applicable to meshes, like Shacham et. al's <ref type="bibr" target="#b23">[24]</ref> and Cornell's Phastlane <ref type="bibr" target="#b6">[7]</ref>. Joshi et. al <ref type="bibr" target="#b10">[11]</ref> propose at an optical Clos network that performs all necessary arbitration in the router. Finally, Kirman et. al <ref type="bibr" target="#b12">[13]</ref> use a broadcast-based interconnect that shares access to the medium using uses simple local state machines that are globally synchronized. We believe our arbiters may be applied to this work to dynamically adjust access according to demand.</p><p>The Metaring system <ref type="bibr" target="#b7">[8]</ref> enforces distributed fairness in a ring topology with the use of electrical SAT(isfied) tokens. A SAT token travels in the opposite direction of data and refreshes a node's transmission quota with k credits. An unsatisfied (or starved) node holds the SAT token, causing other nodes' quotas to deplete. The number of hops in a revolution has an impact on k, because, under normal traffic circumstances, the credits should last an entire token revolution. Although every starving node will be serviced eventually, it may take as long as N k units of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">CONCLUSION</head><p>We have demonstrated a mechanism for optical arbitration that provides full channel utilization, fairly across all sources, and adds little to communication latency. We accomplish this by taking full advantage of optics. Our protocols leave signals in the optical domain until the information that they convey can be used. Prior optical arbitration mechanisms convert optical tokens to the electrical domain and back at each node thereby increasing the latency of the system. Leaving signals in the optical domain limits the ways in which information can be conveyed; this work has examined in detail protocols that cope with these limitations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Arbitration Scalability. The arbitration waveguides snake throughout chip, passing each of the N cores exactly once and having length O( √ N ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Ring-based Optical Interconnects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Basic Optical Arbitration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Token Channel. Arbitration for one channel of an N channel interconnect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Token Slot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Fast Forwarding for Token Channel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Fair Slot Finite State Machine.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Fair Slot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Bandwidth(a &amp; b), Average Latency(c &amp; d), and Worst Serviced Node (e &amp; f ) for Uniform random traffic (left) and HotSpot traffic (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>) and (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Single-Channel Bandwidth Allocation by Fair Slot. Workloads use ascending demand assignment (left) and random assignment (right). Note: Excessive demands are shown at the chart's limits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: SPLASH-2: Achieved Bandwidth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Power Consumption of Arbitration Systems. m corresponds to the maximum number of outstanding requests a node may nominate (or detectors it may have active).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>System Parameters destination, one source that generates a new request on every cycle. Values over 1 indicate that demand exceeds capacity.</figDesc><table><row><cell>Resource</cell><cell>Value</cell></row><row><cell>Number of nodes</cell><cell>64</cell></row><row><cell>Per node:</cell><cell></cell></row><row><cell>Network Input Request Entries</cell><cell>8</cell></row><row><cell>Network Input Response Entries (SPLASH-2 only)</cell><cell>8</cell></row><row><cell>Network Output Request &amp; Response Entries</cell><cell>16</cell></row><row><cell>Max Concurrent Nominations</cell><cell>16</cell></row><row><cell>Max Concurrent Transmissions</cell><cell>2</cell></row><row><cell>Interconnect:</cell><cell></cell></row><row><cell>Packet Size (bytes)</cell><cell>64</cell></row><row><cell>Flit Rate (bytes/cycle)</cell><cell>64</cell></row><row><cell>Max Propagation Latency (cycles)</cell><cell>8</cell></row><row><cell>Bandwidth (TB/s)</cell><cell>20.48</cell></row><row><cell>Memory (SPLASH-2 experiments only):</cell><cell></cell></row><row><cell>Bandwidth (TB/s)</cell><cell>10.24</cell></row><row><cell>Memory Controllers</cell><cell>64</cell></row><row><cell>Max Outstanding Requests per MC</cell><cell>64</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>indicate that Token Slot is the best protocol available. Its implementation is relatively straightforward and it achieves nearly the best possible throughput for both test cases across the range from very light to heav-</figDesc><table><row><cell>(a)</cell><cell></cell><cell></cell><cell>1.2</cell><cell></cell><cell></cell><cell>Baseline Channel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell>1.2</cell><cell></cell><cell></cell><cell>Baseline Channel</cell></row><row><cell></cell><cell cols="2">Achieved Bandwidth</cell><cell>0.4 0.6 0.8 1.0</cell><cell></cell><cell></cell><cell cols="3">Channel w/ FF (Corona) Slot Fair Slot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Achieved Bandwidth</cell><cell>0.4 0.6 0.8 1.0</cell><cell></cell><cell></cell><cell>Channel w/ FF (Corona) Slot Fair Slot</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.0</cell><cell></cell><cell></cell></row><row><cell>(c)</cell><cell></cell><cell></cell><cell>100</cell><cell cols="2">0.0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6 Offered Load</cell><cell>0.8</cell><cell>1.0</cell><cell>1.2</cell><cell>(d)</cell><cell></cell><cell></cell><cell>100</cell><cell cols="2">0.0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6 Offered Load</cell><cell>0.8</cell><cell>1.0</cell><cell>1.2</cell></row><row><cell></cell><cell cols="2">Average Latency (cycles)</cell><cell>40 60 80</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Average Latency (cycles)</cell><cell>40 60 80</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>20</cell><cell></cell><cell></cell></row><row><cell>(e)</cell><cell>Achieved Bandwidth of Least Serviced Node</cell><cell cols="3">0 0.000 0.002 0.004 0.006 0.008 0.010 0.012 0.014 0.016</cell><cell>0.0 0.0</cell><cell cols="3">0.2 0.2 Baseline Channel Channel w/ FF (Corona) 0.4 0.6 Offered Load 0.4 0.6 Offered Load Slot Fair Slot</cell><cell>0.8 0.8</cell><cell>1.0 1.0</cell><cell>1.2 1.2</cell><cell>(f)</cell><cell>Achieved Bandwidth of Least Serviced Node</cell><cell cols="3">0 0.000 0.002 0.004 0.006 0.008 0.010 0.012 0.014 0.016</cell><cell>0.0 0.0</cell><cell>0.2 0.2 Baseline Channel Channel w/ FF (Corona) 0.4 0.6 Offered Load 0.4 0.6 Offered Load Slot Fair Slot</cell><cell>0.8 0.8</cell><cell>1.0 1.0</cell><cell>1.2 1.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Optical Device Power Consumption. Note: Two-thirds of the Ring Resonator power budget is set aside for analog drivers.</figDesc><table><row><cell></cell><cell>3.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Laser</cell><cell></cell></row><row><cell></cell><cell>3.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Ring Modulation</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Ring Resonance</cell></row><row><cell></cell><cell>2.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Ring Trim</cell></row><row><cell>Watts</cell><cell>1.5 2.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>m=16</cell><cell>m=64</cell><cell>m=16</cell><cell>m=64</cell><cell>m=16</cell><cell>m=64</cell><cell>m=16</cell><cell>m=64</cell><cell>m=16</cell><cell>m=64</cell></row><row><cell></cell><cell cols="2">Baseline</cell><cell cols="2">Channel</cell><cell cols="2">Channel</cell><cell></cell><cell>Slot</cell><cell cols="2">Fair Slot</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>w/ FF</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(Corona)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">ACKNOWLEDGEMENTS</head><p>This research was supported in part by the National Science Foundation under grant CCF-0702272, as well as grants and equipment donations from Hewlett-Packard, IBM, and Intel.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Devices and architectures for photonic chip-scale integration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fiorentino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beausoleil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Binkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mclaren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Santori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schreiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Physics A: Materials Science &amp; Processing</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="989" to="997" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Local Area Networks: Token Ring Access Method and Physical Layer Specifications</title>
		<author>
			<persName><surname>Ansi/Ieee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Std</title>
		<imprint>
			<biblScope unit="volume">802</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Building manycore processor-to-DRAM networks with monolithic silicon photonics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Batten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Orcutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khilo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holzwarth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Popvic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Smitth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoyt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stojanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hot Interconnects</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gallager</surname></persName>
		</author>
		<title level="m">Data Networks</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Binkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Dreslinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The M5 Simulator: Modeling Networked Systems</title>
		<imprint>
			<date type="published" when="2006-08">Jul/Aug 2006</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="52" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">low-complexity multiple access protocols for wavelength-division multiplexed photonic networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bogineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Sivalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Dowd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="590" to="604" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Phastlane: a rapid transit optical routing network</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cianchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Kerekes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA &apos;09</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="441" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Metaring-a full-duplex ring with fairness and spatial reuse</title>
		<author>
			<persName><forename type="first">I</forename><surname>Cidon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ofek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Communications</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="110" to="120" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining Simulation and Virtualization through Dynamic Sampling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Falcon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Faraboschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ortega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISPASS</title>
		<imprint>
			<date type="published" when="2007-04">Apr 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new token-based channel access protocol for wavelength division multiplexed multiprocessor interconnects</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Pinkston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="169" to="188" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Silicon-Photonic Clos Networks for Global On-Chip Communication</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Batten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shamim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stojanovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>In NOCS &apos;09</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Input versus output queueing on a space-division packet switch</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hluchyj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1347" to="1356" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note>Communications</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Leveraging Optical Technology in Future Bus-based Chip Multiprocessors</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Apsel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO&apos;06</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="492" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Design of a high-speed optical interconnect for scalable shared memory multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Louri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 12th Annual IEEE Symposium on</title>
		<meeting>12th Annual IEEE Symposium on</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
	<note>High Performance Interconnects</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Performance adaptive power-aware reconfigurable optical interconnects for high-performance computing (hpc) systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Louri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC &apos;07: Proceedings of the 2007 ACM/IEEE conference on Supercomputing</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dynamic reconfiguration of an optical interconnect</title>
		<author>
			<persName><forename type="first">P</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chamberlain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ANSS &apos;03</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">89</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">All-optical WDM multi-rings with differentiated QoS</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Marsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Leonardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Morabito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="58" to="66" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The iSLIP scheduling algorithm for input-queued switches</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Netw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="188" to="201" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Designing a crossbar scheduler for hpc applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Minkenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gusat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Iliadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luijten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Hemenway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grzybowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schiattarella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="58" to="71" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparative study of arbitration algorithms for the alpha 21364 pipelined router</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Silla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="223" to="234" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Firefly: illuminating future network-on-chip with nanophotonics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Memik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choudhary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA &apos;09</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="429" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">How far can data loops go?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pierce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Communications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="527" to="530" />
			<date type="published" when="1972-06">Jun 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Time-division optical communications in multiprocessor arrays</title>
		<author>
			<persName><forename type="first">C</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Melhem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC &apos;91</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="644" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Photonic NoC for DMA Communications in Chip Multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Biberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Carloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Hot Interconnects</title>
		<meeting>Hot Interconnects</meeting>
		<imprint>
			<date type="published" when="2007-08">Aug 2007</date>
			<biblScope unit="page" from="29" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">high-performance Multi-Queue Buffers for VLSI Communications Switches</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Frazier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="343" to="354" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Corona: System Implications of Emerging Nanophotonic Technology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vantrease</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monchiero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mclaren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fiorentino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Binkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Beausoleil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<idno>ISCA-35</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="153" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The SPLASH-2 Programs: Characterization and Methodological Considerations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ohara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Torrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="1995-06">Jun 1995</date>
			<biblScope unit="page" from="24" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Silicon microring resonators with 1.5-µm radius</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beausoleil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics Express</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4309" to="4315" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Micrometre-scale silicon electro-optic modulator</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">435</biblScope>
			<biblScope unit="page">325</biblScope>
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Embedded ring resonators for microphotonic applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Beausoleil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Willner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1978" to="1980" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
