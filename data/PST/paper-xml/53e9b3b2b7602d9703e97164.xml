<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Grenoble Images Speech Signals and Automatics Laboratory, Signal and Image Department</orgName>
								<orgName type="institution">Grenoble Institute of Technology</orgName>
								<address>
									<postCode>38402</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Iceland</orgName>
								<address>
									<postCode>107</postCode>
									<settlement>Reykjavik</settlement>
									<country key="IS">Iceland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Iceland</orgName>
								<address>
									<postCode>107</postCode>
									<settlement>Reykjavik</settlement>
									<country key="IS">Iceland</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Grenoble Images Speech Signals and Automatics Laboratory, Signal and Image Department</orgName>
								<orgName type="institution">Grenoble Institute of Technology</orgName>
								<address>
									<postCode>38402</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">46306A64140B4B70D1A830D088F8A092</idno>
					<idno type="DOI">10.1109/TGRS.2008.922034</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spectral and Spatial Classification of Hyperspectral Data Using SVMs and Morphological Profiles</head><p>Mathieu Fauvel, Student Member, IEEE, Jón Atli Benediktsson, Fellow, IEEE, Jocelyn Chanussot, Senior Member, IEEE, and Johannes R. Sveinsson, Senior Member, IEEE Abstract-A method is proposed for the classification of urban hyperspectral data with high spatial resolution. The approach is an extension of previous approaches and uses both the spatial and spectral information for classification. One previous approach is based on using several principal components (PCs) from the hyperspectral data and building several morphological profiles (MPs). These profiles can be used all together in one extended MP. A shortcoming of that approach is that it was primarily designed for classification of urban structures and it does not fully utilize the spectral information in the data. Similarly, the commonly used pixelwise classification of hyperspectral data is solely based on the spectral content and lacks information on the structure of the features in the image. The proposed method overcomes these problems and is based on the fusion of the morphological information and the original hyperspectral data, i.e., the two vectors of attributes are concatenated into one feature vector. After a reduction of the dimensionality, the final classification is achieved by using a support vector machine classifier. The proposed approach is tested in experiments on ROSIS data from urban areas. Significant improvements are achieved in terms of accuracies when compared to results obtained for approaches based on the use of MPs based on PCs only and conventional spectral classification. For instance, with one data set, the overall accuracy is increased from 79% to 83% without any feature reduction and to 87% with feature reduction. The proposed approach also shows excellent results with a limited training set.</p><p>Index Terms-Data fusion, extended morphological profile (EMP), feature extraction (FE), high spatial resolution, hyperspectral data, support vector machines (SVMs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I N CLASSIFICATION of remote sensing data from urban ar- eas, the identification of relatively small objects, e.g., houses and narrow streets, is important. Therefore, high spatial resolution of the imagery is necessary for accurate classification. The most commonly available remote sensing data of high spatial resolution from urban areas are single-band panchromatic data. However, using only one high-resolution panchromatic data channel is usually not sufficient for accurate classification of structural information. To overcome that problem, Pesaresi and Benediktsson <ref type="bibr" target="#b0">[1]</ref> proposed the use of morphological transformations to build a morphological profile (MP). In <ref type="bibr" target="#b1">[2]</ref>, the method in <ref type="bibr" target="#b0">[1]</ref> was extended for hyperspectral data with high spatial resolution. The approach in <ref type="bibr" target="#b1">[2]</ref> is based on using several principal components (PCs) from the hyperspectral data. From each of the PCs, an MP is built. These profiles are used all together in one extended MP (EMP), which is then classified by a neural network. The method in <ref type="bibr" target="#b1">[2]</ref> has been shown to perform well in terms of accuracies when compared to more conventional classification approaches. However, a shortcoming of the approach is that it is primarily designed for classification of urban structures and it does not fully utilize the spectral information in the multispectral or hyperspectral data.</p><p>However, this type of data contains a lot of information about the spectral properties and the land cover of the data. A finer definition of the classes is possible, and more classes can be considered. Based on the spectral signatures of the classes, many advanced pixel-based classifiers have been proposed, including advanced statistical classifiers <ref type="bibr" target="#b2">[3]</ref> and distributionfree approaches such as neural networks and support vector machines (SVMs) <ref type="bibr" target="#b3">[4]</ref>. The latter one has shown remarkable abilities to deal with remote multispectral data, particularly with hyperspectral data. However, if the spatial content of the image is not used, the resulting thematic map sometimes looks noisy (salt and pepper classification noise). Approaches involving Markov random field (MRF) and Monte Carlo optimization have been proposed in <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b5">[6]</ref>. These approaches use the contextual information. The main shortcoming of such algorithms is the computing time, which can be high even for small data sets. Regarding the high dimensionality of recently acquired data, both in the spectral and in the spatial domain, computationally light algorithm is of interest. In this sense, the MP has been proposed as an alternative way to use spatial information <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b6">[7]</ref>. Relative to the MRF-based classifiers, the MP and its extension to a multiband image, the EMP, have the possibility to use geometrical contextual information (shape, size, etc.) and perform well on many kinds of data (panchromatic, multispectral, and hyperspectral data). However, as stated above, a shortcoming of this approach is that it does not fully utilize the spectral information in the data, and consequently, several approaches based on the MP/EMP have been proposed to fully exploit the spatial and the spectral information <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>.</p><p>Each data set has its own properties, defining its ability to deal with different natures of classes.  properties of spectral and morphological/spatial data. The first main consideration is the complementary characteristics of the data. It has a consequence in the discrimination ability of such a feature, as will be seen in the experiments. The fusion of two types of information should clearly results in an increase of the classification in terms of global accuracy. The use of spectral information can be critical for classification of nonstructured information in urban areas, e.g., vegetation and soil classes, whereas the use of spatial information can be useful for classification of structured objects, e.g., road and building classes. The second consideration is the possible redundancy of each feature set (see <ref type="bibr" target="#b2">[3]</ref> for the spectral features and <ref type="bibr" target="#b10">[11]</ref> for the spatial features). Hence, feature extraction (FE) algorithms could be of an interest.</p><p>To include both types of information, an extension to the approach in <ref type="bibr" target="#b1">[2]</ref> is proposed in this paper. The proposed method is based on the data fusion of the morphological information and the original data: First, an EMP is created based on the PCs from the hyperspectral data. Second, FE is applied on the original hyperspectral data and the EMP. Finally, the extracted feature vectors from both the original data and the EMP are concatenated into one stacked vector and classified. The proposed approach is different from the approaches in <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>, where the authors had extracted spatial information and used composite kernel to include both types of information. Here, FE algorithms are used to select informative feature from the spectral and spatial domains.</p><p>For the multisource classification, SVMs are used rather than a neural network, which was used in our previous experiment with MP/EMP. The superiority of SVMs, implementing structural risk minimization, over the neural classifiers, implementing empirical risk minimization, has been discussed in [4, Ch.9.6 and 12] and in <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. SVMs aim to discriminate two classes by fitting an optimal separating hyperplane to the training data within a multidimensional feature space by using only the closest training samples. Thus, the approach only considers samples close to the class boundary and works well with small training set, even when high-dimensional data sets are classified. SVMs have already been applied for multisource classification in <ref type="bibr" target="#b16">[17]</ref> where several output coding methods were investigated.</p><p>In this paper, the proposed approach has been compared to statistical classification methods and SVM classification. Experiments were conducted on two different high-resolution remote sensing data sets from urban areas. The effectiveness of the proposed methodology with a limited training set has also been assessed.</p><p>This paper is organized as follows. Section II reviews the use of morphological transformations for processing of hyperspectral imagery in urban areas. In Section III, the considered supervised FE approaches are introduced. SVMs are discussed in Section IV. The applied data fusion schemes are discussed in Section V. Experimental results obtained on two ROSIS data sets from urban areas are presented in Section VI. Finally, conclusions are drawn in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. EMP</head><p>Mathematical morphology is a theory aiming to analyze the spatial relationship between pixels. For a remote sensing application, several morphological operators are available for extracting geometrical information. An overview of operators can be found in <ref type="bibr" target="#b17">[18]</ref>. In the following section, some basic notions of mathematical morphology are reviewed. Then, the concept of the morphological profile and its extension to multivalued data are detailed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Mathematical Morphology</head><p>The two fundamental operators in mathematical morphology are erosion and dilation <ref type="bibr" target="#b18">[19]</ref>. These operators are applied to an image with a set of known shapes, called the structuring elements (SEs). To erode an image consists of finding where the SE fits the objects in the image. The dilation, which is dual to the erosion, shows where the SE hits the objects.</p><p>Opening and closing are combinations of erosion and dilation. These operators are removed from the original image structures of size less than the SE. However, they also modify structures which are still present in the image after the opening/closing. Thus, they can introduce fake objects in the image. To avoid this problem, geodesic morphology and reconstruction should be used <ref type="bibr" target="#b18">[19]</ref>. Opening and closing by reconstructions are connected operators that satisfy the following assertion: If the structure of the image cannot contain the SE, then it is totally removed; else, it is totally preserved. For a given SE, geodesic opening or geodesic closing allows one to know the size or shape of some objects present in the image: The objects that are smaller than the SE are deleted, whereas the others (that are bigger than the SE) are preserved. To determine the shape or size of all elements present in an image, it is necessary to use a range of different SE sizes. This concept is called granulometry.</p><p>Granulometries are typically used for the analysis of the size distribution of the structures in the images. Classical granulometry by opening is built by successive opening operations with an SE of an increasing size. By doing so, the image is progressively simplified. By using connected operators, like opening by reconstruction, no shape noise is introduced.</p><p>MPs are defined by using the granulometry. An MP is composed of the opening profile (OP) and the closing profile (CP). The OP at the pixel x of the image I is defined as an n-dimensional vector</p><formula xml:id="formula_0">OP i (x) = γ (i) R (x) ∀i ∈ [0, n]<label>(1)</label></formula><p>where γ</p><formula xml:id="formula_1">(i)</formula><p>R is the opening by reconstruction with an SE of a size i and n is the total number of openings. In addition, the CP at the pixel x of image I is defined as an n-dimensional vector:</p><formula xml:id="formula_2">CP i (x) = φ (i) R (x) ∀i ∈ [0, n]<label>(2)</label></formula><p>where φ</p><formula xml:id="formula_3">(i)</formula><p>R is the closing by reconstruction with an SE of a size i. Clearly, we have CP 0 (x) = OP 0 (x) = I(x). By collating the OP and the CP, the MP of image I is defined as 2n + 1dimensional vector MP(x) = {CP n (x), . . . , I(x), . . . , OP n (x)} .</p><p>(</p><formula xml:id="formula_4">)<label>3</label></formula><p>Example of MP is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Thus, from a single image results a multiband image, whose dimension corresponds to the number of transformations, and spatial information is now contained in the MP for each pixel. However, an MP is built with only one band. Therefore, the spectral information is lost.</p><p>One approach to deal with this problem is to extract several images that contain some parts of the spectral information and then build the MP on each of the individual images. This approach, namely, the EMP, is discussed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. EMP</head><p>In order to apply this approach to hyperspectral data, characteristic images need to be extracted. In <ref type="bibr" target="#b10">[11]</ref>, it was suggested to use several PCs of the hyperspectral data for such a purpose. Hence, the MP is applied on the first PCs, corresponding to a certain amount of the cumulative variance, and a stacked vector is built with the MP on each PC. This yields to the EMP. Following the previous notation, the EMP is an m(2n + 1)dimensional vector:</p><formula xml:id="formula_5">MP ext (x) = {MP PC 1 (x), . . . , MP PC m (x)} (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where m is the number of retaining PCs. An example of EMP is shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>As with multispectral data, the MP/EMP may include some redundancy. Classical feature reduction algorithm can be applied, as detailed in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SUPERVISED FEATURE EXTRACTION (FE)</head><p>FE can be viewed as finding a set of vectors that represents an observation while reducing the dimensionality. In pattern recognition, it is desirable to extract features that are focused on discriminating between classes of interest. Although a reduction in dimensionality is desirable, the error increment due to the reduction in dimension has to be without sacrificing the discriminative power of classifiers. In linear FE, the number of input dimensions corresponds to the number of selected eigenvectors <ref type="bibr" target="#b2">[3]</ref>. The transformed data are determined by</p><formula xml:id="formula_7">x = Φ T x (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where Φ is the transformation matrix composed of the eigenvectors of the feature matrix, x is the data in the input space, and x is the transformed data in the feature space. We have in general dim(x) ≥ dim(x). Several statistical extraction approaches have been proposed for remote sensing data <ref type="bibr" target="#b2">[3]</ref>, including decision boundary FE (DBFE) and nonparametric weighted FE (NWFE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. DBFE</head><p>It was shown in <ref type="bibr" target="#b19">[20]</ref> that both discriminantly informative features and redundant features can be extracted from the decision boundary between two classes. The features are extracted from the decision boundary feature matrix (DBFM). The eigenvectors of the DBFM corresponding to nonzero eigenvalues are the necessary feature vectors to achieve the same classification accuracy as in the original space. The efficiency of the DBFE is related to the training set and can be computationally intensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. NWFE</head><p>To overcome the limitations of the DBFE, Kuo and Landgrebe <ref type="bibr" target="#b20">[21]</ref> proposed the NWFE. NWFE is based on the discriminant analysis FE by focusing on samples near the eventual decision boundary. The main ideas of the NWFE are as follows: 1) putting different weights on every sample to compute the local means and 2) defining nonparametric between-class and within-class scatter matrices <ref type="bibr" target="#b2">[3]</ref>.</p><p>Many experiments have shown the effectiveness of these approaches for the classification of hyperspectral data <ref type="bibr" target="#b2">[3]</ref>. They are usually applied on the spectral data, but they are successfully applied to the EMP <ref type="bibr" target="#b10">[11]</ref>.</p><p>IV. CLASSIFICATION BY SVM So far, in our previous approach <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b21">[22]</ref>, the classification was done with either a statistical classifier [Gaussian maximum likelihood (ML)], a neural network, or a fuzzy classifier. Here, it is proposed to use the SVMs. Early work in classification of remotely sensed images by SVM showed excellent results <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>. In <ref type="bibr" target="#b14">[15]</ref>, several SVM-based classifiers were compared to other classical classifiers such as a K-nearest neighbor classifier and a neural network classifier, and the SVM using the kernel method outperformed the other classifiers in terms of accuracy. Multiclass SVM performances were also positively compared with a discriminant analysis classifier, a decision tree classifier, and a feedforward neural network classifier with a limited training set <ref type="bibr" target="#b24">[25]</ref>. SVMs show good results in the situation of limited training set in <ref type="bibr" target="#b25">[26]</ref>. Semisupervised SVMs were also investigated for multispectral data classification <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>.</p><p>SVM is surely among the most used kernel learning algorithms. It performs robust nonlinear classification of samples using the kernel trick. The idea is to find a separating hyperplane in some feature space induced by the kernel function while all the computations are done in the original space <ref type="bibr" target="#b3">[4]</ref>. A good introduction to SVM for pattern recognition can be found in <ref type="bibr" target="#b28">[29]</ref>. Given a training set S = {(x 1 , y 1 ), . . . , (x , y )} ∈ R n {-1; 1}, the decision function is found by solving the convex optimization problem  where α's are the Lagrange coefficients, C is a constant that is used to penalize the training errors, and k is the kernel function.</p><formula xml:id="formula_9">max α g(α) = i=1 α i - 1 2 i,j=1 α i α j y i y j k(x i , x j ) subject to 0 ≤ α i ≤ C and i=1 α i y i = 0<label>(6)</label></formula><p>To be an acceptable kernel, k should be a positive semidefinite function <ref type="bibr" target="#b29">[30]</ref>. One classical effective kernel is the Gaussian kernel</p><formula xml:id="formula_10">k σ (x i , x j ) = exp - x i -x j 2 2σ 2<label>(7)</label></formula><p>where the norm is the Euclidean norm and σ ∈ R + tunes the flexibility of the kernel. A short comparison of kernels for remotely sensed image classification can be found in <ref type="bibr" target="#b25">[26]</ref>.</p><p>When the optimal solution of ( <ref type="formula" target="#formula_9">6</ref>) is found, i.e., the α i , the classification of a sample x is achieved by looking to which side of the hyperplane it belongs</p><formula xml:id="formula_11">y = sgn i=1 α i y i k(x i , x) + b . (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>To deal with multiclass classification problem, the pairwise approach was used in our experiments <ref type="bibr" target="#b30">[31]</ref>. More advanced multiclass approaches applied to remote sensing data can be found in <ref type="bibr" target="#b14">[15]</ref>. For the particular case of one-class classification, a dedicated methodology is proposed in <ref type="bibr" target="#b31">[32]</ref>.</p><p>The SVMs are mainly a nonparametric method, yet some parameters need to be tuned before the optimization. In the Gaussian kernel case, there are two parameters: C, which is the penalty term, and σ, which is the width of the exponential. It is usually done by a cross-validation step, where several values are tested. In our experiments, C was fixed to 200 and σ 2 ∈ {0.5, 1, 2, 4} was selected by using a fivefold cross validation. The SVM optimization problem was solved by using library LIBSVM <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DATA FUSION</head><p>The proposed method is based on the data fusion of the morphological information and the original data. In a previous work <ref type="bibr" target="#b33">[34]</ref>, it was proposed to fuse the classification results of two SVM classifiers, each one working with either the spectral or the EMP data. It consisted in an appropriate adaptive fusion scheme based on the output's characteristics of the SVM. The results in terms of accuracy were increased, but it needed two training of SVM, that could be time-consuming.</p><p>Here, it is proposed to use a multisource strategy to fuse spectral and spatial information. First, an EMP is created based on applying the PCA on the hyperspectral data. Second, FE is applied on both the EMP and the original hyperspectral data. Finally, the extracted feature vectors are concatenated into one stacked vector and classified by the SVM.</p><p>In the morphological processing, we usually retain PCs corresponding to 99% of the cumulative variance. This is done in order to reduce the redundancy in the data but keep most of the variation. The EMP is built by using the m PCs that correspond to the 99% variance. Each MP is composed of n geodesic openings, n geodesic closing, and the corresponding PC. The SE is a disk with initial radius of r pixels. The size increment is s. Hence, each MP has 2n + 1 features, and the EMP has m(2n + 1) features. Noting x ϕ as the features associated to the spectral bands and x ω as the features associated to the EMP, the corresponding extracted features from the FE algorithm are as follows:</p><formula xml:id="formula_13">x ϕ = Φ T ϕ x ϕ (9) x ω = Φ T φ x ω . (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>The stack vector is finally x = [x ϕ , x ω ] T . Fig. <ref type="figure" target="#fig_2">3</ref> shows the data fusion scheme. Note that in this paper, only morphological information is extracted, but it is possible to extract other types of spatial information with other processing and include them in the stacked vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Set</head><p>Airborne data from the ROSIS-3 (Reflective Optics System Imaging Spectrometer) optical sensor are used for the experiments. The flight over the city of Pavia, Italy, was operated by the Deutschen Zentrum fur Luft-und Raumfahrt (DLR, the German Aerospace Agency) in the framework of the HySens project, and managed and sponsored by the European Union. According to specifications, the number of bands of the ROSIS-3 sensor is 115 with a spectral coverage ranging from 0.43 to 0.86 μm. The data have been atmospherically corrected   <ref type="table" target="#tab_2">II</ref> and<ref type="table" target="#tab_2">III</ref>, and Fig. <ref type="figure" target="#fig_4">4</ref> shows false color images for both data sets. The classification accuracy was assessed with the following: 1) an overall accuracy (OA) which is the number of well-classified samples divided by the number of test's samples; 2) an average accuracy which represents the average of class classification accuracy; 3) a kappa coefficient of agreement (κ) which is the percentage of agreement corrected by the amount of agreement that could be expected due to chance alone <ref type="bibr" target="#b34">[35]</ref>.  These criteria were used to compare classification results and were computed by using the confusion matrix. Furthermore, the statistical significance of differences was computed by using McNemar's test, which is based upon the standardized normal test statistic <ref type="bibr" target="#b35">[36]</ref> </p><formula xml:id="formula_15">Z = f 12 -f 21 √ f 12 + f 21<label>(11)</label></formula><p>where f 12 indicates the number of samples classified correctly by classifier 1 and incorrectly by classifier 2. The difference in accuracy between classifiers 1 and 2 is said to be statistically significant if |Z| &gt; 1.96. The sign of Z indicates whether classifier 1 is more accurate than classifier 2 (Z &gt; 0) or vice versa (Z &lt; 0). This test assumes related testing samples and thus is adapted to our situation since the training and testing set were the same for each experiment. The FEs were done with MultiSpec <ref type="bibr" target="#b2">[3]</ref>, whereas the morphological operations were done with the image processing toolbox of Matlab. The SVM classification was done by using the LIBSVM through its Matlab interface <ref type="bibr" target="#b32">[33]</ref>. From previous experiments on the same data set, the Gaussian kernel provides the best results and was used for the experiments <ref type="bibr" target="#b25">[26]</ref>. The range of each feature, be it spectral or morphological, was stretched between zero and one.</p><p>To obtain a baseline result for comparison, the classification was also done by using the Gaussian ML classifier on the hyperspectral data using MultiSpec. <ref type="foot" target="#foot_0">1</ref> FE was done by using   the two FE algorithms (DBFE and NWFE), but only the best results have been reported for both data sets. The results were compared to those obtained by the proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. University Area Data Set</head><p>PCs were computed from the hyperspectral data. The results for the eigenvalues are shown in Table <ref type="table" target="#tab_3">IV</ref>. The left column gives the component number, the center column the eigenvalues in percentage of the total amount of variance, and the right column the cumulative amount of variance. From the table, three PCs were necessary to retain 99% of the variance criterion. EMPs were built according to the scheme presented in Section V: A circular SE with a step size increment of two was used. Four openings and closings were computed for each PC, resulting in an EMP of dimension 27.</p><p>First, the classification with SVM was done by using the spectral information and the EMP. The best ML accuracy was obtained by using eight features extracted with the NWFE, following Landgrebe's recommendations in <ref type="bibr" target="#b2">[3]</ref>. The results are reported in Table <ref type="table" target="#tab_4">V</ref>. Regarding the global accuracies, both SVM approaches perform equally well, for instance, the difference between the classification using the spectral information and the EMP is not statistically significant (see Table <ref type="table" target="#tab_5">VI</ref>). Note that it is consistent with the characteristics of the scene:</p><p>The university area is a mix between man-made structures and natural materials. Therefore, the morphological information is not as useful as it could be in a very dense urban area. When a careful analysis is done on the class-specific accuracies, we can see from Table <ref type="table" target="#tab_4">V</ref> that each approach performed well for complementary classes, e.g., the spectral approach performed better for classes 3, 6, and 9, whereas the EMP approach performed better for classes 1, 2, 7, and 8. After the data fusion, we have to look at these classes and see if the best information was used, i.e., if the classification accuracy increased for these classes.</p><p>The experiment was then performed with the concatenated vector. The vector was made of the 103 spectral bands and the 27 features of the EMP. The vector was directly used as an input to the SVM. The classification results are reported in Table <ref type="table" target="#tab_4">V</ref>. As can be seen from the table, the global accuracies increased. The κ value in percentage is 79.13% against 74.47% for the spectral approach and 73.25% for the EMP, and the differences are statistically significant (see Table <ref type="table" target="#tab_5">VI</ref>). Regarding the classspecific accuracies, the results in terms of accuracies have increased for classes 1, 7, and 8 when compared to both individual approaches. In fact, all the classes are more accurately classified than the worst respective cases for the individual approaches.</p><p>In the last experiment, feature reduction was applied on the morphological data and the original data before the concatenation. Then, the stacked vector was classified by the SVM. Table <ref type="table" target="#tab_6">VII</ref> gives the summary of the test accuracies for several  <ref type="table" target="#tab_4">V</ref>.</p><p>values of the variance criterion for the DBFE and NWFE. Best results were obtained with 95% and 80% variance criterion for the DBFE and NWFE, respectively. By using 95% of the variance criterion with DBFE, the hyperspectral data were reduced to 27 features and the EMP to 10 features. With NWFE and 80%, seven features were extracted from the hyperspectral data and six from the EMP. Again, as can be seen in Table <ref type="table" target="#tab_5">VI</ref>, differences between the classification accuracies are statistically significant.</p><p>Considering the class-specific accuracies, the DBFE approach improved the classification for class 2, whereas class 3 was less accurately classified than with the concatenated full hyperspectral data and EMP. However, the DBFE outperformed the individual classifications of the spatial or spectral information. On this data set, the classification of the DBFE-featureextracted data gave the best classification results. Similar comments can be made for the accuracies obtained with classifications of the NWFE. Still, the number of features needed to achieve the same accuracy is significantly lower for the NWFE approach than for the DBFE. Since the SVM is linearly related to the dimensionality of the data, lower dimensional data reduced the training time and increased the speed of the classification.</p><p>To assess this increase, comparison of the processing time (training and classification process) for the different approaches was made. Table <ref type="table" target="#tab_7">VIII</ref> gives the summary of the results which are clearly different according to the features used. The training time could depend on several factors: 1) the dimension of the data; 2) the size of the training set; 3) the number of parameters for the kernel.</p><p>For our given problem, items 2) and 3) are the same. Reducing the size of the data is beneficial for the processing time, since data with lower dimensionality (EMP and NWFE) have the shortest processing time. For the best case (NWFE), the gain is about 73%.  Classification maps for the different approaches are shown in Fig. <ref type="figure" target="#fig_5">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Pavia Center Data Set</head><p>For the second test, the scene is a very dense urban area in the center of the city of Pavia. Because of that, morphological information should be useful for the discrimination. PCs were computed from the hyperspectral data. The results for the eigenvalues are shown in Table <ref type="table" target="#tab_8">IX</ref>. From the table, three PCs were necessary to retain 99% of the variance criterion. The EMP was built according to the scheme presented in Section V: A circular SE with a step size increment of two was used. Four openings and closings were computed for each PC, resulting in an EMP of dimension 27.</p><p>SVM classification was applied to the original hyperspectral data and the EMP. The best ML accuracy was obtained by using 29 features extracted with the DBFE. The results are reported in Table <ref type="table" target="#tab_10">X</ref>. From the table, it can be seen that SVM classifier achieved excellent global accuracies. In these experiments, the morphological approach performs better than the spectralbased approach.    of differences between the classification accuracies for the different approaches. This is consistent with the characteristics of the picture: It is a very dense urban area, and morphological processing provides discriminative information. In terms of accuracies, the main improvement in the classification is achieved for class 4. The other classes are classified equally accurately. The data fusion should thus improve the classification of class 4 while preserving very good results for the other classes.</p><p>Next, the experiment was performed by using the concatenated vector. The vector was made of the 102 spectral bands and the 27 features of the EMP. This vector was used as an input for the SVM without any additional processing. The classification results are reported in Table <ref type="table" target="#tab_10">X</ref>. The differences of classification accuracies between the EMP and the concatenated vector are not statistically significant, since the McNemar's test is almost equal to zero (see Table <ref type="table" target="#tab_11">XI</ref>). Thus, both EMP and concatenated vector perform equally well.</p><p>As in the previous experiment, feature reduction was applied both on the morphological data and on the original data before the concatenation. Then, the stacked vector was classified by the SVM.  For this experiment, the DBFE does not help for the classification since the Z-test is not significant. On the other hand, similar classification accuracy is reached with far less features, nearly half the size of the previous feature set, thus decreasing the total training and classification time. The NWFE leads to a significant increase of the classification accuracies, |Z| = 7.75, by comparison to the best results obtained with the concatenation vector, which is contrary to the previous experiment. Classification maps for the different approaches are shown in Fig. <ref type="figure" target="#fig_7">6</ref>. Visually, the thematic map produced with the classification of the NWFE features seems less noisy than the one obtained with the classification of the DBFE features. This is particularly true in the top-left corner which corresponds to a very dense urban area.</p><p>Regarding the computing time, the results for the training and the classification are reported in Table XIII. As expected, using FE methods reduces the processing time for both the training and the classification.</p><p>Classification maps for the different approaches are shown in Fig. <ref type="figure" target="#fig_7">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Small Training Set Experiment: University Area</head><p>To assess the effectiveness of the proposed methodology for a limited training set, we have randomly extracted a few  training samples from the training set. For this experiment, we used 20 samples for each class, which represents less than 5% of the original training set. We have used the same EMP but had some problems with the DBFE; the covariance matrix was noninvertible (the NWFE does not suffer from this problem). In order to overcome this shortcoming and to apply the DBFE anyway, we use the leave on out covariance to estimate the covariance matrix and perform a statistical enhancement with unlabeled samples; both algorithms were implemented in the MultiSpec software <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. We have repeated the training sample selection and the classification process five times, and the mean classification results are reported in this paper.</p><p>As with the previous experiments, we perform the classification using the spectral or the morphological feature with SVM. The ML produced very poor results, simply close to random classification and hence not reported. The global accuracies are reported in Table <ref type="table" target="#tab_15">XIV</ref>. Statistical significance of differences is reported in Table <ref type="table" target="#tab_16">XV</ref>.</p><p>First of all, the test results are lower than those in Tables V and VII, due to the limited training set. For instance, with the concatenated feature vector, the OA and the κ are, respectively, 83.53% and 79.13% for the original training set, whereas using a limited training set, the OA and the κ are, respectively, 75.35% and 68.66%. Nevertheless, with a very small training set, the results are still good.</p><p>For FE, NWFE with 99% of the cumulative variance provides the best results: The obtained OA is 85.42%, and the κ is 80.87%, which is closed to the best results obtained with the full training set (OA = 97.87% and κ = 84.40%, see Table <ref type="table" target="#tab_4">V</ref>). The |Z| between the best results with limited training and the best results with full training set is equal to 13.65.</p><p>Furthermore, the accuracies are better than those obtained with the full training set with the spectral or morphological information alone. It is also important to note that NWFE outperforms the DBFE without any statistical enhancement.</p><p>Considering the processing time, with only 20 samples for each class, the training, as well as the classification of the entire data set, is done in 1 or 2 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>Classification of hyperspectral data with a fine spatial resolution has been investigated. The contribution of this paper is a methodology to include both spatial and spectral information in the classification process by a data fusion scheme. Experimental results on two ROSIS data sets showed excellent accuracies and improvements compared to those obtained with pixel-based classifiers and the EMP-based classifier.</p><p>The use of FE was motivated by the fact that the full stacked vector contains a lot of redundancies because there is a redundancy in the hyperspectral data <ref type="bibr" target="#b2">[3]</ref> as well as in the EMP <ref type="bibr" target="#b10">[11]</ref>, which was confirmed by the experiments. On the other hand, SVMs are known to be robust to dimensionality. Therefore, the use of feature reduction for SVMs could be disputable. However, in the experiments, lower dimensional data decreased the processing time, which can be crucial for some applications, and more importantly, it has been shown that SVMs can suffer from the dimensionality when many features are irrelevant <ref type="bibr" target="#b38">[39]</ref>. By construction, the stacked vector may contain many copies of the same information, and an FE step may finally be needed to ensure correct classification on every data set, which is confirmed by the experiments (usefulness of feature reduction for the classification of remote sensing data with SVMs was also assessed in <ref type="bibr" target="#b39">[40]</ref>).</p><p>It is clear that FE helps for the classification of hyperspectral data, but it is not clear which one of the FE methods should be used for the fusion of morphological and spectral features. From a theoretical point of view, the NWFE was derived because of some intrinsic problems with the DBFE <ref type="bibr" target="#b2">[3]</ref>, i.e., "DBFE can involve lengthy calculations, and more significantly, it does not perform as well for small numbers of training samples." Hence, the NWFE might be more preferable, particularly when a small training set is available. The experiments performed with a limited training set confirmed that.</p><p>In conclusion, the proposed fusion method succeeded in taking advantage of the spatial and the spectral information simultaneously. It outperformed previous results <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b9">[10]</ref>. Our current research is oriented to the definition of additional spatial features, such as textural characteristics <ref type="bibr" target="#b40">[41]</ref>, to be included in the feature vectors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Simple morphological profile with two openings and two closings. In the shown profile, circular SEs are used with radius increment 4 (r = 4, 8 pixels). The processed image is a part of Fig. 4(a).</figDesc><graphic coords="3,44.94,70.02,246.12,64.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. EMP of two images. Each of the original profile has two openings and two closings. Circular SE with radius increment 4 was used (r = 4, 8). The processed image is a part of Fig. 4(a).</figDesc><graphic coords="4,114.23,191.60,360.12,54.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Proposed data fusion scheme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>but not geometrically corrected. The spatial resolution is 1.3 m per pixel. Two data sets were used in the experiment. 1) University area: The first test set is around the Engineering School at the University of Pavia. It is 610 × 340 pixels. Some channels (12) have been removed due to noise. The remaining 103 spectral dimensions are processed. Nine classes of interest are considered, i.e., trees, asphalt, bitumen, gravel, metal sheets, shadow, bricks, meadows, and soil. 2) Pavia center: The second test set is the center of Pavia. The Pavia center image was originally 1096 × 1096 pixels. A 381-pixel-wide black stripe in the left part of image was removed, resulting in a "two parts" image. This "two parts" image is 1096 × 715 pixels. Some channels (13) have been removed due to noise. The remaining 102 spectral dimensions are processed. Nine classes of interest are considered, i.e., water, trees, meadows, bricks, soil, asphalt, bitumen, tiles, and shadows. Available training and testing set for each data set are given in Tables</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. ROSIS data: (a) University area and (b) Pavia center. Three-channel color composite of the areas used for the classification. Data characteristics are detailed in Sections VI-B and C.</figDesc><graphic coords="5,307.95,70.02,245.40,208.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. University area: Classification map obtained with SVMs from (a) the original hyperspectral data, (b) the EMP, (c) 37 DBFE features, and (d) 13 NWFE feautres. Classification accuracies are reported in TableV.</figDesc><graphic coords="7,47.44,69.94,504.12,224.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>For</head><label></label><figDesc>the classification processing time, two factors have an influence: the dimension of the data and the number of support vectors [nonzero α i in (8)]. Thus, approaches with low dimensionality and few support vectors perform the classification task of the whole image faster (EMP and NWFE). Nevertheless, the classification processing is really fast by comparison to the training time, in all the cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Pavia center: Classification map obtained with SVMs from (a) the original hyperspectral data, (b) the EMP, (c) 66 DBFE features, and (d) 64 NWFE features. Classification accuracies are reported in TableX.</figDesc><graphic coords="9,47.44,70.18,504.12,194.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I SPECTRAL</head><label>I</label><figDesc>AND SPATIAL DATA PROPERTIES. " " INDICATES A GOOD PROPERTY, "∼" INDICATES THAT THE PROPERTY MIGHT BE HARMFUL,</figDesc><table /><note><p>AND " " INDICATES A CRITICAL PROPERTY</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II INFORMATION</head><label>II</label><figDesc>CLASSES AND TRAINING-TEST SAMPLES FOR THE UNIVERSITY AREA AND DATA SET TABLE III INFORMATION CLASSES AND TRAINING-TEST SAMPLE FOR THE PAVIA CENTER DATA SET</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV UNIVERSITY</head><label>IV</label><figDesc>AREA. EIGENVALUES OF PC IN PERCENTAGE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V UNIVERSITY</head><label>V</label><figDesc>AREA. SUMMARY OF THE GLOBAL AND THE CLASS-SPECIFIC TEST ACCURACIES IN PERCENTAGE FOR THE CLASSIFICATION. THE NUMBERS OF FEATURES FROM THE SPECTRAL DATA AND THE MORPHOLOGICAL DATA, RESPECTIVELY, ARE GIVEN IN BRACKETS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI UNIVERSITY</head><label>VI</label><figDesc>AREA. STATISTICAL SIGNIFICANCE OF DIFFERENCES IN CLASSIFICATION ACCURACIES</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII UNIVERSITY</head><label>VII</label><figDesc>AREA. GLOBAL ACCURACIES IN PERCENTAGE WITH DIFFERENT FE METHODS. THE NUMBERS OF FEATURES FROM THE SPECTRAL DATA AND THE MORPHOLOGICAL DATA, RESPECTIVELY, ARE GIVEN IN BRACKETS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VIII UNIVERSITY</head><label>VIII</label><figDesc>AREA. PROCESSING TIME IN SECONDS AS FUNCTION OF DIMENSIONALITY AND NUMBER OF SUPPORT VECTORS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE IX PAVIA</head><label>IX</label><figDesc>CENTER. EIGENVALUES OF PCS IN PERCENTAGE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Table XI shows the statistical significance</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE X PAVIA</head><label>X</label><figDesc>CENTER. SUMMARY OF THE GLOBAL AND THE CLASS-SPECIFIC TEST ACCURACIES IN PERCENTAGE FOR SVM CLASSIFICATION. THE NUMBERS OF THE FEATURES FROM THE SPECTRAL DATA AND THE MORPHOLOGICAL DATA, RESPECTIVELY, ARE GIVEN IN BRACKETS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE XI PAVIA</head><label>XI</label><figDesc>CENTER. STATISTICAL SIGNIFICANCE OF DIFFERENCES IN CLASSIFICATION ACCURACIES</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XII PAVIA</head><label>XII</label><figDesc>CENTER. GLOBAL ACCURACIES IN PERCENTAGE WITH DIFFERENT FE METHODS. THE NUMBERS OF FEATURES FROM THE SPECTRAL DATA AND THE MORPHOLOGICAL DATA, RESPECTIVELY, ARE IN BRACKETS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Table XII gives the summary of the test accuracies for several values for the variance criterion for the DBFE and NWFE. The best results are obtained with 99% variance criterion for both DBFE and NWFE. By using 99% of the</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE XIII PAVIA</head><label>XIII</label><figDesc>CENTER. PROCESSING TIME IN SECONDS AS FUNCTION OF DIMENSIONALITY</figDesc><table /><note><p><p><p>AND NUMBER OF SUPPORT VECTORS variance with the DBFE, the hyperspectral data are reduced to 51 features, and the EMP is reduced to 15 features. With the NWFE and 99% of the variance criterion, 44 features were extracted from the hyperspectral data and 20 from the EMP. The results are given in Table</p>X</p>.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE XIV UNIVERSITY</head><label>XIV</label><figDesc>AREA. SUMMARY OF THE GLOBAL TEST ACCURACIES IN PERCENTAGE FOR SVM CLASSIFICATION USING LIMITED TRAINING SET. THE NUMBERS IN BRACKETS ARE THE NUMBERS OF FEATURES FROM THE SPECTRAL DATA AND FROM MORPHOLOGICAL DATA, RESPECTIVELY</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>TABLE XV UNIVERSITY</head><label>XV</label><figDesc>AREA. STATISTICAL SIGNIFICANCE OF DIFFERENCES IN CLASSIFICATION ACCURACY FOR A LIMITED TRAINING SET</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For the ML, the kappa coefficient was not accessible.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Mr. J. A. Palmason for his contributions, the IAPR-TC7 for providing the data, and Prof. P. Gamba and Prof. F. Dell'Acqua of the University of Pavia, Italy, for providing reference data. The authors would also like to thank the reviewers for their many helpful comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Research Fund of the University of Iceland and in part by the Jules Verne Program of the French and Icelandic governments (PAI EGIDE).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new approach for the morphological segmentation of high-resolution satellite imagery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pesaresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="320" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral data from urban areas using morphological preprocessing and independent component analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Palmason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Sveinsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IGARSS</title>
		<meeting>IGARSS</meeting>
		<imprint>
			<date type="published" when="2005-07">Jul. 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="176" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Signal Theory Methods in Multispectral Remote Sensing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Wiley</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Supervised segmentation of remote sensing images based on a tree-structure MRF model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Poggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scarpa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zerubia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1901" to="1911" />
			<date type="published" when="2005-08">Aug. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive Bayesian contextual classification based on Markov random fields</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2454" to="2463" />
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classification and feature extraction for remote sensing images from urban areas based on morphological transformations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pesaresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Arnason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1940" to="1949" />
			<date type="published" when="2003-09">Sep. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploiting spectral and spatial information in hyperspectral urban data with high resolution</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dell'acqua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gamba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Palmason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="322" to="326" />
			<date type="published" when="2004-10">Oct. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spectral and spatial classification of hyperspectral data using SVMs and morphological profiles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Sveinsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IGARSS</title>
		<meeting>IGARSS</meeting>
		<imprint>
			<date type="published" when="2007-07">Jul. 2007</date>
			<biblScope unit="page" from="4834" to="4837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fusion of morphological and spectral information for classification of hyperspectral urban remote sensing data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Palmason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Sveinsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IGARSS</title>
		<meeting>IGARSS</meeting>
		<imprint>
			<date type="published" when="2006-07">Jul. 2006</date>
			<biblScope unit="page" from="2506" to="2509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral data from urban areas based on extended morphological profiles</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Palmason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sveinsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="491" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Composite kernels for hyperspectral image classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gomez-Chova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Munoz-Mari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vila-Francés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Calpe-Maravilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="97" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Partially supervised oil-slick detection by SAR imagery using kernel expansion</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mercier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Girard-Ardhuin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2839" to="2846" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A joint spatial and spectral SVM&apos;s classification of panchromatic images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IGARSS</title>
		<meeting>IGARSS</meeting>
		<imprint>
			<date type="published" when="2007-07">Jul. 2007</date>
			<biblScope unit="page" from="1497" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral remote sensing images with support vector machines</title>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1778" to="1790" />
			<date type="published" when="2004-08">Aug. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Performance analysis and comparison of neural networks and support vectors machines classifier</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th World Congr</title>
		<meeting>5th World Congr</meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
			<biblScope unit="page" from="4232" to="4235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Support vector machines in multisource classification</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Halldorsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Sveinsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IGARSS</title>
		<meeting>IGARSS</meeting>
		<imprint>
			<date type="published" when="2003-07">Jul. 2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2054" to="2056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Advances in mathematical morphology applied to geoscience and remote sensing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Soille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pesaresi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2042" to="2055" />
			<date type="published" when="2002-09">Sep. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Soille</surname></persName>
		</author>
		<title level="m">Morphological Image Analysis, Principles and Applications</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Feature extraction based on decision boundaries</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="388" to="400" />
			<date type="published" when="1993-04">Apr. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A robust classification procedure based on mixture classifiers and nonparametric weighted feature extraction</title>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2486" to="2494" />
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Classification of remote sensing images from urban areas using a fuzzy possibilistic model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="44" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Support vector machines for hyperspectral remote sensing classification</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gualtieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Cromp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">3584</biblScope>
			<biblScope unit="page" from="221" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Support vector machines for classification of hyperspectral data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gualtieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chettri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IGARSS</title>
		<meeting>IGARSS</meeting>
		<imprint>
			<date type="published" when="2000-07">Jul. 2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="813" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A relative evaluation of multiclass image classification by support vector machines</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Foody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mathur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1335" to="1343" />
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluation of kernels for multiclass classification of hyperspectral remote sensing data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="813" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A novel transductive SVM for semisupervised classification of remote-sensing images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marconcini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3363" to="3373" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semisupervised classification of hyperspectral images by SVMs optimized in the primal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1870" to="1880" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998-06">Jun. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Theory of reproducing kernel</title>
		<author>
			<persName><forename type="first">N</forename><surname>Aronszajn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Div. Eng. Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="1950">1950</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Harvard Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A comparison of methods for multiclass support vector machines</title>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="415" to="425" />
			<date type="published" when="2002-03">Mar. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">One-class classification for mapping a specific land-cover class: SVDD classification of fenland</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sanchez-Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Boydand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Foody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1061" to="1073" />
			<date type="published" when="2007-04">Apr. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Decision fusion for the classification of urban remote sensing images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2828" to="2838" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Remote Sensing Digital Image Analysis: An Introduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Thematic map comparison: Evaluating the statistical significance of differences in classification accuracy</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Foody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm. Eng. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="627" to="633" />
			<date type="published" when="2004-05">May 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Covariance matrix estimation and classification with limited data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="763" to="767" />
			<date type="published" when="1996-07">Jul. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The effect of unlabeled samples in reducing the small sample size problem and mitigating the Hughes phenomenon</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Shahshahani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1087" to="1095" />
			<date type="published" when="1994-09">Sep. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Support vector machines: Induction principle, adaptive tuning and prior knowledge</title>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<ptr target="http://www.kyb.mpg.de/publication.html?publ=2167" />
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Paris, France</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. Pierre et Marie Curie</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Toward an optimal SVM classification system for hyperspectral remote sensing images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3374" to="3385" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Morphological texture features for unsupervised and supervised segmentations of natural landscapes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Epifanio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Soille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1074" to="1083" />
			<date type="published" when="2007-04">Apr. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
