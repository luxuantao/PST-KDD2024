<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Work Stealing with Parallelism Feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kunal</forename><surname>Agrawal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<postCode>02139</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Work Stealing with Parallelism Feedback</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">081A478F6B268CF0559EF4FD55882591</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.4.1 [Software]: Operating Systems -process management; F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity General Terms Algorithms</term>
					<term>Performance</term>
					<term>Theory Adaptive scheduling</term>
					<term>Adversary</term>
					<term>Critical path</term>
					<term>Multithreaded Languages</term>
					<term>Distributed scheduling</term>
					<term>Job scheduling</term>
					<term>Multiprocessing</term>
					<term>Multiprogramming</term>
					<term>Parallelism feedback</term>
					<term>Parallel computation</term>
					<term>Processor allocation</term>
					<term>Space sharing</term>
					<term>Thread scheduling</term>
					<term>Two-level scheduling</term>
					<term>Trim analysis</term>
					<term>Work</term>
					<term>Work stealing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an adaptive work-stealing thread scheduler, A-STEAL, for fork-join multithreaded jobs, like those written using the Cilk multithreaded language or the Hood work-stealing library. The A-STEAL algorithm is appropriate for large parallel servers where many jobs share a common multiprocessor resource and in which the number of processors available to a particular job may vary during the job's execution. A-STEAL provides continual parallelism feedback to a job scheduler in the form of processor requests, and the job must adapt its execution to the processors allotted to it. Assuming that the job scheduler never allots any job more processors than requested by the job's thread scheduler, A-STEAL guarantees that the job completes in near-optimal time while utilizing at least a constant fraction of the allotted processors.</p><p>Our analysis models the job scheduler as the thread scheduler's adversary, challenging the thread scheduler to be robust to the system environment and the job scheduler's administrative policies. We analyze the performance of A-STEAL using "trim analysis," which allows us to prove that our thread scheduler performs poorly on at most a small number of time steps, while exhibiting near-optimal behavior on the vast majority. To be precise, suppose that a job has work T1 and criticalpath length T∞. On a machine with P processors, A-STEAL completes the job in expected O(T1/ P + T∞ + L lg P ) time steps, where L is the length of a scheduling quantum and P denotes the O(T∞ + L lg P )-trimmed availability. This quantity is the average of the processor availability over all but the O(T∞ + L lg P ) time steps having the highest processor availability. When the job's parallelism dominates the trimmed availability, that is, P T1/T∞, the job achieves nearly perfect linear speedup. Conversely, when the trimmed mean dominates the parallelism, the asymptotic running time of the job is nearly the length of its critical path.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The large expense of high-end multiprocessors makes it attractive for them to run multiprogrammed workloads, where many parallel applications share the same machine. As Feitelson describes in his excellent survey <ref type="bibr" target="#b28">[29]</ref>, schedulers for these machines can be implemented using two levels: a kernel-level job scheduler to allot processors to jobs, and a user-level thread scheduler to schedule the threads belonging to a given job onto the allotted processors. The job schedulers may implement either space-sharing, where jobs occupy disjoint processor resources, or time-sharing, where different jobs may share the same processor resources at different times. Moreover, both the thread scheduler and the job scheduler may be adaptive (called "dynamic" in <ref type="bibr" target="#b20">[21]</ref>), where the number of processors allotted to a job may change while the job is running, or nonadaptive (called "static" in <ref type="bibr" target="#b20">[21]</ref>), where a job runs on a fixed number of processors for its lifetime.</p><p>Randomized work-stealing <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b30">31]</ref> has proved to be an effective way to design a thread scheduler, both in theory and in practice. The decentralized thread scheduler is unaware of all the available threads to execute at a given moment. Whenever a processor runs out of work, it "steals" work from another processor chosen a random. To date, however, no work-stealing thread schedulers have been designed that provide provably effective parallelism feedback to a job scheduler.</p><p>In this paper we present an adaptive work-stealing thread scheduler, A-STEAL, which provides feedback about the job's parallelism to a space-sharing job scheduler by requesting processors from the job scheduler at regular intervals, called scheduling quanta. Based on this parallelism feedback, the job scheduler can alter the allotment of processors to the job for the upcoming quantum according to the availability of processors in the current system environment and the job scheduler's administrative policy. A-STEAL is inspired by a task-scheduling algorithm, called A-GREEDY, which we developed in previous work <ref type="bibr" target="#b1">[2]</ref> with Wen Jing Hsu from Nanyang Technological University in Singapore. Whereas A-GREEDY uses a centralized algorithm to schedule tasks on allotted processors, our new A-STEAL algorithm works in a decentralized fashion, using work-stealing to schedule the threads on allotted pro-cessors. We prove that A-STEAL is efficient, minimizing both execution time and wasted processor cycles.</p><p>While A-STEAL is an extension of classic randomized work stealing and the feedback algorithm of A-GREEDY, combining the algorithms posed novel technical challenges, because unlike classical randomized work-stealing, A-STEAL must deal with dynamic changes in the job's processor allotment. In particular, when the allotment decreases, we use a mechanism called "mugging" <ref type="bibr" target="#b13">[14]</ref>, which involves a processor stealing all the work of another processor, rather than just a single task. Paradoxically, although muggings are considered as waste in our analysis, they are treated as productive work for the purpose of providing parallelism feedback.</p><p>Like prior work on scheduling of multithreaded jobs <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44]</ref>, we model the execution of a multithreaded job as a dynamically unfolding directed acyclic graph (dag). Each node in the dag represents a unit-time instruction, and an edge represents a serial dependence between nodes. A thread is a chain of nodes with no branches. A node becomes ready when all its predecessors have been executed, and a thread becomes ready when its first node becomes ready. The work T1 of the job corresponds to the total number of nodes in the dag and the critical-path length T∞ corresponds to the length of the longest chain of dependencies. The parallelism of the job is the quantity T1/T∞, which represents the average amount of work along each step of the critical path. Each job has its own thread scheduler, which operates in an online manner, oblivious to the future characteristics of the dynamically unfolding dag.</p><p>In the scheduling model, we assume that time is broken into a sequence of equal-size scheduling quanta 1, 2, . . ., each consisting of L time steps, and the job scheduler is free to reallocate processors between quanta. The quantum length L is a system configuration parameter chosen to be long enough to amortize the time to reallocate processors among the various jobs and to perform various other bookkeeping for scheduling, including communication between the thread scheduler and the job scheduler, which typically involves a system call.</p><p>The thread scheduler operates as follows. Between quanta q -1 and q, it determines its job's desire dq, which is the number of processors the job wants for quantum q. The thread scheduler provides the desire dq to the job scheduler as its parallelism feedback. The job scheduler follows some processor allocation policy to determine the processor availability pqthe number of processors to which the job is entitled for the quantum q. In order to make the thread scheduler robust to different system environments and administrative policies, our analysis of A-STEAL assumes that the job scheduler decides the availability of processors as an adversary. The number of processors the job receives for quantum q is the job's allotment aq = min {dq, pq}, the smaller of the job's desire and the processor availability. Once a job is allotted its processors, the allotment does not change during the quantum. Consequently, the thread scheduler must do a good job before a quantum of estimating how many processors it will need for all L time steps of the quantum, as well as do a good job of scheduling the ready threads on the allotted processors.</p><p>In an adaptive setting where the number of processors allotted to a job can change during execution, both T1/P and T∞ are lower bounds on the running time, where P is the mean of the processor availability during the computation. In the worst case, however, an adversarial job scheduler can prevent any thread scheduler from providing good speedup with respect to the mean availability P . For example, if the adversary chooses a huge number of processors for the job's processor availabil-ity just when the job has little instantaneous parallelismthe number of threads ready to run at a given moment -no adaptive scheduling algorithm can effectively utilize the available processors on that quantum. <ref type="foot" target="#foot_0">1</ref>We use trim analysis <ref type="bibr" target="#b1">[2]</ref> to analyze the time bound of adaptive thread schedulers under these adversarial conditions. Trim analysis borrows from the field of statistics the idea of ignoring a few "outliers." A trimmed mean, for example, is calculated by discarding a certain number of lowest and highest values and then computing the mean of those that remain. For our purposes, it suffices to trim the availability from just the high side. For a given value R, we define the R-high-trimmed mean availability as the mean availability after ignoring the R steps with the highest availability, or just R-trimmed availablility, for short. A good thread scheduler should provide linear speedup with respect to an R-trimmed availability, where R is as small as possible.</p><p>We prove that A-STEAL guarantees linear speedup with respect to O(T∞ + L lg P )-trimmed availability. Specifically, consider a job with work T1 and critical-path length T∞ running on a machine with P processors and a scheduling quantum of length L. A-STEAL completes the job in expected O(T1/ P + T∞ + L lg P ) time steps, where P denotes the O(T∞ + L lg P )-trimmed availability. Thus, the job achieves linear speed up with respect to the trimmed availability P when the parallelism T1/T∞ dominates P . In addition, we prove that the total number of processor cycles wasted by the job is O(T1), representing at most a constant-factor overhead.</p><p>Although this paper concerns itself only with the theoretical performance of A-STEAL, we have also studied its empirical performance using simulations <ref type="bibr" target="#b2">[3]</ref>. To summarize that work, a linear-regression analysis using a variety of availability profiles indicates that A-STEAL provides almost perfect linear speedup with respect to the mean availability. The simulations indicate that A-STEAL typically wastes less than 20% of the processor cycles allotted to the job. We also compared A-STEAL with the ABP algorithm, an adaptive work-stealing thread scheduler developed by Arora, Blumofe, and Plaxton which does not employ parallelism feedback. We ran single jobs using both A-STEAL and ABP with the same availability profiles. We found that on moderately to heavily loaded large machines, when P P , A-STEAL completes almost all jobs about twice as fast as ABP on average, despite the fact that ABP's allotment on any quantum is never less than A-STEAL's allotment on the same quantum. In virtually all of these job runs, A-STEAL wastes less than 10% of the processor cycles wasted by ABP.</p><p>The remainder of this paper is organized as follows. Section 2 describes the A-STEAL algorithm and Section 3 provides a trim analysis of its completion time, while Section 4 provides the waste analysis. Section 5 explains the trade-offs among various parameters. Section 6 describes related work in adaptive and nonadaptive scheduling, putting this paper into an historical perspective. Finally, Section 7 offers some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Adaptive work-stealing</head><p>This section presents the adaptive work-stealing thread scheduler A-STEAL. Before the start of a quantum, A-STEAL es-timates processor desire based on the job's history of utilization. It uses this estimate as its parallelism feedback to the job scheduler, which it provides in the form of a request for processors. In this section, we describe A-STEAL and its desireestimation heuristic.</p><p>During a quantum, A-STEAL uses work-stealing <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b40">41</ref>] to schedule the job's threads on the allotted processors. A-STEAL can use any provably good work-stealing algorithm, such as that of Blumofe and Leiserson <ref type="bibr" target="#b12">[13]</ref> or the nonblocking one presented by Arora, Blumofe, and Plaxton <ref type="bibr" target="#b3">[4]</ref>. In a workstealing thread scheduler, every processor alloted to the job maintains a queue of ready threads for the job. When the ready queue of a processor becomes empty, the processor becomes a thief , randomly picking a victim processor and stealing work from the victim's ready queue. If the victim has no available work, then the steal is unsuccessful, and the thief continues to steal at random from other processors until it is successful and finds work. At all times, every processor is either working or stealing.</p><p>This basic work-stealing algorithm must be modified to deal with dynamic changes in processor allotment to the job between quanta. Two simple modifications make the workstealing algorithm adaptive.</p><p>Allotment gain: When the allotment increases from quantum q -1 to q, the thread scheduler obtains aq -aq-1 additional processors. Since the ready queues of these new processors start out empty, all these processors immediately start stealing to get work from the other processors.</p><p>Allotment loss: When the allotment decreases from quantum q -1 to q, the job scheduler deallocates aq-1 -aq processors, whose ready queues may be nonempty. To deal with these queues, we use the concept of "mugging" <ref type="bibr" target="#b13">[14]</ref>. When a processor runs out of work, instead of stealing immediately, it looks for a muggable queue, a nonempty queue that has no associated processor working on it. Upon finding a muggable queue, the thief mugs the queue by taking over the entire queue as its own. Thereafter, it works on the queue as if it were its own. If there are no muggable queues, the thief steals normally.</p><p>At all time steps during the execution of A-STEAL, every processor is either working, stealing, or mugging. We call the cycles a processor spends on working, stealing, and mugging as work-cycles, steal-cycles, and mug-cycles, respectively. Cycles spent stealing and mugging are wasted.</p><p>The salient part of A-STEAL is its desire-estimation algorithm, which is extended from the desire-estimation heuristic for the A-GREEDY algorithm originally presented in <ref type="bibr" target="#b1">[2]</ref>. To estimate the desire for the next quantum q + 1, A-STEAL classifies the previous quantum q as either "satisfied" or "deprived" and either "efficient" or "inefficient." Of the four possibilities for classification, A-STEAL only uses three: inefficient, efficient-and-satisfied, and efficient-and-deprived. Using this three-way classification and the job's desire for the previous quantum q, it computes the desire for the next quantum q + 1.</p><p>A-STEAL classifies a quantum as satisfied versus deprived by comparing the allotment aq with the desire dq. The quantum q is satisfied if aq = dq, that is, the job receives as many processors as A-STEAL requested for it from the job scheduler. Otherwise, if aq &lt; dq, the quantum is deprived, because the job did not receive as many processors as it requested.</p><p>A-STEAL classifies a quantum as efficient versus inefficient by comparing the usage with the allotment. We define the usage uq of quantum q as the total number of work-cycles in q and the nonsteal usage nq as the sum of the number of work-cycles and mug-cycles. Therefore, we have uq ≤ nq. A-STEAL uses a utilization parameter δ as the threshold to differ-A-STEAL (q, δ, ρ)</p><formula xml:id="formula_0">1 if q = 1 2 then dq ← 1 £ base case 3 elseif nq-1 &lt; Lδaq-1 4 then dq ← dq-1/ρ £ inefficient 5 elseif aq-1 = dq-1 6</formula><p>then dq ← ρdq-1 £ efficient-and-satisfied 7 else dq ← dq-1</p><p>£ efficient-and-deprived 8 Report dq to the job scheduler. 9 Receive allotment aq from the job scheduler. 10 Schedule on aq processors using randomized work stealing for L time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1:</head><p>Pseudocode for the adaptive work-stealing thread scheduler A-STEAL, which provides parallelism feedback to a job scheduler in the form of processor desire. Before quantum q, A-STEAL uses the previous quantum's desire d q-1 , allotment a q-1 , and nonsteal usage n q-1 to compute the current quantum's desire dq based on the utilization parameter δ and the responsiveness parameter ρ.</p><p>entiate between efficient and inefficient quanta. The utilization parameter δ in A-STEAL is a lower bound on the fraction of available processors used to work or mug on accounted steps. Typical values for δ might be in the range of 80% to 95%. We call a quantum q efficient if nq ≥ δLaq, that is, the nonsteal usage is at least a δ fraction of the total processor cycles allotted. A quantum is inefficient otherwise. Inefficient quanta contain at least (1 -δ)Laq steal-cycles. It might seem counterintuitive for the definition of "efficient" to include mug-cycles. After all, mug-cycles are wasted. The rationale is that mug-cycles arise as a result of an allotment loss. Thus, they do not generally indicate that the job has a surplus of processors. Therefore, A-STEAL does not penalize jobs for too many mug cycles in a quantum.</p><p>A-STEAL calculates the desire dq of the current quantum q based on the previous desire dq-1 and the three-way classification of quantum q -1 as inefficient, efficient-and-satisfied, and efficient-and-deprived. The initial desire is d1 = 1. Like A-GREEDY, A-STEAL uses a responsiveness parameter ρ &gt; 1 to determine how quickly the scheduler responds to changes in parallelism. Typical values of ρ might range between 1.2 and 2.0.</p><p>Figure <ref type="figure">1</ref> shows the pseudocode of A-STEAL for one quantum. A-STEAL takes as input the quantum q, the utilization parameter δ, and the responsiveness parameter ρ. For the first quantum, it requests 1 processor. Thereafter, it operates as follows:</p><p>• Inefficient: If quantum q -1 was inefficient, it contained many steal-cycles, which indicates that most of the processors had insufficient work to do. Therefore, A-STEAL overestimated the desire for quantum q -1. In this case, A-STEAL does not care whether quantum q -1 was satisfied or deprived. It simply decreases the desire (line 4) for quantum q. • Efficient-and-satisfied: If quantum q -1 was efficientand-satisfied, the job effectively utilized the processors that A-STEAL requested on its behalf. In this case, A-STEAL speculates that the job can use more processors. It increases the desire (line 6) for quantum q. • Efficient-and-deprived: If quantum q -1 was efficientand-deprived, the job used all the processors it was allotted, but A-STEAL had requested more processors for the job than the job actually received from the job scheduler. Since A-STEAL has no evidence whether the job could have used all the processors requested, it maintains the same desire (line 7) for quantum q. After determining the job's desire, A-STEAL requests that many processors from the job scheduler, receives its allotment, and then schedules the job on the allotted processors for the L time steps of the quantum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Time analysis</head><p>This section uses a trim analysis to analyze A-STEAL with respect to the completion time. Suppose that A-STEAL schedules a job with work T1 and critical-path length T∞ on a machine with P processors. Let ρ denote A-STEAL's responsiveness parameter, δ its utilization parameter, and L the quantum length. For any constant 0 &lt; &lt; 1, A-STEAL completes the job in time T = O T1/ P + T∞ + L log ρ P + L ln(1/ ) , with probability at least 1 -, where P is the O(T∞ + L log ρ P + L ln(1/ ))-trimmed availability. This bound implies that A-STEAL achieves linear speedup on all the time steps excluding O(T∞ + L log ρ P + L ln(1/ )) time steps with the highest processor availability.</p><p>We make two assumptions to simply the presentation of the analysis. First, we assume that there is no contention for steals and that a steal can be completed on a single time step. Second, we assume that a mug can be completed on one time step as well. That is, if there is a muggable queue, then a thief processor can find it instantly and mug it. If there is no muggable queue, then a thief processor knows instantly that there is no muggable queue and it should start stealing. We shall relax these assumptions at the end of this section.</p><p>We prove our completion-time bound using a trim analysis, which calculates the performance by discarding a few outliers and measures that for the remaining majority. We label each quantum as either accounted or deductible. Accounted quanta are those for which nq ≥ Lδpq, where nq is the nonsteal usage. That is, the job works or mugs for at least a δ fraction of the Lpq processor cycles available during the quantum. Conversely, the deductible quanta are those for which nq &lt; Lδpq. Our trim analysis will show that when we ignore the relatively few deductible quanta, we obtain linear speedup on the more numerous accounted quanta.</p><p>We can relate this labeling of quanta as accounted versus deductible to a three-way classification of quanta as inefficient, efficient-and-satisfied, and efficient-and-deprived:</p><p>• Inefficient: On an inefficient quantum q, we have nq &lt; Lδaq ≤ Lδpq, since the allotment aq never exceeds the availability pq. We label all inefficient quanta as deductible, irrespective of whether they are satisfied or deprived. • Efficient-and-satisfied: On an efficient quantum q, we have nq ≥ Lδaq. Since we have aq = min {pq, dq} for a satisfied quantum, it follows that aq = dq ≤ pq. Despite these two bounds, we may nevertheless have nq &lt; Lδpq.</p><p>Since we cannot guarantee that nq ≥ Lδpq, we pessimistically label the quantum q as deductible.</p><p>• Efficient-and-deprived: As before, on an efficient quantum q, we have nq ≥ Lδaq. On a deprived quantum, we have aq &lt; dq by definition. Since aq = min {pq, dq}, we must have aq = pq. Hence, it follows that nq ≥ Lδaq = Lδpq, and we label quantum q as accounted.</p><p>We now analyze the execution time of A-STEAL by bounding the number of deductible and accounted quanta separately. Two observations provide intuition for the proof. First, each inefficient quantum contains a large number of steal-cycles, which we can expect to reduce the length of the remaining critical path. This observation will help us to bound the number of deductible quanta. Second, most of the processor cycles on an efficient quantum are spent either working or mugging. We shall show that there cannot be too many mug-cycles during the job's execution, and thus most of the processor cycles on efficient quanta are spent doing useful work. This observation will help us to bound the number of accounted quanta.</p><p>The following lemma, proved in <ref type="bibr" target="#b12">[13]</ref>, shows how stealcycles reduce the length of the job's critical path. LEMMA 1. If a job has r ready queues, then 3r steal-cycles suffice to reduce the length of the job's remaining critical path by at least 1 with probability at least 1 -1/e, where e is the base of the natural logarithm.</p><p>The next lemma shows that an inefficient quantum reduces the length of the job's critical path, which we shall later use to bound the total number of inefficient quanta. LEMMA 2. If ρ is A-STEAL's responsiveness parameter and L is the quantum length, on an inefficient quantum, A-STEAL reduces the length of a job's remaining critical path by at least (1 -δ)L/6 with probability greater than 1/4.</p><p>Proof. Let q be an inefficient quantum. A processor with an empty ready queue steals only when it cannot mug a queue, and hence, all the steal-cycles on quantum q occur when the number of nonempty queues is at most the allotment aq. Therefore, Lemma 1 dictates that 3aq steal-cycles suffice to reduce the critical-path length by 1 with probability at least 1 -1/e. Since the quantum q is inefficient, it contains at least (1 -δ)Laq steal-cycles. Divide the time steps of the quantum into rounds such that each round contains 3aq steal-cycles. Thus, there are at least j = (1 -δ)Laq/3aq = (1 -δ)L/3 rounds. <ref type="foot" target="#foot_3">2</ref> We call a round good if it reduces the length of the critical path by at least 1; otherwise, the round is bad. For each round i on quantum q, we define the indicator random variable Xi to be 1 if round i is a bad round and 0 otherwise, and let X = j i=1 Xi. Since Pr {Xi = 1} &lt; 1/e, linearity of expectation dictates that E [X] &lt; j/e. We now apply Markov's inequality <ref type="bibr">[22, p. 1111</ref>], which says that for a nonnegative random variable, we have Pr {X ≥ t} ≤ E [X] /t for all t &gt; 0. Substituting t = j/2, we obtain Pr {X &gt; j/2} ≤ E [X] /(j/2) ≤ (j/e)/(j/2) = 2/e &lt; 3/4. Thus, with probability greater than 1/4, the quantum q contains at least j/2 good rounds. Since each good round reduces the criticalpath length by at least 1, with probability greater than 1/4, the critical-path length reduces by least j/2 = ((1 -δ)L/3)/2 = (1 -δ)L/6 during quantum q. LEMMA 3. Suppose that A-STEAL schedules a job with critical-path length T∞. If L is the quantum length, then for any &gt; 0, the schedule produces at most 48T∞/(L(1 -δ)) + 16 ln(1/ ) inefficient quanta with probability at least 1 -.</p><p>Proof. Let I be the set of inefficient quanta. Define an inefficient quantum q as productive if it reduces the criticalpath length by at least (1 -δ)L/6 and unproductive otherwise. For each quantum q ∈ I, define the indicator random variable Yq to be 1 if q is productive and 0 otherwise. By </p><formula xml:id="formula_1">Pr {Y &lt; A} = Pr Y &lt; 1 - A + 4 ln(1/ ) 2A + 4 ln(1/ ) (2A + 4 ln(1/ )) = Pr {Y &lt; (1 -λ) (2A + 4 ln(1/ ))} ≤ exp - λ 2 2 (2A + 4 ln(1/ )) = exp - 1 2 • (A + 4 ln(1/ )) 2 2A + 4 ln(1/ ) &lt; exp - 1 2 • 4 ln(1/ ) • 1 2 = .</formula><p>Therefore, if the number |I| of inefficient quanta is at least 48T∞/(1-δ)L+16 ln(1/ ), the number of productive quanta is at least A = 6T∞/(1 -δ)L with probability at least 1 -. By Lemma 2 each productive quantum reduces the criticalpath length by at least (1 -δ)L/6, and therefore at most A = 6T∞/(1-δ)L productive quanta occur during job's execution. Consequently, with probability at least 1 -, the number of inefficient quanta is |I| ≤ 48T∞/(1 -δ)L + 16 ln(1/ ).</p><p>The following technical lemma proved in <ref type="bibr" target="#b1">[2]</ref> bounds the maximum value of the desire. LEMMA 4. Suppose that A-STEAL schedules a job on a machine with P processors. If ρ is A-STEAL's responsiveness parameter, then before any quantum q, the desire dq of the job is bounded by dq &lt; ρP .</p><p>The next lemma reveals a relationship between inefficient quanta and efficient-and-satisfied quanta. LEMMA 5. Suppose that A-STEAL schedules a job on a machine with P processors. If ρ is A-STEAL's responsiveness parameter and the schedule produces m inefficient quanta, then it produces at most m+log ρ P +1 efficient-and-satisfied quanta.</p><p>Proof. Assume for the purpose of contradiction that a job's execution has m inefficient quanta, but k &gt; m + log ρ P + 1 efficient-and-satisfied quanta. Recall that desire increases by ρ after every efficient-and-satisfied quantum, decreases by ρ after every inefficient quantum, and does not change otherwise. Thus, the total increase in desire is ρ k , and the total decrease in desire is ρ m . Since the desire starts at 1, the desire at the end of the job is ρ k-m &gt; ρ log ρ P +1 = ρP , contradicting Lemma 4.</p><p>The following lemma bounds the number of efficient-andsatisfied quanta. LEMMA 6. Suppose that A-STEAL schedules a job with critical-path length T∞ on a machine with P processors. If ρ is A-STEAL's responsiveness parameter, δ is its utilization parameter, and L is the quantum length, then the schedule produces at most 48T∞/(1 -δ)L + log ρ P + 16 ln(1/ ) + 1 efficient-and-satisfied quanta with probability at least 1for any &gt; 0.</p><p>Proof. The lemma follows directly from Lemmas 3 and 5.</p><p>The next lemma exhibits the relationship between inefficient quanta and efficient-and-satisfied quanta. LEMMA 7. Suppose that A-STEAL schedules a job, and let I and C denote the sets of inefficient and efficient-and-satisfied quanta, respectively, produced by the schedule. If ρ is A-STEAL's responsiveness parameter, then there exists an injective mapping f : I → C such that for all q ∈ I, we have f (q) &lt; q and d f (q) = dq/ρ.</p><p>Proof. For every inefficient quantum q ∈ I, define r = f (q) to be the latest efficient-and-satisfied quantum such that r &lt; q and dr = dq/ρ. Such a quantum always exists, because the initial desire is 1 and the desire increases only after an efficient-and-satisfied quantum. We must prove that f does not map two inefficient quanta to the same efficient-and-satisfied quantum. Assume for the sake of contradiction that there exist two inefficient quanta q &lt; q such that f (q) = f (q ) = r. By definition of f , the quantum r is efficient-and-satisfied, r &lt; q &lt; q , and dq = d q = ρdr. After the inefficient quantum q, A-STEAL reduces the desire to dq/ρ. Since the desire later increases again to d q = dq and the desire increases only after efficient-and-satisfied quanta, there must be an efficientand-satisfied quantum r in the range q &lt; r &lt; q such that d(r ) = d(q )/ρ. But then, by the definition of f , we would have f (q ) = r . Contradiction.</p><p>We can now bound the total number of mug-cycles executed by processors. LEMMA 8. Suppose that A-STEAL schedules a job with work T1 on a machine with P processors. If ρ is A-STEAL's responsiveness parameter, δ is its utilization parameter, and L is the quantum length, the schedule produces at most ((1+ρ)/(Lδ -1 -ρ))T1 mug-cycles.</p><p>Proof. When the allotment decreases, some processors are deallocated, and their ready queues are declared muggable. The total number M of mug-cycles is at most the number of muggable queues during the job's execution. Since the allotment reduces by at most aq -1 from quantum q to quantum q + 1, there are M ≤ q (aq -1) &lt; q aq mug-cycles during the execution of the job. By Lemma 7, for each inefficient quantum q, there is a distinct corresponding efficient-and-satisfied quantum r = f (q) that satisfies dq = ρdr. By definition, each efficient-andsatisfied quantum r has a nonsteal usage nr ≥ Lδar and allotment ar = dr. Thus, we have nr + nq ≥ Lδar = (Lδ/(1 + ρ))(ar + ρar) = (Lδ/(1 + ρ))(ar + ρdr) ≥ (Lδ/(1 + ρ))(ar + aq), since aq ≤ dq and dq = ρdr. Except for these inefficient quanta and their corresponding efficientand-satisfied quanta, every other quantum q is efficient, and hence nq ≥ Lδaq for these quanta. Let N = q nq be the total number of nonsteal-cycles during the job's execution. We have N = q nq ≥ (Lδ/(1+ρ)) q aq ≥ (Lδ/(1+ρ))M . Since the total number of nonsteal-cycles is the sum of workcycles and mug-cycles and the total number of work-cycles is T1, we have N = T1 + M , and hence,</p><formula xml:id="formula_2">T1 = N -M ≥ (Lδ/(1 + ρ))M -M = ((Lδ -1 -ρ)/(1 + ρ))M , which yields M ≤ ((1 + ρ)/(Lδ -1 -ρ))T1.</formula><p>LEMMA 9. Suppose that A-STEAL schedules a job with work T1 on a machine with P processors. If ρ is A-STEAL's responsiveness parameter, δ is its utilization parameter, and L is the quantum length, the schedule produces at most (T1/(LδPA))(1 + (1 + ρ)/(Lδ -1 -ρ)) accounted quanta, where PA is the mean availability on the accounted quanta.</p><p>Proof. Let A and D denote the set of accounted and deductible quanta, respectively. The mean availability on accounted quanta is PA = (1/ |A|) q∈A pq. Let N be the total number of nonsteal-cycles. By definition of accounted quanta, the nonsteal usage satisfies nq ≥ Lδaq. Thus, we have N = q∈A∪D nq ≥ q∈A nq ≥ q∈A δLpq = δL |A| PA, and hence, we obtain |A| ≤ N/LδPA .</p><p>(1)</p><p>But, the total number of nonsteal-cycles is the sum of the number of work-cycles and mug-cycles. Since there are at most T1 work-cycles on accounted quanta and Lemma 8 shows that there are at most M ≤ ((1 + ρ)/(Lδ -1 -ρ))T1 mug-cycles, we have</p><formula xml:id="formula_3">N ≤ T1 + M ≤ T1(1 + (1 + ρ)/(Lδ -1 -ρ)).</formula><p>Substituting this bound on N into Inequality (1) completes the proof.</p><p>We are now ready to bound the running time of jobs scheduled with A-STEAL. THEOREM 10. Suppose that A-STEAL schedules a job with work T1 and critical-path length T∞ on a machine with P processors. If ρ is A-STEAL's responsiveness parameter, δ is its utilization parameter, and L is the quantum length, then for any &gt; 0, with probability at least 1 -, A-STEAL completes the job in Proof. Straightforward conversion of high-probability bound to expectation, together with setting δ and ρ to suitable constants.</p><formula xml:id="formula_4">T ≤ T1 δ P 1 + 1 + ρ Lδ -1 -ρ + O T∞ 1 -δ + L log ρ P + L ln(1/ )<label>(2</label></formula><p>Our analysis made two assumptions to ease the presentation. First, we assumed that there is no contention for steals. Second, we assumed that a thief processor can find a muggable queue and mug it in unit time. Now, let us relax these assumptions.</p><p>The first issue dealing with the contention on steals has been addressed by Blumofe and Leiserson in <ref type="bibr" target="#b12">[13]</ref>. A balls-andbins argument can be used to prove that taking the contention of steals into account would increase the running time by at most O(lg P ), which is tiny compared to the other terms in our running time.</p><p>Mugging requires more data-structure support. When a processor runs out of work, it needs to find out if there are any muggable queues for the job. As a practical matter, these muggable queues can be placed in a set (using any synchronous queue or set implementations as in <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b55">56]</ref>). This strategy could increase the number of mug-cycles by a factor of P in the worse case. If P L, however, this change does not affect the running time bound by much. Moreover, in practice, the number of muggings is so small that the time spent on muggings is insignificant compared to the total running time of the job. Alternatively, to obtain a better theoretical bound, we could use a counting network <ref type="bibr" target="#b4">[5]</ref> with width P to implement the list of muggable queues, in which case each mugging operation would consume O(lg 2 P ) processor cycles. The number of accounted steps in the time bound from Lemma 9 would increase slightly to (T1/δ P ) 1 + (1 + ρ) lg 2 P/(Lδ -1 -ρ) , but the number of deductible steps would not change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Waste analysis</head><p>This section proves that when a job is scheduled by A-STEAL, the total number of processor cycles wasted during the job's execution is W = O(T1) in the worst case. THEOREM 12. Suppose that A-STEAL schedules a job with work T1 on a machine with P processors. If ρ is A-STEAL's responsiveness parameter, δ is its utilization parameter, and L is the quantum length, then A-STEAL wastes at most</p><formula xml:id="formula_5">W ≤ 1 + ρ -δ δ + (1 + ρ) 2 δ(Lδ -1 -ρ) T1<label>(3)</label></formula><p>processor cycles during the course of the computation.</p><p>Proof. Let M be the total number of mug-cycles, and let S be the total number of steal-cycles. Hence, we have W = S + M . Since Lemma 8 provides an upper bound of M , we only need to bound S. We use an accounting argument to calculate S based on whether a quanta is inefficient or efficient. Let S ineff and S eff , where S = S ineff + S eff , be the numbers of steal-cycles on inefficient and efficient quanta, respectively. Inefficient quanta: Lemma 7 shows that every inefficient quantum q with desire dq corresponds to a distinct efficientand-satisfied quantum r = f (q) with desire dr = dq/ρ. Thus, the steal-cycles on quantum q can be amortized against the nonsteal-cycles on quantum r. Since quantum r is efficientand-satisfied, its nonsteal usage satisfies nr ≥ Lδaq/ρ, and its allocation is ar = dr. Therefore, we have nr ≥ Lδar = Lδdr = Lδdq/ρ ≥ Lδaq/ρ. Let sq be the number of stealcycles on quantum q. Since the quantum contains at most Laq total processor cycles, we have sq ≤ Laq ≤ ρnr/δ, that is, the number of steal-cycles in the inefficient quantum q is at most a ρ/δ fraction of the nonsteal-cycles in its corresponding efficient-and-satisfied quantum r. Therefore, the total number of steal-cycles in all inefficient quanta satisfies S ineff ≤ (ρ/δ)(T1 + M ).</p><p>Efficient quanta: On any efficient quantum q, the job performs at least Lδaq work-and mug-cycles and at most L(1 -δ)aq steal-cycles. Summing over all efficient quanta, the number of steal-cycles on efficient quanta is S eff ≤ ((1 -δ)/δ)(T1 + M ).</p><p>Using the bound M ≤ ((1 + ρ)/(Lδ -1 -ρ))T1 from Lemma 8, we obtain</p><formula xml:id="formula_6">W = S + M = S ineff + S eff + M ≤ (ρ/δ)(T1 + M ) + ((1 -δ)/δ)(T1 + M ) + M = (T1 + M ) 1 + ρ -δ δ + M ≤ T1 + T1 1 + ρ Lδ -1 -ρ 1 + ρ -δ δ + T1 1 + ρ Lδ -1 -ρ = T1 1 + 1 + ρ Lδ -1 -ρ 1 + ρ -δ δ + 1 + ρ Lδ -1 -ρ = T1 1 + ρ -δ δ + (1 + ρ) 2 δ(Lδ -1 -ρ) ,</formula><p>which proves the theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Interpretation of the bounds</head><p>In this section, we simplify the bounds on A-STEAL's behavior to understand the tradeoffs involved in completion time and waste due to parameter settings. Although our bounds are good asymptotically, they contain large constants. Some might wonder whether these large constants might adversely affect A-STEAL's practical utility. We argue that most of the large constants are due to the assumption of the adversarial behavior of the job scheduler, and thus, we should expect the practical performance of A-STEAL to be better than that indicated by our bounds. Moreover, we have implemented A-STEAL in a simulation environment <ref type="bibr" target="#b2">[3]</ref> using the DESMO-J <ref type="bibr" target="#b23">[24]</ref> Java simulator, which provides strong evidence that A-STEAL should be efficient in practice.</p><p>If the utilization parameter δ and responsiveness parameter ρ are constants, the bounds in Inequalities ( <ref type="formula" target="#formula_4">2</ref>) and ( <ref type="formula" target="#formula_5">3</ref>) can be simplified as follows:</p><formula xml:id="formula_7">T ≤ T1 δ P (1 + O(1/L)) + O T∞ 1 -δ + L log ρ P + L ln(1/ ) ,<label>(4)</label></formula><formula xml:id="formula_8">W ≤ 1 + ρ -δ δ + O(1/L) T1 .<label>(5)</label></formula><p>This reformulation allows us to see the trade-offs due to the setting of the δ and ρ parameters more easily. As δ increases and ρ decreases, the completion time increases and the waste decreases. Thus, reasonable values for the utilization parameter δ might lie between 80% and 95%, and the responsiveness parameter ρ might be set between 1.2 and 2.0. The quantum length L is a system configuration parameter, which might have values in the range 10 3 to 10 5 . For the time bound in Inequality (4), as δ increases toward 1, the coefficient of T1/ P decreases toward 1, and the job comes closer to perfect linear speedup on accounted steps, but the number of deductible steps increases as well. The large number of deductible steps is due to the adversarial job scheduler. We have performed simulations <ref type="bibr" target="#b2">[3]</ref> which indicate that the jobs usually achieve nearly perfect linear speedup with respect to P for a variety of availability profiles.</p><p>To see how these settings affect the waste bound, consider the waste bound in Inequality (5) as two parts, where the waste due to steal-cycles is S ≤ (1 + ρ -δ)T1/δ, and the waste due to mug-cycles is only M = O(1/L)T1. Since the waste on mug-cycles is just a tiny fraction compared to the work T1, an implementation of A-STEAL need not overly concern itself with the bookkeeping overhead of adding and removing processors from jobs.</p><p>The major part of waste comes from steal-cycles, where S is generally less than 2T1 for typical parameter values. The analysis of Theorem 12 shows that the number of steal-cycles on efficient steps is bounded by ((1-δ)/δ)T1, which is a small fraction of S. Thus, most of the waste that occurs in the bound can be attributed to the steal-cycles on the inefficient quanta. To ensure the robustness of A-STEAL, our analysis assumes that the job scheduler is an adversary, which creates as many inefficient quanta as possible. Since job schedulers are generally not adversarial, we should not expect these large overheads to materialize in practice. The simulations in <ref type="bibr" target="#b2">[3]</ref> indicate that the waste is a much smaller fraction of T1 than that suggested by our theoretical bound. In those experiments, A-STEAL typically wastes less than 20% of the allotted processor cycles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related work</head><p>This section discusses related work on adaptive and nonadaptive schedulers for multithreaded jobs. Prior work on thread scheduling for multithreaded jobs has tended to focus on nonadaptive scheduling <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b43">44]</ref> or adaptive scheduling without parallelism feedback <ref type="bibr" target="#b3">[4]</ref>. We start by discussing nonadaptive work-stealing schedulers. We then discuss empirical and theoretical work on adaptive thread schedulers. Finally, we give a brief summary of research on adaptive job schedulers.</p><p>Work-stealing has been used as a heuristic since Burton and Sleep's research <ref type="bibr" target="#b19">[20]</ref> and Halstead's implementation of Multilisp <ref type="bibr" target="#b35">[36]</ref>. Many variants have been implemented since then <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41]</ref>, and it has been analyzed in the context of load balancing <ref type="bibr" target="#b47">[48]</ref>, backtrack search <ref type="bibr" target="#b38">[39]</ref> etc. Blumofe and Leiserson <ref type="bibr" target="#b12">[13]</ref> proved that the work-stealing algorithm is efficient with respect to time, space, and communication for the class of "fully strict" multithreaded computations. Arora, Blumofe and Plaxton <ref type="bibr" target="#b3">[4]</ref> extended the time bound result to arbitrary multithreaded computations. In addition, Acar, Blelloch and Blumofe <ref type="bibr" target="#b0">[1]</ref> show that work-stealing schedulers are efficient with respect to cache misses for jobs with "nested parallelism." Moreover, variants of work-stealing algorithms have been implemented in many systems <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b30">31]</ref> and empirical studies show that work-stealing schedulers are scalable and practical <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>Adaptive thread scheduling without parallelism feedback has been studied in the context of multithreading, primarily by Blumofe and his coauthors <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18]</ref>. In this work, the thread scheduler uses randomized work-stealing strategy to schedule threads on available processors but does not provide the feedback about the job's parallelism to the job scheduler. The research in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18]</ref> addresses networks of workstations where processors may fail or join and leave a computation while the job is running, showing that work-stealing provides a good foundation for adaptive task scheduling. In theoretical work, Arora, Blumofe, and Plaxton <ref type="bibr" target="#b3">[4]</ref> show that their task scheduler (we call it the ABP scheduler) provably completes a job in O(T1/P + P T∞/P ) expected time. Blumofe and Papadopoulos <ref type="bibr" target="#b15">[16]</ref> perform an empirical evaluation of ABP and show that on an 8-processor machine, ABP provides almost perfect linear speedup for jobs with reasonable parallelism.</p><p>Adaptive task scheduling with parallelism feedback has also been studied empirically in <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref>. These researchers use a job's history of processor utilization to provide feedback to dynamic-equipartitioning job schedulers. Their studies use different strategies for parallelism feedback, and all report better system performance with parallelism feedback than without, but it is not apparent which of their strategies is best. Our earlier work <ref type="bibr" target="#b1">[2]</ref> appears to be the only theoretical analysis of a task scheduler with parallelism feedback.</p><p>In contrast to adaptive thread schedulers, adaptive job schedulers have been studied extensively, both empirically <ref type="bibr">[21, 25, 32, 40, 45-47, 51, 57]</ref> and theoretically <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42]</ref>. McCann, Vaswani, and Zahorjan <ref type="bibr" target="#b39">[40]</ref> studied many different job schedulers and evaluated them on a set of benchmarks. They also introduced the notion of dynamic equipartitioning, which gives each job a fair allotment of processors, while allowing processors that cannot be used by a job to be reallocated to other jobs. Gu <ref type="bibr" target="#b33">[34]</ref> proved that dynamic equipartitioning with instantaneous parallelism feedback is 4competitive with respect to makespan for batched jobs with multiple phases, where the parallelism of the job remains constant during the phase and the phases are relatively long compared with the length of a scheduling quantum. Deng and Dymond <ref type="bibr" target="#b22">[23]</ref> proved a similar result for mean response time for multiphase jobs regardless of their arrival times. He, Hsu and Leiserson <ref type="bibr" target="#b36">[37]</ref> recently proved that two-level schedulers which combine A-STEAL (or A-GREEDY) with dynamic equipartitioning are constant competitive with respect to makespan (for arbitrary job arrivals) and mean completion time (for batched arrivals). Song <ref type="bibr" target="#b53">[54]</ref> proves that a randomized distributed strategy can implement dynamic equipartitioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>This section offers some conclusions and directions for future work.</p><p>This and previous research <ref type="bibr" target="#b1">[2]</ref> has used the technique of trimming to limit a powerful adversary, enabling us to analyze adaptive schedulers with parallelism feedback. The idea of ignoring a few outliers while calculating averages is often used in statistics to ignore anomalous data points. For example, teachers often ignore the lowest score while computing a student's grade, and in the Olympic Games, the lowest and the highest scores are sometimes ignored when computing an athlete's average. In theoretical computer science, when an adversary is too powerful, we sometimes make statistical assumptions about the input to render the analysis tractable, but statistical assumptions may not be valid in practice. Trimming may prove itself of value for analyzing such problems.</p><p>A-STEAL needs full information about the previous quantum to estimate the desire of the current quantum. Collecting perfect information might become difficult as the number of processors becomes larger, especially if the number of processors exceeds the quantum length. A-STEAL only estimates the desire, however, and therefore approximate information should be enough to provide feedback. We are currently studying the possibility of using sampling techniques to estimate the number of steal-cycles, instead of counting the exact number.</p><p>Our model for jobs and scheduling takes only computation into account and has no performance model for handling input and output operations. But there is a large class of parallel applications which perform a large number of input/output operations. It is unclear how the thread scheduler should respond when a thread is performing I/O even in the case of nonadaptive work-stealing schedulers and the effect of I/O on all kinds of thread schedulers in theory and in practice is an interesting open question.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Lemma 2 ,</head><label>2</label><figDesc>we have Pr {Yq = 1} &gt; 1/4. Let the total number of unproductive quanta be Y = q∈I Yq. For simplicity in notation, let A = 6T∞/(1 -δ)L. If the job's execution contains |I| ≥ 48T∞/(1 -δ)L + 16 ln(1/ ) inefficient quanta, then we have E [Y ] &gt; |I| /4 ≥ 12T∞/(1δ)L + 4 ln(1/ ) = 2A + 4 ln(1/ ). Using the Chernoff bound Pr {Y &lt; (1 -λ)E[Y ]} &lt; exp(-λ 2 E[Y ]/2) [43, p. 70] and choosing λ = (A + 4 ln(1/ )) / (2A + 4 ln(1/ )), we obtain</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>)</head><label></label><figDesc>time steps, where P is the O(T∞/(1 -δ) + L log ρ P + L ln(1/ ))-trimmed availability.Proof. The proof uses trim analysis. Let A be the set of accounted quanta, and let D be the set of deductible quanta. Lemmas 3 and 6 show that there are |D| = O(T∞/((1 -δ)L) + log ρ P + ln(1/ )) deductible quanta, and hence L |D| = O(T∞/(1 -δ) + L log ρ P + L ln(1/ )) time steps belong to deductible quanta. We have that PA ≥ P , since the mean availability on the accounted time steps (we trim the L |D| deductible steps) must be at least the O(T∞/(1-δ)+L log ρ P + L ln(1/ ))-trimmed availability (we trim the O(T∞/(1-δ)+ L log ρ P + L ln(1/ )) steps that have the highest availability). From Lemma 9, the number of accounted quanta is at most (T1/(LδPA))(1 + (1 + ρ)/(Lδ -1 -ρ)), and since T = L(|A| + |D|), the desired time bound follows. COROLLARY 11. Suppose that A-STEAL schedules a job with work T1 and critical-path length T∞ on a machine with P processors. If ρ is A-STEAL's responsiveness parameter, δ is its utilization parameter, and L is the quantum length, then A-STEAL completes the job in expected time E [T ] = O(T1/ P + T∞ + L lg P ), where P is the O(T∞ + L lg P )-trimmed availability.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Using mean processor allotment instead of mean availability does not provide useful results. The trivial thread scheduler that always requests (and receives) 1 processor can achieve perfect linear speedup with respect to its mean allotment (which is 1) while wasting no processor cycles. By using a measure of availability, the thread scheduler must attempt to exploit parallelism.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>2006/10/3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>2006/10/3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>Actually, the number of rounds is j = (1 -δ)L/3 , but we shall ignore the roundoff for simplicity. A more detailed analysis can nevertheless produce the same constants in the bounds for Lemmas</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>and 6.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>2006/10/3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_6"><p>2006/10/3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_7"><p>2006/10/3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_8"><p>2006/10/3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_9"><p>2006/10/3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_10"><p>2006/10/3</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Thanks to the members of the Supercomputing Technologies group at MIT CSAIL and to Wen Jing Hsu of the Nanyang Technological Institute in Singapore for numerous helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The data locality of work stealing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Umut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><surname>Blumofe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive task scheduling with parallelism feedback</title>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><forename type="middle">Jing</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PPoPP</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An empirical evaluation of work stealing with parallelism feedback</title>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><forename type="middle">Jing</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDCS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Thread scheduling for multiprogrammed multiprocessors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nimar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><surname>Greg Plaxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<meeting><address><addrLine>Puerto Vallarta, Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="119" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Counting networks</title>
		<author>
			<persName><forename type="first">James</forename><surname>Aspnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurice</forename><surname>Herlihy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Shavit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1020" to="1048" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Non-clairvoyant scheduling for minimizing mean slowdown</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kedar</forename><surname>Dhamdhere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jochen</forename><surname>Konemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amitabh</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="318" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Provably efficient scheduling for languages with fine-grained parallelism</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="321" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Provably efficient scheduling for languages with fine-grained parallelism</title>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<meeting><address><addrLine>Santa Barbara, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A provable time and space efficient implementation of NESL</title>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICFP</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="213" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Executing Multithreaded Programs Efficiently</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cilk: An efficient multithreaded runtime system</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">F</forename><surname>Joerg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><forename type="middle">C</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">H</forename><surname>Randall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuli</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</title>
		<meeting>the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming<address><addrLine>Santa Barbara, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-07">July 1995</date>
			<biblScope unit="page" from="207" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Space-efficient scheduling of multithreaded computations</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="202" to="229" />
			<date type="published" when="1998-02">February 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scheduling multithreaded computations by work stealing</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="720" to="748" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Automatic processor allocation for work-stealing jobs</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adaptive and reliable parallel computing on networks of workstations</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">A</forename><surname>Lisiecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX</title>
		<meeting><address><addrLine>Anaheim, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="133" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The performance of work stealing in multiprogrammed environments</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dionisios</forename><surname>Papadopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="266" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Hood: A userlevel threads library for multiprogrammed multiprocessors</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dionisios</forename><surname>Papadopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scheduling large-scale parallel computations on networks of workstations</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPDC</title>
		<meeting><address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="96" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The parallel evaluation of general arithmetic expressions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Brent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="page" from="201" to="206" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Executing functional programs on a virtual tree of processors</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Warren</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Ronan</forename><surname>Sleep</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPCA</title>
		<meeting><address><addrLine>Portsmouth, New Hampshire</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981-10">October 1981</date>
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic vs. static quantum-based parallel processor allocation</title>
		<author>
			<persName><forename type="first">Su-Hui</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">K</forename><surname>Vernon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JSSPP</title>
		<imprint>
			<biblScope unit="page" from="200" to="223" />
			<date type="published" when="1996">1996</date>
			<pubPlace>Honolulu, Hawaii, United States</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Introduction to Algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">L</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clifford</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>The MIT Press and McGraw-Hill</publisher>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On multiprocessor system scheduling</title>
		<author>
			<persName><forename type="first">Xiaotie</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Dymond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="82" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A framework for discrete-event modelling and simulation</title>
		<author>
			<persName><surname>Desmo-J</surname></persName>
		</author>
		<ptr target="http://asi-www.informatik.uni-hamburg.de/desmoj/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Speedup versus efficiency in parallel systems</title>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">L</forename><surname>Eager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Zahorjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">D</forename><surname>Lozowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="408" to="423" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scheduling in the dark</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Edmonds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Non-clairvoyant multiprocessor scheduling of jobs with changing execution characteristics</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Edmonds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">D</forename><surname>Chinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Brecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotie</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Scheduling</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="250" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamic processor self-scheduling for general parallel nested loops</title>
		<author>
			<persName><forename type="first">Zhixi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pen-Chung</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan-Qi</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="919" to="929" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Job scheduling in multiprogrammed parallel systems (extended version)</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName><surname>Feitelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IBM Research Report RC 19790 (87657) 2nd Revision</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">DIB-A distributed implementation of backtracking</title>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Udi</forename><surname>Manber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOPLAS</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="1987-04">April 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The implementation of the Cilk-5 multithreaded language</title>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">H</forename><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="212" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The processor working set and its use in scheduling multiprocessor systems</title>
		<author>
			<persName><forename type="first">Dipak</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Serazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satish</forename><forename type="middle">K</forename><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="443" to="453" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bounds on multiprocessing anomalies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="416" to="429" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Competitive analysis of dynamic processor allocation strategies</title>
		<author>
			<persName><forename type="first">Nian</forename><surname>Gu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>York University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MIMD-style parallel programming with continuation-passing threads</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Halbherr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuli</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">F</forename><surname>Joerg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Massive Parallelism: Hardware, Software, and Applications</title>
		<meeting>the International Workshop on Massive Parallelism: Hardware, Software, and Applications<address><addrLine>Capri, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-09">September 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Implementation of Multilisp: Lisp on a multiprocessor</title>
		<author>
			<persName><forename type="first">H</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Halstead</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LFP</title>
		<imprint>
			<biblScope unit="page" from="9" to="17" />
			<date type="published" when="1984-08">August 1984</date>
			<pubPlace>Austin, Texas</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Provably efficient two-level adaptive scheduling for multithreaded jobs on parallel computers</title>
		<author>
			<persName><forename type="first">Yuxiong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JSSPP</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Low-overhead scheduling of nested parallelism</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schonberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="743" to="765" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A randomized parallel branch-and-bound procedure</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<meeting><address><addrLine>Chicago, Illinois</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-05">May 1988</date>
			<biblScope unit="page" from="290" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors</title>
		<author>
			<persName><forename type="first">Cathy</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raj</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Zahorjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="146" to="178" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Lazy task creation: A technique for increasing the granularity of parallel programs</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Mohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Kranz</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Halstead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LFP</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="185" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Nonclairvoyant scheduling</title>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Torng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="422" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Randomized Algorithms</title>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prabhakar</forename><surname>Raghavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>1 edition</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Space-efficient scheduling of nested parallelism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Girija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">E</forename><surname>Narlikar</surname></persName>
		</author>
		<author>
			<persName><surname>Blelloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="138" to="173" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Maximizing speedup through self-tuning of processor allocation</title>
		<author>
			<persName><forename type="first">Thu</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raj</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Zahorjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPPS</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="463" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Using runtime measured workload characteristics in parallel processor scheduling</title>
		<author>
			<persName><forename type="first">Thu</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raj</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Zahorjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JSSPP</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Dror</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Larry</forename><surname>Feitelson</surname></persName>
		</editor>
		<editor>
			<persName><surname>Rudolph</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="155" to="174" />
			<date type="published" when="1996">1996</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multiprocessor scheduling for high-variability service time distributions</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">C</forename><surname>Sevcik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPPS</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="127" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A simple load balancing scheme for task allocation in parallel machines</title>
		<author>
			<persName><forename type="first">Larry</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miriam</forename><surname>Slivkin-Allalouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Upfal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<meeting><address><addrLine>Hilton Head, South Carolina</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-07">July 1991</date>
			<biblScope unit="page" from="237" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Scalable synchronous queues</title>
		<author>
			<persName><forename type="first">William</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Lea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PPoPP</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Dynamic processor allocation for adaptively parallel jobs</title>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Sen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Characterizations of parallelism in applications and their use in scheduling</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Sevcik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Elimination trees and the construction of pools and stacks: preliminary version</title>
		<author>
			<persName><forename type="first">Nir</forename><surname>Shavit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Touitou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Diffracting trees</title>
		<author>
			<persName><forename type="first">Nir</forename><surname>Shavit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asaph</forename><surname>Zemach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions of Computer Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="385" to="428" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Scheduling adaptively parallel jobs. Master&apos;s thesis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Using parallel program characteristics in dynamic processor allocation policies</title>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">B</forename><surname>Kaushik Guha</surname></persName>
		</author>
		<author>
			<persName><surname>Brecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Performance Evaluation</title>
		<imprint>
			<biblScope unit="page" from="519" to="539" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The counting pyramid: an adaptive distributed counting scheme</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Wattenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Widmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="449" to="460" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Implementing a dynamic processor allocation policy for multiprogrammed parallel applications in the Solaris TM operating system</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lilja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency and Computation-Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="449" to="464" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
