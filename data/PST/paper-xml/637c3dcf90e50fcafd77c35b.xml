<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ACIC: Admission-Controlled Instruction Cache</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-11-18">18 Nov 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yunjin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chia-Hao</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Niranjan</forename><surname>Soundararajan</surname></persName>
							<email>niranjan.k.soundararajan@intel.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Intel Labs</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ACIC: Admission-Controlled Instruction Cache</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-11-18">18 Nov 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2211.10480v1[cs.AR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The front end bottleneck in datacenter workloads has come under increased scrutiny, with the growing code footprint, involvement of numerous libraries and OS services, and the unpredictability in the instruction stream. Our examination of these workloads points to burstiness in accesses to instruction blocks, which has also been observed in data accesses <ref type="bibr" target="#b60">[61]</ref>. Such burstiness is largely due to spatial and short-duration temporal localities, that LRU fails to recognize and optimize for, when a single cache caters to both forms of locality. Instead, we incorporate a small i-Filter as in previous works <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b48">[49]</ref> to separate spatial from temporal accesses. However, a simple separation does not suffice, and we additionally need to predict whether the block will continue to have temporal locality, after the burst of spatial locality. This combination of i-Filter and temporal locality predictor constitutes our Admission-Controlled Instruction Cache (ACIC). ACIC outperforms a number of state-of-the-art pollution reduction techniques (replacement algorithms, bypassing mechanisms, victim caches), providing 1.0223 speedup on the average over a baseline LRU based conventional i-cache (bridging over half of the gap between LRU and OPT) across several datacenter workloads.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The front-end stalls in datacenter applications have come under much scrutiny in recent years. These applications have complex and deep software stacks, executing millions of instructions even for a single user query <ref type="bibr" target="#b4">[5]</ref>. The consequent unpredictability in their control flow, involvement of numerous software layers (libraries and OS) beyond the application, and the resulting large code footprint have been noted to cause higher instruction cache (referred henceforth as icache) misses compared to the more conventional scientific and desktop workloads, like SPEC <ref type="bibr" target="#b0">[1]</ref>. One can attempt to prefetch instruction blocks, and/or predict branches, based on anticipated control flow, which can help reduce i-cache misses and branch mispredictions. Another important angle for attacking this problem is by being more discretionary in what to bring and retain (replacement algorithm) within the precious and limited i-cache space. Taking the latter approach, this paper draws insights from prior work <ref type="bibr" target="#b60">[61]</ref> that proposes dead block predictors based on bursty accesses to a cache block, and finds that such bursty accesses are also widespread in datacenter workloads, due to distinct spatial and temporal localities in the instruction stream, that are often not well serviced by the conventional LRU replacement algorithm in a single i-cache. Instead, the paper adds a separate and small (16-entry) buffer, whose similar/variant forms have been ? This work was done while the author was at Intel Labs.</p><p>proposed in prior works <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b48">[49]</ref>, to meet spatial localities, and implements an admission control mechanism to determine whether the block will continue to have temporal locality to justify bringing it into the i-cache. This Admission-Controlled Instruction Cache (ACIC) delivers 1.0223 speedup on the average across 10 datacenter applications 18.14% reduction in i-cache misses), buying back 55.85% of the performance loss of the baseline LRU over the oracle-based optimal (OPT) replacement algorithm that is theoretically possible.</p><p>While one may question the motivation for reducing icache misses given that it typically results in single-digit percentage speedups, as pointed out in <ref type="bibr" target="#b81">[82]</ref>, achieving even these single-digit percentage speedups is important to provide significant performance-per-watt benefits in these workloads. Consequently, there have been numerous studies looking to reduce i-cache misses <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b49">[50]</ref>. These techniques can be categorized into: (i) prefetching mechanisms (whether purely in hardware <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b75">[76]</ref> or through profile-guided <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b45">[46]</ref> and compilation <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b64">[65]</ref> techniques); (ii) code re-layout optimizations for better instruction locality <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b66">[67]</ref>, <ref type="bibr" target="#b68">[69]</ref>, <ref type="bibr" target="#b73">[74]</ref>; and (iii) better management of i-cache space by controlling what should be brought in/replaced (e.g. GHRP <ref type="bibr" target="#b63">[64]</ref>, Ripple <ref type="bibr" target="#b46">[47]</ref>). This work falls in category (iii), and we will show that it can complement some of the recently proposed prefetching techniques of category (i) as well.</p><p>Conventionally, the L1 instruction caches (i-cache) have been considered with a relatively small (4 or 8) associativity and a LRU-based replacement algorithm within a set. To a large extent, this structure has served its purpose fairly well for the much smaller code footprints. However, with the larger footprints of datacenter workloads, it is not clear whether the traditional LRU would work as well. This has also been a reason for some of the recent efforts such as GHRP <ref type="bibr" target="#b63">[64]</ref> and Ripple <ref type="bibr" target="#b46">[47]</ref> which have tried to improve the replacement mechanism by predicting reuse distances and identifying problematic program fragments. LRU relies on the recent past to predict the future, and may not be suitable for some of the bursty scenarios that we observe in emerging datacenter applications <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b69">[70]</ref>.</p><p>In this paper, we draw insight from prior work <ref type="bibr" target="#b60">[61]</ref> which uses cache burst history, instead of cache access history, to predict dead blocks. Unsurprisingly, such bursty accesses are also common in the instruction stream of these datacenter workloads: (a) a block that is referenced, continues to experi-ence considerable spatial and short-term temporal locality, i.e. a burst. This is fairly intuitive since successive instructions of the stream would fall in the same block. There is also shortterm temporal locality due to locality in the recent branch targets, as pointed out in <ref type="bibr" target="#b20">[21]</ref>. (b) after this burst, it is not very clear whether the block is more important than another block which may already be present in the i-cache. It may happen that after this burst, the block may not be needed for a long time (its reuse distance is much longer) that it better not be brought into the i-cache to result in pollution. A single i-cache with LRU-based replacement policy, would not differentiate between the accesses within a burst and those between bursts. This is a reason why streaming buffers <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b67">[68]</ref>, separate caches for the two forms of locality <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b85">[86]</ref>, and/or cache bypassing schemes <ref type="bibr" target="#b36">[37]</ref>, have been proposed to handle the two localities differently.</p><p>Based on this observation, we add an i-Filter (whose similar forms have been proposed and studied in prior works <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b48">[49]</ref>), which is a 16-slot buffer for instruction blocks to handle the spatial and short-term temporal accesses. However, when this buffer becomes full, the victim cannot be simply evicted (then i-cache serves no purpose) or simply inserted into i-cache (which can cause pollution). Instead, we need a prediction mechanism to determine whether its reuse distance (i.e. to the next burst) is shorter than a block already in the i-cache that it will replace. If so, and only then, should we bring it into i-cache. This overall mechanism, termed Admission-Controlled Instruction Cache (ACIC), provides the necessary spatio-temporal separation to differentially meet the intra-burst and inter-burst accesses that LRU is not tuned for.</p><p>This paper makes the following contributions to reduce icache misses in datacenter workloads:</p><p>? We show that accesses to an instruction block are bursty, similar to the observation for data accesses in <ref type="bibr" target="#b60">[61]</ref>, with a large number of spatial and near-term temporal accesses, rather than spread out over the execution. ? At the same time, one cannot ignore the separation between the bursts. LRU, in such cases, presumes the block will continue to be needed soon, thus reaching a wrong decision in bringing it into i-cache. ? Further, we cannot throw away the block after its burst is done either. With several blocks being needed, we need to be very discretionary about what to retain and what to throw away from the i-cache. ? We present the design of ACIC which provisions (i) a 16-entry i-Filter to temporarily hold incoming blocks for accesses during a burst, and (ii) a prediction mechanism to determine whether its reuse distance after the burst is shorter than a contender block already in its i-cache set, and filtering it out otherwise. ? Using a number of datacenter applications we show that ACIC reduces i-cache misses by 18.14% (with a standard fetch-directed prefetcher <ref type="bibr" target="#b30">[31]</ref>). This results in a 1.0223 speedup, bridging over half of the gap between conventional LRU and OPT (which is not implementable). The hardware takes 2.67KB (around 2/3rd of some other recent proposals) space and saves 0.63% chip energy over the baseline system.</p><p>? We also show that ACIC provides better performance than other recently proposed cache replacement policies (GHRP <ref type="bibr" target="#b63">[64]</ref>, SRRIP <ref type="bibr" target="#b33">[34]</ref>, SHiP <ref type="bibr" target="#b88">[89]</ref>, Hawkeye <ref type="bibr" target="#b31">[32]</ref>/Harmony <ref type="bibr" target="#b32">[33]</ref>), cache bypassing policies (DSB <ref type="bibr" target="#b22">[23]</ref> and OBM <ref type="bibr" target="#b57">[58]</ref> which were initially proposed for d-caches), and alternate strategies such as victim caches (VVC <ref type="bibr" target="#b43">[44]</ref> which were earlier proposed for d-caches).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MOTIVATION</head><p>Need for Spatio-Temporal Separation: Inspired by prior work <ref type="bibr" target="#b60">[61]</ref> which observes bursty accesses to data blocks and proposes better cache management policies based on such burstiness, we explore similar optimizations for the instruction stream in datacenter workloads <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b69">[70]</ref>. We first study the reuse distances of instruction blocks in server workloads, previously identified to have a front-end bottleneck <ref type="foot" target="#foot_0">1</ref> . Figure <ref type="figure" target="#fig_0">1a</ref> plots the distribution of reuse distances between current and previous accesses to the same instruction block. They are histogrammed into buckets on the x-axis for interesting reuse distance ranges (0 implies spatial locality to the same block, 1-16 for very short-term temporal locality, 16-512 captures the size of an i-cache, 512-1024 for distances just out-of-reach of i-cache, and much larger reuse distances (1024-10000).</p><p>In around 85% of the cases, an instruction block continues to be re-accessed, indicating strong spatial locality (due to successive instructions lying in the same block). This is typically followed by the <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref> bucket, indicating high shortterm temporal locality. While the log-scale in y-axis does indicate a significant drop as we move beyond reuse-distances that can be captured by today's i-cache sizes (until 512), there is a non-negligible fraction (up to 6%) that falls beyond the reach of i-cache. While one would think these misses could be ignored, such misses can still amount to as much as 8.23% loss in speedup in some applications (due to the cost of servicing a miss). This is the region that this paper sets out to optimize. Incidentally, note that even an oracle-based Belady's OPT replacement algorithm <ref type="bibr" target="#b8">[9]</ref>, tries to optimize for this region.</p><p>To further illustrate the spatial locality, in Figure <ref type="figure" target="#fig_0">1b</ref>, we show the correlation between successive reuse distances as a Markov Chain in Media Streaming. Each state represents the range of reuse distances, and the transition from one to another indicates the probability of the next reuse distance from the current reuse distance. Again, the self-transitions/transitions into the smallest reuse distance states (particularly 0) dominate. This diagram indicates the "burstiness" of accesses to instruction blocks, i.e. once a block is referenced, it continues to get referenced for a while (largely due to spatial locality) as is illustrated in the diagram on top of Figure <ref type="figure" target="#fig_0">1b</ref>. After this burst, its reuse distance can become long again. When this happens, LRU-like schemes which look at the past (rather than the future), try to retain rather than evict such blocks. These two sets of results point to the need to optimize for both spatial and temporal localities of instruction blocks. Currently, both these forms of locality are fulfilled by the single i-cache. However, as has been well known <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b62">[63]</ref>, a single cache (with LRU replacement) is not well suited to meet both these forms of locality simultaneously. This is also one of the reasons why streaming buffers <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b67">[68]</ref>, separate caches for the two forms of locality <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b85">[86]</ref>, and/or cache bypassing schemes <ref type="bibr" target="#b36">[37]</ref>, have been proposed to handle the two localities differently.</p><p>It is very likely that a block has already been evicted from and misses in i-cache when it is re-accessed again after the longer reuse distance from its last burst. Our proposed spatiotemporal separation for i-cache aims to eliminate such misses if the block turns out to be useful enough to be retained in i-cache after its burst. While a prefetcher can also try to reduce such misses by predictions, we should note (and will show experimentally) that the two techniques -ACIC and prefetching -are complementary. In fact, as we will show, ACIC can reduce such misses even when a state-ofthe-art prefetcher (e.g. <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b75">[76]</ref>) falls short. This goes to show that there is headroom for replacement policies and bypassing policies beyond what prefetchers can provide to further improve i-cache performance. Need for further admission control: To provide spatiotemporal separation, we add a 16-slot fully associative buffer, called i-Filter, residing next to i-cache, similar to that in <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b48">[49]</ref>. As Figure <ref type="figure">2</ref> shows, upon a fetch, the requested address is searched concurrently in both i-Filter and i-cache. If found in either, the instruction block is sent to CPU, and is considered a hit. Otherwise, the missed block is fetched from deeper in the memory hierarchy and is then placed in i-Filter only. If i-Filter is full, the LRU block in i-Filter is evicted in order to make space. Victim blocks that are evicted from i-Filter are always inserted into i-cache for now. This i-Filter can fulfill much of the spatial locality. Only when evicted from this structure and inserted into i-cache, will it be subject more to the temporal access patterns for subsequent replacement.</p><p>We evaluate such a spatio-temporal separation using this i-Filter + i-cache design for 10 widely used datacenter applications listed in Table <ref type="table" target="#tab_2">III</ref>. The experimental setup and simulation parameters are described in Section IV. Figure <ref type="figure" target="#fig_2">3a</ref> shows the speedup comparison between this scheme and the OPT replacement policy (for i-cache). While the OPT replacement policy provides a 1.0398 speedup over the LRU baseline on average, the i-Filter+i-cache scheme provides a measely 1.0057 average speedup, i.e. the spatio-temporal separation with i-Filter is not very effective. The reason behind this gap is that some of the i-Filter victims can cause i-cache pollution, and thus should not be placed in i-cache.</p><p>This happens when the current burst of accesses for a block is done, and the next reuse distance is much larger. At this point, it is not clear whether this reuse distance is larger or smaller than the block in i-cache that it may evict in the corresponding set. If we could find out that this was larger (through oracle knowledge), we would not be inserting it into i-cache. In Figure <ref type="figure" target="#fig_2">3b</ref>, we plot the subsequent reuse distance of the block being inserted from the i-Filter into i-cache, and substract this from the reuse distance of the block that is being evicted from the corresponding i-cache set (selected using OPT). Ideally, this newly inserted block into i-cache should have its next access earlier than the next access for the victim evicted from i-cache, i.e. the percentages of x values greater than 0 should be 0. However, as we can see, nearly 40% of the time, we are making a wrong decision in moving the block from i-Filter to i-cache.</p><p>This suggests that a simple separation of spatial (using i-Filter) and temporal (using i-cache) localities with different structures will not suffice. We additionally need an admission control mechanism to determine whether the block evicted from i-Filter should replace some other block in the corresponding set of i-cache, or whether it should be thrown away, motivating our ACIC admission-controlled i-cache. We can also use Figure <ref type="figure" target="#fig_0">1a</ref> as an indicator of when such admission control would really matter for an application. In applications such as Web search, Neo4J-analytics, Data caching, and Media streaming, we see the intermediary range (512-1024, which is just beyond i-cache's reach), more prominent than even larger reuse distances. These are the cases when comparing reuse distances become more important, as opposed to applications such as TPC-C and Wikipedia which have much larger reuse distances.</p><p>Fig. <ref type="figure">2</ref>: Instruction block access datapath with i-Filter III. SOLUTION While i-Filter can provide some amount of separation of spatial vs. temporal locality, the key challenge is on what we should do when we have to evict a block from i-Filter (due to capacity): should we simply throw it away or should we insert it into the corresponding set of i-cache (hoping that it will be more useful than an existing block in that set)? Throwing it out from the i-Filter blindly implies that we are not leveraging i-cache's capacity. On the other hand, while inserting every block evicted from the i-Filter into i-cache (and evicting the LRU candidate from that set) does provide 1.0057 speedup over the baseline on the average across a number of applications as shown in Figure <ref type="figure" target="#fig_2">3a</ref>, it falls significantly short of the potential that an OPT replacement algorithm would provide without an i-Filter at all. This suggests that we need a more sophisticated mechanism to decide whether to insert the block from i-Filter into the i-cache upon its eviction from the former structure, which we explore in this section. This decision depends on whether the victim from the i-Filter has a reuse distance smaller than that of the block in the corresponding set of i-cache that it will replace, which we will henceforth refer to as the contender block.</p><p>This issue has been explored to some extent for data caches in a prior cache bypassing work in <ref type="bibr" target="#b36">[37]</ref> where access counters of the two are compared, and whichever is larger is retained in the cache and the other is evicted. We can apply the same mechanism to our i-Filter victim, and insert it into i-cache if its access count exceeds that of the i-cache contender. However, unlike the data cache study of <ref type="bibr" target="#b36">[37]</ref>, as Figure <ref type="figure" target="#fig_2">3a</ref> shows, this mechanism does not work well for instruction blocks.</p><p>Instead of an access count history, we would like to observe patterns in this history of the relative utility of the i-Filter victim vs. the contender in i-cache, to determine what we should retain in i-cache. Such history needs to be long enough to effectively capture the complex pattern of past reuse distance comparison results of an i-Filter victim and its i-cache contender. The well studied two-level branch predictor <ref type="bibr" target="#b91">[92]</ref> is good at maintaining long histories in an abridged form -predicts based on not only the history of the last n branches, but also the record of the last m occurrences of a certain history. It effectively compresses a long history to a smaller representation. Hence, we leverage the two-level branch predictor <ref type="bibr" target="#b91">[92]</ref> to develop our filtering mechanism as to which (the i-Filter victim vs. the i-cache contender) to admit/retain in i-cache.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Two-level Predictor-based Admission Control</head><p>Figure <ref type="figure">4</ref> illustrates our predictor for making this decision. Similar to the two-level branch predictor <ref type="bibr" target="#b91">[92]</ref>, our two-level i-cache admission predictor is comprised of two major data structures: a comparison History Register Table (HRT) and a Pattern Table (PT). The tag of an i-Filter victim block is first hashed to index HRT. Each HRT entry is a history register that shifts left with bits which represent the last few comparison results of an i-Filter victim block and its i-cache contender block. If the former is re-accessed sooner in the future<ref type="foot" target="#foot_1">2</ref> than the latter, the history register that the i-Filter victim block is mapped to is shifted left and a 1 is inserted into the least significant bit (LSB). Else, it is shifted left and a 0 is inserted into the LSB. PT is indexed by the content of history register. Each PT entry contains a saturating counter that is incremented each time that the i-Filter victim is re-accessed sooner than the i-cache contender block, and is decremented otherwise. A simple threshold is then used to determine whether the i-Filter victim is to be inserted (in place of the contender) in i-cache, or simply thrown away.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparing next accesses of i-Filter victim and i-cache contender</head><p>To update HRT entries and the counters in PT, we must find out whether an i-Filter victim block will be re-accessed in the nearer future (shorter reuse distance) than its i-cache contender block. Inspired by the design of MSHR (Missing Status Holding Registers) that tracks outstanding misses <ref type="bibr" target="#b50">[51]</ref>, we use a similar structure called CSHR (Comparison Status Holding Registers) to keep track of pairs of i-Filter victim blocks and their i-cache contenders whose comparison results</p><p>are not yet resolved as shown in Figure <ref type="figure">5</ref>. When an i-Filter victim block is being evicted, its tag and the tag of its i-cache contender are inserted into a CSHR entry. As a result of this, the LRU entry in CSHR may need to be evicted since it has a finite size (discussed in Section III-C1).</p><p>When the pipeline front-end issues fetch requests to i-cache in order, the tag of the instruction block being fetched is searched in CSHR. If it matches the i-Filter victim block tag field in a CSHR entry, it means that the i-Filter victim block in the entry is re-accessed sooner than its i-cache contender block. Therefore, the HRT entry is left shifted with a 1 and the corresponding counter of this pattern in PT is incremented. On the other hand, if the tag of the instruction block being fetched matches the i-cache contender block tag in a CSHR entry, the PT counter of the HRT entry is decremented with  C. Discussion about CSHR 1) Storage overhead: A large CSHR that contains many entries can track more outstanding i-Filter and i-cache block pairs, but it incurs higher storage overhead. On the other hand, with a small CSHR, entries are more likely to be evicted before comparisons are resolved, leading to less accurate predictions. To study the balance between these two factors, we plot Figure <ref type="figure" target="#fig_3">6</ref> which shows the incremental percentage of comparisons performed as we increase CSHR entries for a fully associative CSHR design. Although around 23% of comparisons require a very large number of CSHR entries, we find that nearly 70% of the comparisons get done with just 256 CSHR entries. Consequently we simply use a 256 entry CSHR, and for those entries which get evicted before being resolved, we give the benefit of doubt to the i-Filter victim as if it was re-accessed earlier than its i-cache contender. To further reduce storage overhead, instead of full tags of i-Filter victim blocks and i-cache contenders, partial tags are stored in each CSHR entry. When HRT is accessed for either prediction or predictor updates, partial tag, rather than the full block address, of the i-Filter victim block is hashed to index HRT. We will show later in Section IV-G that a 12-bit tag suffices for our needs. Consequently the CSHR totally takes 256?(2?12-bit tags + 1-bit valid + 5-bit LRU) = 0.9375 KB of space.</p><p>2) Access cycles: Since fetching an instruction block from i-cache can proceed in parallel with searching the partial tag of the instruction block in CSHR, accessing CSHR and updating predictor tables are not in the critical path to accessing i-cache. However, it is not practical to finish searching all the 256 entries in CSHR within one CPU cycle. To solve this problem, we adopt a set associative design for CSHR, in which the 256 entries are divided into k sets. Since the i-Filter block address and the i-cache contender block address in a CSHR entry are always mapped to the same i-cache set, we use the m most significant bits in the i-cache set index to find out to which CSHR set this pair should be inserted. When the instruction block being fetched needs to be searched in CSHR, the m most significant bits in its i-cache set index are used to index the CSHR set and parallel search is done within that set. We find that a k value of 8 and a m value of 3 to index the 8 CSHR sets, works quite well for our needs. Each CSHR set adopts LRU as the replacement policy. Figure <ref type="figure">7</ref> shows how the instruction block being fetched is simultaneously searched in the set-associative CSHR and how the predictor tables are updated when CSHR entries are matched. Fig. <ref type="figure">7</ref>: Search incoming block in set-associative CSHR When an instruction block is being searched for in a CSHR set, it can match the i-Filter block field of at most one CSHR entry. This is because when a block becomes i-Filter victim again and is inserted into the CSHR set, it must have already been re-accessed for it to have got back into the i-Filter after the previous eviction. This re-access guarantees that the block's previous comparison has been resolved and the corresponding CSHR entry is no longer valid, if we assume updating the predictor tables can finish before the block becomes i-Filter victim again (which does occur in most cases, as described in the next paragraph). However, the instruction block being searched can match the i-cache contender block field of multiple CSHR entries, because the i-cache contender block can be compared with different i-Filter victims and wins the competition each time to stay in i-cache. Therefore, one instruction block being searched can lead to multiple HRT and PT update requests. To address this, HRT is first indexed in parallel, and then the current history values in HRT are used to index and update PT in the next cycle. After the history values are passed to the PT updater, the current history registers in HRT are updated accordingly. Aliasing can occur when updating HRT and PT, and can cause conflicts when we update multiple entries in parallel. However, we find that aliasing in indexing HRT is so rare that we simply update each HRT entry for only one request and ignore the others. Since PT is much smaller than HRT, the probability of aliasing in PT is a little higher. To mitigate this problem, we add a 10-slot queue for each PT entry to accommodate the update requests. In each cycle, the heads of the PT update queues are popped and are used to update the PT entries. Figure <ref type="figure">8</ref> summarizes the datapath to update the predictor tables after matched CSHR entries are found.</p><p>There is a concern that due to the 2 cycles (or more if waiting in the PT entry update queue) spent in updating the predictor tables, a block X may become i-Filter victim again while there is already one unresolved CSHR entry whose i-Filter victim block field is X. This implies that the stale (older) Fig. <ref type="figure">8</ref>: Updating predictor tables information for block X in the predictor tables is used to make prediction this time. We illustrate this problem in Figure <ref type="figure">9</ref>. Fig. <ref type="figure">9</ref>: CSHR entry could not be resolved in time with a prefetcher</p><p>In the case with a prefetcher, where block X is prefetched before it is re-accessed, the predictor could be updated after block X becomes i-Filter victim again. As shown in the timeline, the prefetch request reduces the cycles between reaccessing block X and loading it into i-Filter from L2 cache. For a superscalar processor, it could take as few as 3 cycles for block X to move from the MRU position to LRU position in i-Filter. Therefore, it is possible that the CSHR entry could not be resolved in time with the presence of a prefetcher if N &gt; 3. However, as discussed in Section IV-G, such cases have a negligible impact on the overall performance. D. Additional Storage and Energy requirements for ACIC Storage: Each i-Filter entry contains 58 tag bits, 1 valid bit, 4 LRU bits, which adds up to 63 metadata bits, and a 64B instruction block. We empirally determine the size of HRT to be 1024 entries, each of which consists of 4 history bits, leading to 2 4 entries in PT. Each PT entry contains a 5-bit counter that indicates the prediction result. Each of the 10 slots in PT entry update queue contains a 4-bit PT index and 1 bit indicating whether the counter in the PT entry should be incremented or decremented.</p><p>CSHR contains 256 entries, and each entry consists of 12 tag bits for the i-Filter victim block, 12 tag bits for the i-cache contender block, 1 valid bit, and 5 LRU bits for the 32-way CSHR design. Table <ref type="table" target="#tab_0">I</ref> summarizes the storage overhead of ACIC for a 32KB i-cache with 8-way associativity. Evaluation results of ACIC in Section IV are based on the ACIC parameters in Table <ref type="table" target="#tab_0">I</ref>, and we provide sensitivity analysis of ACIC in Section IV-G.</p><p>We also list the storage overhead of the prior schemes that we compared with in Table <ref type="table" target="#tab_3">IV</ref>. ACIC requires 2.67KB extra storage, which is roughly 2/3rd of the 4.06KB storage overhead of GHRP, the state-of-the-art i-cache replacement policy with hardware techniques. Energy: We use the power pack (of the simulation infrastructure described in Section IV-A) to measure the chip energy for a 22nm process technology. It uses the McPAT <ref type="bibr" target="#b58">[59]</ref> model, and we calculate power for the i-Filter, HRT, PT, and CSHR with CACTI 7 <ref type="bibr" target="#b6">[7]</ref> and add the estimated values to the McPAT power numbers. It includes the chip energy with total execution time, runtime dynamic power, and total leakage power. We find that ACIC saves 0.63% chip energy on average, despite the additional power taken by the new structures. While this is only the chip energy, the higher speedup and higher i-cache hit rates of ACIC, will further decrease the overall system energy if we consider off-chip DRAM, interconnects and peripherals.</p><p>IV. EVALUATION A. Simulation infrastructure We first collect the full system execution trace of each application with the Qemu <ref type="bibr" target="#b9">[10]</ref> emulator. Specifically, a trace of 500 million or 1 billion instructions (depending on the execution time of the application) in the steady state is recorded. The traces are then fed to the Tejas <ref type="bibr" target="#b76">[77]</ref> simulator, a detailed cycle accurate trace-driven simulator. In each simulation, the simulator is warmed up with the first 10% (i.e. 50-100 million) of the instructions. Our core model is similar to the Intel Sunny Cove, as shown in Table <ref type="table" target="#tab_1">II</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Prior Works for Comparison</head><p>ACIC has similar motivations (avoiding and dealing with i-cache pollution) targeted by the following three broad strategies: cache replacement policies, cache bypassing policies, and Twitter's HTTP server 46.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neo4J-Analytics</head><p>Renaissance <ref type="bibr" target="#b69">[70]</ref> graph queries for a database 58.7 victim cache. Consequently, we compare ACIC quantitatively with prior and recent proposals that fall in these three categories as shown in Table <ref type="table" target="#tab_3">IV</ref>. The Cache Type column identifies the cache targetted by the original proposal. For each of these prior proposals, we also list their important parameters used in the simulations, along with the additional storage that they require. As Table <ref type="table" target="#tab_3">IV</ref> shows, for the simulated system, ACIC imposes an additional storage requirement of 2.67KB, which is around 2/3rd of the recent GHRP <ref type="bibr" target="#b63">[64]</ref> proposal. Additionally, a prefetcher, which reduces i-cache misses, can complement or belittle the benefits of these prior/our proposals. Consequently, we consider a standard fetch-directed prefetcher (FDP) <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Workloads and Metrics</head><p>Table III lists the datacenter applications used in our evaluations. These applications have been noted to suffer from front-end bottlenecks in related studies <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b51">[52]</ref> due to their large footprints, involvement of libraries and OS, as well as varying dynamism in their execution paths. Column MPKI quantifies the i-cache MPKI (misses per 1000 instructions) in these applications on our FDP baseline platform.</p><p>The most important metric for an application is the execution time, and speedup of any proposed enhancement over the baseline is the first metric that we consider. Equally important is the reduction in i-cache misses (MPKI) attained with the enhancements, since those are the key targets of optimization in these schemes. Consequently, we study both these metrics in our evaluation below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison with replacement policies (SRRIP, SHiP, Hawkeye/Harmony, GHRP)</head><p>From Figure <ref type="figure" target="#fig_0">10</ref>, we can see that the recently proposed GHRP provides the highest speedup amongst these previously proposed replacement policies. Still, ACIC outperforms GHRP with FDP. In particular, ACIC provides 1.0223 speedup on GHRP uses instruction reuse to predict dead blocks in the i-cache and prioritizes such dead blocks for replacement. If we define replacement accuracy as the percentage of victims selected by a given policy (e.g. GHRP) that are identical to the victims selected by OPT, we find that the replacement accuracy of GHRP is 17.90% on average, resulting in 15.64% of the MPKI reduction provided by OPT. ACIC is much more accurate, reducing 55.85% of misses reduced by OPT, as shown in Figure <ref type="figure" target="#fig_0">11</ref>.</p><p>As can be seen from Figure <ref type="figure" target="#fig_0">11</ref>, Media streaming, Data caching, Web search, and Neo4J-analytics are applications that show higher MPKI reduction under ACIC and GHRP than the other applications. The potential of a replacement policy is determined by the performance/MPKI difference between the OPT replacement policy and the baseline LRU policy. With the larger headroom, these four applications, ACIC and GHRP can help them to a greater extent. These are also those applications which suffer more from the burstiness behavior identified earlier (Figure <ref type="figure" target="#fig_0">1a</ref>), for which LRU cannot predict and optimize for the larger reuse distance after a recent burst. The relative benefits across applications with ACIC is further explained in Section IV-G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison with bypassing policies (DSB and OBM)</head><p>Of these two prior bypassing policies, DSB performs slightly better, though providing only a limited 1.0006 speedup over the LRU baseline with FDP.</p><p>DSB bypasses newly allocated blocks from the cache with a probability tuned based on the effectiveness of past bypassing decisions. Though similar in goals, unlike ACIC, DSB does not provide spatio-temporal locality separation whose importance was pointed out in Section II. Even with a higher storage budget, DSB does not perform as well as ACIC due to this fundamental problem. DSB provides only 0.46% MPKI reduction over the LRU baseline on average. Moreover, the bypassing policy of DSB is not very effective, and when equipped with i-Filter, DSB still only provides 1.0010 speedup over baseline.</p><p>Interestingly, we see that the results for OPT bypassing and OPT replacement are similar/close, implying that combining the spatio-temporal separation provided by i-Filter and a good admission control mechanism, can be an effective way to improve i-cache performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Comparison with victim caches (VC3K, VVC) and larger i-cache</head><p>One could question whether the real-estate required for the filtering mechanism could have been better served with an appropriate victim cache (which temporarily retains evictions for another chance), or even a larger i-cache. Consequently, we compare ACIC with (i) a traditional 3KB fully-associative victim cache VC3K <ref type="bibr" target="#b38">[39]</ref>, (ii) a recent work on victim cache <ref type="bibr" target="#b43">[44]</ref>, VVC which better uses the existing space, and (iii) a larger 36KB, 9-way i-cache (i.e. adding 4KB over our baseline, which is more than the additional real-estate needed for ACIC and also has a higher associativity).</p><p>VVC turns out to actually slow down the execution as seen in Figure <ref type="figure" target="#fig_0">10</ref>. VVC uses slots in the existing i-cache that are predicted dead to hold blocks evicted from other sets. We find that in nearly 60% of the cases, the victim blocks have longer reuse distances than the predicted dead blocks in other sets, but they are still brought into other sets by VVC, leading to waste of cache capacity. While a traditional victim cache (VC3K) does much better than VVC, ACIC gives 1.018? the speedup provided by the 3KB victim cache on average.</p><p>Figure <ref type="figure" target="#fig_0">10</ref> shows that ACIC provides 1.009? the speedup provided by the 36KB i-cache on average. These results tend to reiterate the importance of being more discretionary in what comes into and goes out of i-cache, than blindly throwing more resources at it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Insights into the working of ACIC</head><p>Discretionary Filtering: Figure <ref type="figure" target="#fig_2">13</ref> depicts the percentage of i-Filter victims that are inserted into i-cache based on the predictor in ACIC. The percentages vary significantly across applications (from 30-99%). As Figure <ref type="figure" target="#fig_0">1a</ref> showed, Web search, Neo4J-analytics, Data caching, and Media streaming show a higher fraction of reuse distances which fall just beyond the i-cache's reach, where it becomes more critical to decide whether or not to insert the victim from i-Filter into icache. This is confirmed by Figure <ref type="figure" target="#fig_2">13</ref>, where we see these applications exhibiting a larger filtering effect. This reiterates the need for dynamic adaptation to application behavior as in ACIC, rather than a static way of determining whether to insert into i-cache after the current burst. Accuracy of Filtering: It is even more important to examine whether ACIC made the correct filtering choice. To do this, we use oracle knowledge about reuse distances to compare the future reuse distances of the i-cache victim and the i-Filter victim, and compare that decision with ACIC's prediction. The filter accuracy of ACIC is calculated as the percentage of the correct predictions over total predictions. Surprisingly, the average bypass accuracy of ACIC is only 60.89%, as shown in the first bar (corresponding to [0,InF)) of Figure <ref type="figure" target="#fig_0">12a</ref>. However, the bypass accuracy matters only in cases when the reuse distances of the i-Filter victim and the i-cache contender block are not both very large (if they are, they will both likely get evicted before being accessed), and their reuse distances are not equal either. We consequently plot the ACIC bypass accuracy for varying ranges of reuse distances in Figure <ref type="figure" target="#fig_0">12a</ref>.</p><p>To demonstrate that ACIC is reasonably accurate where it really matters, we also consider a "random" filtering mechanism to determine whether to insert the evicted i-Filter block into i-cache. In Figure <ref type="figure" target="#fig_0">12b</ref>, we compare the i-cache MPKI reduction of ACIC and this random bypass scheme over the FDP baseline. Even though the random bypass scheme has 60% accuracy, similar to the overall bypass accuracy of ACIC, we can see that it provides only 7.65% MPKI reduction, which is 42.17% of the MPKI reduction provided by ACIC. Figure <ref type="figure" target="#fig_0">12a</ref> and Figure <ref type="figure" target="#fig_0">12b</ref> provide a key insight: prediction accuracy matters only when at least either of the two (i-Filter victim or i-cache contender) has a reuse distance that is not very large, so that at least one of them is likely to be accessed again while in i-cache in the near future. Latency in updating predictor: Section III-C2 described the possibility that stale information is read from predictor due to the multiple cycles spent in updating the two tables, HRT and PT, with the existence of a prefetcher. To see whether this could cause a problem in performance, we compare the i-cache MPKI reduction with our parallel update scheme, in which at least 2 cycles are spent in updating HRT and PT, and an instant update scheme, in which the HRT and PT are updated immediately. From Figure <ref type="figure" target="#fig_0">14</ref>, we can see that the MPKI reduction of the parallel update scheme is very close to that of the instant update scheme. The update latency of the predictor tables thus does not affect ACIC's effectiveness, and does not need to come into the critical path. Sensitivity Analysis: Figure <ref type="figure" target="#fig_0">15</ref> shows the average speedup of ACIC when its key design parameters are varied. The leftmost bar default gives the average speedup of ACIC with parameters shown in Table <ref type="table" target="#tab_0">I</ref>. Since the number of CSHR entries has been discussed in Section III-C1, here we only show sensitivity to HRT entries, length of each history register in HRT, length of counters in PT, number of i-Filter slots, and length of partial tags in CSHR. We can see that among all the parameters, increasing the i-Filter size gives the most benefit, while decreasing i-Filter size, length of PT counter and CSHR tags worsen performance the most. Increasing the history length from 4-bit to 10-bit does not show a big performance gain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Discussion</head><p>1) Performance benefit due to bypass policy: While similar/variant forms of i-Filter are not necessarily modeled in current academic simulators, i-Filter-like small buffers are usually present in real processors to contain recently accessed instruction blocks. To show the benefit of ACIC more realistically, we present Figure <ref type="figure" target="#fig_3">16</ref> to show the speedup of ACIC over FDP baseline equipped with i-Filter. We can see that ACIC's bypass policy itself gives 1.0165 geomean speedup over the LRU replacement policy baseline.</p><p>2) Necessity of each ACIC structure: While ACIC gives better performance and less storage overhead than the recently proposed GHRP, ACIC's mechanism is more complex. CSHR is responsible for training the predictor, so it cannot exist on its own. To justify the necessity of the other two parts of ACIC (i-Filter and two-level predictor), we plot Figure <ref type="figure" target="#fig_0">17</ref> to show the geomean speedup of ACIC with simpler designs over FDP baseline: ACIC without i-Filter, ACIC with i-Filter only, ACIC with a global history two-level predictor, and ACIC with a bimodal predictor. We can see that turning off i-Filter/predictor or replacing two-level predictor with simpler ones does not give as good performance as our default ACIC.</p><p>3) Evaluation of ACIC with SPEC workloads: ACIC targets datacenter workloads, as these workloads suffer from higher i-cache misses than conventional workloads like SPEC <ref type="bibr" target="#b0">[1]</ref>. For completeness, we evaluate how ACIC performs in SPEC workloads as well. Figure <ref type="figure" target="#fig_0">18</ref> and Figure <ref type="figure" target="#fig_0">19</ref> show speedup and MPKI reduction of ACIC, GHRP, 36KB L1i, and OPT over FDP baseline for SPEC2017 Integer Speedup benchmarks with L1i MPKI&gt;1. These workloads have high i-cache hit rates even in the baseline, leaving little headroom for ACIC. Still, ACIC does as well as having the larger 36KB L1i.</p><p>4) With Entangling Prefetching baseline: Entangling prefetcher <ref type="bibr" target="#b75">[76]</ref> is a more recent state-of-the-art instruction prefetcher than FDP. From Figure <ref type="figure">20</ref> and Figure <ref type="figure" target="#fig_0">21</ref>, we can see that with the entangling prefetcher (with a 4K-entry entangled table) baseline, ACIC still outperforms GHRP and 36KB L1i, which are the two best prior policies shown in Figure <ref type="figure" target="#fig_0">10</ref>   (b) MPKI reduction comparison of random bypass with 60% accuracy and ACIC over fetch-directed prefetching baseline Fig. <ref type="figure" target="#fig_0">12</ref>: ACIC bypass accuracy analysis speedup and 6.71% MPKI reduction over the baseline. Entangling prefetcher improves the baseline L1i hit rate to be over 97% in our datacenter workloads, so it further complements ACIC's benefits. However, considering that the entangling prefetcher incurs about 40KB storage overhead, which is larger than i-cache itself, ACIC is not redundant. As stated in Section II, ACIC and prefetching are complementary, and ACIC can improve i-cache performance beyond the benefits of prefetchers.</p><note type="other">Speedup SRRIP SHiP Harmony GHRP DSB OBM VVC VC3K ACIC 36KB L1i OPT OPT Bypass Fig</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RELATED WORK</head><p>The cache pollution problem that ACIC addresses is most closely related to 3 broad categories -replacement policies, bypassing mechanisms and victim caches -that have similar goals, though most of the prior work in these have targetted d-caches as opposed to i-caches. Replacement policies: There has been considerable work on replacement policies <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b65">[66]</ref>, <ref type="bibr" target="#b71">[72]</ref>, <ref type="bibr" target="#b74">[75]</ref>, <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b80">[81]</ref>, <ref type="bibr" target="#b86">[87]</ref>, <ref type="bibr" target="#b87">[88]</ref>. Since OPT is not implementable, heuristics include variations of LRU <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b53">[54]</ref>, Fig. <ref type="figure" target="#fig_3">16</ref>: ACIC speedup over FDP baseline with i-Filter <ref type="bibr" target="#b65">[66]</ref>, <ref type="bibr" target="#b80">[81]</ref>, <ref type="bibr" target="#b87">[88]</ref>, frequency <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b74">[75]</ref>, reuse prediction <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b63">[64]</ref>, <ref type="bibr" target="#b88">[89]</ref>, and others <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b70">[71]</ref>, <ref type="bibr" target="#b72">[73]</ref>, <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b82">[83]</ref>. There have also been learning-based policies based on machine learning <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b79">[80]</ref>, <ref type="bibr" target="#b84">[85]</ref> and Belady's optimal solution <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b59">[60]</ref>. However, as our quantitative evaluation shows, many of these prior proposals for d-caches (e.g. <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b88">[89]</ref>) do not work as well for i-caches, compared to ACIC. On the other hand, recent techniques for i-caches such as Ripple <ref type="bibr" target="#b46">[47]</ref> and GHRP <ref type="bibr" target="#b63">[64]</ref> do not identify and leverage the burstiness of accesses to instruction blocks, making ACIC a better Bypassing policies: Cache bypassing policies use static approaches <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b89">[90]</ref> with a profile-guided compiler to identify lines for bypassing, and dynamic approaches <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b35">[36]</ref>- <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b83">[84]</ref>, <ref type="bibr" target="#b90">[91]</ref> which use run-time behavior to learn and predict bypassing opportunities. DSB <ref type="bibr" target="#b22">[23]</ref> and OBM <ref type="bibr" target="#b57">[58]</ref> are two bypassing policies most similar to ACIC in that they also track the reuse behavior An early work <ref type="bibr" target="#b36">[37]</ref> uses a small buffer, similar to ACIC, for short temporal/spatial locality. However, they use access counters to compare the utility of incoming and contender blocks, which does not work very well for the instruction stream that exhibits burstiness requiring a more extensive predictor as in ACIC. Victim caches: Rather than regulate entry, an alternative is to retain the evicted victims temporarily in a victim cache to reduce pollution. Works on victim caches <ref type="bibr" target="#b38">[39]</ref> include <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b29">[30]</ref>. VVC <ref type="bibr" target="#b43">[44]</ref> is a more recent work that predicts dead blocks and reuse the dead regions in the cache as a virtual victim cache. We have shown that ACIC can provide better performance for the instruction stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUDING REMARKS &amp; FUTURE WORK</head><p>We drew insight from the observation of bursty accesses in data stream <ref type="bibr" target="#b60">[61]</ref>, leveraged i-Filter proposed in <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b48">[49]</ref> to optimize "burstiness" in the instruction stream, and presented an admission control mechanism, ACIC, that regulates the entry of instruction blocks into the i-cache. Comparing with several (8 in all) prior approaches -replacement algorithms, bypassing mechanisms and victim caches -we have shown the benefits of ACIC over these prior approaches. We have also shown that it can complement previously proposed prefetching mechanisms.</p><p>The predictor in ACIC learns from on-demand instruction accesses, and tries to estimate reuse distances to implement a more practical version of Belady's OPT algorithm (comparing reuse distances of i-Filter and i-cache victim). Prefetching could further reduce on-demand misses, but comes at a possible cost of higher memory traffic. As was pointed out in <ref type="bibr" target="#b32">[33]</ref>, Belady's OPT may not be the best when prefetching is considered. Developing a prefetching-aware ACIC mechanism is part of our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Reuse distance analysis. Shows the need for separating spatio-temporal localities.</figDesc><graphic url="image-1.png" coords="3,309.52,60.60,231.53,120.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>-Filter victim to i-cache Bypass with access count comparison OPT replacement policy (a) Always inserting i-Filter victims to i-cache provides 1.0057 geomean speedup over baseline. Bypassing with access count comparison provides 1.0102 geomean speedup. OPT replacement policy provides 1.0398 geomean speedup. Reuse distance of incoming block (from i-Filter into i-cache)reuse distance of outgoing block (selected from the corresponding set of i-cache using OPT) in Media Streaming. In 38.38% of the cases, the incoming block has a larger reuse distance, showing that the last access of the burst (spatial locality) should not be used for projecting future temporal reuse.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Media streaming: Need for additional filtering of blocks from entering L1i after the current burst of accesses in i-Filter</figDesc><graphic url="image-3.png" coords="5,72.25,240.21,202.53,97.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Distribution of comparisons during the lifetime of CSHR entries in Data Caching</figDesc><graphic url="image-4.png" coords="5,67.79,379.02,213.40,112.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>and Figure 11. ACIC provides 1.0102 geomean</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 17 :Fig. 18 :Fig. 19 :Fig. 20 :</head><label>17181920</label><figDesc>Fig. 17: Speedup of ACIC with simpler designs over FDP baseline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Storage overhead of ACIC for a 32KB, 8-way icache</figDesc><table><row><cell>Component</cell><cell>Number of bits</cell></row><row><cell>i-Filter</cell><cell>16 entries ? (63 bit metadata + 64B instruction</cell></row><row><cell></cell><cell>block) = 1.123KB</cell></row><row><cell>HRT</cell><cell>1024 entries ? 4 bit history = 0.5KB</cell></row><row><cell>PT</cell><cell>2 4 entries ? 5 bit counters = 10B</cell></row><row><cell>PT entry update queue</cell><cell>16 PT update queues ? 10 slots ? (4 bit PT</cell></row><row><cell></cell><cell>idx + 1 bit update request) = 100B</cell></row><row><cell>CSHR</cell><cell>256 entries ? (24 bit tags + 1 bit valid + 5 bit</cell></row><row><cell></cell><cell>LRU) = 0.9375KB</cell></row><row><cell>Total</cell><cell>2.67KB</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Simulation parameters</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>CPU frequency</cell><cell>4GHz</cell></row><row><cell>Fetch width</cell><cell>6-wide, 24-entry Fetch Target Queue</cell></row><row><cell>Decode width</cell><cell>6-wide, 60-entry Decode Queue</cell></row><row><cell>Out-of-order Core</cell><cell>352-entry Reorder Buffer</cell></row><row><cell>BTB</cell><cell>8192-entry, 4-way</cell></row><row><cell>Branch predictor</cell><cell>TAGE [79]</cell></row><row><cell>L1 I-Cache</cell><cell>32KB, 8-way, 16 MSHRs, 4-cycle</cell></row><row><cell>L1 D-Cache</cell><cell>48KB, 8-way, 16 MSHRs, 5-cycle</cell></row><row><cell>L2 Unified Cache</cell><cell>512KB, 8-way, 32 MSHRs, 15-cycle</cell></row><row><cell>L3 Unified Cache</cell><cell>2MB, 16-way, 64 MSHRs, 35-cycle</cell></row><row><cell>DRAM</cell><cell>1 channel, 3200MT/s (25.6GB/s)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Data center applications used in our evaluation</figDesc><table><row><cell></cell><cell>Benchmark</cell><cell>Description</cell><cell>MPKI</cell></row><row><cell></cell><cell>Suite</cell><cell></cell><cell></cell></row><row><cell>Media</cell><cell>CloudSuite</cell><cell>Darwin streaming server</cell><cell>81.2</cell></row><row><cell>Streaming</cell><cell>[20]</cell><cell></cell><cell></cell></row><row><cell>Data Caching</cell><cell>CloudSuite</cell><cell>Memcached for Twitter</cell><cell>78.1</cell></row><row><cell></cell><cell>[20]</cell><cell></cell><cell></cell></row><row><cell>Data Serving</cell><cell>CloudSuite</cell><cell>YCSB data store server</cell><cell>31.6</cell></row><row><cell></cell><cell>[20]</cell><cell></cell><cell></cell></row><row><cell>Web Serving</cell><cell>CloudSuite</cell><cell>cloud web services</cell><cell>65.8</cell></row><row><cell></cell><cell>[20]</cell><cell></cell><cell></cell></row><row><cell>Web Search</cell><cell>CloudSuite</cell><cell>Apache Solr search en-</cell><cell>151.5</cell></row><row><cell></cell><cell>[20]</cell><cell>gine</cell><cell></cell></row><row><cell>TPC-C</cell><cell>OLTP-</cell><cell>OLTP workload</cell><cell>42.5</cell></row><row><cell></cell><cell>Bench [16]</cell><cell></cell><cell></cell></row><row><cell>Wikipedia</cell><cell>OLTP-</cell><cell>online encyclopedia</cell><cell>41.1</cell></row><row><cell></cell><cell>Bench [16]</cell><cell></cell><cell></cell></row><row><cell>SIBench</cell><cell>OLTP-</cell><cell>snapshot isolations in</cell><cell>35.0</cell></row><row><cell></cell><cell>Bench [16]</cell><cell>DBMSs</cell><cell></cell></row><row><cell>Finagle-</cell><cell>Renaissance</cell><cell></cell><cell></cell></row><row><cell>HTTP</cell><cell>[70]</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>Schemes for comparison</figDesc><table><row><cell></cell><cell>Optimization Strategy</cell><cell>Cache Type</cell><cell>Important Parameters/Notes</cell><cell>Storage</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Overhead</cell></row><row><cell>SRRIP [34]</cell><cell>replacement policy</cell><cell>LLC</cell><cell>2-bit RRPV</cell><cell>0.125KB</cell></row><row><cell>SHiP [89]</cell><cell>replacement policy</cell><cell>LLC</cell><cell>13-bit signature, 8K-entry SHCT, 2-bit counter</cell><cell>2.88KB</cell></row><row><cell>Hawkeye [32]/</cell><cell>replacement policy</cell><cell>LLC</cell><cell>64 entries per occupancy vector, 8K-entry predictor, 3-bit training</cell><cell>4.69KB</cell></row><row><cell>Harmony [33]</cell><cell></cell><cell></cell><cell>counter, 3-bit RRIP</cell><cell></cell></row><row><cell>GHRP [64]</cell><cell>replacement policy</cell><cell>L1 i-cache</cell><cell>3 4096-entry predictor tables, 2-bit counter, 16-bit signature, 1-bit</cell><cell>4.06KB</cell></row><row><cell></cell><cell></cell><cell></cell><cell>prediction, 16-bit history register</cell><cell></cell></row><row><cell>DSB [23]</cell><cell>bypassing policy</cell><cell>LLC</cell><cell>16-bit tracked line tag, 3-bit competitor way tag, 2 sampled sets for</cell><cell>0.48KB</cell></row><row><cell></cell><cell></cell><cell></cell><cell>policy selection</cell><cell></cell></row><row><cell>OBM [58]</cell><cell>bypassing policy</cell><cell>LLC</cell><cell>21-bit incoming block tag, 21-bit victim block tag, 10-bit signature,</cell><cell>1.41KB</cell></row><row><cell></cell><cell></cell><cell></cell><cell>128-entry RHT, 1024-entry BDCT, 4-bit counter</cell><cell></cell></row><row><cell>VVC [44]</cell><cell>victim cache</cell><cell>LLC</cell><cell>15-bit trace, 2 2 14 -entry predictor tables, 2-bit counter</cell><cell>9.06KB</cell></row><row><cell>VC8K [39]</cell><cell>victim cache</cell><cell>L1 cache</cell><cell>4-way associative, 128 blocks</cell><cell>8KB</cell></row><row><cell>40KB i-cache</cell><cell>larger i-cache</cell><cell>L1 i-cache</cell><cell>10-way associative, 640 blocks</cell><cell>8KB</cell></row><row><cell>OPT [9]</cell><cell>replacement policy</cell><cell>all types</cell><cell>evict the block that is reused furthest in the future</cell><cell>0KB</cell></row><row><cell>OPT bypass with i-</cell><cell>bypassing policy</cell><cell>L1 i-cache</cell><cell>place i-Filter victim in i-cache only if i-Filter victim is known (with</cell><cell>1.123KB</cell></row><row><cell>Filter</cell><cell></cell><cell></cell><cell>oracle knowledge) to have smaller reuse distance than the i-cache</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>contender selected by LRU</cell><cell></cell></row><row><cell>ACIC</cell><cell>bypassing policy</cell><cell>L1 i-cache</cell><cell>16-entry i-Filter, 1024-entry HRT, 4-bit history, 2 4 -entry PT, 5-bit</cell><cell>2.67KB</cell></row><row><cell></cell><cell></cell><cell></cell><cell>counter, 10-entry PT entry update queue, 256-entry CSHR, 24-bit partial</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>tags</cell><cell></cell></row><row><cell cols="4">average over the LRU replacement policy FDP baseline, which</cell><cell></cell></row><row><cell cols="4">corresponds to 56.03% of the attainable speedups of the</cell><cell></cell></row><row><cell cols="2">oracle-based OPT replacement policy.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>,InF) [0, 2048) [0, 1024) [0, 512) [0, 256) [0, 128) Reuse distance range 0% 10% 20% 30% 40% 50% 60% 70% 80% Avg ACIC bypass accuracy</head><label></label><figDesc>. 10: ACIC's speedup compared with state-of-the-art replacement, bypassing, and victim cache policies over an LRU baseline with fetch-directed prefetching.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">SRRIP</cell><cell cols="2">Harmony</cell><cell>DSB</cell><cell>VVC</cell><cell>ACIC</cell><cell>OPT</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>SHiP</cell><cell></cell><cell cols="2">GHRP</cell><cell>OBM</cell><cell>VC3K</cell><cell>36KB L1i</cell><cell>OPT Bypass</cell></row><row><cell></cell><cell>40%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L1i MPKI reduction</cell><cell>0% 20%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">-15%</cell><cell>-27.09% -94.58%</cell><cell cols="4">-16.52% -131.37% -243.67% -199.39% -38.29% -40.43%</cell><cell></cell><cell cols="2">-60.24% -254.35% -289.29% -41.85%</cell><cell>-47.43% -67.71%</cell><cell>-62.26% -195.66%</cell><cell>-79.22%</cell><cell>-29.97% -156.24%</cell></row><row><cell></cell><cell></cell><cell cols="2">media streaming</cell><cell>data caching</cell><cell>data serving</cell><cell>web serving</cell><cell>web search</cell><cell></cell><cell>TPC-C wikipedia sibench finagle http</cell><cell>neo4j analytics</cell><cell>Avg</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Random bypass with 60% accuracy</cell><cell>ACIC</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>40%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>L1i MPKI reduction</cell><cell>10% 20% 30%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>media streaming</cell><cell>data caching</cell><cell>data serving</cell><cell>web serving</cell><cell>web search</cell><cell>TPC-C wikipedia sibench</cell><cell>finagle http</cell><cell>neo4j analytics</cell><cell>Avg</cell></row><row><cell cols="8">(a) Average ACIC bypass accuracy for various reuse distance</cell><cell></cell></row><row><cell>ranges</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>Fig. 11: ACIC's MPKI reduction compared with state-of-the-art replacement, bypassing, and victim cache policies over an LRU baseline with fetch-directed prefetching.</p>[0</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Fig.21: MPKI reduction comparison of various policies over entangling prefetching baseline of newly allocated cache lines and their corresponding cache contender blocks to learn whether an incoming block should bypass the cache. DSB randomly bypasses newly allocated lines and the effectiveness of the past bypassing decisions is used to tune the bypassing probability. However, unlike the CSHR in ACIC, DSB only tracks one pair in a cache set at a time, and OBM tracks incoming-victim pairs with a low probability to reduce storage overhead. The selective tracking used by DSB and OBM turns out to be much less effective than our CSHR design. Moreover, DSB and OBM are further undermined since they are direct bypassing schemes without first separating spatial and temporal locality.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>GHRP</cell><cell>36KB L1i</cell><cell>ACIC</cell><cell>OPT</cell></row><row><cell></cell><cell>20.0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>15.0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L1i MPKI reduction</cell><cell>10.0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>5.0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-0.39%</cell><cell></cell><cell></cell></row><row><cell></cell><cell>media streaming</cell><cell>data caching</cell><cell>data serving</cell><cell>web serving</cell><cell>web search</cell><cell cols="2">TPC-C wikipedia sibench finagle http</cell><cell>neo4j analytics</cell><cell>Avg</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In this work, the term reuse distance is defined similar to stack distance of LRU, i.e. the number of unique instruction cache blocks accessed between two successive accesses to the same instruction block.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Section III-B will discuss how to track future accesses.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.spec.org/cpu" />
		<title level="m">SPEC CPU</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Architectural and compiler support for effective instruction prefetching: A cooperative approach</title>
		<idno type="DOI">10.1145/367742.367786</idno>
		<ptr target="https://doi.org/10.1145/367742.367786" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="109" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dbmss on a modern processor: Where does time go</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Very Large Data Bases, ser. VLDB &apos;99</title>
		<meeting>the 25th International Conference on Very Large Data Bases, ser. VLDB &apos;99<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="266" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Divide and conquer frontend bottleneck</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="65" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Memory hierarchy for web search</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="643" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Asmdb: Understanding and mitigating front-end stalls in warehouse-scale computers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Nagendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3307650.3322234</idno>
		<ptr target="https://doi.org/10.1145/3307650.3322234" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture, ser. ISCA &apos;19</title>
		<meeting>the 46th International Symposium on Computer Architecture, ser. ISCA &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="462" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cacti 7: New tools for interconnect exploration in innovative off-chip memories</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Muralimanohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shafiee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivas</surname></persName>
		</author>
		<idno type="DOI">10.1145/3085572</idno>
		<ptr target="https://doi.org/10.1145/3085572" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Archit. Code Optim</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017-06">Jun. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scavenger: A new last level cache architecture with global block priority</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">40th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A study of replacement algorithms for a virtual-storage computer</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Belady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="78" to="101" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Qemu, a fast and portable dynamic translator</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bellard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on USENIX Annual Technical Conference, ser. ATEC &apos;05. USA: USENIX Association</title>
		<meeting>the Annual Conference on USENIX Annual Technical Conference, ser. ATEC &apos;05. USA: USENIX Association</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page">41</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pseudo-lifo: The foundation of a new family of replacement policies for last-level caches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="401" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bashyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nuzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 21st International Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="293" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Autofdo: Automatic feedbackdirected optimization for warehouse-scale applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE/ACM International Symposium on Code Generation and Optimization</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="12" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving cache performance by selective cache bypass</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second Annual Hawaii International Conference on System Sciences</title>
		<meeting>the Twenty-Second Annual Hawaii International Conference on System Sciences</meeting>
		<imprint>
			<date type="published" when="1989">1989. 1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="277" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hardware identification of cache conflict misses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-32. Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="126" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Oltpbench: An extensible testbed for benchmarking relational databases</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Difallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Curino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cudre-Mauroux</surname></persName>
		</author>
		<idno type="DOI">10.14778/2732240.2732246</idno>
		<ptr target="https://doi.org/10.14778/2732240.2732246" />
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2013-12">Dec. 2013</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="277" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving cache management policies using dynamic reuse distances</title>
		<author>
			<persName><forename type="first">N</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cammarota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Veidenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 45th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="389" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Enhancing last-level cache performance by block bypassing and early miss determination</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dybdahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenstr?m</surname></persName>
		</author>
		<idno type="DOI">10.1007/11859802_6</idno>
		<ptr target="https://doi.org/10.1007/118598026" />
	</analytic>
	<monogr>
		<title level="m">Advances in Computer Systems Architecture, 11th Asia-Pacific Conference</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Jesshope</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Egan</surname></persName>
		</editor>
		<meeting><address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006-09-06">2006. September 6-8, 2006. 2006</date>
			<biblScope unit="volume">4186</biblScope>
			<biblScope unit="page" from="52" to="66" />
		</imprint>
	</monogr>
	<note>Proceedings, ser. Lecture Notes in Computer Science</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Leeway: Addressing variability in dead-block prediction for last-level caches</title>
		<author>
			<persName><forename type="first">P</forename><surname>Faldu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 26th International Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="180" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Clearing the clouds: A study of emerging scale-out workloads on modern hardware</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alisafaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<ptr target="http://infoscience.epfl.ch/record/173764" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Proactive instruction fetch</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 44th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Temporal instruction fetch streaming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2008.4771774</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2008.4771774" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 41</title>
		<meeting>the 41st Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 41<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Dueling Segmented LRU Replacement Algorithm with Adaptive Bypassing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/inria-00492965" />
	</analytic>
	<monogr>
		<title level="m">JWAC 2010 -1st JILP Worshop on Computer Architecture Competitions: cache replacement Championship</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</editor>
		<meeting><address><addrLine>Saint Malo, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bypass and insertion algorithms for exclusive last-level caches</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 38th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="81" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A data cache with multiple caching strategies tuned to different types of locality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gonz?lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Aliagas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1145/2591635.2667170</idno>
		<ptr target="https://doi.org/10.1145/2591635.2667170" />
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Supercomputing 25th Anniversary Volume</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive cache bypassing for inclusive last level caches</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 27th International Symposium on Parallel and Distributed Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1243" to="1253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A fully associative software-managed cache design</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hallnor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reinhardt</surname></persName>
		</author>
		<idno>RS00201</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 27th International Symposium on Computer Architecture</title>
		<meeting>27th International Symposium on Computer Architecture</meeting>
		<imprint>
			<publisher>IEEE Cat</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reactive nuca: Near-optimal block placement and replication in distributed caches</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<idno type="DOI">10.1145/1555754.1555779</idno>
		<ptr target="https://doi.org/10.1145/1555754.1555779" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual International Symposium on Computer Architecture, ser. ISCA &apos;09</title>
		<meeting>the 36th Annual International Symposium on Computer Architecture, ser. ISCA &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Guaranteeing hits to improve the efficiency of a small instruction cache</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whalley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tyson</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2007.18</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2007.18" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 40</title>
		<meeting>the 40th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO 40<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="433" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Timekeeping in the memory system: Predicting and optimizing memory behavior</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Computer Architecture, ser. ISCA &apos;02</title>
		<meeting>the 29th Annual International Symposium on Computer Architecture, ser. ISCA &apos;02<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="209" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Re-establishing fetchdirected instruction prefetching: An industry perspective</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nathella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sunwoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="172" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Back to the future: Leveraging belady&apos;s algorithm for improved cache replacement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="78" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Rethinking belady&apos;s algorithm to accommodate prefetching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="110" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">High performance cache replacement using re-reference interval prediction (rrip)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Steely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
		<idno type="DOI">10.1145/1815961.1815971</idno>
		<ptr target="https://doi.org/10.1145/1815961.1815971" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual International Symposium on Computer Architecture, ser. ISCA &apos;10</title>
		<meeting>the 37th Annual International Symposium on Computer Architecture, ser. ISCA &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="60" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Insertion and promotion for tree-based pseudolru lastlevel caches</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="284" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multiperspective reuse prediction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 50th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="436" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Run-time cache bypassing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Connors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Merten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1338" to="1354" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Run-time adaptive cache hierarchy via reference analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings. The 24th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="315" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. The 17th Annual International Symposium on Computer Architecture</title>
		<meeting>The 17th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1990">1990. 1990</date>
			<biblScope unit="page" from="364" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ptask: A smart prefetching scheme for os intensive applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kallurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Sarangi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 49th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Profiling a warehouse-scale computer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Shift: Shared history instruction fetch for lean-core server processors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="272" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Confluence: Unified instruction supply for scale-out servers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 48th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="166" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Using dead blocks as a virtual victim cache</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1854273.1854333</idno>
		<ptr target="https://doi.org/10.1145/1854273.1854333" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;10</title>
		<meeting>the 19th International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sampling dead block prediction for last-level caches</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">I-spy: Context-driven conditional instruction prefetching with coalescing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="146" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Ripple: Profile-guided instruction cache replacement for data center applications</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kasikci</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA52012.2021.00063</idno>
		<ptr target="https://doi.org/10.1109/ISCA52012.2021.00063" />
	</analytic>
	<monogr>
		<title level="m">48th ACM/IEEE Annual International Symposium on Computer Architecture, ISCA 2021</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">June 14-18, 2021. IEEE, 2021</date>
			<biblScope unit="page" from="734" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Counter-based cache replacement algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kharbutli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Solihin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 International Conference on Computer Design</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The filter cache: an energy efficient memory structure</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mangione-Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 30th Annual International Symposium on Microarchitecture</title>
		<meeting>30th Annual International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="184" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Rdip: Return-address-stack directed instruction prefetching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="260" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Lockup-free instruction fetch/prefetch cache organization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual Symposium on Computer Architecture, ser. ISCA &apos;81</title>
		<meeting>the 8th Annual Symposium on Computer Architecture, ser. ISCA &apos;81<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="81" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Blasting through the frontend bottleneck with shotgun</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173162.3173178</idno>
		<ptr target="https://doi.org/10.1145/3173162.3173178" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;18</title>
		<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="30" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Boomerang: A metadata-free architecture for control flow delivery</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="493" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">On the existence of a spectrum of policies that subsumes the least recently used (lru) and least frequently used (lfu) policies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1145/301453.301487</idno>
		<ptr target="https://doi.org/10.1145/301453.301487" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, ser. SIGMETRICS &apos;99</title>
		<meeting>the 1999 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, ser. SIGMETRICS &apos;99<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="134" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">LRFU: A spectrum of policies that subsumes the least recently used and least frequently used policies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1109/TC.2001.970573</idno>
		<ptr target="https://doi.org/10.1109/TC.2001.970573" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computers</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1352" to="1361" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A new cache architecture based on temporal and spatial locality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1383-7621(00)00035-7</idno>
		<ptr target="https://doi.org/10.1016/S1383-7621(00" />
	</analytic>
	<monogr>
		<title level="j">J. Syst. Archit</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="35" to="37" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Lightweight feedbackdirected cross-module optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hundt</surname></persName>
		</author>
		<idno type="DOI">10.1145/1772954.1772964</idno>
		<ptr target="https://doi.org/10.1145/1772954.1772964" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual IEEE/ACM International Symposium on Code Generation and Optimization, ser. CGO &apos;10</title>
		<meeting>the 8th Annual IEEE/ACM International Symposium on Code Generation and Optimization, ser. CGO &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="53" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Optimal bypass monitor for high performance last-level caches</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1145/2370816.2370862</idno>
		<ptr target="https://doi.org/10.1145/2370816.2370862" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;12</title>
		<meeting>the 21st International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Mcpat: An integrated power, area, and timing modeling framework for multicore and manycore architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An imitation learning approach for cache replacement</title>
		<author>
			<persName><forename type="first">E</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2006">2006.16239, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Cache bursts: A new approach for eliminating dead blocks and increasing cache efficiency</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 41st IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Ispike: a post-link optimizer for the intel/spl reg/ itanium/spl reg/ architecture</title>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lowney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Code Generation and Optimization</title>
		<imprint>
			<date type="published" when="2004">2004. 2004. 2004</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">ARC: A self-tuning, low overhead replacement cache</title>
		<author>
			<persName><forename type="first">N</forename><surname>Megiddo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Modha</surname></persName>
		</author>
		<ptr target="http://www.usenix.org/events/fast03/tech/megiddo.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the FAST &apos;03 Conference on File and Storage Technologies</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Chase</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Usenix</surname></persName>
		</editor>
		<meeting>the FAST &apos;03 Conference on File and Storage Technologies<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cathedral Hill Hotel</publisher>
			<date type="published" when="2003-04-02">March 31 -April 2, 2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Exploring predictive replacement policies for instruction cache and branch target buffer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirbagher Ajorpaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="519" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Callchain software instruction prefetching in J2EE server applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nagpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Cain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Krintz</surname></persName>
		</author>
		<idno type="DOI">10.1109/PACT.2007.20</idno>
		<ptr target="http://doi.ieeecomputersociety.org/10.1109/PACT.2007.20" />
	</analytic>
	<monogr>
		<title level="m">16th International Conference on Parallel Architectures and Compilation Techniques (PACT 2007)</title>
		<meeting><address><addrLine>Brasov, Romania</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">September 15-19, 2007. 2007</date>
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The lru-k page replacement algorithm for database disk buffering</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.1145/170035.170081</idno>
		<ptr target="https://doi.org/10.1145/170035.170081" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data, ser. SIGMOD &apos;93</title>
		<meeting>the 1993 ACM SIGMOD International Conference on Management of Data, ser. SIGMOD &apos;93<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Optimizing function placement for large-scale data-center applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ottoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Maher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/ACM International Symposium on Code Generation and Optimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Evaluating stream buffers as a secondary cache replacement</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 21 International Symposium on Computer Architecture</title>
		<meeting>21 International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Bolt: A practical binary optimizer for data centers and beyond</title>
		<author>
			<persName><forename type="first">M</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization</title>
		<meeting>the 2019 IEEE/ACM International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="2" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Renaissance: Benchmarking suite for parallel applications on the jvm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prokopec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ros?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leopoldseder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Duboscq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>T?ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Studener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bulej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Villaz?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>W?rthinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Binder</surname></persName>
		</author>
		<idno type="DOI">10.1145/3314221.3314637</idno>
		<ptr target="https://doi.org/10.1145/3314221.3314637" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="31" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A case for mlp-aware cache replacement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd International Symposium on Computer Architecture (ISCA&apos;06)</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="167" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The v-way cache: demandbased associativity via global replacement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd International Symposium on Computer Architecture (ISCA&apos;05)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="544" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Adaptive insertion policies for high performance caching</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Steely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
		<idno type="DOI">10.1145/1250662.1250709</idno>
		<ptr target="https://doi.org/10.1145/1250662.1250709" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual International Symposium on Computer Architecture, ser. ISCA &apos;07</title>
		<meeting>the 34th Annual International Symposium on Computer Architecture, ser. ISCA &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="381" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Code layout optimizations for transaction processing workloads</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larriba-Pey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1145/379240.379260</idno>
		<ptr target="https://doi.org/10.1145/379240.379260" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International Symposium on Computer Architecture, ser. ISCA &apos;01</title>
		<meeting>the 28th Annual International Symposium on Computer Architecture, ser. ISCA &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Data cache management using frequency-based replacement</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Devarakonda</surname></persName>
		</author>
		<idno type="DOI">10.1145/98460.98523</idno>
		<ptr target="https://doi.org/10.1145/98460.98523" />
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS Perform</title>
		<imprint>
			<date type="published" when="1990-04">Apr. 1990</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="134" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A cost-effective entangling prefetcher for instructions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jimborean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="99" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Tejas: A java based versatile micro-architectural simulator</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Sarangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kalayappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kallurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Peter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 25th International Workshop on Power and Timing Modeling, Optimization and Simulation</title>
		<imprint>
			<publisher>PATMOS</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">The evictedaddress filter: A unified mechanism to address both cache pollution and thrashing</title>
		<author>
			<persName><forename type="first">V</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<idno type="DOI">10.1145/2370816.2370868</idno>
		<ptr target="https://doi.org/10.1145/2370816.2370868" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;12</title>
		<meeting>the 21st International Conference on Parallel Architectures and Compilation Techniques, ser. PACT &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A case for (partially) tagged geometric history length branch prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
		<ptr target="http://www.jilp.org/vol8/v8paper1.pdf" />
	</analytic>
	<monogr>
		<title level="j">J. Instr. Level Parallelism</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Applying deep learning to the cache replacement problem</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352460.3358319</idno>
		<ptr target="https://doi.org/10.1145/3352460.3358319" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52</title>
		<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="413" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Eelru: Simple and effective adaptive page replacement</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Smaragdakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1145/301453.301486</idno>
		<ptr target="https://doi.org/10.1145/301453.301486" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, ser. SIGMETRICS &apos;99</title>
		<meeting>the 1999 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, ser. SIGMETRICS &apos;99<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="122" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Softsku: Optimizing server architectures for microservice diversity @scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dhanotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Inter-reference gap distribution replacement: An improved replacement algorithm for set-associative caches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hiraki</surname></persName>
		</author>
		<idno type="DOI">10.1145/1006209.1006213</idno>
		<ptr target="https://doi.org/10.1145/1006209.1006213" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual International Conference on Supercomputing, ser. ICS &apos;04</title>
		<meeting>the 18th Annual International Conference on Supercomputing, ser. ICS &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="20" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Active management of data caches by exploiting reuse information</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1244" to="1259" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Perceptron learning for reuse prediction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Teran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 49th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A spatial and temporal locality-aware adaptive cache design with network optimization for tiled many-core architectures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2419" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Using the compiler to improve cache replacement decisions</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings.International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>.International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Modified lru policies for improving secondlevel cache behavior</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Baer</surname></persName>
		</author>
		<idno>PR00550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings Sixth International Symposium on High-Performance Computer Architecture. HPCA-6</title>
		<meeting>Sixth International Symposium on High-Performance Computer Architecture. HPCA-6</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="49" to="60" />
		</imprint>
	</monogr>
	<note type="report_type">Cat. No.</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Ship: Signature-based hit predictor for high performance caching</title>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hasenplaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Steely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
		<idno type="DOI">10.1145/2155620.2155671</idno>
		<ptr target="https://doi.org/10.1145/2155620.2155671" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-44</title>
		<meeting>the 44th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-44<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="430" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Compiler managed micro-cache bypassing for high performance epic processors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rakvic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chrysos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">35th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="134" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Less reused filter: Improving l2 cache performance via filtering less reused lines</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1542275.1542290</idno>
		<ptr target="https://doi.org/10.1145/1542275.1542290" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Supercomputing, ser. ICS &apos;09</title>
		<meeting>the 23rd International Conference on Supercomputing, ser. ICS &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="68" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Two-level adaptive training branch prediction</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<idno type="DOI">10.1145/123465.123475</idno>
		<ptr target="https://doi.org/10.1145/123465.123475" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Microarchitecture, ser. MICRO 24</title>
		<meeting>the 24th Annual International Symposium on Microarchitecture, ser. MICRO 24<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="51" to="61" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
