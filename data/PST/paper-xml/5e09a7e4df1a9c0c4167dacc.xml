<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Attention-Based Dual-Source Spatiotemporal Neural Network for Lightning Forecast</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tianyang</forename><surname>Lin</surname></persName>
							<idno type="ORCID">0000-0002-1228-8385</idno>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingyong</forename><surname>Li</surname></persName>
							<idno type="ORCID">0000-0002-3860-4809</idno>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Yangli-Ao</forename><surname>Geng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Lei</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liangtao</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Don</forename><surname>Zheng</surname></persName>
							<idno type="ORCID">0000-0002-7573-424X</idno>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wen</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weitao</forename><surname>Lyu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yijun</forename><surname>Zhang</surname></persName>
							<idno type="ORCID">0000-0002-7573-424X</idno>
							<affiliation key="aff0">
								<orgName type="institution">University</orgName>
								<address>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Attention-Based Dual-Source Spatiotemporal Neural Network for Lightning Forecast</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/ACCESS.2019.2950328</idno>
					<note type="submission">Received September 8, 2019, accepted October 15, 2019, date of publication October 29, 2019, date of current version November 12, 2019.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>INDEX TERMS Deep learning</term>
					<term>lightning forecast</term>
					<term>spatiotemporal data mining</term>
					<term>convolutional neural network</term>
					<term>channel-wise attention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accurate lightning forecast is significant for disaster prevention and reduction. However, the mainstream lightning forecast methods, which mainly rely on numerical simulations and parameterizations, can hardly cope with the spatiotemporal deviations. Meanwhile, the rapid and complex evolution of lightning regions go beyond the traditional extrapolation-based forecast methods. In this work, we propose a data-driven neural network model for hourly lightning forecast, which exploits both the numerical simulations and the recent historical lightning observations. The two kinds of data complement each other and play different roles at different stages of the forecast. The use of dual-source data greatly increases the amount of information available to improve the forecasting performance. To handle the variability of deviation patterns in numerical simulations, we introduce a channel-wise attention mechanism, which adaptively adjusts the proportion of each simulated parameter to maximize the useful information. The attention mechanism also enables the model to reveal the contribution of each simulated parameter for the forecast. Experimental results on a real-world dataset show that the proposed method outperforms several baseline methods. Ablation studies further demonstrate the effectiveness of our data fusion approach and attention module.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Lightning not only has destructive power to communication systems and electrical infrastructures, but also brings a serious threat to the safety of human life. In addition, lightning is often accompanied by extreme weather such as heavy rain, squally winds and hail, causing floods, landslides and other disasters. Due to these facts, there is always a great demand for effective high-resolution forecasts of lightning activities, which can help reduce risks in time.</p><p>It is a fundamental approach to forecast weather phenomena by extrapolating from recent trends. As the performance The associate editor coordinating the review of this manuscript and approving it for publication was Hualong Yu . of real-time lightning detection system improves, relatively precise lightning location data become readily available. These data contain valuable information for predicting future lightning occurrences. However, although extrapolationbased methods for weather nowcasting <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref> can be migrated to lightning forecast tasks, they encounter rapid decline in forecasting accuracy beyond two to three hours because of the complex evolution of the lightning region. Unlike stable precipitation weather systems, the movement and development trends of severe convective weather systems tend to change obviously in a much shorter period of time.</p><p>Another way to forecast lightning is to infer from other meteorological factors provided by numerical simulations. The past years have seen wide application of numerical weather prediction (NWP) systems in operational services. Taking original meteorological observations and background field data as initial conditions, the NWP systems solve a series of partial differential equations to simulate parameters that denote future atmospheric dynamics and physical states. The values of these parameters have different degrees of correlation with the generation of lightning. To obtain the lightning density (or probability of occurrence) from these parameters, researchers have proposed a lot of lightning parameterization schemes <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b7">[8]</ref>. Unfortunately, the simulations of NWP systems have more or less deviations in both the spatial and temporal domains. These deviations introduce non-negligible, irreversible inaccuracy into parameterization schemes. Constrained by the intrinsic chaos of atmospheric partial differential equations, the deviations do not show obvious regularity, which makes it difficult to rectify various cases by a specific algorithm.</p><p>With the above two routes combined, it is natural to consider the fusion of recent lightning observations and numerical simulations (Fig. <ref type="figure" target="#fig_0">1</ref>). The former carries recent development trends of lightning, which are important initial conditions for the forecast. The latter provides the information of the atmospheric states corresponding to the forecast time, giving more direct references to the forecast. Besides, recent observations have correction effects on the deviations of numerical simulations.</p><p>Deep learning has shown impressive capability in complex correlation modeling and heterogeneous data fusion. In particular, the recurrent neural network (RNN) captures the sequential correlations while the convolutional neural network (CNN) extracts spatial features. The encoder-decoder structure facilitates sequence-to-sequence (Seq2Seq) conversion between data series with different lengths <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>. Since both recent lightning observations and numerical simulations can be organized in the form of spatiotemporal data grids, lightning forecasts can be easily implemented by deep learning methods. The powerful nonlinear expression ability of deep neural networks helps characterize the variable motion trends of weather systems and intricate interactions between different simulated parameters. Furthermore, different from the artificial lightning parameterization schemes, neural network can automatically extract features, which is helpful to discover more effective feature combinations for lightning forecasts. Nonetheless, in our task, the characteristics of data pose a higher requirement for model design. First, the development trends of thunderstorms usually change rapidly. As the forecast proceeds, the difference between historical and actual trends of lightning will gradually widen, making the correction effect on simulation deviation limited to the early stage of the forecast. Second, although lightning is the result of multiple factors, it tends to be more closely related to some of them <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. The more complicated fact is that the contribution of a certain parameter to the lightning also varies with conditions such as season, terrain, stage of thunderstorm development and type of weather system <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b19">[20]</ref>. The naive deep learning models are short of specialized means to deal with the above problems. Therefore, more effective approaches are needed to achieve more accurate forecasts.</p><p>To tackle the aforementioned challenges, we propose an attention-based dual-source spatiotemporal neural network (ADSNet) that aims at forecast hourly lightning occurance over the next 12 hours. In ADSNet, an RNN encoder is utilized to model the spatiotemporal information of the recent observations. The encoded information is then fed into an RNN decoder as the initial states. In each decoding step, the decoder receives the states of the last step along with the NWP simulation for this step. This is feasible thanks to the hour-to-hour correspondence between the NWP simulations and the forecast results. Such a setting maintains the temporal continuity of data flow between the encoder and the decoder. Moreover, drawing on the creativity of the previous attention mechanisms <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b23">[24]</ref> and the depthwise convolution <ref type="bibr" target="#b24">[25]</ref>, we devise an channel-wise attention module. During the whole decoding stage, it adaptively enhances the influence of the useful NWP parameters and indirectly makes up for the deviation of the numerical simulations. The attention weights reflect the contribution of each NWP parameter quantitatively, which provides references for the research into lightning.</p><p>In summary, our primary contributions in this paper are as follows:</p><p>• We propose a dual-source neural network for hourly lightning forecast. It leverages the strengths of conventional RNN and Seq2Seq structure to combine the information of recent lightning observations and numerical simulations, overcoming the defect of existing methods that just rely on a single type of data.</p><p>• We introduce a channel-wise attention mechanism into our model, which automatically adjusts the influences of different simulated parameters during forecasts. It improves the forecasting accuracy as well as enhances the interpretability of the model.</p><p>• We conduct experiments on the real-world North China lightning dataset. Experimental results demonstrate the efficacy of the data fusion method and the attention mechanism.</p><p>The remainder of this paper is organized as follows. Section II discusses the related works. Section III formulates the lightning forecast problem and details the proposed model. In section IV, we first describe the dataset and the selected simulated parameters, then we present experimental results. The paper is concluded in section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. EXISTING LIGHTNING FORECAST METHODS</head><p>The main approach of lightning forecasting is to use lightning parameterization schemes. These schemes are contrived on the basis of the correlations between lightning and other meteorological factors. Early researchers Price and Rind <ref type="bibr" target="#b5">[6]</ref> proposed the famous PR92 scheme which discovers the relation between maximum vertical velocity and lightning frequency. In <ref type="bibr" target="#b25">[26]</ref>, a formula is proposed for converting the radar reflectivity at two height levels to the flash rates. Considering the instability of the height of the charging bands, Wang et al. <ref type="bibr" target="#b7">[8]</ref> improved the above scheme by replacing the radar reflectivity from height levels to temperature levels. Lynn and Yair <ref type="bibr" target="#b6">[7]</ref> proposed Lightning Potential Index (LPI) that calculated from the max mixing ratio of snow, cloud ice, and graupel. But they did not provide a direct way to acquire lightning density. McCaul et al. <ref type="bibr" target="#b4">[5]</ref> proposed two threats that can be converted to the total flash rates by reasonable thresholds. The first threat is represented as a function of the product of the maximum vertical wind speed and graupel mixing ratio. The second threat is jointly obtained from the mixing ratio of ice, snow and graupel. Nevertheless, due to the insufficient expression ability of these existing lightning parameterization schemes, their accuracy remains to be enhanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DEEP LEARNING APPLICATIONS ON SPATIOTEMPORAL DATA</head><p>Many works have witnessed the comparable performance of deep learning on spatiotemporal data mining and prediction. For example, FCN-rLSTM <ref type="bibr" target="#b26">[27]</ref> uses a fully convolutional network followed by a Long Short-Term Memory network (LSTM) <ref type="bibr" target="#b27">[28]</ref> to estimate vehicle density and vehicle count from monitoring videos. ST-ResNet <ref type="bibr" target="#b28">[29]</ref> uses convolutional layers and residual units to predict future traffic from periodic historical data. In StepDeep <ref type="bibr" target="#b29">[30]</ref>, a series of 3D convolution <ref type="bibr" target="#b30">[31]</ref> filters that are sensitive to different dimensions are assembled to predict mobile events in the city. Shi et al. <ref type="bibr" target="#b0">[1]</ref> proposed convolutional LSTM (ConvLSTM) for precipitation nowcasting. As a landmark structure, ConvLSTM is used as a base module in many subsequent works. In MCnet <ref type="bibr" target="#b31">[32]</ref>, a CNN-ConvLSTM motion encoder and a CNN content encoder cooperate to predict future frames in video sequences. In PredRNN <ref type="bibr" target="#b2">[3]</ref>, a vertical data flow is added in the stacked ConvLSTM, making the model better at learning spatial deformations. In <ref type="bibr" target="#b32">[33]</ref>, 3D convolutional layers and ConvLSTM layers are arranged in one network to learn short-term and long-term spatiotemporal features of gestures from vedios, respectively. Similar design appears in <ref type="bibr" target="#b33">[34]</ref> for travel demand prediction. These works provide us with the basic ideas of proposing an appropriate model to fill the gap of deep learning in hourly lightning forecast.</p><p>The invention of attention mechanism benefits from the way humans observing unknown things: Focusing more on partial of the object to get more critical information. Previous works show a variety of design strategies for attention mechanisms. In <ref type="bibr" target="#b20">[21]</ref>, attention mechanism is introduced into image captioning. When generating each caption word, the LSTM decoder always selects the spatial feature maps that are highly semantic-related to the current description. Also designed for image captioning, the SCA-CNN <ref type="bibr" target="#b23">[24]</ref> employs channel-wise attention to select semantic attributes. In <ref type="bibr" target="#b21">[22]</ref>, researchers proposed a two-stage attention model for time series prediction with exogenous driving series. The first attention is used to adaptively select useful driving series. The second attention is used to select relevant encoder hidden states across the time steps. Chen et al. <ref type="bibr" target="#b22">[23]</ref> presented a similar dual-attention model. The first attention extracts effective information from internal and external features while the second attention uses a sliding time step window to find the best matching pattern of the current predicted trend from the historical sequence. Shao et al. <ref type="bibr" target="#b9">[10]</ref> added the target-side attention to a Seq2Seq conversation response generation model, which makes up for the difficulty of encoder-decoder model to generate long predictions sequences. We are greatly inspired by the above works. In our model, the decoder incorporates an input attention mechanism adapted for high-dimensional, downsampled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head><p>In this section, we first define the hourly lightning forecast problem with notations. Then we give detailed description of the proposed model. Finally, the training method is introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. PROBLEM FORMALIZATION</head><p>In the lightning forecast scenario of this work, the forecasting area is divided into a grid of h rows and w columns. The side length of each grid cell serves as the spatial resolution of the forecast. Both recent observations, NWP simulations and forecast results are stored in data grids of the same spatial size. The goal is to predict whether lightning will occur in each grid cell within each hour. Suppose we make forecast for p hours, starting at time t = 0. We employ</p><formula xml:id="formula_0">{X t } p−1 t=0 = {X 0 , X 1 , . . . X p−1 } to represent the NWP simulation sequence of p hours, where X t = {X (1) t , X (2) t , . . . , X (m) t } ∈ R h×w×m .</formula><p>Here, m is the number of channels and each channel corresponds to a parameter or one height level of a parameter (see Table <ref type="table" target="#tab_2">2</ref>). We use </p><formula xml:id="formula_1">{V t } −1 t=−q = {V −q , V −q+1 , . . . , V −1 } to denote recent observations, in which V t ∈ R h×w records</formula><formula xml:id="formula_2">{ Ŷt } p−1 t=0 = F {X t } p−1 t=0 , {V t } −1 t=−q .<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MODEL ARCHITECTURE</head><p>As illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, the ADSNet mainly contains a pair of RNN encoder-decoder, multiple CNN modules, deconvolution neural network (DCNN) modules and attention modules. We implement the RNNs by convolutional LSTM (Con-vLSTM), for it specializes in capturing the long-term spatiotemporal dependencies. On the basis of LSTM, ConvL-STM replaces the inner product operations with convolution operations. In ConvLSTM, the update to gates and states at each time step can be summarized as:</p><formula xml:id="formula_3">i t = σ (W xi * X t + W hi * H t−1 + b i ) f t = σ (W xf * X t + W hf * H t−1 + b f ) o t = σ (W xo * X t + W ho * H t−1 + b o ) C t = f t • C t−1 + i t • tanh(W xc * X t + W hc * H t−1 + b c ) H t = o t • tanh(C t ) (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where * is the convolution operation </p><formula xml:id="formula_5">H t−1 , C t−1 .</formula><p>The ConvLSTM in this paper does not include peephole connections, as mentioned in <ref type="bibr" target="#b0">[1]</ref>. The data first enters the CNN modules, where sequentially arranged 2D convolutional layers expand the receptive field and enhance the presentation capabilities of the network. ReLU activations are applied after each convolution operation. Maximum pooling layers are used to reduce the spatial size of data and relieve the burden on model training. Since the data grids have high spatial resolution, and adjacent grid cells usually have similar values, the downsampling-generated information loss is tolerable. We distribute the same CNN modules to each time step of the encoding or decoding process, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. In CNN Module 1, we use two sets of convolution-pooling layers to extract the spatial features of the recent lightning observations. The obtained sequence of feature maps can be expressed as:</p><formula xml:id="formula_6">{E} −1 t=−q = CNN 1 ({V } −1 t=−q ),<label>(3)</label></formula><p>where E t ∈ R h ×w ×c 2 , h = (1/4)h, w = (1/4)w and c 2 equals to the number of filters in Conv2D 2 . These feature maps are then served as the input of the ConvLSTM encoder. We take the states of the final time step:</p><formula xml:id="formula_7">[H −1 , C −1 ] = Encoder({E} −1 t=−q ). (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>The information about recent movements, growths or shrinks of lightning regions is encapsulated in contextual tensors H −1 and C −1 , which we intend to feed into the decoder as the initial states. However, the decoder is set to have more filters than the encoder since it takes the multichannel NWP simulations as input, which contain much wealthier available information than the recent lightning observations. To solve this problem, we leverage 1 × 1 convolutional layers as a bridge between the encoder and the decoder that realize the elevation of channel numbers, which is formulated as:</p><formula xml:id="formula_9">D −1 = Conv2D 4 (H −1 ), L −1 = Conv2D 3 (C −1 ),<label>(5)</label></formula><p>here, D −1 ∈ R h ×w ×c 4 and L −1 ∈ R h ×w ×c 3 are respectively the initial hidden state and cell state of the decoder. c 4 is the</p><formula xml:id="formula_10">VOLUME 7, 2019</formula><p>number of filters in Conv2D 4 and c 3 is the numbers of filters in Conv2D 3 . On the other side, the numerical simulations are transformed as follows in CNN module 2:</p><formula xml:id="formula_11">{A} p−1 t=0 = CNN 2 ({ X } p−1 t=0 ),<label>(6)</label></formula><p>where Xt ∈ R h×w×m is the weighted simulation of time step t. The weights are generated by the attention module which is detailed in subsection III-C. A t ∈ R h ×w ×c 6 is the feature map and c 6 is the number of filters in Conv2D 6 .</p><p>The information of the recent lightning observations and the numerical simulations is fused in the decoder, which outputs the hidden state at each time step:</p><formula xml:id="formula_12">{D} p−1 t=0 = Decoder({A} p−1 t=0 , D −1 , L −1 ). (<label>7</label></formula><formula xml:id="formula_13">)</formula><p>A deconvolution module is deployed at each time step to restore the spatial size of the data. The upsampling operation is performed by two deconvolution layers with stride of 2. A 1 × 1 convolutional layer is followed to reduce the number of channels. The single-channel prediction is finally converted into probability value by the softmax function. The above process can be formulated as:</p><formula xml:id="formula_14">{ Ŷ } p−1 t=0 = softmax((DCNN ({D} p−1 t=0 ))).<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CHANNEL-WISE ATTENTION</head><p>Referring to previous works <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b23">[24]</ref>, we introduce a channel-wise attention mechanism into our model. Motivation. The channel-wise attention provides an adaptive method to improve the accuracy of the forecast. In convolution operation, a specific set of weights is used to fuse the information of each channel. Once the network is trained, the weights are fixed and no longer change. However, the effect of each NWP parameter usually varies in different cases (a case refers to a p-hour forecast), as these cases span different seasons and different stages of thunderstorm evolution. For example, in one case, the high concentration of graupel particles may constitute the main reason for lightning excitation, while the strong updraft may become the most prominent feature in another case. The accuracy of the numerical simulation itself is also changing. For instance, the simulation of the ice particles could be more reliable in the first six hours, while the simulation of snow particles may be more accurate in the last six hours. Therefore, it is meaningful to set different weights for different channels in each singlestep forecast to amplify the more valuable information. The attention mechanism also enhances the interpretability of the model and provide reference for lightning research. The model utilizes a series of simulated parameters to forecast lightning. We look forward to seeing how these parameters play their respective roles in the forecast. With channel-wise attention, the model outputs attention weights that reflect the importance of each parameter (or each height level of a parameter) for the forecast.</p><p>Implementation. The attention weights are obtained at each time step, by calculating the degree of matching between the simulation data with the last RNN states. Before that,  we first converted the simulation data to feature maps with the same spatial size as the RNN states. In order to maintain the independence of each channel, we use depthwise convolution instead of conventional convolution here. Fig. <ref type="figure" target="#fig_2">3</ref> illustrates the difference between the two types of convolutions. The depthwise convolution is actually the first stage of the depthwise separable convolution <ref type="bibr" target="#b24">[25]</ref>: Each convolution kernel is only responsible for one channel and there are no fusion operations between channels. The entire workflow of the attention module is shown in Fig. <ref type="figure" target="#fig_3">4</ref>. X t ∈ R h×w×m is the raw simulation data of time step t and A t ∈ R h ×w ×m is the downsampled feature map. To eliminate the influence of different orders of magnitude, the X t here is scaled in the channel dimension by Min-max normalization. We take the hidden state D t−1 ∈ R h ×w ×c 4 and cell state L t−1 ∈ R h ×w ×c 3 of the last time step t − 1. The attention weights α t = {α</p><formula xml:id="formula_15">(1) t , α<label>(2)</label></formula><p>t , . . . , α (m) t } are calculated as follows:</p><formula xml:id="formula_16">A t = CNN att (X t ),<label>(9) e</label></formula><formula xml:id="formula_17">(i) t = (W att * [D t−1 ; L t−1 ]) • (U (i) att A (i) t ) ,<label>(10)</label></formula><formula xml:id="formula_18">α (i) t = softmax( e (i) t √ hw ),<label>(11)</label></formula><p>where i = 1, 2, . . . , m, * denotes the conventional convolution and denotes the depthwise convolution. W att ∈ R h ×w ×(c 4 +c 3 ) and U att ∈ R h ×w ×m are learnable weights. The bias terms are omitted in <ref type="bibr" target="#b9">(10)</ref>. • is Hadamard product and refers specifically here to the summation of all elements of the vector. According to <ref type="bibr" target="#b36">[37]</ref>, we scale the weights before normalizing them to avoid getting values into the saturation region of the softmax function, as shown in <ref type="bibr" target="#b10">(11)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applying the attention weights, we get the new input</head><formula xml:id="formula_19">Xt = {α (1) t X (1) t , α (2) t X (2) t , . . . , α (m) t X (m)</formula><p>t }. In this way, the attention module calculates a set of weights at each time step. At the moment t = 0, all information in the RNN states comes from the recent lightning observations. As time goes on, the simulation data gradually predominates the main information source. The effective information screened by the attention mechanism can be transmitted continuously over time. Thus, the overall forecast performance can be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. TRAINING PROCEDURE</head><p>In our dataset, the grid cells without lightning far outnumber those with lightning. In order to balance the influence of positive samples and negative samples, we take the weighted binary cross entropy as the loss function. The loss of a case (a p-hour forecast) is expressed as:</p><formula xml:id="formula_20">loss(Y , Ŷ ) = − p−1 t=0 w j=1 h i=1 βY i,j,t log( Ŷi,j,t ) + (1 − Y i,j,t ) log(1 − Ŷi,j,t ), (<label>12</label></formula><formula xml:id="formula_21">)</formula><p>where β is the weight of positive samples. We tune β in {10, 15, 20, 25, 30, 35} and find that the optimal value is 25.</p><p>We select the Adaptive Moment Estimation (Adam) <ref type="bibr" target="#b37">[38]</ref> optimizer. The learning rate is initialized to 0.0001 and does not decay during the training process. The parameter settings of each layer in the network are listed in Table <ref type="table" target="#tab_1">1</ref>. The model is implemented in Keras 1 2.2.4 and experiments are run on Ubuntu 16.04 with an NVIDIA TITAN X GPU. The code is available at https://github.com/geolvr/ADSNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we first give a description of the selected datasets. Next, we introduce the evaluation metrics of our experiments. Then we compare our model against several baseline methods by quantitative experimental results. We visualize a few cases of lightning forecasts as an intuitively complement to numerical results. Finally, we verify the validity of each module of our model.</p><p>1 https://keras.io We choose parameters that are closely related to lightning <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>: the mixing ratio of ice, snow and graupel, the maximum vertical wind speed and precipitation.</p><p>A detailed description of the selected parameters is shown in Table <ref type="table" target="#tab_2">2</ref>. Observation Data. Our lightning observations are derived from the Cloud-to-Ground Lightning Location System (CGLLS) operated by the State Grid Corporation of China <ref type="foot" target="#foot_2">3</ref> . The raw data mainly describes the time and location of each lightning strike. We convert them into data grids with the same spatial size and temporal interval as the WRF data. Each grid cell records the hourly accumulated number of lightning occurrences within a 4km × 4km scope. We take the recent three hours of lightning observations for every 12-hour forecast.</p><p>We select all available data from three time periods as our training data: June to September 2015, May to September 2016 and May to June 2017. We use data from August to September 2017 to evaluate the performance of our model. To be consistent with the real scenario, we choose to evaluate the 12-hour periods starting at 0:00, 6:00, 12:00 and 18:00 (UTC) every day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. EVALUATION METRICS</head><p>Our evaluation metrics include four types of commonly used skill-scores in meteorological forecasts <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>: probability of detection (POD), false alarm ratio (FAR), threat score (TS) and equitable threat score (ETS). Among them, TS and ETS are comprehensive scores, where larger value represents better performance. TS is defined as the ratio of numbers of hit events to the number except true-negative events. On the basis of TS, ETS excludes the effect of hit events that occur by random chance. Let TP, FP, FN and TN represent the number of true-positive, false-positive, falsenegative and true-negative grid cells respectively. The above metrics are calculated as:</p><formula xml:id="formula_22">POD = TP (TP + FN) ,<label>(13)</label></formula><formula xml:id="formula_23">FAR = FP (TP + FP) ,<label>(14)</label></formula><formula xml:id="formula_24">TS = TP (TP + FP + FN) ,<label>(15)</label></formula><formula xml:id="formula_25">ETS = TP − R TP + FP + FN − R ,<label>(16)</label></formula><p>where R = (TP+FP)(TP+FN) (TP+FP+FN+TN) . However, these metrics are too strict for forecasts on grids with high spatial resolution. We adopt the neighborhood-based metrics <ref type="bibr" target="#b40">[41]</ref> as a supplement. It loosens the criteria for the hit events to the range of a circle. For example, in Fig. <ref type="figure" target="#fig_4">5</ref>(a), the center grid cell is considered a hit rather than a false alarm because an observation occurs in the neighborhood. In turn, in Fig. <ref type="figure" target="#fig_4">5</ref>(b), the center grid cell is also a hit rather than a miss because there exists forecasted lightning in the neighborhood. The results given by the neighborhood method are reasonable because appropriate position error is acceptable for lightning forecasts.</p><p>When evaluating each case, we use cumulative results of multiple hours. In other words, suppose we calculate a 12-hour cumulative result, lightning that observed (or be forecasted to occur) at any time during the 12-hour period will be recorded only once. When evaluating multiple cases, we first accumulate TP, FP, FN, TN of each case and then calculate the overall metrics once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. BASELINE METHODS</head><p>We compare ADSNet with the following methods, including two lightning parameterization schemes, a representative machine learning model and a novel spatiotemporal deep neural network. To verify the effectiveness of the network components, we also explore several variations of ADSNet and compare their performance.</p><p>PR92. The lightning parameterization scheme PR92 <ref type="bibr" target="#b5">[6]</ref> depicts the relationship between the lightning flash rate and vertical windspeed. A formula is given as:</p><formula xml:id="formula_26">F = 5.7 × 10 −6 w 4.5 max ,<label>(17)</label></formula><p>where F is the lightning frequency (min −1 ) and w max is the maximum vertical velocity. Threat F2. Threat F2 is one of the state of the art lightning parameterization methods in the field of meteorology <ref type="bibr" target="#b4">[5]</ref>. It poses a lightning threat that calculated as:</p><formula xml:id="formula_27">F 2 = 0.2 ρ(i z + s z + g z )dz, (<label>18</label></formula><formula xml:id="formula_28">)</formula><p>where ρ is the local air density. i z , s z , g z are mixing ratios of ice, snow and graupel at height level z, respectively. The threat can be converted into flash rate by a threshold = 0.40 <ref type="bibr" target="#b4">[5]</ref>.</p><p>GBDT. The Gradient Boost Decision Tree (GBDT) is a kind of common method in supervised learning. We choose LightGBM<ref type="foot" target="#foot_3">4</ref> 2.0.4 to implement GBDT. We take single grid cell as sample and extract samples from the entire 159×159 grid. We take the WRF simulations of a neighborhood around the sample grid cell as features. The simulated parameters used are the same as those listed in Table <ref type="table" target="#tab_2">2</ref>, but recent lightning observations are not involved.</p><p>StepDeep.</p><p>StepDeep is a newly-proposed deep neural network that achieves good performance in predicting spatiotemporal mobility events <ref type="bibr" target="#b29">[30]</ref> ADSNet-W. The encoder is removed in this variant of ADSNet. In contrast to ADSNet-O, all the information required for the forecast is provided only by the numerical simulations. This model does not include an attention module.</p><p>ADSNet-Plain. In ADSNet-Plain, all components of ADSNet are retained except the attention module. The decoder directly takes the unweighted simulation data as its input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. ANALYSIS OF NUMERICAL RESULTS</head><p>We evaluate the cumulative results of the total 12 hours, the first six hours and the last six hours for all methods. Table <ref type="table" target="#tab_3">3</ref> shows the numerical experimental results of our method and baselines. It can be seen that the two lightning    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. ANALYSIS OF ATTENTION WEIGHTS</head><p>The attention mechanism is expected to hold a valid explanation for the contributions of numerical parameters in addition to improving the forecasting performance. We summarize the average attention weights generated by ADSNet over all test cases, as shown in Table <ref type="table" target="#tab_4">4</ref>. We mark the five parameters (or height levels of parameters) with the largest weights in bold. The maximum vertical wind speed and graupel mixing ratio occupy most of the weights. These two parameters are exactly meteorological factors leveraged by the lightning parameterization schemes threat F1 <ref type="bibr" target="#b4">[5]</ref> and PR92 <ref type="bibr" target="#b5">[6]</ref>.</p><p>Research has found that the content of ice-phase particles in different temperature layers is related to lightning occurance to varying degrees. Specifically, temperature layers between −10 • C to −20 • C are considered the most relevant <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. We test the consistency of the attention weights with this conclusion. The correspondence between height levels and temperature layer in WRF changes with topography and seasons. So we first calculate the distribution of temperature levels at different locations in each test case. We get the frequency histogram (Fig. <ref type="figure" target="#fig_7">6</ref>) of the temperature distribution on the fifth height level. It can be seen that the  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. CASE VISUALIZATION</head><p>To illustrate the effect of the proposed method more concretely, we visualize several representative 12-hour lightning forecast cases. In Fig. <ref type="figure" target="#fig_8">7</ref>, the first three cases show the stable development, shrink and expansion of the lightning regions. The last case shows different evolution patterns of multiple lightning regions. can be seen that ADSNet-O simply extends the recent movements of the lightning region and makes almost no forecasts after the hour 5. In contrast, ADSNet-W is less accurate in the first few hours than other models due to the lack of the rectifying effect of recent observations. These two models reflect the limitation of single data source. The dual-source models ADSNet-Plain and ADSNet have similar forecasting capacity in the first six hours. However, the difference becomes apparent in the following hours. In case 1, ADSNet-Plain loses the track of the lightning region since hour 6, while ADSNet keeps giving lightning positions that are generally consistent with observation till the forecast ends. In case 2, the lightning region given by ADSNet-Plain vanishes too early. Oppositely, ADSNet estimates the speed of lightning evolution more accurately. The forecast of ADSNet-Plain breaks in the middle hours in case 3, which does not occur on ADSNet. Case 4 shows a more complicated situation. From hour 4 to hour 5, a new lightning region develops in the middle of the forecast region. Obviously, the information about it cannot be derived from recent observations. ADSNet captures its birth while ADSNet-Plain is almost completely unaware of it, which suggests that the attention mechanism does extract more critical information from the WRF simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we proposed an attention-based dual-source spatiotemporal neural network (ADSNet) for 12-hour lightning forecast. The model draws on the advantage of the RNN encoder-decoder structure, combining the information from recent lightning observations and numerical simulations to improve the accuracy of the forecast. We also deployed a channel-wise attention mechanism on our model to adaptively enhance the valuable information carried in the simulation data during the forecasting process. The attention mechanism not only upgrades the forecasting performance, but also endows the model with interpretability for the contributions of various inputted meteorological parameters. Experimental results on the real-world North China lightning dataset demonstrate the superiority of our model against the baseline methods. In future research, we will extend the current work to further forecast the intensity and frequency of lightning. From a longer perspective, we will explore the use of our framework to forecast other extreme weather such as hail and hurricane.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 .</head><label>1</label><figDesc>FIGURE 1. The framework of dual-source lightning forecast based on recent lightning observations and numerical simulations.</figDesc><graphic url="image-3.png" coords="2,38.78,66.81,237.71,123.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 2 .</head><label>2</label><figDesc>FIGURE 2. The overall structure of the proposed model. ConvLSTM is abbreviated as CLSTM in this figure. Rounded rectangles represent layers while arrows indicate data flows. The encoder-decoder structure in temporal (horizantal) direction inherits the idea of extrapolating lightning occurrence from recent observations. The decoder also takes NWP simulation data as its input at each time step. The red part marks the attention module. The CNN and DCNN modules extract spatial features and realize the spatial scaling.</figDesc><graphic url="image-6.png" coords="4,34.65,66.06,510.47,171.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 3 .</head><label>3</label><figDesc>FIGURE 3. Conventional convolution vs. depthwise convolution.</figDesc><graphic url="image-8.png" coords="5,299.18,66.06,237.00,120.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 4 .</head><label>4</label><figDesc>FIGURE 4. Workflow of the attention module.</figDesc><graphic url="image-9.png" coords="5,296.72,218.54,241.05,104.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIGURE 5 .</head><label>5</label><figDesc>FIGURE 5. Examples of the neighborhood-based method. Suppose the grid cells are squares with side length = 4km. This figure shows neighborhoods with radius = 6km. The Color-filled cells denote the center of neighborhoods and the shadow show the range of neighborhoods. The red patterns mark observed lightnings and the blue patterns mark forecasted lightnings.</figDesc><graphic url="image-12.png" coords="7,76.94,65.30,159.93,92.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>. The highlight of StepDeep is the combination of 3D convolution kernels with different functions. We use StepDeep to extract WRF features, which are then fused with the recent lightning observations by CNNs to produce the final forecasts. We slightly adjust the structure of the original StepDeep to make it more suitable for 12-hour lightning forecasting task. More details are provided in our open source code. ADSNet-O. In this variant of ADSNet, only recent lightning observations are used to make forecasts. At each time step, the decoder receives the forecast result of the past hour as the input.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>parameterization schemes (PR92 and Threat F2) and GBDT are inferior to StepDeep, ADSNet and its variants in most metrics. The former three methods are based entirely on WRF data and have no compensation capability for the spatiotemporal deviations of the numerical simulations. Compared with GBDT, lightning parameterization schemes have worse performance because of their weak expression ability and high dependence on manual experiences. Also completely rely on WRF data, ADSNet-W outperforms GBDT, which reflects the advantage of deep learning methods in spatiotemporal data mining.For deep learning baselines, we can observe that methods relying on a single type of data have poor performance. ADSNet-W has a mediocre performance in the first six hours and its advantage in the last six hours is not enough to raise the overall forecast level. Like the three non deep learning methods, it suffers from the spatiotemporal deviations of the WRF simulations. ADSNet-O scores well in the first six hours, but its results of the subsequent hours show a complete failure. This is due to the fact that the development trends of lightning carried in recent observations rarely sustain for very long. The ADSNet-O simply extrapolates the trends that have deviated from the reality. During the training process, the ADSNet-O gradually learns to give completely no-lightning forecasts in the last six hours to reduce the punishment of false alarm by the weighted loss function. In comparison, the forecast levels of dual-source methods are higher. The StepDeep has better 12-hour cumulative scores than the two single-source deep learning models, but it lags behind ADSNet in TS, ETS and POD. Its disadvantage is particularly evident in the last six hours. Compared with StepDeep, ADSNet-Plain shows almost the same forecast level. It makes good forecast in the first six hours but does not perform well in the following hours. ADSNet achieves the best performance among all selected methods. It has competitive TS, ETS and POD on</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FIGURE 6 .</head><label>6</label><figDesc>FIGURE 6. Temperature distribution on the fifth height level of the WRF data. the 12-hour cumulative measurement. Compared to ADSNet-Plain, it experiences a slight drop in TS and ETS during the first six hours, while the POD still maintains an advantage. But it overtakes ADSNet-Plain in the last six hours. As analyzed in III-C, WRF simulation plays a major role in the later stage of the forecast. And ADSNet mainly focuses on the more crucial WRF parameters with the help of attention mechanism, therefore wins out in the last six hours.</figDesc><graphic url="image-14.png" coords="8,330.78,187.19,170.94,141.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>FIGURE 7 .</head><label>7</label><figDesc>FIGURE 7. Visualization of four forecast cases. In each case, the left-most column shows lightning observations of the recent three hours from top to bottom, where darker dots indicate higher lightning frequency. The three rows on the right, from top to bottom, are 12-hour forecasts made by ADSNet-O, ADSNet-W, ADSNet-Plain and ADSNet. The observations (lightning occurs or not), forecast results and hits are represented by red, blue, and green dots, respectively.</figDesc><graphic url="image-19.png" coords="9,52.13,522.94,470.40,126.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>temperatures are concentrated between −8 • c and −20 • C. which basically conforms to the existing conclusion. The above facts prove that our model is reasonably interpretable to the contribution of parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, • is the Hadamard product and σ (•) is the sigmoid function. i, f and o denotes the input gate, output gate and forget gate respectively. W and b are learnable weights and bias. The current hidden state H</figDesc><table /><note>t and cell state C t are generated by the current input X t and the previous states</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 .</head><label>1</label><figDesc>Detailed settings of layers in ADSNet.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 2 .</head><label>2</label><figDesc>Information about selected WRF parameters. The Weather and Forecasting (WRF) model is one of the state-of-the-art mesoscale numerical weather prediction (NWP) systems. We conduct experiments on WRF data<ref type="bibr" target="#b12">[13]</ref> of North China accessed from Chinese Academy of Meteorological Sciences 2 . Specifically, the data area is centered around 40 • N and 116.2 • E. It is composed of a grid with 159 rows and 159 columns, while each grid cell corresponding to a scope of 4km × 4km in the real world. Each data grid carries simulation results of different parameters. The WRF model performs hourly numerical simulation at 0:00, 6:00, 12:00, 18:00 (UTC) per day and each simulation covers the next 24 hours. We select 12-hour segments from the simulations as the training data.</figDesc><table><row><cell>A. DATASETS</cell></row><row><cell>WRF Simulation Data.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 .</head><label>3</label><figDesc>Numerical results.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 4 .</head><label>4</label><figDesc>Average attention weights over test cases.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">VOLUME 7, 2019   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">http://www.camscma.cn</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">http://www.sgcc.com.cnVOLUME 7, 2019   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://github.com/microsoft/LightGBM 158302 VOLUME 7, 2019</note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFC1501503, in part by the Beijing Municipal Education Commission Research Program under Grant SM20191001107 and Grant PXM2019_014213_000007, and in part by the National Social Science Foundation of China under Grant 18CSH019.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Convolutional LSTM network: A machine learning approach for precipitation nowcasting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">A short-term rainfall prediction model using multi-task convolutional neural networks,&apos;&apos; in Proc. ICDM</title>
				<imprint>
			<date type="published" when="2017-11">Nov. 2017</date>
			<biblScope unit="page" from="395" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PredRNN: Recurrent neural networks for predictive learning using spatiotemporal LSTMs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="879" to="888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">PredRNN++: Towards a resolution of the deep-in-time dilemma in spatiotemporal predictive learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
				<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2018-04">Apr. 2018</date>
			<biblScope unit="page" from="5110" to="5119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Forecasting lightning threat using cloud-resolving model simulations</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Mccaul</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Lacasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cecil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Weather Forecasting</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="709" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple lightning parameterization for calculating global lightning distributions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Geophys. Res., Atmos</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">D9</biblScope>
			<biblScope unit="page" from="9919" to="9933" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Prediction of lightning flash density with the WRF model</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Geosci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="11" to="16" />
			<date type="published" when="2010-02">Feb. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A lightning activity forecast scheme developed for summer thunderstorms in South China</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Meteorol. Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="631" to="640" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">'</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generating high-quality and informative conversation responses with sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Britz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
				<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017-01">Jan. 2017</date>
			<biblScope unit="page" from="2210" to="2219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sequence to sequence-Video to text</title>
		<author>
			<persName><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
				<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015-12">Dec. 2015</date>
			<biblScope unit="page" from="4534" to="4542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The tripole structure of thunderstorms</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Geophys. Res., Atmos</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">D11</biblScope>
			<biblScope unit="page" from="13151" to="13167" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simulation of the electrification of a tropical cyclone using the WRF-ARW model: An idealized case</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Meteorol. Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="468" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting the potential for lightning activity in Mediterranean storms based on the Weather Research and Forecasting (WRF) model dynamic and microphysical fields</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kotroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lagouvardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mugnai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L E</forename><surname>Morin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Geophys. Res</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">D4</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2010-02">Feb. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evaluation of lightning forecasting based on one lightning parameterization scheme and two diagnostic methods</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmosphere</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">99</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluating a lightning parameterization based on cloud-top height for mesoscale numerical model simulations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Noone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Geosci. Model Develop.</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="429" to="443" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting lightning activity in Greece with the Weather Research and Forecasting (WRF) model</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Giannaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kotroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lagouvardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmos. Res</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2015-04">Apr. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Performance evaluation of an explicit lightning forecasting system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dafis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fierro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Giannaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kotroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lagouvardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mansell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Geophys. Res., Atmos</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5130" to="5148" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lightning activity and electrical structure in a thunderstorm that continued for more than 24 H</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmos. Res</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="256" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Characteristics of flash initiations in a supercell cluster with tornadoes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Macgorman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmos. Res</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="page" from="249" to="264" />
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
				<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015-06">Jun. 2015</date>
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A dualstage attention-based recurrent neural network for time series prediction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
				<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2017-04">Apr. 2017</date>
			<biblScope unit="page" from="2627" to="2633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">TADA: Trend alignment with dual-attention multi-task recurrent neural networks for sales prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICDM</title>
				<meeting>ICDM</meeting>
		<imprint>
			<date type="published" when="2018-11">Nov. 2018</date>
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SCA-CNN: Spatial and channel-wise attention in convolutional networks for image captioning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
				<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017-07">Jul. 2017</date>
			<biblScope unit="page" from="5659" to="5667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
				<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017-07">Jul. 2017</date>
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Use of high-resolution WRF simulations to forecast lightning threat</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mccaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lacasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cecil</surname></persName>
		</author>
		<idno>paper_115074.htm</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd Conf. Severe Local Storms</title>
				<meeting>23rd Conf. Severe Local Storms<address><addrLine>St. Louis, MO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">'</forename><surname>Fcn-Rlstm</surname></persName>
		</author>
		<title level="m">Deep spatio-temporal neural networks for vehicle counting in city cameras,&apos;&apos; in Proc. ICCV</title>
				<imprint>
			<date type="published" when="2017-10">Oct. 2017</date>
			<biblScope unit="page" from="3667" to="3676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep spatio-temporal residual networks for citywide crowd flows prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
				<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2017-02">Feb. 2017</date>
			<biblScope unit="page" from="1655" to="1661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Carley</surname></persName>
		</author>
		<title level="m">StepDeep: A novel spatial-temporal mobility event prediction framework based on deep neural network,&apos;&apos; in Proc. SIGKDD</title>
				<imprint>
			<date type="published" when="2018-08">Aug. 2018</date>
			<biblScope unit="page" from="724" to="733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal features with 3D convolutional networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
				<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015-12">Dec. 2015</date>
			<biblScope unit="page" from="4489" to="4497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Decomposing motion and content for natural video sequence prediction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08033</idno>
		<ptr target="https://arxiv.org/abs/1706.08033" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal features using 3DCNN and convolutional LSTM for gesture recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
				<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017-10">Oct. 2017</date>
			<biblScope unit="page" from="3120" to="3128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">DeepSTCL: A deep spatio-temporal ConvLSTM for travel demand prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNN</title>
				<meeting>IJCNN</meeting>
		<imprint>
			<date type="published" when="2018-07">Jul. 2018</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep learning for precipitation nowcasting: A benchmark and a new model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5617" to="5627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
				<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018-06">Jun. 2018</date>
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Łkaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
				<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014-12">Dec. 2014</date>
			<biblScope unit="page" from="1" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An evaluation of the efficacy of using observed lightning to improve convective lightning forecasts</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ellrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Weather Forecasting</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="405" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Free access probabilistic 0-1-h convective initiation nowcasts that combine geostationary satellite observations and numerical weather prediction model data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mecikalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Jewett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ahijevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Meteorol. Climatol</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1039" to="1059" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neighborhood-based verification of precipitation forecasts from convection-allowing NCAR WRF model simulations and the operational NAM</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Gallus</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Weisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Weather Forecasting</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1495" to="1509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">LightGBM: A highly efficient gradient boosting decision tree</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liuand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
				<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
