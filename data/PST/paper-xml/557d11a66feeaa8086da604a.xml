<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Instruction Issue Logic for High-Performance, Interruptible, Multiple Functional Unit, Pip elined Computers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Instruction Issue Logic for High-Performance, Interruptible, Multiple Functional Unit, Pip elined Computers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dependency resolution</term>
					<term>multiple functional units</term>
					<term>out-of-order execution</term>
					<term>pipelined computers</term>
					<term>precise interrupts</term>
					<term>register update unit</term>
					<term>Tomasulo&apos;s algorithm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstmct-The performance of pipelined processors is limited by data dependencies and branch instructions. In order to achieve high performance, mechanisms must exist to alleviate the effects of data dependencies and branch instructions. Furthermore, in many cases, for example the support of virtual memory, it is essential interrupts be precise. In multiple functional unit pipelined processors where the instructions can complete and update the state of the machine out of program order, hardware support must be provided to implement precise interrupts. In this paper, we combine the problems of data dependency resolution and precise interrupt implementation. We present a design for a hardware mechanism that resolves dependencies dynamically and, at the same time, guarantees precise interrupts. Simulation studies show that, by resolving dependencies, the proposed mechanism is able to obtain a significant speedup over a simple instruction issue mechanism as well as implement precise interrupts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION HE CPU's of most supercomputers consist of several</head><p>T pipelined functional units connected together in some fashion. Such multiple functional unit, pipelined machines are able to achieve a considerable overlap in the execution of instructions. Unfortunately, pipelined CPU's have two major impediments to their performance: 1) data dependencies and 2) branch instructions. An instruction cannot begin execution until its operands are available. If an instruction is dependent upon a previous instruction, the instruction must wait until the previous instruction has completed execution. This waiting can degrade performance. The performance degradation due to branch instructions can be even more severe. Not only must a conditional branch instruction wait for the branch condition to be known, an additional penalty may be incurred when fetching an instruction from the taken branch path to the stage where the instruction is decoded and issued.</p><p>Pipelined CPU's suffer from another major problem-an interrupt can be imprecise <ref type="bibr">[3]</ref>, <ref type="bibr">[ 121, [24]</ref>. This problem is especially severe in multiple functional unit computers in which instructions can complete execution out of program order even though they are issued in program order [l], [3], <ref type="bibr">[21]</ref>. For a high-performance, pipelined CPU, an adequate solution must be found for the imprecise interrupt problem and means must be provided for overcoming the performance degradation due to data dependencies and branch instructions.</p><p>The detrimental effects of branch instructions can be alleviated by using delayed branch instructions. However, the utility of delayed branch instructions is limited for long pipelines. In such cases, other means must exist to alleviate the detrimental effects. A common approach is to use branch prediction <ref type="bibr">1131, [22]</ref>. Using prediction techniques, the probable execution path of a branch instruction is determined. Instructions from the predicted path can then be fetched into instruction buffers or even executed in a conditional mode <ref type="bibr">[3]</ref>, [4], <ref type="bibr">[7]</ref>, <ref type="bibr">[ 141, [ 191.</ref> While the conditional mode of execution will generally result in a higher pipeline throughput, a mechanism to allow the machine to recover from an incorrect sequence of conditionally executed instructions must be provided. Both hardware and software solutions exist to the data dependency problem. Software solutions use code scheduling techniques (combined with a large set of registers) to increase the distance between dependent instructions and to provide interlocks <ref type="bibr">[6]</ref>. Most hardware solutions employ some form of waiting stations where an instruction can wait for its operands and allow subsequent instructions to proceed, thereby allowing instructions to issue out of program order. Examples of waiting stations include the reservation stations of the IBM 360/91 floating point unit <ref type="bibr">[26]</ref> and the node tables of the HPS microarchitecture [ 171. The waiting stations form the core of a dependency-resolution mechanism that must exist in order to preserve program dependencies. In this paper, a dependencyresolution mechanism is synonymous with an out-of-order instruction issue mechanism. Note the difference between outof-order instruction issue (also called out-of-order instruction execution) and out-of-order instruction completion. Instructions can complete out of program order even though they were issued in program order.</p><p>In a pipelined machine, imprecise interrupts can be caused by instruction-generated traps such as arithmetic exceptions and page faults. An imprecise interrupt can leave the machine in an irrecoverable state. While the occurrence of arithmetic exceptions is rare, the occurrence of page faults in a ma-OO18-9340/90/03OO-0349$01 .OO 0 1990 IEEE chine that supports virtual memory is not. Therefore, if virtual memory is to be used with a pipelined CPU, it is crucial that interrupts be precise. Several hardware solutions to the problem are described in <ref type="bibr">[24]</ref> and in <ref type="bibr">[8]</ref>. We are unaware of any software solutions to the imprecise interrupt problem for multiple functional unit computers. A software solution will be extremely difficult, if not impossible. Not only must the software allow for the worst case execution time for any instruction, it must also keep track of instructions that have completed out of program order and generate an appropriate code sequence to undo the effects of those instructions. In any case, some hardware support must be provided to maintain run-time information.</p><p>The problems of out-of-order instruction issue and imprecise interrupts have been considered independent of one another by many researchers [2], [8], <ref type="bibr">[24]</ref>, <ref type="bibr">[26]</ref>, <ref type="bibr">[27]</ref>. The solutions provided thus far attack each problem individually. For example, a recent microarchitecture, HPS, uses register alias tables and node alias tables to permit out-of-order instruction issue [8], <ref type="bibr">[ 171, [ 181.</ref> To provide precise interrupts, HPS uses a checkpoint repair mechanism [9], <ref type="bibr">[lo]</ref>. In this paper, we treat the problems of out-of-order instruction issue and imprecise interrupts simultaneously. If interrupts are to be precise, some hardware support is needed. In its simplest form, a preciseinterrupt mechanism will aggravate dependencies <ref type="bibr">[24]</ref>. Why not combine a simple mechanism that implements precise interrupts with an out-of-order instruction issue mechanism so that the aggravated dependencies (as well as other dependencies) can be tolerated?</p><p>The remainder of this paper is as follows. In Section 11, we describe the model architecture that we use throughout this paper. In Section 111, we discuss Tomasulo's out-of-order instruction issue algorithm and extend it, giving several variations, so that the cost of implementing it using discrete components is not very high even for a large number of registers. In Section IV, we discuss the problem of imprecise interrupts and review known solutions. Section V describes a unit, the register update unit (RUU), that resolves dependencies as well as implements precise interrupts. The precise interrupt and out-of-order instruction issue mechanisms mutually aid and simplify each other. An evaluation of the RUU is carried out in Section VI. Finally, we discuss how our mechanism can be used to alleviate the degradation due to branch instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">MODEL ARCHITECTURE</head><p>The model architecture that we use for our studies is presented in Fig. <ref type="figure">1</ref>. It has the same capabilities and executes the same instruction set as the scalar unit of the CRAY-1 [5], [2 13. The CRAY-1 was chosen because it represents a state-of-theart scalar unit and its execution can be modeled precisely. The author also had easy access to tools that could be used to generate instruction traces for the CRAY-1 scalar unit <ref type="bibr">[16]</ref>. There are a few differences between the CRAY-1 scalar unit and our model architecture. First, in our model architecture, all instructions, whether they are composed of 1 parcel (16 bits) or 2 parcels (32 bits) can issue in a single cycle if issue conditions are favorable. Next, only one function can output data onto the result bus in any clock cycle. In contrast, the CRAY-1 scalar unit has separate result buses for the address and scalar functional units. Instructions are fetched by the instruction fetch unit and decoded and issued by the decode and issue unit. Once dependencies have been resolved in the decode and issue unit, instructions are forwarded to the functional units for execution. The results of the functional units are written directly into the register file. The register file consists of 8 A , 8 S, 64 B, and 64 T registers. In this paper, we shall focus on an issue unit that is capable of issuing only one instruction per clock cycle. Extensions to this work to allow the issue of multiple instructions per clock cycle can be found in <ref type="bibr">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Benchmark Programs</head><p>The benchmark programs used throughout this paper were the first 14 Lawrence Livermore loops <ref type="bibr">[15]</ref>. The first 14 loops were chosen because they were readily available and also allow us to compare our results to previous studies that tackle similar problems <ref type="bibr">[24]</ref>, <ref type="bibr">[27]</ref>. Henceforth, we shall refer to them as LLLl , LLL2, . . . , LLL14. The simulations were carried out as follows. The benchmark programs, as compiled by the CFT compiler for the scalar unit, were fed into a CRAY-1 simulator [ 161. The CRAY-1 simulator generates an instruction trace for each program. Vector instructions are not used. Each instruction trace was then fed into the appropriate simulator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . Simulation of the Model Architecture</head><p>We simulated the execution of the benchmark programs on the model architecture of Fig. <ref type="figure">1</ref>. The number of instructions executed, the number of clock cycles taken for the execution of each benchmark program, and the number of instructions executed per cycle is given in Table <ref type="table">I</ref>. In generating the results of Table <ref type="table">I</ref>, we assumed that: 1) no memory bank conflicts occur, 2) all instruction references are serviced by the instruction buffers, and 3) the instructions are already present in the instruction buffers when the program is started. These assumptions do not affect the execution time considerably for the benchmark programs. These assumptions and a difference in the bus structure account for the difference between the data presented in <ref type="bibr">Table I and in [27]</ref>. The instruction issue rate is the average number of instructions that are executed in a cycle, i.e., the total number of instructions executed in the benchmark divided by the total number of cycles to execute the benchmark. The instruction issue rate for the total of all 14 loops is calculated as the harmonic mean of the individual issue rates <ref type="bibr" target="#b20">[23]</ref>. For reasons of brevity, we shall present all subsequent simulation results as a harmonic mean of all 14 loops rather than report the results for each individual loop.</p><p>As we can see from Table <ref type="table">I</ref>, the performance of the model machine is far from the issue limit of 1 instruction per cycle. From our simulations, we determined that the main reason for this suboptimal performance is data dependencies. Therefore, we must find some way of alleviating the affects of data dependencies. We have two choices: 1) eliminating the dependencies or 2) tolerating the dependencies. Data dependencies can be eliminated by software code scheduling techniques. Hardware dependency resolution techniques allow the machine to tol-  erate dependencies. Since we are mainly concerned with a hardware mechanism that allows the architecture to tolerate dependencies as well as implement precise interrupts, we can restrict our attention to hardware mechanisms for tolerating dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. HARDWARE DEPENDENCY RESOLUTION</head><p>When an instruction reaches the decode and issue stage in the pipeline, checks must be made to determine if the operands for the instruction are available, i.e., if all dependencies for this instruction have been resolved. If an operand is not available, the instruction must wait in the decode and issue stage. Because the decode and issue stage of the pipeline i s busy, subsequent instructions cannot proceed even though they may be ready to execute. Subsequent instructions can proceed if the waiting instruction "steps aside, " thereby freeing the decode and issue stage and allowing other instructions to bypass the waiting instruction. In order to do so, some form of waiting stations or reservation stations must be provided <ref type="bibr">[26]</ref>. Other mechanisms also exist in the literature [2]. Since our work is I Memory I based on the concept of reservation stations, we shall focus our attention on mechanisms that employ reservation stations in some form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Tomasulo's Algorithm</head><p>Tomasulo's hardware dependency-resolution (or out-oforder instruction issue) algorithm was first presented for the floating point unit of the IBM 360/91 [26]. Extensions of this algorithm for the CRAY-1 scalar unit are presented in [27] and for the HPS microarchitecture in [8]. The algorithm operates as follows. An instruction whose operands are not available when it enters the decode and issue stage is forwarded to a reservation station (RS) associated with the functional unit that it will be using. It waits in the RS until its data dependencies have been resolved and its operands are available. Once at a reservation station, an instruction can resolve its dependencies by monitoring the common data bus (the result bus in our model architecture). When all the operands for an instruction are available, it is dispatched to the functional unit for execution. The result bus can be reserved either when the instruction is dispatched to the functional unit [27] or before it is about the leave the functional unit <ref type="bibr">[26]</ref>.</p><p>Each source register is assigned a busy bit. A register is busy if it is the destination of an instruction that is still in execution. Each destination register (also called a sink register)</p><p>is assigned a tag which identifies the result that will be written into the register. Since any register in the register file can be a destination register, each register must be assigned a tag. The fields in each reservation station are shown in Fig. <ref type="figure">2</ref>. If a source register is busy when the instruction reaches the issue stage, the tag for the source register is obtained and the instruction is forwarded to a reservation station. The appropriate ready bit in the reservation station is set to indicate that the source operand is unavailable. If the source register is not busy, the contents of the register are read into the reservation station and the ready bit is reset to indicate that be forwarded to the appropriate slot in the TU. The fields in the modified reservation stations are shown in Fig. <ref type="figure">4</ref>.</p><p>As before, the instruction along with its associated tagdoperands is forwarded to a reservation station where it waits for its operands to become ready. The result from a functional unit (along with its tag) is broadcast to all reservation stations and is also forwarded to the TU. Reservation stations monitor the result bus and gate in the result if the tag of the data on the result bus matches the tag stored in the reservation station. The TU forwards the result to the register specified in the appropriate slot of the TU. All registers are, therefore, updated only by the TU when their data are available and no direct connection is needed between the functional units and the register file. When the register has been updated by the TU, the corresponding tag is released and is marked free in the TU. The modified architecture that incorporates a tag unit and reservation stations associated with each functional unit is shown in Fig. <ref type="figure" target="#fig_0">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a) Example:</head><p>The operation of the tag unit is best illustrated by an example. Consider a TU that has six entries as shown in Fig. <ref type="figure">6</ref>. Each entry in the TU has a bit indicating if the tag is free (tag free), i.e., available for use by the issue logic, a bit indicating if the tag is the latest tag for the register (latest copy), and a field for the number of the destination register (register number) as in Fig. <ref type="figure">3</ref>. The TU is indexed by the tag number.</p><p>Consider the execution of an instruction ZI that adds the contents of registers SO and S7 and puts the result in S4.</p><p>Assume that the state of the TU is as shown in Fig. <ref type="figure">6</ref> and that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I S3</head><note type="other">Tag Register Tag Latest Number Number Free Copy</note><p>No</p><formula xml:id="formula_0">Yes I L I L</formula><p>S7 is free (indeed a register must be free if it does not have an entry in the TU). When the issue logic decodes ZI , it attempts to get a new tag for the destination register S4 from the TU and obtains tag 3. Since the TU already has a tag for S4, the old tag (4) is updated to indicate that it no longer represents the latest copy of the register. Since S7's contents are valid, they can be read from the register file and forwarded to the reservation stations directly. However, since the contents of S O are not valid, the latest tag for SO (tag 2) must be obtained from the TU. The issue unit forwards a packet to the reservation station associated with the add functional unit. The packet contains the contents of 5'7, a tag (2) for S O and a tag (3) for the destination register S4. Zl waits in the reservation station until that tag 2 appears on the result bus.</p><p>At this point, the reservation station reads the value for SO and ZI is ready to execute. When ZI completes execution and leaves the add functional unit, the result is forwarded to all reservation stations that have a matching tag (3) and also to the TU. The TU forwards the result to the register file to be written into S4. Since tag 3 is the latest tag for S4, S4's busy bit can be reset when the data have been written into S4. Tag 3 is then marked free and is available for reuse by the issue logic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>b) Interactions with Memory:</head><p>Loadlstore operations that interact with memory pose a challenge to architectures that allow out-of-order instruction issue (the reader is referred to [ 181 for a discussion of and some solutions to the problem).</p><p>In our model, we handle memory dependencies in a fashion similar to the way register dependencies are handled in the TU. A set of load registers contains the addresses of "currently active" memory locations. Each load register has tags to allow for multiple instances of a memory address just as the TU allows multiple instances of registers.</p><p>The reservation stations associated with the memory functional unit are managed in a pseudoqueue fashion to satisfy dependencies. A load operation needs a memory address before it can be issued to the memory whereas a store operation needs both a memory address and a data value. If the address of a loadlstore operation is unavailable, subsequent loadlstore instructions are not allowed to proceed. This prevents a possible violation of dependencies.</p><p>When the memory address required by the operation is known, checks are made to see if the address matches an address in the load registers. A match indicates that there is a pending operation to the same memory address. If no match results, a free load register is obtained. Instruction issue is blocked if no free load register is available.</p><p>If the current operation is a load operation and a match results, the load operation need not be submitted to memory. This is because the pending operation to the same address can also satisfy the load operation. In this case, the tag of the appropriate load register is returned to the reservation station. If there is no pending request to the same address, the tag is returned to the reservation station and the load operation is submitted to the memory. In either case, the load operation completes when a matching tag appears on the result bus.</p><p>If the current operation is a store operation and a match results, the tag of the load register is updated and the tag returned to the reservation station. By doing so, a new instance of the memory location is provided. If no match results, a free load register is obtained and the tag returned to the reservation station. When the data for the store operation are available, they are forwarded (along with the tag) via the load registers to the memory and the store operation is complete.</p><p>When the loadktore operation is complete, the reservation station is freed. The corresponding load register is also freed if the tags match, i.e., there is no pending operation to the same memory address. Note that the above scheme allows load operations to bypass store operations as long as the addresses of all the operations are known. Also note that the load registers need to be searched associatively. However, for a small number of load registers, this associative search is not very wide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Merging the Reservation Stations:</head><p>If each functional unit has a separate set of reservation stations, it is likely that some functional unit will run out of reservation stations while the reservation stations associated with another functional unit are idle. As suggested in [27], we can combine all he reservation stations into a common RS pool rather than hasl.:ig disjoint pools of reservation stations associated with each functional unit. All instructions that were previously issued to distributed reservation stations associated with the functional units now go to the common RS pool. Instruction issue is blocked if the RS pool is full. As instructions become ready in the RS pool, they are issued to the functional units. All the other functions are as before.</p><p>3) Merging the RS Pool and the Tag Unit: In the tag unit, there is one entry for every instruction that is present in either the RS pool or in the functional units. Therefore, at any time, there is a one-to-one correspondence between the entries in the TU and the instructions in the reservation stations or the functional units. This suggests that we can combine the RS pool and the tag unit into a single RS tag unit (RSTU). Of course, a reservation station is wasted if it is associated with an instruction that is in a functional unit. However, as we shall see in Section V, this organization can easily be extended to allow for the implementation of precise interrupts.</p><p>In the RSTU, a reservation station is reserved at the same time that a tag is reserved. When an instruction issues, it obtains a tag from the RSTU and in doing so automatically reserves a reservation station. All the other functions, including interactions with the memory, are as before. The architecture with an RSTU is shown in Fig. <ref type="figure">7</ref> and an entry in the RSTU is shown in Fig. <ref type="figure">8</ref>. Since the reservations stations are merged, a functional unit field is needed to identify the functional unit to which the instruction occupying the RSTU entry will be issued.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes/No</head><p>Yes </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a) Simulation Analysis of the RSTU:</head><p>In order to evaluate the effectiveness of the RSTU, we carried out a simulation analysis of the RSTU using the first 14 Lawrence Livermore loops as a benchmark. The results obtained for the execution of all 14 loops are presented in Table <ref type="table">11</ref>. The relative speedup is the speedup compared to the simple instruction issue mechanism of Table <ref type="table">I</ref> and the instruction issue rate is the harmonic mean of the individual issue rates. The number of load registers in these simulations was six. This guarantees that, for our benchmark programs, instruction issue is never blocked because of an unavailable load register.</p><p>From Table <ref type="table">11</ref>, it is quite clear that the RSTU is able to achieve a significant speedup over a simple instruction issue mechanism with a reasonable amount of hardware. The RSTU is also quite close to achieving the issue limit of 1 instruction per clock cycle for our model architecture. Indeed, all nonbranch instructions are able to achieve the limit of 1 instruction per cycle. The only cycles in which no useful instruction is executed are the dead cycles following each branch instruction. The degradation due to such cycles could be reduced by using delayed branch instructions or by conditionally executing instructions. The results presented in Table <ref type="table">I1</ref> compare favorably to the results presented in <ref type="bibr">[27]</ref>. Because the RSTU can implement the dependency-resolution mechanism for the B and T register files, it can achieve a better speedup than a mechanism that is somewhat restricted as in <ref type="bibr">[27]</ref>.</p><p>At first glance, it may seem that an organization with merged reservation stations (such as the RSTU of Fig. <ref type="figure">8</ref>) is at a disadvantage when compared to an organization with distributed reservation stations (such as Fig. <ref type="figure" target="#fig_0">5</ref>) since only one instruction can issue from the reservation stations to the functional units in a clock cycle unless multiple paths are provided between the RSTU and the functional units. On the other hand, a better use of the reservations stations results since the reservation stations can be shared among several functional units. In order to evaluate the effectiveness of multiple data paths between the RSTU and the functional units, we simulated an architecture with two paths from the RSTU to the functional units, but only a single issue unit, a single result bus, and single path from the RSTU to the register file. The results are presented in Table <ref type="table">111</ref>.</p><p>As is evident from Table <ref type="table">111</ref>, the presence of a duplicate path from the RSTU to the functional units makes little difference. This result is not counterintuitive. We use an argument based on instruction flow to convince the reader. The RSTU is essentially a reservoir of instructions that is filled by the decode and issue logic and drained by the functional units. Since the decode and issue logic can fill this reservoir at a maximum rate of 1 instruction per cycle, having a drain that is capable of draining more than 1 instruction per cycle will not be very useful in a steady state. Of course, if the decode and issue unit itself could submit more than 1 instruction per clock cycle to the RSTU, additional paths from the RSTU to the functional units would be needed <ref type="bibr">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV . IMPLEMENTATION OF PRECISE INTERRUPTS</head><p>We now address the issue of precise interrupts. A complete description of several schemes that implement precise interrupts is given in <ref type="bibr">[24]</ref>. An alternate scheme that uses checkpoint repair is presented in <ref type="bibr">[lo]</ref>.</p><p>The mechanisms described in [24] include a simple reorder buffer, a more complex reorder buffer with bypass logic, a history buffer, and a future file. The simple reorder buffer allows instructions to finish execution out of order but up-dates the state of the machine, i.e., commits the instructions, in the order that the instructions arrived at the decode and issue stage. This ensures that a precise state of the machine is recoverable at any time. However, by forcing an ordering of commitment among the instructions, the reorder buffer aggravates data dependencies. This is because the value of a register cannot be read until it has been updated by the reorder buffer, even though the instruction that computed a value for the register may have already completed and the new value is in the reorder buffer. If bypass logic is associated with the reorder buffer, an instruction does not have to wait for the reorder buffer to update a source register; it can fetch the value from the reorder buffer (if it is available) and can issue. With a bypass mechanism, the issue rate of the machine is not degraded considerably if the size of the buffer is reasonably large [24]. However, a bypass mechanism is expensive to implement since it requires a search capability and additional data paths for each buffer entry. A history buffer has the same performance as a reorder buffer with bypass logic. It does not need bypass logic but the register file needs another read port. A future file achieves the same performance as a reorder buffer with bypass logic at the expense of duplicating the entire register file. The checkpoint repair mechanism described in [lo] maintains three copies of the register file. We shall not discuss these mechanisms in more detail in this paper. The interested reader is referred to the original papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. MERGING DEPENDENCY RESOLUTION AND PRECISE INTERRUPTS</head><p>We note that the RSTU of Section 111-B3 can be modified to behave like a reorder buffer if it is forced to update the state of the machine in the order that the instructions are encountered by the decode and issue unit. This is easily accomplished by managing the RSTU as a queue. Therefore, all that we have to do to implement precise interrupts in an architecture with an RSTU is to manage the RSTU like a queue. We call the modified logic the register update unit (RUU). The RUU is essentially the RSTU constrained to commit instructions in the order that the instructions were received by the decode and issue logic (and consequently by the RUU). The functional units remain unchanged. The modified architecture that uses an RUU to execute instructions out of program order and to ensure a precise state of the machine is given in Fig. <ref type="figure" target="#fig_1">9</ref>. Let us consider the operation of the RUU in some more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . The Register Update Unit (RUU)</head><p>The RUU performs four major functions in each clock cycle. First, it accepts new instructions from the decode and issue logic. Second, it monitors the result bus to resolve dependencies. Third, it determines which instruction should be issued to the functional units for execution, reserves the result bus, and dispatches the instruction to the selected functional unit for execution. Fourth, it determines if an instruction can commit, i.e., update the registers, and commits the instruction if it can. Below, we see how the RUU accomplishes these tasks.</p><p>First, the RUU must accept an instruction from the decode and issue logic. The RUU is managed like a queue using RUU-Head and RUU-Tail pointers. If RUU-Head = RUU-Tail, the RUU is full. RUU-Tail points to the slot that will be used by the decode and issue logic and RUU-Head points to the next instruction that must commit to ensure a precise state. When an instruction is decoded, the issue logic requests an entry in the RUU. If the RUU is full, instruction issue is blocked. If an entry is available, the issue logic obtains the position of the entry (using the RUU-Tail pointer) and updates the RUU-Tail pointer. Simultaneously, it forwards the contents of the source registers (if they are availaule) or a register tag to the selected reservation station in the RIJU.</p><p>Managing the RSTU like a queue has a very important side effect-the logic for obtaining tags for source operands and generating tags for destination operands, i.e., for dependency resolution, is greatly simplified. Recall that in the RSTU, the issue logic had to search the RSTU associatively to obtain the correct tag for the source operand and to update the latest copy field for the destination register. If multiple instances of the same destination register are disallowed, i.e., instruction issue is blocked if the destination register is busy, no associative logic is necessary since the register number itself serves as the tag. An instance of a register is a new copy of the register. By providing multiple instances of a destination register, the architecture can process several instructions with the same destination register simultaneously, i.e., resolve writeafter-write hazards [ 111. Disallowing multiple instances of a destination register can degrade performance [27]. As noted in [26], it is possible to eliminate the associative search and use a counter to provide multiple instances and source operand tags for each register if we can guarantee that results return to the registers in order. This is precisely the situation in the RUU. The implementation of precise interrupts, therefore, simplifies the out-of-order instruction issue mechanism.</p><p>The scheme we use to provide multiple instances of a destination register and to provide source operand tags associates two n-bit counters with each register in the register file (this includes the B and T register files). There is no busy bit. The counters, the number of instances (NO and the latest instance (Lo, represent the number of instances of a register in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>YeslNo</head><p>the RUU and the number of the latest instance, respectively. When an instruction with a destination register Ri is issued to the RUU, both NI and LI associated with Ri are incremented. LI is incremented modulo n. Up to 2" -1 instances of a register can be present in the RUU at any time; issue is blocked if NI for a destination register is 2" -1. When an instruction leaves the RUU and updates the value of Ri, the associated NI is decremented (since n is small, the incrementing/decrementing process is fast). A register is free if NI = 0, i.e., there is no instruction in the RUU that is going to write into the register.</p><p>The register tag sent to the RUU consists of the register number Ri appended with the LI counter. This guarantees that future instructions access the latest instance, i.e., obtain the latest copy of the register contents and that instructions already present in the RUU get the correct version of the data.</p><p>In our experiments, each of these counters was 3 bits wide. This allowed up to seven instances of a destination register. A 3-bit counter ensured that, for our benchmark programs, an instruction never blocked in the decode and issue stage because an instance of a register was unavailable. Since we had a totA of 144 registers, the tag field was 11 (8 + 3) bits wide.</p><p>To accomplish its second task of resolving dependencies, the RUU must monitor the result bus. To do so, each source operand field in the RUU has a ready bit, a tag subfield, and a content subfield. If the operand is not ready, the tag subfield monitors the result bus for a matching tag. If a match is detected, the data on the bus are gated into the content field. This task of the RUU corresponds to the task carried out by the reservation stations in Tomasulo's algorithm. Note that there is no need for a latest copy field in the RUU and no associative search logic is needed in the RUU to generate and maintain the tags. However, associative comparison logic is still needed for all the reservation stations in the RUU so that they can gate in the value of source operands when available.</p><p>An entry in the RUU is shown in Fig. <ref type="figure">10</ref>. The dispatched field indicates if the instruction has been dispatched for execution to the functional unit specified in the functional unit field. The executed field indicates if the instruction has finished execution and is ready to update the register file. The program counter field is needed for the implementation of precise interrupts [24]. We have omitted the details of extra information that must be carried around with each instruction since the details of such information are straightforward.</p><p>The RUU accomplishes its third task by monitoring the ready bits of the source operands. When the operands of an instruction in the RUU are ready, the instruction can issue to the functional units. The RUU issues the highest priority instruction and sets the dispatched bit to indicate that the instruction has been dispatched for execution and should not be selected again by the dispatching algorithm. Priority is first given to loadhtore instructions and then to an instruction which entered the RUU earlier. The RUU reserves the result bus when it issues an instruction to the functional units.</p><p>The final RUU task of committing an instruction is accomplished by monitoring the executed bit of the RUU entry at the head of the RUU. If the executed bit of the instruction at the head of the RUU is set, the results of its destination register are forwarded to the register file. The associated NI counter in the register file is decremented and RUU-Head updated.</p><p>As is obvious from the above discussion, each of the tasks of the RUU can be carried out in parallel in each clock cycle and each task is simple enough that it is not likely to penalize the clock cycle. Instructions that interact with the memory are handled as in Section 111-Blb. The reservation stations for the memory are provided by the RUU. Note that the load registers still need to be searched associatively for memory addresses. However, the hardware needed for this comparison is not very great for a small number of load registers. In our simulations, we used six load registers, although four were sufficient for most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EVALUATION OF THE RUU</head><p>In order to evaluate the effectiveness of the RUU, we simulated three RUU organizations, 1) an RUU with bypass logic for source operand values, 2) an RUU without bypass logic, and 3) an RUU with a limited bypass logic. The results presented in this section differ from results presented previously <ref type="bibr" target="#b22">[25]</ref>. The main reason for the difference is a different pipeline structure and a different issue mechanism for load and store instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . The RUU with Bypass Logic</head><p>Recall that the RUU forces the results to return to the registers in program order. In doing so, it aggravates data dependencies. Such a degradation could be eliminated if bypass logic for source operands was provided in some form. The simplest form could be associative comparison hardware with the destination field of each RUU entry. If a source operand for instruction I , is provided by Ii and the destination operand of Ii is ready in the RUU, the operand can be read from the RUU and I j is allowed to proceed with execution. Note that the history buffer and the future file [24] are alternate forms for bypass logic. The relative speedups (compared to the simple instruction issue mechanism of Table <ref type="table">I</ref>) and the corresponding instruction issue rate for different sizes of an RUU with bypass logic are presented in Table <ref type="table" target="#tab_8">IV</ref>.</p><p>The results of Table <ref type="table" target="#tab_8">IV</ref> are quite promising. An RUU with a reasonable number of entries (10-12) not only speeds up execution but also provides precise interrupts. Moreover, for somewhat larger RUU sizes, the RUU is able to achieve a speedup that is quite similar to the RSTU. Note that the RSTU was not constrained to implement precise interrupts and it also requires additional associative logic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . The RUU without Bypass Logic</head><p>Since bypass logic is expensive to implement, we decided to evaluate an RUU without any bypass logic. Before we present  Consider an instruction Ij that uses the result of a previous instruction I;. Recall that the reservation stations associated with the RUU already have the capability to monitor the result bus. Therefore, if I; completes execution after I, is issued to the RUU, Ij can gate in the result from I; when it appears on the result bus. In this case, bypass logic is not needed.</p><p>Bypass logic is helpful only in the cases where Ii has completed execution when I, is issued. Rather that providing bypass logic for this case, we wait for the result of I; to come out on the bus between the RUU and the register file in order to resolve Ij's dependency on I;. If Ij is issued to the RUU before I; completes, Ij's dependency on I; can be resolved when I;'s result appears on the result bus if we extend the capabilities of the reservation stations to monitor both the result bus and the RUU to register file bus.</p><p>Table <ref type="table">V</ref> presents the relative speedups and instruction issue rates for a RUU without bypass logic. From Table <ref type="table">V</ref> we see that a RUU without any bypass logic at all is still able to achieve a substantial increase in speed over a simple instruction issue mechanism and implement precise interrupts at the same time. The speedup, however, is not as impressive as the speedup obtained if bypass logic were used. The difference arises mainly because of the ordering of code in the loops. Let us illustrate the problem with an example.</p><p>Consider the following section of code: </p><formula xml:id="formula_1">I; A 2 + A l + A 3 Ij A O c A 2 f l Ik JAM loopstart.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C . The RUU with Limited Bypass Logic</head><p>Because of the problem illustrated above, we found that branch instructions were blocked for a long period of time in the decode and issue stage since the contents of the A0 register could not be read from the RUU (or were unavailable because of a dependency chain aggravated as above). The branch instruction has to wait in the decode and issue unit until the value of A0 appears on a bus. In order to eliminate this problem, we duplicated the A register file, effectively creating a limited bypass path for the A registers. The duplicate A register file acts as a future file for the A registers. The entire A register file (eight registers) was duplicated to prevent the unnecessary increase in the length of the dependency chain that affects the conditional branch instruction. All other functions are as before. Specifically, there is only l copy of the B, S, and T register files and there is no bypass logic in the RUU. As functions that affect the A registers are completed and appear on the result bus, the result is forwarded to the RUU and also to the A future file. The architectural register file contains a valid copy of registers at all time for recovering a precise state. Instructions that use A registers as source operands, fetch the data from the A future file, if it is available, and proceed. The results for an RUU with limited bypass logic is presented in Table <ref type="table" target="#tab_10">VI</ref>. An RUU with limited bypass logic is able to overcome a significant portion of the performance penalty paid for eliminating bypass logic especially for small RUU sizes. For larger RUU sizes, however, the performance is not as good. This is because instructions that transfer data from a B register to an A register are still held up in the RUU (no bypass logic for the B register file). Since the destination A register of such transfer instructions eventually affects the branch condition (most branch instructions in the benchmark programs tested the value of the A0 register), instruction issue is blocked for longer periods of time. We are confident that the performance of an RUU without bypass logic and an RUU with limited bypass logic could be improved considerably and would come close to the speedups with bypass logic if the code was modified accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. BRANCH PENALTY AND CONDITIONAL INSTRUCTIONS</head><p>As mentioned earlier, the performance degradation due to branches can be reduced by conditionally executing instruc- tions from a predicted branch path. Several architectures employ this approach [3], <ref type="bibr">[4]</ref>, [8], <ref type="bibr">[19]</ref>. To allow conditional execution of instructions, a hardware mechanism is needed that would allow the machine to recover from an incorrect branch prediction.</p><p>The RUU provides a very powerful mechanism for nullifying instructions, be the instructions valid instructions or instructions that executed in a conditional mode. Valid instructions may be nullified because of a trap caused by a previous instruction; conditionally executed instructions may be nullified if they are from an incorrect execution path. Therefore, the conditional execution of instructions with an RUU is very easy. If the decode and issue unit predicts the outcome of branches and actually executes instructions from a predicted path in a conditional mode, recovery from incorrect branch predictions can be achieved very easily without duplicating the register file. We can identify such instructions through the use of an additional field in the RUU and prevent them from being committed until they are proven to be from a correct path. Furthermore, there is no hard limit to the number of branches that can be predicted; the RUU can provide multiple instances of a register for the different paths. Extending the RUU to accommodate branch prediction and conditional execution is an ongoing research topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. SUMMARY</head><p>In this paper, we have combined the issues of hardware dependency-resolution and implementation of precise interrupts. We devised a scheme that can resolve dependencies and thereby allows out-of-order instruction execution without associating tag-matching hardware with each register. Such a scheme can, therefore, be used even in the presence of a large number of registers without a substantial hardware cost. Then we extended the scheme to incorporate precise interrupts. The precise interrupt and the dependency-resolution mechanisms mutually aid and simplify each other. We evaluated the performance of the resulting hardware using 14 Livermore loops as the benchmark. The results are quite encouraging. The combined mechanism, called the RUU, is able to implement precise interrupts and is able to achieve a significant performance improvement over a simple instruction issue mechanism without a substantial cost in hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The author would like to thank J. Goodman, A. Pleszkun, and J. Smith for their useful discussions during this research. The author would also like to thank S. Vajapeyam for his help with the simulations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The model architecture with a tag unit and distributed reservation stations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. The model architecture with an RUU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript receivedAugust 8, 1987; revised July 25, 1989.  This work was supported in part by the University of Wisconsin Graduate Research Committee and in part by NSF Grant CCR-8706722. A preliminary version of this paper appeared in the 14th International Symposium on Computer Architecture, Pittsburgh, PA, June 1987.</figDesc><table><row><cell>The author is with the Computer Sciences Department, University of Wis-</cell></row><row><cell>consin, Madison, WI 53706.</cell></row><row><cell>IEEE Log Number 8932910.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1 From Memory Register File Instruction Fetch Unit Decode and Issue Uiit c Fig. 1 STATISTICS FOR THE BENCHMARK PROGRAMS Benchmark LLL5 LLL6 LU9 LLL IO LLLll LLLl2 LLLl3 LLL 14 Harmonic Mean 7217 17234 8448 17102 14015 36023 9783 20643 8347 20696 9 3 s 22034 4573 10231 4031 8026 4918 10134 4412 9420 12002 28002 17814 9915 I 27w1 23573 Instruction Issue Rate 0.419 0.494 0.389 0.474 0.403 0.424 0.447 0.502 0.485 0.468 0.429 0.429 0.497 0.421 0.446 - Result Bus The model architecture.</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>An entry in the RSTU. TABLE I1 RELATIVE SPEEDUP AND ISSUE RATE WITH AN RSTU</head><label></label><figDesc>Tag I Contents I Ready I l a g I Contents 1 1 Register 1</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>A Data</cell></row><row><cell>Source Operand 1</cell><cell cols="2">Source Operand 2</cell><cell>Destination</cell></row><row><cell>I Ready 1 7</cell><cell>1.483</cell><cell>0.661</cell></row><row><cell>8 9</cell><cell>1.547 1.593</cell><cell>0.6W 0.710</cell></row><row><cell>10</cell><cell>1.634</cell><cell>0.723</cell></row><row><cell>15</cell><cell>1.721</cell><cell>0.768</cell></row><row><cell>20</cell><cell>1.748</cell><cell>0.780</cell></row><row><cell>25</cell><cell>1.773</cell><cell>0.791</cell></row></table><note><p>/No Unit Number IEEE TRANSACTIONS ON COMPUTERS, VOL. 39, NO. 3, MARCH 1990 Fig. 8.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE I11 RELATIVE SPEEDUP AND ISSUE RATE WITH AN RSTU AND Two DATA PATHS Number of Entries in RSTU</head><label>I11</label><figDesc></figDesc><table><row><cell>3</cell></row><row><cell>4</cell></row><row><cell>5</cell></row><row><cell>6</cell></row><row><cell>7</cell></row><row><cell>8</cell></row><row><cell>9</cell></row><row><cell>10</cell></row><row><cell>15</cell></row><row><cell>20</cell></row><row><cell>25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Source Operand 1 Source Operand 2</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Desunation</cell></row><row><cell>Ready</cell><cell>Tag</cell><cell>Content</cell><cell>Ready</cell><cell>Tag</cell><cell>Content</cell><cell>RegisterS</cell><cell>Content</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TRANSACTIONS ON COMPUTERS, VOL. 39, NO. 3, MARCH 1990</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>IEEE</cell></row><row><cell>Unit Number</cell><cell>YesINo</cell><cell>Content</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Number of Entries in RUU</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE IV RELATIVE SPEEDUP AND ISSUE RATE WITH AN RUU WITH BYPASS LOGIC Relative Insuuction Specdup Issue Rate RELATIVE SPEEDUP TABLE V AND ISSUE RATE WITH AN RUU WITHOUT BYPASS LOGIC</head><label>IV</label><figDesc></figDesc><table><row><cell>3 4 6</cell><cell>0.853 I 0.940 1.079</cell><cell>0.380 0.419 0.481</cell></row><row><cell>8</cell><cell>1.248</cell><cell>0.557</cell></row><row><cell>10 12</cell><cell>1.383</cell><cell>0.61 7</cell></row><row><cell></cell><cell>1.508</cell><cell>0.673</cell></row><row><cell>15</cell><cell>1.584</cell><cell>0.706</cell></row><row><cell>20</cell><cell>1.619</cell><cell>0.735</cell></row><row><cell>25</cell><cell>1.682</cell><cell>0.750</cell></row><row><cell>30</cell><cell>1.700</cell><cell>0.758</cell></row><row><cell>40</cell><cell>1.735</cell><cell>0.774</cell></row><row><cell>50</cell><cell>1.737</cell><cell>0.775</cell></row><row><cell cols="3">the results, let us see the situations where bypass logic is</cell></row><row><cell>helpful.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Conventional compilation techniques try and increase the distance between instructions Ii and Ij and instructions Ij and Ik so that when instructions Ij and I k reach the issue stage, their respective operands are ready. Such an increase in dependency distance is in fact harmful to an RUU without bypass logic. If I, was issued sufficiently before Ik and completed execution before Ik reached the decode and issue stage, I k would be forced to wait until I, left the RUU. If, on the other hand, I, was issued soon before Ik, Ik could resolve its dependency on Ij when the result of Ij was available on the functional</figDesc><table><row><cell>Number of 1 Entries in RUU</cell></row><row><cell>3</cell></row><row><cell>4</cell></row><row><cell>6</cell></row><row><cell>8</cell></row><row><cell>IO</cell></row><row><cell>12</cell></row><row><cell>15 20 I !!</cell></row><row><cell>unit result bus. In our simulations, no attempt was made to</cell></row><row><cell>improve the performance of the RUU without bypass logic by</cell></row><row><cell>reordering the code for such cases.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE VI RELATIVE</head><label>VI</label><figDesc>SPEEDUP AND ISSUE RATE WITH AN RUU WITH LIMITED BYPASS LOGIC</figDesc><table><row><cell>Number of</cell></row><row><cell>Enmes in RUU</cell></row><row><cell>3</cell></row><row><cell>4</cell></row><row><cell>6</cell></row><row><cell>8</cell></row><row><cell>10</cell></row><row><cell>12</cell></row><row><cell>15</cell></row><row><cell>20</cell></row><row><cell>25</cell></row><row><cell>30</cell></row><row><cell>40</cell></row><row><cell>50</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">CDC Cyber 200 Model 205 Compu fer System Hardware Reference Manual, Control Data Corp</title>
		<meeting><address><addrLine>Arden Hills, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An instruction issuing approach to enhancing performance in multiple functional unit processors</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kjelstrup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Torng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="815" to="828" />
			<date type="published" when="1986-09">Sept. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Sparacio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Tomasulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IBM System/360 Model 9 1 : Machine philosophy and instruction-handling</title>
		<imprint>
			<date type="published" when="1967-01">Jan. 1967</date>
			<biblScope unit="page" from="8" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Architectural tradeoffs in the design of MIPS-X</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Annu. Symp. Comput. Architecture, Pittsburgh</title>
		<meeting>14th Annu. Symp. Comput. Architecture, Pittsburgh</meeting>
		<imprint>
			<date type="published" when="1987-06">June 1987</date>
			<biblScope unit="page" from="300" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">CRAY-1 Computer Systems, Hardware Reference Manual</title>
		<author>
			<persName><surname>Cray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Cray Research, Inc</publisher>
			<pubPlace>Chippewa Falls, WI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hardware/software tradeoffs for increased performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Baskett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp</title>
		<meeting>Int. Symp</meeting>
		<imprint>
			<date type="published" when="1982-03">Mar. 1982</date>
			<biblScope unit="page" from="2" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Highly concurrent scalar processing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y T</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Annu. Symp. Comput. Architecture</title>
		<meeting>13th Annu. Symp. Comput. Architecture</meeting>
		<imprint>
			<date type="published" when="1986-06">June 1986</date>
			<biblScope unit="page" from="386" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">HPSm, A high performance restricted data flow architecture having minimal functionality</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Annu. Symp. Comput. Architecture</title>
		<meeting>13th Annu. Symp. Comput. Architecture</meeting>
		<imprint>
			<date type="published" when="1986-06">June 1986</date>
			<biblScope unit="page" from="297" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Design choices for the HPSm microprocessor chip</title>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Annu. Hawaii Int. Conf. Syst. Sci</title>
		<imprint>
			<date type="published" when="1987-01">Jan. 1987</date>
			<pubPlace>Kona, HI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Checkpoint repair for high-performance out-of-order execution machines</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="66" to="72" />
			<date type="published" when="1975-12">Dec. 1987. Dec. 1975</date>
		</imprint>
	</monogr>
	<note>ACM Comput. Surveys</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The Architecture of Pipelined Computers</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Kogge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Branch prediction strategies and branch target buffer design</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcfarling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Mcmahon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Annu. Symp. Comput. Architecture</title>
		<meeting>13th Annu. Symp. Comput. Architecture<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1972-06">Jan. 1984. June. 1972</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="6" to="22" />
		</imprint>
		<respStmt>
			<orgName>FORTRAN CPU Performance Analysis, Lawrence Livermore Labs</orgName>
		</respStmt>
	</monogr>
	<note>Reducing the cost of braxhes</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">CRAY-1 simulation tools</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983-12">Dec. 1983</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. ECE-83-11</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">HPS, A new microarchitecture: Rationale and introduction</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shebanow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Annu. Workshop Microprogramming</title>
		<meeting>18th Annu. Workshop Microprogramming<address><addrLine>Pacific Grove, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-12">Dec. 1985</date>
			<biblScope unit="page" from="103" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Critical issues regarding HPS, A high performance microarchitecture</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Melvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shebanow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Annu. Workshop Microprogmmming</title>
		<meeting>18th Annu. Workshop Microprogmmming<address><addrLine>Pacific Grove, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-12">Dec. 1985</date>
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">WISQ: A restartable architecture using queues</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pleszkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Joersz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Woest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schecter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">P m . 14th Annu. Symp. Comput. Architecture</title>
		<imprint>
			<biblScope unit="page" from="290" to="299" />
			<date type="published" when="1987-06">June 1987</date>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The performance potential of multiple functional unit processors</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Peszkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Annu. Symp. Comput. Architecture</title>
		<meeting>15th Annu. Symp. Comput. Architecture<address><addrLine>Honolulu, HI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">June 1988. 1986</date>
			<biblScope unit="page" from="396" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The CRAY-1 computer system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Russel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cornmun. ACM</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="63" to="72" />
			<date type="published" when="1978-01">Jan. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A study of branch prediction strategies</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">P m . 8th Annu. Symp. Comput. Architecture</title>
		<imprint>
			<date type="published" when="1981-05">May 1981</date>
			<biblScope unit="page" from="135" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Characterizing computer performance with a single number</title>
	</analytic>
	<monogr>
		<title level="j">Cornmun. ACM</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1202" to="1206" />
			<date type="published" when="1988-10">Oct. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Implementing precise interrupts in pipelined processors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Pleszkun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cornput</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="562" to="573" />
			<date type="published" when="1988-05">May 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Instruction issue logic for highperformance, interruptible pipelined processors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vajapeyam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">P m . 14th Annu. Symp. Cornput. Architecture</title>
		<meeting><address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-06">June 1987</date>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An efficient algonthm for exploiting multiple arithmetic units</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Tomasulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Develop</title>
		<imprint>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="1967-01">Jan 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gurindar S. Sohi (S&apos;85-M&apos;85) received the B.E. (Hons.) degree in electrical engineering from the</title>
		<author>
			<persName><forename type="first">S</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PJani, India, in 1981 and the M S. and Ph.D degrees in electrical engineering from the University of 1111nois</title>
		<meeting><address><addrLine>Urbana-Champaign</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983">Nov. 1984. 1983. 1985</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="re" to=" spectively" />
		</imprint>
		<respStmt>
			<orgName>Birla Institute of Science and Technology</orgName>
		</respStmt>
	</monogr>
	<note>Instruction issue logic in pipelined super-computers</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Since September 1985, he has been with the Computer Sciences Department at the University of Wisconsin-Madison where is currently an Assistant Professor</title>
	</analytic>
	<monogr>
		<title level="m">His interests are in computer architec</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m">ture, parallel and distributed processing, and fault-tolerant computing</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
