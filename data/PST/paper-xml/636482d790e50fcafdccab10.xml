<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data-free Defense of Black Box Models Against Adversarial Attacks</title>
				<funder ref="#_6GEQhfE">
					<orgName type="full">DAE-BRNS, India</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-11-03">3 Nov 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Graduate Student Member, IEEE</roleName><forename type="first">Gaurav</forename><forename type="middle">Kumar</forename><surname>Nayak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Inder</forename><surname>Khatri</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shubham</forename><surname>Randive</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ruchit</forename><surname>Rawal</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Anirban</forename><surname>Chakraborty</surname></persName>
						</author>
						<title level="a" type="main">Data-free Defense of Black Box Models Against Adversarial Attacks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-11-03">3 Nov 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2211.01579v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Black-box Defense</term>
					<term>Adversarial Attacks</term>
					<term>Model Stealing</term>
					<term>Surrogate Data</term>
					<term>Wavelet Decomposition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Several companies often safeguard their trained deep models (i.e. details of architecture, learnt weights, training details etc.) from third-party users by exposing them only as black boxes through APIs. Moreover, they may not even provide access to the training data due to proprietary reasons or sensitivity concerns. We make the first attempt to provide adversarial robustness to the black box models in a data-free set up. We construct synthetic data via generative model and train surrogate network using model stealing techniques. To minimize adversarial contamination on perturbed samples, we propose 'wavelet noise remover' (WNR) that performs discrete wavelet decomposition on input images and carefully select only a few important coefficients determined by our 'wavelet coefficient selection module' (WCSM). To recover the highfrequency content of the image after noise removal via WNR, we further train a 'regenerator' network with an objective to retrieve the coefficients such that the reconstructed image yields similar to original predictions on the surrogate model. At test time, WNR combined with trained regenerator network is prepended to the black box network, resulting in a high boost in adversarial accuracy. Our method improves the adversarial accuracy on CIFAR-10 by 38.98% and 32.01% on state-of-the-art Auto Attack compared to baseline, even when the attacker uses surrogate architecture (Alexnet-half and Alexnet) similar to the black box architecture (Alexnet) with same model stealing strategy as defender. The code is available at https://github.com/vcl-iisc/datafree-black-box-defense</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Deep neural networks have become a powerful tool which is applied in different fields such as computer vision <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, machine translation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, speech recognition <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> etc. Despite the huge success of these deep models, they are unreliable, as incorrect predictions are obtained when the input image is perturbed using adversarial attacks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. Depending on the amount of information available to the malicious users (adversary), such attacks can be broadly divided into -white box <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref> (complete knowledge of the target model) and black box <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref> attacks (no access to the weights of the target model and no knowledge of its architecture).</p><p>Black box attacks are more practical and realistic compared to white-box attacks. Companies often make huge investments in curating large training datasets. Also, their annotation and their training on sophisticated deep models requires human efforts and computational resources. Thus, the trained deep models serve as an asset and are a valuable 'intellectual property'. To protect them and maintain a competitive edge, the organizations usually do not share the information about the exact architecture of the model and the associated details of hyperparameters. These models are integrated with their products and are then sold to the consumers as 'Machine learning as a service (MLaaS)' <ref type="bibr" target="#b17">[18]</ref> for monetary gains. They are deployed as black boxes that only allow the end-users to query them and obtain corresponding predictions from them (i.e. 'image-in and predictions-out'). However, they are still susceptible to black box attacks where the attacker can steal the functionality of target models by training the surrogate models using the pairs of (image, predictions) <ref type="bibr" target="#b13">[14]</ref>. The adversarial samples crafted using surrogate models can also attack the target model by the property of transferability. Thus, protection from such attacks requires immediate attention.</p><p>To make it harder for the adversary in crafting black box attacks, companies prefer not to release the training dataset and keep them proprietary. However, recent works have shown that model stealing can compromise the confidentiality of blackbox models even without the training data. Existing works perform generative modeling either with proxy data <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref> or without proxy data <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> and train the surrogate model with the synthesized data for model stealing. However, their focus is more on obtaining highly accurate surrogate models. In contrast to existing works, we inquire about an important question regarding the safety of the black box models -"how to defend against black box attacks in data-free (absence of training data) set up". This problem is still unexplored to the best of our knowledge.</p><p>In order to tackle this problem, our proposed method 'DBMA' (i.e. defending black box models against adversarial attacks in data-free setup) leverages on the wavelet transforms <ref type="bibr" target="#b24">[25]</ref>. We observe difference between wavelet transform on adversarial sample and original sample (shown in Fig. <ref type="figure" target="#fig_0">1</ref> (B)), we notice that detail coefficients in high-frequency regions (LH, HL and HH regions) are majorly corrupted by adversarial attacks and the approximate coefficients (LL region) is least affected for level 1 decomposition. Similar observation holds even for decomposition on other levels. To improve the adversarial accuracy, a naive way would be to completely remove the detail coefficients which can minimize the contamination in adversarial samples but it can lead to a huge drop in clean accuracy as the model predictions are highly correlated with high frequencies <ref type="bibr" target="#b25">[26]</ref>. To avoid that, we assign importance to each of the detail coefficients based on magnitude. The least perturbed LL region usually contains higher magnitude coefficients than other regions (Fig. <ref type="figure" target="#fig_9">1 (A)</ref>). So, we prefer high magnitude detail coefficients. However, taking a large number of such coefficients can lead to good clean accuracy but at the cost of low adversarial accuracy due to more contamination. On the other hand, taking very few such coefficients can allow lower contamination but results in low clean accuracy. Our method judiciously takes care of this trade-off, and carefully selects the required important detail coefficients (discussed in Sec. IV-B) using the proposed wavelet coefficient selection module (WCSM). The wavelet noise remover (WNR) removes noise coefficients by filtering out only the top-k% high magnitude coefficients where optimal k is selected using the WCSM module. As a side-effect, a lot of high-frequency content of the image gets lost which reduces the overall discriminability and ultimately results in suboptimal model's performance. To cope up with this reduced discriminability, we introduce a U-netbased regenerator network(Sec. IV-C), that takes the spatial samples corresponding to selected coefficients as input and outputs the reconstructed image. The regenerator network is trained by regularizing the feature and input space of the reconstructed image on the surrogate model. In the feature space, we apply cosine similarity and kl-divergence losses to ensure proper reconstruction on clean and adversarial data respectively. Besides this, we also regularize the input space using our spatial consistency loss. Finally, the WNR module combined with the trained regenerator network is appended before the black-box model. The attacker has black-box access to the complete end to end model containing the defense components.</p><p>We summarize our contributions as follows:</p><p>? To the best of our knowledge, we are the first to propose and solve the novel problem of providing defense against adversarial attacks on a black box model without access to the network weights and in the absence of original training samples.</p><p>? We propose a novel strategy to provide adversarial robustness against data-free black box attacks which has two key defense components: i.) We propose a wavelet-based noise remover (WNR) containing selective wavelet coefficient module (Sec. IV-B) that aims to remove coefficients corresponding to high frequency components which are most likely to be corrupted by adversarial attack.</p><p>ii.) We propose a U-net-based regenerator network (Sec. IV-C) that retrieves the coefficients that are lost after the noise removal (via WNR) so that the highfrequency image content can be restored.</p><p>? We demonstrate the efficacy of our method via extensive experiments and ablations on both the components of proposed framework namely wavelet noise remover (Sec. V-A, V-B, V-C) and the regenerator network an alternate training mechanism between generator and surrogate model, where generator is trained to produce synthetic samples to maximize the discrepancy between the predictions of the surrogate and the black box model. Truong et al. <ref type="bibr" target="#b22">[23]</ref> also train generator and surrogate model alternatively but they replace discrepancy loss computed using KL divergence with L1 norm over logits approximated from softmax. Similarly, Zhou et al. <ref type="bibr" target="#b23">[24]</ref> also formulate a min-max adversarial game but they additionally enforce the synthetic data to be equally distributed among the classes using a conditional generator. Unlike these existing works, we use model stealing only as a means to obtain the surrogate model and synthetic data. Unlike them where they steal as an adversary, our goal is to provide robustness against black box attacks i.e. to reduce the effects of the adversarial samples on the black box model that are crafted using the surrogate model.</p><p>Wavelet in CNNs: Before the CNNs, the wavelets had been used for noise reduction and denoising <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>. In the Pre Deep Learning Era, wavelets were also popularly used for image compression <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref> and image enhancement <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>. Li et al. <ref type="bibr" target="#b37">[38]</ref> integrated wavelets into the CNNs where the downsampling operations performed by max pooling, average pooling and strided-convolution are replaced only with low-frequency components of the discrete wavelet transform to suppress the aliasing effect. However, we do not have the luxury to modify the architecture in the black box settings. Also, we noticed that only keeping lowfrequency components and completely neglecting the high frequencies results in lower performance on both clean and adversarial data. Soleymani et al. <ref type="bibr" target="#b38">[39]</ref> use wavelets for detecting adversarially perturbed iris images. Prakash et al. <ref type="bibr" target="#b39">[40]</ref> used pixel deflection technique followed by adaptive thresholding on the wavelets coefficients for denoising. Unlike these works, our setup is more challenging due to no access to both the training data and the model weights. Mustafa et al. <ref type="bibr" target="#b40">[41]</ref> utilized wavelet denoising with image superresolution as a defense mechanism against adversarial attacks in grey-box settings. Different from this work, our approach utilizes the wavelet with a proposed regenerator network for defense against adversarial attacks in a black-box setting.</p><p>We find our work most related to <ref type="bibr" target="#b41">[42]</ref>, which presented a defense protocol against adversarial attacks for black-box facial recognition classifiers. They iteratively used an ensemble of image purifiers to remove the adversarial noise and a Bayesian CNN-based adversarial attack detector to validate the purified image. One of the drawbacks is they reject the given adversarial image and not pass it to the black box classifier if the purifier is not able to remove the adversarial noise from it in a given number of iterations. Moreover, training of purifier required data from the same domain as the data used to train the black-box model, making it dependent upon the domain knowledge of the training data. In contrast, our approach is free from any such data dependency. Also, the iterative pass through the image purifiers and attack detectors makes their method a highly time-consuming process. Further, if the attacker is aware of purifier, then the attack becomes more powerful. The purifier in such cases can't purify effectively leading to more images getting rejected and not passed to the black-box classifier for inference. Unlike their work, our method do not suffer from such problems while allowing complete access to our defense mechanism in the black-box setting, i.e., the attacker can use model stealing methods to steal the functionality of the defense components along with the victim model. Wavelet Transforms: Unlike time series signal (high resolution in time but uncertainty in frequency) and Fourier Transform (high resolution in frequency but uncertainty in time), wavelets can determine when individual frequencies turn on and off in time. The low frequency changes slowly over time whereas the high frequency changes fast in time. Thus, motivated by the natural signals which humans care about, wavelets provide more temporal resolution in high frequencies and more frequency resolution at lower frequencies. Wavelets represent the data using linear combinations of an orthogonal basis depending on which there are different types of wavelets such as Haar <ref type="bibr" target="#b42">[43]</ref>, Daubechies <ref type="bibr" target="#b43">[44]</ref>, Cohen <ref type="bibr" target="#b44">[45]</ref>. The 2D DWT on an i th image x i for level 1 yields low pass subband (i.e approximation coefficients -denoting by LL i 1 ) and high pass subband (i.e. detail-level coefficients -denoting by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notations</head><formula xml:id="formula_0">LH i 1 , HL i 1 , HH i 1 )</formula><p>. In multi-level DWT, the approximation subband is further decomposed (for e.g. on a 2-level decomposition,</p><formula xml:id="formula_1">LL i 1 is also decomposed to LL i 2 , LH i 2 , HL i 2 , HH i 2 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROPOSED APPROACH</head><p>In this section, we first discuss the model stealing method (Sec. IV-A) that we use to train the surrogate model S m (as proxy for black box model B m ) and generate synthetic data S d (as proxy for original training data O train d ). Next, we propose our method to remove the detail coefficients (Sec. IV-B) that can be most corrupted by an adversarial attack and select the important coefficients to preserve the signal strength in terms of retaining feature discriminability. We dub this approach as wavelet noise remover (WNR) and the coefficients are selected using the wavelet coefficient selection module (WCSM). To boost the performance, we propose a U-Net-based regenerator network (Sec. IV-C) that takes the output of WNR as input and is trained to output a regenerated image on which the surrogate model would yield similar features as the features of the clean sample. The different steps involved in our proposed method (DBMA) for providing data-free adversarial defense in the black box settings are shown in Fig. <ref type="figure" target="#fig_2">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Obtain Proxy Model and Synthetic Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Noise Removal with Wavelet Coefficient Selection Module (WCSM)</head><p>For an i th sample of the composed synthetic data S d (i.e. x i s ), its corresponding wavelet coefficients are obtained by DW T operation on it. The approximate coefficients are the low frequencies that are least affected by the adversarial attack (shown in Fig. <ref type="figure" target="#fig_9">1 (B)</ref>). Thus, we retain these coefficients. For e.g. on level-2 discrete wavelet decomposition, LL i 2 (approximate coefficients for i th sample) is kept. As the adversarial attack severely harms the detail coefficients, we determine the coefficients that can be most affected by it using WCSM for effective noise removal.</p><p>Based on our observation that the least affected approximate coefficients often have high magnitude coefficients, indicating that the high magnitude detail coefficients can be a good measure for choosing which coefficients to retain. Thus, we arrange the detail coefficients based on magnitude (from high to low order) and retain the top-k % coefficients. The efficacy of choosing top-k compared to different baselines (such as random-k and bottom-k) is empirically verified in Sec. V-A. However, determining the suitable value of k is a challenge and, if not properly chosen, can lead to a major bottleneck in clean/adversarial performance. To handle it, we propose a wavelet coefficient selection mechanism that carefully selects the value of k so that decent performance can be obtained on both the clean and adversarial data.</p><p>We empirically estimate optimal k using all the crafted synthetic training samples S d and their corresponding adversarial counterparts. We define a quantity label consistency rate (LCR k ) which is calculated for a particular value of k using the following steps:</p><p>1) Construct adversarial synthetic samples ({x i sa } N i=1 ) by using an adversarial attack A j a ? A a on the surrogate model S m .</p><p>2) Obtain approximate and detail coefficients for each adversarial synthetic sample using DW T (x i sa , l), ?i ? (1, . . . , N ) where l is the decomposition level.</p><p>3) Craft spatial samples ( Sk da = {x i sa } N i=1 ) using IDW T operation on complete approximate and selected topk detail coefficients corresponding to each adversarial synthetic sample (i.e. S da = x i sa , ?i ? (1, . . . , N )). For simplicity, we envelop the operations (2) and (3) and name them 'wavelet noise remover' (WNR). In general, for a given input image and k value, WNR applies DW T on input where the approximate coefficients and the chosen top-k % detail coefficients are retained, whereas the non-selected detail coefficients are made to zeros. These coefficients are then passed to IDW T to obtain the filtered spatial image. Using above steps, we calculate</p><formula xml:id="formula_2">LCR for different values of k ? [1, ? ? ? , k max ].</formula><p>As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, we observe that as we increase the value of k, initially LCR A increases and reaches its maximum value, and then it starts decreasing. High LCR A implies that the predictions of the B m model on Sk da and S d have a low mismatch. Similarly, with the increase in value of k, LCR C keeps increasing which implies as we add more coefficients, model discriminability increases. The value of LCR increases with the value of k, but the rate of increase of LCR keeps decreasing. Refer Fig. <ref type="figure" target="#fig_5">5</ref> where we plot the rate of change (ROC). We choose k at which ROC saturates. Here ROC is negligible at k = 16. This value of k gives the best trade-off between clean and adversarial accuracy (empirically validated in Sec. V-B). Thus, wavelet noise remover (WNR) is applied on input at estimated optimal k ( k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Training of Regenerator Network</head><p>After the noise removal using the WNR at optimal k (i.e. k obtained by WCSM), there is also loss in the image signal information as a side effect. Thus, we further regenerate the coefficients using a regenerator network (R n ) that takes input as the output of WNR at k and yields reconstructed image which is finally passed to the black box model B m for test predictions. The architecture of our R n network is a U-net based architecture with skip connections which is inspired from <ref type="bibr" target="#b45">[46]</ref>. It is a encoder-decoder model, where encoder downsamples the input and provide high level information at the bottleneck. After downsampling, the bottleneck information is passed to the decoder that upsamples it to provide the final reconstructed image. For more details on the architecture of regenerator network, refer Supplementary (Sec. III).</p><p>For training, we feed the output obtained from the WNR at k as input to the network R n and obtain a reconstructed image which is passed to the frozen surrogate model S m for loss calculations. The losses used to train R n are as follows:</p><p>? Cosine similarity loss (L cs ), to enforce similar predictions from S m on the regenerated synthetic sample and the corresponding original synthetic sample. ? KL divergence loss (L kl ), to align the predictions of S m on the regenerated sample and its adversarial counterpart. ? Spatial consistency loss (L sc ), to make sure that the spatial reconstructed image (clean and adversarial) and the corresponding original synthetic image are similar in the image manifold. The losses are calculated on i th synthetic sample as below:</p><formula xml:id="formula_3">k = W CSM (S d , S m ) xi s = W N R(x i s , k) xi sa = W N R(x i sa , k)<label>(1)</label></formula><formula xml:id="formula_4">L cs = CS(S m (R n (x i s )), S m (x i s ))<label>(2)</label></formula><formula xml:id="formula_5">L kl = KL(sof t(S m (R n (x i sa ))), sof t(S m (R n (x i s )))) (3) L sc = R n (x i s ) -x i s 1 + R n (x i sa ) -x i s 1<label>(4)</label></formula><p>Here, CS and KL denotes cosine similarity and KL divergence respectively. Overall loss used in training R n :</p><formula xml:id="formula_6">L(R ? n ) = -? 1 L cs + ? 2 L kl + ? 3 L sc<label>(5)</label></formula><p>Finally, the black box model B m is modified by prepending the WNR (with k = k) and the trained R n network to it. The overall steps of our method DBMA are summarized in Sec. VII in supplementary. The resulting black box model defends the adversarial attacks which we discuss in detail in next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In this section, we validate the effectiveness of our proposed method (DBMA) and perform ablations to show the importance of individual components. We use the benchmark classification datasets i.e. CIFAR-10 <ref type="bibr" target="#b46">[47]</ref> and SVHN <ref type="bibr" target="#b47">[48]</ref>, on which we evaluate the clean and the adversarial accuracy against three different adversarial attacks (i.e., BIM <ref type="bibr" target="#b48">[49]</ref>, PGD <ref type="bibr" target="#b49">[50]</ref> and Auto Attack <ref type="bibr" target="#b50">[51]</ref>). Throughout all the experiments, we use Alexnet <ref type="bibr" target="#b51">[52]</ref> as black box B m (results on a larger black-box model are in Sec. VI in supplementary) and Resnet-18 <ref type="bibr" target="#b52">[53]</ref> as the defender's surrogate model S d m , which the defender uses to train the regenerator network R n as explained in Sec. IV. In the black-box setting, attackers also do not have access to the black-box model's weights, thus restricting the generation of adversarial samples. So similar to the defender, we leverage the model stealing techniques to get a new surrogate model S a m , which the attacker uses for generating the adversarial samples.</p><p>We perform experiments with two different architectures for S a m : Alexnet-half and Alexnet, which are similar to the black-box model (Alexnet), making it tough for the defender. Ablation for different combination of S d m and S a m are in Sec. V in supplementary. The attacker uses the same model stealing technique <ref type="bibr" target="#b19">[20]</ref> as used by defender. We use the Daubechies wavelet for both DW T and IDW T operations. Refer to supplementary (Sec. I) for experimental results on other wavelets. The decomposition level is fixed at 2 for all the experiments and ablations. The value of k max is taken as 50. We assign equal weights to all the losses with weight as 1 (i.e. ? 1 = ? 2 = ? 3 = 1) in eq. 5. The defender constructs a defense module (D m ) using S d m . In subsections V-A, V-B and V-C, the defense module only consists of the WNR , whereas subsections V-D onwards, both R n and WNR are part of the defense module as shown in Fig. <ref type="figure" target="#fig_4">4</ref>. We prepend the defense module before the B m to create a new black box model that is used to defend against the adversarial attacks. To show the efficacy of defense components used in our method (DBMA), we consider the most challenging scenario, where the attacker uses the same model stealing technique as defender, and considers the defense module also a part of the black-box model while generating adversarial samples. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Ablation on coefficient selection strategy</head><p>Apart from approximate coefficients, we select only a limited number of coefficients(i.e., k% coefficients) to obtain a decent tradeoff between the adversarial and clean performance. As shown in Fig <ref type="figure" target="#fig_9">1 (A)</ref>, the least affected approximate coefficients have a high magnitude. Thus, we select the essential detail coefficients as the top-k high magnitude. As they are likely to be less affected by the adversarial attack (Fig 1 <ref type="figure">(B</ref>)), they can yield better performance. In this section, we perform an ablation to assess the effectiveness of selecting topk coefficients over the other possible choices. For comparative analysis, we perform the experiments using the bottom-k and random-k coefficients. Table <ref type="table" target="#tab_2">I</ref> shows the adversarial and clean performance for the different coefficient selection strategies. The top-k coefficient selection strategy, selecting the most important coefficient in terms of magnitude, improves both the clean and adversarial performance. On the other hand bottomk coefficient selection strategy, selecting the least significant coefficients shows the least performance as they primarily consist of contaminated high-frequency content. Although, randomly selecting k% coefficients showed improved performance than the bottom-k, it still performs poorly compared to top-k coefficient selection strategy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Ablation on quantity of coefficients</head><p>In Sec. I and IV, we discussed the importance of selecting the optimal number of detail coefficients ( k) and proposed the steps to find the value of k using the WCSM module. In this subsection, we do an ablation over the different choices for values of k (i.e., the number of detail coefficients to select) and analyze its impact on clean and adversarial accuracy. Specifically, we consider six distinct values of k across a wide range i.e. 0 (no detail coefficients, only approximate coefficients), 1, 2 and 4(small k), 50(large k), k (optimal k given by WCSM). Fig. <ref type="figure" target="#fig_5">5</ref> shows the graph of the rate of change of LCR for different values of k. We select the value of k at which the ROC starts saturating, i.e. k with value 16 as k. The results corresponding to the different values of k are shown in Table <ref type="table" target="#tab_2">II</ref>. We observe poor performance for both adversarial and clean samples when no detail coefficients are taken. On increasing the fraction of detail coefficients (k = 1, 2, 4), an increasing trend for both clean and adversarial performance is observed. Further, for a high value of k clean accuracy improves, but with a significant drop in the adversarial performance. Our choice of k (i.e., k) indeed leads to better clean accuracy with decent adversarial accuracy, hence justifying the importance of the proposed noise removal using WCSM component. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effect of wavelet noise remover with WCSM</head><p>In this section, we study the effect of prepending the WNR module to the black-box model B m . WNR selects the approximate coefficients and optimal k% detail coefficients (obtained by WCSM). It filters out the remaining detail coefficients, which helps in reducing the adversarial noise from the samples. We evaluate the performance of the B m with and without the WNR Module and present the results in Table <ref type="table" target="#tab_8">III</ref>. When the attacker's surrogate model is Alexnethalf, adversarial accuracy improves by ? 19 -22% across attacks using the WNR module. Similarly, when the attacker's surrogate model is Alexnet, the adversarial accuracy improves by ? 11 -12%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ablation on losses</head><p>Until now, we performed experiments by using only the WNR defense module. Now, we additionally attach another defense module (R n ) to WNR (refer <ref type="bibr">Fig 4)</ref>. In this subsection, we perform ablation to demonstrate the importance of different losses used for training the Regenerator network R n . As shown in eq. 5, the total loss L is the weighted sum of three different losses (i.e., L cs , L kl , and L sc ). To determine the effect of each of the individual losses, we train R n using only the L cs loss, L kl loss and L sc loss. Further to analyse the cumulative effect, we train R n with different possible pairs of loss i.e., L cs + L sc loss, L cs + L kl loss, L kl + L sc loss, and finally with the total loss (L cs + L kl + L sc ) respectively. The results are displayed in Table <ref type="table" target="#tab_5">IV</ref>.</p><p>Compared to the earlier best performance with WNR defense module (Table <ref type="table" target="#tab_8">III</ref>), we observe R n trained with only L cs loss gives no significant improvement in both the adversarial and clean accuracy. Similar trend is observed for R n trained with L sc loss. However, using only the L kl loss shows a deteriorated clean and adversarial performance of R n . Further, using the combination of both L cs and L sc loss also does not show much improvement. Combining the L kl with L cs and L sc loss improves the adversarial performance of R n appreciably, but with a drop in the clean accuracy. L kl with L cs loss shows a consistent improvement of ? 9 -11% in adversarial accuracy across attacks using both the Alexnet and Alexnet-half. Similarly, the combination of L kl with L sc loss improves the adversarial accuracy of R n by ? 11 -13% and ? 15-17% against the attacks using Alexnet-half and Alexnet respectively. When R n is trained with all three losses gives the best adversarial accuracy across all the possible combinations. We observe an overall improvement of ? 16 -19% across different attacks using both Alexnet and Alexnet-half with a slight drop in clean accuracy (? 4%). Regenerator networks regenerates the lost coefficients, but as explained in section IV-B, detail coefficients also cause a decrease in adversarial accuracy. When we train a regenerator network using the combination of L cs , L sc , and L kl loss, the L cs and L sc loss help to increase clean accuracy, but at the same time L kl loss ensures regenerated coefficients do not decrease the adversarial accuracy. To achieve best tradeoff between clean and adversarial accuracy, R n gets trained to increase adversarial accuracy at the cost of decreased clean accuracy compared to R n network trained with only L cs loss. Refer Sec. IV in supplementary for more experimental results emphasizing the importance of R n .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results on different datasets</head><p>In this subsection, we validate the efficacy of the complete proposed method DBMA consisting of both the WNR and R n defense components on two benchmark datasets, i.e., SVHN and CIFAR-10. We obtain the optimal k as 20 using the WCSM module for the black box model trained on SVHN dataset. In Table <ref type="table" target="#tab_6">V</ref>, with only WNR in the defender module, the adversarial accuracy improves by ? 10 -11% across attacks crafted using different surrogate architectures S a m (Alexnet and Alexnet-half). The clean accuracy, on the other hand, has a minor drop of less than 1%. While using both the WNR and R n in the defender module, the adversarial performance further improves by ? 13% and ? 14% across the attacks crafted using surrogate Alexnet-half and Alexnet, respectively. At the same time, the clean accuracy drops by ? 4%. Overall, we observe a gain of ? 24-26% in adversarial accuracy compared to the baseline model on the cost ? 5% drop in clean accuracy.</p><p>Similarly, for the CIFAR-10 dataset, we observe an overall improvement of ? 35 -38% and ? 29 -32% against the attacks crafted using Alexnet-half and Alexnet, respectively. We observe that the clean accuracy drops by ? 8% compared to baseline, which is reasonable considering the challenging nature of our problem setup. Even in traditional adversarial training with access to full data, clean performance often drops at the cost of improving adversarial accuracy <ref type="bibr" target="#b49">[50]</ref>. In our case, neither the training data nor the model weights are provided. Moreover, the black-box model is often obtained as APIs, and re-training the model from scratch becomes unfeasible. Considering these difficulties, the drop we observe on clean data is small with respectable overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Defense against different data-free black box attacks</head><p>All the previous experiments assume that both defender and attacker use the same model stealing technique <ref type="bibr" target="#b19">[20]</ref> for creating a surrogate model. To prove our data-free black box defense (DBMA) is robust to different model stealing strategies, we evaluate our method against two different approaches: a) Data-free model extraction (DFME) <ref type="bibr" target="#b22">[23]</ref> and b) Data-free model stealing in hard label setting (DFMS-HL) <ref type="bibr" target="#b20">[21]</ref> that are used by attacker to obtain a surrogate model (Alexnet-Half) for crafting adversarial samples. We use the same defense module used in Sec. V-E. As shown in Fig. <ref type="figure" target="#fig_6">6</ref>, our method yields a consistent boost in adversarial accuracy on different data-free model stealing methods. In the case of DFME, we observe a massive improvement of ?36%, ?40% and ?21% on BIM , PGD and Auto Attack respectively. On the other hand, in case of DFMS-HL the performance against the three attacks improves by ?28%, ?29%, and ?31%. Overall across different model stealing methods, our method (DBMA) yields significant improvement in adversarial accuracy (i.e. ? 29 -42% in PGD, ? 28 -38% in BIM , and ? 25 -31% in state-of-the-art Auto Attack).</p><p>Further, we check our defense in a more tougher scenario, where attacker is aware of the black box model B m 's architecture (i.e., Alexnet), and uses the same for attacker's surrogate model (S a m ). The results for this setup are reported in Table <ref type="table" target="#tab_7">VI</ref>. Compared to baseline, we observe an improvement of ? 29 -32%, ? 38 -40% and ? 22 -25% in adversarial accuracy across attacks using the Black box ripper, DFME and DFMS-HL methods, respectively. This indicates that even if the attacker is aware of the black box model's architecture, our method DBMA can provide data-free black-box adversarial defense irrespective of the different model stealing methods.</p><p>Hence, our proposed method DBMA provides strong robustness even when the attacker uses a different model stealing In this work, we presented our approach (DBMA) for defending the black-box model against adversarial attacks without any training data for the first time. Our approach consisted of two defense components that are prepended to the victim model: a) wavelet noise remover (WNR) that removes the most contaminated portions of the image affected by adversarial attack and retains the least affected regions determined by wavelet coefficient selection module (WCSM), b) regenerator network to retrieve the information lost after the noise removal using WNR. We showed the efficacy of each of the defense components via several ablations. The combined model (defense components and victim model) as a black box provides significant robustness against data-free black box attacks (constructed using different surrogate networks) across datasets. Also, we showed DBMA to be resistant and provide stronger robustness against the black box attacks crafted using different model stealing methods. Similar to contemporary work in adversarial defenses in white-box setups, we observe that significant gains in robust accuracy come at the cost of slight drop in clean accuracy. In future work, we plan to work on further mitigating this trade-off. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMPORTANCE OF REGENERATOR NETWORK</head><p>In order to evaluate the effectiveness of proposed Regenerator network R n in our approach DBMA, we analyze the performance of DBMA with and without R n for different values of k (i.e. k=1, 2, 4, 8, 16 (ours), 50). In Table <ref type="table" target="#tab_8">III</ref>, we observe that across different k, appending R n to the WNR improves the adversarial accuracy against various attacks crafted using Alexnet-half and Alexnet by ? 13 -18%. Further, we observe a similar trend for clean accuracy, which also improves on adding R n to WNR. However, the improvement margin for clean accuracy gradually drops on increasing the value of coefficient percent k. For higher k's (e.g., <ref type="bibr">16 , 50)</ref>, there is a small drop in clean performance using R n compared to the performance with only WNR but leads to significant increase in adversarial accuracy. This implies regenerator network enhances the output image of WNR to increase the adversarial accuracy. In this process, for smaller values of k, it increases clean accuracy too, but for a large value of k, the decrease in clean accuracy is compensated by the increase in adversarial accuracy to achieve the best trade-off. Combining WNR with the regenerator network at our k (i.e., k = 16) produces the best adversarial accuracy.</p><p>From Table <ref type="table" target="#tab_5">IV</ref>, we observe that DBMA with only WNR improves adversarial accuracy with a small drop in clean accuracy compared to baseline. Similarly, with only regenerator network R n , adversarial accuracy increases compared to the baseline. Also, R n performs better than WNR. However, using WNR and R n together in DBMA gives the best adversarial accuracy. Hence this demonstrates the importance of both the defense components (WNR and R n ) in our method DBMA.  ). We observe that the bigger the network size, the more accurate the surrogate models. With accurate surrogate models, the gradients with respect to the input are better estimated. Thus better black-box attacks and defenses can be obtained using the bigger architectures for surrogate models. For better defense, S d m should have a relatively higher capacity than S a m . This can be confirmed by rows 1, 4, and 7, where the defense becomes more effective on increasing the S d m 's capacity against various attacks using Alexnet-half as S a m . A similar trend is observed against the attacks crafted using Alexnet and Resnet18. For the other way around, i.e., when S a m has relatively higher capacity than S d m , more powerful attacks can be crafted. This is evident from rows 1, 2, and Apart from the wavelet transformations, some recent works utilised the fourier transformations to remove the adversarial noise from the adversarial images, and further found it to be effective in denoising <ref type="bibr" target="#b57">[58]</ref>. In this section, we do an ablation on our choice of Wavelet-based Noise Remover (WNR) over the other possible choice of fourier-based Noise Remover (FNR). As observed in recent works <ref type="bibr" target="#b57">[58]</ref>, adversarial attack affects the high-frequency components more than low-frequency components. Therefore, In FNR we apply a low pass filter on an image with threshold radius r. Similar to WCSM, we compute LCR C , LCR A , LCR and ROC for different values of r. The optimal value of r (i.e., r) is selected at which ROC starts saturating (r = 11). In Table <ref type="table" target="#tab_12">VII</ref>, we observe, compared to baseline, Fourier-based DBMA gives an improvement of ? 21 -34% in adversarial accuracy across attacks for Alexnet half (rows 1 and 3).Compared to Fourierbased DBMA, the results using our wavelet-based DBMA are significantly better in terms of adversarial accuracy (rows 1 and 5) with similar clean performance. Similarly, for Alexnet, Wavelet-based DBMA gives ? 16 -24% better adversarial accuracy compared to Fourier based DBMA across all attacks (rows 8 and 10). Hence, our method wavelet-based DBMA is more robust across different adversarial attacks than Fourierbased DBMA. if label(Bm(x i sa )) = label(Bm(x i s )) then  <ref type="table" target="#tab_12">VIII</ref>.</p><p>Training details of Regenerator Network (R n ): The regenerator network is trained with Adam optimizer with learning rate of 0.0002 for 300 epochs. Learning rate is decayed using linear scheduler, where we keep the learning rate fixed for 100 epochs and then linearly decay the rate to zero. Batch size is set to 128.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The average absolute magnitude of approximate (LL) and detail coefficients (LH, HL and HH) (via wavelet decomposition) across samples on a) clean data and b) normalized difference between wavelet decomposition of clean and corresponding adversarial image. In (a) the lesser contaminated LL coefficients have higher magnitude. In (b) LL are least affected.</figDesc><graphic url="image-1.png" coords="2,46.54,189.56,127.43,85.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(Sec. V-D) which are appended before the black box target model. The resulting combined model used as the new black box (as seen by attacker), yields high clean and adversarial accuracy on test data (Sec. V-E). II. RELATED WORKS Our work is closely related to model stealing and wavelets, so we briefly discuss their related works below. Data-efficient Model stealing: Based on the availability of training data, we categorize model stealing works as follows: ? Training data -On full training data, knowledge distillation [27] is used to extract knowledge using soft labels obtained from the black box model. With few training samples, Papernot et al. [14] generates additional synthetic data in the directions (computed using jacobian) where model's output varies in the neighborhood of training samples. ? Proxy data -In the absence of training data, either natural or synthetic images are used as proxy data. Orekondy et al. [19] query the black box model on the natural images using adaptive strategy via reinforcement learning to get output predictions and use them to replicate the functionality of the black box model. Barbalau et al. [20] use evolutionary framework to learn image generation on a proxy dataset where the generated images are enforced to exhibit high confidence on the black box model. Sanyal et al. [21] use the GAN framework with a proxy dataset composed of either related/unrelated data or synthetic data. ? Without Proxy data -Kariyappa et al. [22] proposed</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An overview of our proposed approach DBMA. In step 1, we obtain the defender's surrogate model S d m and synthetic data S d by model stealing from the victim model Bm. In step 2, we use the Wavelet Coefficient Selection Module (WCSM) that gives the optimal % of coefficients ( k) to be selected by the Wavelet Noise Remover (WNR) which are likely to be least corrupted by adversarial attacks. In step 3, we train a regenerator network Rn using different losses (Lcs, L kl , Lsc) such that the model S d m yields features on the regenerated data (clean Rn( Sk d ) and adversarial Rn( Sk da )) similar to the features on clean data S d . Finally in step 4, we evaluate our DBMA approach on test clean (O test d ) and adversarial samples (O test da ) where the WNR (with k = k) and trained Rn are prepended to Bm.</figDesc><graphic url="image-3.png" coords="4,48.96,56.07,514.07,232.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Given a black box model B m , our first step is to obtain a proxy model S m which can allow gradient backpropagation. To steal the functionality of B m , S m can be trained using a model stealing technique. But we also do not have access to the original training samples O train d . Hence, we use a datafree model stealing technique [20] that trains a generator using proxy data to produce synthetic samples (S d ) on which the black box model B m gives high-confident predictions. The surrogate model S m is then trained on synthetic data S d under the guidance of B m , where the model S m is enforced to mimic the predictions of model B m . The trained S m and the generated data S d are used in next steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Defense module Dm consisting of Wavelet Noise Remover (WNR) and Regenerator Rn is prepended before the victim model Bm in our approach (DBMA). The Dm and Bm are combinedly considered as the blackbox model by the attacker.</figDesc><graphic url="image-4.png" coords="6,71.68,322.25,205.61,79.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Rate of change (ROC) of LCR vs detail coefficients (k%) plotted using prediction from black-box model Bm on Cifar-10 data. As we increase value of k, ROC becomes negligible. At k = 16 it is close to zero.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Performance of our approach DBMA for different model stealing methods used to get the attacker's surrogate model for data-free black box attacks. DBMA consistently improves performance against different attacks across all model stealing methods.</figDesc><graphic url="image-5.png" coords="8,308.99,238.61,257.03,154.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm 1 2 :</head><label>12</label><figDesc>Algorithm for our proposed method (DBMA) Input: Black box model Bm, max coefficients k max Output: Bm Step 1: Model Stealing 1: Surrogate model Sm, Synthetic data S d ? Model Stealing on Bm Step Wavelet Coefficient Selection Module 2: Obtain adversarial samples (S da ) corresponding to S d using adversarial attack on Sm 3: for k = 1 : k max : do 4: Sk da ? WNR(S da ,k) Sk da [i] {i th element of Sk da } 8: x i s ? S d [i] {i th element of S d } 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>24 :-x i s 1 27 :</head><label>2427</label><figDesc>LF R k = N f lips /|S d | 14: end for 15: k = argmin k LF R k Step 3: Training Regenerator network (Rn) 16: Sk d ? WNR(S d , k) 17: Sk da ? WNR(S da , k) 18: Initialize R ? n 19: for epoch &lt; M axEpoch do 20: for i = 1 : (|S d |) do 21:x i s ? S d [i] {i th element of S d } Lcs = CS(Sm(Rn(x i s )), Sm(x i s )){CS is cosine similarity} 25:L kl = KL(sof t(Sm(Rn(x i sa ))), sof t(Sm(Rn(x i s )))) {KL is KL divergence} 26:Lsc = Rn(x i s ) -x i s 1 + Rn(x i sa ) L(R ? n ) = -?1Lcs + ?2L kl + ?3Lsc 28:Update R ? n by minimizing L(R ? n ) using Adam Optimizer 29: end for 30: end for 31: Bm ? concatenate(W N R(., k), R ? * n , Bm) {The black box model Bm is used by attacker} 32: return Bm IX. ADVERSARIAL ATTACK PARAMETERS AND TRAINING DETAILS We evaluate the performance of black box model (B m ) on three adversarial attacks, PGD, BIM and Auto Attack. Parameters used for each attack are summarized in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Visualization of images: The top row indicates input as clean image and bottom row corresponds to adversarial image. The predictions obtained by the black-box network on inputs: (a) Original clean image (b) Output of wavelet noise remover on clean image (c) Output of WNR with regenerator network (Rn) on clean image (d) Original adversarial image (e) Output of wavelet noise remover (WNR) on adversarial image (f) Output of WNR with regenerator network (Rn) on adversarial Image. Here, the ground truth class is Cat. Our method (DBMA) produces correct output using regenerated image as input.</figDesc><graphic url="image-9.png" coords="15,322.45,333.70,85.07,85.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>:</head><label></label><figDesc>The black box model is denoted by B m which is trained on the proprietary training dataset O train d . We denote the surrogate model by S m . The generator G produces synthetic data S d = {x i s } N i=1 containing N samples. The logit obtained by the model S m on input x is S m (x). The softmax and the label predictions on sample x by model S m are represented by sof t(S m (x)) and label(S m (x)) respectively. An attack A i a ? A a is referred as adversarial attack when an original image x o is perturbed with carefully crafted human-imperceptible noise ( ? ? &lt; , called adversarial noise) such that the model's predictions on the perturbed sample (i.e. adversarial sample) x oa is different from x o . In the case of black box adversarial attack, the surrogate model S m is used to craft adversarial samples. By property of transferability, these samples are also suitable to attack the black box model B m .</figDesc><table><row><cell cols="3">The set A a = {A p a } P p=1 contains P different adversarial</cell></row><row><cell cols="3">attacks. The adversarial sample corresponding to the n th</cell></row><row><cell cols="2">sample of test dataset O test d</cell><cell>(i.e. x n o ) is denoted by x n oa which</cell></row><row><cell cols="3">is crafted with a goal to fool the network B m . Similarly, S da</cell></row><row><cell cols="3">is the set of crafted adversarial samples corresponding to the</cell></row><row><cell cols="3">synthetic data S d where the adversarial sample x n sa ? S da is obtained by perturbing the synthetic sample x n s ? S d using an adversarial attack A j a ? A a .</cell></row><row><cell cols="3">We denote the discrete wavelet transform and its inverse op-</cell></row><row><cell cols="3">eration by DW T (.) and IDW T (.) respectively. The wavelet</cell></row><row><cell cols="3">coefficient selection module is denoted by WCSM. The regen-</cell></row><row><cell cols="3">erator network is represented by R n .</cell></row><row><cell cols="3">Model Stealing: The objective is to steal the functionality</cell></row><row><cell cols="3">of the black box model B m whose information about the</cell></row><row><cell cols="3">architecture, weights and training details such as loss function,</cell></row><row><cell cols="3">hyperparameters etc., are not accessible. The adversary creates</cell></row><row><cell cols="3">an (input, output) pair where input image is fed to the black</cell></row><row><cell cols="3">box API and output is the response obtained from it. Using</cell></row><row><cell cols="3">this paired data, a surrogate model S m is trained. When the</cell></row><row><cell>training dataset O train d</cell><cell cols="2">is not available, then we refer to this</cell></row><row><cell cols="3">problem as data-free model stealing.</cell></row><row><cell cols="2">Adversarial Attacks:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>4) Perform WNR by repeating the steps 2 and 3 on clean samples x s to obtain Sk d . 5) Compare the predictions of black box model B m on samples of Sk d and the corresponding samples in S d . LCR k C denotes the fraction of clean samples whose predictions match when top-k % coefficients are selected. 6) Compare the predictions of the black box model B m on samples of Sk da and the corresponding samples in S d . LCR k A denotes the fraction of adversarial samples whose predictions match when top-k % coefficients are selected. 7) Compute LCR k = LCR k C + LCR k</figDesc><table><row><cell>Label Consistency Rate</cell></row><row><cell>Detailed Coefficients (k%)</cell></row></table><note><p><p>A 8) Calculate the rate of change of LCR k (i.e. ROC k ) as ROC k = LCR k+1 -LCR k</p>Fig. 3. Label consistency rates (LCR A , LCR C and LCR) vs detail coefficients (k%) plotted using prediction from black-box model Bm on Cifar-10 Dataset.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I PERFORMANCE</head><label>I</label><figDesc>COMPARISON WHEN k% DETAIL COEFFICIENTS ARE SELECTED IN WAVELET COEFFICIENT SELECTION MODULE (WCSM) USING DIFFERENT METHODS. SELECTION OF TOP-K COEFFICIENTS YIELDS BETTER CLEAN AND ADVERSARIAL ACCURACY THAN OTHER STRATEGIES.</figDesc><table><row><cell>Surrogate</cell><cell>coefficient</cell><cell></cell><cell cols="3">Black Box Model : Alexnet</cell></row><row><cell>model</cell><cell>selection</cell><cell cols="4">Surrogate Model (defense): Resnet-18</cell></row><row><cell>(attacker)</cell><cell>strategy</cell><cell>clean</cell><cell>BIM</cell><cell>PGD</cell><cell>Auto Attack</cell></row><row><cell>Alexnet-half</cell><cell>bottom-k random-k top-k (ours)</cell><cell>31.25 42.58 77.92</cell><cell>8.59 13.13 26.66</cell><cell>7.32 11.74 24.55</cell><cell>12.57 19.77 34.02</cell></row><row><cell></cell><cell>bottom-k</cell><cell>31.25</cell><cell>6.14</cell><cell>4.84</cell><cell>10.92</cell></row><row><cell>Alexnet</cell><cell>random-k</cell><cell>42.92</cell><cell>8.61</cell><cell>7.52</cell><cell>14.29</cell></row><row><cell></cell><cell>top-k (ours)</cell><cell>77.92</cell><cell>15.98</cell><cell>14.04</cell><cell>21.34</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV CONTRIBUTION</head><label>IV</label><figDesc>OF DIFFERENT LOSSES USED FOR TRAINING Rn.THE LOSS (Lcs + L kl + Lsc) GIVES THE BEST IMPROVEMENT IN ADVERSARIAL ACCURACY WITH DECENT CLEAN ACCURACY.</figDesc><table><row><cell>Surrogate</cell><cell>Losses to train</cell><cell></cell><cell cols="3">Black Box Model : Alexnet</cell></row><row><cell>model</cell><cell>Regenerator</cell><cell cols="4">Surrogate Model (defense): Resnet-18</cell></row><row><cell>(attacker)</cell><cell>network (Rn)</cell><cell>clean</cell><cell>BIM</cell><cell>PGD</cell><cell>Auto Attack</cell></row><row><cell>Alexnet-half</cell><cell>Lcs Lsc L kl</cell><cell>78.96 78.85 9.82</cell><cell>26.33 27.38 6.56</cell><cell>24.75 25.75 6.54</cell><cell>33.81 35.51 8.98</cell></row><row><cell></cell><cell>Lcs + Lsc</cell><cell>79.75</cell><cell>27.70</cell><cell>25.34</cell><cell>34.64</cell></row><row><cell></cell><cell>Lcs + L kl</cell><cell>62.06</cell><cell>36.03</cell><cell>35.93</cell><cell>43.05</cell></row><row><cell></cell><cell>L kl + Lsc</cell><cell>65.94</cell><cell>37.72</cell><cell>37.62</cell><cell>46.14</cell></row><row><cell></cell><cell>Lcs+ L kl + Lsc</cell><cell>73.77</cell><cell>42.71</cell><cell>42.71</cell><cell>50.63</cell></row><row><cell></cell><cell>Lcs</cell><cell>78.96</cell><cell>16.34</cell><cell>14.57</cell><cell>21.81</cell></row><row><cell>Alexnet</cell><cell>Lsc</cell><cell>78.85</cell><cell>17.68</cell><cell>15.97</cell><cell>23.77</cell></row><row><cell></cell><cell>L kl</cell><cell>9.82</cell><cell>6.61</cell><cell>6.38</cell><cell>8.98</cell></row><row><cell></cell><cell>Lcs+ Lsc</cell><cell>79.75</cell><cell>17.28</cell><cell>15.6</cell><cell>23.59</cell></row><row><cell></cell><cell>Lcs+ L kl</cell><cell>62.06</cell><cell>24.86</cell><cell>25.91</cell><cell>32.26</cell></row><row><cell></cell><cell>L kl + Lsc</cell><cell>65.94</cell><cell>31.04</cell><cell>31.05</cell><cell>38.26</cell></row><row><cell></cell><cell>Lcs+ L kl + Lsc</cell><cell>73.77</cell><cell>33.31</cell><cell>31.72</cell><cell>40.56</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V UTILITY</head><label>V</label><figDesc>OF EACH COMPONENT USED IN OUR METHOD (DBMA)-WAVELET NOISE REMOVER (WNR) AND REGENERATOR NETWORK Rn ON SVHN AND CIFAR DATASET. WNR WITH Rn YIELDS HUGE GAINS IN ADVERSARIAL PERFORMANCE COMPARED TO BASELINE AND WNR ALONE.</figDesc><table><row><cell>Surrogate Model (attacker)</cell><cell>Dataset</cell><cell>Method</cell><cell>clean</cell><cell cols="3">Black Box Model : Alexnet Surrogate Model (defender) : Resnet-18 BIM PGD Auto Attack</cell></row><row><cell></cell><cell></cell><cell>Baseline</cell><cell>94.49</cell><cell>44.26</cell><cell>44.21</cell><cell>46.79</cell></row><row><cell>Alexnet-half</cell><cell>SVHN</cell><cell>WNR (Ours) WNR+ Rn (Ours)</cell><cell>94.21 90.91</cell><cell>55.42 (? 11.16) 68.63 (? 24.37)</cell><cell>55.70 (? 11.49) 68.60 (? 24.39)</cell><cell>58.47(? 11.68) 71.71 (? 24.92)</cell></row><row><cell></cell><cell></cell><cell>Baseline</cell><cell>82.58</cell><cell>7.02</cell><cell>4.53</cell><cell>11.65</cell></row><row><cell></cell><cell>CIFAR</cell><cell>WNR (Ours)</cell><cell>77.92</cell><cell>26.66 (? 19.64)</cell><cell>24.55 (? 20.02)</cell><cell>34.02 (? 22.37)</cell></row><row><cell></cell><cell></cell><cell>WNR+ Rn (Ours)</cell><cell>73.77</cell><cell>42.71 (? 35.69)</cell><cell>42.71 (? 38.18)</cell><cell>50.63 (? 38.98)</cell></row><row><cell></cell><cell></cell><cell>Baseline</cell><cell>94.49</cell><cell>38.14</cell><cell>38.19</cell><cell>40.16</cell></row><row><cell>Alexnet</cell><cell>SVHN</cell><cell>WNR (Ours) WNR+ Rn (Ours)</cell><cell>94.21 90.91</cell><cell>48.98 (? 10.84) 63.13 (? 24.99)</cell><cell>49.02 (? 10.83) 63.12 (? 24.93)</cell><cell>51.49 (? 11.33) 66.18 (? 26.02)</cell></row><row><cell></cell><cell></cell><cell>Baseline</cell><cell>82.58</cell><cell>4.17</cell><cell>2.19</cell><cell>8.55</cell></row><row><cell></cell><cell>CIFAR</cell><cell>WNR (Ours)</cell><cell>77.92</cell><cell>15.98 (? 11.81)</cell><cell>14.04 (? 11.85)</cell><cell>21.34(? 12.79)</cell></row><row><cell></cell><cell></cell><cell>WNR+ Rn (Ours)</cell><cell>73.77</cell><cell>33.31 (? 29.14)</cell><cell>31.72 (? 29.53)</cell><cell>40.56 (? 32.01)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI PERFORMANCE</head><label>VI</label><figDesc>OF DBMA ACROSS SEVERAL DATA-FREE BLACK BOX ATTACKS THAT ARE CONSTRUCTED USING THE SURROGATE MODEL HAVING SAME ARCHITECTURE AS THE BLACK BOX MODEL. WE OBSERVE CONSISTENT SIGNIFICANT IMPROVEMENTS IN ADVERSARIAL PERFORMANCE USING PROPOSED DBMA ACROSS DIFFERENT ADVERSARIAL ATTACKS AND MODEL STEALING TECHNIQUES.</figDesc><table><row><cell>Surrogate model (attacker)</cell><cell>Method</cell><cell>Model stealing (Attacker)</cell><cell>clean</cell><cell cols="3">Black Box Model : Alexnet Surrogate Model (defense): Resnet-18 BIM PGD Auto Attack</cell></row><row><cell></cell><cell>Without DBMA</cell><cell>Black Box Ripper</cell><cell>82.58</cell><cell>4.17</cell><cell>2.19</cell><cell>8.55</cell></row><row><cell></cell><cell>With DBMA (Ours)</cell><cell>Black Box Ripper</cell><cell>73.77</cell><cell>33.31 (? 29.14)</cell><cell>31.72 (? 29.53)</cell><cell>40.56 (? 32.01)</cell></row><row><cell>Alexnet</cell><cell>Without DBMA With DBMA (Ours)</cell><cell>DFME DFME</cell><cell>82.58 73.77</cell><cell>4.21 42.84 (? 38.63)</cell><cell>1.99 42.49 (? 40.5)</cell><cell>16.93 55.04 (? 38.11)</cell></row><row><cell></cell><cell>Without DBMA</cell><cell>DFMS-HL</cell><cell>82.58</cell><cell>3.30</cell><cell>1.82</cell><cell>7.84</cell></row><row><cell></cell><cell>With DBMA (Ours)</cell><cell>DFMS-HL</cell><cell>73.77</cell><cell>26.0 (? 22.7)</cell><cell>24.94 (? 23.12)</cell><cell>32.57 (? 24.73)</cell></row><row><cell cols="3">strategy compared to the defender. Refer to supplementary</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">(Sec. II) for adversarial robustness results when the defender</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">uses different model stealing methods to obtain the surrogate</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>model.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">VI. CONCLUSION</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE III PERFORMANCE</head><label>III</label><figDesc>OF DBMA WITH AND WITHOUT REGENERATOR NETWORK ACROSS DIFFERENT VALUES OF k. FOR LOW VALUES OF k, REGENERATOR NETWORK IMPROVES BOTH CLEAN AS WELL AS ADVERSARIAL ACCURACY. FOR k = 16, SMALL DECREASE IN CLEAN ACCURACY, BUT ADVERSARIAL ACCURACY INCREASES SIGNIFICANTLY.</figDesc><table><row><cell>Surrogate model (attacker)</cell><cell>Coefficients (k%)</cell><cell>Method</cell><cell>clean</cell><cell cols="3">Black Box Model : Alexnet Surrogate Model (defense): Resnet-18 BIM PGD Auto Attack</cell></row><row><cell></cell><cell>1</cell><cell>WNR WNR + Rn</cell><cell>42.75 56.08</cell><cell>14.89 30.58 (? 15.69)</cell><cell>13.79 30.14 (? 16.35)</cell><cell>21.41 37.04 (? 15.63)</cell></row><row><cell></cell><cell>2</cell><cell>WNR WNR + Rn</cell><cell>50.17 60.35</cell><cell>17.34 34.94 (? 17.60)</cell><cell>16.38 34.61 (? 18.23)</cell><cell>25.36 41.61 (? 16.25)</cell></row><row><cell>Alexnet-half</cell><cell>4 8</cell><cell>WNR WNR + Rn WNR WNR + Rn</cell><cell>59.14 65.82 69.89 70.37</cell><cell>21.99 39.65 (? 17.66) 24.9 41.89 (? 16.99)</cell><cell>20.77 39.62 (? 18.85) 23.54 42.21 (? 18.67)</cell><cell>29.43 46.94 (? 17.51) 33.04 49.88 (? 16.84)</cell></row><row><cell></cell><cell>16</cell><cell>WNR WNR + Rn</cell><cell>77.92 73.77</cell><cell>26.66 42.71 (? 16.05)</cell><cell>24.55 42.71 (? 18.16)</cell><cell>34.02 50.63 (? 16.61)</cell></row><row><cell></cell><cell>50</cell><cell>WNR WNR + Rn</cell><cell>82.58 75.19</cell><cell>11.36 33.12 (? 21.76)</cell><cell>8.23 31.60 (? 23.37)</cell><cell>17.34 40.11 (? 22.77)</cell></row><row><cell></cell><cell>1</cell><cell>WNR WNR + Rn</cell><cell>42.75 56.08</cell><cell>10.20 24.02 (? 14.82)</cell><cell>8.72 23.13 (? 14.41)</cell><cell>15.80 30.55 (? 14.75)</cell></row><row><cell>Alexnet</cell><cell>2 4</cell><cell>WNR WNR + Rn WNR WNR + Rn</cell><cell>50.17 60.34 59.14 65.82</cell><cell>15.37 32.89 (? 17.52) 17.54 31.00 (? 13.46)</cell><cell>14.14 32.24 (? 18.10) 16.03 30.85 (? 14.82)</cell><cell>21.92 40.50 (? 18.58) 25.08 38.26 (? 13.18)</cell></row><row><cell></cell><cell>8</cell><cell>WNR WNR + Rn</cell><cell>69.89 70.37</cell><cell>19.65 34.13 (? 14.48)</cell><cell>18.30 33.61 (? 15.31)</cell><cell>27.73 41.08 (? 13.35)</cell></row><row><cell></cell><cell>16</cell><cell>WNR WNR + Rn</cell><cell>77.92 73.77</cell><cell>15.98 33.31 (? 17.33)</cell><cell>14.04 31.72 (? 17.68)</cell><cell>21.34 40.56 (? 19.22)</cell></row><row><cell></cell><cell>50</cell><cell>WNR WNR + Rn</cell><cell>82.58 75.19</cell><cell>5.58 19.65 (? 14.07)</cell><cell>3.33 18.38(? 15.04)</cell><cell>10.44 25.41 (? 14.97)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE IV ABLATION</head><label>IV</label><figDesc>ON DEFENSE COMPONENTS OF PROPOSED DBMA AND COMPARISON WITH BASELINE. BOTH THE COMPONENTS INDIVIDUALLY PROVIDE BETTER DEFENSE THAN BASELINE. DBMA YIELDS BEST PERFORMANCE WHEN WNR AND Rn ARE USED TOGETHER. This shows that the value of k is not much sensitive to the choice of architecture of the defender's surrogate model S d m . The results are reported in Table V. We obtain the best performance for Resnet-18 as S d m and Alexnet-half as S a m (1 st row), whereas the lowest for Alexnethalf as S d m and Resnet18 as S a m (6 th row). Further, on carefully observing the results, we deduce some key insights. Clean accuracy remains similar across different choices of surrogate models, but adversarial accuracy depends on the surrogate</figDesc><table><row><cell>Surrogate model (attacker)</cell><cell>Defense Components</cell><cell>clean</cell><cell cols="3">Black Box Model : Alexnet Surrogate Model (defense): Resnet-18 BIM PGD Auto Attack</cell></row><row><cell>Alexnet-</cell><cell>Baseline</cell><cell>82.58</cell><cell>7.02</cell><cell>4.53</cell><cell>11.65</cell></row><row><cell>half</cell><cell>WNR</cell><cell>77.92</cell><cell>26.66 (? 19.69)</cell><cell>24.55 (? 20.02)</cell><cell>34.02 (? 22.37)</cell></row><row><cell></cell><cell>Rn</cell><cell>77.03</cell><cell>29.40 (? 22.38)</cell><cell>28.32 (? 23.79)</cell><cell>37.16 (? 25.51)</cell></row><row><cell></cell><cell>WNR + Rn</cell><cell>73.77</cell><cell>42.71 (? 35.69)</cell><cell>42.71 (? 38.18)</cell><cell>50.63 (? 38.98)</cell></row><row><cell>Alexnet</cell><cell>Baseline WNR</cell><cell>82.58 77.92</cell><cell>4.17 15.98 (? 11.81)</cell><cell>2.19 14.04 (? 11.85)</cell><cell>8.55 21.34 (? 12.79)</cell></row><row><cell></cell><cell>Rn</cell><cell>77.03</cell><cell>16.52 (? 12.35)</cell><cell>15.09 (? 12.9)</cell><cell>22.40 (? 13.85)</cell></row><row><cell></cell><cell>WNR + Rn</cell><cell>73.77</cell><cell>33.31 (? 29.14)</cell><cell>31.72 (? 29.53)</cell><cell>40.56 (? 32.01 )</cell></row><row><cell cols="6">V. ABLATION ON CHOICE OF SURROGATE ARCHITECTURE</cell></row><row><cell cols="6">To better analyze the performance of DBMA against dif-</cell></row><row><cell cols="6">ferent combinations of defender surrogate (S d m ) and attacker surrogate models (S a m ), we perform experiments with different</cell></row><row><cell cols="6">choices of surrogate models (i.e., Alexnet-half, Alexnet, and</cell></row><row><cell cols="6">Resnet18). For all the experiments, Alexnet is used as the</cell></row><row><cell cols="6">black box model. For Resnet18 as S d m , the wavelet coeffi-cient selection module (WCSM) yields optimal k ( k) as 16.</cell></row><row><cell cols="6">Similarly, for other choices of S d m (i.e., Alexnet and Alexnet-half), we obtain k as 15.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE V INVESTIGATING</head><label>V</label><figDesc>THE EFFECT OF SURROGATE MODEL'S ARCHITECTURE (FOR BOTH DEFENDER AND ATTACKER) ON THE PERFORMANCE OF OUR PROPOSED APPROACH (DBMA). WE OBSERVE THAT FOR A GIVEN DEFENDER'S SURROGATE MODEL, THE ATTACK IS STRONGER IF LARGER SURROGATE MODEL IS USED BY THE ATTACKER.</figDesc><table><row><cell>Surrogate model</cell><cell>Surrogate model</cell><cell></cell><cell cols="3">Black Box Model : Alexnet</cell></row><row><cell>(defender)</cell><cell>(attacker)</cell><cell>clean</cell><cell>BIM</cell><cell>PGD</cell><cell>Auto Attack</cell></row><row><cell>Resnet-18</cell><cell>Alexnet-half</cell><cell>73.77</cell><cell>42.71</cell><cell>42.71</cell><cell>50.63</cell></row><row><cell>Resnet-18</cell><cell>Alexnet</cell><cell>73.77</cell><cell>33.31</cell><cell>31.72</cell><cell>40.56</cell></row><row><cell>Resnet-18</cell><cell>Resnet-18</cell><cell>73.77</cell><cell>22.48</cell><cell>21.93</cell><cell>29.48</cell></row><row><cell>Alexnet-half</cell><cell>Alexnet-half</cell><cell>74.94</cell><cell>38.98</cell><cell>39.3</cell><cell>47.83</cell></row><row><cell>Alexnet-half</cell><cell>Alexnet</cell><cell>74.94</cell><cell>29.04</cell><cell>27.58</cell><cell>35.37</cell></row><row><cell>Alexnet-half</cell><cell>Resnet-18</cell><cell>74.94</cell><cell>20.72</cell><cell>19.11</cell><cell>26.79</cell></row><row><cell>Alexnet</cell><cell>Alexnet-half</cell><cell>74.67</cell><cell>40.08</cell><cell>39.6</cell><cell>48.5</cell></row><row><cell>Alexnet</cell><cell>Alexnet</cell><cell>74.67</cell><cell>29.49</cell><cell>28.63</cell><cell>36.93</cell></row><row><cell>Alexnet</cell><cell>Resnet-18</cell><cell>74.67</cell><cell>21.51</cell><cell>20.24</cell><cell>28.44</cell></row><row><cell cols="4">model of defender (S d m ) and attacker (S a m</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Throughout all our experiments, we used Alexnet as the black-box model B m . To check the consistency of our approach DBMA across different architecture, especially for bigger and high-capacity networks, we perform experiments using Resnet34 as black-box model and report corresponding results in Table VI. With Resnet18 and Alexnet as the defender's and attacker's surrogate model (S d m and S a m ) respectively, we observe the improvement of ? 27 -32% in adversarial accuracy across attacks compared to baseline (rows 3 rd and 4 th ). With Alexnet as the defender's surrogate and Resnet18 as the attacker's surrogate model, we get an improvement of ? 17 -23% across attacks (rows 1 st and 2 nd ). As observed in previous experiments, compared to baseline, clean accuracy drops by ? 7 -8%. Overall, across different black box models, our proposed defense DBMA has obtained decent performance. Hence we conclude, DBMA is even effective on bigger black box architectures.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>VII. COMPARISON WITH FOURIER TRANSFORM BASED</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NOISE REMOVAL</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">3, where stronger adversarial</cell></row><row><cell cols="7">samples are obtained on increasing the capacity of S a m for a given S d m . For instance, for Resnet18 as S d m , stronger attacks</cell></row><row><cell cols="7">(lower adversarial accuracy) are obtained by using Resnet18 as</cell></row><row><cell cols="7">S a m , followed by Alexnet and Alexnet-half. A similar pattern is observed on other choices of S d m .</cell></row><row><cell cols="7">VI. OUR DEFENSE (DBMA) ON LARGER BLACK BOX</cell></row><row><cell></cell><cell></cell><cell cols="2">MODEL</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE VI</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">PERFORMANCE OF OUR APPROACH DBMA IN DEFENDING THE LARGER</cell></row><row><cell cols="7">BLACK-BOX NETWORK (I.E., RESNET34). WE OBSERVE THAT DBMA</cell></row><row><cell cols="7">SHOWS A CONSISTENT IMPROVEMENT AGAINST THE DIFFERENT ATTACKS</cell></row><row><cell cols="7">WITH A SMALL DROP IN THE CLEAN ACCURACY ACROSS VARIOUS</cell></row><row><cell cols="7">COMBINATION OF DEFENDER AND ATTACKER SURROGATE MODELS.</cell></row><row><cell>DBMA</cell><cell>Surrogate Model</cell><cell>Surrogate Model</cell><cell cols="4">Black Box Model : Resnet34</cell></row><row><cell></cell><cell>(Defender)</cell><cell>(Attacker)</cell><cell>Clean</cell><cell>BIM</cell><cell>PGD</cell><cell>Auto-Attack</cell></row><row><cell></cell><cell>-</cell><cell>Resnet18</cell><cell>95.66</cell><cell>3.11</cell><cell>1.23</cell><cell>11.82</cell></row><row><cell>(Ours)</cell><cell>Alexnet</cell><cell>Resnet18</cell><cell>87.06</cell><cell>20.76</cell><cell>17.33</cell><cell>25.11</cell></row><row><cell></cell><cell>-</cell><cell>Alexnet</cell><cell>95.66</cell><cell>21.36</cell><cell>12.83</cell><cell>27.85</cell></row><row><cell>(Ours)</cell><cell>Resnet18</cell><cell>Alexnet</cell><cell>88.40</cell><cell>48.16</cell><cell>44.80</cell><cell>56.65</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE VII PERFORMANCE</head><label>VII</label><figDesc>OF OUR APPROACH DBMA WITH FOURIER TRANSFORM AND WAVELET TRANSFORM BASED NOISE REMOVAL TECHNIQUE (FNR AND WNR, RESPECTIVELY). WNR DEFENSE OUTPERFORMS THE FNR ACROSS DIFFERENT ATTACKS. ALSO, WNR-BASED DBMA (WNR + Rn) YIELDS MORE SIGNIFICANT GAINS IN PERFORMANCE ON CIFAR10.</figDesc><table><row><cell>Surrogate model</cell><cell>Method</cell><cell></cell><cell cols="3">Black Box Model : Alexnet Surrogate Model (defense): Resnet-18</cell></row><row><cell>(attacker)</cell><cell></cell><cell>clean</cell><cell>BIM</cell><cell>PGD</cell><cell>Auto Attack</cell></row><row><cell></cell><cell>Baseline</cell><cell>82.58</cell><cell>7.02</cell><cell>4.53</cell><cell>11.65</cell></row><row><cell>Alexnet-half</cell><cell>FNR FNR+ Rn WNR</cell><cell>79.14 74.13 77.92</cell><cell>13.30 (? 6.28) 28.38 (? 21.36) 26.66 (? 19.64)</cell><cell>10.86 (? 6.33) 27.05 (? 22.52) 24.55 (? 20.02)</cell><cell>20.47 (? 8.82) 35.47 (? 23.82) 34.02 (? 22.37)</cell></row><row><cell></cell><cell>WNR + Rn (Ours)</cell><cell>73.77</cell><cell>42.71 (? 35.69)</cell><cell>42.71 (? 38.18)</cell><cell>50.63 (? 38.98)</cell></row><row><cell></cell><cell>Baseline</cell><cell>82.58</cell><cell>4.17</cell><cell>2.19</cell><cell>8.55</cell></row><row><cell></cell><cell>FNR</cell><cell>79.14</cell><cell>5.87 (? 1.70)</cell><cell>4.03 (? 1.84)</cell><cell>10.97 (? 2.42)</cell></row><row><cell>Alexnet</cell><cell>FNR+ Rn</cell><cell>74.13</cell><cell>19.24 (? 15.07)</cell><cell>17.88 (? 15.69)</cell><cell>24.55 (? 16.00)</cell></row><row><cell></cell><cell>WNR</cell><cell>77.92</cell><cell>15.98 (? 11.81)</cell><cell>14.04 (? 11.85)</cell><cell>21.34 (? 12.79)</cell></row><row><cell></cell><cell>WNR + Rn (Ours)</cell><cell>73.77</cell><cell>33.31 (? 29.14)</cell><cell>31.72 (? 29.53)</cell><cell>40.56 (? 32.01)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>G. K. Nayak, I. Khatri, S. Randive, R. Rawal and A. Chakraborty are with the Department of Computational and Data Sciences, Indian Institute of Science, Bangalore, India, 560012.For all correspondence: Anirban Chakraborty (anirban@iisc.ac.in)</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>VII. ACKNOWLEDGMENTS</head><p>This work is partially supported by a <rs type="grantName">Young Scientist Research Award</rs> (Sanction no. <rs type="grantNumber">59/20/11/2020-BRNS</rs>) to Anirban Chakraborty from <rs type="funder">DAE-BRNS, India</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_6GEQhfE">
					<idno type="grant-number">59/20/11/2020-BRNS</idno>
					<orgName type="grant-name">Young Scientist Research Award</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary for</head><p>"Data-free Defense of Black Box Models Against Adversarial Attacks"</p><p>I. PERFORMANCE OF OUR METHOD (DBMA) USING</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DIFFERENT WAVELETS</head><p>The experiments in the main draft, have used Daubechies wavelets <ref type="bibr" target="#b53">[54]</ref> in wavelet noise remover (WNR). Along with Daubechies, several other wavelets are available in the literature that varies in time, frequency, and rate of decay. This section analyzes the effect of different wavelets on the performance of proposed data-free black box defense (DBMA). We perform experiments with Coiflets <ref type="bibr" target="#b54">[55]</ref> and Biorthogonal wavelets <ref type="bibr" target="#b55">[56]</ref>. Table <ref type="table">I</ref> summarizes the results obtained with Resnet18 as the defender's surrogate model and Alexnethalf as the attacker's surrogate model. We observe a similar performance trend over the adversarial and clean samples on using the different wavelet functions when compared to the Daubechies. This confirms DBMA yields consistent performance irrespective of the choice of the wavelet function used. In all the experiments in the main draft, we used the Black Box Ripper (BBR) model stealing method to obtain surrogate model for defense. To demonstrate that our method DBMA can work across different model stealing techniques also, we obtain the defender's surrogate model using a different model stealing method (DFMS-HL). To get better insights, we analyze the performance of DBMA by varying the model stealing techniques for both attack and defense.</p><p>In Table <ref type="table">II</ref> we observe the clean accuracy is not affected on using different model stealing techniques. DBMA obtains the best performance when the attacker uses BBR to attack while the defense is performed using model stealing DFMS-HL (third row). However, when the attacker uses the DFMS-HL method to create a surrogate model (second and fourth row), the adversarial accuracy decreases by ? 7 -11% across attacks compared to the performance with BBR method used by attacker. For attacks crafted using BBR, the defender's performance with DFMS-HL remains almost similar to BBR (first and third rows). These results suggest that the adversarial samples created using the DFMS-HL are stronger than the ones created using BBR method. This aligns with the Sec. 5.6 in the main draft, where we observed a similar trend indicating that the attacks crafted using DFMS-HL are powerful than BBR. Further, we observe that the choice of the defender's model stealing method does not significantly affect the adversarial and clean accuracy.</p><p>Overall, for different model stealing methods, DBMA ensures good clean performance with decent adversarial performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. ARCHITECTURE DETAILS OF REGENERATOR NETWORK</head><p>The Regenerator network consists of U-net-based <ref type="bibr" target="#b56">[57]</ref> generator with five downsampling and upsampling layers. Each i th downsampling layer has a skip connection to (n -i) th upsampling layer that concatenates channels of i th layer with those at layer n -i, n represents number of upsampling and downsampling layers (i.e. n = 5). The number of channels in the network's input and output are the same as the image channels in the training dataset (surrogate data S d in our case). Each Downsampling layer first filters input through Leaky relu with negative slope = 0.2, followed by convolution operation with kernelsize = 4, stride = 2, and padding = 1. The number of output channels for layers 1 to 5 are 64,128,256,512,512 respectively. Upsampling layers start with a Relu layer. Followed by transposed convolution. Each transposed convolution has kernelsize = 4 , padding = 1 and stride = 2. The number of output channels for layers 1 to 5 are 1024, 512, 256, 128, and 3 respectively.The output of convolution and deconvolution layers is normalized using instance normalization to avoid 'instance-specific mean and covariance shifts'. The output of the last upsampling layer is normalized using Tanh normalization to ensure output values lie in the range [-1, 1].</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning for computer vision: A brief review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Voulodimos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Doulamis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Doulamis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Protopapadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2018</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for image classification: A comprehensive review</title>
		<author>
			<persName><forename type="first">W</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2352" to="2449" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations, ICLR 2015, Conference Track Proceedings</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rudnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1609.08144</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Speech recognition using deep neural networks: A systematic review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Nassif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Attili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Azzeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shaalan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">165</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep speech: Scaling up endto-end speech recognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<idno>abs/1412.5567</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Threat of adversarial attacks on deep learning in computer vision: A survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">430</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A survey on adversarial attacks and defences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chattopadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mukhopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAAI Transactions on Intelligence Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="45" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<title level="s">Conference Track Proceedings</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adversarial examples in the physical world</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence safety and security</title>
		<imprint>
			<publisher>Chapman and Hall/CRC</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="99" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2206" to="2216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against machine learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Asia conference on computer and communications security</title>
		<meeting>the 2017 ACM on Asia conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="506" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security</title>
		<meeting>the 10th ACM Workshop on Artificial Intelligence and Security</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against machine learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Asia conference on computer and communications security</title>
		<meeting>the 2017 ACM on Asia conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="506" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Black-box generation of adversarial text sequences to evade deep learning classifiers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Soffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Security and Privacy Workshops (SPW)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="50" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mlaas: Machine learning as a service</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grolinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A M</forename><surname>Capretz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="896" to="902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Knockoff nets: Stealing functionality of black-box models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Orekondy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4954" to="4963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Black-box ripper: Copying black-box models using generative evolutionary algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barbalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="20" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards datafree model stealing in a hard label setting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Addepalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">293</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Maze: Data-free model stealing attack using zeroth-order gradient estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kariyappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">823</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Data-free model extraction</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Walls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4771" to="4780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dast: Data-free substitute training for adversarial attacks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="234" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611970104</idno>
		<ptr target="https://epubs.siam.org/doi/abs/10.1137/1.9781611970104" />
	</analytic>
	<monogr>
		<title level="j">Ten Lectures on Wavelets. Society for Industrial and Applied Mathematics</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Highfrequency component helps explain the generalization of convolutional neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8684" to="8694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ideal spatial adaptation by wavelet shrinkage</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Johnstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">biometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="425" to="455" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">De-noising by soft-thresholding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Image compression using wavelet transform and multiresolution decomposition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Averbuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Israeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="15" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image compression using wavelets and jpeg2000: a tutorial</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics &amp; Communication Engineering Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="112" to="121" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Performance analysis of image compression using wavelets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zovko-Cihlar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on industrial electronics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="682" to="695" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Signal processing and compression with wavelet packets</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Quake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Wickerhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wavelets and their applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="363" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Medical image enhancement algorithm based on wavelet transform</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics letters</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="120" to="121" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint exact histogram specification and image enhancement through the wavelet transform</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2245" to="2250" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Microarray image enhancement by denoising using stationary wavelet transform</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Istepanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Nanobioscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="184" to="189" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Combination of contrast limited adaptive histogram equalisation and discrete wavelet transform for image enhancement</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lidong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zebin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="908" to="915" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Wavecnet: Wavelet integrated cnns to suppress aliasing effect for noiserobust image classification</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="7074" to="7089" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Defending against adversarial iris examples usingwavelet decomposition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soleymani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dabouei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 10th International Conference on Biometrics Theory, Applications and Systems (BTAS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deflecting adversarial attacks with pixel deflection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dilillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Storer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8571" to="8580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Image super-resolution as a defense against adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1711" to="1724" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Defending black box facial recognition classifiers against adversarial attacks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Theagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bhanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</meeting>
		<imprint>
			<date type="published" when="2020-06">June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The haar wavelet transform: its status and achievements</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Stankovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Falkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Electrical Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="44" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Orthonormal bases of compactly supported wavelets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<idno type="DOI">10.1002/cpa.3160410705</idno>
		<ptr target="https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.3160410705" />
	</analytic>
	<monogr>
		<title level="s">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="909" to="996" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Biorthogonal bases of compactly supported wavelets</title>
		<idno type="DOI">10.1002/cpa.3160450502</idno>
		<ptr target="https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.3160450502" />
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="485" to="560" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>Online]. Available</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Canadian Institute for Advanced Research, Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="http://ufldl.stanford.edu/housenumbers/nips2011housenumbers.pdf" />
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adversarial examples in the physical world</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence safety and security</title>
		<imprint>
			<publisher>Chapman and Hall/CRC</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="99" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2206" to="2216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2012/file/c399862" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
	<note>d3b9d6b76c8436e924a68c45b-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Ten lectures on wavelets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Physics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="697" to="697" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Fast wavelet transforms and numerical algorithms i</title>
		<author>
			<persName><forename type="first">G</forename><surname>Beylkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rokhlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="141" to="183" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Biorthogonal bases of compactly supported wavelets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Feauveau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="485" to="560" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">A fourier perspective on model robustness in computer vision</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
