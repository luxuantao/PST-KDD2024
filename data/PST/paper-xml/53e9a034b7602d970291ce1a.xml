<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Local Graph Partitioning using PageRank Vectors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Reid</forename><surname>Andersen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fan</forename><surname>Chung</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Lang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Local Graph Partitioning using PageRank Vectors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A local graph partitioning algorithm finds a cut near a specified starting vertex, with a running time that depends largely on the size of the small side of the cut, rather than the size of the input graph. In this paper, we present an algorithm for local graph partitioning using personalized PageRank vectors. We develop an improved algorithm for computing approximate PageRank vectors, and derive a mixing result for PageRank vectors similar to that for random walks. Using this mixing result, we derive an analogue of the Cheeger inequality for PageRank, which shows that a sweep over a single PageRank vector can find a cut with conductance ?, provided there exists a cut with conductance at most f (?), where f (?) is ?(? 2 / log m), and where m is the number of edges in the graph. By extending this result to approximate PageRank vectors, we develop an algorithm for local graph partitioning that can be used to a find a cut with conductance at most ?, whose small side has volume at least 2 b , in time O(2 b log 3 m/? 2 ). Using this local graph partitioning algorithm as a subroutine, we obtain an algorithm that finds a cut with conductance ? and approximately optimal balance in time O(m log 4 m/? 3 ).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the central problems in algorithmic design is the problem of finding a cut with a small conductance. There is a large literature of research papers on this topic, with applications in numerous areas.</p><p>Spectral partitioning, where an eigenvector is used to produce a cut, is one of the few approaches to this problem that can be analyzed theoretically. The Cheeger inequality <ref type="bibr" target="#b3">[4]</ref> shows that the cut obtained by spectral partitioning has conductance within a quadratic factor of the optimum. Spectral partitioning can be applied recursively, with the resulting cuts combined in various ways, to solve more complicated problems; for example, recursive spectral algorithms have been used to find k-way partitions, spectral clusterings, and separators in planar graphs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>. There is no known way to lower bound the size of the small side of the cut produced by spectral partitioning, and this adversely affects the running time of recursive spectral partitioning.</p><p>Local spectral techniques provide a faster alternative to recursive spectral partitioning by avoiding the problem of unbalanced cuts. Spielman and Teng introduced a local partitioning algorithm called Nibble, which finds relatively small cuts near a specified starting vertex, in time proportional to the volume of the small side of the cut. The small cuts found by Nibble can be combined to form balanced cuts and multiway partitions in almost linear time, and the Nibble algorithm is an essential subroutine in algorithms for graph sparsification and solving linear systems <ref type="bibr" target="#b14">[15]</ref>. The analysis of the Nibble algorithm is based on a mixing result by Lov?sz and Simonovits <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, which shows that cuts with small conductance can be found by simulating a random walk and performing sweeps over the resulting sequence of walk vectors.</p><p>In this paper, we present a local graph partitioning algorithm that uses personalized PageRank vectors to produce cuts. Because a PageRank vector is defined recursively (as we will describe in section 2), we can consider a single PageRank vector in place of a sequence of random walk vectors, which simplifies the process of finding cuts and allows greater flexibility when computing approximations. We show directly that a sweep over a single approximate PageRank vector can produce cuts with small conductance. In contrast, <ref type="bibr">Spielman and</ref> Teng show that when a good cut can be found from a series of walk distributions, a similar cut can be found from a series of approximate walk distributions. Our method of analysis allows us to find cuts using approximations with larger amounts of error, which improves the running time.</p><p>The analysis of our algorithm is based on the following results:</p><p>? We give an improved algorithm for computing approximate PageRank vectors. We use a technique introduced by Jeh-Widom <ref type="bibr" target="#b6">[7]</ref>, and further developed by Berkhin in his Bookmark Coloring Algorithm <ref type="bibr" target="#b0">[1]</ref>. The algorithms of Jeh-Widom and Berkhin compute many personalized PageRank vectors simultaneously, more quickly than they could be computed individually. Our algorithm computes a single approximate PageRank vector more quickly than the algorithms of Jeh-Widom and Berkhin by a factor of log n.</p><p>? We prove a mixing result for PageRank vectors that is similar to the Lov?sz-Simonovits mixing result for random walks. Using this mixing result, we show that if a sweep over a PageRank vector does not produce a cut with small conductance, then that PageRank vector is close to the stationary distribution. We then show that for any set C with small conductance, and for many starting vertices contained in C, the resulting PageRank vector is not close to the stationary distribution, because it has significantly more probability within C. Combining these results yields a local version of the Cheeger inequality for PageRank vectors: if C is a set with conductance ?(C) ? f (?), then a sweep over a PageRank vector pr(?, ? v ) finds a set with conductance at most ?, provided that ? is set correctly depending on ?, and that v is one of a significant number of good starting vertices within C. This holds for a function f (?) that satisfies f (?) = ?(? 2 / log m).</p><p>Using the results described above, we produce a local partitioning algorithm PageRank-Nibble which improves both the running time and approximation ratio of Nibble. PageRank-Nibble takes as input a starting vertex v, a target conductance ?, and an integer b ? [1, log m]. When v is a good starting vertex for a set C with conductance ?(C) ? g(?), there is at least one value of b where PageRank-Nibble produces a set S with the following properties: the conductance of S is at most ?, the volume of S is at least 2 b-1 and at most (2/3)vol(G), and the intersection of S and C satisfies vol(S ? C) ? 2 b-2 . This holds for a function g(?) that satisfies g(?) = ?(? 2 / log 2 m). The running time of PageRank-Nibble is O(2 b log 3 m/? 2 ), which is nearly linear in the volume of S. In comparison, the Nibble algorithm requires that C have conductance O(? 3 / log 2 m), and runs in time O(2 b log 4 m/? 5 ).</p><p>PageRank-Nibble can be used interchangeably with Nibble, leading immediately to faster algorithms with improved approximation ratios in several applications. In particular, we obtain an algorithm PageRank-Partition that finds cuts with small conductance and approximately optimal balance: if there exists a set C satisfying ?(C) ? g(?) and vol(C) ? 1  2 vol(G), then the algorithm finds a set S such that ?(S) ? ? and 1  2 vol(C) ? vol(S) ? 5 6 vol(G), in time O(m log 4 m/? 3 ). This holds for a function g(?) that satisfies g(?) = ?(? 2 / log 2 m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this paper we consider an undirected, unweighted graph G, where V is the vertex set, E is the edge set, n is the number of vertices, and m is the number of undirected edges. We write d(v) for the degree of vertex v, let D be the degree matrix (the diagonal matrix with D i,i = d(v i )), and let A be the adjacency matrix. We will consider distributions on V , which are vectors indexed by the vertices in V , with the additional requirement that each entry be nonnegative. A distribution p is considered to be a row vector, so we can write the product of p and A as pA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Personalized Pagerank Vectors</head><p>PageRank was introduced by Brin and Page <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b2">3]</ref>. For convenience, we introduce a lazy variation of PageRank, which we define to be the unique solution pr(?, s) of the equation</p><formula xml:id="formula_0">pr(?, s) = ?s + (1 -?)pr(?, s)W,<label>(1)</label></formula><p>where ? is a constant in (0, 1] called the teleportation constant, s is a distribution called the preference vector, and W is the lazy random walk transition matrix W = 1 2 (I + D -1 A). In the Appendix, we show that this is equivalent to the traditional definition of PageRank (which uses a regular random walk step instead of a lazy step) up to a change in ?.</p><p>The PageRank vector that is usually associated with search ranking has a preference vector equal to the uniform distribution 1 n . PageRank vectors whose preference vectors are concentrated on a smaller set of vertices are often called personalized PageRank vectors. These were introduced by Haveliwala <ref type="bibr" target="#b5">[6]</ref>, and have been used to provide personalized search ranking and context-sensitive search <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7]</ref>. The preference vectors used in our algorithms have all probability on a single starting vertex.</p><p>Here are some useful properties of PageRank vectors (also see <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref>). The proofs are given in the Appendix.</p><p>Proposition 1. For any starting distribution s, and any constant ? in (0, 1], there is a unique vector pr(?, s) satisfying pr(?, s) = ?s + (1 -?)pr(?, s)W.</p><p>Proposition 2. For any fixed value of ? in (0, 1], there is a linear transformation R ? such that pr(?, s) = sR ? . Furthermore, R ? is given by the matrix</p><formula xml:id="formula_1">R ? = ? ? t=0 (1 -?) t W t ,<label>(2)</label></formula><p>which implies that a PageRank vector is a weighted average of lazy walk vectors,</p><formula xml:id="formula_2">pr(?, s) = ? ? t=0 (1 -?) t sW t .<label>(3)</label></formula><p>It follows that pr(?, s) is linear in the preference vector s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Conductance</head><p>The volume of a subset S ? V of vertices is</p><formula xml:id="formula_3">vol(S) = x?S d(x).</formula><p>We remark that vol(V ) = 2m, and we will sometimes write vol(G) in place of vol(V ). The edge boundary of a set is defined to be ?(S) = {{x, y} ? E | x ? S, y ? S} , and the conductance of a set is ?(S) = |?(S)| min (vol(S), 2m -vol(S)) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Distributions</head><p>Two distributions we will use frequently are the stationary distribution,</p><formula xml:id="formula_4">? S (x) = d(x) vol(S) if x ? S 0 otherwise .</formula><p>and the indicator function,</p><formula xml:id="formula_5">? v (x) = 1 if x = v 0 otherwise .</formula><p>The amount of probability from a distribution p on a set S of vertices is written</p><formula xml:id="formula_6">p (S) = x?S p(x).</formula><p>We will sometimes refer to the quantity p(S) as an amount of probability even if p(V ) is not equal to 1. As an example of this notation, the PageRank vector with teleportation constant ? and preference vector ? v is written pr(?, ? v ), and the amount of probability from this distribution on a set S is written [pr(?, ? v )] (S). The support of a distribution is Supp(p) = {v | p(v) = 0}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Sweeps</head><p>A sweep is an efficient technique for producing cuts from an embedding of a graph, and is often used in spectral partitioning <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref>. We will use the following degree-normalized version of a sweep. Given a distribution p, with support size N p = |Supp(p)|, let v 1 , . . . , v Np be an ordering of the vertices such that p(v i )</p><formula xml:id="formula_7">d(v i ) ? p(v i+1 ) d(v i+1 )</formula><p>. This produces a collection of sets, S p j = {v 1 , . . . , v j } for each j ? {0, . . . , N p }, which we call sweep sets. We let</p><formula xml:id="formula_8">?(p) = min j?[1,Np] ?(S p j )</formula><p>be the smallest conductance of any of the sweep sets. A cut with conductance ?(p) can be found by sorting p and computing the conductance of each sweep set, which can be done in time O(vol(Supp(p)) log n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Measuring the spread of a distribution</head><p>We measure how well a distribution p is spread in the graph using a function p [k] defined for all integers k ? [0, 2m]. This function is determined by setting</p><formula xml:id="formula_9">p [k] = p S p j ,</formula><p>for those values of k where k = vol(S p j ), and the remaining values are set by defining p [k] to be piecewise linear between these points. In other words, for any integer k ? [0, 2m], if j is the unique vertex such that vol(S p j ) ? k ? vol(S p j+1 ), then </p><formula xml:id="formula_10">p [k] = p S p j + k -vol(S p j ) d(v j ) p (v j+1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Computing approximate PageRank vectors</head><p>To approximate a PageRank vector pr(?, s), we compute a pair of distributions p and r with the following property. p + pr(?, r) = pr(?, s).</p><p>If p and r are two distributions with this property, we say that p is an approximate PageRank vector, which approximates pr(?, s) with the residual vector r. We will use the notation p = apr(?, s, r) to refer to an approximate PageRank vector obeying the equation above. Since the residual vector is nonnegative, it is always true that apr(?, s, r) ? pr(?, s), for any residual vector r.</p><p>In this section, we give an algorithm that computes an approximate PageRank vector with a small residual vector and small support, with running time independent of the size of the graph.</p><formula xml:id="formula_12">Theorem 1. ApproximatePageRank(v, ?, ) runs in time O( 1 ?</formula><p>), and computes an approximate PageRank vector p = apr(?, ? v , r) such that the residual vector r satisfies max u?V r(u) d(u) &lt; , and such that vol(Supp(p)) ? 1 ? . We remark that this algorithm is based on the algorithms of Jeh-Widom <ref type="bibr" target="#b6">[7]</ref> and Berkhin <ref type="bibr" target="#b0">[1]</ref>, both of which can be used to compute similar approximate PageRank vectors in time O( log n ? ). The extra factor of log n in the running time of these algorithms is overhead from maintaining a heap or priority queue, which we eliminate. The proof of Theorem 1 is based on a series of facts which we describe below.</p><p>Our algorithm is motivated by the following observation of Jeh-Widom.</p><p>pr(?, s) = ?s + (1 -?)pr(?, sW ).</p><p>(</p><formula xml:id="formula_13">)<label>5</label></formula><p>Notice that the equation above is similar to, but different from, the equation used in Section 2 to define PageRank. This observation is simple, but it is instrumental in our algorithm, and it is not trivial. To prove it, first reformulate the linear transformation R ? that takes a starting distribution to its corresponding PageRank vector, as follows.</p><formula xml:id="formula_14">R ? = ? ? t=0 (1 -?) t W t = ?I + (1 -?)W R ? .</formula><p>Applying this rearranged transformation to a starting distribution s yields equation <ref type="bibr" target="#b4">(5)</ref>.</p><formula xml:id="formula_15">pr(?, s) = sR ? = ?s + (1 -?)sW R ? = ?s + (1 -?)pr(?, sW ).</formula><p>This provides a flexible way to compute an approximate PageRank vector. We maintain a pair of distributions: an approximate PageRank vector p and its associated residual vector r. Initially, we set p = 0 and r = ? v . We then apply a series of push operations, based on equation ( <ref type="formula" target="#formula_13">5</ref>), which alter p and r. Each push operation takes a single vertex u, moves an ? fraction of the probability from r(u) onto p(u), and then spreads the remaining (1 -?) fraction within r, as if a single step of the lazy random walk were applied only to the vertex u. Each push operation maintains the invariant</p><formula xml:id="formula_16">p + pr(?, r) = pr(?, ? v ),<label>(6)</label></formula><p>which ensures that p is an approximate PageRank vector for pr(?, ? v ) after any sequence of push operations. We now formally define push u , which performs this push operation on the distributions p and r at a chosen vertex u. push u (p, r):</p><p>1. Let p = p and r = r, except for the following changes:</p><formula xml:id="formula_17">(a) p (u) = p(u) + ?r(u). (b) r (u) = (1 -?)r(u)/2. (c) For each v such that (u, v) ? E: r (v) = r(v) + (1 -?)r(u)/(2d(u)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Return (p , r ).</head><p>Lemma 1. Let p and r be the result of the operation push u on p and r. Then</p><formula xml:id="formula_18">p + pr(?, r ) = p + pr(?, r).</formula><p>The proof of Lemma 1 can be found in the Appendix. During each push, some probability is moved from r to p, where it remains, and after sufficiently many pushes r can be made small. We can bound the number of pushes required by the following algorithm.  Lemma 2. Let T be the total number of push operations performed by ApproximatePageRank, and let d i be the degree of the vertex u used in the ith push. Then</p><formula xml:id="formula_19">T i=1 d i ? 1 ? .</formula><p>Proof. The amount of probability on the vertex pushed at time i is at least d i , therefore |r| 1 decreases by at least ? d i during the ith push. Since |r| 1 = 1 initially, we have ? T i=1 d i ? 1, and the result follows.</p><p>To implement ApproximatePageRank, we determine which vertex to push at each step by maintaining a queue containing those vertices u with r(u)/d(u) ? . At each step, push operations are performed on the first vertex in the queue until r(u)/d(u) &lt; for that vertex, which is then removed from the queue. If a push operation raises the value of r(x)/d(x) above for some vertex x, that vertex is added to the back of the queue. This continues until the queue is empty, at which point every vertex has r(u)/d(u) &lt; . We will show that this algorithm has the properties promised in Theorem 1. The proof is contained in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A mixing result for PageRank vectors</head><p>In this section, we prove a mixing result for PageRank vectors that is an analogue of the Lov?sz-Simonovits mixing result for random walks. For an approximate PageRank vector apr(?, s, r), we give an upper bound on apr(?, s, r) [k] that depends on the smallest conductance found by a sweep over apr(?, s, r). In contrast, the mixing result of Lov?sz and Simonovits bounds the quantity p (t) [k] for the lazy random walk distribution p (t) in terms of the smallest conductance found by sweeps over the previous walk distributions p (0) , . . . , p (t-1) . The recursive property of PageRank allows us to consider a single vector instead of a sequence of random walk vectors, simplifying the process of finding cuts.</p><p>We use this mixing result to show that if an approximate PageRank vector apr(?, s, r) has significantly more probability than the stationary distribution on any set, the sweep over apr(?, s, r) produces a cut with small conductance. The proof of this theorem, and the more general mixing result from which it is derived, is described at the end of this section. The proof requires a sequence of lemmas, which we present below.</p><p>Every approximate PageRank vector, no matter how large the residual vector, obeys the following inequality. It is a one-sided version of the equation used to define PageRank. Lemma 3. If apr(?, s, r) is an approximate PageRank vector, then apr(?, s, r) ? ?s + (1 -?)apr(?, s, r)W.</p><p>The proof of Lemma 3 can be found in the Appendix. Notice that this inequality relates apr(?, s, r) to apr(?, s, r)W . We will soon prove a result, Lemma 4, which describes how probability mixes in the single walk step between apr(?, s, r) and apr(?, s, r)W . We will then combine Lemma 4 with the inequality from Lemma 3 to relate apr(?, s, r) to itself, removing any reference to apr(?, s, r)W .</p><p>We now present definitions required for Lemma 4. Instead of viewing an undirected graph as a collection of undirected edges, we view each undirected edge {u, v} as a pair of directed edges (u, v) and (v, u). For each directed edge (u, v) we let</p><formula xml:id="formula_20">p(u, v) = p(u) d(u) .</formula><p>For any set of directed edges A, we define</p><formula xml:id="formula_21">p(A) = (u,v)?A p(u, v).</formula><p>When a lazy walk step is applied to the distribution p, the amount of probability that moves from u to v is 1 2 p(u, v). For any set S of vertices, we have the set of directed edges into S, and the set of directed edges out of S, defined by in(S) = {(u, v) ? E | u ? S}, and out(S) = {(u, v) ? E | v ? S}, respectively. The proof of Lemma 4 can be found in the Appendix. We now combine this result with the inequality from Lemma 3 to relate apr(?, s, r) to itself. In contrast, the proof of Lov?sz and Simonovits <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> relates the walk distributions p (t) and p (t+1) , where p (t+1) = p (t) W , and p (0) = s. Lemma 5. If p = apr(?, s, r) is an approximate PageRank vector, then for any set S of vertices,</p><formula xml:id="formula_22">p(S) ? ?s(S) + (1 -?) 1 2 (p (in(S) ? out(S)) + p (in(S) ? out(S))) . Furthermore, for each j ? [1, n -1],</formula><p>p vol(S p j ) ? ?s vol(S p j ) + (1 -?)</p><formula xml:id="formula_23">1 2 p vol(S p j ) -|?(S p j )| + p vol(S p j ) + |?(S p j )| .</formula><p>The proof of Lemma 5 is included in the Appendix.</p><p>The following lemma uses the result from Lemma 5 to place an upper bound on apr(?, s, r) [k]. More precisely, it shows that if a certain upper bound on apr(?, s, r) [k] -k 2m does not hold, then one of the sweep sets from apr(?, s, r) has both small conductance and a significant amount of probability from apr(?, s, r). This lower bound on probability will be used in Section 6 to control the volume of the resulting sweep set. Theorem 3. Let p = apr(?, s, r) be an approximate PageRank vector with |s| 1 ? 1. Let ? and ? be any constants in [0, 1]. Either the following bound holds for any integer t and any k ? [0, 2m]:</p><formula xml:id="formula_24">p [k] - k 2m ? ? + ?t + min(k, 2m -k) 1 - ? 2 8 t ,</formula><p>or else there exists a sweep cut S p j with the following properties:</p><formula xml:id="formula_25">1. ?(S p j ) &lt; ?, 2. p S p j - vol(S p j ) 2m &gt; ? + ?t + min(vol(S p j ), 2m -vol(S p j )) 1 -? 2 8 t</formula><p>, for some integer t,</p><formula xml:id="formula_26">3. j ? [1, |Supp(p)|].</formula><p>The proof can be found in the Appendix. We can rephrase the sequence of bounds from Theorem 3 to prove the theorem promised at the beginning of this section. Namely, we show that if there exists a set of vertices, of any size, that contains a constant amount more probability from apr(?, s, r) than from the stationary distribution, then the sweep over apr(?, s, r) finds a cut with conductance roughly ? ? ln m. We remark that this applies to any approximate PageRank vector, regardless of the size of the residual vector: the residual vector only needs to be small to ensure that apr(?, s, r) is large enough that the theorem applies. The proof is given in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Local partitioning using approximate PageRank vectors</head><p>In this section, we show how sweeps over approximate PageRank vectors can be used to find cuts with nearly optimal conductance. Unlike traditional spectral partitioning, where a sweep over an eigenvector produces a cut with conductance near the global minimum, the cut produced by a PageRank vector depends on the starting vertex v, and also on ?. We first identify a sizeable collection of starting vertices for which we can give a lower bound on apr(?, ? v , r)(C).</p><p>Theorem 4. For any set C and any constant ?, there is a subset C ? ? C, with vol(C ? ) ? vol(C)/2, such that for any vertex v ? C ? , the approximate PageRank vector apr(?, ? v , r) satisfies</p><formula xml:id="formula_27">apr(?, ? v , r)(C) ? 1 - ?(C) ? -vol(C) max u?V r(u) d(u) .</formula><p>We will outline the proof of Theorem 4 at the end of this section. Theorem 4 can be combined with the mixing results from Section 4 to prove the following theorem, which describes a method for producing cuts from an approximate PageRank vector.</p><formula xml:id="formula_28">Theorem 5. Let ? be a constant in [0, 1], let ? = ? 2</formula><p>135 ln m , and let C be a set satisfying</p><formula xml:id="formula_29">1. ?(C) ? ? 2 1350 ln m , 2. vol(C) ? 2 3 vol(G).</formula><p>If v ? C ? , and if apr(?, ? v , r) is an approximate PageRank vector with residual vector r satisfying max u?V r(u) d(u) ? 1 10vol(C) , then ?(apr(?, ? v , r)) &lt; ?. We prove Theorem 5 by combining Theorem 4 and Theorem 2. A detailed proof is provided in the Appendix. As an immediate consequence of Theorem 5, we obtain a local Cheeger inequality for personalized PageRank vectors, which applies when the starting vertex is within a set that achieves the minimum conductance in the graph. Theorem 6. Let ?(G) be the minimum conductance of any set with volume at most vol(G)/2, and let C opt be a set achieving this minimum. If pr(?, ? v ) is a PageRank vector where ? = 10?(G), and v ? C opt ? , then ?(pr(?, ? v )) &lt; 1350?(G) ln m.</p><p>Theorem 6 follows immediately from Theorem 5 by setting ? = 1350?(G) ln m.</p><p>To prove Theorem 4, we will show that a set C with small conductance contains a significant amount of probability from pr(?, ? v ), for many of the vertices v in C. We first show that this holds for an average of the vertices in C, by showing that C contains a significant amount of probability from pr(?, ? C ). Lemma 6. The PageRank vector pr(?, ? C ) satisfies</p><formula xml:id="formula_30">[pr(?, ? C )]( C) ? ?(C) 2? .</formula><p>The proof of Lemma 6 will be given in the Appendix. To prove Theorem 4 from Lemma 6, we observe that for many vertices in C, pr(?, ? v ) is not much larger than pr(?, ? C ), and then bound the difference between apr(?, ? v , r) and pr(?, ? v ) in terms of the residual vector r. A detailed proof can be found in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">An algorithm for nearly linear time graph partitioning</head><p>In this section, we extend our local partitioning techniques to find a set with small conductance, while providing more control over the volume of the set produced. The result is an algorithm called PageRank-Nibble that takes a scale b as part of its input, runs in time proportional to 2 b , and only produces a cut when it finds a set with conductance ? and volume roughly 2 b . We prove that PageRank-Nibble finds a set with these properties for at least one value of b ? [1, log m ], provided that v is a good starting vertex for a set of conductance at most g(?), where g(?) = ?(? 2 / log 2 m). </p><formula xml:id="formula_31">Conductance: ?(S p j ) &lt; ?, Volume: 2 b-1 &lt; vol(S p j ) &lt; 2 3 vol(G), Probability Change: p 2 b -p 2 b-1 &gt; 1 48B , 4.</formula><p>If some set S p j satisfies all of these conditions, return S p j . Otherwise, return nothing. </p><formula xml:id="formula_32">1. ?(S) &lt; ?, 2. 2 b-1 &lt; vol(S) &lt; 2 3 vol(G), 3. vol(S ? C) &gt; 2 b-2 .</formula><p>The proofs of Theorems 7 and 8 are included in the Appendix. PageRank-Nibble improves both the running time and approximation ratio of the Nibble algorithm of Spielman and Teng, which runs in time O(2 b log 4 m/? 5 ), and requires ?(C) = O(? 3 / log 2 m). PageRank-Nibble can be used interchangeably with Nibble in several important applications. For example, both PageRank-Nibble and Nibble can be applied recursively to produce cuts with nearly optimal balance. An algorithm PageRank-Partition with the following properties can be created in essentially the same way as the algorithm Partition in <ref type="bibr" target="#b14">[15]</ref>, so we omit the details. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Appendix</head><p>To demonstrate the equivalence of lazy and standard PageRank vectors, let rpr(?, s) be the standard PageRank vector, defined to be the unique solution p of the equation p = ?s + (1 -?)pM , where M is the random walk transition matrix M = D -1 A. We prove the following proposition.</p><p>Proposition 3. pr(?, s) = rpr( 2? 1+? , s).</p><p>Proof. We have the following sequence of equations.</p><p>pr(?, s)</p><formula xml:id="formula_33">= ?s + (1 -?)pr(?, s)W pr(?, s) = ?s + ( 1 -? 2 )pr(?, s) + ( 1 -? 2 )pr(?, s)(D -1 A) ( 1 + ? 2 )pr(?, s) = ?s + ( 1 -? 2 )pr(?, s)(D -1 A) pr(?, s) = ( 2? 1 + ? )s + ( 1 -? 1 + ? )pr(?, s)m</formula><p>Since pr(?, s) satisfies the equation for rpr( 2? 1+? , s), and since this equation has a unique solution, the result follows.</p><p>Proof of Proposition 1. The equation</p><formula xml:id="formula_34">p = ?s + (1 -?)pW is equivalent to ?s = p[I -(1 -?)W ].</formula><p>The matrix (I -(1 -?)W ) is nonsingular, since it is strictly diagonally dominant, so this equation has a unique solution p.</p><p>Proof of Proposition 2. The sum in equation ( <ref type="formula" target="#formula_1">2</ref>) that defines R ? is convergent for ? ? (0, 1], and the following computation shows that sR ? obeys the steady state equation for pr(?, s).</p><p>?s</p><formula xml:id="formula_35">+ (1 -?)sR ? W = ?s + (1 -?)s ? ? t=0 (1 -?) t W t W = ?s + s ? ? t=1 (1 -?) t W t = s ? ? t=0 (1 -?) t W t = sR ? .</formula><p>Since the solution to the steady state equation is unique by Proposition 1, it follows that pr(?, s) = sR ? .</p><p>Proof of Lemma 1. After the push operation, we have</p><formula xml:id="formula_36">p = p + ?r(u)? u . r = r -r(u)? u + (1 -?)r(u)? u W.</formula><p>Using equation <ref type="bibr" target="#b4">(5)</ref>,</p><formula xml:id="formula_37">p + pr(?, r) = p + pr(?, r -r(u)? u ) + pr(?, r(u)? u ) = p + pr(?, r -r(u)? u ) + [?r(u)? u + (1 -?)pr(?, r(u)? u W )] = [p + ?r(u)? u ] + pr(?, [r -r(u)? u + (1 -?)r(u)? u W ]) = p + pr(?, r ).</formula><p>Proof of Theorem 1. Lemma 1 implies that p + pr(?, r) = pr(?, ? v ) at every step of the algorithm, and so the vector returned by the algorithm is an approximate PageRank vector apr(?, ? v , r). It is clear from the stopping condition that max u?V r(u) d(u) &lt; . To bound the support volume, notice that for each vertex in Supp(p), ApproximatePageRank must have performed at least one push operation on that vertex. If d i is the degree of the vertex pushed during step i, then Lemma 2 implies</p><formula xml:id="formula_38">vol(Supp(p)) = v?Supp(p) d(v) ? T i=1 d i ? 1 ? .</formula><p>It is possible to perform a push operation on the vertex u, and perform any necessary queue updates, in time proportional to d(u). The running time then follows from Lemma 2.</p><p>Proof of Lemma 3. From the definition of the approximate PageRank vector apr(?, s, r), we have the following sequence of equations.</p><p>apr(?, s, r) = pr(?, s) -pr(?, r)</p><formula xml:id="formula_39">= ?s + (1 -?)pr(?, s)W -pr(?, r) = ?s + (1 -?)(pr(?, s) -pr(?, r))W + (1 -?)pr(?, r)W -pr(?, r) = ?s + (1 -?)apr(?, s, r)W + ((1 -?)pr(?, r)W -pr(?, r)) = ?s + (1 -?)apr(?, s, r)W -?r ? ?s + (1 -?)apr(?, s, r)W.</formula><p>The last line uses the fact that r is nonnegative.</p><p>Proof of Lemma 4. The amount of probability from pW on a vertex u can be written as follows.</p><formula xml:id="formula_40">pW (u) = 1 2 p(u) + 1 2 (v,u)?E p(v) d(v) = 1 2 (u,v)?E p(u, v) + 1 2 (v,u)?E p(v, u) = 1 2 p (in(u)) + 1 2 p (out(u)) .</formula><p>The amount of probability on a set S can then be written this way.</p><p>pW (S) = p(in(S)) + p(out(S))</p><p>= p (in(S) ? out(S)) + p (in(S) ? out(S)) .</p><p>Proof of Lemma 5. Let p = apr(?, s, r) be an approximate PageRank vector. By Lemma 3 we have the inequality p ? ?s + (1 -?)pW , which implies</p><formula xml:id="formula_41">p(S) ? [?s + (1 -?)pW ] (S) = ?s(S) + (1 -?)pW (S) ? ?s(S) + (1 -?) 1 2 (p (in(S) ? out(S)) + p (in(S) ? out(S))) .</formula><p>This proves the first part of the lemma. To prove the second part, recall that p vol(S p j ) = p(S p j ) for any integer j ? [0, n]. Also, for any set of directed edges A, we have the bound p(A) ? p [|A|]. Therefore, p vol(S p j ) = p(S p j )</p><p>? ?s(S p j ) + (1 -?)</p><formula xml:id="formula_42">1 2 p in(S p j ) ? out(S p j ) + p in(S p j ) ? out(S p j ) ? ?s vol(S p j ) + (1 -?) 1 2 p in(S p j ) ? out(S p j ) + p in(S p j ) ? out(S p j ) .</formula><p>All that remains is to bound the sizes of the sets in the inequality above. Notice that in(S p j ) ? out(S p j )| + |in(S p j ) ? out(S p j ) = 2vol(S p j ), and in(S p j ) ? out(S p j ) -in(S p j ) ? out(S p j ) = 2|?(S p j )|.</p><p>This implies that in(S p j ) ? out(S p j ) = vol(S p j ) + |?(S p j )|, and in(S p j ) ? out(S p j ) = vol(S p j ) -|?(S p j )|. The result follows.</p><p>Proof of Theorem 3. Let k j = vol(S p j ), let k j = min(k j , 2m -k j ), and let</p><formula xml:id="formula_43">f t (k) = ? + ?t + min(k, 2m -k) 1 - ? 2 8 t .</formula><p>Assuming that there does not exist a sweep cut with all of the properties stated in the theorem, we will prove by induction that the following holds for all t ? 0:</p><formula xml:id="formula_44">p [k] - k 2m ? f t (k), for any k ? [0, 2m].<label>(7)</label></formula><p>For the base case, equation ( <ref type="formula" target="#formula_44">7</ref>) holds for t = 0, with any choice of ? and ?. To see this, notice that for each integer</p><formula xml:id="formula_45">k ? [1, 2m -1], p [k] - k 2m ? 1 ? min(k, 2m -k) ? f 0 (k).</formula><p>For k = 0 and k = 2m we have p</p><formula xml:id="formula_46">[k] -k 2m ? 0 ? f 0 (k).</formula><p>The claim follows because f 0 is concave, p [k] is less than f 0 for each integer value of k, and p [k] is linear between these integer values.</p><p>Assume for the sake of induction that equation ( <ref type="formula" target="#formula_44">7</ref>) holds for t. To prove that equation ( <ref type="formula" target="#formula_44">7</ref>) holds for t + 1, which will complete the proof of the theorem, it suffices to show that the following equation holds for each j ? [1, |Supp(p)|]:</p><formula xml:id="formula_47">p [k j ] - k j 2m ? f t+1 (k j ).<label>(8)</label></formula><p>This equation holds trivially for j = 0, and j = n. The theorem will follow because f t+1 is concave, we have shown that equation <ref type="bibr" target="#b7">(8)</ref>  </p><formula xml:id="formula_48">p [k j ] ? ? + 1 2 f t (k j -?k j ) + k j -?k j 2m + f t (k j + ?k j ) + k j + ?k j 2m . = ? + k j 2m + 1 2 f t (k j -?k j ) + f t (k j + ?k j ) .</formula><p>Therefore,</p><formula xml:id="formula_49">p [k j ] - k j 2m ? ? + 1 2 f t (k j -?k j ) + f t (k j + ?k j ) = ? + ? + ?t + 1 2 min(k j -?k j , 2m -k j + ?k j ) + min(k j + ?k j , 2m -k j -?k j ) 1 - ? 2 8 t ? ? + ? + ?t + 1 2 k j -?k j + k j + ?k j 1 - ? 2 8 t .</formula><p>This last step can be verified by considering the two cases k j ? m and k j ? m separately. By examining the Taylor series of ? 1 + ? at ? = 0, we obtain the following for any k ? 0 and ? ? [0, 1].</p><formula xml:id="formula_50">1 2 k -?k + k + ?k ? ? k 2 (1 - ? 2 - ? 2 8 ) + (1 + ? 2 - ? 2 8 ) ? ? k 1 - ? 2 8 .</formula><p>By applying this with k = k j , we obtain</p><formula xml:id="formula_51">p [k j ] - k j 2m ? ? + ? + ?t + k j 1 - ? 2 8 1 - ? 2 8 t = f t+1 (k j ).</formula><p>Proof of Theorem 2. Let ? = ?(apr(?, s, r)). Proof of Lemma 6. We first prove the following monotonicity property for the PageRank operator: for any starting distribution s, and any k ? [0, 2m],</p><formula xml:id="formula_52">pr(?, s) [k] ? s [k] .<label>(9)</label></formula><p>This is a consequence of Lemma 5; if we let p = s), then for each j ? [1, n -1] we have p vol(S p j ) ? ?s vol(S p j ) + (1 -?) Using the recursive property of PageRank,</p><formula xml:id="formula_53">[pr(?, ? C )] C = [?? C + (1 -?)pr(?, ? C )W ] C ? (1 -?)[pr(?, ? C )] C + 1 2 pr(?, ? C ) [|?(C)|] ? (1 -?)[pr(?, ? C )] C + 1 2 ?(C).</formula><p>This implies</p><formula xml:id="formula_54">[pr(?, ? C )]( C) ? ?(C) 2? .</formula><p>Proof of Theorem 4. For a set C ? V , let C ? be the set of vertices v in C satisfying</p><formula xml:id="formula_55">pr(?, ? v ) C ? ?(C) ? .</formula><p>Let v be a vertex chosen randomly from the distribution ? C , and define the random variable X = pr(?, ? v ) C . The linearity property of PageRank vectors from Proposition 2, combined with the bound from Lemma 6, implies the following bound on the expectation of X.</p><formula xml:id="formula_56">E [X] = pr(?, ? C ) C ? ?(C) 2? .</formula><p>Then,</p><formula xml:id="formula_57">Pr [v ? C ? ] ? Pr [X &gt; 2E [X]] ? 1 2 . Since Pr [v ? C ? ] ? 1 2 , the volume of C ? is at least 1 2 vol(G). If v is a vertex in C ? ,</formula><p>we can obtain a lower bound for apr(?, ? v , r)(C) by bounding the difference between apr(?, ? v , r) and pr(?, ? v ) in terms of the residual vector r. Using the monotonicity property pr(?, r)</p><formula xml:id="formula_58">[k] ? r [k] from equation (9), we have apr(?, ? v , r)(C) = pr(?, ? v )(C) -pr(?, r)(C) ? pr(?, ? v )(C) -pr(?, r) [vol(C)] ? pr(?, ? v )(C) -r [vol(C)] ? 1 - ?(C) ? -vol(C) max u?V r(u) d(u) .</formula><p>Proof of Theorem 5. Theorem 4 gives a lower bound on apr(?, ? v , r)(C).</p><formula xml:id="formula_59">apr(?, ? v , r) (C) ? 1 - ?(C) ? -vol(C) max u?V r(u) d(u) ? 1 - ?(C) ? -<label>1 10</label></formula><p>.</p><formula xml:id="formula_60">Since ?(C) ? ? 1 10 , we have apr(?, ? v , r)(C) ? 4 5 , which implies apr(?, ? v , r)(C) - vol(C) vol(G) ? 4 5 - 2 3 = 2 15 .</formula><p>Theorem 2 then implies ?(apr(?, s, r)) &lt; ? 135? ln m = ?.</p><p>We remark that it is possible to replace the term ln m in Theorem 5 with ln M , where M is an upper bound on the volume of the set C. This can be done by setting ? as a function of log M rather than log m, and changing the value of t used in the proof of Theorem 2. Although the proof follows by similar methods, this would complicate the statement of the theorem. Similarly, the term ln m in Theorem 6 could be replaced with ln(vol(C opt )). Therefore, the running time of PageRank-Nibble is</p><formula xml:id="formula_61">O(2 b log 2 m ? ) = O(2 b log 3 m ? 2 ).</formula><p>Proof of Theorem 8. Consider the PageRank vector pr(?, ? v ). Since v is in C ? , and since</p><formula xml:id="formula_62">?(C) ? ? 1 96B , we have pr(?, ? v ) [vol(C)] - vol(C) 2m ? (1 - ?(C) ? ) - 1 2 ? 1 2 -<label>1 96 .</label></formula><p>We have set ? so that ?t ? 1/25 when t =  </p><formula xml:id="formula_63">v ) [vol(C)] - vol(C) 2m &gt; ? + ?t + min(vol(C), 2m -vol(C)) 1 - ? 2 8 t .<label>(10)</label></formula><formula xml:id="formula_64">(?, ? v ) [k] - k 2m &gt; ? b + ?t + min(k, 2m -k) 1 - ? 2<label>8</label></formula><p>t , for some integer t ? 0. ) + ?t + min(k 0 , 2m -k 0 ) 1 -? 2 8 t .</p><p>Theorem 3 then shows that there exists a sweep cut S j , with S j = S apr(?,?v,r) j</p><p>for some value of j in the range [1, |Supp(apr(?, ? v , r))|], such that ?(S j ) ? ?, and such that following lower bound holds for some integer t: apr(?, ? v , r) (S j ) -vol(S j ) 2m &gt; (? b 0 -1 + 1 48B</p><p>) + ?t + min(vol(S j ), 2m -vol(S j )) 1 -? 2 8 t .</p><p>We will show that this cut S j satisfies all the requirements of PageRank-Nibble.</p><p>It must be true that vol(S j ) &gt; 2 b 0 -1 , since if were true that vol(S j ) ? 2 b 0 -1 , the definition of b 0 would imply that for any integer t, apr(?, ? v , r) (S j ) -vol(S j ) 2m = apr(?, ? v , r) [vol(S j )] -vol(S j ) 2m</p><p>? pr(?, s) [vol(S j )] -vol(S j ) 2m</p><p>? ? b 0 -1 + ?t + min(vol(S j ), 2m -vol(S j )) 1 -? 2 8 t , and this would contradict the lower bound from equation <ref type="bibr" target="#b11">(12)</ref>. It must also be true that vol(S j ) &lt; 2 3 vol(G). Otherwise, the lower bound from equation ( <ref type="formula" target="#formula_65">12</ref>) would imply that for some integer t, apr(?, ? v , r) (S j ) &gt; vol(S j ) 2m + ? b 0 -1 + ?t + min(vol(S j ), 2m -vol(S j )) 1 - Since ? = 5 12 , this implies apr(?, ? v , r) (S j ) &gt; 1, which is impossible.</p><p>To prove that there is a significant difference between apr(?, ? v , r) 2 b 0 and apr(?, ? v , r) 2 b 0 -1 , observe that equation <ref type="bibr" target="#b11">(12)</ref> does not hold with b = b 0 -1 and k = 2 b 0 -1 . Therefore, for every integer t ? 0, apr(?, ? v , r)</p><formula xml:id="formula_66">2 b 0 -1 - k 0 2m ? ? b 0 -1 + ?t + min(2 b 0 -1 , 2m -2 b 0 -1 ) 1 - ? 2 8 t .<label>(13)</label></formula><p>We also know that for some integer t,</p><formula xml:id="formula_67">apr(?, ? v , r) [k 0 ] - k 0 2m &gt; (? b 0 -1 + 1 48B ) + ?t + min(k 0 , 2m -k 0 ) 1 - ? 2 8 t .<label>(14)</label></formula><p>Since 2 b 0 -1 ? k 0 ? m, we have min(s b 0 -1 , 2m -s b 0 -1 ) ? min(k 0 , 2m -k 0 ). Taking an integer t that makes equation ( <ref type="formula" target="#formula_67">14</ref>) true, and plugging this value of t into equations ( <ref type="formula" target="#formula_67">14</ref>) and ( <ref type="formula" target="#formula_66">13</ref>), yields the following inequality.</p><p>apr(?, ? v , r) 2 b 0 -apr(?, ? v , r) 2 b 0 -1 ? apr(?, ? v , r) [k 0 ] -apr(?, ? v , r)</p><formula xml:id="formula_68">2 b 0 -1 &gt; 1 48B</formula><p>.</p><p>We have shown that S j meets all the requirements of PageRank-Nibble, which proves that the algorithm outputs some cut when run with b = b 0 . We now prove a lower bound on vol(S?C), which </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>ApproximatePageRank (v, ?, ): 1. Let p = 0, and r = ? v . 2. While max u?V r(u) d(u) ? : (a) Choose any vertex u where r(u) d(u) ? . (b) Apply push u at vertex u, updating p and r.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3 .</head><label>3</label><figDesc>Return p, which satisfies p = apr(?, ? v , r) with max u?V r(u) d(u) &lt; .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 2 .</head><label>2</label><figDesc>If there exists a set S of vertices and a constant ? ? 2 ? m satisfying apr(?, s, r)(S) -vol(S) vol(G) &gt; ?, then ?(apr(?, s, r)) &lt; 18? ln m ? .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Lemma 4 .</head><label>4</label><figDesc>For any distribution p, and any set S of vertices, pW (S) ? 1 2 (p (in(S) ? out(S)) + p (in(S) ? out(S))) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 . 3 .</head><label>23</label><figDesc>PageRank-Nibble(v, ?, b): Input: a vertex v, a constant ? ? (0, 1], and an integer b ? [1, B], where B = log 2 m . Compute an approximate PageRank vector p = apr(?, ? v , r) with residual vector r satisfying max u?V r(u) d(u) ? 2 -b 1 48B . Check each set S p j with j ? [1, |Supp(p)|], to see if it obeys the following conditions:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 7 .</head><label>7</label><figDesc>PageRank-Nibble(v, ?, b) can be implemented with running time O(2 b log 3 m ? 2 ). Theorem 8. Let C be a set satisfying ?(C) ? ? 2 /(22500 log 2 100m) and vol(C) ? 1 2 vol(G), and let v be a vertex in C ? for ? = ? 2 /(225 ln(100 ? m)). Then, there is some integer b ? [1, log 2 m ] for which PageRank-Nibble(v, ?, b) returns a set S. Any set S returned by PageRank-Nibble(v, ?, b) has the following properties:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Theorem 9 .</head><label>9</label><figDesc>The algorithm PageRank-Partition takes as input a parameter ?, and has expected running time O(m log(1/p) log 4 m/? 3 ). If there exists a set C with vol(C) ? 1 2 vol(G) and ?(C) ? ? 2 /(1845000 log 2 m), then with probability at least 1 -p, PageRank-Partition produces a set S satisfying ?(S) ? ? and 1 2 vol(C) ? vol(S) ? 5 6 vol(G).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 2 p</head><label>12</label><figDesc>vol(S p j ) -|?(S p j )| + p vol(S p j ) + |?(S p j )| ? ?s vol(S p j ) + (1 -?)p vol(S p j ) , where the last line follows from the concavity of p [k]. This implies that pr(?, s) [k j ] ? s [k j ], where k j = vol(S pr(?,s) j ), for each j ? [1, n -1]. The result follows, since s [k] is concave, and pr(?, s) [k] is linear between the points where k = k j . The amount of probability that moves from C to C in the step from pr(?, ? C ) to pr(?, ? C )W is bounded by 1 2 pr(?, ? C ) [|?(C)|], since |?(C)| is the number of directed edges from C to C. By the monotonicity property, pr(?, ? C ) [|?(C)|] ? ? C [|?(C)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Proof of Theorem 7 .</head><label>7</label><figDesc>An approximate PageRank vector p = apr(?, ? v , r), with residual vector r satisfying max u?V r(u) d(u) ? 2 -b 48B , can be computed in time O(2 b log m ? ) using ApproximatePageRank. By Theorem 1, we have vol(Supp(p)) = O(2 b log m ? ). It is possible to check each of the conditions in step 4, for every set S p j with j ? [1, |Supp(p)|], in time O(vol(Supp(apr(?, ? v , r))) log n) = O(2 b log 2 m ? ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Let B = log 2 m+ 1 10 bB</head><label>210</label><figDesc>. For each integer b in [1, B], let ? b = ?( 9 10 ). Consider the smallest value of b in [1, B] for which the following equation holds for some k ? 2 b . pr</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>( 11 )? 0 ? 8 t-</head><label>1108</label><figDesc>Equation<ref type="bibr" target="#b9">(10)</ref> shows that this equation holds with b = B and k = m. Let b 0 be the smallest value of b for which this equation holds, and let k 0 be some value such that k 0 ? m and such that this equation holds with b = b 0 and k = k 0 . Notice that s b 0 -1 &lt; k 0 ? s b 0 , because if equation<ref type="bibr" target="#b10">(11)</ref> holds for b = b 0 and k = k 0 , it also holds for b = b 0 -1 and k 0 .When PageRank-Nibble is run with b = b 0 , the approximate PageRank vector apr(?, ? v , r) computed by PageRank-Nibble has only a small amount of error on a set of volume k 0 : the error is small enough that the difference pr(?,? v ) [k 0 ] -apr(?, ? v , r) [k 0 ] is less than ? b -? b-1 = 1 10B ? = 1 24B . apr(?, ? v , r) [k 0 ] ? pr(?, ? v ) [k 0 ] -max u?V pr(?, ? v ) [k 0 ] -2 -b 0 48B k pr(?, ? v ) [k 0 ] -1 48B ? pr(?, ? v ) [k 0 ] -(? b 0 -? b 0 -1 ) + 1 48B.We then use the lower bound on pr(?, v) [k 0 ] implied by the definition of b 0 : for some integer t ? 0,apr(?, ? v , r) [k 0 ] -k 0 2m &gt; ? b 0 + ?t + min(k 0 , 2m -k 0 ) 1 -? 2 (? b 0 -? b 0 -1 ) + 1 48B &gt; (? b 0 -1 + 1 48B</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>1 &gt; 1 2</head><label>11</label><figDesc>holds for any cut S output by PageRank-Nibble, with any value of b. Let p[k] = p [k] -p [k -1]. Since p [k] is a decreasing function of k, p 2 b-1 ? p 2 b -p 2 b-1 2 b -2 b-(b-1) 48B .It is not hard to see that combining this lower bound on p 2 b-1 with the upper bound p C ? ?(C) ? gives the following bound on the volume of the intersection.vol(S j ? C) ? 2 b-1 -p C p [2 b-1 ] &gt; 2 b-1 -2 b-1 (48B ?(C) ? ).Since we have assumed that ?(C) ? ? 1 96B , we have vol(S ? C) &gt; 2 b-1 -2 b-2 = 2 b-2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>holds at k j for each j in the set [1, |Supp(p)|] ? {0, n}, and p [k] is linear between these points. Consider an index j ? [1, |Supp(p)|]. If property 2 does not hold for j, then this directly implies that equation (8) holds at j. If property 1 does not hold for j, then we have ?(S p j ) ? ?, and Lemma 5 implies the following. -?k j + p k j + ?k j . The last step above follows from the concavity of p [k]. Using the induction hypothesis,</figDesc><table><row><cell cols="3">p vol(S p j ) ? ?s vol(S p j ) + (1 -?)</cell><cell>1 2</cell><cell>p vol(S p j ) -|?(S p j )| + p vol(S p j ) + |?(S p j )|</cell></row><row><cell>? ? +</cell><cell>1 2</cell><cell cols="2">p vol(S p j ) -|?(S p j )| + p vol(S p j ) + |?(S p j )|</cell></row><row><cell>= ? +</cell><cell>1 2</cell><cell cols="2">p k j -?(S p j )k j + p k j + ?(S p j )k j</cell></row><row><cell>? ? +</cell><cell>1 2</cell><cell>p k j</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bookmark-coloring approach to personalized pagerank computing</title>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Berkhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet Mathematics</title>
		<imprint/>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploring the community structure of newsgroups</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">T</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Saberi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="783" to="787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual Web search engine</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks and ISDN Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-7</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Chung</surname></persName>
		</author>
		<title level="m">Number 92 in CBMS Regional Conference Series in Mathematics</title>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Spectral graph theory</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards scaling fully personalized pagerank</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Racz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Algorithms and Models for the Web-Graph (WAW)</title>
		<meeting>the 3rd Workshop on Algorithms and Models for the Web-Graph (WAW)</meeting>
		<imprint>
			<date type="published" when="2004-10">October 2004</date>
			<biblScope unit="page" from="105" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Topic-sensitive pagerank: A context-sensitive ranking algorithm for web search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="784" to="796" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Scaling personalized web search</title>
		<author>
			<persName><forename type="first">Glen</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th World Wide Web Conference (WWW)</title>
		<meeting>the 12th World Wide Web Conference (WWW)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On clusterings: Good, bad and spectral</title>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santosh</forename><surname>Vempala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Vetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="497" to="515" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The mixing rate of markov chains, an isoperimetric inequality, and computing the volume</title>
		<author>
			<persName><forename type="first">L?szl?</forename><surname>Lov?sz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikl?s</forename><surname>Simonovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="346" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Random walks in a convex body and an improved volume algorithm</title>
		<author>
			<persName><forename type="first">L?szl?</forename><surname>Lov?sz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikl?s</forename><surname>Simonovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Random Struct. Algorithms</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="359" to="412" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Conductance and convergence of markov chains-a combinatorial treatment of expanders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mihail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 30th FOCS</title>
		<meeting>of 30th FOCS</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="526" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The pagerank citation ranking: Bringing order to the web</title>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Stanford Digital Library Technologies Project</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">How good is recursive bisection?</title>
		<author>
			<persName><forename type="first">Horst</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang-Hua</forename><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1436" to="1445" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spectral partitioning works: Planar graphs and finite element meshes</title>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Spielman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang-Hua</forename><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Foundations of Computer Science</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="96" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems</title>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Spielman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang-Hua</forename><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM STOC-04</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
