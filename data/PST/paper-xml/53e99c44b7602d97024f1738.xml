<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Three-Dimensional Structure Determination from Common Lines in Cryo-EM by Eigenvectors and Semidefinite Programming *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">A</forename><surname>Singer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and PACM</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>Fine Hall, Washington Road</addrLine>
									<postCode>08544-1000</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Y</forename><surname>Shkolnisky</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Applied Mathematics</orgName>
								<orgName type="department" key="dep2">School of Mathematical Sciences</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Three-Dimensional Structure Determination from Common Lines in Cryo-EM by Eigenvectors and Semidefinite Programming *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BEEB4738FD26BEB776BC212C619CADAE</idno>
					<idno type="DOI">10.1137/090767777</idno>
					<note type="submission">Received by the editors August 11, 2009; accepted for publication (in revised form) February 15, 2011;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cryo-electron microscopy</term>
					<term>angular reconstitution</term>
					<term>random matrices</term>
					<term>semicircle law</term>
					<term>semidefinite programming</term>
					<term>rotation group SO(3)</term>
					<term>tomography AMS subject classifications. 92E10</term>
					<term>68U10</term>
					<term>33C55</term>
					<term>60B20</term>
					<term>90C22</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The cryo-electron microscopy reconstruction problem is to find the three-dimensional (3D) structure of a macromolecule given noisy samples of its two-dimensional projection images at unknown random directions. Present algorithms for finding an initial 3D structure model are based on the "angular reconstitution" method in which a coordinate system is established from three projections, and the orientation of the particle giving rise to each image is deduced from common lines among the images. However, a reliable detection of common lines is difficult due to the low signal-to-noise ratio of the images. In this paper we describe two algorithms for finding the unknown imaging directions of all projections by minimizing global self-consistency errors. In the first algorithm, the minimizer is obtained by computing the three largest eigenvectors of a specially designed symmetric matrix derived from the common lines, while the second algorithm is based on semidefinite programming (SDP). Compared with existing algorithms, the advantages of our algorithms are five-fold: first, they accurately estimate all orientations at very low common-line detection rates; second, they are extremely fast, as they involve only the computation of a few top eigenvectors or a sparse SDP; third, they are nonsequential and use the information in all common lines at once; fourth, they are amenable to a rigorous mathematical analysis using spectral analysis and random matrix theory; and finally, the algorithms are optimal in the sense that they reach the information theoretic Shannon bound up to a constant for an idealized probabilistic model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction.</head><p>Cryo-electron microscopy (cryo-EM) is a technique by which biological macromolecules are imaged in an electron microscope. The molecules are rapidly frozen in a thin (∼ 100nm) layer of vitreous ice, trapping them in a nearly physiological state <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Cryo-EM images, however, have very low contrast due to the absence of heavy-metal stains or other contrast enhancements, and have very high noise due to the small electron doses that can be applied to the specimen. Thus, to obtain a reliable three-dimensional (3D) density map of a macromolecule, the information from thousands of images of identical molecules must be combined. When the molecules are arrayed in a crystal, the necessary signal-averaging of noisy images is straightforwardly performed. More challenging is the problem of single-particle reconstruction (SPR), where a 3D density map is to be obtained from images of individual molecules present in random positions and orientations in the ice layer <ref type="bibr" target="#b0">[1]</ref>.</p><p>Because it does not require the formation of crystalline arrays of macromolecules, SPR is a very powerful and general technique, which has been successfully used for 3D structure determination of many protein molecules and complexes roughly 500 kDa or larger in size. In some cases, sufficient resolution (∼ 0.4nm) has been obtained from SPR to allow tracing of the polypeptide chain and identification of residues in proteins <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>; however, even with lower resolutions many important features can be identified <ref type="bibr" target="#b5">[6]</ref>.</p><p>Much progress has been made in algorithms that, given a starting 3D structure, are able to refine that structure on the basis of a set of negative-stain or cryo-EM images, which are taken to be projections of the 3D object. Datasets typically range from 10 4 to 10 5 particle images, and refinements require tens to thousands of CPU-hours. As the starting point for the refinement process, however, some sort of ab initio estimate of the 3D structure must be made. If the molecule is known to have some preferred orientation, then it is possible to find an ab initio 3D structure using the random conical tilt method <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. There are two known solutions to the ab initio estimation problem of the 3D structure that do not involve tilting. The first solution is based on the method of moments <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> that exploits the known analytical relation between the second order moments of the 2D projection images and the second order moments of the (unknown) 3D volume in order to reveal the unknown orientations of the particles. However, the method of moments is very sensitive to errors in the data and is of rather academic interest <ref type="bibr">[11, section 2.1, p. 251</ref>]. The second solution, on which present algorithms are based, is the "angular reconstitution" method of Van Heel <ref type="bibr" target="#b11">[12]</ref> in which a coordinate system is established from three projections, and the orientation of the particle giving rise to each image is deduced from common lines among the images. This method fails, however, when the particles are too small or the signal-to-noise ratio is too low, as in such cases it is difficult to correctly identify the common lines (see section 2 and Figure <ref type="figure" target="#fig_0">2</ref> for a more detailed explanation about common lines).</p><p>Ideally one would want to do the 3D reconstruction directly from projections in the form of raw images. However, the determination of common lines from the very noisy raw images is typically too error-prone. Instead, the determination of common lines is performed on pairs of class averages, namely, averages of particle images that correspond to the same viewing direction. To reduce variability, class averages are typically computed from particle images that have already been rotationally and translationally aligned <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13]</ref>. The choice of reference images for the alignment is, however, arbitrary and can represent a source of bias in the classification process. This therefore sets the goal for an ab initio reconstruction algorithm that requires as little averaging as possible.</p><p>By now there is a long history of common-line-based algorithms. As mentioned earlier, the common lines between three projections uniquely determine their relative orientations up to handedness (chirality). This observation is the basis of the angular reconstitution method of Van Heel <ref type="bibr" target="#b11">[12]</ref>, which was also developed independently by Vainshtein and Goncharov <ref type="bibr" target="#b13">[14]</ref>. Other historical aspects of the method can be found in <ref type="bibr" target="#b14">[15]</ref>. Farrow and Ottensmeyer <ref type="bibr" target="#b15">[16]</ref> used quaternions to obtain the relative orientation of a new projection in a least squares sense. The main problem with such sequential approaches is that they are sensitive to false detection of common lines, which leads to the accumulation of errors (see also <ref type="bibr">[13, p. 336]</ref>). Penczek, Zhu, and Frank <ref type="bibr" target="#b16">[17]</ref> tried to obtain the rotations corresponding to all projections simultaneously by minimizing a global energy functional. Unfortunately, minimization of the energy functional requires a brute force search in a huge parametric space of all possible orientations for all projections. Mallick et al. <ref type="bibr" target="#b17">[18]</ref> suggested an alternative Bayesian approach, in which the common line between a pair of projections can be inferred from their common lines with different projection triplets. The problem with this particular approach is that it requires too many (at least seven) common lines to be correctly identified simultaneously. Therefore, it is not suitable in cases where the detection rate of correct common lines is low. In <ref type="bibr" target="#b18">[19]</ref> we introduced an improved Bayesian approach based on voting that requires only two common lines to be correctly identified simultaneously and can therefore distinguish the correctly identified common lines from the incorrect ones at much lower detection rates. The common lines that passed the voting procedure are then used by our graph-based approach <ref type="bibr" target="#b19">[20]</ref> to assign Euler angles to all projection images. As shown in <ref type="bibr" target="#b18">[19]</ref>, the combination of the voting method with the graph-based method resulted in a 3D ab initio reconstruction of the E. coli 50S ribosomal subunit from real microscope images that had undergone only rudimentary averaging.</p><p>The two-dimensional (2D) variant of the ab initio reconstruction problem in cryo-EM, namely, the reconstruction of 2D objects from their one-dimensional (1D) projections taken at random and unknown directions, has a somewhat shorter history, starting with the work of Basu and Bresler <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, who considered the mathematical uniqueness of the problem as well as the statistical and algorithmic aspects of reconstruction from noisy projections. In <ref type="bibr" target="#b22">[23]</ref> we detailed a graph-Laplacian based approach for the solution of this problem. Although the two problems are related, there is a striking difference between the ab initio reconstruction problems in 2D and 3D. In the 3D problem, the Fourier transforms of any pair of 2D projection images share a common line, which provides some non-trivial information about their relative orientations. In the 2D problem, however, the intersection of the Fourier transforms of any 1D projection sinograms is the origin, and this trivial intersection point provides no information about the angle between the projection directions. This is a significant difference, and, as a result, the solution methods to the two problems are also quite different. Hereafter we solely consider the 3D ab initio reconstruction problem as it arises in cryo-EM.</p><p>In this paper we introduce two common-line-based algorithms for finding the unknown orientations of all projections in a globally consistent way. Both algorithms are motivated by relaxations of a global minimization problem of a particular self-consistency error (SCE) that takes into account the matching of common lines between all pairs of images. A similar SCE was used in <ref type="bibr" target="#b15">[16]</ref> to assess the quality of their angular reconstitution techniques. Our approach is different in the sense that we actually minimize the SCE in order to find the imaging directions. The precise definition of our global SCE is given in section 2.</p><p>In section 3, we present our first recovery algorithm, in which the global minimizer is approximated by the top three eigenvectors of a specially designed symmetric matrix derived from the common-line data. We describe how the unknown rotations are recovered from these eigenvectors. The underlying assumption for the eigenvector method to succeed is that the unknown rotations are sampled from the uniform distribution over the rotation group SO(3), namely, that the molecule has no preferred orientation. Although it is motivated by a certain Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php global optimization problem, the exact mathematical justification for the eigenvector method is provided later in section 6, where we show that the computed eigenvectors are discrete approximations of the eigenfunctions of a certain integral operator.</p><p>In section 4, we use a different relaxation of the global optimization problem, which leads to our second recovery method based on semidefinite programming (SDP) <ref type="bibr" target="#b23">[24]</ref>. Our SDP algorithm has similarities to the Goemans-Williamson max-cut algorithm <ref type="bibr" target="#b24">[25]</ref>. The SDP approach does not require the previous assumption that the rotations are sampled from the uniform distribution over SO <ref type="bibr" target="#b2">(3)</ref>.</p><p>Compared with existing algorithms, the main advantage of our methods is that they correctly find the orientations of all projections at amazingly low common line detection rates as they take into account all the geometric information in all common lines at once. In fact, the estimation of the orientations improves as the number of images increases. In section 5 we describe the results of several numerical experiments using the two algorithms, showing successful recoveries at very low common-line detection rates. For example, both algorithms successfully recover a meaningful ab initio coordinate system from 500 projection images when only 20% of the common lines are correctly identified. The eigenvector method is extremely efficient, and the estimated 500 rotations were obtained in a matter of seconds on a standard laptop machine.</p><p>In section 6, we show that in the limit of an infinite number of projection images, the symmetric matrix that we design converges to a convolution integral operator on the rotation group SO(3). This observation explains many of the spectral properties that the matrix exhibits. In particular, this allows us to demonstrate that the top three eigenvectors provide the recovery of all rotations. Moreover, in section 7 we analyze a probabilistic model which is introduced in section 5 and show that the effect of the misidentified common lines is equivalent to a random matrix perturbation. Thus, using classical results in random matrix theory, we demonstrate that the top three eigenvalues and eigenvectors are stable as long as the detection rate of common lines exceeds 6 √ 2 5 √ N , where N is the number of images. From the practical point of view, this result implies that 3D reconstruction is possible even at extreme levels of noise, provided that enough projections are taken. From the theoretical point of view, we show that this detection rate achieves the information theoretic Shannon bound up to a constant, rendering the optimality of our method for ab initio 3D structure determination from common lines under this idealized probabilistic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>The global self-consistency error. Suppose we collect N 2D digitized projection images P 1 , . . . , P N of a 3D object taken at unknown random orientations. To each projection image P i (i = 1, . . . , N) there corresponds a 3 × 3 unknown rotation matrix R i describing its orientation (see Figure <ref type="figure">1</ref>). Excluding the contribution of noise, the pixel intensities correspond to line integrals of the electric potential induced by the molecule along the path of the imaging electrons, that is, (2.1)</p><formula xml:id="formula_0">P i (x, y) = ∞ -∞ φ i (x, y, z) dz,</formula><p>where φ(x, y, z) is the electric potential of the molecule in some fixed "laboratory" coordinate system and φ i (r) = φ(R -1 i r) with r = (x, y, z). The projection operator (2.1) is also known</p><formula xml:id="formula_1">Projection Pi Molecule φ Electron source Ri = ⎛ ⎝ | | | R 1 i R 2 i R 3 i | | | ⎞ ⎠ ∈ SO(3)</formula><p>Figure <ref type="figure">1</ref>. Schematic drawing of the imaging process: every projection image corresponds to some unknown 3D rotation of the unknown molecule.</p><p>as the X-ray transform <ref type="bibr" target="#b25">[26]</ref>. Our goal is to find all rotation matrices R 1 , . . . , R N given the dataset of noisy images.</p><p>The Fourier projection-slice theorem (see, e.g., <ref type="bibr">[26, p. 11]</ref>) says that the 2D Fourier transform of a projection image, denoted P , is the restriction of the 3D Fourier transform of the projected object φ to the central plane (i.e., going through the origin) θ ⊥ perpendicular to the imaging direction, that is,</p><formula xml:id="formula_2">(2.2) P (η) = φ(η), η ∈ θ ⊥ .</formula><p>As every two nonparallel planes intersect at a line, it follows from the Fourier projectionslice theorem that any two projection images have a common line of intersection in the Fourier domain. Therefore, if Pi and Pj are the 2D Fourier transforms of projections P i and P j , then there must be a central line in Pi and a central line in Pj on which the two transforms agree (see Figure <ref type="figure" target="#fig_0">2</ref>). This pair of lines is known as the common line. We parameterize the common line by (ωx ij , ωy ij ) in Pi and by (ωx ji , ωy ji ) in Pj , where ω ∈ R is the radial frequency and (x ij , y ij ) and (x ji , y ji ) are two unit vectors for which <ref type="bibr">(2.3)</ref> Pi (ωx ij , ωy ij ) = Pj (ωx ji , ωy ji ) for all ω ∈ R.</p><p>It is instructive to consider the unit vectors (x ij , y ij ) and (x ji , y ji ) as 3D vectors by zeropadding. Specifically, we define c ij and c ji as</p><formula xml:id="formula_3">c ij = (x ij , y ij , 0) T , (2.4) c ji = (x ji , y ji , 0) T .</formula><p>(2.5) Being the common line of intersection, the mapping of c ij by R i must coincide with the mapping of c ji by R j :</p><formula xml:id="formula_4">Projection P i Projection P j Pi Pj 3D Fourier space 3D Fourier space (x ij , y ij ) (x ij , y ij ) (x ji , y ji ) (x ji , y ji ) R i c ij R i c ij = R j c ji</formula><p>(2.6)</p><formula xml:id="formula_5">R i c ij = R j c ji for 1 ≤ i &lt; j ≤ N.</formula><p>These can be viewed as N 2 linear equations for the 6N variables corresponding to the first two columns of the rotation matrices (as c ij and c ji have a zero third entry, the third column of each rotation matrix does not contribute in (2.6)). Such overdetermined systems of linear equations are usually solved by the least squares method <ref type="bibr" target="#b16">[17]</ref>. Unfortunately, the least squares approach is inadequate in our case due to the typically large proportion of falsely detected common lines that will dominate the sum of squares error in <ref type="bibr">(2.7)</ref> min</p><formula xml:id="formula_6">R 1 ,...,R N i =j R i c ij -R j c ji 2 .</formula><p>Moreover, the global least squares problem (2.7) is nonconvex and therefore extremely difficult to solve if one requires the matrices R i to be rotations, that is, when adding the constraints</p><formula xml:id="formula_7">(2.8) R i R T i = I, det(R i ) = 1 for i = 1, . . . , N,</formula><p>where I is the 3 × 3 identity matrix. A relaxation method that neglects the constraints (2.8) will simply collapse to the trivial solution R 1 = • • • = R N = 0 which obviously does not satisfy the constraint (2.8). Such a collapse is easily prevented by fixing one of the rotations, for example, by setting R 1 = I, but this would not make the robustness problem of the least squares method go away. We therefore take a different approach for solving the global optimization problem.</p><p>Since c ij = c ji = 1 are 3D unit vectors, their rotations are also unit vectors; that is, R i c ij = R j c ji = 1. It follows that the minimization problem (2.7) is equivalent to the maximization problem of the sum of dot products (2.9) max</p><formula xml:id="formula_8">R 1 ,...,R N i =j R i c ij • R j c ji ,</formula><p>subject to the constraints (2.8). For the true assignment of rotations, the dot product R i c ij • R j c ji equals 1 whenever the common line between images i and j is correctly detected. Dot products corresponding to misidentified common lines can take any value between -1 to 1, and if we assume that such misidentified lines have random directions, then such dot products can be considered as identically independently distributed (i.i.d.) zero-mean random variables taking values in the interval [-1, 1]. The objective function in (2.9) is the summation over all possible dot products. Summing up dot products that correspond to misidentified common lines results in many cancelations, whereas summing up dot products of correctly identified common lines is simply a sum of ones. We may consider the contribution of the falsely detected common lines as a random walk on the real line, where steps to the left and to the right are equally probable. From this interpretation it follows that the total contribution of the misidentified common lines to the objective function (2.9) is proportional to the square root of the number of misidentifications, whereas the contribution of the correctly identified common lines is linear. This square-root diminishing effect of the misidentifications makes the global optimization (2.9) extremely robust compared with the least squares approach, which is much more sensitive because its objective function is dominated by the misidentifications. These intuitive arguments regarding the statistical attractiveness of the optimization problem (2.9) will later be put on firm mathematical ground using random matrix theory as elaborated in section 7. Still, in order for the optimization problem (2.9) to be of any practical use, we must show that its solution can be efficiently computed. We note that our objective function is closely related to the SCE of Farrow and Ottensmeyer [16, eq. ( <ref type="formula">6</ref>), p. 1754] given by (2.10)</p><formula xml:id="formula_9">SCE = i =j arccos (R i c ij • R j c ji ) .</formula><p>This SCE was introduced and used in <ref type="bibr" target="#b15">[16]</ref> to measure the success of their quaternion-based sequential iterative angular reconstitution methods. At the small price of deleting the wellbehaved monotonic nonlinear arccos function in (2.10), we arrive at (2.9), which, as we will soon show, has the great advantage of being amenable to efficient global nonsequential optimization by either spectral or semidefinite programming relaxations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Eigenvector relaxation.</head><p>The objective function in (2.9) is quadratic in the unknown rotations R 1 , . . . , R N , which means that if the constraints (2.8) are properly relaxed, then the solution to the maximization problem (2.9) would be related to the top eigenvectors of the matrix defining the quadratic form. In this section we give a precise definition of that matrix and show how the unknown rotations can be recovered from its top three eigenvectors. Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>We first define the four N × N matrices S 11 , S 12 , S 21 , and S 22 using all available commonline data (2.4)-(2.5) as</p><formula xml:id="formula_10">(3.1) S 11 ij = x ij x ji , S 12 ij = x ij y ji , S 21 ij = y ij x ji , S 22 ij = y ij y ji</formula><p>for 1 ≤ i = j ≤ N , while their diagonals are set to zero:</p><formula xml:id="formula_11">S 11 ii = S 12 ii = S 21 ii = S 22 ii = 0, i = 1, . . . , N.</formula><p>Clearly, S 11  is symmetric (S = S T ) and stores all available common line information. More importantly, the top eigenvectors of S will reveal all rotations in a manner we describe below.</p><p>We denote the columns of the rotation matrix R i by R 1 i , R 2 i , and R 3 i , and write the rotation matrices as</p><formula xml:id="formula_12">(3.3) R i = ⎛ ⎝ | | | R 1 i R 2 i R 3 i | | | ⎞ ⎠ = ⎛ ⎝ x 1 i x 2 i x 3 i y 1 i y 2 i y 3 i z 1 i z 2 i z 3 i ⎞ ⎠ , i = 1, . . . , N.</formula><p>Only the first two columns of the R i 's need to be recovered, because the third column is given by the cross product:</p><formula xml:id="formula_13">R 3 i = R 1 i × R 2 i .</formula><p>We therefore need to recover the six N -dimensional coordinate vectors x 1 , y 1 , z 1 , x 2 , y 2 , z 2 that are defined by</p><formula xml:id="formula_14">x 1 = (x 1 1 x 1 2 • • • x 1 N ) T , y 1 = (y 1 1 y 1 2 • • • y 1 N ) T , z 1 = (z 1 1 z 1 2 • • • z 1 N ) T , (3.4) x 2 = (x 2 1 x 2 2 • • • x 2 N ) T , y 2 = (y 2 1 y 2 2 • • • y 2 N ) T , z 2 = (z 2 1 z 2 2 • • • z 2 N ) T . (3.5)</formula><p>Alternatively, we need to find the following three 2N -dimensional vectors x, y, and z:</p><formula xml:id="formula_15">x = x 1 x 2 , y = y 1 y 2 , z = z 1 z 2 . (3.6)</formula><p>Using this notation we rewrite the objective function (2.9) as</p><formula xml:id="formula_16">(3.7) i =j R i c ij • R j c ji = x T Sx + y T Sy + z T Sz,</formula><p>Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php which is a result of the following index manipulation:</p><formula xml:id="formula_17">i =j R i c ij • R j c ji = i =j x ij x ji R 1 i • R 1 j + x ij y ji R 1 i • R 2 j + y ij x ji R 2 i • R 1 j + y ij y ji R 2 i • R 2 j = i =j S 11 ij R 1 i • R 1 j + S 12 ij R 1 i • R 2 j + S 21 ij R 2 i • R 1 j + S 22 ij R 2 i • R 2 j (3.8) = i,j S 11 ij (x 1 i x 1 j + y 1 i y 1 j + z 1 i z 1 j ) + S 12 ij (x 1 i x 2 j + y 1 i y 2 j + z 1 i z 2 j ) + S 21 ij (x 2 i x 1 j + y 2 i y 1 j + z 2 i z 1 j ) + S 22 ij (x 2 i x 2 j + y 2 i y 2 j + z 2 i z 2 j ) = x 1 T S 11 x 1 + y 1 T S 11 y 1 + z 1 T S 11 z 1 + x 1 T S 12 x 2 + y 1 T S 12 y 2 + z 1 T S 12 z 2 + x 2 T S 21 x 1 + y 2 T S 21 y 1 + z 2 T S 21 z 1 + x 2 T S 22 x 2 + y 2 T S 22 y 2 + z 2 T S 22 z 2 = x T Sx + y T Sy + z T Sz. (3.9)</formula><p>The equality <ref type="bibr">(3.7)</ref> shows that the maximization problem (2.9) is equivalent to the maximization problem</p><formula xml:id="formula_18">(3.10) max R 1 ,...,R N x T Sx + y T Sy + z T Sz,</formula><p>subject to the constraints (2.8). In order to make this optimization problem tractable, we relax the constraints and look for the solution of the proxy maximization problem (3.11) max</p><p>x =1</p><p>x T Sx.</p><p>The connection between the solution to <ref type="bibr">(3.11)</ref> and that of (3.10) will be made shortly. Since S is a symmetric matrix, it has a complete set of orthonormal eigenvectors {v</p><formula xml:id="formula_19">1 , . . . , v 2N } satisfying Sv n = λ n v n , n = 1, . . . , 2N, with real eigenvalues λ 1 ≥ λ 2 ≥ • • • ≥ λ 2N .</formula><p>The solution to the maximization problem (3.11) is therefore given by the top eigenvector v 1 with largest eigenvalue λ 1 :</p><p>(3.12)</p><formula xml:id="formula_20">v 1 = argmax x =1</formula><p>x T Sx.</p><p>If the unknown rotations are sampled from the uniform distribution (Haar measure) over SO <ref type="bibr" target="#b2">(3)</ref>, that is, when the molecule has no preferred orientation, then the largest eigenvalue should have multiplicity three, corresponding to the vectors x, y, and z, as the symmetry of the problem in this case suggests that there is no reason to prefer x over y and z that appear in <ref type="bibr">(3.10)</ref>  <ref type="bibr">(3.11)</ref>. The required formal justification is provided in section 6, where we prove that in the limit of infinitely many images (N → ∞) the matrix S converges to an integral operator over SO(3) for which x, y, and z in (3.6) are eigenfunctions sharing the same eigenvalue. The computed eigenvectors of the matrix S are therefore discrete approximations of the eigenfunctions of the limiting integral operator. In particular, the linear subspace spanned by the top three eigenvectors of S is a discrete approximation of the subspace spanned by x, y, and z.</p><p>We therefore expect to be able to recover the first two columns of the rotation matrices R 1 , . . . , R N from the top three computed eigenvectors v 1 , v 2 , v 3 of S. Since the eigenspace of x, y, and z is of dimension three, the vectors x, y, and z should be approximately obtained by a 3× 3 orthogonal transformation applied to the computed eigenvectors v 1 , v 2 , v 3 . This global orthogonal transformation is an inherent degree of freedom in the estimation of rotations from common lines. That is, it is possible to recover the molecule only up to a global orthogonal transformation, that is, up to rotation and possibly reflection. This recovery is performed by constructing for every i = 1, . . . , N a 3 × 3 matrix</p><formula xml:id="formula_21">A i = ⎛ ⎝ | | | A 1 i A 2 i A 3 i | | | ⎞ ⎠</formula><p>whose columns are given by (3.13)</p><formula xml:id="formula_22">A 1 i = ⎛ ⎜ ⎝ v 1 i v 2 i v 3 i ⎞ ⎟ ⎠ , A 2 i = ⎛ ⎜ ⎝ v 1 N +i v 2 N +i v 3 N +i ⎞ ⎟ ⎠ , A 3 i = A 1 i × A 2 i .</formula><p>In practice, due to erroneous common lines and deviations from the uniformity assumption, the matrix A i is approximately a rotation, so we estimate R i as the closest rotation matrix to A i in the Frobenius matrix norm. This is done via the well-known procedure <ref type="bibr" target="#b26">[27]</ref> </p><formula xml:id="formula_23">R i = U i V T i , where A i = U i Σ i V T</formula><p>i is the singular value decomposition of A i . A second set of valid rotations Ri is obtained from the matrices Ãi whose columns are given by</p><formula xml:id="formula_24">(3.14) Ã1 i = ⎛ ⎝ 1 0 0 0 1 0 0 0 -1 ⎞ ⎠ A 1 i , Ã2 i = ⎛ ⎝ 1 0 0 0 1 0 0 0 -1 ⎞ ⎠ A 2 i , Ã3 i = Ã1 i × Ã2 i ,</formula><p>via their singular value decomposition, that is, Ri = Ũi Ṽ T i , where Ãi = Ũi Σi Ṽ T i . The second set of rotations Ri amounts to a global reflection of the molecule; it is a well-known fact that the chirality of the molecule cannot be determined from common-line data. Thus, in the absence of any other information, it is impossible to prefer one set of rotations over the other.</p><p>From the computational point of view, we note that a simple way of computing the top three eigenvectors is using the iterative power method, where three initial randomly chosen vectors are repeatedly multiplied by the matrix S and then orthonormalized by the Gram-Schmidt (QR) procedure until convergence. The number of iterations required by such a procedure is determined by the spectral gap between the third and forth eigenvalues. The spectral gap is further discussed in sections 5-7. In practice, for large values of N we use the MATLAB function eigs to compute the few top eigenvectors, while for small N we compute all eigenvectors using the MATLAB function eig. We remark that the computational bottleneck for large N is often the storage of the 2N × 2N matrix S rather than the time complexity of computing the top eigenvectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Relaxation by a semidefinite program.</head><p>In this section we present an alternative relaxation of (2.9) using semidefinite programming (SDP) <ref type="bibr" target="#b23">[24]</ref>, which draws similarities with the Goemans-Williamson SDP for finding the maximum cut in a weighted graph <ref type="bibr" target="#b24">[25]</ref>. The relaxation of the SDP is tighter than the eigenvector relaxation and does not require the assumption that the rotations are uniformly sampled over SO <ref type="bibr" target="#b2">(3)</ref>.</p><p>The SDP formulation begins with the introduction of two 3 × N matrices R 1 and R 2 defined by concatenating the first columns and second columns of the N rotation matrices, respectively, (4.1)</p><formula xml:id="formula_25">R 1 = ⎛ ⎝ | | | R 1 1 R 1 2 • • • R 1 N | | | ⎞ ⎠ , R 2 = ⎛ ⎝ | | | R 2 1 R 2 2 • • • R 2 N | | | ⎞ ⎠ .</formula><p>We also concatenate R 1 and R 2 to define a 3 × 2N matrix R given by</p><formula xml:id="formula_26">(4.2) R = (R 1 R 2 ) = ⎛ ⎝ | | | | | | R 1 1 R 1 2 • • • R 1 N R 2 1 R 2 2 • • • R 2 N | | | | | | ⎞ ⎠ .</formula><p>The Gram matrix G for the matrix R is a 2N × 2N matrix of inner products between the 3D column vectors of R, that is,</p><formula xml:id="formula_27">(4.3) G = R T R.</formula><p>Clearly, G is a rank-3 semidefinite positive matrix (G 0), which can be conveniently written as a block matrix</p><formula xml:id="formula_28">(4.4) G = G 11 G 12 G 21 G 22 = R 1 T R 1 R 1 T R 2 R 2 T R 1 R 2 T R 2 .</formula><p>The orthogonality of the rotation matrices (R</p><formula xml:id="formula_29">T i R i = I) implies that (4.5) G 11 ii = G 22 ii = 1, i = 1, 2, . . . , N,</formula><p>and</p><formula xml:id="formula_30">(4.6) G 12 ii = G 21 ii = 0, i = 1, 2, . . . , N.</formula><p>From (3.8) it follows that the objective function (2.9) is the trace of the matrix product SG: </p><formula xml:id="formula_31">(4.7) i =j R i c ij • R j c ji =</formula><formula xml:id="formula_32">G 11 ii = G 22 ii = 1, G 12 ii = G 21 ii = 0, i = 1, 2, . . . , N. (4.10)</formula><p>The only constraint missing in this SDP formulation is the nonconvex rank-3 constraint on the Gram matrix G. The matrix R is recovered from the Cholesky decomposition of the solution G of the SDP (4.8)-(4.10). If the rank of G is greater than 3, then we project the rows of R onto the subspace spanned by the top three eigenvectors of G and recover the rotations using the procedure that was detailed in the previous section in <ref type="bibr">(3.13)</ref>. We note that except for the orthogonality constraint (4.6), the semidefinite program (4.8)-(4.10) is identical to the Goemans-Williamson SDP for finding the maximum cut in a weighted graph <ref type="bibr" target="#b24">[25]</ref>.</p><p>From the complexity point of view, SDP can be solved in polynomial time to any given precision, but even the most sophisticated SDP solvers that exploit the sparsity structure of the max cut problem are not competitive with the much faster eigenvector method. At first glance it may seem that the SDP (4.8)-(4.10) should outperform the eigenvector method in terms of producing more accurate rotation matrices. However, our simulations show that the accuracy of both methods is almost identical when the rotations are sampled from the uniform distribution over SO <ref type="bibr" target="#b2">(3)</ref>. As the eigenvector method is much faster, it should also be the method of choice whenever the rotations are a priori known to be uniformly sampled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Numerical simulations.</head><p>We performed several numerical experiments that illustrate the robustness of the eigenvector and the SDP methods to false identifications of common lines. All simulations were performed in MATLAB on a Lenovo Thinkpad X300 laptop with Intel Core 2 CPU L7100 1.2GHz with 4GB RAM running Windows Vista.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experiments with simulated rotations.</head><p>In the first series of simulations we tried to imitate the experimental setup by using the following procedure. In each simulation, we randomly sampled N rotations from the uniform distribution over SO <ref type="bibr" target="#b2">(3)</ref>. This was done by randomly sampling N vectors in R 4 whose coordinates are i.i.d. Gaussians, followed by normalizing these vectors to the unit 3D sphere S 3 ⊂ R 4 . The normalized vectors are viewed as unit quaternions which we converted into 3 × 3 rotation matrices R 1 , . . . , R N . We then computed all pairwise common-line vectors</p><formula xml:id="formula_33">c ij = R -1 i R 3 i ×R 3 j R 3 i ×R 3 j and c ji = R -1 j R 3 i ×R 3 j R 3 i ×R 3 j</formula><p>(see also the discussion following (6.2)). For each pair of rotations, with probability p we kept the values of c ij and c ji unchanged, while with probability 1p we replaced c ij and c ji by two random vectors that were sampled from the uniform distribution over the unit circle in the plane. The parameter p ranges from 0 to 1 and indicates the proportion of the correctly detected common lines. For example, p = 0.1 means that only 10% of the common lines are identified correctly, and the other 90% of the entries of the matrix S are filled in with random entries corresponding to some randomly chosen unit vectors. is the spectral gap between the three largest eigenvalues and the remaining eigenvalues, as long as p is not too small. As p decreases, the spectral gap narrows down, until it completely disappears at some critical value p c , which we call the threshold probability. Figure <ref type="figure">3</ref> indicates that the value of the critical probability for N = 100 is somewhere between 0.1 and 0.25, whereas for N = 500 it is bounded between 0.05 and 0.1. The algorithm is therefore more likely to cope with a higher percentage of misidentifications by using more images (larger N ).</p><p>When p decreases, not only does the gap narrow, but also the histogram of the eigenvalues becomes smoother. The smooth part of the histogram seems to follow the semicircle law of Wigner <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, as illustrated in Figure <ref type="figure">3</ref>. The support of the semicircle gets slightly larger as p decreases, while the top three eigenvalues shrink significantly. In the next sections we will provide a mathematical explanation for the numerically observed eigenvalue histograms and for the emergence of Wigner's semicircle.</p><p>A further investigation into the results of the numerical simulations also reveals that the rotations that were recovered by the top three eigenvectors successfully approximated the sampled rotations, as long as p was above the threshold probability p c . The accuracy of our methods is measured by the following procedure. Denote by R1 , . . . , RN the rotations as estimated by either the eigenvector or SDP methods, and by R 1 , . . . , R N the true sampled rotations. First, note that (2.6) implies that the true rotations can be recovered only up to a fixed 3</p><formula xml:id="formula_34">× 3 orthogonal transformation O, since if R i c ij = R j c ji , then also OR i c ij = OR j c ji .</formula><p>In other words, a completely successful recovery satisfies R-1</p><p>i R i = O for all i = 1, . . . , N for some fixed orthogonal matrix O. In practice, however, due to erroneous common lines and deviation from uniformity (for the eigenvector method), there does not exist an orthogonal transformation O that perfectly aligns all the estimated rotations with the true ones. But we may still look for the optimal rotation Ô that minimizes the sum of squared distances between the estimated rotations and the true ones:</p><p>(5.1) Ô = argmin where • F denotes the Frobenius matrix norm. That is, Ô is the optimal solution to the registration problem between the two sets of rotations in the sense of minimizing the mean squared error (MSE). Using properties of the trace, in particular tr(AB) = tr(BA) and tr(A) = tr(A T ), we notice that</p><formula xml:id="formula_35">O∈SO(3) N i=1 R i -O Ri</formula><formula xml:id="formula_36">N i=1 R i -O Ri 2 F = N i=1 tr R i -O Ri R i -O Ri T = N i=1 tr 2I -2O Ri R T i = 6N -2 tr O N i=1 Ri R T i . (5.2)</formula><p>Let Q be the 3 × 3 matrix</p><formula xml:id="formula_37">(5.3) Q = 1 N N i=1 Ri R T i ;</formula><p>then from (5.2) it follows that the MSE is given by</p><formula xml:id="formula_38">(5.4) 1 N N i=1 R i -O Ri 2 F = 6 -2 tr(OQ).</formula><p>Arun, Huang, and Bolstein <ref type="bibr" target="#b26">[27]</ref> proved that tr(OQ) ≤ tr(V U T Q) for all O ∈ SO <ref type="bibr" target="#b2">(3)</ref>, where Q = U ΣV T is the singular value decomposition of Q. It follows that the MSE is minimized by the orthogonal matrix Ô = V U T , and the MSE in such a case is given by (5.5)</p><formula xml:id="formula_39">MSE = 1 N N i=1 R i -Ô Ri 2 F = 6 -2 tr(V U T U ΣV T ) = 6 -2 3 r=1 σ r ,</formula><p>where σ 1 , σ 2 , σ 3 are the singular values of Q. In particular, the MSE vanishes whenever Q is an orthogonal matrix, because in such a case σ 1 = σ 2 = σ 3 = 1.</p><p>In our simulations we compute the MSE (5.5) for each of the two valid sets of rotations (due to the handedness ambiguity, see (3.13)-(3.14)) and always present the smallest of the two. Table <ref type="table" target="#tab_3">1</ref> compares the MSEs that were obtained by the eigenvector method with the ones obtained by the SDP method for N = 100 and N = 500 with the same common-line input data. The SDP was solved using SDPLR, a package for solving large-scale SDP problems <ref type="bibr" target="#b29">[30]</ref> in MATLAB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experiments with simulated noisy projections.</head><p>In the second series of experiments, we tested the eigenvector and SDP methods on simulated noisy projection images of a ribosomal subunit for different numbers of projections (N = 100, 500, 1000) and different levels of noise. For each N , we generated N noise-free centered projections of the ribosomal subunit, whose corresponding rotations were uniformly distributed on SO(3). Each projection was of size 129 × 129 pixels. Next, we fixed a signal-to-noise ratio (SNR), and added to each   where Var is the variance (energy), Signal is the clean projection image, and Noise is the noise realization of that image. Figure <ref type="figure" target="#fig_4">4</ref> shows one of the projections at different SNR levels. The SNR values used throughout this experiment were 2 -k with k = 0, . . . , 9. Clean projections were generated by setting SNR = 2 20 . We computed the 2D Fourier transform of all projections on a polar grid discretized into L = 72 central lines, corresponding to an angular resolution of 360 • /72 = 5 • . We constructed the matrix S according to (3.1)-(3.2) by comparing all N 2 pairs of projection images; for each pair we detected the common line by computing all L 2 /2 possible different 1 Perhaps a more realistic model for the noise is that of a correlated Poissonian noise rather than the Gaussian white noise model that is used in our simulations. Correlations are expected due to the varying width of the ice layer and the point-spread-function of the camera <ref type="bibr" target="#b0">[1]</ref>. A different noise model would most certainly have an effect on the detection rate of correct common lines, but this issue is shared by all common-line-based algorithms and is not specific to our presented algorithms. normalized correlations between their Fourier central lines, of which the pair of central lines having the maximum normalized correlation was declared as the common line. Table <ref type="table" target="#tab_4">2</ref> shows the proportion p of the correctly detected common lines as a function of the SNR (we consider a common line as correctly identified if each of the estimated direction vectors (x ij , y ij ) and (x ji , y ji ) is within 10 • of its true direction). As expected, the proportion p is a decreasing function of the SNR.</p><p>We used the MATLAB function eig to compute the eigenvalue histograms of all S matrices as shown in Figures <ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>. There is a clear resemblance between the eigenvalue histograms of the noisy S matrices shown in Figure <ref type="figure">3</ref> and those shown in Figures <ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>. One noticeable difference is that the top three eigenvalues in Figures <ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>tend to spread (note, for example, the spectral gap between the top three eigenvalues in Figure <ref type="figure">5</ref>(e)), whereas in Figure <ref type="figure">3</ref> they tend to stick together. We attribute this spreading effect to the fact that the model used in section 5.1 is too simplified; in particular, it ignores the dependencies among the misidentified common lines. Moreover, falsely detected common lines are far from being uniformly distributed. The correct common line is often confused with a Fourier central line that is similar to it; it is not just confused with any other Fourier central line with equal probability. Also, the detection of common lines tends to be more successful when computed between projections that have more pronounced signal features. This means that the assumption that each common line is detected correctly with a fixed probability p is too restrictive. Still, despite the simplified assumptions that were made in section 5.1 to model the matrix S, the resulting eigenvalue histograms are very similar.</p><p>From our numerical simulations it seems that increasing the number of projections N separates the top three eigenvalues from the bulk of the spectrum (the semicircle). For example, for N = 100 the top eigenvalues are clearly distinguished from the bulk for SNR = 1/32, while for N = 500 they can be distinguished for SNR = 1/128 (maybe even at SNR = 1/256), and for N = 1000 they are distinguished even at the most extreme noise level of SNR = 1/512. The existence of a spectral gap is a necessary but not sufficient condition for a successful 3D reconstruction, as demonstrated below. We therefore must check the resulting MSEs in order to assess the quality of our estimates. Table <ref type="table" target="#tab_5">3</ref>  methods for N = 100, N = 500, and N = 1000. Examining Table <ref type="table" target="#tab_5">3</ref> reveals that the MSE is sufficiently small for SNR ≥ 1/32, but is relatively large for SNR ≤ 1/64 for all N . Despite the visible spectral gap that was observed for SNR = 1/64 with N = 500 and N = 1000, Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php the corresponding MSE is not small. We attribute the large MSE to the shortcomings of our simplified probabilistic Wigner model that assumes independence among the errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>details the MSE of the eigenvector and SDP</head><p>To demonstrate the effectiveness of our methods for ab initio reconstruction, we present in Figure <ref type="figure" target="#fig_6">8</ref> the volumes estimated from N = 1000 projections at various levels of SNR. For each level of SNR, we present in Figure <ref type="figure" target="#fig_6">8</ref> four volumes. The left volume in each row was reconstructed from the noisy projections at the given SNR and the orientations estimated using the eigenvector method. The middle-left volume was reconstructed from the noisy projections and the orientations estimated using the SDP method. The middle-right volume is a reference volume reconstructed from the noisy projections and the true (simulated) orientations. This enables us to gauge the effect of the noise in the projections on the reconstruction. Finally, the right column shows the reconstruction from clean projections and orientations estimated using the eigenvector method. It is clear from Figure <ref type="figure" target="#fig_6">8</ref> that errors in estimating the orientations have far more effect on the reconstruction than high levels of noise in the projections. All reconstructions in Figure <ref type="figure" target="#fig_6">8</ref> were obtained using a simple interpolation of Fourier space into the 3D pseudopolar grid, followed by an inverse 3D pseudopolar Fourier transform, implemented along the lines of <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>.</p><p>As mentioned earlier, the usual method for detecting the common-line pair between two images is by comparing all pairs of radial Fourier lines and declaring the common line as the pair whose normalized cross-correlation is maximal. This procedure for detecting the common lines may not be optimal. Indeed, we have observed empirically that the application Reconstruction from N = 1000 noisy projections at various SNR levels using the eigenvector method. Left column: reconstructions generated from noisy projections and orientations estimated using the eigenvector method. Middle-left column: reconstructions generated from noisy projections and orientations estimated using the SDP method. Middle-right column: reconstructions from noisy projections and the true orientations. Right column: reconstructions from estimated orientations (using the eigenvector method) and clean projections.</p><p>of principal component analysis (PCA) improves the fraction of correctly identified common lines. More specifically, we applied PCA to the radial lines extracted from all N images, and linearly projected all radial lines into the subspace spanned by the top k principal components (k ≈ 10). As a result, the radial lines are compressed (i.e., represented by only k feature coefficients) and filtered. Table <ref type="table">4</ref> shows the fraction of correctly identified common lines using Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>The fraction of correctly identified common lines p using the PCA method for different numbers of images: N = 100, N = 500, and N = 1000. the PCA method for different numbers of images. By comparing Table <ref type="table">4</ref> with Table <ref type="table" target="#tab_4">2</ref> we conclude that PCA improves the detection of common lines. The MSEs shown in Table <ref type="table" target="#tab_5">3</ref> correspond to common lines that were detected using the PCA method. In summary, even if ab initio reconstruction is not possible from the raw noisy images whose SNR is too low, the eigenvector and SDP methods should allow us to obtain an initial model from class averages consisting of only a small number of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SNR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">The matrix S as a convolution operator on SO(3).</head><p>Taking an even closer look into the numerical distribution of the eigenvalues of the "clean" 2N × 2N matrix S clean corresponding to p = 1 (all common lines detected correctly) reveals that its eigenvalues have the exact same multiplicities as the spherical harmonics, which are the eigenfunctions of the Laplacian on the unit sphere S 2 ⊂ R 3 . In particular, Figure <ref type="figure" target="#fig_7">9</ref>(a) is a bar plot of the 50 largest eigenvalues of S clean with N = 1000 and clearly shows numerical multiplicities of 3, 7, 11, . . . corresponding to the multiplicity 2l + 1 (l = 1, 3, 5, . . . ) of the odd spherical harmonics. Moreover, Figure <ref type="figure" target="#fig_7">9</ref>(b) is a bar plot of the magnitude of the most negative eigenvalues of S. The multiplicities 5, 9, 13, . . . corresponding to the multiplicity 2l + 1 (l = 2, 4, 6, . . . ) of the even spherical harmonics are evident (the first even eigenvalue corresponding to l = 0 is missing).</p><p>The numerically observed multiplicities motivate us to examine S clean in more detail. To that end, it is more convenient to reshuffle the 2N × 2N matrix S defined in (3.1)-(3.2) into an N × N matrix K whose entries are 2 × 2 rank-1 matrices given by (6.1)</p><formula xml:id="formula_40">K ij = x ij x ji x ij y ji y ij x ji y ij y ji = 1 0 0 0 1 0 c ij c T ji 1 0 0 0 1 0 T , i,j = 1, . . . , N,</formula><p>with c ij and c ji given in (2.4)-(2.5). From (2.6) it follows that the common line is given by the normalized cross product of R 3 i and R 3 j , that is,  and R 3 j must be given by either</p><formula xml:id="formula_41">(6.2) R i c ij = R j c ji = ± R 3 i × R 3 j R 3 i × R 3 j , because R i c ij is a linear combination of R 1 i and R 2 i (perpendicular to R 3 i ), while R j c ji is a linear combination of R 1 j and</formula><formula xml:id="formula_42">R 3 i ×R 3 j R 3 i ×R 3 j or - R 3 i ×R 3 j R 3 i ×R 3 j</formula><p>. Equations (6.1)-( <ref type="formula">6</ref>.2) imply that K ij is a function of R i and R j given by (6.3)</p><formula xml:id="formula_43">K ij = K(R i , R j ) = 1 0 0 0 1 0 R -1 i (R 3 i × R 3 j )(R 3 i × R 3 j ) T R 3 i × R 3 j 2 R j 1 0 0 0 1 0 T ,</formula><p>for i = j regardless of the choice of the sign in (6.2), and K ii = 0 0 0 0 . The eigenvalues of K and S are the same, with the eigenvectors of K being vectors of length 2N obtained from the eigenvectors of S by reshuffling their entries. We therefore try to understand the operation of matrix-vector multiplication of K with some arbitrary vector f of length 2N . It is convenient to view the vector f as N vectors in R 2 obtained by sampling the function f : SO(3) → R 2 at R 1 , . . . , R N , that is, (6.4)</p><formula xml:id="formula_44">f i = f (R i ), i = 1, . . . , N.</formula><p>The matrix-vector multiplication is thus given by (6.5)</p><formula xml:id="formula_45">(Kf ) i = N j=1 K ij f j = N j=1 K(R i , R j )f (R j ), i = 1, . . . , N.</formula><p>If the rotations R 1 , . . . , R N are i.i.d. random variables uniformly distributed over SO(3), then the expected value of (Kf</p><formula xml:id="formula_46">) i conditioned on R i is (6.6) E [(Kf ) i | R i ] = (N -1) SO(3) K(R i , R)f (R) dR,</formula><p>where dR is the Haar measure (recall that by being a zero matrix, K(R i , R i ) does not contribute to the sum in (6.5)). </p><formula xml:id="formula_47">K(R 1 , R 2 )f (R 2 ) dR 2 ,</formula><p>due to the law of large numbers, with the kernel K : SO(3) × SO(3) → R 2×2 given by (6.3). We are thus interested in the eigenfunctions of the integral operator K given by (6.7).</p><p>The integral operator K is a convolution operator over SO <ref type="bibr" target="#b2">(3)</ref>. Indeed, note that K given in (6.3) satisfies (6.8)</p><formula xml:id="formula_48">K(gR 1 , gR 2 ) = K(R 1 , R 2 ) for all g ∈ SO(3), because (gR 3 1 ) × (gR 3 2 ) = g(R 3 1 × R 3 2</formula><p>) and gg -1 = g -1 g = I. It follows that the kernel K depends only upon the "ratio" R -1</p><p>1 R 2 , because we can choose g = R -1 1 so that</p><formula xml:id="formula_49">K(R 1 , R 2 ) = K(I, R -1 1 R 2 ),</formula><p>and the integral operator K of (6.7) becomes (6.9)</p><formula xml:id="formula_50">(Kf )(R 1 ) = SO(3) K(I, R -1 1 R 2 )f (R 2 ) dR 2 .</formula><p>We will therefore define the convolution kernel K : SO(3) → R 2×2 as (6.10) K(U -1 ) ≡ K(I, U ) = 1 0 0 0 1 0</p><formula xml:id="formula_51">(I 3 × U 3 )(I 3 × U 3 ) T I 3 × U 3 2 U 1 0 0 0 1 0 T ,</formula><p>where I 3 = (0 0 1) T is the third column of the identity matrix I. We rewrite the integral operator K from (6.7) in terms of K as</p><formula xml:id="formula_52">(6.11) (Kf )(R 1 ) = SO(3) K(R -1 2 R 1 )f (R 2 ) dR 2 = SO(3) K(U )f (R 1 U -1 ) dU,</formula><p>where we used the change of variables U = R -1 2 R 1 . Equation (6.11) implies that K is a convolution operator over SO <ref type="bibr" target="#b2">(3)</ref> given by <ref type="bibr">[33, p. 158]</ref> (6.12)</p><formula xml:id="formula_53">Kf = K * f.</formula><p>Similar to the convolution theorem for functions over the real line, the Fourier transform of a convolution over SO <ref type="bibr" target="#b2">(3)</ref> is the product of their Fourier transforms, where the Fourier transform is defined by a complete system of irreducible matrix-valued representations of SO(3) (see, e.g., <ref type="bibr" target="#b32">[33,</ref><ref type="bibr">Theorem (4.14)</ref>, p. 159]). Let ρ θ ∈ SO(3) be a rotation by the angle θ around the z-axis, and let ρθ ∈ SO(2) be a planar rotation by the same angle:</p><formula xml:id="formula_54">ρ θ = ⎛ ⎝ cos θ -sin θ 0 sin θ cos θ 0 0 0 1 ⎞ ⎠ , ρθ = cos θ -sin θ sin θ cos θ .</formula><p>The kernel K satisfies the invariance property (6.13) K((ρ θ Uρ α ) -1 ) = ρθ K(U -1 )ρ α for all θ, α ∈ [0, 2π).</p><p>To that end, we first observe that ρ θ I 3 = I 3 and (Uρ α ) 3 = U 3 , so (6.14)</p><formula xml:id="formula_55">I 3 × (ρ θ Uρ α ) 3 = (ρ θ I 3 ) × (ρ θ Uρ α ) 3 = ρ θ (I 3 × (Uρ α ) 3 ) = ρ θ (I 3 × U 3 ),</formula><p>from which it follows that (6.15)</p><formula xml:id="formula_56">I 3 × (ρ θ Uρ α ) 3 = ρ θ (I 3 × U 3 ) = I 3 × U 3 ,</formula><p>because ρ θ preserves length, and it also follows that (6.16)</p><formula xml:id="formula_57">(I 3 × (ρ θ Uρ α ) 3 )(I 3 × (ρ θ Uρ α ) 3 ) T = ρ θ (I 3 × U 3 )(I 3 × U 3 ) T ρ -1 θ .</formula><p>Combining (6.15) and (6.16) yields (6.17</p><formula xml:id="formula_58">) (I 3 × (ρ θ Uρ α ) 3 )(I 3 × (ρ θ Uρ α ) 3 ) T I 3 × (ρ θ Uρ α ) 3 2 ρ θ Uρ α = ρ θ (I 3 × U 3 )(I 3 × U 3 ) T I 3 × U 3 2 Uρ α ,</formula><p>which together with the definition of K in (6.10) demonstrates the invariance property (6.13).</p><p>The fact that K is a convolution satisfying the invariance property (6.13) implies that the eigenfunctions of K are related to the spherical harmonics. This relation, as well as the exact computation of the eigenvalues, will be established in a separate publication <ref type="bibr" target="#b33">[34]</ref>. We note that the spectrum of K would have been much easier to compute if the normalization factor I 3 × U 3 2 did not appear in the kernel function K of (6.10). Indeed, in such a case, K would have been a third order polynomial, and all eigenvalues corresponding to higher order representations would have vanished.</p><p>We note that (6.6) implies that the top eigenvalue of S clean , denoted λ 1 (S clean ), scales linearly with N ; that is, with high probability, <ref type="bibr">(6.18</ref>)</p><formula xml:id="formula_59">λ 1 (S clean ) = Nλ 1 (K) + O( √ N ),</formula><p>where the O( √ N ) term is the standard deviation of the sum in (6.5). Moreover, from the top eigenvalues observed in Figures <ref type="figure">3(a</ref> We calculate λ 1 (K) analytically by showing that the three columns of (6.20)</p><formula xml:id="formula_60">f (U ) = 1 0 0 0 1 0 U -1</formula><p>are eigenfunctions of K. Notice that since U -1 = U T , f (U ) is equal to the first two columns of the rotation matrix U . This means, in particular, that U can be recovered from f (U ). Since the eigenvectors of S, as computed by our algorithm <ref type="bibr">(3.6)</ref>, are discrete approximations of the eigenfunctions of K, it is possible to use the three eigenvectors of S that correspond to the three eigenfunctions of K given by f (U ) to recover the unknown rotation matrices. We now verify that the columns f (U ) are eigenfunctions of K. Plugging (6.20) into (6.11) and employing (6.10) give</p><formula xml:id="formula_61">(6.21) (Kf )(R) = SO(3) 1 0 0 0 1 0 (I 3 × U 3 )(I 3 × U 3 ) T I 3 × U 3 2 U ⎛ ⎝ 1 0 0 0 1 0 0 0 0 ⎞ ⎠ U -1 R -1 dU.</formula><p>From UU -1 = I it follows that</p><formula xml:id="formula_62">(6.22) U ⎛ ⎝ 1 0 0 0 1 0 0 0 0 ⎞ ⎠ U -1 = UIU -1 -U ⎛ ⎝ 0 0 0 0 0 0 0 0 1 ⎞ ⎠ U -1 = I -U 3 U 3 T .</formula><p>Combining <ref type="bibr">(6.22)</ref> with the fact that (I 3 × U 3 ) T U 3 = 0, we obtain (6.23)</p><formula xml:id="formula_63">(I 3 × U 3 )(I 3 × U 3 ) T I 3 × U 3 2 U ⎛ ⎝ 1 0 0 0 1 0 0 0 0 ⎞ ⎠ U -1 = (I 3 × U 3 )(I 3 × U 3 ) T I 3 × U 3 2 .</formula><p>Letting U 3 = (x y z) T , the cross product I 3 × U 3 is given by (6.24)</p><formula xml:id="formula_64">I 3 × U 3 = (-y x 0) T ,</formula><p>whose squared norm is (6.25)</p><formula xml:id="formula_65">I 3 × U 3 2 = x 2 + y 2 = 1 -z 2 ,</formula><p>and (6.26)</p><formula xml:id="formula_66">(I 3 × U 3 )(I 3 × U 3 ) T = ⎛ ⎝ y 2 -xy 0 -xy x 2 0 0 0 0 ⎞ ⎠ .</formula><p>It follows from (6.21) and identities (6.23)-(6.26) that</p><formula xml:id="formula_67">(6.27) (Kf )(R) = SO(3) 1 1 -z 2 y 2 -xy 0 -xy x 2 0 dU R -1 .</formula><p>Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p><p>The integrand in (6.27) is only a function of the axis of rotation U 3 . The integral over SO(3) therefore collapses to an integral over the unit sphere S 2 with the uniform measure dμ (satisfying S 2 dμ = 1) given by (6.28)</p><formula xml:id="formula_68">(Kf )(R) = S 2 1 1 -z 2 y 2 -xy 0 -xy x 2 0 dμR -1 .</formula><p>From symmetry it follows that S 2 xy 1-z 2 dμ = 0 and that S 2</p><formula xml:id="formula_69">x 2 1-z 2 dμ = S 2 y 2 1-z 2 dμ. As x 2 1-z 2 + y 2 1-z 2 = 1 on the sphere, we conclude that S 2 x 2 1-z 2 dμ = S 2 y 2 1-z 2 dμ = 1 2 and (6.29) (Kf )(R) = 1 2 1 0 0 0 1 0 R -1 = 1 2 f (R).</formula><p>This shows that the three functions defined by (6.20), which are the same as those defined in (3.6), are the three eigenfunctions of K with the corresponding eigenvalue λ 1 (K) = 1 2 , as was speculated before in (6.19) based on the numerical evidence.</p><p>The remaining spectrum is analyzed in <ref type="bibr" target="#b33">[34]</ref>, where it is shown that the eigenvalues of K are <ref type="bibr">(6.30)</ref> λ l (K) = (-1) l+1 l(l + 1) , with multiplicities 2l + 1 for l = 1, 2, 3, . . . . An explicit expression for all eigenfunctions is also given in <ref type="bibr" target="#b33">[34]</ref>. In particular, the spectral gap between the top eigenvalue λ 1 (K) = 1 2 and the next largest eigenvalue λ 3 (K) = 1  12 is (6.31)</p><formula xml:id="formula_70">Δ(K) = λ 1 (K) -λ 3 (K) = 5 12<label>.</label></formula><p>7. Wigner's semicircle law and the threshold probability. As indicated by the numerical experiments of section 5, false detections of common lines due to noise lead to the emergence of what seems to be Wigner's semicircle for the distribution of the eigenvalues of S. In this section we provide a simple mathematical explanation for this phenomenon.</p><p>Consider the simplified probabilistic model of section 5.1 that assumes that every common line is detected correctly with probability p, independently of all other common lines, and that with probability 1p the common lines are falsely detected and are uniformly distributed over the unit circle. The expected value of the noisy matrix S, whose entries are correct with probability p, is given by <ref type="bibr">(</ref> </p><formula xml:id="formula_71">W ij = (1 -p)S clean ij with probability p, -pS clean ij + X ij X ji with probability 1 -p,</formula><p>where X ij and X ji are two independent random variables obtained by projecting two independent random vectors uniformly distributed on the unit circle onto the x-axis. For small values of p, the variance of W ij is dominated by the variance of the term X ij X ji . Symmetry implies that EX 2 ij = EX 2 ji = 1 2 , from which we have that</p><formula xml:id="formula_72">(7.4) EW 2 ij = EX 2 ij X 2 ji + O(p) = 1 4 + O(p).</formula><p>Wigner <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref> showed that the limiting distribution of the eigenvalues of random n × n symmetric matrices (scaled down by √ n), whose entries are i.i.d. symmetric random variables with variance σ 2 and bounded higher moments, is a semicircle whose support is the symmetric interval <ref type="bibr">[-2σ, 2σ</ref>]. This result applies to our matrix W with n = 2N and σ = </p><formula xml:id="formula_73">√ n = √ 2N (1 + O(p)).</formula><p>It is known that λ 1 (R) is concentrated near that value <ref type="bibr" target="#b34">[35]</ref>; that is, the fluctuations are small. Moreover, the universality of the edge of the spectrum <ref type="bibr" target="#b35">[36]</ref> implies that λ 1 (W ) follows the Tracy-Widom distribution <ref type="bibr" target="#b36">[37]</ref>. For our purposes, the leading order approximation</p><formula xml:id="formula_74">(7.5) λ 1 (W ) ≈ √ 2N</formula><p>suffices, with the probabilistic error bound given in <ref type="bibr" target="#b34">[35]</ref>.</p><p>The eigenvalues of W are therefore distributed according to Wigner's semicircle law whose support, up to small O(p) terms and finite sample fluctuations, is [-√ 2N, √ 2N ]. This prediction is in full agreement with the numerically observed supports in Figure <ref type="figure">3</ref>  72. The agreement is striking especially for Figures <ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure">7</ref>that were obtained from simulated noisy projections without imposing the artificial probabilistic model of section 5.1 that was used here to actually derive <ref type="bibr">(7.5)</ref>.</p><p>The threshold probability p c depends on the spectral gap of S clean , denoted Δ(S clean ), and on the top eigenvalue λ 1 (W ) of W . From (6.31) it follows that</p><formula xml:id="formula_75">(7.6) Δ(S clean ) = 5 12 N + O( √ N ).</formula><p>In <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref> it is proved that the top eigenvalue of the matrix A + W , composed of a rank-1 matrix A and a random matrix W , will be pushed away from the semicircle with high probability if the condition</p><formula xml:id="formula_76">(7.7) λ 1 (A) &gt; 1 2 λ 1 (W )</formula><p>is satisfied. Clearly, for matrices A that are not necessarily of rank-1, the condition (7.7) can be replaced by</p><formula xml:id="formula_77">(7.8) Δ(A) &gt; 1 2 λ 1 (W ),</formula><p>where Δ(A) is the spectral gap. Therefore, the condition</p><formula xml:id="formula_78">(7.9) pΔ(S clean ) &gt; 1 2 λ 1 (W )</formula><p>guarantees that the top three eigenvalues of S will reside away from the semicircle. Substituting (7.5) and (7.6) in (7.9) results in (7.10)</p><formula xml:id="formula_79">p 5 12 N + O( √ N ) &gt; 1 2 √ 2N (1 + O(p)),</formula><p>from which it follows that the threshold probability p c is given by (7.11)</p><formula xml:id="formula_80">p c = 6 √ 2 5 √ N + O(N -1 ).</formula><p>For example, the threshold probabilities predicted for N = 100, N = 500, and N = 1000 are p c ≈ 0.17, p c ≈ 0.076, and p c ≈ 0.054, respectively. These values match the numerical results of section 5.1 and are also in good agreement with the numerical experiments for the noisy projections presented in section 5.2.</p><p>From the perspective of information theory, the threshold probability (7.11) is nearly optimal. To that end, notice that to estimate N rotations to a given finite precision requires O(N ) bits of information. For p 1, the common line between a pair of images provides O(p 2 ) bits of information (see [41, section 5, eq. (82)]). Since there are N (N -1)/2 pairs of common lines, the entropy of the rotations cannot decrease by more than O(p 2 N 2 ). Comparing p 2 N 2 to N , we conclude that the threshold probability p c of any recovery method cannot be lower than O( 1 √ N ). The last statement can be made precise by Fano's inequality and Wolfowitz's converse, also known as the weak and strong converse theorems to the coding theorem that provide a lower bound for the probability of the error in terms of the conditional entropy (see, e.g., <ref type="bibr" target="#b41">[42,</ref><ref type="bibr">Chapter 8.9,</ref> and <ref type="bibr" target="#b42">[43,</ref><ref type="bibr">Chapter 5.8,</ref>). This demonstrates the near-optimality of our eigenvector method, and we refer the reader to section 5 in <ref type="bibr" target="#b40">[41]</ref> for a complete discussion about the information theory aspects of this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Summary and discussion.</head><p>In this paper we presented efficient methods for computing the rotations of all cryo-EM particles from common-line information in a globally consistent way. Our algorithms, one based on a spectral method (computation of eigenvectors), and the other based on SDP (a version of max-cut), are able to find the correct set of rotations even at very low common-line detection rates. Using random matrix theory and spectral analysis on SO(3), we showed that rotations obtained by the eigenvector method can lead to a meaningful ab initio model as long as the proportion of correctly detected common lines exceeds 6 √ 2 5 √ N (assuming a simplified probabilistic model for the errors). It remains to Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php be seen how these algorithms will perform on real raw projection images or on their class averages, and to compare their performance to the recently proposed voting recovery algorithm <ref type="bibr" target="#b18">[19]</ref>, whose usefulness has already been demonstrated on real datasets. Although the voting algorithm and the methods presented here try to solve the same problem, the methods and their underlying mathematical theory are different. While the voting procedure is based on a Bayesian approach and is probabilistic in its nature, the approach here is analytical and is based on spectral analysis of convolution operators over SO <ref type="bibr" target="#b2">(3)</ref> and random matrix theory.</p><p>The algorithms presented here can be regarded as a continuation of the general methodology initiated in <ref type="bibr" target="#b40">[41]</ref>, where we showed how the problem of estimating a set of angles from their noisy offset measurements can be solved using either eigenvectors or SDP. Notice, however, that the problem considered here of recovering a set of rotations from common-line measurements between their corresponding images is different and more involved mathematically than the angular synchronization problem that is considered in <ref type="bibr" target="#b40">[41]</ref>. Specifically, the commonline-measurement between two projection images P i and P j provides only partial information about the ratio R -1 i R j . Indeed, the common line between two images determines only two out of the three Euler angles (the missing third degree of freedom can be determined only by a third image). The success of the algorithms presented here shows that it is also possible to integrate all the partial offset measurements between all rotations in a globally consistent way that is robust to noise. Although the algorithms presented in this paper and in <ref type="bibr" target="#b40">[41]</ref> seem to be quite similar, the underlying mathematical foundation of the eigenvector algorithm presented here is different, as it crucially relies on the spectral properties of the convolution operator over SO <ref type="bibr" target="#b2">(3)</ref>.</p><p>We would like to point out two possible extensions of our algorithms. First, it is possible to include confidence information about the common lines. Specifically, the normalized correlation value of the common line is an indication for its likelihood of being correctly identified. In other words, common lines with higher normalized correlations have a better chance of being correct. We can therefore associate a weight w ij with the common line between P i and P j to indicate our confidence in it, and multiply the corresponding 2 × 2 rank-1 submatrix of S by this weight. This extension gives only a little improvement in terms of the MSE as seen in our experiments, which will be reported elsewhere. Another possible extension is to include multiple hypotheses about the common line between two projections. This can be done by replacing the 2 × 2 rank-1 matrix associated with the top common line between P i and P j by a weighted average of such 2 × 2 rank-1 matrices corresponding to the different hypotheses. On the one hand, this extension should benefit from the fact that the probability that one of the hypotheses is the correct one is larger than that of just the common line with the top correlation. On the other hand, since at most one hypothesis can be correct, all hypotheses except maybe one are incorrect, and this leads to an increase in the variance of the random Wigner matrix. Therefore, we often find the single hypothesis version favorable compared to the multiple hypotheses version. The corresponding random matrix theory analysis and the supporting numerical experiments will be reported in a separate publication.</p><p>Finally, we note that the techniques and analysis applied here to solve the cryo-EM problem can be translated to the computer vision problem of structure from motion, where lines perpendicular to the epipolar lines play the role of the common lines. This particular application will be the subject of a separate publication.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Fourier projection-slice theorem and common lines.</figDesc><graphic coords="6,148.11,218.10,76.78,76.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 Figure 3 .</head><label>33</label><figDesc>Figure 3. Eigenvalue histograms for the matrix S for different values of N and p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 F,</head><label>2</label><figDesc>Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>SNR=1/16 (g) SNR=1/32 (h) SNR=1/64 (i) SNR=1/128 (j) SNR=1/256</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Simulated projection with various levels of additive Gaussian white noise.</figDesc><graphic coords="15,145.32,334.41,58.24,58.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .Figure 6 .Figure 7 .</head><label>567</label><figDesc>Figure 5. Eigenvalue histograms of S for N = 100 and different levels of noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Reconstruction from N = 1000 noisy projections at various SNR levels using the eigenvector method. Left column: reconstructions generated from noisy projections and orientations estimated using the eigenvector method. Middle-left column: reconstructions generated from noisy projections and orientations estimated using the SDP method. Middle-right column: reconstructions from noisy projections and the true orientations. Right column: reconstructions from estimated orientations (using the eigenvector method) and clean projections.</figDesc><graphic coords="19,162.06,469.32,71.92,56.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Bar plot of the positive (left) and the absolute values of the negative (right) eigenvalues of S with N = 1000 and p = 1. The numerical multiplicities 2l + 1 (l = 1, 2, 3, . . . ) of the spherical harmonics are evident, with odd l values corresponding to positive eigenvalues, and even l values (except l = 0) corresponding to negative eigenvalues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 ,</head><label>2</label><figDesc>), 3(e), 5(a), 6(a), and 7(a) corresponding to p = 1 and p values close to 1, it is safe to speculate that (6.<ref type="bibr" target="#b18">19</ref>)λ 1 (K) = 1as the top eigenvalues are approximately 50, 250, and 500 for N = 100, 500, and 1000, respectively.Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>and in Figures 5-7, noting that for N = 100 the right edge of the support is located near √ 200 ≈ 14.14, for N = 500 near √ 1000 ≈ 31.62, and for N = 1000 near √ 2000 ≈ 44.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and S 22 are symmetric matrices (S 11 = S 11 T and S 22 = S 22 T ), while S 12 = S 21 T . It follows that the 2N × 2N matrix S given by</figDesc><table><row><cell>(3.2)</cell><cell>S =</cell><cell>S 11 S 12 S 21 S 22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>trace(SG).</figDesc><table><row><cell></cell><cell cols="3">A natural relaxation of the optimization problem (2.9) is thus given by the SDP</cell></row><row><cell></cell><cell>(4.8)</cell><cell>max G∈R 2N×2N</cell><cell>trace(SG)</cell></row><row><cell>Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</cell><cell>(4.9)</cell><cell cols="2">subject to G 0,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>The MSE of the eigenvector and SDP methods for N = 100 (left) and N = 500 (right) and different values of p.</figDesc><table><row><cell></cell><cell cols="2">(a) N = 100</cell><cell></cell><cell cols="2">(b) N = 500</cell></row><row><cell>p</cell><cell cols="2">MSE(eig) MSE(sdp)</cell><cell>p</cell><cell cols="2">MSE(eig) MSE(sdp)</cell></row><row><cell>1</cell><cell>0.0055</cell><cell>4.8425e-05</cell><cell>1</cell><cell>0.0019</cell><cell>1.0169e-05</cell></row><row><cell>0.5</cell><cell>0.0841</cell><cell>0.0676</cell><cell>0.5</cell><cell>0.0166</cell><cell>0.0143</cell></row><row><cell>0.25</cell><cell>0.7189</cell><cell>0.7140</cell><cell>0.25</cell><cell>0.0973</cell><cell>0.0911</cell></row><row><cell>0.15</cell><cell>2.8772</cell><cell>2.8305</cell><cell>0.15</cell><cell>0.3537</cell><cell>0.3298</cell></row><row><cell>0.1</cell><cell>4.5866</cell><cell>4.7814</cell><cell>0.1</cell><cell>1.2739</cell><cell>1.1185</cell></row><row><cell>0.05</cell><cell>4.8029</cell><cell>5.1809</cell><cell>0.05</cell><cell>5.4371</cell><cell>5.3568</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>The proportion p of correctly detected common lines as a function of the SNR. As expected, p is not a function of the number of images N .</figDesc><table><row><cell cols="2">(a) N = 100</cell><cell cols="2">(b) N = 500</cell><cell cols="2">(c) N = 1000</cell></row><row><cell>SNR</cell><cell>p</cell><cell>SNR</cell><cell>p</cell><cell>SNR</cell><cell>p</cell></row><row><cell>clean</cell><cell>0.997</cell><cell>clean</cell><cell>0.997</cell><cell>clean</cell><cell>0.997</cell></row><row><cell>1</cell><cell>0.968</cell><cell>1</cell><cell>0.967</cell><cell>1</cell><cell>0.966</cell></row><row><cell>1/2</cell><cell>0.930</cell><cell>1/2</cell><cell>0.922</cell><cell>1/2</cell><cell>0.919</cell></row><row><cell>1/4</cell><cell>0.828</cell><cell>1/4</cell><cell>0.817</cell><cell>1/4</cell><cell>0.813</cell></row><row><cell>1/8</cell><cell>0.653</cell><cell>1/8</cell><cell>0.639</cell><cell>1/8</cell><cell>0.638</cell></row><row><cell>1/16</cell><cell>0.444</cell><cell>1/16</cell><cell>0.433</cell><cell>1/16</cell><cell>0.437</cell></row><row><cell>1/32</cell><cell>0.247</cell><cell>1/32</cell><cell>0.248</cell><cell>1/32</cell><cell>0.252</cell></row><row><cell>1/64</cell><cell>0.108</cell><cell>1/64</cell><cell>0.113</cell><cell>1/64</cell><cell>0.115</cell></row><row><cell cols="2">1/128 0.046</cell><cell cols="2">1/128 0.046</cell><cell cols="2">1/128 0.047</cell></row><row><cell cols="2">1/256 0.023</cell><cell cols="2">1/256 0.023</cell><cell cols="2">1/256 0.023</cell></row><row><cell cols="2">1/512 0.017</cell><cell cols="2">1/512 0.015</cell><cell cols="2">1/512 0.015</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>The MSE of the eigenvector and SDP methods for N = 100, N = 500, and N = 1000.</figDesc><table><row><cell></cell><cell cols="2">(a) N = 100</cell><cell></cell><cell></cell><cell cols="2">(b) N = 500</cell></row><row><cell>SNR</cell><cell cols="2">MSE(eig) MSE(sdp)</cell><cell></cell><cell>SNR</cell><cell cols="2">MSE(eig) MSE(sdp)</cell></row><row><cell>1</cell><cell>0.0054</cell><cell>3.3227e-04</cell><cell></cell><cell>1</cell><cell>0.0023</cell><cell>2.4543e-04</cell></row><row><cell>1/2</cell><cell>0.0068</cell><cell>0.0016</cell><cell></cell><cell>1/2</cell><cell>0.0030</cell><cell>0.0011</cell></row><row><cell>1/4</cell><cell>0.0129</cell><cell>0.0097</cell><cell></cell><cell>1/4</cell><cell>0.0069</cell><cell>0.0071</cell></row><row><cell>1/8</cell><cell>0.0276</cell><cell>0.0471</cell><cell></cell><cell>1/8</cell><cell>0.0203</cell><cell>0.0414</cell></row><row><cell>1/16</cell><cell>0.0733</cell><cell>0.1951</cell><cell></cell><cell>1/16</cell><cell>0.0563</cell><cell>0.1844</cell></row><row><cell>1/32</cell><cell>0.2401</cell><cell>0.6035</cell><cell></cell><cell>1/32</cell><cell>0.1859</cell><cell>0.6759</cell></row><row><cell>1/64</cell><cell>2.5761</cell><cell>1.9509</cell><cell></cell><cell>1/64</cell><cell>1.7549</cell><cell>1.3668</cell></row><row><cell>1/128</cell><cell>3.2014</cell><cell>3.1020</cell><cell></cell><cell>1/128</cell><cell>2.6214</cell><cell>2.4046</cell></row><row><cell>1/256</cell><cell>4.0974</cell><cell>4.1163</cell><cell></cell><cell>1/256</cell><cell>3.4789</cell><cell>3.3539</cell></row><row><cell>1/512</cell><cell>4.9664</cell><cell>4.9702</cell><cell></cell><cell>1/512</cell><cell>4.6027</cell><cell>4.5089</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(c) N = 1000</cell><cell></cell></row><row><cell></cell><cell></cell><cell>SNR</cell><cell cols="3">MSE(eig) MSE(sdp)</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>0.0018</cell><cell cols="2">2.3827e-04</cell></row><row><cell></cell><cell></cell><cell>1/2</cell><cell>0.0030</cell><cell cols="2">0.0011</cell></row><row><cell></cell><cell></cell><cell>1/4</cell><cell>0.0072</cell><cell cols="2">0.0067</cell></row><row><cell></cell><cell></cell><cell>1/8</cell><cell>0.0208</cell><cell cols="2">0.0406</cell></row><row><cell></cell><cell></cell><cell>1/16</cell><cell>0.0582</cell><cell cols="2">0.1899</cell></row><row><cell></cell><cell></cell><cell>1/32</cell><cell>0.1996</cell><cell cols="2">0.7077</cell></row><row><cell></cell><cell></cell><cell>1/64</cell><cell>1.7988</cell><cell cols="2">1.5370</cell></row><row><cell></cell><cell></cell><cell>1/128</cell><cell>2.5159</cell><cell cols="2">2.3243</cell></row><row><cell></cell><cell></cell><cell>1/256</cell><cell>3.5160</cell><cell cols="2">3.4365</cell></row><row><cell></cell><cell></cell><cell>1/512</cell><cell>4.6434</cell><cell cols="2">4.6013</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>The eigenvectors of K are therefore discrete approximations to Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc><table><row><cell cols="2">the eigenfunctions of the integral operator K given by</cell></row><row><cell>(6.7)</cell><cell>(Kf )(R 1 ) =</cell></row><row><cell></cell><cell>SO(3)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Downloaded 01/02/13 to 128.148.252.35. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We are indebted to Fred Sigworth and Ronald Coifman for introducing us to the cryo-electron microscopy problem and for many stimulating discussions. We would like to thank Ronny Hadani, Ronen Basri, and Boaz Nadler for many valuable discussions on representation theory, computer vision, and random matrix theory. We also thank Lanhui Wang for conducting some of the numerical simulations.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>electronically June 7, 2011. This work was partially supported by award R01GM090200 from the National Institute of General Medical Sciences and by award 485/10 from the Israel Science Foundation. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institute of General Medical Sciences or the National Institutes of Health.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Three-Dimensional Electron Microscopy of Macromolecular Assemblies: Visualization of Biological Molecules in Their Native State</title>
		<author>
			<persName><forename type="first">J</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cryo-EM and single particles</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Sigworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiology (Bethesda)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="13" to="18" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Realizing the potential of electron cryo-microscopy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Q. Rev. Biophys</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">De novo backbone trace of GroEL from single particle electron cryomicroscopy</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Ludtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structure</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="441" to="448" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Near-atomic resolution using electron cryomicroscopy and single-particle reconstruction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Settembre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Dormitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bellamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Grigorieff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="1867" to="1872" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Electron cryomicroscopy of biological machines at subnanometer resolution</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dougherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structure</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="363" to="372" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Three-dimensional reconstruction from a single-exposure, random conical tilt series applied to the 50S ribosomal subunit of Escherichia coli</title>
		<author>
			<persName><forename type="first">M</forename><surname>Radermacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagenknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Verschoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Microsc</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="113" to="136" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Three-dimensional structure of the large subunit from Escherichia coli</title>
		<author>
			<persName><forename type="first">M</forename><surname>Radermacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagenknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Verschoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMBO J</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1107" to="1114" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A method of general moments for orienting 2D projections of unknown 3D objects, Comput. Vision Graphics Image Process</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Salzman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="129" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Integral geometry and three-dimensional reconstruction of randomly oriented identical particles from their electron microphotos</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Goncharov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Appl. Math</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="199" to="211" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The ribosome at improved resolution: New techniques for merging and orientation refinement in 3D cryo-electron microscopy of biological particles</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Penczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Grassucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ultramicroscopy</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="251" to="270" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Angular reconstitution: A posteriori assignment of projection directions for 3D reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Heel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ultramicroscopy</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="111" to="123" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Single-particle electron cryo-microscopy: Towards atomic resolution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Heel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gowen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Matadeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Orlova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schatz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Patwardhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Q. Rev. Biophys</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="307" to="369" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Determination of the spatial orientation of arbitrarily arranged identical particles of an unknown structure from their projections</title>
		<author>
			<persName><forename type="first">B</forename><surname>Vainshtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goncharov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Congress on Electron Mircoscopy</title>
		<meeting>the 11th International Congress on Electron Mircoscopy</meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="459" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Angular reconstitution in three-dimensional electron microscopy: Historical and theoretical aspects</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Heel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Orlova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Harauz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zemlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scanning Microscopy</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="195" to="210" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A posteriori determination of relative projection directions of arbitrarily oriented macromolecules</title>
		<author>
			<persName><forename type="first">M</forename><surname>Farrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ottensmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA A</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1749" to="1760" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A common-lines based method for determining orientations for N &gt; 3 particle projections simultaneously</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Penczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ultramicroscopy</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="205" to="218" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structure and view estimation for tomographic reconstruction: A Bayesian approach</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Mallick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carragher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="2253" to="2260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Detecting consistent common lines in cryo-EM by voting</title>
		<author>
			<persName><forename type="first">A</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Sigworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Chester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shkolnisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Struct. Biol</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="312" to="322" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reference free structure determination through eigenvectors of center of mass operators</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shkolnisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Sigworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Harmon. Anal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="296" to="312" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Uniqueness of tomography with unknown view angles</title>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bresler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1094" to="1106" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Feasibility of tomography with unknown view angles</title>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bresler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1107" to="1122" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Graph Laplacian tomography from unknown random projections</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shkolnisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Sigworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1891" to="1899" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semidefinite programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="49" to="95" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Goemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1115" to="1145" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><surname>Natterer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Mathematics of Computerized Tomography</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
	<note>SIAM, Philadelphia</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Least-squares fitting of two 3-D point sets</title>
		<author>
			<persName><forename type="first">K</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bolstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="698" to="700" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Characteristic vectors of bordered matrices with infinite dimensions</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Wigner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. of Math</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="548" to="564" />
			<date type="published" when="1955">1955. 1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the distribution of the roots of certain symmetric matrices</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Wigner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. of Math</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="325" to="327" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Burer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D C</forename><surname>Monteiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program. Ser. B</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="329" to="357" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">3D Fourier based discrete radon transform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Averbuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shkolnisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Harmon. Anal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="33" to="69" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A framework for discrete integral transformations I-The pseudo-polar Fourier transform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Averbuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Israeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shkolnisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="764" to="784" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Representations of compact groups and spherical harmonics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Enseignement Math</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="121" to="173" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Representation theoretic patterns in cryo electron microscopy I-The intrinsic reconstitution algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hadani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. of Math</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the concentration of eigenvalues of random symmetric matrices</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krivelevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Israel J. Math</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="259" to="267" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Universality at the edge of the spectrum in Wigner random matrices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Soshnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="697" to="733" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Level-spacing distributions and the Airy kernel</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Tracy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="151" to="174" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The largest eigenvalues of small rank perturbations of Hermitian random matrices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Péché</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Probab. Theory Related Fields</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="127" to="174" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The largest eigenvalue of rank one deformation of large Wigner matrices</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Péché</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">272</biblScope>
			<biblScope unit="page" from="185" to="228" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The eigenvalues of random symmetric matrices</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Füredi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komlós</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="233" to="241" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Angular synchronization by eigenvectors and semidefinite programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Harmon. Anal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="20" to="36" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Elements of Information Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
		<title level="m">Information Theory and Reliable Communication</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
