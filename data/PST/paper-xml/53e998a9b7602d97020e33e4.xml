<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">News Recommendation via Hypergraph Learning: Encapsulation of User Behavior and News Content</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Sciences</orgName>
								<orgName type="institution">Florida International University Miami</orgName>
								<address>
									<postCode>33199</postCode>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Tao</forename><surname>Li</surname></persName>
							<email>taoli@cs.fiu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computing and Information Sciences</orgName>
								<orgName type="institution">Florida International University Miami</orgName>
								<address>
									<postCode>33199</postCode>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">News Recommendation via Hypergraph Learning: Encapsulation of User Behavior and News Content</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F7F0FAD124E87A3546B7C57C8FC696E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3[Information Search and Retrieval]: Information filtering Algorithms</term>
					<term>Design</term>
					<term>Experimentation Personalization</term>
					<term>News Recommendation</term>
					<term>Hypergraph Learning</term>
					<term>Named Entity</term>
					<term>Transductive Inference</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Personalized news recommender systems have gained increasing attention in recent years. Within a news reading community, the implicit correlations among news readers, news articles, topics and named entities, e.g., what types of named entities in articles are preferred by users, and why users like the articles, could be valuable for building an effective news recommender. In this paper, we propose a novel news personalization framework by mining such correlations. We use hypergraph to model various high-order relations among different objects in news data, and formulate news recommendation as a ranking problem on fine-grained hypergraphs. In addition, by transductive inference, our proposed algorithm is capable of effectively handling the socalled cold-start problem. Extensive experiments on a data set collected from various news websites have demonstrated the effectiveness of our proposed algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Common research efforts in personalized news recommendation can be divided into two categories: (1)modeling user profiles by analyzing news content in users' consumption history and then retrieving relevant news articles for recommendation (content filtering); and (2)analyzing reading behaviors of users similar to the target user and then recommending items based on the collaborative activities (collaborative filtering). Many hybrid methods, which integrate the above two categories of algorithms, have also been developed. Despite extensive recent advances, several critical issues in news recommendation have not been well explored in previous studies, including user profiling (i.e., how to obtain high-quality user profiles from historical consumptions of users?), news evolving (i.e., how to recommend news items that are newly published and without enough accessing activities?) and user cold-start (i.e., how to provide reasonable recommendation for new users?) <ref type="bibr" target="#b21">[21]</ref>.</p><p>A key step in news recommender systems is to build the readers' preference profiles based on their historical consumption, i.e., the reading history. Traditionally, user profiling is conducted by extracting representative elements (e.g., words or phrases) from the reading history or selecting similar access patterns. However, users' historical consumption may contain a gigantic amount of element correlations, e.g., a group of users like the same topic, which cannot be well captured by the aforementioned profiling paradigms.</p><p>Further, online readers tend to prefer some named entities in news articles, e.g., when the event happened, where it happened, who were involved, etc. These types of entities can attract online readers' interest since they contain concise information about the news article itself. Therefore, named entities would be valuable to model users' preferences. However, few research efforts have been reported on utilizing named entities for user profiling. In <ref type="bibr" target="#b12">[12]</ref> and <ref type="bibr" target="#b20">[20]</ref>, named entities extracted from news articles are represented as an entity vector, and then the similarity based on such a vector is calculated for retrieving relevant news items. Such a representation might cause the information loss of news access data, e.g., what type of entities is preferred by a group of users, and therefore render user profiling less effective.</p><p>In our work, to address the aforementioned issues, we propose a novel news personalization algorithm by mining the implicit relations among users, news articles, topics and named entities. Motivated by <ref type="bibr" target="#b5">[5]</ref>, we use a unified hypergraph to model multi-type objects and implicit relations in news reading community. A hypergraph is a generalization of the ordinary graph, in which the edges, called hyperedges, are arbitrary non-empty subsets of the vertex set <ref type="bibr" target="#b4">[4]</ref>. However, due to the special properties of news articles (e.g., textual content, implicit relation and short shelf life), a straightforward extension of hypergraph modeling on music community cannot be directly applied to news recommendation. Instead, we first partition the hypergraph into multiple fine-grained ones, and further model personalized news recommendation as a ranking problem on fine-grained hypergraphs to recommend news articles.</p><p>To the best of our knowledge, our work is the first journey towards modeling implicit high-order correlations in news reading community via hypergraph, by considering the special properties of news articles and online readers' behaviors. The contribution of this paper is three-fold:</p><p>• A hypergraph representation of news reading community. We explore implicit correlations among readers, articles, topics and named entities, and represent these relations as a unified hypergraph, by which a user's reading behavior can be well captured (cf. §3.2).</p><p>• A principled framework for news selection. We partition the hypergraph into fine-grained ones, and then model the recommendation problem as a local selection problem on sub-hypergraphs, instead of global selection on the entire hypergraph (cf. §4.1 and §4.2).</p><p>• A novel strategy for solving "cold-start". We embrace new users into a specific sub-hypergraph, and then resolve cold-start using transductive inference on the hypergraph (cf. §4.3).</p><p>Roadmap: §2 presents a brief summary of prior work relevant to personalized news recommendation and hypergraph learning. In §3, we introduce the data model used in our work and formalize the problem. In §4, we discuss how to perform ranking and transductive inference on the hypergraph. Extensive experimental results are reported in §5, and finally §6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Content-based Methods</head><p>Content-based news recommenders construct user profiles based on news content, and recommend for users news articles similar to user profiles in content-wise <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b22">22]</ref>. The computational representation of news content is the cornerstone of content-based recommenders. In practice, news content is often represented by vector space model or topic models that are widely used in text mining. To calculate the relevance between news items and user profiles, different affinity measurements might be applied, depending on specific strategies of news recommenders. For example, Newsjunkie <ref type="bibr" target="#b12">[12]</ref> filters news stories by formal measures of information novelty to custom-tailor newsfeeds based on a user's reading history. <ref type="bibr" target="#b10">[10]</ref> tries to obtain users' reading interests from multiple news channels. However, it might be insufficient to simply represent users' profiles by a bag of words for capturing the reading preference of users <ref type="bibr" target="#b20">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Collaborative filtering</head><p>Collaborative filtering based news recommenders model users profiles by analyzing feedbacks of news readers, e.g., click on news articles, and then recommend news based on similar users' behaviors. Therefore, these news recommenders are content-free <ref type="bibr" target="#b9">[9]</ref>. Collaborative filtering can be roughly categorized into two groups: memory-based methods <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b26">26]</ref> (i.e., neighborhood-based recommendation) and model-based approaches <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b24">24]</ref> (i.e., latent factor based recommendation). Collaborative filtering assumes that the overlap historical consumptions between users exist; however, with the rapid change of both news repository and user repository, it suffers from the well-known cold-start problem <ref type="bibr" target="#b27">[27]</ref>, which renders collaborative filtering less effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Hybrid Approaches</head><p>To remedy the inability of both content filtering and collaborative filtering, many researchers investigate the feasibility of combining these two types of methods, and propose hybrid solutions to news recommendation. Representative examples include <ref type="bibr" target="#b6">[6,</ref><ref type="bibr">7]</ref>. Another extensively studied direction in recommendation community is hybrid filtering, which is similar to the problem in our work. Several recently published methods include <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b3">3,</ref><ref type="bibr" target="#b17">17]</ref>. However, most hybrid filtering methods either focus on analyzing explicit ratings in the data, or assume that demographic and other auxiliary information of users are available. Although it is possible to incorporate user behaviors into these methods, they still suffer from the difficulty of comprehensively capsuling highorder relations within news reading community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Hypergraph Learning</head><p>In machine learning problem settings, a typical representation of data is hypergraph, by which the information loss issue resulted from pairwise relationship among objects can be effectively remedied. Hypergraph can help resolve general learning problems, e.g., clustering <ref type="bibr" target="#b13">[13]</ref>, classification <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b30">30]</ref> and embedding <ref type="bibr" target="#b34">[34]</ref>. Hypergraph learning has been explored in various machine learning areas, such as gene expression classification <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b29">29]</ref>, image retrieval <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b31">31]</ref>, document analysis <ref type="bibr" target="#b18">[18]</ref>, etc.</p><p>Our work is essentially a graph-based hybrid recommendation approach. In <ref type="bibr" target="#b1">[1]</ref>, social interactions, e.g., comments by news readers, are modeled as a graph and news articles are filtered based on the content and interactions. However, their model failed to consider the implicit relations among news readers, news articles and named entities, which are essential for news recommendation.</p><p>What differentiates our work from prior methods is that we model personalized news recommendation as a hypergraph learning paradigm by integrating all implicit correlations among users, news items, topics and named entities into a unified hypergraph, and then recommending news articles via a hypergraph ranking algorithm. The way that we encapsule the data into a hypergraph is similar to <ref type="bibr" target="#b5">[5]</ref>, in which a music recommendation algorithm is proposed by considering the integration of multiple kinds of social media information and music acoustic-based content. However, the intrinsic characteristics of news recommendation render it different from music recommendation. The differences between these two tasks are summarized as follows:</p><p>• Content-wise: News content is composed of words, prone to be associated with topics, whereas music content consists of acoustic features, which are difficult to interpret and understand;</p><p>• Evolutionary: News community evolves much faster than music community due to the instantaneity of news articles, i.e., news articles have short shelf life;</p><p>• Relation-wise: The relations within news community are mostly implicit, while music community has multiple explicit relations.</p><p>Given these differences, the derived hypergraph from a news reading community would be much more complex than the one from a music sharing community. Simply applying the work in <ref type="bibr" target="#b5">[5]</ref> to news recommendation might suffer the scalability issue. Therefore, we propose to first partition the hypergraph into more fine-grained ones. Further, our proposed method has the capability of effectively handling the cold-start problem in recommendation scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DATA MODEL AND PROBLEM STATE-MENT</head><p>In this section we start by introducing our data model of news reading community and some basic notations, and then we formally state our exploration problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head><p>We follow the definitions in <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b34">34]</ref> to describe hypergraph preliminaries. We denote G(V, E, w) as a hypergraph, where V is a finite set of vertices, E is a family of hyperedges on V , and w is a weight function, w : E → R. Each hyperedge e ∈ E contains a list of vertices that belong to V . The degree of a hyperedge e is defined by δ(e) = |e|, i.e., the number of vertices in e. The degree d(v) of a vertex v is defined by d(v) = v∈e w(e), where w(e) is the weight of the hyperedge e. We say that there is a hyperpath between vertices v 1 and v k if there is an alternative sequence of distinct vertices and hyperedges v 1, e1, v2, e2, </p><formula xml:id="formula_0">• • • , e k-1 , v k , such that {v i, vi+1} ⊆ ei for 1 ≤ i ≤ k -1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Model</head><p>In news reading community, multiple types of resources are often available for analysis, including users, news articles, representative terms, named entities, etc. Let U denote the user pool, and N denote the set of news articles, both of which are the major elements being considered in recommender systems. Further, let T t denote the representative terms, or say, topics, and T e be the set of named entities involved in the entire news corpus. Notice that in reality, the pools of these four types of resources would be enlarged as there are always news events happening everyday with different topic categories and distinct named entities. In our data model, we name these resources as Media Objects. To facilitate the reading, we list some notations in Table <ref type="table" target="#tab_1">1</ref>. Besides, several relations among objects are implicitly embedded among media objects. For example, two users u 1, u2 ∈ U are the fans of NBA star LeBron James (t e i ∈ T e ), which is a named entity appearing in news articles of sports event (t t j ∈ T t ). Then there is an implicit relation among these media objects. In our data model, we formalize a hypergraph G that contains 7 different implicit relations with different objects<ref type="foot" target="#foot_0">1</ref> and 1 implicit relation that considers the similarity graph of news articles:</p><p>• E UNT t : A user reads a news article that describes an event, or a topic. Typically we assign the weight of this hyperedge to be 1. Here we assume that a user would only navigate a news item once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• E UNT e</head><p>: A user reads a news article that embraces a named entity. Similar to E UNT t , we assign the hyperedge weight as 1.</p><p>• E UUN : Two users might read the same news article.</p><p>We assign the hyperedge weight to be 1.</p><p>• E UUT t : Two users might read news articles with the same topic. The weight w(e u i u j t t k ) for this relation is set to be the frequency that both users, u i and uj, read articles with the same topic t t k , i.e.,</p><p>w(e</p><formula xml:id="formula_1">u i u j t t k ) = |{(ui, uj, t t k )|ui ∈ U, uj ∈ U, t t k ∈ T t }|.</formula><p>(1) We normalize the weight as</p><formula xml:id="formula_2">w(e u i u j t t k ) = w(e u i u j t t k ) |U| l=1 w(e u l u j t t k ) |U| m=1 w(e u i umt t k )</formula><p>.</p><p>(</p><formula xml:id="formula_3">)<label>2</label></formula><p>The above heuristic normalization aims to penalize the abnormal news readers with dense reading activities. Moreover, in order to treat different types of relations equally, we further normalize the weight as follows:</p><formula xml:id="formula_4">w(e u i u j t t k ) = w(e u i u j t t k ) ave(w(e u i u j T t )) , (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where ave(w(e u i u j T t )) is the average of normalized weights for users u i and uj on different topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• E UUT e</head><p>: Two users might read news articles containing the same named entity. The weight w(e u i u j t e k ) for this relation is set to be the frequency that both users, u i and uj, read articles containing the same entity t e k . The weight normalization is similar to Eq.( <ref type="formula" target="#formula_3">2</ref>) and Eq.(3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• E NNT t</head><p>: Two news articles might describe the same or similar topic. We assign the hyperedge weight as 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• E NNT e</head><p>: Two news articles might contain the same entity. We assign the hyperedge weight to be 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• E N k</head><p>: In our data model, we also consider the similarity of news articles. We construct a k nearest neighbor (k-NN) news graph based on content-based item similarities. In the hypergraph, a hyperedge of this type is composed of the top k articles similar to the target news item and the target item itself. The weight w(e n k i ) is the averaged similarity between the target news item and the ones similar to the target, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>w(e n</head><formula xml:id="formula_6">k i ) = 1 k k j=1 sim(ni, nj),<label>(4)</label></formula><p>where sim(ni, nj) is the similarity between two news articles. In our work, this similarity is calculated using the cosine similarity by considering the content features of news items. We introduce a parameter α to control the relative importance of content-based similarities in the unified hypergraph model. Then, the hyperedge weight is given by</p><formula xml:id="formula_7">w(e n k i ) = α * w(e n k i ).<label>(5)</label></formula><p>Finally, the unified hypergraph of news reading community is composed of 4 types of media objects as vertices and 8 types of object relations as hyperedges. Figure <ref type="figure" target="#fig_0">1</ref> summarizes the aforementioned media objects and relations. By employing the unified hypergraph model, we can effectively capture the high-order relations among various types of media objects without loss of any important information. Based on the data model introduced above, we can derive the vertex-hyperedge incidence matrix H (as described in Table <ref type="table" target="#tab_2">2</ref>) and also the weight matrix W. The size of both matrices depends on the cardinality of different element sets involved in the matrices, and they are all sparse matrices.</p><formula xml:id="formula_8">t E UNT e E UNT e E NNT UUN E e E UUT k E N t E NNT t E UUT</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Problem Statement</head><p>In this subsection, we first define the problem of personalized news recommendation, and then analyze the major technical issues for resolving the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROBLEM (Personalized News Recommendation):</head><p>Given a collection of newly-published news articles N and a target online reader u, recommend a list of news items S that maximally match u's reading preference.</p><p>It is straightforward to observe that the success of personalized news recommendation depends on two critical subproblems: user profiling and news personalization. The former aims at capturing online users' reading preference, whereas the latter tries to select news items to be optimally consistent to user's preference.</p><p>To facilitate user profiling, we define a concept of news capsule as follows:</p><formula xml:id="formula_9">Definition 1. (News Capsule). A news capsule, C = (V C , E C , w C ), is a subset of a given hypergraph G = (V, E, w), where V C = {U, N, T t , T e } ⊂ V = {U, N, T t , T e }, i.e., U ⊂ U, N ⊂ N, T t ⊂ T t , T e ⊂ T e , and E C ⊂ E, w C ⊂ w.</formula><p>A capsule C is said to be compact iff ∀u ∈ U , u's reading preference is maximally captured in C. To evaluate how well u's preference is captured, we formalize another definition. Definition 2. (Maximality). Given a user u and a news capsule C that u belongs to, u's reading preference is said to be maximally captured in C iff most hyperedges that embrace u are within C.</p><p>Then the first technical problem of user profiling in our setting can be defined as follows: SUBPROBLEM 1 (User Profiling): Given a hypergraph G consisting of multiple media objects (U,N,T t and T e ) associated with a series of object relations (see § 3.2), model users' profiles P to capture users' reading preferences by news capsules, such that in each news capsule, the maximality is satisfied.</p><p>The well-captured user profiles serve as the basis of personalized news recommendation. We discuss our solution to this subproblem in § 4.1.</p><p>Given a collection of newly-published news articles and a target online user's profile, our goal is to recommend to this user a list of news articles that satisfy the user's reading appetite. We expect that by a recommendation list, the user's preference is optimally matched, and also the news list is diverse enough so that the user would not get bored when he/she is navigating news articles. Definition 3. (Optimally Matchable). Given a news list l recommended to a user u and u's profile p, l is said to be optimally matchable to u's reading preference only if there is no other list l by which the similarity between l and p is larger than the one between l and p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4. (Diversity). Given a news list l recommended to a user u, l is said to be diverse if it matches all of u's different reading interests. A user's reading interest can be categorized by the topics and named entities in the consumption history.</head><p>We now formally define our second problem of selecting a list of news articles from newly-published news collection to maximally match an online user's reading preference. SUBPROBLEM 2 (News Personalization): Given a collection of newly-published news articles S and a user's profile p, select a subset S * from S where S * is optimally matchable to p and the diversity of S * is maximized, where the diversity denotes distinct topics and named entities in p.</p><p>The essence of personalized news recommendation is well captured in the above problem formation. We discuss our personalization solution in § 4.2.</p><p>In reality, with various subjective factors involved in news recommendation, the optimality of both SUBPROBLEM1 and SUBPROBLEM2 is difficult to achieve. Many existing news recommenders try to approximately resolve both problems based on certain evaluation criteria. In our work, we employ hypergraph learning to tackle these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RECOMMENDATION METHODOLOGY</head><p>In this section, we discuss how to approximately address the aforementioned problems via hypergraph learning. The </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">News Hypergraph Partition</head><p>Recall from § 3.3 that a news capsule is a subset of a given hypergraph. We follow the definitions in <ref type="bibr" target="#b34">[34]</ref> to describe the hypergraph partition. For a vertex subset S ⊂ V , let S c denote the complement of S. A hyperedge e is said to be a cut if it is incident with both S and S c simultaneously. We further denote the hyperedge boundary ∂S of S be a hyperedge set consisting of multiple cuts, i.e., ∂S := {e ∈ E|e ∩ S = ∅, e ∩ S c = ∅}, and define the volume volS of S to be the sum of degrees of the vertices in S, i.e., volS := v∈S d(v). Moreover, we denote the volume of ∂S by</p><formula xml:id="formula_10">vol ∂S := e∈∂S w(e) |e ∩ S||e ∩ S c | δ(e) . (<label>6</label></formula><formula xml:id="formula_11">)</formula><p>We then formalize the hypergraph partition as arg min</p><formula xml:id="formula_12">∅ =S⊂V Ncut(S) := vol∂S( 1 volS + 1 volS c ),<label>(7)</label></formula><p>which is similar to the normalized cut on ordinary graphs.</p><p>In this paper, we will not focus on how to resolve the hypergraph partitioning problem. To automatically generate hypergraph partitions (news capsules) with compact representations, we employ the method introduced in <ref type="bibr" target="#b34">[34]</ref>. It generalizes a methodology of spectral clustering originally operating on undirected graphs to hypergraphs, which is essentially suitable to the problem setting in our work. We partition the news hypergraph into m disjoint news capsules where m is predefined. Discussion: The hypergraph built upon a news reading community could be very large. Directly performing graph inference on such a hypergraph would be inefficient. By partitioning the graph into multiple subgraphs, the inference will be performed on a smaller scale, which can improve the efficiency to a great extent. In our work, we employ "cut" to partition the graph, which can be viewed as a hard clustering scheme. Other clustering methods can be applied to our problem setting, e.g., soft clustering that can generate overlapping news capsules. However, this is not our main focus, and therefore we leave it to our future work.</p><p>A practical issue suffered by the hypergraph partitioning in our problem setting would be the imbalanced user distribution over different capsules. This issue could be caused by the imbalanced distribution of different types of edges. For example, the edges between news and topics can be much denser than the edges between news and users, and as a result, some capsules might contain very few users, or even no users at all. It is trivial to resolve this issue by considering some constrains (e.g., do not "cut" on user-inside edges) when partitioning the hypergraph.</p><p>The partition paradigm is based on not only topical categories, but also the reading behaviors of users, involving the preferences on topics and named entities. In each capsule C, ∀u ∈ U , the maximality defined in § 3.3 is suboptimally satisfied based on the partition paradigm. One may argue that a per-user capsule would be more suitable to satisfy the maximality; however, such a capsule cannot be used for graph inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">News Recommendation via Ranking</head><p>Hypergraph partitioning provides us a list of disjoint news capsules, in which the users' reading preferences are encapsulated, including topics, named entities and similar users.</p><p>In the following, we present our approach in which we model the recommendation as a sub-hypergraph ranking problem.</p><p>Formally, given a capsule (or a sub-hypergraph) C, a set of newly-published news articles S and a target user u within C, we first link articles in S onto C. To do so, we extract topics and named entities from S and then compare these objects with the objects in C. In this way, we can not only connect new articles to C, but also add new objects into C. Next, we reconstruct the unified hypergraph based on the enriched C and get the vertex-hyperedge incidence matrix H C and the weight matrix W C . Since the scale of C is supposed to be much smaller than the entire hypergraph, the reconstruction would be more efficient. Then the vertex degree matrix D C v and the hyperedge degree matrix D C e are computed based on H C and W C . In the following, we discuss how to perform ranking on a sub-hypergraph by using similar idea of <ref type="bibr" target="#b5">[5]</ref>.</p><p>We define the cost function of f as follows:</p><formula xml:id="formula_13">Q(f ) = 1 2 |V | i,j=1 e∈E 1 δ(e) {v i ,v j }⊆e w(e) f i d(v i ) - f j d(v j ) 2 + μ |V | i=1 ||f i -y i || 2 , (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>where μ &gt; 0 is the regularization factor. To achieve the optimal ranking result, we need to minimize Q(f ):</p><formula xml:id="formula_15">f * = arg min f Q(f ).<label>(9)</label></formula><p>For inference, we need to smooth the process as much as possible under the constraint that vertices that are contained by many common hyperedges should have similar ranking scores. As an illustrative example, if two news articles have been accessed by many common users, then both articles will have similar ranking scores. The smoothness can be achieved by minimizing the first term in Eq. <ref type="bibr" target="#b8">(8)</ref>. We also need to minimize the difference between the obtained ranking scores and the pre-given scores to guarantee that the result will not deviate much from the truth, i.e., to minimize the second term in Eq.( <ref type="formula" target="#formula_13">8</ref>). After a series of mathematical derivation by <ref type="bibr" target="#b5">[5]</ref>, we can obtain the optimal f * as f * = (I -γA) -1 y, <ref type="bibr" target="#b10">(10)</ref> where</p><formula xml:id="formula_16">A = (D C v ) -1/2 H C W C (D C e ) -1 (H C ) T (D C v ) -1/2</formula><p>. Notice that under the constraint of C, the matrix I -γA is highly sparse, and therefore the inverse of I -γA can be efficiently calculated. y corresponds a query vector given a user, each entry of which can be either 1 or 0, indicating what topics and entities are preferred by the user. After performing ranking on the sub-hypergraph, we can choose top ranked news articles as the recommendation list.</p><p>Discussion: An interesting setup to approximately satisfy the diversity requirement defined in § 3.3 is to predefine query scores over different topics T t and named entities T e within the profile of the target user. Specifically, we can analyze the user's profile and choose the topics and named entities that are ranked high in terms of the accumulated score of the edge weights. For these topics and named entities, the corresponding values in y can be set to 1 for the query purpose, whereas for other topics and named entities, the values can be set to 0. For example, given a user q with preference over the topic "Basketball" and the named entity "LeBron James", we can specify 1 value for the corresponding two entries in y q . In addition, we can set 1 value for entries that are related to the user's preference, e.g., "NBA" and "Competitive Sports", which can be obtained using some simple text mining techiniques. In this way, the ranking result can have more diverse content in terms of topics and named entities that are distributed over the target user's profile and related preferences. Therefore the setup of the query vector y fosters the diversity in the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Transductive Inference on Hypergraph</head><p>Our proposed framework is capable of handling the socalled cold-start problem, especially for new users. In this subsection, we introduce the strategy of how we can tackle the user cold-start problem. Given a new user q without enough reading history, traditional recommender systems fail to construct a comprehensive user profile due to the data sparsity. Comparatively in our framework, we initially embrace this new user q into a specific capsule (by extracting topics and named entities of the limited consumption history of q and linking them to the capsule). Taking q into the construction of the query vector y, we perform transductive inference on the new capsule to derive the vertices related to q's preference, and finally provide the recommendation list for q.</p><p>Specifically, given a news capsule C = (V C , E C , w C ), in which the vertices in a subset S ⊂ V C have labels in L = {1, -1} predefined by the new user q according to q's reading history, our goal is to predict the labels of the remaining unlabeled vertices. Note that for news recommendation, the labels {1, -1} indicate whether the user is interested in the corresponding element or not. On the one hand, the inference function should be as smooth as possible, i.e., we should assign the same label to all vertices contained in the same hyperedge; moreover, vertices lying on a densely linked sub-hypergraph are likely to have the same label. Thus we define a function</p><formula xml:id="formula_17">Ω(f ) = 1 2 e∈E {u,v}⊆e w(e) δ(e) f (u) d(u) - f (v) d(v) 2 , (<label>11</label></formula><formula xml:id="formula_18">)</formula><p>which sums the weighted variation of a function on each edge of the capsule. On the other hand, the initial label assignment should be changed as little as possible. Let y denote the initial label vector, in which the assignments are defined by y(v) = 1 or -1 if vertex v has been labeled as positive or negative respectively, and 0 if it is unlabeled. Then we consider the following optimization problem <ref type="bibr" target="#b33">[33]</ref> arg min</p><formula xml:id="formula_19">f ∈R |V | {Ω(f ) + μ||f -y|| 2 }, (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>where μ &gt; 0 is the parameter specifying the tradeoff between the two components. The optimization problem defined in Eq.( <ref type="formula" target="#formula_19">12</ref>) is similar to the one in Eq.( <ref type="formula" target="#formula_13">8</ref>). The difference here is that for transudctive inference, our goal is to derive the labels of the unlabeled vertices, whereas for ranking, we try to derive the complete importance order of the vertices. Due to the space limit, we omit the detailed procedure for sovling Eq.( <ref type="formula" target="#formula_19">12</ref>). In this way, even if a user does not have enough reading history, we can still get enough labeled news items that the user might prefer. Hereby, for new users, we can recommend a list of unordered news articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EMPIRICAL EVALUATION</head><p>In this section, we provide a comprehensive experimental evaluation to show the effectiveness of our proposed hypergraphbased news recommendation algorithm (Hyper for short).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Real-World Data Collection</head><p>The data used in our experiment is obtained from multiple news reading portals, ranging from Aug 15th, 2010 to Nov 16th, 2010 <ref type="bibr" target="#b20">[20]</ref>, which includes news articles and users' access histories. It contains 10 news topic categories, such as sports, movies, politics, etc. We preprocess the data by removing news articles that are rarely accessed (i.e., the accessed frequency is less than 1 per day) and by storing users with frequent online reading behaviors (i.e., users who read news articles everyday and read more than 1 piece of news each day). By preprocessing, some unexpected noise can be removed to ensure the quality of the generated hypergraph. We perform LDA on news articles to extract representative words from each news category, as the topics of the data model<ref type="foot" target="#foot_1">2</ref> . For named entities, we use NLP tools, e.g., GATE <ref type="bibr" target="#b8">[8]</ref>, to perform information extraction. The media objects and relations contained in this data collection are summarized in Table <ref type="table" target="#tab_3">3</ref>(a) and 3(b), respectively. Note that the number of nearest neighbors, k, in the news similarity graph is not fixed, and therefore the number of hyperedges varies for E N k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiments</head><p>In this subsection, we first consider the effect of different factors in our unified news hypergraph on the recommendation performance, i.e., by constructing the hypergraph using different combinations of hyperedges; We then investigate the performance of local selection (selecting articles in specific news capsules) and global selection (selecting articles on the entire hypergraph); Further, we demonstrate the superiority of the transductive inference on news capsules in handling the user cold-start problem; We also provide comprehensive comparisons with existing and recently published approaches related to news recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Evaluation Setup</head><p>For evaluation purpose, we divide the entire news data into two disjoint sets, where the first one ranges from Aug 15th, 2010 to Nov 6th, 2010, regarded as the training set, and the remaining falls into the testing set. The training set is used to construct the unified hypergraph, whereas the testing set is regarded as the ground truth for recommendation evaluation. For each user in the testing set, we recommend news items (top@10, top@20 and top@30<ref type="foot" target="#foot_2">3</ref> ) to the user at each day of the testing range. For comparison, we compute the averaged F1-score over multiple users and multiple days. We also use Normalized Discount Cumulative Gain (NDCG) to measure the ranking quality of the recommended list based on a user's actual accessing sequence. NDCG at position n is defined as</p><formula xml:id="formula_21">NDCG@n = N (n) × n i=1 2 r i -1 log 2 (i + 1) , (<label>13</label></formula><formula xml:id="formula_22">)</formula><p>where N (n) is the NDCG at n of the ideal ranking list, and ri is the relevance rating of item at rank i. In our scenario, r i = 1 if the user has read the recommended news article and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Construction of Hypergraph</head><p>In our proposed data model, we integrate 8 different hyperedges or object relations into the construction of news hypergraph. Such a hypergraph provides an elegant representation of the news data, encapsulating multiple correlations among different media objects. To evaluate the effect of such a representation in personalized news recommendation, we consider different combinations of hyperedges for hypergraph construction: (1) E N k (NK): consider news similarities based on users' profiles, which is essentially a content-based method; (2) E UUN (UN): construct the hypergraph using only users' co-visit information, which can be regarded as an example of collaborative filtering; (3) E UNT t , E UUT t and E NNT t (UNT): build hypergraph by considering the topics in news collection and users' access patterns in a hybrid way; and (4) E UNT e , E UUT e , E NNT e (UNE): construct the hypergraph using the entity information, i.e., considering users' preference on specific named entities. We com-pare the metrics introduced in § 5.2.1, and the results are shown in Figure <ref type="figure" target="#fig_1">2</ref>, in which Figure <ref type="figure" target="#fig_1">2</ref> It is evident that the unified hypergraph model significantly outperforms other constructions of hypergraph from both accuracy and ranking perspective. The reason behind this is straightforward: in our unified model, high-order correlations among different media objects are well-captured, which extensively enrich a user's reading preference and hence make the recommended result more accurate. Besides this, we observe that: (i) The performance of hybrid constructions (i.e., UNT and UNE) is better than uni-edge construction (i.e., NK and UN); and (ii) the result of UNE is comparable with UNT, which means that in real-world news recommender systems, users pay equal or more attention on named entities they prefer, not just the topics that news articles are reporting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Local Selection V.S. Global Selection</head><p>To recommend news articles to a target user, our approach first partitions the entire hypergraph into multiple news capsules, and then locates the capsule that the user belongs to for further recommendation. Such a paradigm can not only expedite the recommendation (since we only consider partial hypergraph), but also improve the accuracy of the recommendation because the information in a news capsule is more specialized than the one in a global perspective. To validate this claim, we choose different values for m (the number of capsules defined in § 4.1) and compare the recommendation results with the one using the entire hypergraph (Global, for short). Figure <ref type="figure" target="#fig_2">3</ref>  With different m, the performance of our approach varies. Hyper achieves the optimal performance when m = 50, which is not compatible with the number of topics. By partitioning the entire hypergraph into more capsules, the information within each capsule is more specialized, and therefore a user's reading interest can be modeled in a more finegrained level. Compared with the global selection, Hyper m=50 performs better in terms of both F1-score and NDCG.</p><p>We are also interested in the performance details of local selection and global selection. Therefore, for Hyper m=50 and global selection, we randomly select 100 users to provide recommendations for them, and then plot the precision and recall pair for each user on top@10, top@20 and top@30 news items recommended to these user. Figure <ref type="figure" target="#fig_3">4</ref> shows the resulted plot. As observed in Figure <ref type="figure" target="#fig_3">4</ref>, besides the higher recommendation precision and recall, the performance distribution of Hyper is more dense than the one of the global selection, which demonstrates the stability of our proposed local selection strategy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Parameter Tuning</head><p>In our algorithm, there are several parameters for tuning, i.e., the number of the nearest neighbor k in Eq.( <ref type="formula" target="#formula_6">4</ref>), the control parameter α in Eq.( <ref type="formula" target="#formula_7">5</ref>), the regularization factor γ in Eq. <ref type="bibr" target="#b10">(10)</ref> and μ in Eq. <ref type="bibr" target="#b12">(12)</ref>.</p><p>Both k and α are related to E N k in the data model. To explore the effect of the parameters k and α (the influence of hyperedges relevant to news content similarity), we use F1score as the evaluation metric. Figure <ref type="figure">5</ref> shows the results. We first empirically fix α = 0.2 and evaluate the changing of k. Figure <ref type="figure">5</ref>(a) shows the F1-score measured as a function of k. The optimal value for k is obtained when k = 70. We then fix k and evaluate the changing of α. The parameters γ and μ are common factors in many hypergraph learning methods. In our experiment, we empirically set γ as 0.9 and μ as 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5">Comparison with Other Methods</head><p>We also implement several recently published methods: Goo <ref type="bibr" target="#b9">[9]</ref>, ClickB <ref type="bibr" target="#b23">[23]</ref>, Bilinear <ref type="bibr">[7]</ref>, Bandit <ref type="bibr" target="#b19">[19]</ref>, fLDA <ref type="bibr" target="#b3">[3]</ref>, and SCENE <ref type="bibr" target="#b20">[20]</ref> for comparison. The details of these algorithms are described as follows:</p><p>• Goo: The method is essentially a collaborative filtering approach, in which MinHash clustering, PLSI and covisitation counts are taken into account for a unified recommendation paradigm.</p><p>• ClickB: In this approach, the profiles of user's news interests are built based on their past click behavior, and then a Bayesian framework for predicting users' current news interests.</p><p>• Bilinear: This method maintains profiles of content of interest based on temporal characteristics of the content, e.g., popularity and freshness, and also maintains profiles of users including historical activities. The recommendation is achieved via a feature-based machine learning approach.</p><p>• Bandit: The method models recommendation as a contextual bandit problem, in which a learning algorithm sequentially selects articles to serve users based on contextual information about users and articles, while simultaneously adapting its selection strategy based on user-click feedback.</p><p>• fLDA: The method regularizes both user and item factors simultaneously through user features and the bag of words associated with each item. It is essentially a hybrid filtering method.</p><p>• SCENE: The method assumes the interestingness of news articles with respect to a user could be regressive, and uses the "submodularity" property to model the news selection problem.</p><p>Note that the parameters of these baseline methods are optimally tuned in our experiment to ensure the fair comparison. We use F1-score and NDCG to compare these baselines with Hyper. The results are shown in Figure <ref type="figure" target="#fig_5">6</ref>(a) and 6(b). It is evident that our proposed method significantly outperforms other candidates on both metrics. The results of fLDA and SCENE are comparable to ours. In fLDA, each word in an item is associated with a discrete latent factor often referred to as the topic of the word; item topics are obtained by averaging topics across all words in an item. Therefore, fLDA considers more fine-grained granularity of topics, and consequently obtains reasonable recommendation results. SCENE explicitly takes into account the "submodularity" within users' reading behaviors for recommendation. As we observe, the performance of Goo and ClickB is relatively poor. This is because the recommended lists of both methods are heavily determined by users' co-visiting histories; however, the news data used in the experiments contains a great portion of relatively new users<ref type="foot" target="#foot_3">4</ref> , i.e., users </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.6">Handling Cold-start</head><p>In traditional recommendation methods, the cold-start problem cannot be well handled due to the data sparsity. To resolve it, we perform transductive inference on the unified news capsule for new users. The intuition is straightforward: we borrow the concept of inference by utilizing a small set of labeled data to infer the labels of unlabeled data on the hypergraph. Notice that in such a case, we do not focus on the ranking of news articles, but pay more attention on the interestedness of items, i.e., whether the items are preferred by the user or not.</p><p>Specifically, we randomly choose 100 users who read news articles less than 5 per day, and then recommend news articles (top@10, top@20 and top@30) for these users. For evaluation purpose, we compare our method with Goo, ClickB, Bilinear, Bandit, fLDA and SCENE. Figure <ref type="figure" target="#fig_5">6</ref>(c) and 6(d) shows the comparison results. As shown in Figure <ref type="figure" target="#fig_5">6</ref>(c), the cold-start problem can be elegantly alleviated by using our proposed method, Hyper. The explanation is straightforward: in Hyper, we explicitly model the recommendation for new users as transductive inference on a specified news capsule, and meanwhile we consider high-order correlations among different media objects, which significantly complement the data sparsity of new users when performing recommendation. In Figure <ref type="figure" target="#fig_5">6</ref>(d) we also observe that although we do not intentionally take the ranking into account, our method surprisingly outperforms the others in terms of NDCG. The reason is that we can provide more news articles in the recommendation list that match a user's reading interest, and thus the quality of ranking is improved consequently. The result of fLDA on cold-start handling is comparable to our performance. For cold-start users, fLDA gives more weight to the prior mean (predicted by user and/or item features) in estimating the factor, and therefore selects news items that are quite relevant to the prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.7">Diversity Evaluation</head><p>The recommended news list provided by our algorithm shows a great diversity on topic aspects. Such diversity is originated from the sparkle of the query vector y designed in § 4.2, by which we can not only specify the target user, but also provide topics and named entities that the user prefers. To evaluate how diverse our recommendation result is, we compare the set diversity <ref type="bibr" target="#b32">[32]</ref> among the results of our method and other recommender systems. The set diversity is defined as the average dissimilarity of all pairs of news items in the resulted list. Specifically, given a news set S, the average dissimilarity of S, f d (S), is defined as</p><formula xml:id="formula_23">f d (S) = 2 p(p -1)</formula><p>s i ∈S s j ∈S,s j =s i (1sim(si, sj)), <ref type="bibr" target="#b14">(14)</ref> where |S| = p, and the dissimilarity of a news pair is 1sim(s i, sj), in which sim(si, sj) denotes the content similarity between the news item s i and sj, and it is calculated using the cosine similarity.</p><p>For diversity evaluation, we choose the aforementioned methods (Goo, ClickB, Bilinear, Bandit, fLDA and SCENE) as our comparison baselines. We employ the experiment setup similar to the previous section, and then compare the diversities of recommended lists with different cardinalities (top@10, top@20 and top@30). Table <ref type="table" target="#tab_5">4</ref> shows the averaged diversity for 100 randomly selected users. From the result, we observe that (i) The diversity decreases as the recommended news list enlarges. It is straightforward that when more news articles are selected, the topic distribution of the news list becomes closer to the user's reading interest, and therefore the selected news items are more similar. (ii) The diversity of the recommendation list provided by the baseline methods drops dramatically as the list size increases, since they did not take the diversity into account. (iii) Our proposed method outperforms the others very significantly, except SCENE. SCENE explicitly selects different news items solely from topic-wise for recommendation, and hence the diversity of the result from SCENE is higher more or less. In our work, we consider the interest of news readers by specifying different topics and named en-tities in the query vector y. The diversity decreases very smoothly when we recommend more news items to individual users, compared with other rivals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUDING REMARKS</head><p>In this paper, we propose to use hypergraph learning methods to deal with the issues existed in news recommenders. We first represent news data as a unified hypergraph, in which various correlations among different media objects are integrated into an information capsule. We then decompose the recommendation problem as two subproblems: partitioning and ranking, where the former aims to separate the entire hypergraph into multiple groups, or subcapsules, and the latter is designed to select a list of news articles from a specific capsule and recommend them to a target user (the user is regarded as a query).</p><p>In our proposed data model, we simplify the profiling problem by only analyzing a user's reading history (as the profile) without accessing any other auxiliary information. In reality, a news reader might have other information, e.g., demographics, locations, and other social and behavioral patterns. We believe such information can be easily incorporated into our proposed framework, e.g., by encapsuling the user relations within close locations or the same social community into the data model. In our future work, we plan to delve into extending our framework along this direction. In addition, although we intentionally partition the hypergraph into multiple small ones to expedite the procedure, the scalability of our proposed framework is not quite satisfactory. We plan to use distributed environment, e.g. Hadoop, to accelerate the partitioning and recommendation procedure in our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustrative example of data model in news reading community.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Performance comparison of different hypergraph constructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance comparison of local selection with different number of capsules and global selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Precision-recall plot for local selection with m = 50 and global selection. Remark: "2" denotes users using the global selection strategy; and "+" represents users using the local selection strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 (Figure 5 :</head><label>55</label><figDesc>Figure 5: Parameter Tuning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance comparison for regular recommendation and cold-start user recommendation. Remark: (a) and (b) are comparisons of different algorithms on averaged metrics; (c) and (d) are comparisons of different algorithms for the cold-start problem of new users.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Notations in our data model. UUT e the set of user-user-entity hyperedges. E NNT t the set of article-article-topic hyperedges. E NNT e the set of article-article-entity hyperedges. E N</figDesc><table><row><cell>U</cell><cell>the user set.</cell><cell>u i a particular user.</cell></row><row><cell>N T t T e</cell><cell cols="2">the article set. n i a particular article. the topic set. t t the k-th topic. k the entity set. t e k the k-th entity.</cell></row><row><cell>n k i α</cell><cell cols="2">the k nearest neighbors of an article i. the importance factor of content similarities.</cell></row><row><cell cols="3">E UNT t E UNT e the set of user-article-entity hyperedges. the set of user-article-topic hyperedges.</cell></row><row><cell>E UUN</cell><cell cols="2">the set of user-user-article hyperedges.</cell></row><row><cell>E UUT t</cell><cell cols="2">the set of user-user-topic hyperedges.</cell></row><row><cell>E</cell><cell></cell><cell></cell></row></table><note><p>k the set of k-nearest-articles hyperedges.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The incidence matrix H of the unified hypergraph. unified hypergraph defined in § 3.2 is used to model the high-order relations among different types of media objects in news reading community. In order to effectively capture online users' reading preference, we propose to initially partition the entire hypergraph into multiple news capsules, by which users' reading behaviors can be stored. Given newlypublished news articles, we integrate relevant articles into the capsule that embraces the user, and then perform ranking on this specific news capsule. In this way, we are capable of providing instant news recommendation.</figDesc><table><row><cell></cell><cell>E UNT t</cell><cell>E UNT e</cell><cell>E UUN</cell><cell>E UUT t</cell><cell>E UUT e</cell><cell>E NNT t</cell><cell>E NNT e</cell><cell>E N k</cell></row><row><cell>U</cell><cell>UE UNT t</cell><cell>UE UNT e</cell><cell cols="2">UE UUN UE UUT t</cell><cell>UE UUT e</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>N</cell><cell>NE UNT t</cell><cell>NE UNT e</cell><cell>NE UUN</cell><cell>0</cell><cell>0</cell><cell>NE NNT t</cell><cell>NE NNT e</cell><cell>NE N k</cell></row><row><cell cols="2">T t T t E UNT t T e 0</cell><cell>0 T e E UNT e</cell><cell>0 0</cell><cell>T t E UUT t 0</cell><cell>0 T e E UUT e</cell><cell>T t E NNT t 0</cell><cell>0 T e E NNT e</cell><cell>0 0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Statistics of our news collection.</figDesc><table><row><cell cols="2">(a) Objects</cell><cell></cell><cell cols="2">(b) Relations</cell><cell></cell></row><row><cell cols="2">Elements Count Users 3,280 Articles 58,873 Topics 10</cell><cell cols="4">Relations Count Relations Count E UNT t 501,239 E UUT e 402,918 E UNT e 672,348 E NNT t 52,136 E UUN 307,652 E NNT e 176,431</cell></row><row><cell>Entities</cell><cell>121,617</cell><cell>E UUT t</cell><cell>43,785</cell><cell>E N k</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Diversity evaluation on the result list. (Bold indicates the best performance. * indicates the statistical significance at p &lt; 0.01 w.r.t. the randomness of selected users.)</figDesc><table><row><cell cols="2">Methods top@10</cell><cell>top@20</cell><cell>top@30</cell></row><row><cell>Goo</cell><cell>0.4101</cell><cell>0.3074</cell><cell>0.1105</cell></row><row><cell>ClickB</cell><cell>0.4329</cell><cell>0.3128</cell><cell>0.1562</cell></row><row><cell>Bilinear</cell><cell>0.4234</cell><cell>0.2517</cell><cell>0.0933</cell></row><row><cell>Bandit</cell><cell>0.5056</cell><cell>0.4126</cell><cell>0.2925</cell></row><row><cell>fLDA</cell><cell>0.4726</cell><cell>0.3981</cell><cell>0.2705</cell></row><row><cell cols="2">SCENE 0.6537*</cell><cell>0.5771</cell><cell>0.4859</cell></row><row><cell>Ours</cell><cell>0.6323</cell><cell cols="2">0.5987* 0.5072*</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>It is natural that the edges can be generalized from a pairwise co-occurrence, e.g., an edge incident on a news item and all of its readers. However, the generated incidence matrix would become much denser. For simplicity, we only consider the hyperedges with three vertices. Our algorithm can be extend to hyperedges with arbitrary number of vertices.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Here each "topic" is represented as a bag of words when constructing the unified hypergraph.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The "top@x" means the top ranked x news items being recommended to the user.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>In our dataset, the number of new users is around 400, compared with the total number of users, 3,280.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank the reviewers for their valuable comments. The work is supported in part by NSF grants IIS-0546280, DBI-0850203, CCF-0939179, HRD-0833093 and CNS-1126619.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social reader: following social networks in the wilds of the blogosphere</title>
		<author>
			<persName><forename type="first">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 1st SIGMM workshop on Social media</title>
		<meeting>of 1st SIGMM workshop on Social media</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Regression-based latent factor models</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGKDD</title>
		<meeting>of SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">flda: matrix factorization through latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WSDM</title>
		<meeting>of WSDM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Higher order learning with graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Music recommendation by unified hypergraph: Combining social media information and music content</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM MM</title>
		<meeting>of ACM MM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="391" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Hybrid systems for personalized recommendations. Intelligent Techniques for Web Personalization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="133" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Personalized recommendation on dynamic content using predictive bilinear models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="691" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">GATE: A framework and graphical development environment for robust NLP tools and applications</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Tablan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Google news personalization: scalable online collaborative filtering</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Implicit news recommendation based on user interest models and multimodal content analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Di Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Montagnuolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Messina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AIEMPro</title>
		<meeting>of AIEMPro</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image segmentation as learning on hypergraphs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICMLA</title>
		<meeting>of ICMLA</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="247" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Newsjunkie: providing personalized newsfeeds via analysis of information novelty</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="482" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multilevel k-way hypergraph partitioning</title>
		<author>
			<persName><forename type="first">K</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vipin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLSI Design</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="300" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Latent semantic models for collaborative filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="115" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image retrieval via probabilistic hypergraph ranking</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="3376" to="3383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning on weighted hypergraphs to integrate protein interactions and gene expressions for cancer outcome prediction</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuangy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICDM</title>
		<meeting>of ICDM</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="293" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Amatriain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of RecSys</title>
		<meeting>of RecSys</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hypergraph-based inductive learning for generating implicit key phrases</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="77" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A contextual-bandit approach to personalized news article recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="661" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scene: a scalable two-stage personalized news recommendation system</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Knox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Padmanabhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Personalized news recommendation: a review and an experimental investigation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="754" to="766" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Logo: a long-short user interest integration in personalized news recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of RecSys</title>
		<meeting>of RecSys</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="317" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Personalized news recommendation based on click behavior</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IUI</title>
		<meeting>of IUI</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Collaborative filtering by personality diagnosis: A hybrid memory-and model-based approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of UAI</title>
		<meeting>of UAI</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">GroupLens: an open architecture for collaborative filtering of netnews</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Iacovou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suchak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bergstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCW</title>
		<meeting>of CSCW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW</title>
		<meeting>of WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Methods and metrics for cold-start recommendations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Schein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Popescul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
		<meeting>of SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hypergraph spectral learning for multi-label classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGKDD</title>
		<meeting>of SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="668" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A hypergraph-based learning algorithm for classifying gene expression and arraycgh data with prior knowledge</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page">2831</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning from interpretations: a rooted kernel for ordered hypergraphs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Khardon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="943" to="950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiple hypergraph clustering of web images by miningword2image correlations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="750" to="760" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Avoiding monotony: improving the diversity of recommendation lists</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hurley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of RecSys</title>
		<meeting>of RecSys</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Beyond pairwise classification and clustering using hypergraphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning with hypergraphs: Clustering, classification, and embedding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">1601</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
