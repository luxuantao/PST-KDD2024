<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning-by-Narrating: Narrative Pre-Training for Zero-Shot Dialogue Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chao</forename><surname>Zhao</surname></persName>
							<email>zhaochao@cs.unc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">UNC Chapel Hill</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
									<region>NC</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenlin</forename><surname>Yao</surname></persName>
							<email>wenlinyao@tencent.com</email>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
							<email>yudian@tencent.com</email>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaiqiang</forename><surname>Song</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
							<email>jianshuchen@tencent.com</email>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<settlement>Bellevue</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning-by-Narrating: Narrative Pre-Training for Zero-Shot Dialogue Comprehension</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Comprehending a dialogue requires a model to capture diverse kinds of key information in the utterances, which are either scattered around or implicitly implied in different turns of conversations. Therefore, dialogue comprehension requires diverse capabilities such as paraphrasing, summarizing, and commonsense reasoning. Towards the objective of pretraining a zero-shot dialogue comprehension model, we develop a novel narrative-guided pre-training strategy that learns by narrating the key information from a dialogue input. However, the dialogue-narrative parallel corpus for such a pre-training strategy is currently unavailable. For this reason, we first construct a dialogue-narrative parallel corpus by automatically aligning movie subtitles and their synopses. We then pre-train a BART model on the data and evaluate its performance on four dialogue-based tasks that require comprehension. Experimental results show that our model not only achieves superior zero-shot performance but also exhibits stronger finegrained dialogue comprehension capabilities. The data and code are available at https: //github.com/zhaochaocs/Diana.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dialogue comprehension <ref type="bibr" target="#b20">(Sun et al., 2019;</ref><ref type="bibr" target="#b4">Cui et al., 2020)</ref> aims to capture diverse kinds of key information in utterances, which are either scattered around or implicitly implied in different turns of conversations. Therefore, it requires different capabilities such as paraphrasing <ref type="bibr" target="#b6">(Falke et al., 2020)</ref>, summarizing <ref type="bibr" target="#b7">(Gliwa et al., 2019)</ref>, and commonsense reasoning <ref type="bibr" target="#b1">(Arabshahi et al., 2021)</ref>. Recent advances in pre-trained language models (PLMs) <ref type="bibr" target="#b5">(Devlin et al., 2019;</ref><ref type="bibr" target="#b17">Radford et al., 2019)</ref> have been applied to the problem <ref type="bibr" target="#b10">(Jin et al., 2020;</ref><ref type="bibr" target="#b14">Liu et al., 2021)</ref>. However, these PLMs are generally pretrained on formal-written texts, which are different from dialogue data in nature. Specifically, dialogues are composed of colloquial languages from multi-speakers, and utterances usually have complex discourse structures <ref type="bibr" target="#b0">(Afantenos et al., 2015)</ref>. Therefore, applying these models directly to dialogue comprehension, especially in low-resource settings, is sub-optimal.</p><p>To learn better dialogue representations, recent studies have designed several dialogue-specific pretraining objectives such as speaker prediction <ref type="bibr" target="#b16">(Qiu et al., 2021)</ref>, utterance prediction <ref type="bibr" target="#b2">(Chapuis et al., 2020)</ref>, response selection <ref type="bibr" target="#b22">(Wu et al., 2020)</ref>, and turn order restoration <ref type="bibr" target="#b25">(Zhang and Zhao, 2021)</ref>. These methods, albeit improve over the vanilla PLMs, usually rely on surface-level dialogue information. In particular, they still fail to train the models to explicitly learn the aforementioned capabilities which are critical for dialogue comprehension (e.g., linguistic knowledge, world knowledge, and commonsense knowledge). Furthermore, it was not able to incorporate knowledge beyond dialogue (e.g., non-verbal communications between speakers, as well as time and location information), which are also crucial for dialogue comprehension.</p><p>To pre-train a zero-shot dialogue comprehension model with the aforementioned features, we develop a novel generative pre-training strategy that learns by narrating the key information from a dialogue input (see Figure <ref type="figure" target="#fig_0">1</ref> for an example). In particular, the generated narrative text is supposed to not only (i) paraphrase the gists of the dialogue but also (ii) carry certain inferred information (e.g., the time and location of a scene and relations between speakers) that are not explicitly mentioned in the dialogues. Learning to narrate such information helps the model to learn varied lexical, syntactic, and semantic knowledge of dialogue. It also enhances the model's ability to infer extra information beyond the literal meaning within dialogues, which will benefit the model's capability of dialogue comprehension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2203.10249v1 [cs.CL] 19 Mar 2022</head><p>Movies &amp; TVs S: One hundred two point two. It's like you're not trying to get better. A: Sheldon, you don't get over the flu in half an hour. S: I just want you to get better as soon as possible. S: let me ask you a question. Do you believe in the placebo effect? A: Of course I do. There have been many studies proving its validity. S: Great. Now, this may look like a Tic Tac... but it is really powerful A: Sheldon, this isn't helping. Why don't you just let me get some rest Sheldon is checking Amy's temperature of 102.2 ?F and it is the same as half an hour before. He asks if she believes in placebo and then gives her a Tic Tac. Amy doesn't like this and tries to get to sleep? Dialogue Narrative However, the learning-by-narrating strategy would require a dialogue-narrative parallel corpus, which, to our best knowledge, is not publicly available. For this reason, we first create DIANA, a large-scale dataset with (DIAlogue, NArrative) pairs automatically collected from subtitles of movies and their corresponding plot synopses. We consider dialogues from movie subtitles as they are close to daily human-to-human conversations <ref type="bibr" target="#b24">(Zhang and Zhou, 2019)</ref>. In addition, the movie synopses include rich narrative information, which is helpful for dialogue comprehension. After data collection and strict quality control, we obtain a dataset with 243K (dialogue, narrative) pairs written in English. As the automatic data construction procedure is language-independent, it can be applied to low-resource languages as well.</p><p>We then pre-train a BART model <ref type="bibr" target="#b12">(Lewis et al., 2020)</ref> on the constructed corpus with the proposed learning-by-narrating strategy, and evaluate it on four dialogue-based tasks that require comprehension. In zero-shot settings, our pre-trained model outperforms the BART baseline on all tasks by a large margin (e.g., +8.3% on DREAM <ref type="bibr" target="#b20">(Sun et al., 2019)</ref>), demonstrating the success of our approach.</p><p>The contributions of this paper are three-fold:</p><p>? We propose a novel learning-by-narrating pretraining strategy for dialogue comprehension;</p><p>? We release DIANA, a new large-scale dialogue-narrative parallel corpus;</p><p>? Experiments show that our pre-trained dialogue comprehension model achieves superior zero-shot performance on a variety of downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DIANA: A Dialogue-Narrative Corpus</head><p>In this section, we describe the procedure to create the dialogue-narrative parallel dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Collection and Segmentation</head><p>We collect 47,050 English subtitles of movies and TV episodes released from Opensubtitle <ref type="bibr" target="#b13">(Lison et al., 2018)</ref> and their corresponding synopses from online resources such as Wikipedia and TMDB. To link the subtitle and synopsis of the same movie or TV episode, we require a subtitle and a synopsis to have the same title and the release year, as well as a high overlap rate (&gt; 50%) on role names.</p><p>The subtitle and synopsis of a movie are too long for a PLM. To facilitate pre-training, we split both the subtitle and synopsis into smaller segments and align the related segments from each part to shorter (dialogue, narrative) pairs. We split subtitles using the time interval ? T between utterances and split a synopsis into sentences. We set ? T = 5s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Alignment</head><p>We aim to align the dialogue sessions {d 1 , . . . , d n } and narrative segments {s 1 , . . . , s m } with maximum global similarity to form (dialogue, narrative) pairs. For each dialogue session d j , the goal is to find its corresponding narrative segment s i .</p><p>Inspired by <ref type="bibr" target="#b21">(Tapaswi et al., 2015)</ref> in which the narrative in a synopsis follows the timeline of a movie or a TV episode, we develop a dynamic time warping method to find the globally optimal alignment score. During aligning, some narrative segments contain information beyond the dialogue, so they cannot be aligned to any dialogue session. We therefore allow our algorithm to skip at most k narrative segments during alignment searching:</p><formula xml:id="formula_0">A(i, j) = max 0?k?K+1 A(i -k, j -1) + S (si, dj) , (1)</formula><p>where A(i, j) denotes the optimal alignment score of the first i narrative segments and the first j dialogue sessions. S (s i , d j ) is the text similarity between s i and d j .</p><p>We compare the performance of three text similarity measures: Jaccard similarity, Rouge-1F, and TF-IDF. In consideration of time efficiency, we don't apply more advanced neural methods. We compare these similarity measures on MovieNet dataset <ref type="bibr" target="#b9">(Huang et al., 2020)</ref>, which provides a manual alignment between the segments of subtitles and synopses of 371 movies. <ref type="foot" target="#foot_0">1</ref> We evaluate the performance of each similarity measure by alignment accuracy, a.k.a, the percentage of dialogue sessions that are correctly aligned to the corresponding narrative segment. As shown in Table <ref type="table" target="#tab_0">1</ref>, TF-IDF performs best among all similarity measures. We also find that a narrative-wise L 2 normalization of the TF-IDF can further improve the alignment accuracy. It helps to penalize the similarity of (d j , s i ) when s i has high similarity with many dialogues (e.g., when s i contains common words or protagonists' names.) We therefore choose the normalized TF-IDF as our similarity function. We further analyze the errors during alignment and find that 85.94% of errors happen because the dialogue session is aligned to the previous or next segment of the gold narrative segment. It indicates that most of the errors happen locally. Figure <ref type="figure" target="#fig_1">2</ref> shows an example from MovieNet, where the red line and the blue line indicate the gold alignment and the predicted alignment via normalized TF-IDF, respectively. It shows that the two lines are generally well overlapped except for some local discrepancies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Quality Control</head><p>After data alignment, each narrative segment s i can be aligned to multiple dialogues. To consider the local alignment errors, we also merge the aligned dialogues of s i-1 and s i+1 to the dialogues of s i . Some of these dialogues may not be relevant to s i .</p><p>To select the relevant dialogues, we use a greedy method to incrementally select dialogues until the rouge-F score between the narrative and the selected dialogues doesn't increase. After selection, we concatenate the selected dialogues and preserve their relative position. We finally obtain around 1.5 Million (dialogue, narrative) pairs. To further improve the quality of data, we filter out pairs where the dialogue and the narrative are irrelevant. To evaluate the relevance, we use two automatic measures: Coverage and Density <ref type="bibr" target="#b8">(Grusky et al., 2018)</ref>. Low Coverage and Density indicate that the narrative text is either too abstractive or irrelevant to the dialogue. We thus only select the pairs with Coverage &gt; 0.5 and Density &gt; 1. After this strict quality control, we obtain 243K (dialogue, narrative) pairs as the final DIANA dataset, which is a high-quality subset of the original dataset. The average length of the dialogue and the narrative are 58 tokens and 18 tokens, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Analysis of Knowledge Type</head><p>To analyze what types of knowledge are included in DIANA, we randomly sample 100 instances and manually categorize the relation between dialogue and the corresponding narrative text into seven knowledge types. We show the percentage of each knowledge type in parentheses and in Figure <ref type="figure" target="#fig_2">3</ref> as well. The knowledge types are:</p><p>? Summarizing (39%): The narrative text summarizes multiple utterances as a concise statement to reflect the salient event or information of the dialogue.  ? Implicit (10%):</p><p>The narrative text provides extra information that is not explicitly mentioned in the dialogue. ? Causal (6%): The narrative text describes the cause and effect relationship between events. ? Interpersonal (5%): The narrative text reveals the relationships between speakers.</p><p>Among these knowledge types, Summarizing and Visual/Audial are the two most frequent ones. They are followed by Paraphrasing and Text Matching, which contribute to 23% in total. It also shows that narratives use paraphrasing more often than copying. Additionally, DIANA contains three higher-level knowledge types that require the awareness of real-world commonsense and more complicated inference such as implicit knowledge, causal relationships, and interpersonal relationships. The diverse knowledge types in DIANA indicate the benefit of this dataset for dialogue comprehension and other downstream tasks as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Pre-training: Learning-by-Narrating</head><p>During pre-training, we aim to inject the knowledge contained in DIANA into pre-trained models. One option is to ask the model to distinguish between a correct narrative and an incorrect narrative via a classification objective. However, it requires carefully designing additional non-trivial negative (dialogue, narrative) pairs. Therefore, we propose to directly generate a narrative text from the given dialogue by maximizing the generative probability:</p><formula xml:id="formula_1">p(y | x; ?) = |y| t=1 p (y t | y 1:t-1 , x; ?) , (2)</formula><p>where x are dialogue texts and y are narrative texts.</p><p>There are two main advantages of using the generative objective. First, it can fully leverage the narrative information from each token of the narrative text with no need to construct negative pairs. Second, the pre-trained model can be directly applied to both generative and discriminative downstream tasks without further fine-tuning. For discriminative tasks, we calculate the probability of each candidate according to Equation 2 and choose the most probable candidate as the predicted answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate the performance of the pre-trained model on four downstream tasks that require dialogue comprehension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setting</head><p>We use BART, a state-of-the-art sequence-tosequence model, as our baseline model. <ref type="foot" target="#foot_1">2</ref> We use its released checkpoint and further pre-train the model on DIANA. During pre-training, we concatenate the utterances as the input and update the parameters to maximize the probability of the corresponding narrative. We use Adam as the optimizer, and we set the learning rate and weight decay to 3?10 -5 and 0.01, respectively. Following previous studies that suggest that a larger batch size helps pre-training, we set the batch size to 1024 and pretrain the model for 1,000 steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tasks</head><p>We evaluate our model's ability of dialogue comprehension on four downstream tasks. DREAM <ref type="bibr" target="#b20">(Sun et al., 2019)</ref> aims to read a dialogue and select the correct answer from options of a dialoguerelated question. To make the task similar to our pre-training task, we follow previous work <ref type="bibr" target="#b3">(Chen et al., 2021)</ref> to train a T5 model to convert each (question, answer) pair to a statement. PCMD <ref type="bibr" target="#b15">(Ma et al., 2018</ref>) is a passage completion task. Given a dialogue and a passage that describes the dialogue, a query is created by replacing a character mention with a variable x, and the model needs to recover the character mention. VLEP <ref type="bibr" target="#b11">(Lei et al., 2020)</ref> aims to select the most probable future event given the dialogue of the current event and two candidates of future events. SAMSum <ref type="bibr" target="#b7">(Gliwa et al., 2019)</ref> is a dialogue summarization task to create a concise abstractive summary for a dialogue. The first three are discriminative tasks, and SAMSum is a generative task. None of the source dialogues in these tasks are included in DIANA. We evaluate the model performance on these tasks under the zero-shot setting. For discriminative tasks, we convert each test instance with K answer candidates as K (dialogue, narrative) pairs. Given the dialogue as input, we evaluate the conditional probability of each narrative according to Equation 2 and choose the most probable narrative as the predicted answer. We use accuracy (ACC) as the evaluation metric for discriminative tasks and ROUGE for the summarization task.</p><p>We compare our pre-trained model (Narrator) with strong pre-trained baselines such as GPT-2, RoBERTa, and BART. To investigate the impact of the pre-training objective, we compare with 1) BART-DIAL-DE: the original BART de-noising objectives, which is trained on the dialogue part of DIANA; and 2) BART-CNN-CLS: a classification objective, which is trained using the CNNDM dataset <ref type="bibr" target="#b19">(See et al., 2017)</ref> to distinguish between positive and negative summaries based on the documents. Negative summaries are obtained from DocNLI <ref type="bibr" target="#b23">(Yin et al., 2021)</ref> by replacing the words, entities, and sentences of positive summaries. We also investigate the quality of DIANA by comparing it with two large summarization datasets: CN-NDM and CRD3 <ref type="bibr" target="#b18">(Rameshkumar and Bailey, 2020)</ref>. We pre-train BART to generate the summaries of these datasets from the corresponding documents and refer to the models as BART-CNN-GEN and BART-CRD3-GEN. Besides the zero-shot models, we list the supervised results finetuned on BART (BART-FT) as a reference for the upper bound.  We further analyze what types of knowledge are enhanced during pre-training. To this end, we test Narrator on a subset of the DREAM test set, which includes annotated knowledge types released along with the DREAM dataset. As shown in Table <ref type="table" target="#tab_4">3</ref>, compared with the vanilla BART, Narrator achieves better performance on all knowledge types except Arithmetic, which is not covered in DIANA. The performance gain indicates that the narrative pretraining contributes the most to the knowledge related to paraphrasing and matching. It also benefits from other knowledge types that require various reasoning abilities such as commonsense reasoning and logic reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results are shown in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We propose a learning-by-narrating strategy to pretrain a zero-shot dialogue comprehension model. We first construct a dialogue-narrative dataset named DIANA, which contains 243K (dialogue, narrative) pairs obtained by automatically aligning movie subtitles with their corresponding synopses. We then pre-train a dialogue comprehension model based on DIANA and evaluate its performance on four downstream tasks that require dialogue comprehension abilities. Experiments show that our model outperforms strong pre-trained baselines, demonstrating that the learning-by-narrating strategy is a promising direction for dialogue comprehension. We also hope that DIANA will promote future research in related areas.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the learning-by-narrating strategy for pre-training a zero-shot dialogue comprehension model (with an encoder-decoder architecture).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The Alignment of dialogues and narrative segments of a movie. X-axis and Y -axis are the ID of dialogue sessions and narrative segments, respectively. The variety of colors depicts the different similarity values between a dialogue session and a narrative segment. The blue line is the predicted alignment via normalized TF-IDF while the red line is the gold alignment.</figDesc><graphic url="image-2.png" coords="3,306.14,70.86,218.27,103.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The knowledge type distribution in DIANA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Alignment accuracy of different similarity measures on MovieNet.</figDesc><table><row><cell>Similarity Function</cell><cell>Accuracy</cell></row><row><cell>Jaccard</cell><cell>57.98</cell></row><row><cell>Rouge-1F</cell><cell>60.01</cell></row><row><cell>TF-IDF</cell><cell>67.20</cell></row><row><cell>TF-IDF normalized</cell><cell>71.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on four dialogue-based tasks. For models that require further pre-training, we list the corresponding pre-training dataset and task.</figDesc><table><row><cell></cell><cell cols="2">Data Task</cell><cell cols="3">DREAM PCMD VLEP ACC ACC ACC R1</cell><cell>SAMSum R2</cell><cell>RL</cell></row><row><cell>BART-FT</cell><cell>-</cell><cell>-</cell><cell>62.56</cell><cell cols="4">75.89 65.07 49.18 24.47 47.12</cell></row><row><cell>GPT-2</cell><cell>-</cell><cell>-</cell><cell>41.99</cell><cell cols="4">45.02 54.58 10.83 0.74 11.68</cell></row><row><cell>RoBERTa</cell><cell>-</cell><cell>-</cell><cell>45.22</cell><cell>46.25 52.28</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>45.07</cell><cell cols="4">46.07 54.26 29.92 9.58 28.54</cell></row><row><cell></cell><cell cols="2">DIAL DE</cell><cell>46.69</cell><cell cols="4">47.34 55.98 30.08 9.52 29.36</cell></row><row><cell>BART</cell><cell cols="3">CNN CLS 50.46</cell><cell>49.27 55.53</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell cols="3">CNN GEN 52.72</cell><cell cols="4">45.34 58.13 31.33 9.08 28.03</cell></row><row><cell></cell><cell cols="3">CRD3 GEN 52.96</cell><cell cols="4">45.71 57.12 27.07 9.09 27.64</cell></row><row><cell cols="4">Narrator DIANA GEN 53.41</cell><cell cols="4">54.88 58.90 37.27 13.23 36.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Our observations are as follows. (i) When compared with vanilla PLMs, Narrator outperforms GPT-2, RoBERTa, and BART, demonstrating that the learning-bynarrating pre-training objective can improve the</figDesc><table><row><cell>Question Type</cell><cell>BART</cell><cell>Narrator</cell></row><row><cell>Paraphrase+Matching</cell><cell>58.4</cell><cell>66.1 (+7.7)</cell></row><row><cell>Reasoning</cell><cell>42.2</cell><cell>46.2 (+4.0)</cell></row><row><cell>Summary</cell><cell>51.1</cell><cell>53.4 (+2.3)</cell></row><row><cell>Logic</cell><cell>43.8</cell><cell>48.2 (+4.4)</cell></row><row><cell>Commonsense</cell><cell>37.8</cell><cell>41.9 (+4.1)</cell></row><row><cell>Arithmetic</cell><cell>23.8</cell><cell>23.8 (+0.0)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Accuracy by question types on DREAM. effective than the de-noising objective and the discriminative objective. (iii) When compared with different pre-training data, Narrator achieves better performance on all tasks compared with BART-CNN-GEN and BART-CRD3-GEN, demonstrating that DIANA is a more helpful resource for dialogue comprehension.</figDesc><table><row><cell>model's ability of dialogue comprehension. (ii)</cell></row><row><cell>When compared with different pre-training tasks,</cell></row><row><cell>Narrator outperforms BART-DIAL-DE, and BART-</cell></row><row><cell>CNN-GEN outperforms BART-CNN-CLS. This</cell></row><row><cell>indicates that the narrative-guided generative ob-</cell></row><row><cell>jective is more</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We use MovieNet for test purposes only.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We also tried T5 and Pegasus in our early experiments but did not observe better performance compared with BART.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Discourse parsing for multiparty chat dialogues</title>
		<author>
			<persName><forename type="first">Stergos</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Kow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?r?my</forename><surname>Perret</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1109</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="928" to="937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Conversational neuro-symbolic commonsense reasoning</title>
		<author>
			<persName><forename type="first">Forough</forename><surname>Arabshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikayla</forename><surname>Gawarecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Azaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4902" to="4911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical pre-training for sequence labelling in spoken dialog</title>
		<author>
			<persName><forename type="first">Emile</forename><surname>Chapuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Labeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chlo?</forename><surname>Clavel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.239</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2636" to="2648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Can NLI models verify QA systems&apos; predictions?</title>
		<author>
			<persName><forename type="first">Jifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3841" to="3854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MuTual: A dataset for multi-turn dialogue reasoning</title>
		<author>
			<persName><forename type="first">Leyang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.130</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1406" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Leveraging user paraphrasing behavior in dialog systems to automatically collect annotations for long-tail utterances</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Falke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Boese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Tirkaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lehnen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-industry.3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics: Industry Track</title>
		<meeting>the 28th International Conference on Computational Linguistics: Industry Track</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="21" to="32" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SAMSum corpus: A human-annotated dialogue dataset for abstractive summarization</title>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Gliwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iwona</forename><surname>Mochol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maciej</forename><surname>Biesek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Wawer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-5409</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on New Frontiers in Summarization</title>
		<meeting>the 2nd Workshop on New Frontiers in Summarization<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Grusky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mor</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1065</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers; New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="708" to="719" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Movienet: A holistic dataset for movie understanding</title>
		<author>
			<persName><forename type="first">Qingqiu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anyi</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-08-23">2020. August 23-28, 2020</date>
			<biblScope unit="page" from="709" to="727" />
		</imprint>
	</monogr>
	<note>Proceedings, Part IV 16</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MMM: multi-stage multi-task learning for multi-choice reading comprehension</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiun-Yu</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tagyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilek</forename><surname>Hakkani-T?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020-02-07">2020. February 7-12, 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="8010" to="8017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">What is more likely to happen next? videoand-language future event prediction</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Licheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamara</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.706</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8769" to="8784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">Marjan Ghazvininejad,. 2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">OpenSubtitles2018: Statistical rescoring of sentence alignments in large, noisy parallel corpora</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Lison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?rg</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milen</forename><surname>Kouylekov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A graph reasoning network for multi-turn response selection via customized pre-training</title>
		<author>
			<persName><forename type="first">Yongkang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaisong</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feiliang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13433" to="13442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Challenging reading comprehension on daily conversation: Passage completion on multiparty dialog</title>
		<author>
			<persName><forename type="first">Kaixin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Jurczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1185</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2039" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Different strokes for different folks: Investigating appropriate further pre-training approaches for diverse dialogue tasks</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinchao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2318" to="2327" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Storytelling with dialogue: A Critical Role Dungeons and Dragons Dataset</title>
		<author>
			<persName><forename type="first">Revanth</forename><surname>Rameshkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bailey</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.459</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5121" to="5134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1099</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DREAM: A challenge data set and models for dialogue-based reading comprehension</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00264</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="217" to="231" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Aligning plot synopses to videos for story-based retrieval</title>
		<author>
			<persName><forename type="first">Makarand</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>B?uml</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Multimedia Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="16" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">TOD-BERT: Pre-trained natural language understanding for task-oriented dialogue</title>
		<author>
			<persName><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><surname>Xiong</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.66</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="917" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DocNLI: A large-scale dataset for documentlevel natural language inference</title>
		<author>
			<persName><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.435</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4913" to="4922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatically annotate tv series subtitles for dialogue corpus construction</title>
		<author>
			<persName><forename type="first">Leilan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1029" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Structural pretraining for dialogue comprehension</title>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.399</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5134" to="5145" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
