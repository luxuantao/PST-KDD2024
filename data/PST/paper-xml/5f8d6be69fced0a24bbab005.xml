<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dimension Relation Modeling for Click-Through Rate Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zihao</forename><surname>Zhao</surname></persName>
							<email>zhaozihao3@jd.com</email>
						</author>
						<author>
							<persName><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
							<email>fangzhiwei2@jd.com</email>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
							<email>liyong5@jd.com</email>
						</author>
						<author>
							<persName><forename type="first">Changping</forename><surname>Peng</surname></persName>
							<email>pengchangping@jd.com</email>
						</author>
						<author>
							<persName><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
							<email>baoyongjun@jd.com</email>
						</author>
						<author>
							<persName><forename type="first">Weipeng</forename><surname>Yan</surname></persName>
						</author>
						<title level="a" type="main">Dimension Relation Modeling for Click-Through Rate Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3340531.3412108</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems ‚Üí Recommender systems; Computational advertising Neural Networks</term>
					<term>Deep Learning</term>
					<term>Recommendation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Embedding mechanism plays an important role in Click-Through-Rate (CTR) prediction. Essentially, it tries to learn a new feature space with some learned latent properties as the basis, and maps the high dimensional and categorical raw data to dense, rich and expressive representations, i.e., the embedding features. Current researches usually focus on learning the interactions through operations on the whole embedding features without considering the relations among the learned latent properties. In this paper, we find it has clear positive effects on CTR prediction to model such relations and propose a novel Dimension Relation Module (DRM) to capture them through dimension recalibration. We show that DRM can improve the performance of existing models consistently and the improvements are more obvious when the embedding dimension is higher. We further boost Field-wise and Element-wise embedding methods with our DRM and name this new model FED network. Extensive experiments demonstrate that FED is very powerful in CTR prediction task and achieves new state-of-the-art results on Criteo, Avazu and JD.com datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Click-Through-Rate (CTR) prediction plays a primary role in industry advertising system. It reflects the probability of an ad to be clicked on and influences the rank of items in advertising system. Thus, the accuracy of CTR prediction usually makes a direct effect on final revenue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sparse Binary Features</head><p>Dense Embedding Features One challenge in CTR prediction is that the input variables are mostly discrete and categorical, leading to a large and sparse feature space. A common practice is to transform the data into highdimensional sparse binary feature via one hot encoding and apply linear models such as logistic regression to make predictions. Although linear model is fast and simple, it's hard to capture highorder interactions under the linear assumption. Thus, embedding method is proposed to project each sparse and discrete source feature into a dense embedding feature with a fixed length. With the dense representations, more complicate models can be applied to learn potential patterns of feature interactions without much effort in hand-craft feature design. Meanwhile, embedding based methods have the ability to improve model generalization and explore different level (low-order or high-order) feature interactions thus making it the base of many models in CTR prediction, <ref type="bibr">[1, 3-6, 8, 10]</ref>. Now, let's review the embedding mechanism from the view of feature space transformation. In the raw feature space, a sample is represented by its responses on a series of fields, such as Location, Gender, Time or Click. Namely, the basis of raw feature space is a set of fields. Since the responses on these fields are usually discrete and categorical, the raw features (in one hot format) are also discrete, sparse and high-dimensional. The embedding mechanism assumes that each categorical field can be mapped into a new feature space whose basis is a series of some latent fields. These latent fields are continuous, unknown but learnable. Usually, the raw fields are not independent, thus it's effective to learn information from their interactions, such as low-order interactions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref> or high-order interactions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Similarly, in the embedding feature space, the learned latent fields are also in high probability dependent since there is no constraint to force the basis of the space to be orthogonal. However, current researches only model the interactions among the raw fields without deep research on the relations among latent fields in embedding feature space.</p><p>In this paper, we aim to explicitly model such relations to improve CTR prediction. Specifically, we propose a novel module based on dimension recalibration and self-attention mechanism <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref> to learn the relations among latent fields. Since each latent field corresponds to a specific dimension in the embedding feature space, we name our module Dimension Relation Module (DRM). Our experimental results show that the proposed DRM module can catch extra useful information for CTR prediction and boost the performance of existing state-of-the-art methods such as <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref>, especially when the size of embedding dimension is high.</p><p>The main contributions of this paper are concluded as follows:</p><p>‚Ä¢ We find it's useful for CTR prediction to model the relations of latent fields in embedding space and propose a novel module named DRM to capture such relations. DRM is easily incorporated into existing methods to learn more powerful embedding representations, leading to better performance, especially when the dimension of embedding space is high. ‚Ä¢ We design FED network based on DRM, which takes the advantage of field-wise and element-wise modeling simultaneously to learn interactions explicitly and implicitly. ‚Ä¢ We conduct extensive experiments on several datasets like Criteo, Avazu and JD.com datasets. Experimental results demonstrate the superiority over the state-of-art models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD 2.1 Feature Embedding</head><p>In advertising systems, the input samples are sparse, of huge dimension and containing response values on a series of categorical fields. The field-aware one-hot encoding is a widely used form in current related works to present such data.</p><p>Embedding mechanism maps the one-hot vector of each field to a d-dimensional dense vector, i.e., the embedding feature. Let</p><formula xml:id="formula_0">v i = [v i,1 , v i,2 , ..., v i,d ] T ‚àà R d denote</formula><p>the embedding feature for i th field, then after embedding, an input sample is described as:</p><formula xml:id="formula_1">V = [v 1 , v 2 , ..., v i , ..., v m ] T<label>(1)</label></formula><p>where V ‚àà R m√ód and m is the number of fields in source features.</p><p>In embedding feature space, each dimension stands for one of the d learned latent fields. Then the representation of i t h dimension is</p><formula xml:id="formula_2">u i = [v 1,i , v 2,i , ..., v m,i ] T ‚àà R m . Let U = [u 1 , u 2 , ..., u d ] T , the relation between U and V is obvious: U = V T ‚àà R d√óm<label>(2)</label></formula><p>From Eq.2, we have some insight into embedding feature v i and dimension feature u i . For a specific v i , it recodes the response values of the corresponding field on all latent fields, while a u i reflects different fields' behaviors on a single latent fields. Unlike the raw fields, it's hard to assign a clear and unique semantic nature word such as Location or Gender to each latent field, while u i provides another observation for each of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dimension Relation Module</head><p>We propose a module named Dimension Relation Module (DRM) based on attention mechanism. DRM helps to learn sample-level enhanced embedding vectors, which selectively emphasizes specific dimensions and suppress less useful ones for the given task. Specifically, self attention is preferred to determine the importance and relations among dimensions, then we elaborate the process to adaptively aggregate dimension information.</p><formula xml:id="formula_3">‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ V ‚àà ùëÖ m√óùëë input ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ùëáùëüùëéùëõùëùùëúùë†ùëí ‚Ä¶ ‚Ä¶ ‚Ä¶ ‚Ä¶ ùëÜ ‚àà ùëÖ ùëë√óùëë ùëÜùëúùëìùë°ùëöùëéùë• ùê∏ ‚àà ùëÖ ùëö√óùëë : Matrix multiplication : Element-wise sum</formula><p>The DRM module is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Given the dimension feature matrix U ‚àà R d√óm , the dimension attention map matrix S ‚àà R d√ód can be achieved by:</p><formula xml:id="formula_4">S = so f tmax((UW Œ∏ )(UW œï ) T )<label>(3)</label></formula><p>where W Œ∏ , W œï ‚àà R m√óm is the transform matrix. Each entry S ji in S measures the i t h dimension's impact on j t h dimension. Then embedding vectors can be enhanced by performing the attention map matrix to the origin input as follows:</p><formula xml:id="formula_5">E = (W Œ¥ V)S<label>(4)</label></formula><p>where W Œ¥ ‚àà R m√óm is the transform matrix to original input. For better optimization, the residual connection is added to the attention embedding vectors like Resnet, and the final form of DRM is as follows:</p><formula xml:id="formula_6">E = (W Œ¥ V)S + V<label>(5)</label></formula><p>We can see that the output E at each dimension is a weighted sum of the vectors of all dimension and original embeddings, where the weight is determined by the similarity of dimensions. Thus, if a dimension is important, it would generate more impact on E and finally contribute more to the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">FED Network</head><p>The framework of FED-net is shown in Fig. <ref type="figure" target="#fig_2">3</ref>, the origin embedding V is first passed through DRM, which helps to learn more powerful embedding representation by explicitly modeling relations among dimensions. FED-net models the complex interactions among features from multiple levels, including the field-wise and element-wise. The predicted value ≈∑ for a given sample is as follows:</p><formula xml:id="formula_7">≈∑ = œÉ ([x dim ; x f ield ; x el ement ] T w lo–¥ist ic )<label>(6)</label></formula><p>where œÉ (x) = 1/(1 +exp(‚àíx)) is the sigmoid function, x dim ‚àà R dm is the vectorized output of DRM module, x f ield ‚àà R dm is the vectorized output of field-wise module, x el ement ‚àà R l is the output of element-wise module and w lo–¥ist ic ‚àà R 2md+l is the weight for the logistic layer. Then the loss function is defined as:</p><formula xml:id="formula_8">loss = ‚àí 1 N N i=1 y i lo–¥( ≈∑i ) + (1 ‚àí y i )lo–¥(1 ‚àí ≈∑i ) (7)</formula><p>where y i is the ground truth label for the given sample i, and N is the size of training dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Field-wise Module.</head><p>Field information is an explicit description for a given sample. Different samples are supposed to pay attention to different fields and its interactions for the given task <ref type="bibr" target="#b10">[11]</ref>. We propose to utilize attention mechanism to model field-wise feature interactions.</p><p>In the field-wise module, we first perform matrix multiplication between the output embedding E of DRM and its transpose E T . Then a softmax function is applied to calculate the field attention map H ‚àà R m√óm . H ji is computed by:</p><formula xml:id="formula_9">H = so f tmax((EW Œ∏ 1 ) ‚Ä¢ (EW œï 1 ) T )<label>(8)</label></formula><p>where W Œ∏ 1 , W œï 1 ‚àà R d√ód is the tranform matrix, and H ji measures the i th field's impact on j t h field. Thereafter, the field attention map H applies to the embedding vectors E to enhance field information, and identity term is added. Then, the output F of field-wise module is:</p><formula xml:id="formula_10">F = H(EW Œ¥ 1 ) +<label>(9)</label></formula><p>where W Œ¥ 1 ‚àà R d√ód is the transform matrix to original input. With such structure of layer, each field feature will be updated into a high-order feature which takes the field interactions into account. Therefore, we can model certain order combinatorial features by stacking multiple layers. Finally, the output F of final layer is vectorized into x f ield .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Element-wise Module.</head><p>The element-wise module is a feedforward DNN network. The output embedding vectors of DRM are vectorized into a one-dimension vector, and fed into the hidden layers of DNN network. Specifically, for the l t h hidden layer, computation is performed as:</p><formula xml:id="formula_11">h l +1 = f (W l h l + b l ) (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>where h l is the input of the l t h hidden layer, and h l +1 is the output of the l th hidden layer. W l is the weight matrix and b l is bias   at l t h layer, and f is the activation function which is chosen as rectified linear units (ReLU). The output of last layer is vectorized to x el ement .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENT 3.1 Datasets</head><p>We conduct our experiments on two public datasets Criteo, Avazu and one commercial dataset JD.com. Criteo and Avazu are both popular industry benchmarking datasets for predicting ads CTR.</p><p>For thees two datasets, data is randomly split into three parts, where 80% samples are used for training, and 10% for validation and the 10% for testing.</p><p>JD.com Dataset: The JD.com dataset covers a period of 9 days, where the first 8 days are used for training, and the last day is for validation and testing. Finally there are 82 million samples for training, 5 million for validation and 5 million for testing. Each sample has 20 categorical features including user information, item information and context information (city, request time and so on).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dimension Relation Module</head><p>In this section, we validate the effectiveness of DRM in boosting element-wise model (DNN) and field-wise model (Field Attention Network). Furthermore, we perform experiments with different embedding sizes, and experimental results show that improvement of DRM is consistent, and DRM achieves more remarkable improvement when embedding size is high.</p><p>Firstly, we show experiments of DRM with DNN network and Field Attention Network on the Criteo dataset in Table <ref type="table" target="#tab_0">1</ref>. We find that both architectures get improvements in AUC and decreases  <ref type="bibr" target="#b0">[1]</ref> 0.8076 0.4436 0.7869 0.3755 0.6685 0.1432 AFM <ref type="bibr" target="#b10">[11]</ref> 0.8038 0.4478 0.7817 0.3792 0.6618 0.1457 DeepFM <ref type="bibr" target="#b2">[3]</ref> 0.8091 0.4423 0.7878 0.3753 0.6708 0.1372 DCN <ref type="bibr" target="#b9">[10]</ref> 0.8093 0.4420 0.7875 0.3759 0.6702 0.1361 PNN <ref type="bibr" target="#b6">[7]</ref> 0.8094 0.4414 0.7879 0.3752 0.6705 0.1360 xDeepFM <ref type="bibr" target="#b4">[5]</ref> 0.8096 0.4412 0.7877 0.3753 0.6710 0.1356 FGCNN <ref type="bibr" target="#b5">[6]</ref> 0.8093 0.4422 0.7878 0.3752 0.6709 0.1361 FED (Ours) 0.8113 0.4403 0.7889 0.3748 0.6735 0.1341 in LogLoss, which indicates that DRM can learn extra information from dimension relations for CTR prediction. It should be explained that increase at 10 ‚àí3 level in Criteo dataset is already clear compared with recent works such as xDeepFM <ref type="bibr" target="#b4">[5]</ref> and DCN <ref type="bibr" target="#b9">[10]</ref>.</p><p>Since DRM learns the relations of dimensions in embedding features space, its performance is affected by the number of dimensions, i.e., the embedding size. The experiments are summarized in Fig. <ref type="figure" target="#fig_4">4</ref>. From Fig. <ref type="figure" target="#fig_4">4</ref>, we have the following observations when dimension increases: 1) the performance of DNN increases very marginally and even becomes worse if dimension is higher than 35; 2) DNN with DRM keeps increases all the time; 3) the margin between the two curves keeps growing. Similar phenomena can also be found in Field Attention Network without/with DRM in Fig. <ref type="figure" target="#fig_4">4</ref>. This indicates that DRM can boost different architectures and improve their learning capacity. The reason is that higher dimensions can enhance the expression of embedding features but will introduce noise and cause hard optimization, while our DRM alleviates such problem by applying enhancement and suppression operations on embedding features with the learned dimension relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">FED Network</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Ablation Experiments.</head><p>In FED network, there are three core modules, i.e., DRM, element-wise module and field-wise module, to contribute to the final prediction. In order to analyze their effects, we conduct an ablation study which is summarized in Tab.2. From the results, we can have the following observations. Firstly, elementwise module outperforms field-wise module, which means that element-wise transformation still plays an essential role in CTR prediction although it is simple. Secondly, when further using DRM, the FED network achieves the best performance, which indicates that the dimension relation has positive effectives and the three modules complement each other in FED network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Comparison to the State-of-the-art.</head><p>The performance of different models is listed in Tab.3. On Criteo dataset, we observe that LR is far worse than all the rest models, which demonstrates that embedding-based models are essential for measuring sparse features. W&amp;D, DeepFM, DCN, PNN, xDeepFM, FGCNN and FED are significantly better than FM, which directly reflects that deep learning is important for boosting the accuracy. Besides, as a useful practice in CTR prediction, incorporating hybrid components is used nearly in all the deep learning based models. Our proposed FED achieves the best performance with a clear margin, which verifies that learning the dimension relations in embedding space is another effective way to enhance CTR prediction.</p><p>To further ensure the generality of above conclusion, we conduct the comparisons on another two datasets: Avazu and JD.com, and the results are shown in Tab. <ref type="bibr" target="#b2">3</ref>. We can see that, in all three datasets, our FED outperforms other models, which again demonstrates that FED can integrate different level information to improve the accuracy of CTR prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>In this paper, we propose a novel module to model dimension relations named DRM. DRM helps to learn sample-level enhanced embedding vectors, which selectively emphasizes specific features and suppress less useful ones for the given task. DRM can be easily incorporated into the existing methods to boost their performance. Furthermore, we propose a unified model FED-net based on DRM, which models field-wise network and element-wise network jointly. Extensive experiments on three real-world datasets demonstrate the effectiveness of FED-net.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Feature Interaction and Dimension Relation. The former learns the relations among raw categorical fields while the latter models relations among the learned latent dense fields.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overview architecture of DRM. We omit the transform matrix for simplicity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The overview architecture of FED-net.</figDesc><graphic url="image-1.png" coords="3,317.69,185.23,127.29,65.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( a )</head><label>a</label><figDesc>Impact of DRM on DNN (b) Impact of DRM on Field Attention Network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Impact of DRM on Criteo dataset while dimension number increases.</figDesc><graphic url="image-3.png" coords="3,320.09,257.68,124.88,65.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>DRM boosting DNN and Field Attention Network on Criteo dataset.</figDesc><table><row><cell>Model</cell><cell>AUC</cell><cell>Logloss</cell></row><row><cell>DNN</cell><cell>0.8073</cell><cell>0.4439</cell></row><row><cell>DNN+DRM</cell><cell>0.8084</cell><cell>0.4429</cell></row><row><cell>Field Attention</cell><cell>0.8060</cell><cell>0.4453</cell></row><row><cell>Field Attention + DRM</cell><cell>0.8073</cell><cell>0.4441</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Ablation experiments about different modules.</figDesc><table><row><cell>Model</cell><cell>AUC</cell><cell>Logloss</cell></row><row><cell>Element-wise Module</cell><cell>0.8073</cell><cell>0.4439</cell></row><row><cell>Only Field-wise Module</cell><cell>0.8060</cell><cell>0.4421</cell></row><row><cell>Element-wise &amp; Field-wise</cell><cell>0.8094</cell><cell>0.4453</cell></row><row><cell>FED</cell><cell>0.8113</cell><cell>0.4403</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Performances on three Datasets.</figDesc><table><row><cell></cell><cell>Criteo</cell><cell>Avazu</cell><cell>JD.com</cell></row><row><cell>Model</cell><cell cols="3">AUC Logloss AUC Logloss AUC Logloss</cell></row><row><cell>LR</cell><cell cols="3">0.7948 0.4553 0.7713 0.3849 0.6495 0.1494</cell></row><row><cell>FM</cell><cell cols="3">0.8025 0.4496 0.7804 0.3805 0.6609 0.1460</cell></row><row><cell>W&amp;D</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Heng-Tze</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levent</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremiah</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishi</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glen</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Ispir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st workshop on deep learning for recommender systems</title>
				<meeting>the 1st workshop on deep learning for recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">DeepFM: a factorization-machine based neural network for CTR prediction</title>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04247</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fieldaware factorization machines for CTR prediction</title>
		<author>
			<persName><forename type="first">Yuchin</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Sheng</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
				<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">xDeepFM: Combining explicit and implicit feature interactions for recommender systems</title>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongxia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangzhong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1754" to="1763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Feature generation by convolutional neural network for click-through rate prediction</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinkai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhou</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1119" to="1129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Product-Based Neural Networks for User Response Prediction over Multi-Field Categorical Data</title>
		<author>
			<persName><forename type="first">Yanru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minzhe</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Factorization machines</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Data Mining. IEEE</title>
		<imprint>
			<biblScope unit="page" from="995" to="1000" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">≈Åukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep &amp; cross network for ad click predictions</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingliang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ADKDD&apos;17</title>
				<meeting>the ADKDD&apos;17</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Attentional factorization machines: Learning the weight of feature interactions via attention networks</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>Hao Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Chua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04617</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
