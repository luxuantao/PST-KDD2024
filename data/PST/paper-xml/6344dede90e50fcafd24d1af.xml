<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Noise-Robust De-Duplication at Scale</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-10">October, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Emily</forename><surname>Silcock</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luca</forename><surname>D'amico-Wong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinglin</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Melissa</forename><surname>Dell</surname></persName>
							<email>melissadell@fas.harvard.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Noise-Robust De-Duplication at Scale</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-10">October, 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2210.04261v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying near duplicates within large, noisy text corpora has a myriad of applications that range from de-duplicating training datasets, reducing privacy risk, and evaluating test set leakage, to identifying reproduced news articles and literature within large corpora. Across these diverse applications, the overwhelming majority of work relies on N -grams. Limited efforts have been made to evaluate how well N -gram methods perform, in part because it is unclear how one could create an unbiased evaluation dataset for a massive corpus. This study uses the unique timeliness of historical news wires to create a 27,210 document dataset, with 122,876 positive duplicate pairs, for studying noise-robust de-duplication. The time-sensitivity of news makes comprehensive hand labelling feasible -despite the massive overall size of the corpus -as duplicates occur within a narrow date range. The study then develops and evaluates a range of de-duplication methods: hashing and N -gram overlap (which predominate in the literature), a contrastively trained bi-encoder, and a "re-rank" style approach combining a bi-and cross-encoder. The neural approaches significantly outperform hashing and N -gram overlap. We show that the bi-encoder scales well, de-duplicating a 10 million article corpus on a single GPU card in a matter of hours. The public release of our NEWS-COPY de-duplication dataset will facilitate further research and applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Robust identification of near-duplicate texts in large, noisy corpora is important for a variety of applications. Duplication in training data degrades model performance <ref type="bibr" target="#b18">Lee et al. [2021]</ref> and can also raise serious privacy risks: <ref type="bibr" target="#b15">Kandpal et al. [2022]</ref> show that there is a superlinear relationship between a sequence's count and the rate at which language models regenerate training sequences, with a sequence appearing 10 times in training data being a thousand times more likely to be regenerated than a sequence appearing only once. Additionally, the presence of test set leakage complicates evaluation of model performance, concerns that are elevated with large language models that have greater capacity to memorize training data or can consult an external database. In introducing the retrieval-enhanced transformer model, <ref type="bibr" target="#b2">Borgeaud et al. [2022]</ref> conclude: "Further work is yet needed to better understand the role of test set leakage in the performance of LMs." Patterns of duplication are also themselves of interest, for studying the dissemination of reproduced content such as literature or news <ref type="bibr" target="#b4">[Cordell, 2015</ref><ref type="bibr" target="#b26">, Smith et al., 2015</ref><ref type="bibr" target="#b29">, Vesanto et al., 2017]</ref>.</p><p>In contrast to the literature on semantic textual similarity, where deep neural architectures predominate -e.g. <ref type="bibr" target="#b23">Reimers and Gurevych [2019]</ref> -text de-duplication overwhelmingly uses N -gram methods. There have been few efforts to formally evaluate the adequacy of N -gram based de-duplication or to explore potential performance gains from neural text de-duplication. This study builds a large de-duplication dataset and develops neural methods for robust textual de-duplication that significantly outperform N -gram based methods and scale efficiently.</p><p>A major hurdle to overcome in systematically studying text de-duplication is the lack of data for an unbiased evaluation of different methods. Typically, there is no way to exhaustively identify all duplicates of a given example in a large corpus, complicating comparisons of recall.</p><p>To circumvent this challenge, we examine duplication in a unique context: historical news. Reproduction of news from news wires and syndicate services was widespread, forming over half the content of U.S. local newspapers. Media historian Julia <ref type="bibr" target="#b8">Guarneri [2017]</ref> writes: "by the 1910s and 1920s, most of the articles that Americans read in their local papers had either been bought or sold on the national news market... This constructed a broadly understood American 'way of life' that would become a touchstone of U.S. domestic politics and international relations throughout the twentieth century." Because news is timely, reproduction happens within a narrow time window, and hence annotators can exhaustively identify all duplicates despite the massive overall size of the corpus. To build an unbiased evaluation sample, highly skilled human annotators manually reviewed every front page article from 973 newspapers on four randomly chosen days in <ref type="bibr">1930, 1955, and 1974</ref> to create clusters of duplicated articles (including all singletons). Additional data, spanning the period from 1920 to 1977, were compiled for model training. The resulting public NEWS-COPY dataset -which contains 27,210 articles, comprising 122,876 positive duplicate pairs -aims to encourage further study of robust de-duplication.</p><p>In the absence of evaluation data, the literature has largely assumed that text de-duplication is sufficiently simple that neural methods are not required. However, noise -rampant in user-generated or OCR'ed textscan lead near duplicate documents to have low N -gram similarity. Amongst duplicated pairs of articles in the NEWS-COPY test set, the average number of 3-grams (4-grams, 5-grams) shared between pairs of reproduced articles, normalized by the number of N -grams in the shorter article, is 56% (50%, 45%). 19% of duplicates have no 10-grams in common and 31% have no 15-grams in common, often as a result of minor text noise. Neural methods are plausibly more robust in the presence of noise, which is a common feature of large text corpora more generally.</p><p>Using the NEWS-COPY dataset, we examine different text de-duplication methods that vary along two key dimensions: whether or not the method is neural and computational cost. Drawing inspiration from work on semantic textual similarity and on retrieval, we develop two approaches for neural text de-duplication: a contrastively trained bi-encoder plus clustering method and a 'reranking' style method, which uses a computationally cheap transformer bi-encoder to measure the pairwise similarity between all articles and then passes each article's nearest neighbors to a cross-encoder, at an additional computational cost. We also examine N -gram overlap and locally sensitive hashing, the latter of which is highly scalable. The neural methods significantly outperform the non-neural approaches. The Adjusted Rand Index (ARI) for the re-rank model is 93.7 and for the bi-encoder model is 91.5, versus 73.7 for LSH.</p><p>While the primary advantage of hashing -and a central motivation for its frequent usage -is its scalability, massive scale similarity search <ref type="bibr" target="#b14">[Johnson et al., 2019]</ref> is sufficiently cheap on modern GPUs to make neural deduplication highly scalable. We use our contrastively-trained bi-encoder and a single NVIDIA 40GB A6000 GPU card to de-duplicate a 10 million document, 19 GB corpus in 11 hours and 45 minutes. While this cost is already marginal in the context of working with large text corpora, it could be reduced significantly further by using a lighter weight language model, as the majority of the time cost is embedding the 10M articles.</p><p>The large performance gains of our highly scalable neural approach do come at the cost of needing data to train the supervised bi-encoder. The publicly available NEWS-COPY dataset and our neural de-duplication models can be applied off-the-shelf or provide a starting point for using active learning to obtain training data for novel de-duplication problems.</p><p>The rest of this paper is organized as follows: Section 2 provides an overview of the de-duplication literature, as well as related problems in semantic textual similarity and retrieval. Section 3 describes the NEWS-COPY dataset, and Section 4 develops neural de-duplication methods and outlines their non-neural comparisons. Section 5 evaluates the performance of different de-duplication methods, and Section 6 explores scaling to a 10 million article corpus. Finally, Section 7 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Literature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">De-Duplication</head><p>Textual de-duplication is a fundamental task for curating the large text corpora that support the deep learning revolution. <ref type="bibr" target="#b18">Lee et al. [2021]</ref> review the de-duplication literature, providing evidence that duplication in training datasets is widespread: e.g. <ref type="bibr" target="#b7">Dodge et al. [2021]</ref> find up to 14.4% of test examples of various standard benchmarks verbatim in C4 and <ref type="bibr" target="#b1">Bandy and Vincent [2021]</ref> document that the Books Corpus <ref type="bibr" target="#b32">[Zhu et al., 2015]</ref> -used in training BERT <ref type="bibr" target="#b6">[Devlin et al., 2018]</ref>, GPT <ref type="bibr" target="#b3">[Brown et al., 2020]</ref>, and other large language models -contains 4,255 unique books and 2,930 books that are exactly duplicated at least once. When training LMs that are either very large or can consult an external database, test set leakage becomes a particularly salient concern <ref type="bibr" target="#b2">[Borgeaud et al., 2022]</ref>.</p><p>Non-neural methods predominate in textual de-duplication <ref type="bibr" target="#b19">[Leskovec et al., 2020]</ref>. <ref type="bibr" target="#b2">Borgeaud et al. [2022]</ref> compute 13-gram Jaccard similarity between train and test documents using MinHashing and remove all training documents with 0.8 similarity or higher to validation/test documents. <ref type="bibr" target="#b22">Radford et al. [2019]</ref> use 8-gram overlaps for post-hoc identification of duplication between GPT-2's training data and evaluation datasets, and <ref type="bibr" target="#b3">Brown et al. [2020]</ref> remove from the GPT-3 training data any example with a 13-gram overlap with an evaluation example, documenting widespread contamination. They also de-duplicate each component dataset of the training data using MinHashing with 10 hashes. This reduces the training corpus size by 10%, underscoring that duplication is widespread. Other de-duplication contexts include large datasets of medical notes <ref type="bibr" target="#b25">[Shenoy et al., 2017]</ref> and scholarly articles (which can include updates) <ref type="bibr" target="#b9">[Gyawali et al., 2020]</ref>, both of which have been examined with locally sensitive hashing.</p><p>Identifying reproduced texts within historical newspapers is itself an application that has generated considerable interest. The Viral Texts Project <ref type="bibr" target="#b4">[Cordell, 2015</ref><ref type="bibr" target="#b26">, Smith et al., 2015]</ref> uses N -gram comparisons to track the dissemination of reproduced literature in antebellum newspapers. Viral Texts utilizes the Chronicling America <ref type="bibr" target="#b5">[Culpepper, 2007]</ref> OCR of historical U.S. newspaper scans, which does not recognize individual articles, headlines, captions, etc., typically reading a multi-column newspaper page with many different text objects as if it were a single column book. This leads to scrambled up texts. We first apply object detection methods to the document layouts <ref type="bibr" target="#b11">[He et al., 2017</ref><ref type="bibr" target="#b24">, Shen et al., 2021]</ref> to extract structured texts of individual articles. These structured texts then allow us to capture performance gains from the language understanding of neural methods. <ref type="bibr" target="#b29">Vesanto et al. [2017]</ref> use NCBI BLAST, a software for comparing and aligning biological sequences, to quantify text reproduction in Finish newspapers from 1771 to 1910. They remove all characters besides the 23 most common letters from an uncased corpus of Finish newspapers, and then convert these to the alphabet of 23 amino acids recognized by BLAST. BLAST is used to make pairwise comparisons between all documents in the corpus, indicating which pairs have text overlap. They average the start and ending of passages that overlap by at least 80% to get consensus passages, create a graph connecting consensus passages, and use a community detection algorithm to remove false positives. We likewise find that community detection can help control false positives. To scale the problem, we use hashing -which avoids the need to convert texts into amino acid sequences -or a contrastively trained bi-encoder -which leverages the power of deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic Textual Similarity</head><p>There are important parallels between semantic textual similarity (STS) and textual de-duplication. Notably, our bi-encoder method draws inspiration from Sentence BERT (S-BERT) <ref type="bibr" target="#b23">Reimers and Gurevych [2019]</ref>, and we use an S-BERT pre-trained bi-encoder as our base language model. S-BERT adds a pooling operation to BERT/RoBERTa embeddings -that takes the mean of all output vectors -to derive a fixed sized sentence embedding that can then be examined with clustering methods.</p><p>While STS tasks are sometimes framed in terms of duplicates -such as detecting duplicate Quora questions semantic duplicates are different than near textual duplicates. In STS tasks, the aim is to compute how similar texts are in meaning even when their wordings are very different, whereas the textual de-duplication literature aims to detect texts that are worded similarly. We show that an off-the-shelf S-BERT STS model significantly underperforms our neural de-duplication methods -as expected given that S-BERT is not intended for textual de-duplication -although interestingly it performs in the same ballpark as N -gram methods. If our goal was solely to identify exact duplicates, neural methods would not be needed. However, the presence of significant noise makes textual de-duplication a more challenging problem than it might appear at first glance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Retrieval</head><p>We draw inspiration for our reranking approach from the literature on open domain retrieval and question answering <ref type="bibr" target="#b30">[Wang et al., 2018</ref><ref type="bibr" target="#b20">, Lin et al., 2018</ref><ref type="bibr" target="#b16">, Karpukhin et al., 2020</ref><ref type="bibr" target="#b28">, Thakur et al., 2021</ref><ref type="bibr">, Wu et al., 2019]</ref>. This literature avoids the infeasible quadratic cost of applying a cross-encoder to a massive corpus by first ranking documents with a bi-encoder (or with sparse methods). Each document representation needs to be computed only once and can be stored offline, for comparison to any query vector. The passages that are closest to a given query are then passed to a cross-encoder, which jointly embeds the passage and query in order to compute cross-attention between them. In our re-ranking model, instead of a passage encoder and a query encoder, there is a symmetric bi-encoder. Like <ref type="bibr" target="#b16">Karpukhin et al. [2020]</ref>, we use Facebook AI Similarity Search (FAISS) <ref type="bibr" target="#b14">[Johnson et al., 2019]</ref> to select nearby document pairs to evaluate with cross-attention.</p><p>3 The NEWS-COPY Dataset</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Reproduction in News</head><p>Reproduction is an important feature of news. News wire services distribute stories written by their own news bureaus and by member newspapers to member news outlets, whereas syndicates disseminate to their subscribers columns written by freelance journalists or purchased from newspapers. The nation's largest newspapers also ran syndicate services to redistribute their own stories. The main news wire services in the United States historically were the Associate Press (AP), the United Press (UP), and William Randolph Hearst's International News Service (INS), the latter two of which merged to form United Press International (UPI) in 1958. <ref type="bibr" target="#b0">Angelucci et al. [2020]</ref> document that in the 1950s, about two thirds of U.S. daily newspapers subscribed to the AP, 45% to the UP, and 15% to the INS (papers could subscribe to more than one wire).</p><p>Editing could take place at multiple places along the news wire transmission chain. News wire articles were written by local members, by wire staff reporters, and by foreign news services. Wire staff verified and edited stories after receiving them from members, and then stories could be edited again by local wire bureaus, of which there were around 100 for the Associated Press. Finally, local newspapers could further abridge content to fit space requirements. This leads to a range of near-duplicates in the presence of abridgement. For evaluating N -gram methods, we define similarity such that abridgements and truncations are not punished. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Description of the NEWS-COPY Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Procedure For Building the Dataset</head><p>To build NEWS-COPY, we first apply Layout Parser <ref type="bibr" target="#b24">[Shen et al., 2021]</ref> with a custom-trained object detection model <ref type="bibr" target="#b11">[He et al., 2017]</ref> to front page scans of off-copyright historical newspapers to identify individual article bounding boxes. The contents of article bounding boxes are OCR'ed with Tesseract. When component bounding boxes span multiple columns on the same page, the OCR'ed texts are associated into full articles using a rule-based association method that exploits the coordinates of headline and article bounding boxes. This pipeline extracts the structured article texts. Headlines were chosen by local newspapers -not wires -and as a result are rarely reproduced and not included in the dataset. Weather forecasts are removed by running a distil-RoBERTa classifier trained on 392 labeled articles (179 positive, 202 negative). We also hand-removed documents containing incorrectly merged article bounding boxes from different underlying source articles (as there was no single ground truth cluster to which these articles belonged), and news summaries, which summarize multiple news stories in a single article and hence also have no clear cluster with which they are associated.</p><p>Duplicates are defined as articles that came from the same underlying news wire or syndicate source, regardless of the degree of abridgement or OCR noise. Articles from different sources that contain the same quote are labeled as non-duplicated, as are articles about the same event from different news wire sources.</p><p>Likewise, articles updated to reflect breaking news are labeled as different.</p><p>To construct the full-day samples, we first ran 5-gram overlap with a very conservative N -gram overlap threshold of 1% to create large candidate duplicate clusters. Highly trained student research assistants carefully reviewed these clusters, breaking false positive links. Congruence labeling between two annotators was used to ensure that annotators understood the definition of a duplicated article. Next, annotators reviewed each of the resulting clusters to merge together clusters as needed. Finally, annotators exhaustively reviewed every singleton article, associating them with article clusters as needed. Articles were sorted by byline (recognized with a custom-trained named entity recognition model) to facilitate this process. For building the training data, the approach was similar, which provides hard negatives. We did not review all singletons, as the aim was to produce labeled batches for constrastive training. About two thirds of the negative pairs in the training data are hard negatives, with the remaining third coming from randomly selected article pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model Architectures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Bi-Encoder Model</head><p>We contrastively train a symmetric bi-encoder to learn similar representations for near duplicate articles and dissimilar representations for non-duplicated articles. We use an S-BERT MPNET model <ref type="bibr">[Reimers and</ref><ref type="bibr">Gurevych, 2019, Song et al., 2020]</ref> contrastively trained on over a billion sentence pairs -drawn from STS datasets -as the base language model. The S-BERT architecture pools representations for up to the first 512 tokens in each article, using mean pooling, to construct a document level representation. Like <ref type="bibr" target="#b23">Reimers and Gurevych [2019]</ref>, we found when experimenting with vanilla RoBERTa embeddings -which also perform well on de-duplication -that mean pooling of each of the representations significantly outperforms using the [CLS] token to represent the document. S-BERT provides a speed-optimized implementation of this pooling strategy. We chose the MPNET S-BERT because it performs best overall on STS benchmarks.</p><p>We use S-BERT's online contrastive loss <ref type="bibr" target="#b10">[Hadsell et al., 2006]</ref> implementation, with a 0.2 margin and cosine similarity distance. The learning rate is 2e-5 with 100% warm up and a batch size of 32. We use an AdamW optimizer, and the model is trained for 16 epochs.</p><p>The bi-encoder dense document representations can be clustered to identify duplicates. We use FAISS <ref type="bibr" target="#b14">[Johnson et al., 2019]</ref> to compute all embeddings within a given distance range, a hyperparameter tuned on the full-day validation sample. This output is used to build a graph, where nodes are articles and edges connect articles within the threshold distance. Connected components can be extracted to define clusters -which is equivalent to single linkage clustering -or Louvain community detection can be applied to the graph to control false positive edges that can merge otherwise disparate groups of articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Re-Ranking Model</head><p>While a cross-encoder can offer the most flexible, expressive comparisons between texts, it requires N<ref type="foot" target="#foot_1">2</ref> embeddings to compare N texts. In the 10M article corpus explored in Section 6, a cross-encoder would require 10 14 embeddings, well beyond the feasibility of current technology.</p><p>To make the use of a cross-encoder feasible, we draw inspiration from the retrieval literature <ref type="bibr" target="#b30">[Wang et al., 2018</ref><ref type="bibr" target="#b20">, Lin et al., 2018</ref><ref type="bibr" target="#b16">, Karpukhin et al., 2020</ref><ref type="bibr" target="#b28">, Thakur et al., 2021</ref><ref type="bibr">, Wu et al., 2019]</ref> by first ranking document similarity with a bi-encoder, and then passing only the most similarly ranked documents to a cross-encoder. This approach, while not as cheap as simply clustering the bi-encoder embeddings, can still scale to a significant extent. We test whether it offers additional performance gains over using a bi-encoder alone.</p><p>For the baseline re-ranking model, we choose a threshold for the bi-encoder outputs of 0.92, optimized using the one-day validation sample. We use RoBERTa-base <ref type="bibr" target="#b21">[Liu et al., 2019]</ref> as the base language model, with a 2e-5 learning rate and an AdamW optimizer. It is trained for 5 epochs with 20% warmup and a batch size of 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">N-gram Methods</head><p>We explore two different N -gram methods, one which relies on full computation of N -gram overlaps as well as locality-sensitive hashing (LSH), or fingerprinting. For both methods, we first shingle each article into N -grams, where N ? {3, 4, 5, 10, 15}. Uncommon punctuation marks are removed from the text of the article during pre-processing.</p><p>While traditional N -gram approaches to de-duplication often rely on a computation of the Jaccard similarity between two documents, defined for two documents A, B as |A?B| |A?B| , we modify this metric of similarity for our use case, instead defining the "overlap" between two documents as |A?B| min <ref type="bibr">(|A|,|B|)</ref> . This has the desirable property that abridgements and truncations, common in NEWS-COPY, are not penalized. If A is a substring of B, the documents will have an overlap of 1; this is not the case with Jaccard similarity.</p><p>For the N -gram overlap method, we compute overlaps between each pair of articles, drawing an edge between two articles if the overlap is above some minimum overlap threshold. This hyperparameter, which determines the accuracy of N -gram de-duplication, is tuned on the full-day validation sample. We also choose N using the full-day validation sample, with N = 3 providing the best Adjusted Rand Index. Once all edges have been drawn, Louvain community detection can be applied to remove false positives that erroneously connect otherwise disjoint document clusters, a step that we show improves the performance of this method.</p><p>For LSH, we use Datasketch's MinHashLSH library, which is widely used in the literature. The two relevant hyperparameters are the number of hash functions used and the minimum number of hash collisions needed to designate two documents as duplicates. For the former, we choose 10, which predominates in the literature, balancing computational efficiency and accuracy. The latter is tuned on the full-day validation sample. All documents with at least the threshold number of hash collisions are defined as duplicates. As with the other methods, community detection can be run once the graph has been constructed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Model Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baseline Results</head><p>Table <ref type="table">2</ref> compares the accuracy of 4 baseline models on the full-day test samples: non-neural methods (Ngram overlap and hashing) and neural methods (bi-encoder and re-ranking). For both of these, we examine a scalable method (hashing and bi-encoder) and a method that aims to achieve higher accuracy at some computational cost (N -gram overlap and re-ranking). We do not evaluate the cross-encoder alone, as the scale of the majority of de-duplication applications makes it computationally infeasible (i.e. 10 14 embeddings would be required for our scaling exercise).</p><p>Table <ref type="table">2</ref> reports the adjusted Rand index (ARI) <ref type="bibr" target="#b13">[Hubert and Arabie, 1985]</ref>. 2 The neural methods significantly outperform the N -gram based methods, increasing ARI from 73.7 to 91.5 when comparing the most scalable methods (LSH and bi-encoder) and from 44.0 to 93.7 when comparing the more computationally costly methods (N -gram overlap and re-ranking).</p><p>In contrast, the more computationally intensive methods offer little advantage over their more scalable counterparts. In fact, hashing significantly outperforms N -gram overlap on the test data. The thresholds to determine a duplicate (overlap/collisions) were chosen using the validation sample, where N -grams indeed outperform hashing. Defining what a duplicate is using a single threshold makes N -gram based methods</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-Neural</head><p>Most scalable Bi-encoder (91.5) LSH (73.7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Less scalable</head><p>Re-ranking (93.7) N -gram overlap (44.0)</p><p>Table <ref type="table">2</ref>: The numbers in parentheses are the Adjusted Rand Index for four different models -a bi-encoder, a "re-ranking" strategy that combines a bi-and cross-encoder, locally sensitive hashing (LSH), and N -gram overlap. Hyperparameters were chosen on the NEWS-COPY validation set, and all models were evaluated on the NEWS-COPY test set.</p><p>brittle, even in contexts such as this one where distribution shift is likely modest. The optimal N -gram overlap threshold in the validation sample leads to quite poor performance in the test sample. The 'reranking' strategy does offer modest gains over using a bi-encoder alone (ARI of 93.7 vs. 91.5), making it a compelling method for moderately size datasets where accuracy is paramount. These results underscore the potential returns of applying deep neural models to de-duplication of massive text datasets. When neural false positives occur, it is typically in the context of articles that have some repeated content but do not meet the definition of duplicates used to create the NEWS-COPY dataset: i.e. the articles contain the same quote or one is an updated article that contains additional breaking news. False negatives are most likely to occur when the beginning of an article has been truncated due to an error in the data digitization pipeline. If desired, further improvements in accuracy could plausibly be achieved by adding more of these challenging edge cases to the training data.</p><p>With N -gram methods, errors are mechanical, occurring in articles where noise results in fewer N -grams in common or where distinct articles by chance have significant overlap. N -gram overlap and hashing control this tradeoff through a threshold, whereas neural methods are highly flexible and can be finely tuned to the downstream task through curation of appropriate training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablations</head><p>Tables <ref type="table" target="#tab_1">3</ref> and<ref type="table" target="#tab_2">4</ref> explore several sets of ablations to the neural and non-neural methods, respectively. Community detection can detect false positive links between otherwise disparate clusters. Removing it makes little to no difference for the neural models but leads to a significant decline in performance for N -gram overlap and hashing. This underscores the greater robustness of the neural approaches, whereas the non-neural methods are more prone to false positives that link otherwise disparate groups of articles. Next, we consider whether hierarchical agglomerative clustering (HAC), which does not scale well, improves the accuracy of the bi-encoder approach. There are modest gains, with ARI increasing from 91.5 to 92.5, which highlights the potential returns of using HAC for moderately-sized de-duplication problems.</p><p>We also consider off-the-shelf S-BERT <ref type="bibr" target="#b23">[Reimers and Gurevych, 2019]</ref>, a model trained to detect semantic textual similarity (STS). STS and de-duplication are distinct problems -despite STS being framed sometimes as the removal of (semantic) duplicates. As expected, the models designed for STS perform inadequately on textual de-duplication (ARI 70 for the bi-encoder and 69.3 for re-ranking), though these results are not that much worse than LSH despite not being trained for this task. Interestingly, this suggests that our pre-trained NEWS-SIM model could potentially outperform LSH for text de-duplication even on quite distinct corpora. The other columns vary the N used to compute N -grams and include community detection.</p><p>For the neural methods, we also explore different loss functions for contrastively training the bi-encoder -supervised contrastive (SupCon) loss <ref type="bibr" target="#b17">[Khosla et al., 2020]</ref> <ref type="foot" target="#foot_2">3</ref> and multiple negatives ranking loss (MNRL) <ref type="bibr" target="#b12">[Henderson et al., 2017]</ref>. <ref type="foot" target="#foot_3">4</ref> The online contrastive loss outperforms both of these alternative losses in both neural approaches.</p><p>For the N -gram based methods, we chose the optimal N = 3 on the one-day validation sample. Table <ref type="table" target="#tab_2">4</ref> varies N -with the overlap threshold/number of collisions for each N again chosen to maximize ARI in the one-day validation sample. For LSH, N = 3 remains optimal in the test set, whereas for N -gram overlap, it performs quite poorly, with N = 5 having an edge. This again demonstrates that N -gram methods can be brittle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Computational Efficiency</head><p>Hashing is often advocated because of its scalability, and neural methods for de-duplicating large text corpora likewise need to be highly scalable. We conduct experiments on a 19 GB, 10 million article corpus, created by applying the same object detection model used to curate NEWS-COPY to millions of front page newspaper page scans. These experiments use a 32-Core 3.50 GHz AMD RYZEN Threadripper Pro 3975WX and a single NVIDIA A6000 GPU, a very modest setup for working with large text corpora.</p><p>We scale the bi-encoder and LSH approaches to this corpus, reporting speeds in Table <ref type="table" target="#tab_3">5</ref>. The largest cost of scaling the bi-encoder, by a wide margin, is embedding the 10M articles, which takes 8:38:52 on a single GPU. This could be sped up significantly by deploying a smaller language model. However, since this cost is already fairly marginal in the context of working with massive text datasets, we do not explore this here.</p><p>FAISS <ref type="bibr" target="#b14">[Johnson et al., 2019]</ref>, with IndexFlatIP, is used to calculate pairwise exact distances between the embeddings.<ref type="foot" target="#foot_4">5</ref> These computations require just over 3 hours on a single GPU. This produces a list of article pairs whose embeddings are within a threshold distance, using the optimal threshold selected in the NEWS-COPY full day validation sample. We build a graph -where each of the 10M documents is a node and edges connect documents whose embeddings are within the threshold distance. This takes 0:01:23 using CuDF and CuGraph. False positives are controlled by running Louvain community detection on the graph; alternatively, one could define clusters simply by extracting the connected components. Total run-time on the single GPU card is 11:45:10.</p><p>While neural methods are not expected to be faster than hashing, they compare reasonably. LSH requires 3:39:05 CPU hours for pre-processing, shingling, and hashing, and around 1 GPU minute to create the resulting graph and apply community detection. Commonly used hashing libraries run on a CPU, and hence this is where we implement LSH, with Datasketch's MinHashLSH. To effectively scale LSH, we slightly modify the previous architecture and break the hashes into bands comprised of rows of hashes. Each of these bands is hashed again and two articles that share an identical band hash are considered duplicates. The choice of bands and rows determines an S-curve, which gives the probability of being considered a duplicate given a certain Jaccard similarity. To generate our desired S-curve, we used 15 bands and 2 rows. The bi-encoder method detects 810,080 distinct reproduced articles. The average duplicated article was reproduced 6.41 times, strikingly similar to what we document in the single day NEWS-COPY labeled data. This is expected, since most reproduced articles occur within the time window captured in the NEWS-COPY full day samples. The number of true negative pairs is massively greater in the 10M article corpus, and it is encouraging that the average number of times articles are estimated to be reproduced remains quite constant, rather than being blown up by false positives. In contrast, LSH detects only 486,460 distinct reproduced articles, estimating that each on average appears 11.55 times. This is significantly greater than in the labeled NEWS-COPY data, and likely indicates that false positives are significantly increasing the size of detected duplicated article groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>De-duplication is important to a range of NLP tasks, from training large language models, controlling privacy risk, and controlling test set leakage, to detecting reproduced content in large text corpora for social science and humanities research. N -gram based methods predominate, and most contexts do not provide a way to assess how well they perform since duplicates in large corpora cannot typically be comprehensively identified. We exploit the timely nature of news to build NEWS-COPY, a large, human-annotated dataset that comprehensively identifies reproduced news articles.</p><p>NEWS-COPY is then used to evaluate neural and non-neural de-duplication. Neural methods -which utilize a contrastively trained bi-encoder -offer significant performance gains, and can be scaled on a single GPU card to de-duplicate a 10M article corpus in a matter of hours. These results suggest that neural text de-duplication is straightforward and well worth further examination in a range of contexts where hashing and other N -gram based methods currently predominate. The public release of NEWS-COPY and this study's codebase aims to facilitate further work on robust, scalable text de-duplication.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Table1summarizes the key features of the NEWS-COPY dataset. It consists of 27,210 articles, drawn from 973 newspapers between 1920 to 1977. 1 NEWS-COPY contains two types of data: data for training and four full day exhaustively labeled evaluation samples, constructed with two consecutive days of content 1930 and single days in 1955 and 1974, selected at random. The 1955 sample is a validation set used to select hyperparemters for both the N -gram and neural methods. 1930 and 1974 are pooled to form the test set and used only to produce the results shown in this paper. In the full day samples, there are far more negative than positive pairs, as is generally the case in de-duplication problems, whereas the training data contain a more balanced sample for model training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>This table provides summary statistics from the NEWS-COPY dataset, decomposed into the training sample and the full day evaluation data.</figDesc><table><row><cell></cell><cell>Positives</cell><cell>Negative</cell><cell cols="2">Reproduced Singleton</cell><cell>Total</cell></row><row><cell></cell><cell>Pairs</cell><cell>Pairs</cell><cell>Articles</cell><cell>Articles</cell><cell>Articles</cell></row><row><cell>Training Data</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training</cell><cell>36,291</cell><cell>37,637</cell><cell>891</cell><cell>-</cell><cell>7,728</cell></row><row><cell>Validation</cell><cell>3,042</cell><cell>3,246</cell><cell>20</cell><cell>-</cell><cell>283</cell></row><row><cell>Full Day Evaluation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Validation</cell><cell>28,547</cell><cell>12,409,031</cell><cell>447</cell><cell>2,162</cell><cell>4,988</cell></row><row><cell>Test</cell><cell>54,996</cell><cell>100,914,159</cell><cell>1,236</cell><cell>8,046</cell><cell>14,211</cell></row><row><cell>Full Dataset</cell><cell cols="2">122,876 113,364,073</cell><cell>2,594</cell><cell>10,208</cell><cell>27,210</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Numbers report the Adjusted Rand Index. No commun. detection removes community detection. HAC clustering uses hierarchical agglomerative clustering for the bi-encoder. S-BERT STS uses off-the-shelf S-BERT semantic textual similarity models. SupCon uses a supervised contrastive loss function and MNRL uses a multiple negatives ranking loss function.</figDesc><table><row><cell></cell><cell></cell><cell>No commun.</cell><cell>HAC</cell><cell>S-BERT</cell><cell cols="2">Loss Function</cell></row><row><cell></cell><cell>Baseline</cell><cell>detection</cell><cell>clustering</cell><cell>STS</cell><cell cols="2">SupCon MNRL</cell></row><row><cell>Bi-encoder</cell><cell>91.5</cell><cell>91.5</cell><cell>92.5</cell><cell>70.0</cell><cell>87.2</cell><cell>84.5</cell></row><row><cell>Re-ranking</cell><cell>93.7</cell><cell>92.0</cell><cell>-</cell><cell>69.3</cell><cell>91.1</cell><cell>89.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>Numbers report the Adjusted Rand Index. No commun. detection removes community detection.</figDesc><table><row><cell></cell><cell></cell><cell>No commun.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Baseline</cell><cell>detection</cell><cell cols="4">4-grams 5-grams 10-grams 15-grams</cell></row><row><cell>Hashing</cell><cell>73.7</cell><cell>67.7</cell><cell>71.5</cell><cell>69.6</cell><cell>63.7</cell><cell>59.4</cell></row><row><cell>N -gram overlap</cell><cell>44.0</cell><cell>23.2</cell><cell>57.9</cell><cell>59.2</cell><cell>56.6</cell><cell>57.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>This table reports computational efficiency in scaling the bi-encoder and LSH methods to a 10 million article corpus. Parentheses indicate whether the calculations were run on a CPU or a single NVIDIA A6000 GPU card. Mean times reproduced reports the average size of duplicated article communities that each method estimates.</figDesc><table><row><cell cols="2">Embed Compute</cell><cell>Build</cell><cell>Commun.</cell><cell>Total</cell><cell>Mean Times</cell></row><row><cell cols="3">Articles Similarity Graph</cell><cell>Detect.</cell><cell>Time</cell><cell>Reproduced</cell></row><row><cell>Bi-Encoder 8:38:52</cell><cell>3:04:53</cell><cell>0:01:23</cell><cell>0:00:02</cell><cell>11:45:10</cell><cell>6.41</cell></row><row><cell>(GPU)</cell><cell>(GPU)</cell><cell>(GPU)</cell><cell>(GPU)</cell><cell>(GPU)</cell><cell></cell></row><row><cell>Hashing</cell><cell>3:39:05</cell><cell>0:00:55</cell><cell>0:00:08</cell><cell>3:40:08</cell><cell>11.55</cell></row><row><cell></cell><cell>(CPU)</cell><cell>(GPU)</cell><cell>(GPU)</cell><cell>(mostly CPU)</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>A copyright law change effective January 1, 1978 resulted in nearly all newspapers from that date forward being under copyright by default.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Evaluating with F1 leads to similar conclusions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Trained for 32 epochs, 67% warm up, batch size 32, AdamW optimizer, 2e-5 learning rate</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Trained for 32 epochs, 0% warmup, batch size 16, AdamW optimizer, 2e-5 learning rate</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Because FAISS range search is not GPU-supported, we implement k nearest neighbor search, conservatively setting k to 900. Then distances are filtered to those below the optimal threshold found in our one day validation sample. In NEWS-COPY, articles are never reproduced more than 200 times, with the average reproduced article appearing</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>6.3 times, indicating that k = 900 is quite conservative. Similarity search could be sped up by choosing a smaller k.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Abhishek Arora</rs>, <rs type="person">Vania Cheung</rs>, and <rs type="person">William Cox</rs> for invaluable research assistance.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Media competition and news diets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Angelucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cag?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sinkinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>National Bureau of Economic Research</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Addressing &quot;documentation debt</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05241</idno>
	</analytic>
	<monogr>
		<title level="m">machine learning research: A retrospective datasheet for bookcorpus</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving language models by retrieving from trillions of tokens</title>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2206" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reprinting, circulation, and the network author in antebellum newspapers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cordell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Literary History</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="417" to="445" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Chronicling america: Historic american newspapers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reference Reviews</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marasovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Agnew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Groeneveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08758</idno>
		<title level="m">Documenting large webtext corpora: A case study on the colossal clean crawled corpus</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Guarneri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Newsprint Metropolis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deduplication of scholarly documents using locality sensitive hashing and word embeddings</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gyawali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Anastasiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knoth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luk?cs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miklos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.00652</idno>
		<title level="m">Efficient natural language response suggestion for smart reply</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Arabie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of classification</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Kandpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.06539</idno>
		<title level="m">Deduplicating training data mitigates privacy risks in language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11362</idno>
		<title level="m">Supervised contrastive learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nystrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.06499</idno>
		<title level="m">Deduplicating training data makes language models better</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Mining of massive data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Denoising distantly supervised open-domain question answering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1736" to="1745" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Layoutparser: A unified toolkit for deep learning based document image analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Document Analysis and Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="131" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Hsu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05617</idno>
		<title level="m">Deduplication in a massive clinical note dataset</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Computational methods for uncovering reprinted texts in antebellum newspapers</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cordell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mullen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Literary History</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="E15" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mpnet: Masked and permuted pre-training for language understanding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="16857" to="16867" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>R?ckl?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08663</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A system for identifying and exploring text repetition in large historical document corpora</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vesanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Salmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nivala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Nordic Conference on Computational Linguistics</title>
		<meeting>the 21st Nordic Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="330" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">R 3: Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Scalable zero-shot entity linking with dense entity retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Josifoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03814</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
