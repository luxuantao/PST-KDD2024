<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pairwise Multi-Class Document Classification for Semantic Relations between Wikipedia Articles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-03-22">22 Mar 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Malte</forename><surname>Ostendorff</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DFKI GmbH</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Terry</forename><surname>Ruas</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Wuppertal</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Moritz</forename><surname>Schubotz</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Wuppertal</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Georg</forename><surname>Rehm</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DFKI GmbH</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bela</forename><surname>Gipp</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Wuppertal</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pairwise Multi-Class Document Classification for Semantic Relations between Wikipedia Articles</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-03-22">22 Mar 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2003.09881v1[cs.DL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems → Recommender systems</term>
					<term>Similarity measures</term>
					<term>Clustering and classification</term>
					<term>• Computing methodologies → Supervised learning by classification document similarity, recommender systems, document classification, Siamese networks, Transformers, BERT, XLNet, Wikipedia</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many digital libraries recommend literature to their users considering the similarity between a query document and their repository. However, they often fail to distinguish what is the relationship that makes two documents alike. In this paper, we model the problem of finding the relationship between two documents as a pairwise document classification task. To find the semantic relation between documents, we apply a series of techniques, such as GloVe, Paragraph-Vectors, BERT, and XLNet under different configurations (e.g., sequence length, vector concatenation scheme), including a Siamese architecture for the Transformer-based systems. We perform our experiments on a newly proposed dataset of 32,168 Wikipedia article pairs and Wikidata properties that define the semantic document relations. Our results show vanilla BERT as the best performing system with an F1-score of 0.93, which we manually examine to better understand its applicability to other domains. Our findings suggest that classifying semantic relations between documents is a solvable task and motivates the development of recommender systems based on the evaluated techniques. The discussions in this paper serve as first steps in the exploration of documents through SPARQL-like queries such that one could find documents that are similar in one aspect but dissimilar in another.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To cope with the ever-emerging information overload, digital libraries employ literature recommender systems (LRS) <ref type="bibr" target="#b6">[7]</ref>. These systems recommend related documents with the help of similarity measures, which often only distinguish between similar and dissimilar documents. This simplification neglects the many facets of extensive documents in digital libraries. It remains unclear to which of the many facets the similarity relates. In philosophy <ref type="bibr" target="#b17">[18]</ref>, but also in natural language processing (NLP) <ref type="bibr" target="#b5">[6]</ref>, the similarity of A to B has been addressed as an ill-defined notion unless one can say to what the similarity relates. For LRS, one would rather know what aspects of the two documents are similar or how they relate to each other than just knowing that the documents are similar or dissimilar. Identifying the aspects connecting different documents would allow users to explore the document space by formulating SPARQL-like queries in terms of documents and their relations (e.g., find a document with one specific relation to A, but a different relation to B). These queries are generally referred to as analogical queries <ref type="bibr" target="#b16">[17]</ref>. Especially for complex information needs, the formulation of analogical queries is more intuitive <ref type="bibr" target="#b23">[24]</ref>. A system that supports analogical queries would be particularly beneficial for scientific literature since the discovery of the analogies is crucial for scientific progress <ref type="bibr" target="#b9">[10]</ref>.</p><p>Nonetheless, document similarity measures do not take into account the semantic relations that would underpin such a system. While other NLP tasks, like relation extraction (RE) <ref type="bibr" target="#b41">[42]</ref>, deal with relations, they are not concerned with semantic relations between documents. For instance, RE is about relations between entities occurring within a single document text. Similarly, the document classification task aims to categorize individual documents, but fail to address the relationship that binds two or more documents.  Seed article Albert Einstein is connected to other articles by the property educated at and citizenship. Considering articles only a single edge apart leads to diverse recommendations, while two edges can be utilized for recommendation sets focused on a specific or an intersection of aspects.</p><p>In this paper, we combine the ideas of relation extraction, document classification, and document similarity to classify the semantic relation of document pairs. Given a seed document d s , we are interested in finding a target document d t that shares the semantic relation r i with d s . We use the term "semantic relation" to indicate connections between two documents above the syntax level <ref type="bibr" target="#b20">[21]</ref>. We model the task of finding the relation r of a document pair (d s , d t ) as a pairwise multi-class document classification problem.</p><p>The semantic relation between documents provides context for similarity and enables analogical queries. To evaluate the presented techniques, we build a dataset using Wikipedia and Wikidata <ref type="bibr" target="#b37">[38]</ref> repositories to illustrate our problem. Wikipedia articles are the seed and target documents, while Wikidata properties provide the semantic relations between a document pair. Figure <ref type="figure" target="#fig_1">1</ref> shows one example from our dataset. The articles Albert Einstein and German Empire are the pair (d s , d t 1 ) and the relation is defined by r 1 , which is the Wikidata property country of citizenship. These relations enable recommendations and analogical queries (Section 5).</p><p>Our paper makes three major contributions. First, we propose a method to classify the semantic relations of document pairs. Second, we implement six different models using word-based document embeddings from GloVe <ref type="bibr" target="#b30">[31]</ref> and Paragraph Vectors <ref type="bibr" target="#b22">[23]</ref> (as Doc2vec implementation <ref type="bibr" target="#b32">[33]</ref>), and deep contextual language models from BERT <ref type="bibr" target="#b14">[15]</ref> and XLNet <ref type="bibr" target="#b40">[41]</ref> in a vanilla and Siamese architecture <ref type="bibr" target="#b8">[9]</ref>. Each system is evaluated under specific configurations regarding its concatenation method and sequence length. Third, we introduce a novel dataset composed of 32,168 Wikipedia article pairs and Wikidata properties that define the semantic relation of these articles. All our datasets, trained models, and source code are publicly available to contribute to transparency and reproducibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In the following, we relate to other research regarding document similarity and its use for recommender systems and analogies. Besides, we refer to related work that applies similar or the same techniques for solving other NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Similarity &amp; Recommendations</head><p>Bär et al. <ref type="bibr" target="#b5">[6]</ref> discuss the notion of similarity between texts in the context of NLP. They express that while text similarity is present in many NLP tasks, the similarity is often ill-defined and used as an "umbrella term covering quite different phenomena". Bär et al. <ref type="bibr" target="#b5">[6]</ref> formalize text similarity and suggest content, structure, and style as the major dimensions inherent to texts. With approximately 55% of publications using content-based filtering, it accounts for the majority of the LRS research <ref type="bibr" target="#b6">[7]</ref>. Structure and style are not actively being accounted for. Therefore, we focus only on the content.</p><p>Giving its diversity and reach, Wikipedia had been used as a laboratory in which recommender system methodologies can be tested <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b35">36]</ref>. In <ref type="bibr" target="#b35">[36]</ref>, we compared text-and link-based document similarity measures and found that both methods capture similarity differently. Link-based methods tend to retrieve documents from a broader context, while text-based methods are focused on specific terms and topics. Consequently, each similarity approach is suitable for different information needs, e.g., getting an overview of a topic or performing in-depth research. With the classification of semantic document relations, we intend to tailor recommendations depending on specific information needs. For example, we could provide either recommendations focusing on a particular relation class or diverse recommendations from multiple relation classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Analogical Queries</head><p>An analogy is a comparison between two or more elements in which their relation is used to illustrate an explanation. Moreover, analogical query solving in the form of "A is to B as C is to ?" is a fundamental aspect of human intelligence <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b23">24]</ref>. Chan et al. <ref type="bibr" target="#b9">[10]</ref> emphasize the importance of analogical query solving for scientific progress. They propose a semi-automated approach for finding analogies between research papers using expert and crowd annotators to segment the abstracts of papers into background, purpose, mechanism, and findings. Next, they encode the segments with GloVe <ref type="bibr" target="#b30">[31]</ref> and Paragraph Vectors <ref type="bibr" target="#b22">[23]</ref> and compute their similarity to determine whether papers are similar with respect to those segments. However, segmentation breaks the coherence of documents. Our method aims to find semantic relations between documents while maintaining their coherence intact.</p><p>In the context of word embeddings, analogies are often illustrated using vector arithmetic, e.g., ì w King − ì w Queen = ì w Man − ì w Woman <ref type="bibr" target="#b24">[25]</ref>. Allen and Hospedales <ref type="bibr" target="#b2">[3]</ref> give a mathematical description of analogies as linear relationships between word embeddings. Dai et al. <ref type="bibr" target="#b12">[13]</ref> demonstrate that such analogies are also present in document embeddings. In their experiment, using Wikipedia articles, the nearest neighbor to the vector of ì w LadyGaga − ì w American + ì w Japanese is the article on Ayumi Hamasaki, a famous Japanese singer that published an album called "Poker Face" in 1998 (like Lady Gaga in 2008).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Transformers</head><p>Recently, Transformer-based <ref type="bibr" target="#b36">[37]</ref> neural language models introduced a shift from context-free word embeddings, like GloVe <ref type="bibr" target="#b30">[31]</ref>, to contextual embeddings as the ones used in BERT <ref type="bibr" target="#b14">[15]</ref> and XL-Net <ref type="bibr" target="#b40">[41]</ref>. The Transformer architecture allowed the efficient unsupervised pretraining of language models and led to significant improvements in many NLP benchmarks <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b42">43]</ref>. Reimers and Gurevych <ref type="bibr" target="#b33">[34]</ref> proposed to combine BERT with a Siamese architecture <ref type="bibr" target="#b8">[9]</ref> for semantic representations of sentences and their similarity <ref type="bibr" target="#b25">[26]</ref>. In prior work <ref type="bibr" target="#b31">[32]</ref>, we also utilized a Siamese BERT model to determine the discourse relations between text segments to generate a story for the segments. Moreover, BERT has successfully solved various document classification tasks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b28">29]</ref>. Akkalyoncu Yilmaz et al. <ref type="bibr" target="#b1">[2]</ref> apply BERT to an information retrieval system for an end-to-end search over large document collections. Despite their success in NLP, Transformers have gained little attention in the recommender system community so far and are not even mentioned in a recently published survey <ref type="bibr" target="#b4">[5]</ref>. To our knowledge, Hassan et al. <ref type="bibr" target="#b26">[27]</ref> are one of the first to use BERT to recommend research papers. As opposed to our work, Hassan et al. use BERT to encode only the paper titles as vectors and then generate recommendations using cosine similarity. In our experiments, we utilize the article text and learn the document relation using a multilayer perceptron (MLP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In the following, we describe the dataset and investigated systems to facilitate the reproduction of our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data set &amp; Use case</head><p>Existing datasets provide either classifications of single documents (e.g., topic <ref type="bibr" target="#b28">[29]</ref>), relations between sentences or entities (e.g., natural language inference <ref type="bibr" target="#b38">[39]</ref>, word analogies <ref type="bibr" target="#b24">[25]</ref>, entity relation extraction <ref type="bibr" target="#b41">[42]</ref>), or similarity between text pairs (i.e., binary classification <ref type="bibr" target="#b15">[16]</ref>). Our task is defined as as multi-class classification of document pairs consisting of multiple sentences. Moreover, the learning characteristic in our task requires considerably larger dataset than <ref type="bibr" target="#b9">[10]</ref> or <ref type="bibr" target="#b19">[20]</ref>. To the best of our knowledge, no established dataset fulfills these requirements.</p><p>3.1.1 Training data. One example of a digital library that employs an LRS is Wikipedia. Recommendations for Wikipedia articles have been addressed in the literature <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b35">36]</ref>  <ref type="foot" target="#foot_2">3</ref> is connected to the article <ref type="foot" target="#foot_3">4</ref> and item <ref type="foot" target="#foot_4">5</ref> of the German Empire through the property country of citizenship <ref type="foot" target="#foot_5">6</ref> . The Wikidata property acts as both, the relation of the Wikipedia article pair and the class label in the training data for this same pair of documents. Table <ref type="table" target="#tab_1">1</ref> lists other examples to illustrate our scenario better.</p><p>Given Wikipedia's nature as an encyclopedia, its use as the dataset has some shortcomings. Encyclopedic documents tend to describe a single entity, and their semantics can be seen as rather homogeneous in comparison to other literature forms. Nonetheless, we consider Wikipedia and Wikidata to be a suitable corpus to demonstrate our approach. Wikidata properties range from entityspecific relations (e.g., educated at) to abstract ones (e.g., facet of ). Wikipedia articles and their relations are, on average, more comprehensible than those in scientific literature , which contributes to the analysis of our results. Another aspect that supports our choice of Wikipedia and Wikidata is their open license copyright.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantic Relations</head><p>At the time of writing, Wikidata contained 7,091 properties<ref type="foot" target="#foot_6">7</ref> of which we selected the following nine for this research:</p><p>• country of citizenship -seed is citizen of the target;</p><p>• different from -item that is different from another item, with which it is often confused; • educated at -educational institution attended by seed;</p><p>• employer -seed works or worked for target;</p><p>• facet of -topic of which this item is an aspect, item that offers a broader perspective on the same topic; • has effect -the seed causes the target;</p><p>• has quality -the entity has an inherent or distinguishing non-material characteristic; • opposite of -item that is the opposite of this item;</p><p>• symptoms -possible symptoms of a medical condition. Table <ref type="table" target="#tab_1">1</ref> lists the corresponding Wikidata PIDs, their quantity, and examples for each property. Besides the number of available Wikipedia article pairs, diversity was also a criterion in our selection. Diversity refers to the different semantic meanings of properties (e.g., country of citizenship, opposite of ). Similarly, the requirements to predict a relation between documents can also be diverse. While some relations are clearly expressed within the document text (e.g., for documents referencing people, their citizenship is often put in the first sentences), others will require a more comprehensive understanding of the article content. For instance, while floor as the opposite of ceiling is evident, this fact will most likely not be explicitly mentioned in the article text. Also, other relations like has effect or symptoms can require unwritten domain knowledge. The classification performance can also be affected by the type of the connected articles. For example, the relation class country of citizenship exclusively connects persons and countries. No other property uses such a combination. On the contrary, the relation classes educated at and employer, connect a person with an organization. Additionally, all relations are unidirectional, except for opposite of. Given the many aspects our relations are exploring, we expect significant differences in the classification performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Preprocessing</head><p>We sampled 10,000 article pairs in total with a balanced class distribution over the nine properties. The relations were obtained trough the Wikidata SPARQL interface in December 2019. For each Wikipedia article in the sample, we also checked whether the article was connected to any other article but was not part of the initial sample and retrieved the missing relations. We removed all duplicated article pairs and multi-label relations. The main goal of this paper is to explore the multi-class classification problem, so we ensure that the same pair of documents did not share different labels. Wikidata provides data for multi-label relations, especially for hierarchical properties. However, only less than 1% of our sample data contained multi-label relations. For the sake of simplicity, we decided to remove them. This procedure generates 16,084 Wikipedia article pairs with an imbalanced class distribution (Table <ref type="table" target="#tab_1">1</ref>). The increase of samples is due to the retrieval of missing relations. The corresponding articles were converted to plain-text from the English Wikipedia dump of November 2019 using the Gensim API <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Negative Sampling</head><p>In addition to the nine positive classes from Wikidata, we introduce a class named None that works as negative cases for our positive samples in the same proportion. The articles in the None category are randomly selected and do not share any relation with the positive ones. The resulting dataset contains 32,168 samples in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Systems</head><p>This paper evaluates six classifiers under different configurations, totaling 30 systems. We distinguish between three model categories: (i) document embeddings from word embeddings using the full document text (GloVe and Doc2vec), (ii) Vanilla Transformers, and (iii) Siamese Transformers (each Transformer as BERT and XLNet). Each classifier takes two documents d s and d t as input and predicts their relation ŷ = rel(d s , d t ) as its output. The hyperparameters for the considered systems are detailed in Section 3.6.</p><p>3.5.1 Doc2vec. With word2vec, Mikolov et al. <ref type="bibr" target="#b24">[25]</ref> introduced an algorithm to learn dense vector representations of words such that semantically similar words end up close to each other in the embedding space. Word2vec is widely applied in NLP tasks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b34">35]</ref> but unable to represent entire documents. Paragraph Vectors <ref type="bibr" target="#b22">[23]</ref> (also known as Doc2vec), extends word2vec to learn embeddings for word sequences of arbitrary length. In the following, we refer Paragraph Vectors as Doc2vec, since we employ the widely-used implementation of the Gensim <ref type="bibr" target="#b32">[33]</ref> framework. We obtained a 200D document vectors ì d for each Wikipedia article by training Doc2vec's distributed bag of words model (dbow) using both training and test data, and the default hyperparameters in Gensim 8 . The document vector size of 200 corresponds to the size of the GloVe word vectors (Section 3.5.2). The choice of dbow over the distributed memory training model is due to its results in semantic similarity tasks <ref type="bibr" target="#b21">[22]</ref>. It is important to mention that even though the embeddings model used both training and test sets, the latter was not used for training the classifier. 8 https://radimrehurek.com/gensim/models/doc2vec.html 3.5.2 AvgGloVe. GloVe <ref type="bibr" target="#b30">[31]</ref> also produce dense embedding representations, but unlike word2vec, GloVe is a count-based method that uses global statistics to derive its word vectors. In GloVe, the co-occurrence matrix explores the ratio of the probabilities of words in a text to derive its semantic vectors. While we use the 200D pretrained word embedding model<ref type="foot" target="#foot_7">9</ref> , GloVe does not provide document vectors directly. To embed a Wikipedia article ì d, we compute the weighted average over its word vectors ì w i (AvgGloVe), whereby the number of occurrences of the word i in d defines the weight c i . Arora et al. <ref type="bibr" target="#b3">[4]</ref> showed the weighted average of word vectors is effective and yields good results for representing documents.</p><p>For both full-text methods, AvgGloVe and Doc2vec, we encode each document from our document pair (d s , d t ) independent from the classification task and concatenate their resulting vectors. The different concatenation variants tested in our experiments are discussed in Section 3.6. The resulting document pair vector is then used as an input to a fully-connected MLP, which classifies the document pair relation ŷ = rel(d s , d t ). The dimension of the output of the last layer of all classifiers ( ŷ), corresponds to the nine Wikidata properties (Table <ref type="table" target="#tab_1">1</ref>) and one additional dimension for the None class of negative samples (Section 3.4). The logistic sigmoid function is used to generate the probabilities for the multi-class classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.3">Vanilla Transformer.</head><p>As the third model category, we employ two language models for deep contextual text representations based on the Transformer architecture <ref type="bibr" target="#b36">[37]</ref>, named BERT <ref type="bibr" target="#b14">[15]</ref> and XLNet <ref type="bibr" target="#b40">[41]</ref>. The two Transformer models are originally designed to solve sequence pair classification. The base training task (i.e., next sentence prediction) for BERT and XLNet allows us to fine-tune them for the document pair classification task. The content of the document pair (i.e., title and text of d s and d t ) is tokenized, delimited with special tokens, i.e., [CLS] and [SEP] for BERT, &lt;cls&gt; and &lt;sep&gt; for XLNet, and then jointly fed trough the Transformer (Figure <ref type="figure" target="#fig_3">2</ref>). The Transformer output is used as the input to a single fully-connected linear layer with 512 units for the classification (prediction head). Regarding terminology, we refer to the two models as vanilla Transformer since their original architecture is unchanged.  3.5.4 Siamese Transformer. We combine the two Transformers (BERT and XLNet) in a Siamese network architecture <ref type="bibr" target="#b8">[9]</ref>. In Siamese networks, two inputs are fed through identical sub-networks with shared weights (in this case, the Transformers), and then passed to a classifier or a similarity function. Reimers and Gurevych <ref type="bibr" target="#b33">[34]</ref> have shown that Siamese BERT networks are suitable for text similarity tasks. For our experiment, both documents d s and d t are input to the Transformer sub-networks to derive two contextual document vectors (Figure <ref type="figure" target="#fig_5">3</ref>). Next, the document vectors are concatenated and classified with a 2-layer MLP (2x512 units with ReLU activation), the same method applied by Doc2vec and AvgGlove. In contrast to Doc2vec and AvgGloVe, the document representations are neither fixed nor frozen, but continually learned during the training of the classifier. Different than <ref type="bibr" target="#b33">[34]</ref>, our implemented Siamese architecture is applied to a multi-class classification instead of a binary one.  The architectures of the underlying BERT and XLNet models are the corresponding BASE-CASED versions of the pretrained models with 12-layer, 768-hidden, 12-head, and 110M parameters. Even though the architectures of BERT and XLNet are comparable, the associated language models are pretrained with different data. While BERT is trained on English Wikipedia and the BooksCorpus <ref type="bibr" target="#b42">[43]</ref> alone, XLNet uses additional Web corpora for pretraining <ref type="bibr" target="#b40">[41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Hyperparameters</head><p>3.6.1 Sequence length. The vanilla and Siamese Transformer models based on BERT have a maximum sequence length of 512 tokens due to absolute positional embeddings. However, XLNet integrates the relative positional encoding, as proposed in Transformer-XL <ref type="bibr" target="#b13">[14]</ref>. Therefore, XLNet's architecture is, in theory, not bound to a maximum sequence length. However, a custom pretraining is out of scope for this research, and the publicly available pretrained models of XLNet have the same 512 token limit as BERT. It remains unknown how the length of the processed sequence affects the classification task. From <ref type="bibr" target="#b35">[36]</ref>, we know that the performance of similarity measures peaks at 450 words since the introduction section in Wikipedia articles presumably contains all essential information. Other sections might add only noise and make it harder to encode relevant semantic information from the articles. Thus, we evaluate the Transformers using 128, 256, and 512 tokens (Section 4.2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Implementation</head><p>All experiments with Doc2vec and AvgGloVe can be run on CPU in less than 15 minutes using the Gensim <ref type="bibr" target="#b32">[33]</ref> and Scikit-learn <ref type="bibr" target="#b29">[30]</ref> framework. Before training the Doc2Vec model, Gensim preprocesses <ref type="foot" target="#foot_8">10</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>Our results are divided in: overall, sequence length, concatenation, relation classes, and manual sample examination. These five subsections move from a high-level perspective to a detailed investigation of the main aspects that most contributed to our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overall</head><p>The empirical results of the tested systems and hyperparameters are presented in Table <ref type="table" target="#tab_3">2</ref>. Vanilla BERT-512 yields the best micro average F1-Score with 0.933, followed by its 256 length size model, with 0.930. The second-best model is the vanilla XLNet-512 with 0.926 F1 and a statistically significant lower score compared to vanilla BERT-512 (95% confidence interval). The vanilla Transformers generally outperform their Siamese counterparts. Siamese BERT (0.870 F1) and Siamese XLNet (0.870 F1) do not achieve the same performance as their vanilla architectures for the same 128 sequence length size, with scores of 0.920 (BERT-128) and 0.914 (XLNet-128) respectively. The shared contextual information during the encoding of document pairs most likely yields the better performance of vanilla Transformers. AvgGloVe (0.875 F1) outperforms Siamese BERT and Siamese XLNet, which makes AvgGloVe preferable over Siamese Transformers since AvgGloVe requires only a fraction of the computing resources and runs on commodity hardware. With an F1-score of 0.845 at its best configuration, Doc2vec is the worst performing model. In summary, we consider the results of Avg-GloVe and vanilla BERT as most promising for future application scenarios. We hypothesize that an F1-score of above 0.90 is already suitable enough for LRS. Especially, expert users would tolerate some misclassifications in favor of otherwise undiscoverable information. This would be the case for target documents that are considered to be dissimilar to the seed with existing methods but are found to have semantic relation with the help of our methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sequence Length</head><p>As explained in Section 3.6, we are particularly interested in the effect of the sequence length on the Transformer models. To illustrate this effect, Figure <ref type="figure">4</ref> shows the comparison of Siamese BERT, Siamese XLNet, vanilla BERT, and vanilla XLNet with respect to their sequence length (i.e., 128, 256, and 512). In this comparison, the Siamese models use the best performing concatenation method, which is</p><formula xml:id="formula_0">[u; v; |u − v |; u * v].</formula><p>Our findings reveal that longer sequences are related to better results. For all models, except Siamese XLNet, the highest F1-score is achieved with 512 tokens and the second-highest with 256 tokens. One could think this outcome is to be expected. However, in <ref type="bibr" target="#b35">[36]</ref>, the performance of text-and linkbased document similarity measures declines for Wikipedia articles with more than 450 words. When comparing Siamese with vanilla Transformers, the vanilla models work with only half of the sequence length to encode one document of the pair. In vanilla Transformers, the document pairs share the sequence length, while in Siamese Transformers each document has its own Transformer subnetwork (sequence length). For example, a vanilla 128-Transformer would use only 62 or 63 tokens of each document (three tokens are reserved for special tokens as Figure <ref type="figure" target="#fig_3">2</ref> shows). Thus, the small performance difference within vanilla BERT with 512 tokens (0.933 F1), 256 tokens (0.930 F1), and 128 tokens (0.920 F1) is remarkable. Moreover, the performance differences should be considered relative to the higher computation expenses of longer sequences.</p><p>S i a m e s e B E R T S i a m e s e X L N e t V a n i l l a B E R T V a n i l l a X L N e t Models </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Concatenation</head><p>Aside from the sequence length, we also analyzed the different concatenation methods in AvgGloVe, Doc2vec, and the Siamese models (Figure <ref type="figure" target="#fig_8">5</ref>). All models achieve the highest F1-score when the concatenation with an element-wise difference and product is used</p><formula xml:id="formula_1">([u; v; |u −v |; u * v]</formula><p>). Furthermore, we confirmed the results of Reimers and Gurevych <ref type="bibr" target="#b33">[34]</ref>, i.e., the most crucial component is the element-wise difference |u −v |. Only for Doc2vec the element-wise difference decreases the performance in comparison to the simple concatenation. However, this performance decrease is marginal and within standard deviation. In general, the element-wise difference measures the distance between the dimensions of the two document vectors and, thus, ensures that similar pairs are closer to each other than dissimilar pairs. This effect is evident for Siamese BERT and Siamese XLNet, for which the element-wise difference yields the most substantial performance improvement. On the contrary, the element-wise product adds only a small improvement to our models.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Relation Classes</head><p>We selected nine diverse Wikidata properties to explore how the systems would respond to the individual challenges of each property. Table <ref type="table" target="#tab_5">3 presents</ref>  The superiority of vanilla BERT is also present in the classspecific evaluation scenario, although it is outperformed by vanilla XLNet for three relation classes with a small number of samples (has effect, has quality and opposite of ). In AvgGloVe, symptoms has the highest precision score, which is probably caused by Avg-GloVe being able to utilize the full-text of articles in contrast to the Transformer models. Medical articles, like Alcoholism (Example 9 in Table <ref type="table" target="#tab_6">4</ref>), contain a section "Signs and symptoms" in which their symptoms are listed. However, such a section is not part of the 512 Transformer tokens. When comparing precision and recall for all classes, both scores are mostly balanced. There is only one striking exception for vanilla BERT. For employer, the precision score of 0.829 is higher than the recall of 0.653, while for educated at the opposite occurs, with a precision of 0.759 and recall of 0.900, but in a smaller magnitude. A reason for this outcome is that employer is often confused with educated at as Figure <ref type="figure" target="#fig_11">6</ref> shows. 0.88 0.00 0.00 0.06 0.00 0.00 0.02 0.01 0.01 0.03 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.00 0.97 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.14 0.00 0.00 0.69 0.00 0.00 0.03 0.03 0.01 0.11 0.00 0.00 0.00 0.00 0.68 0.27 0.00 0.00 0.00 0.05 0.00 0.00 0.00 0.00 0.05 0.90 0.00 0.00 0.00 0.05 0.06 0.00 0.00 0.03 0.00 0.00 0.87 0.02 0.01 0.01 0.03 0.00 0.00 0.00 0.00 0.00 0.00 0.93 0.00 0.03 0.20 0.00 0.11 0.05 0.00 0.00 0.01 0.03 0.52 0.09 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.99 0.0 0.2 0.4 0.6 0.8 The confusion matrix in Figure <ref type="figure" target="#fig_11">6</ref> depicts which classes are most often confused with each other. The predicted classes are taken from the vanilla BERT-512 system, whereby the number of true and predicted classifications is normalized to make the different classes comparable. With 27% of the test sample, educated at and employer are the most mistaken relation classes in our experiments. We see this outcome because both relation classes connect persons and organizations, and we assume it is harder for the classifier to tell the relations apart. For instance, Albert Einstein could be employed or educated at ETH Zurich (Figure <ref type="figure" target="#fig_1">1</ref>). The misclassification between different relations is also found in opposite of, has quality and has effect, which we conclude is because of similar reasons. In particular, the opposite of relation connects various types of articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Manual Sample Examination</head><p>To validate our empirical findings, we manually examine the prediction from vanilla BERT-512 with a focus on errors (Table <ref type="table" target="#tab_6">4</ref>). Examples 1 and 2 show a desired classifier despite one misclassification according to Wikidata. While Armenia is correctly identified as Rudolf Muradyan's country of citizenship, Brazil is not recognized. However, Brazil is also not mentioned in Rudolf Muradyan's Wikipedia article. The Wikidata statement is not reflected in the Wikipedia article, which states Muradyan as Armenian only. Consequently, both predictions would be correct when only considering the article text. Two errors are exemplified in 3 and 4. Even though Zaki Naguib Mahmoud's article explicitly expresses the educated at relation with the sentence "Mahmoud was educated at Cairo University", Cairo University is classified as his employer. Despite not being mentioned in Mahmoud's article, King's College London is also wrongly classified as his employer. In example 5, Light is incorrectly classified as the quality of Darkness, not as opposite of it. Still, opposite of is the class with the second-highest probability. Example 6 shows the Mexican Revolution as different from the Mexican War of Independence, which would be clear to a human user since the Wikipedia article contains banner "Not to be confused with the Mexican War of Independence. ". However, this banner is missing in the Wikipedia dump and, thus, is not available to the classifier. Many shared terms and vocabulary make their classification hard to predict for the different from relation. Examples 7-9 are not discussed, but similarly illustrate the classifier's performance.</p><p>Our manual examination confirms the overall results. Most relations are correctly identified, while some relations are missing even if they are explicitly mentioned in the text. An analysis of the inner Transformer components <ref type="bibr" target="#b10">[11]</ref> is a subject for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Given the results in Table <ref type="table" target="#tab_3">2</ref>, we can state that vanilla Transformers outperform all other methods. Rather unexpected is that BERT generally achieves slightly better results than XLNet. According to Yang et al. <ref type="bibr" target="#b40">[41]</ref>, XLNet surpasses BERT on the related GLUE benchmark <ref type="bibr" target="#b38">[39]</ref>, so we were expecting a similar outcome. We hypothesize that this difference may be attributed to two reasons, pretraining on different corpora, and smaller models compared to <ref type="bibr" target="#b40">[41]</ref>. We use the BASE, not the LARGE versions of the pretrained models used by Yang et al. <ref type="bibr" target="#b40">[41]</ref>. Furthermore, the published XLNet BASE model we considered is pretrained on different data than the one in Yang et al. <ref type="bibr" target="#b40">[41]</ref>  <ref type="foot" target="#foot_13">15</ref> . In contrast to BERT, XLNet is pretrained on Web corpora in addition to Wikipedia and the BooksCorpus <ref type="bibr" target="#b42">[43]</ref>. The almost exclusive pretraining on Wikipedia most likely causes BERT to surpass XLNet. The effect of domain-specific pretraining on the performance of the language model has already been shown <ref type="bibr" target="#b7">[8]</ref>.</p><p>Our evaluation also shows that the Siamese networks cannot capture the semantic relations as good as vanilla Transformers. In Siamese models, the encoding of the seed document does not affect the target, and vice-versa. Only the MLP is exposed to the documents as a pair in the form of the concatenated document vectors. During the encoding phase, the relation between the documents plays no role. On the contrary, the Multi-Head-Attention mechanism in the vanilla Transformers allows attending on the two documents simultaneously. As the results suggest, this ability is crucial for the pairwise document classification. The Siamese models are also outperformed by the computationally less expensive AvgGloVe. At a general level, the Siamese models are very similar to AvgGloVe (and Doc2vec), since they derive two document vectors and classify their concatenation. So the performance of the method ultimately depends on its ability to encode the documents. Arora et al. <ref type="bibr" target="#b3">[4]</ref> have shown that the weighted average of word vectors can outperform more sophisticated methods. AvgGloVe benefits from the fact that it utilizes the full-text article in contrast to the Transformers, which use only the 512 first tokens of the article text. As a result, AvgGloVe is a reasonable method for real production scenarios, in which computational resources are critical concerns. In production scenarios, one would also avoid classifying all possible n 2 document pairs. Instead, evidently unrelated pairs must be filtered out with traditional similarity measures at first.</p><p>Regarding the different relation classes, almost all results present reasonable performance. Moreover, complex relation classes like facet of or has effect, yield promising results, since they are attractive for the recommender system use case. As the example 1 and 2 shows in Table <ref type="table" target="#tab_6">4</ref>, current systems already reveal wrong or contradicting information between Wikidata and Wikipedia. The results suggest that increasing the sequence length beyond the 512 tokens could further improve the Transformer models. Higher sequence length is already possible with XLNet's architecture, but it would require a pretraining step with longer sequences.</p><p>From Relations to Recommendations. Classifying the document relations is not a purpose on its own. We envision recommender systems as an example of a downstream task. The obtained relations can be used for diverse or focused recommendations. As the relations describe different facets of the seed document, one could diversify the recommendations. Choosing the recommendations from documents connected with different relation classes to the seed document would ensure diversity. In Figure <ref type="figure" target="#fig_1">1</ref>, the German Empire and ETH Zurich can be considered as diverse recommendations, since they present different aspects of Albert Einstein, i.e., his citizenship and education. When considering documents that are connected to a seed (i.e., one common document) over two edges (i.e., different relations), recommendations focusing on specific aspects are more feasible. Diverse and focused recommendations could be especially suitable for scenarios in which different perspectives are required for the same seed. In contrast to user-based recommender systems, content-based approaches usually struggle to account for specific preferences from their users. One way to respect different information requirements would be to suggest alternative recommendation sets that are focused on specific aspects. In the example of Albert Einstein, shown in Figure <ref type="figure" target="#fig_1">1</ref>, focused recommendation sets could include articles about people with the same citizenship or the same educational backgrounds. The intersection of relations would even allow finding people with the same citizenship but different educational background. The classification of the document relations, as demonstrated in our experiments, is the foundation for such recommendations.</p><p>Generalization. Given the long-term goal of applying the tested methods on non-encyclopedic corpora, the question arises whether our findings are generalizable. We acknowledge that Wikipedia is a presumable a simpler corpus compared to other literature domains like research papers. Wikipedia articles represent distinct entities and most relations are explicitly expressed in the article text. However, even research papers express semantic relations in their abstracts, e.g., "we used X" or "we found Y". Accordingly, we hypothesize that our systems would yield worse but still satisfactory results under comparable conditions (size of training data, pretraining on in-domain corpus etc.). A reference value would be the F1-score of 0.65, which was achieved by SciBERT on the related task of citation intent classification <ref type="bibr" target="#b7">[8]</ref>. While the effort for the unsupervised pretraining of a language model is reasonable, we recognize the annotation of sufficient training data for other corpora is one of the most challenging tasks. After all, even annotations can be solved efficiently as Chan et al.'s crowdsourcing approach demonstrates <ref type="bibr" target="#b9">[10]</ref>. We are confident that our results are transferable to other domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>This paper introduces the pairwise document classification to determine semantic relations between documents as an underlying task to advance LRS and other information retrieval applications. We elaborate on why document similarity measures do not account for the heterogeneous semantics of extensive documents and argue that similarity needs a context which defines to what it relates.</p><p>The task of finding semantic document relations is implemented as a multi-class classification of document pairs. We demonstrate the viability of this approach with a new proposed dataset of 32,168 Wikipedia article pairs and Wikidata properties that define semantic relations among these articles. In an empirical study, we implement six different models AvgGloVe, Doc2vec, Siamese BERT, Siamese XLNet, vanilla BERT and vanilla XLNet, and evaluate them under different settings regarding the concatenation method and sequence length (Table <ref type="table" target="#tab_3">2</ref>). Our evaluation indicates a sequence length of 512 tokens as the best performing sequence limit for the Siamese and vanilla Transformer models. In addition, we identify [u; v; |u − v |; u * v] as the best concatenation method for AvgGloVe, Doc2vec and the Siamese Transformer models. With the manual sample examination and our evaluation for different relation classes, we show the behavior of the classifiers when exposed to different input data and provide an analysis over different perspectives. Moreover, the manual analysis confirms our empirical results.</p><p>Our findings suggest that pairwise document classification is a solvable task using existing techniques. Even abstract semantic relations, like facet of, yield a considerable high F1-score. This outcome motivates us to investigate the semantic relations between documents of other literature domains, primarily scientific papers. We envision a system that enables users to explore scientific literature in an analogical manner. For instance, users could retrieve other research papers with a similar methodology but different result. Analogies could be even found with programmatic and SPARQLlike queries. To develop such a system, the Open Research Knowledge Graph <ref type="bibr" target="#b19">[20]</ref> could be utilized as the scientific equivalence of Wikidata, while research paper from any open digital library, e.g., arXiv, would correspond to Wikipedia articles. Lastly, the presented Wikipedia and Wikidata dataset also facilitate the evaluation of methods in terms of required training data. The estimation the necessary amount of data would a prerequisite for looking into other domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>…</head><label></label><figDesc>Other persons who were educated at the same institution Other persons who have the same citizenship</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Semantic relations between Wikipedia articles. Seed article Albert Einstein is connected to other articles by the property educated at and citizenship. Considering articles only a single edge apart leads to diverse recommendations, while two edges can be utilized for recommendation sets focused on a specific or an intersection of aspects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Vanilla Transformer for sequence pair classification. [SEP]-token separates seed and target document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Siamese Transformer architecture. Both documents fed separately trough the Transformer, the concatenated document vectors are input to the classification layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>3. 6 . 2</head><label>62</label><figDesc>Concatenation. Doc2vec, GloVe, and the Siamese models concatenate the separately encoded document vectors ì d s and ì d t . In the literature, there is no widely accepted concatenation method. For instance, Conneau et al. [12] use [u; v; |u −v |; u * v] for sentence embedding, while Sentence-BERT [34] presents [u; v; |u −v |] as the best method. In Section 4.3, we test the following variations: • [u; v] Concatenation of the two vectors u and v; • [u; v; |u − v |] and absolute value of element-wise difference; • [u; v; |u − v |; u * v] and element-wise product.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(micro avg.) u; v u; v; |u v| u; v; |u v|; u * v</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Results of the full-text document embeddings and Siamese Transformer-512 models w.r.t. concatenation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>precision, recall, and F1-score of the best four systems for the different model categories. Each score is the mean over the 4-fold cross-validation (cf. Table 2 for standard deviation). AvgGloVe and Siamese BERT use [u; v; |u − v; u * v] as concatenation method, and all Transformer models (Siamese BERT, vanilla BERT, and vanilla XLNet) use the 512 sequence length. The best relation classes in terms of performance are country of citizenship, none (negative samples), and different from, whereas the classes employer, has quality, has effect yield the lowest scores. Given that the best performing classes are also over-represented in terms of sample count, the outcome suggests that other classes only need more training data. Still, the comparison of the employer class (389 test samples, vanilla BERT 0.740 F1) and facet of (336 test samples, vanilla BERT 0.911) reveals that the performance difference is also due to the diverse requirements of classes themselves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>o p p o s it e o f c o u n t r y o f c it iz e n s h ip s y m p t o m s h a s q u a li t y e d u c a t e d a t e m p lo y e r f a c e t o f d if f e r e n t f r o m h a s e f f e c t n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Confusion matrix for the predicted and Wikidata classes of vanilla BERT. The relation count is normalized. The most frequent confusion is found with the educated at and employer class for 27% of the test samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The triple (d s , d t , r i ) of two documents d s and d t , and the relation class r i describes a document pair relation. In the Resource Description Framework (RDF) terminology, d s is the subject, d t the object, and r i the predicate, whereas in the Wikidata terminology, a relation corresponds to a statement 1 . The relation class r i (predicate) is a Wikidata property that semantically relates a pair of Wikipedia articles (d s , d t ). For instance, the Wikipedia article of Albert Einstein 2 and its Wikidata item</figDesc><table><row><cell>. Wikipedia is connected</cell></row><row><cell>with Wikidata, an open knowledge graph in which nodes represent</cell></row><row><cell>items (e.g., Wikipedia articles) and edges represent properties of</cell></row><row><cell>these items (e.g., relation that connect two different articles). The</cell></row><row><cell>link of most Wikipedia articles to their corresponding Wikidata</cell></row><row><cell>items allows the construction of a large dataset tailored to the prob-</cell></row><row><cell>lem of semantic relation classification.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The relation classes with their Wikidata PIDs, three examples, and the number of samples in our dataset.</figDesc><table><row><cell>Relation class</cell><cell>PID</cell><cell># Example relations</cell></row><row><cell cols="2">country of citizenship P27</cell><cell>3636 Torben Ulrich → Denmak</cell></row><row><cell></cell><cell></cell><cell>Neal Doughty → United States</cell></row><row><cell></cell><cell></cell><cell>Julian Kenny → Trinidad and Tobago</cell></row><row><cell>different from</cell><cell>P1889</cell><cell>4048 Computer file → File folder</cell></row><row><cell></cell><cell></cell><cell>Lee County, Alabama → Lee County, Illinois</cell></row><row><cell></cell><cell></cell><cell>Karo → Karo (name)</cell></row><row><cell>educated at</cell><cell>P69</cell><cell>1798 Hillar Eller → University of Tartu</cell></row><row><cell></cell><cell></cell><cell>Al Young → University of Michigan</cell></row><row><cell></cell><cell></cell><cell>Heinrich Finkelstein → Leipzig University</cell></row><row><cell>employer</cell><cell>P108</cell><cell>1557 Gary M. Mavko → Stanford University</cell></row><row><cell></cell><cell></cell><cell>Alexander Medvedev → Gazprom</cell></row><row><cell></cell><cell></cell><cell>John Reif → Duke University</cell></row><row><cell>facet of</cell><cell>P1269</cell><cell>1343 Reformation → Protestantism</cell></row><row><cell></cell><cell></cell><cell>1974 in Portugal → Portugal</cell></row><row><cell></cell><cell></cell><cell>Sportsmanship → Sport</cell></row><row><cell>has effect</cell><cell>P1542</cell><cell>698 Language attrition → Extinct language</cell></row><row><cell></cell><cell></cell><cell>Arsenic poisoning → Lung cancer</cell></row><row><cell></cell><cell></cell><cell>Foul ball → Out (baseball)</cell></row><row><cell>has quality</cell><cell>P1552</cell><cell>1022 Antisemitism → Nazism</cell></row><row><cell></cell><cell></cell><cell>Employment → Access badge</cell></row><row><cell></cell><cell></cell><cell>Human → Gender</cell></row><row><cell>opposite of</cell><cell>P461</cell><cell>929 Floor → Ceiling</cell></row><row><cell></cell><cell></cell><cell>Person → Society</cell></row><row><cell></cell><cell></cell><cell>Exponentiation → Logarithm</cell></row><row><cell>symptoms</cell><cell>P780</cell><cell>1053 Myalgia → Influenza</cell></row><row><cell></cell><cell></cell><cell>Mercury poisoning → Cough</cell></row><row><cell></cell><cell></cell><cell>Death rattle → Sound</cell></row><row><cell></cell><cell cols="2">Total 16,084</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>the plain-text from the Wikipedia articles. For AvgGloVe, the individual words occurring in the article text are extracted with Scikit-learn's CountVectorizer11 including English stop word removal. The Transformer models require a GPU as hardware. We rely on HuggingFace's PyTorch implementation<ref type="bibr" target="#b39">[40]</ref> of BERT and XLNet. The training time for a single epoch on a GeForce GTX 1080 Ti (11 GB) ranged from less than 10 minutes for vanilla BERT-128 (simplest Transformer architecture), to 55 minutes for Siamese</figDesc><table /><note>XLNet-512 (most complex Transformer architecture). As suggested in<ref type="bibr" target="#b14">[15]</ref>, the Transformer training is performed with batch size b = 4, dropout probability d = 0.1, learning rate η = 2 −4 (Adam optimizer) and 4 training epochs. If not otherwise stated, the default settings of the frameworks were used. The evaluation is conducted as stratified k-fold cross-validation with k = 4 and 24,126 training, and 8,041 test samples (the class distribution remains identical for each fold). The source code, dataset, and trained models are publicly available on Zenodo 12 , GitHub13 and as a demo on Google Colab 14 .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results as micro avg. F1-score with standard deviation in 4-fold cross-validation for all system configurations including full-text document embeddings from GloVe and Doc2vec, and vanilla and Siamese Transformers (BERT-base and XLNet-base). Vanilla BERT-512 performs best.</figDesc><table><row><cell>Model</cell><cell>Seq.</cell><cell>Concatenation</cell><cell>F1</cell><cell>Std.</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.863 ± 0.0040</cell></row><row><cell>AvgGloVe</cell><cell>-</cell><cell>u; v; |u − v |</cell><cell cols="2">0.871 ± 0.0045</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.875 ± 0.0036</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.838 ± 0.0049</cell></row><row><cell>Doc2vec</cell><cell>-</cell><cell>u; v; |u − v |</cell><cell cols="2">0.836 ± 0.0048</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.845 ± 0.0019</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.844 ± 0.0025</cell></row><row><cell></cell><cell>128</cell><cell>u; v; |u − v |</cell><cell cols="2">0.859 ± 0.0080</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.856 ± 0.0102</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.851 ± 0.0046</cell></row><row><cell>Siamese BERT</cell><cell>256</cell><cell>u; v; |u − v |</cell><cell cols="2">0.860 ± 0.0137</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.862 ± 0.0090</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.846 ± 0.0050</cell></row><row><cell></cell><cell>512</cell><cell>u; v; |u − v |</cell><cell cols="2">0.860 ± 0.0087</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.870 ± 0.0067</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.855 ± 0.0075</cell></row><row><cell></cell><cell>128</cell><cell>u; v; |u − v |</cell><cell cols="2">0.869 ± 0.0061</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.867 ± 0.0068</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.856 ± 0.0106</cell></row><row><cell>Siamese XLNet</cell><cell>256</cell><cell>u; v; |u − v |</cell><cell cols="2">0.869 ± 0.0071</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.870 ± 0.0078</cell></row><row><cell></cell><cell></cell><cell>u; v</cell><cell cols="2">0.856 ± 0.0110</cell></row><row><cell></cell><cell>512</cell><cell>u; v; |u − v |</cell><cell cols="2">0.860 ± 0.0179</cell></row><row><cell></cell><cell></cell><cell>u; v; |u − v |; u  *  v</cell><cell cols="2">0.864 ± 0.0096</cell></row><row><cell></cell><cell>128</cell><cell>-</cell><cell cols="2">0.920 ± 0.0028</cell></row><row><cell>Vanilla BERT</cell><cell>256</cell><cell>-</cell><cell cols="2">0.930 ± 0.0042</cell></row><row><cell></cell><cell>512</cell><cell>-</cell><cell cols="2">0.933 ± 0.0039</cell></row><row><cell></cell><cell>128</cell><cell>-</cell><cell cols="2">0.914 ± 0.0065</cell></row><row><cell>Vanilla XLNet</cell><cell>256</cell><cell>-</cell><cell cols="2">0.914 ± 0.0023</cell></row><row><cell></cell><cell>512</cell><cell>-</cell><cell cols="2">0.926 ± 0.0016</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Results for precision (P), recall (R), F1-score, and sample count in test data w.r.t. relation classes. Evaluated systems are AvgGloVe, Siamese BERT, vanilla BERT and vanilla XLNet. The results of other models are published along with the code.</figDesc><table><row><cell>Model</cell><cell></cell><cell>AvgGloVe</cell><cell></cell><cell cols="3">Siamese BERT-512</cell><cell cols="3">Vanilla BERT-512</cell><cell cols="3">Vanilla XLNet-512</cell></row><row><cell>Relation class</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell cols="2">F1 Samples</cell></row><row><cell>country of citizenship</cell><cell cols="9">0.963 0.983 0.973 0.956 0.996 0.976 0.993 0.996 0.994</cell><cell cols="3">0.989 0.996 0.993</cell><cell>909</cell></row><row><cell>different from</cell><cell cols="9">0.856 0.843 0.849 0.872 0.899 0.885 0.971 0.931 0.950</cell><cell cols="3">0.969 0.933 0.950</cell><cell>1012</cell></row><row><cell>educated at</cell><cell cols="6">0.683 0.729 0.703 0.730 0.740 0.734</cell><cell cols="6">0.759 0.900 0.817 0.774 0.759 0.763</cell><cell>450</cell></row><row><cell>employer</cell><cell cols="9">0.662 0.620 0.639 0.639 0.769 0.695 0.892 0.653 0.740</cell><cell cols="3">0.711 0.748 0.725</cell><cell>389</cell></row><row><cell>facet of</cell><cell cols="9">0.786 0.781 0.782 0.839 0.785 0.810 0.916 0.908 0.911</cell><cell cols="3">0.888 0.904 0.896</cell><cell>336</cell></row><row><cell>has effect</cell><cell cols="9">0.644 0.606 0.620 0.626 0.468 0.502 0.783 0.614 0.683</cell><cell cols="3">0.768 0.658 0.704</cell><cell>175</cell></row><row><cell>has quality</cell><cell cols="6">0.694 0.682 0.687 0.662 0.619 0.639</cell><cell cols="6">0.718 0.797 0.749 0.763 0.799 0.774</cell><cell>256</cell></row><row><cell>opposite of</cell><cell cols="6">0.672 0.666 0.667 0.540 0.791 0.640</cell><cell cols="6">0.761 0.763 0.756 0.773 0.835 0.795</cell><cell>232</cell></row><row><cell>symptoms</cell><cell cols="6">0.887 0.932 0.908 0.827 0.969 0.892</cell><cell cols="3">0.872 0.973 0.920</cell><cell cols="3">0.864 0.984 0.919</cell><cell>263</cell></row><row><cell>none</cell><cell cols="6">0.943 0.940 0.942 0.955 0.897 0.925</cell><cell cols="6">0.978 0.981 0.979 0.979 0.968 0.973</cell><cell>4021</cell></row><row><cell>micro avg</cell><cell cols="9">0.875 0.875 0.875 0.870 0.870 0.870 0.933 0.933 0.933</cell><cell cols="3">0.926 0.926 0.926</cell><cell>8043</cell></row><row><cell>macro avg</cell><cell cols="9">0.779 0.778 0.777 0.764 0.793 0.770 0.864 0.852 0.850</cell><cell cols="3">0.848 0.858 0.849</cell><cell>8043</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Example relations between Wikipedia article pairs (seed and target) as defined by Wikidata and as predicted by Vanilla BERT-512 with the first and second highest probability. Correct predictions are marked with ✓.</figDesc><table><row><cell cols="2">ID Seed</cell><cell>Target</cell><cell>Wikidata Relation</cell><cell>1st Prediction</cell><cell>2nd Prediction</cell></row><row><cell>1</cell><cell>Rudolf Muradyan</cell><cell>Brazil</cell><cell cols="2">country of citizenship none</cell><cell>country of citizenship ✓</cell></row><row><cell>2</cell><cell>Rudolf Muradyan</cell><cell>Armenia</cell><cell cols="3">country of citizenship country of citizenship ✓ none</cell></row><row><cell>3</cell><cell cols="2">Zaki Naguib Mahmoud Cairo University</cell><cell>educated at</cell><cell>employer</cell><cell>educated at ✓</cell></row><row><cell>4</cell><cell cols="2">Zaki Naguib Mahmoud King's College London</cell><cell>educated at</cell><cell>employer</cell><cell>educated at ✓</cell></row><row><cell>5</cell><cell>Light</cell><cell>Darkness</cell><cell>opposite of</cell><cell>has quality</cell><cell>opposite of ✓</cell></row><row><cell>6</cell><cell>Mexican Revolution</cell><cell cols="2">Mexican War of Independence different from</cell><cell>has effect</cell><cell>symptoms</cell></row><row><cell>7</cell><cell>History of blogging</cell><cell>Blog</cell><cell>facet of</cell><cell>opposite of</cell><cell>different from</cell></row><row><cell>8</cell><cell>Iced tea</cell><cell>Ice-T</cell><cell>different from</cell><cell>none</cell><cell>different from ✓</cell></row><row><cell>9</cell><cell>Alcoholism</cell><cell>Cirrhosis</cell><cell>has effect</cell><cell>has effect ✓</cell><cell>none</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://www.wikidata.org/wiki/Help:Statements</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://en.wikipedia.org/wiki/Albert_Einstein</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://www.wikidata.org/wiki/Q937</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://en.wikipedia.org/wiki/German_Empire</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">https://www.wikidata.org/wiki/Q43287</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">https://www.wikidata.org/wiki/Property:P27</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">https://tools.wmflabs.org/hay/propbrowse/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7">https://nlp.stanford.edu/projects/glove/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8">https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_9">https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text. CountVectorizer.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_10">https://doi.org/10.5281/zenodo.3713183</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_11">https://github.com/malteos/semantic-document-relations</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_12">https://ostendorff.org/r/jcdl2020-colab</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_13">See https://github.com/zihangdai/xlnet#released-models "This model (XLNet-Base) is trained on full data (different from the one in the paper)".</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The research presented in this article is funded by the German Federal Ministry of Education and Research (BMBF) through the project QURATOR (Unternehmen Region, Wachstumskern, no. 03WKDA1A).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">DocBERT: BERT for Document Classification</title>
		<author>
			<persName><forename type="first">Ashutosh</forename><surname>Adhikari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Achyudh</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><surname>David R Cheriton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08398v1</idno>
		<ptr target="https://arxiv.org/pdf/1904.08398" />
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Applying BERT to Document Retrieval with Birch</title>
		<author>
			<persName><forename type="first">Zeynep</forename><surname>Akkalyoncu Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3004</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-3004" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations. 19-24</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations. 19-24</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analogies Explained: Towards Understanding Word Embeddings</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
				<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A simple but though Baseline for Sentence Embeddings</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="416" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scientific Paper Recommendation: A Survey</title>
		<author>
			<persName><forename type="first">Xiaomei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangjie</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="9324" to="9339" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Bär</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A reflective view on text similarity. International Conference Recent Advances in Natural Language Processing</title>
				<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="515" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Researchpaper recommender systems: a literature survey</title>
		<author>
			<persName><forename type="first">Joeran</forename><surname>Beel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bela</forename><surname>Gipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Breitinger</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00799-015-0156-0</idno>
		<ptr target="https://doi.org/10.1007/s00799-015-0156-0" />
	</analytic>
	<monogr>
		<title level="j">International Journal on Digital Libraries</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="305" to="338" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SciBERT: A Pretrained Language Model for Scientific Text</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1371</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1371" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3613" to="3618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Signature verification using a Siamese time delay neural network</title>
		<author>
			<persName><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Bentz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yann Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sackinger</surname></persName>
		</author>
		<author>
			<persName><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1993">1993. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SOLVENT: A Mixed Initiative System for Finding Analogies between Research Papers</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Chee</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dafna</forename><surname>Shahaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aniket</forename><surname>Kittur</surname></persName>
		</author>
		<idno type="DOI">10.1145/3274300</idno>
		<ptr target="https://doi.org/10.1145/3274300" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2018-11">2018. nov 2018</date>
		</imprint>
	</monogr>
	<note>CSCW</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What Does BERT Look at? An Analysis of BERT&apos;s Attention</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-4828</idno>
		<ptr target="https://doi.org/10.18653/v1/W19-4828" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACL Workshop BlackboxNLP</title>
				<meeting>the 2019 ACL Workshop BlackboxNLP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="276" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loïc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1070</idno>
		<ptr target="https://doi.org/10.18653/v1/D17-1070" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="670" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Document Embedding with Paragraph Vectors</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.07998</idno>
		<ptr target="http://arxiv.org/abs/1507.07998" />
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transformer-XL: Attentive Language Models beyond a Fixed-Length Context</title>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1285</idno>
		<ptr target="https://doi.org/10.18653/v1/P19-1285" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2978-2988</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics. 2978-2988</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
				<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatically Constructing a Corpus of Sentential Paraphrases</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Workshop on Paraphrasing (IWP2005)</title>
				<meeting>the Third International Workshop on Paraphrasing (IWP2005)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Schema induction and analogical transfer</title>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">L</forename><surname>Gick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(83)90002-6</idno>
		<ptr target="https://doi.org/10.1016/0010-0285" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="90002" to="90006" />
			<date type="published" when="1983">1983. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><surname>Goodman</surname></persName>
		</author>
		<title level="m">Seven strictures on similarity. Problems and projects</title>
				<imprint>
			<date type="published" when="1972">1972. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Embeddings for Word Sense Disambiguation: An Evaluation Study</title>
		<author>
			<persName><forename type="first">Ignacio</forename><surname>Iacobacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Taher Pilehvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1085</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-1085" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="897" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Open Research Knowledge Graph: Next Generation Infrastructure for Semantic Scholarly Knowledge</title>
		<author>
			<persName><forename type="first">Mohamad</forename><surname>Yaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaradeh</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Allard</forename><surname>Oelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kheir</forename><forename type="middle">Eddine</forename><surname>Farfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Prinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Jennifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gábor</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Kismihók</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sören</forename><surname>Stocker</surname></persName>
		</author>
		<author>
			<persName><surname>Auer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3360901.3364435</idno>
		<ptr target="https://doi.org/10.1145/3360901.3364435" />
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="243" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantic relations in information science</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin-Cheon</forename><surname>Khoo</surname></persName>
		</author>
		<author>
			<persName><surname>Na</surname></persName>
		</author>
		<idno type="DOI">10.1002/aris.1440400112</idno>
		<ptr target="https://doi.org/10.1002/aris.1440400112" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="157" to="228" />
			<date type="published" when="2007-09">2007. sep 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Jey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><surname>Baldwin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w16-1609</idno>
		<ptr target="https://doi.org/10.18653/v1/w16-1609" />
	</analytic>
	<monogr>
		<title level="m">Proceedings Workshop on Representation Learning for NLP</title>
				<meeting>Workshop on Representation Learning for NLP</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning</title>
				<meeting>the 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards analogy-based recommendation: Benchmarking of perceived analogy semantics</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Lofi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nava</forename><surname>Tintarev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEUR Workshop Proceedings 1892</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="9" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<ptr target="http://arxiv.org/abs/1301.3781" />
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Measuring the Similarity of Sentential Arguments in Dialogue</title>
		<author>
			<persName><forename type="first">Amita</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-3636</idno>
		<ptr target="https://doi.org/10.18653/v1/W16-3636" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
				<meeting>the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="276" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Alessandro Micarelli, and Joeran Beel. 2019. BERT, ELMo, use and infersent sentence encoders: The Panacea for research-paper recommendation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Mohamed</forename><surname>Hebatallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Sansonetti</surname></persName>
		</author>
		<author>
			<persName><surname>Gasparetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEUR Workshop Proceedings</title>
				<imprint>
			<biblScope unit="volume">2431</biblScope>
			<biblScope unit="page" from="6" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Finding Related Pages Using Green Measures : An Illustration with Wikipedia</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Ollivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence Conference</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1427" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Enriching BERT with Knowledge Graph Embedding for Document Classification</title>
		<author>
			<persName><forename type="first">Malte</forename><surname>Ostendorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bourgonje</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Moreno-Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Rehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the GermEval 2019 Workshop</title>
				<meeting>the GermEval 2019 Workshop</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scikit-learn: Machine Learning in Python</title>
				<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Glove: Global Vectors for Word Representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
		<ptr target="https://doi.org/10.3115/v1/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Towards Discourse Parsing-inspired Semantic Storytelling</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Rehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karolina</forename><surname>Zaczynska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><forename type="middle">Moreno</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malte</forename><surname>Ostendorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bourgonje</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Rauenbusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikka</forename><surname>Wild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of QURATOR 2020 -The conference for intelligent content solutions</title>
				<meeting>QURATOR 2020 -The conference for intelligent content solutions</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName><forename type="first">Radim</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
				<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2019 Conference on Empirical Methods in Natural Language Processing</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-sense embeddings through a word sense disambiguation process</title>
		<author>
			<persName><forename type="first">Terry</forename><surname>Ruas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Grosky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2019.06.026</idno>
		<ptr target="https://doi.org/10.1016/j.eswa.2019.06.026" />
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="288" to="303" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Evaluating Link-based Recommendations for Wikipedia</title>
		<author>
			<persName><forename type="first">Malte</forename><surname>Schwarzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Meuschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Breitinger</surname></persName>
		</author>
		<idno type="DOI">10.1145/2910896.2910908</idno>
		<ptr target="https://doi.org/10.1145/2910896.2910908" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM/IEEE Joint Conference on Digital Libraries (JCDL&apos;16</title>
				<meeting>the 16th ACM/IEEE Joint Conference on Digital Libraries (JCDL&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Attention Is All You Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30 NIPS</title>
				<imprint>
			<date type="published" when="2017-06">2017. jun 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Wikidata: a free collaborative knowledgebase</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Vrandecic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w18-5446</idno>
		<idno>ICLR 2019</idno>
		<ptr target="https://doi.org/10.18653/v1/w18-5446" />
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">HuggingFace&apos;s Transformers: State-of-the-art Natural Language Processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Brew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<ptr target="http://arxiv.org/abs/1910.03771" />
		<imprint>
			<date type="published" when="2019-10">2019. oct 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="5754" to="5764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">DocRED: A Large-Scale Document-Level Relation Extraction Dataset</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1074</idno>
		<ptr target="https://doi.org/10.18653/v1/P19-1074" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="764" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Aligning books and movies: Towards story-like visual explanations by watching movies and reading books</title>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2015.11</idno>
		<ptr target="https://doi.org/10.1109/ICCV.2015.11" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision 2015 Inter</title>
				<meeting>the IEEE International Conference on Computer Vision 2015 Inter</meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
