<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An improved ant colony optimization algorithm for solving a complex combinatorial optimization problem §</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-10-17">17 October 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jingan</forename><surname>Yang</surname></persName>
							<email>jayang@mail.hf.ah.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Artificial Intelligence</orgName>
								<orgName type="department" key="dep2">School of Computer and Information Sciences</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<postCode>230009</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Changhzou Key Laboratory of Software Technology and Applications</orgName>
								<address>
									<addrLine>Jiangsu Province</addrLine>
									<postCode>213002</postCode>
									<settlement>Changzhou</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanbin</forename><surname>Zhuang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Changhzou Key Laboratory of Software Technology and Applications</orgName>
								<address>
									<addrLine>Jiangsu Province</addrLine>
									<postCode>213002</postCode>
									<settlement>Changzhou</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computer and Information Engineering</orgName>
								<orgName type="institution">Changzhou Institute of Technology</orgName>
								<address>
									<addrLine>Jiangsu Province</addrLine>
									<postCode>213002</postCode>
									<settlement>Changzhou</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Changhzou Key Laboratory of Software Technology and Applications</orgName>
								<address>
									<addrLine>Jiangsu Province</addrLine>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Anhui Province</orgName>
								<orgName type="institution">Hefei University of Technology</orgName>
								<address>
									<postCode>230009</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An improved ant colony optimization algorithm for solving a complex combinatorial optimization problem §</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-10-17">17 October 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">3EF8F0CDCC67E5B4F7B383A2B046C99E</idno>
					<idno type="DOI">10.1016/j.asoc.2009.08.040</idno>
					<note type="submission">Received 5 March 2008 Received in revised form 25 November 2008 Accepted 29 August 2009</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Ant colony optimization Combinatorial optimization problem Mobile agent routing problem Premature convergence probability Traveling salesman problems Simulated annealing</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an improved ant colony optimization algorithm (IACO) for solving mobile agent routing problem. The ants cooperate using an indirect form of communication mediated by pheromone trails of scent and find the best solution to their tasks guided by both information (exploitation) which has been acquired and search (exploration) of the new route. Therefore the premature convergence probability of the system is lower. The IACO can solve successfully the mobile agent routing problem, and this method has some excellent properties of robustness, self-adaptation, parallelism, and positive feedback process owing to introducing the genetic operator into this algorithm and modifying the global updating rules. The experimental results have demonstrated that IACO has much higher convergence speed than that of genetic algorithm (GA), simulated annealing (SA), and basic ant colony algorithm, and can jump over the region of the local minimum, and escape from the trap of a local minimum successfully and achieve the best solutions. Therefore the quality of the solution is improved, and the whole system robustness is enhanced. The algorithm has been successfully integrated into our simulated humanoid robot system which won the fourth place of RoboCup2008 World Competition. The results of the proposed algorithm are found to be satisfactory.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, neural networks, cell automation, and evolutionary computation have received increasing attention in the intelligent computation technologies. They are developed by simulating natural phenomenon. These technologies are highly parallel, self-adaptive, self-organized, and are full of vigor and vitality in computation intelligence.</p><p>Ant colony optimization (ACO) is a technique of problem solving inspired by the behavior of ants in finding paths from the nest to food and a new search metaphor for solving combinatorial optimization problems, and has been unexpectedly successful in recent years <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. The ants cooperate using an indirect form of communication mediated by pheromone trails of scent and find an optimal solution to their tasks guided by both information (exploitation) which has been acquired and search (exploration) of the new route. Therefore the premature convergence probability of the system is lower. Dorigo et al. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> proposed ant colony algorithm based on the bionics research achievement foundation and applied successfully this algorithm to solve different combinatorial optimization problems, such as the TSP problem <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>, the quadratic assignment problem <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, the job-shop scheduling problem <ref type="bibr" target="#b13">[14]</ref>, sequential ordering problem <ref type="bibr" target="#b14">[15]</ref>, the vehicle routing problem (VRP) <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref>, and data mining <ref type="bibr" target="#b19">[20]</ref> and network routing. Stu ¨tzle and Hoos introduced Max-Min Ant System (MMAS) <ref type="bibr" target="#b20">[21]</ref>, a modification of an ant system applied to traveling salesman problem (TSP). These authors explicitly introduced two important user-defined parameters, a maximum and minimum trail levels, whose values are chosen in a problemdependent way in order to restrict possible trail values to the interval [t min , t max ]. Moreover, the MMAS controls the trail levels (initialized to the maximum value), only allowing the best ant at each iteration to update trails, thus providing a positive feedback on its results. Trails that never or rarely receive reinforcements will continuously lower their trail intensity of scent left on routes and will be selected more and more rarely by the ants, until they reach the value. The parameters, t min and t max , are used to counteract premature stagnation of search for avoiding early convergence to a local minimum, maintaining some kind of elitist strategy at the same time. ACO is a new search metaphor for solving the combinatorial optimization problems, and has been successfully applied to many complex optimization problems, especially applied to the complex discrete optimization problems. The essence of the ant colony optimization process lies in: (1) the selecting mechanism: the more pheromone trail on the route, the larger probability of choosing this route; (2) the updating mechanism: the pheromone on the route can get strong when ant's pass more and moreover simultaneously also gradually volatilizes and vanishes as time goes on; (3) the coordinated mechanism: the mutual communication and coordinated operation between the ants is performed in fact through the ''pheromone''. The ant colony algorithm has fully used such optimized mechanism to finally find the best solution through information exchange and mutual cooperation between the individuals, and enable this algorithm to have a very strong ability to discover the best solutions.</p><p>As a new completely distributed computation tool, a mobile agent can overcome some shortcomings of Client/Server by transmitting their own code and states to the remote host computer and by the way in which it is carried out in local computers using the remote host computer. Thus a mobile agent is one of the main research directions of the distributed computation <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. The mobile agent may move from one host computer to another host computer according to requirements, and complete the global distributed computation tasks using local computation ability and the resources of the various host computers. How do the mobile agent move between the host computers according to the kind of strategies in the process to execute tasks is an important question, how to complete the computation task efficiently and fast, also is the mobile agent routing problem discussed in this paper. This paper proposes an improved ant colony algorithm. This method investigates a mutation genetic operator and modifies the global updating rules and can solve some mobile agent routing problems, and escape from the trap of a local minimum, and speed up the convergence rate. Our algorithm has some excellent properties of robustness, self-adaptation, parallelism, and positive feedback process owing to introducing the genetic operator and modifying the global updating rules. Therefore the mobile agents can perform the distributed computation tasks with optimization efficiency at a fast rate. The experimental results here also have demonstrated that the improved ant colony system may solve some complex combinatorial optimization problems through cooperation between the ants (also regarded as an agent) and indicates some inherent advantages of robustness, self-adaptation, parallelism and positive feedback. The positive feedback process accounts for rapid discovery of good solutions, and the distributed computation avoids premature convergence, and the greedy heuristic helps find acceptable solutions in the early stages of the search process. But we also may introduce some specific questions-correlated domain knowledge, and provide some fully novel ideas for solving certain complex estimation problems.</p><p>The rest of this paper is organized as follows: Section 2 outlines an ant colony algorithm; Section 3 describes how to solve the mobile agent routing problem. We solve the mobile agent routing problem using the improved ant colony algorithm in Section 4 and show the experimental results in Section 5. Section 6 summarizes our algorithm and suggests our further work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Ant colony algorithm</head><p>Ant colony optimization (ACO) is a promising metaheuristic and a great amount of research has been devoted to its empirical and theoretical analysis. The ACO has been and continues to be a fruitful paradigm for designing effective combinatorial optimization algorithms.</p><p>The ants can carry on indirect communication through a chemical substance pheromone <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref>, which is accumulative and also evaporative, but finally achieve the cooperative goal. The ants travel a shorter path on which the pheromone trail accumulates faster than on the longer one. Therefore, the faster the pheromone trails increase on the short path, then the greater the probability that the ants travel this path also. The pheromone trails can deposit unceasingly and evaporate as the time goes on. At the same time, the ants also can unceasingly secrete the pheromone in their travel process, thus the pheromone trails can be updated unceasingly. The pheromone trails on the path which few ants travel decrease more and more, but the pheromone trails on the path which more ants travel increase more and more.</p><p>When an ant is looking for a new food source, each ant is not directed by the pheromone trails and wanders randomly at the initial stage, therefore the path search indicates the complete randomness. Under the pheromone direction, the probability the successor ants travel the shorter path must also be higher than the probability the ants travel a longer path. These successor ants can secrete the new pheromone on the shorter path again in the traveling process. This causes the pheromone trails on the shorter path to continue increasing, but on the longer path that not many ants travel, the pheromone trail starts to evaporate, thus reducing its attractive strength. The more time it takes for an ant to travel down the path and back again, the more time the pheromone has to evaporate. A short path, by comparison, gets marched over faster, and thus the pheromone density remains high as it is laid on the path as fast as it can evaporate. This forms a positive feedback process, and finally causes all ants to travel the shortest path, thus enabling the whole ant colony to find the shortest path from the ant nest to a food source.</p><p>Ants move by a stochastic local decision making based on two parameters, called trail of scent and attractiveness. Each ant incrementally constructs a solution to the problem as it moves. When an ant completes a solution or this solution is under construction, the ant evaluates the solution and modifies the trail value of this solution. This pheromone trail will direct the next ant search. The characteristics of the ant colony optimization algorithms are their explicit use of elements of previous solutions. In fact, they drive a constructive low-level solution, but including it in a population framework and randomizing the construction in a Monte Carlo method. Monte Carlo combination of the different solution elements is suggested also by genetic algorithms <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, but in the case of the ACO, the probability distribution is explicitly defined by previously obtained solution components. The particular way of defining components and associated probabilities is problem-specific, and can be designed in different ways, facing a trade-off between the specificity of the information used for the conditioning and the number of solutions which need to be constructed before effectively biasing the probability distribution to favor the emergence of good solutions <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The mobile agent routing problem</head><p>The distributed computation model based on a mobile agent routing problem can overcome not only drawbacks of the traditional client/server scheme, but also the flexibility, the stability, the extensibility of the ant colony system are suitable well for solving complex and modern distributed computation tasks. Thus the system may widely be applied to the distributed computation tasks, motion computation, the distributed information inspection as well as electronic commerce and so on. In the process for the mobile agents to carry out the distributed computation tasks, they are required to make careful choice to move to some host computer according to the task demand and the current network situation and complete one or several subtasks. After completing the subtasks, they move again to another host computer, and continue other subtasks, repeatedly until the mobile agents complete the entire distributed computation tasks or fail. Therefore, for the distributed computation, and especially for the parallel processing of the distributed information, how to plan the motion route of a mobile agent appears especially important. Therefore, this paper defines the mobile agent routing problem as follows.</p><p>Definition 3.1. Suppose ant i fi ¼ 1; 2; . . . ; k; . . . ; lg represents a set of all ants in an ant colony, then ant k 2 ant i means some ant, l is the number of the ants in the ant colony. Definition 3.2. t 0 is defined as the initial pheromone value, t i j ðtÞ means the pheromone trail laying on the edge (i; j) visited at time t, and Dt k i j represents the amount of the trail contributions by ant k that used move (i j) to construct their solution.</p><p>Definition 3.3. In ant colony optimization, a combinatorial optimization problem is mapped on an undirected graph G ¼ ðV; EÞ, where V ¼ ð0; 1; 2; . . . ; n À 1Þ is the set of vertices and E ¼ fði; jÞji; j 2 Vg is the set of unordered pairs of distinct vertices, called edges. The graph G is called constructed graph. Definition 3.4. (Mobile agent routing problem-MARP): suppose we have n host computers in the distributed computation environments, their serial numbers are 0; 1; . . . ; n À 1 respectively and a mobile agent sets out from the host computer 0 for carrying out some task. Assume the time an mobile agent needs from the host computer i to the host computer j is dði; jÞ, the probability that the mobile agent completes the task in the ith host computer is p i , then time delay in the host computer i is t i , and p 0 ¼ 0, t 0 ¼ 0. If an agent completes the task in some host computer, then the agent directly returns to the initial host computer 0, but no longer visits other host computers. If an agent cannot complete the task, the agent continues moving to another host computer until it completes the task or fails, and each host computer is visited at most one time on the way. For solving the mobile agent routing problem, we are required to propose an effective algorithm so that time for an agent to complete the task in a series of host computers is shortest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Solving MARP and solution construction</head><p>From the definition of the MARP, as we know, when a mobile agent can not complete tasks in all host computers and finally returns to the initial host computer, then MARP would degenerate to TSP. Therefore TSP is an exceptional case of the MARP. Obviously the MARP is a complex combinatorial optimization question which has very high time complexity and the spatial complexity. So the methods for solving the MARP are required to have auto-adaptive, self-learning, distributed, and parallel characteristics. Thus within the time scope to be accepted we can reach the optimization solution or the approximate optimization solution of the problems. The ant colony algorithm discussed in paper not only has these congenital characteristics, moreover also has some advantages of positive feedback, related-domain knowledge that may be introduced and so on. Therefore ant colony algorithm is extremely suitable for solving the MARP and the combinatorial optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Basic ant system</head><p>The algorithm that Dorigo first proposed is the basic ant algorithm <ref type="bibr" target="#b29">[30]</ref>. Each ant may be used to represent one mobile agent when we apply the basic ant algorithm to solve the MARP. According to the definition of the MARP, the ants prefer to choose those routes on which there is higher pheromone trail concentration, that takes a shorter and is of a higher probability, but also must first consider these host computers which have high probability to complete the tasks, because it is very possible for them to complete already the pre-assigned tasks after the ants visited certain host computes. From this the ants can directly return to the initial host computer, but need not continue visiting other host computers. According to this basic idea and the probability given by Eq. ( <ref type="formula" target="#formula_0">1</ref>), when the ant k travels, the probability that the ant k chooses the next host computer to be visited is: </p><p>where r is the current host computer which the ant is at, p k ðr; sÞ is the probability which ant k chooses the s th host computer as the next destination. The tðr; sÞ is the pheromone trail on the route between the r th host computer and the s th host computer (Suppose the pheromone trail on all routes is a constant at the initial trail level). J k ðrÞ is the set of the host computers that remain to be visited by ant k positioned in the r th host computer, bð0 b 1Þ is a parameter to control the trade off between visibility (constructive heuristic) and pheromone trail concentration. From (1) we have seen, the more pheromone trails on the route that the ants choose is, the more shorter the delay time is, the probability on which the route the ants choose is higher. This also just is the precise natural law which the actual ant colony system represents.</p><p>The pheromone trails on the route can evaporate as time goes on, and also the pheromone trails in the route can be updated after all ants completed their tours respectively and returned to the initial host computer. The updated scope is in inverseproportion to the respective total time length: </p><p>where T k is the total time for ant k to complete its tour. We can simulate the pheromone trail intensity changes caused by the pheromone volatility in the actual ant colony system and the new pheromone in the routes unceasingly secreted by the ants using Eq. ( <ref type="formula">2</ref>). Precisely owing to the pheromone existence which can cause the indirect exchange between the ants (using the choice probability of Eq. ( <ref type="formula" target="#formula_0">1</ref>) and the updated rules of Eq. ( <ref type="formula">2</ref>)), thus the whole ant colony system can find the optimization routes. After all ants complete their tour, the amount of pheromone trail is updated according to the rule:</p><formula xml:id="formula_2">t i j ðt þ 1Þ ¼ r Á t i j ðtÞ þ X k¼1 Dt k i j<label>(4)</label></formula><p>where r is a user-defined parameter that controls the speed of evaporation such that ð1 À rÞ represents the evaporation of trail between t and t þ 1, t i j ðtÞ-pheromone trail on the edge ði; jÞ at time t, and we have</p><formula xml:id="formula_3">Dt i j ¼ X m k¼1 Dt k i j<label>(5)</label></formula><p>where Dt k i j is the amount of trail laid on edge ði; jÞ by the k th ant, which can be computed as</p><formula xml:id="formula_4">Dt k i j ¼ Q L k</formula><p>if the ant k travels on edge ði; jÞ 0 otherwise</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">&lt; :</head><p>where Q is a constant, L k is the cost of the k th ant's tour (typically length). The ant colony system simply iterates a main loop where m ants construct in parallel their solutions, thereafter updating the pheromone trail levels. The performance of the algorithm depends on the correct tuning of several parameters, namely: b, relative importance of trail and attractiveness, r, trail persistence, t i j ð0Þ, initial trail level, m, number of ants, and Q, used for defining to be of high quality solutions with low cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Artificial ant colony systems</head><p>Artificial ant colony systems improve the basic ant algorithm in the following aspects:</p><p>(1) When an ant chooses the next host computer, it no longer completely obeys the previous experience, but it chooses the shorter routes with the higher pheromone trail intensity based on the certain probability by itself:</p><formula xml:id="formula_5">S ¼ arg max tðr; uÞ ½ p u dðr; uÞ Á T u b ( ) if q q 0 choose according to ð1Þ otherwise 8 &gt; &lt; &gt; :</formula><p>where q is a random variable uniformly distributed in [0,1] (q 2 ½0; 1), q 0 is a parameter which indicates a balance factor between the information which is accumulated in the moving process of an ant and the path chosen by itself. (2) Only the ants which find the shorter route currently are allowed to update the pheromone trail density, but not all ants are allowed to update the pheromone trail when they return to the initial host computer, this is called global update rule.</p><p>tðr; sÞ ð1 À rÞ Á tðr; sÞ þ r Á Dt g ðr; sÞ</p><p>where Dt g ðr; sÞ ¼ 1 T gb if ðr; sÞ 2 global-optimal path: 0 otherwise</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">&lt; :</head><p>Here T gb is the shortest time for ant to complete its tour. (3) The ants are updating the pheromone trail intensity in the routes which they pass through in the process when the ants march forward (but this is not likely basic ant algorithm, they update the pheromone intensity again after the ants return to the initial host computer), this is called local updated rule.</p><p>tðr; sÞ ð1 À rÞ Á tðr; sÞ þ r Á Dt l ðr; sÞ <ref type="bibr" target="#b6">(7)</ref> where Dt l ðr; sÞ may be set to the initial pheromone trail concentration t 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Improved ant colony algorithm</head><p>In this section, we focus our attention on investigating a mutation genetic operator by introducing a genetic algorithm into ant colony system and modifying global updating rules based on thorough research on working mechanism of ant colony system, and can solve a mobile agent routing problem. Therefore mobile agents can perform the distributed computation tasks with the optimization efficiency and much higher convergence speed. For ant colony systems have improved the basic ant algorithm. So this system causes an ant no longer to be limited to pheromone trail which is already accumulated in its march process, but makes use of both the information (exploitation) which has been acquired and the search (exploration) of new routes, thus greatly promoting the system robustness. However in the experimental process, we found that the ant colony system still fortuitously falls into a local minimum sometimes. This case causes the route which the ant completes no longer to evolve in the direction of the optimization solution so that the whole system presents premature convergence. For ant colony system to escape from a local minimum and avoiding this premature convergence, we consider adding some kind of stochastic perturbation to the solution when the local minimum situation appears. Therefore the solution can escape from the trap of a local minimum, and continues to evolve in the direction of the optimization. This paper considers solving this problem in the following two aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Application of genetic algorithm to our algorithm</head><p>We introduced genetic algorithm into our algorithm by combining two kinds of the optimization algorithms including the ant colony algorithm and genetic algorithm which all originate from the bionics principle. Genetic algorithm is actually a nonlinear optimal problem and produces inevitably local minima. The parameters of the search space in GA are encoded in the form of a chromosome-like structure. A group of these chromosomes constitutes a population. An index of merit (fitness value) is assigned to each individual chromosome according to a defined fitness function. A new generation is evolved by a selection technique, in which there is a larger probability of the fittest individuals being chosen. These chosen chromosomes are used as the parents in the construction of the next generation. A filial generation is produced as a result of reproduction operators applied to parents. There are two main reproduction operators, namely, crossover and mutation. Crossover operation is to choose stochastically two individual p 1 and p 2 from the initial population and to take p 1 and p 2 to be the father generation and produce each components of filial generation individual c only with some probability. Notable crossover techniques include the single-point, the two-point, and the uniform types. Mutation involves the modification of the value of each gene in the chromosome with some probability. The role of mutation is to restore unexplored or lost genetic material into the population to prevent the premature convergence of the GA to suboptimal solutions. Many filial generations are repeatedly produced until a predefined convergence level is reached. Suppose in the evolutionary process, the solutions fall into the local minimum for lack of global information of the environments the route of an ant is: fc 0 ; . . . ; c iÀ1 ; c i ; c iþ1 ; . . . ; c jÀ1 ; c j ; c jþ1 ; . . .g. If we have two host computers c i and c j , and make</p><formula xml:id="formula_7">1 dðc iÀ1 ; c j Þ Á t c j þ 1 dðc j ; c iþ1 Þ Á t c iþ1 þ 1 dðc jÀ1 ; c i Þ Á t c i þ 1 dðc i ; c jþ1 Þ Á t c jþ1 &gt; 1 dðc iÀ1 ; c i Þ Á t c i þ 1 dðc i ; c iþ1 Þ Á t c iþ1 þ 1 dðc jÀ1 ; c j Þ Á t c j þ 1 dðc j ; c jþ1 Þ Á t c jþ1<label>(8)</label></formula><p>then this solution mutates to fc 0 ; . . . ; c iÀ1 ; c j ; c iþ1 ; . . . ; c jÀ1 ; c i ; c jþ1 ; . . .g. After this mutation, the algorithm is allowed to escape from the trap of a local minimum, jumps over the region containing a local minimum point, and continues approaching the optimization solution. This not only improves the convergence rate of the GA, but also prevents the solution from trapping into a local optimum point, and the quality of the solution is improved. Therefore the whole system robustness is promoted. This process is shown in Fig. <ref type="figure" target="#fig_3">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Revising the global update rules</head><p>Once all ants have constructed their solutions, pheromone trails are updated as usually in ACO algorithms: first, pheromone trails are reduced by a constant factor to simulate evaporation; then, some pheromone is laid on components of the best solution. Pheromone trails are updated usually at each iteration, increasing the level of those that facilitate moves that were a part of ''good'' solutions, while decreasing all other ''bad'' solutions when all ants have completed their solution, respectively. For the current optimization solution is very possible to correspond to the local minimum, if we only make the ant which gives the current optimization solution perform the global update, then it is very possible for the whole system to fall into the local minimum. Therefore what this paper considers is: not only that optimal ant in the current cycle can perform the global update, but ''l'' optimal ants simultaneously can update the pheromone trail level laid in the route when they have completed their tours. Namely, Eq. ( <ref type="formula" target="#formula_6">6</ref>) can be revised as tðr; sÞ ð1 À rÞ Á tðr; sÞ þ where T i is the time for ith optimal solution to complete the task. Through suitably promoting the multiplicity of the solutions like this, the solution determined by using IACO can escape from the trap of a local minimum to a great extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Algorithm description</head><p>When we solve the MARP problems using the ant colony algorithm, at the preliminary stage, because there is not the pheromone trail in the paths, the ants all almost choose randomly their respective paths. The ants secrete the pheromone on the  paths when they complete a tour in the process of constructing the solution, and a superior solution of each generation can update the pheromone trail on the paths when the ants complete a tour according to the global update rule. These processes realize pheromone-based indirect and asynchronous communication among ants mediated by an environment, and form a positive feedback where effective fragments of solutions will receive a greater amount of pheromone and in turn a larger number of ants will choose the fragments of solutions and deposit pheromone. This urges the pheromone trail density in the shorter path to continue promoting in turn again. So repeatedly, constituting a positive feedback process which causes almost all ants to select the shortest path and solve the optimization solution. The algorithm for solving MARP problems is shown in Fig. <ref type="figure" target="#fig_4">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results and performance comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Results based on IACO</head><p>In order to examine the performance of the algorithm proposed in this paper, we complete some contrast experiments. First we imitate the topology of the actual network and produce the required data: Number n of the host computers, the time delay dði; jÞ between the host computers, the probability p i and the host computer operating time t i . The MARP question is solved by using basic ant algorithm, the ant colony algorithm, the improved ant colony algorithm, and the simulated annealing respectively. Then the obtained results are compared with the current results. In order to give one objective contrast standard, we also complete one experiment for solving the MARP question using the standard genetic algorithm. By means of the adjustment, the parameters were set as follows: n ¼ 30, b ¼ 0:8, q 0 ¼ 0:9, r ¼ 0:1, t ¼ 0:1, m ¼ 10. Each test iterates 10,000 times, and takes the average results of 10 experiments. Performance contrast of the experiment results of the various algorithms is shown in Table <ref type="table" target="#tab_0">1</ref>. The optimization result of each item is indicated with hold body.</p><p>The evolutionary curves of the optimization solutions and the worst solution of four algorithms are presented in Figs. <ref type="figure">3</ref> and<ref type="figure">4</ref>. Fig. <ref type="figure">3</ref> exhibits that the IACO has the fastest rate of convergence because the number of generations up to convergence is the smallest. The algorithm converging through smaller generations has better convergence performance because all the algorithms have the same population size in the experiment. On average best solution, IACO has lower solution costs than all the other algorithms at every iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Performance comparison of IACO with other algorithms</head><p>The simulated annealing (SA), tabu search (TS), genetic algorithm (GA), and ant colony system (ACS) are four of the main algorithms for solving combinatorial optimization problems of intelligent systems. Performance comparison of our algorithm with the basic ant algorithm, ant colony algorithm, GA and SA is shown in Table <ref type="table" target="#tab_0">1</ref>. Evolutionary curves of the best solution and the worst solution are presented in Figs. <ref type="figure">3</ref> and<ref type="figure">4</ref> repectively. The improved ant colony algorithm proposed in this paper not only can solve optimization solutions, but the IACO is robust, easy to escape from the trap of a local minimum, and has much higher convergence speed than that of GA and SA.</p><p>As a instance, we have evaluated some complex combinatorial optimization problems G 1 $ G 4 proposed in <ref type="bibr" target="#b30">[31]</ref> using GA, SA and our algorithms. As seen in Table <ref type="table" target="#tab_2">2</ref>, the solutions found using IACO algorithm approach the best solutions more fast than using the GA and the SA algorithms. After reaching the best solutions these solutions can stabilize in nearby the best solutions or are the approximate best solutions. The performance comparison of calculating G 1 $ G 4 using IACO, GA, and SA algorithms is shown in Table <ref type="table" target="#tab_2">2</ref>. The results in Table <ref type="table" target="#tab_2">2</ref> have demonstrated that the best solutions of G 1 $ G 4 calculated by IACO approaches most to their theoretical best solutions (À15.000, 7049.331, 680.630, and 0.054) respectively. In our experiments, we take the number of the initial solutions: N ¼ 20, the number of the individuals in population:   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>p k ðr; sÞ ¼ ½tðr; sÞ½ p s =dðr; sÞ Á t s b X u 2 J i ðrÞ ½tðr; uÞ½ p u =dðr; uÞ Á t u b s 2 J k ðrÞ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>tðr; sÞ ð1 À rÞ Á tðr; sÞ þ X m k¼1 Dt k ðr; sÞ (2) where r is a user-defined parameter, m is the number of the ants, and the updated amount of pheromone laid by ant k, Dt k ðr; sÞ, is computed as Dt k ðr; sÞ ¼ 1 T k if ðr; sÞ 2 tour done by ant k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Dt i ðr; sÞ (9) where Dt i ðr; sÞ ¼ 1 i Á T i if ðr; sÞ 2 global-optimal path:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. After mutation of the local minimum, the algorithm is allowed to escape from the trap of a local minimum, jumps over the region containing a local minimum point, and continues approaching the optimization solution.</figDesc><graphic coords="5,124.27,54.71,356.76,101.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The MARP question-solving algorithm in pseudo-code for revising the global update rules and preventing the solution from trapping into a local optimum point.</figDesc><graphic coords="5,107.72,456.66,389.87,270.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 . 3 .</head><label>43</label><figDesc>Fig. 4. Evolutionary curves of the worst solutions. Fig. 3. Evolutionary curves of the optimization solutions.</figDesc><graphic coords="6,38.61,550.60,241.17,176.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Comparison of our algorithm with other methods.</figDesc><table><row><cell>Algorithms</cell><cell>Basic ant algorithm</cell><cell>Ant colony algorithm</cell><cell>Improved ant colony algorithm</cell><cell>Genetic algorithm</cell><cell>Simulated algorithm</cell></row><row><cell>Optimal solutions</cell><cell>154</cell><cell>132</cell><cell>121</cell><cell>162</cell><cell>152</cell></row><row><cell>Average best solutions</cell><cell>160</cell><cell>137</cell><cell>125</cell><cell>167</cell><cell>179</cell></row><row><cell>Normal errors</cell><cell>0.12</cell><cell>0.09</cell><cell>0.04</cell><cell>0.08</cell><cell>0.09</cell></row><row><cell>Iteration numbers</cell><cell>8724</cell><cell>8147</cell><cell>6909</cell><cell>5926</cell><cell>5872</cell></row><row><cell>Time(s) to find BS</cell><cell>453.67</cell><cell>397.13</cell><cell>156.03</cell><cell>352.39</cell><cell>205.24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>The experimental results with different parameters of IACO.</figDesc><table><row><cell>Parameter setup</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Performance comparison of IACO with GA and SA applied to MARP.</figDesc><table><row><cell>Exams</cell><cell>Iteration times</cell><cell></cell><cell></cell><cell cols="2">Time(s) to find BSs</cell><cell></cell><cell>Average BSs</cell><cell></cell><cell></cell></row><row><cell></cell><cell>GA</cell><cell>SA</cell><cell>IACO</cell><cell>GA</cell><cell>SA</cell><cell>IACO</cell><cell>GA</cell><cell>SA</cell><cell>IACO</cell></row><row><cell>G 1</cell><cell>894</cell><cell>598</cell><cell>472</cell><cell>60.08</cell><cell>53.86</cell><cell>40.76</cell><cell>-14.136</cell><cell>-14.571</cell><cell>-14.957</cell></row><row><cell>G 2</cell><cell>4918</cell><cell>3067</cell><cell>2007</cell><cell>352.39</cell><cell>205.24</cell><cell>156.03</cell><cell>8063.12</cell><cell>7128.06</cell><cell>7051.12</cell></row><row><cell>G 3</cell><cell>5828</cell><cell>4679</cell><cell>4182</cell><cell>451.73</cell><cell>384.12</cell><cell>342.54</cell><cell>682.114</cell><cell>687.293</cell><cell>680.203</cell></row><row><cell>G 4</cell><cell>5301</cell><cell>4023</cell><cell>3894</cell><cell>411.48</cell><cell>365.40</cell><cell>319.84</cell><cell>0.056</cell><cell>0.055</cell><cell>0.0557</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J. Yang, Y. Zhuang / Applied Soft Computing 10 (2010) 653-660</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the editors and the reviewers for their valuable comments and suggestions for improving the quality of this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>M ¼ 40, and perform 30 tests repeatedly to each problem under the combination of the different parameter values using IACO, and then take its average result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparison of the results with the different parameters</head><p>Table <ref type="table">3</ref> shows the influence of the different parameter values upon the experimental results of G 1 . As can be seen, the iteration number is smallest (383.8) and the average best solutions is 14.962, when q 0 ¼ 0:7, r ¼ 0:3, p crossover ¼ 0:4, p mutation ¼ 0:5.</p><p>Our algorithm can avoid the premature convergence, escape from the trap of a local minima, jump over the region containing a local minimum point by crossover and mutation, and perform behavior switching and obstacle avoidance effectively by evolutionary learning and some results have been successfully integrated into our CZU2008 simulated humanoid robot soccer team for evolutionary global path optimization which won the fourth place of RoboCup2008 World Competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and future work</head><p>Ant colony optimization has been and continues to be a fruitful paradigm for designing effective combinatorial optimization solution algorithms. After more than ten years of researches, both its application effectiveness and its theoretical groundings have been demonstrated, making ACO one of the most successful paradigm in the metaheuristic area. This paper proposes an improved ant colony algorithm by introducing the mutation operator based on the ant colony algorithm, and improve global update rule. Therefore our algorithm not only inherits many advantages of the ant colony algorithms which integrate selflearning, distributed, parallel computing into one system by allocating a processor to each colony, but also can improve performance by allowing the algorithm to escape from the trap of a local minimum, and speed up the convergence rate. Thus this algorithm is suitable for solving the complex combinatorial optimization problems. At the same time, this paper also defines a very important mobile agent routing problem in mobile agent technology, i.e., proposes an improved ant colony optimization algorithm including a mutation genetic operator by introducing genetic algorithm into the ant colony systems based on thorough research on working mechanism of ant colony system, and solves some mobile agent routing problems using this algorithm. So mobile agents are able to carry out and complete the distributed computing tasks with the optimization efficiency and the fastest convergence rate. This algorithm has a very important significance for enhancing the performance of the mobile agent system and improving the distributed computing model. The experimental results based on the improved ant colony algorithm for solving the mobile agent routing problem have demonstrated that the algorithm is more suitable for solving the combinatorial optimization problems. This ant colony system is not only stable and may achieve the optimization solution or the approximate optimization solution, and has faster convergence rate, but the possibility for this algorithm to fall into a local minimum is extremely low, because at each local minimum, this new algorithm can perform a stochastic mutation of current solutions to escape that local minimum. Therefore the algorithm proposed in this paper is one of the many outstanding optimization algorithms. In contrast with the experimental results of the previous methods and other method, this algorithm has a strong robustness, high selfadaptation, and a fast convergence rate. But the method proposed in this paper is also required to be improved in the following aspects:</p><p>(1) the performance improvement and parameters analysis of ACO algorithm still remain in the experimental stage for lack of solid theoretical support; (2) make the thorough research on the working mechanism of ACO algorithm for reducing its algorithm complexity; (3) combine ACO algorithm with the local search strategy and improve further the quality of the optimization solutions; (4) conduct research on the parallel mechanism of the ant colony optimization algorithms so that it improves the efficiency of the algorithm used in the intelligent systems.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Ant Colony Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-07">2004, July</date>
			<publisher>MIT Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The optimization selection on the parameters of the ant colony algorithm</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of Science and Technology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="381" to="386" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ant colony optimization: a new meta-heuristic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Caro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Congress on Evolutionary Computation</title>
		<meeting>the 1999 Congress on Evolutionary Computation<address><addrLine>Washington, DC; Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ant colony optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Birattari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="28" to="39" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A short convergence proof for a class of ant colony optimization algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transctions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="358" to="365" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The ant system: optimization by a colony of cooperating agents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics: Part B</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ant algorithms for discrete optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="172" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ant colony system: a cooperative learning approach to the traveling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="66" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ant colonies for the traveling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Systems</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="73" to="81" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An ant colony optimization approach to the probabilistic traveling salesman problem</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PPSN-VII, Seventh International Conference on Parallel Problem Solving from Nature</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the PPSN-VII, Seventh International Conference on Parallel Problem Solving from Nature<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving ant colony optimization algorithms for solving traveling salesman problems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Advanced Computational Intelligence and Intelligent Informatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="434" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The ant system applied to the quadratic assignment problem</title>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="769" to="778" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ant colonies for the quadratic assignment problem</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Taillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Operational Research Society</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="167" to="176" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ant system for job-shop scheduling, JORBEL-Belgian</title>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trubia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Operations Research, Statistics and Computer Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="53" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">HAS-SOP: an hybrid ant system for the sequential ordering problem</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<idno>No. IDSIA 97-11</idno>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>IDSIA</publisher>
			<pubPlace>Lugano</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technique Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Vehicle Routing Problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM Monographs on Discrete Mathematics and Applications</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ant colony optimization for routing and load-balancing: Survey and new directions</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions of Systems, Man, and Cybernetics, Part A: System and Humans</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="560" to="572" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-objective genetic algorithms for vehicle routing problem with time windows</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ombuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hanshar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">MACS-VRPTW: A Multiple Ant Colony System for Vehicle Routing Problems with Time Windows</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">´</forename><surname>Taillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Agazzi</surname></persName>
		</author>
		<editor>D. Corne, M. Dorigo, F. Glover</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>McGraw Hill</publisher>
			<biblScope unit="page" from="63" to="76" />
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data mining with an ant colony optimization algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Parpinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on the Evolutionary Computations</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="332" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improvements on the ant system: introducing max-min ant system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stu ¨tzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICANNGA&apos;97, International Conference on ANN and Genetic Algorithms</title>
		<meeting>the ICANNGA&apos;97, International Conference on ANN and Genetic Algorithms<address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributed optimization by ant colonies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Artificial Life (ECAL&apos;91</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Varela</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Bourgine</surname></persName>
		</editor>
		<meeting>the European Conference on Artificial Life (ECAL&apos;91<address><addrLine>Paris, France; Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Publishing</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="134" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Research on the contributed computing model based on mobile agents</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Minicomputer Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="300" to="305" />
			<date type="published" when="2002-03">2002. March</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Probability collectives: a multi-agent approach for solving combinatorial optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Kulkarnia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The hyper-cube framework for ant colony optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics: Part B</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1161" to="1172" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Search biasin ant colony optimization: on the role of competition-balanced systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="2005-04">2005. April</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deception in ant colony optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3172</biblScope>
			<biblScope unit="page" from="119" to="130" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer/Heidelberg</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-objective genetic algorithms for vehicle routing problem with time windows</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Beatrice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">Ross</forename><surname>Ombuki</surname></persName>
		</author>
		<author>
			<persName><surname>Hanshar</surname></persName>
		</author>
		<author>
			<persName><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Genetic algorithm with ant colony optimization (GA-ACO) for multiple sequence alignment</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="78" />
			<date type="published" when="2008-01">2008. January</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adaptive and dynamic ant colony search algorithm for optimal distribution systems reinforcement strategy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Favuzza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Graditi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sanseverino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="42" />
			<date type="published" when="2006-02">2006. February</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<title level="m">Genetic Algorithms + Data Structures = Evolutionary Programs</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag/Heidelberg Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="261" to="262" />
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
