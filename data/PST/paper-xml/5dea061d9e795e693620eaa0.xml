<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Methodology for Cross-Platform, Event-Driven Big Data Analytics-as-a-Service</title>
				<funder>
					<orgName type="full">Universit? degli Studi di Milano</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Claudio</forename><forename type="middle">A</forename><surname>Ardagna</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DSRC</orgName>
								<orgName type="institution">Universit? degli Studi di Milano Crema</orgName>
								<address>
									<postCode>26013</postCode>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Universit? degli Studi di Milano Crema</orgName>
								<address>
									<postCode>26013</postCode>
									<region>DI</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Valerio</forename><surname>Bellandi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universit? degli Studi di Milano Crema</orgName>
								<address>
									<postCode>26013</postCode>
									<region>DI</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paolo</forename><surname>Ceravolo</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universit? degli Studi di Milano Crema</orgName>
								<address>
									<postCode>26013</postCode>
									<region>DI</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ernesto</forename><surname>Damiani</surname></persName>
							<email>ernesto.damiani@ku.ac.ae</email>
							<affiliation key="aff0">
								<orgName type="department">DSRC</orgName>
								<orgName type="institution">Universit? degli Studi di Milano Crema</orgName>
								<address>
									<postCode>26013</postCode>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Universit? degli Studi di Milano Crema</orgName>
								<address>
									<postCode>26013</postCode>
									<region>DI</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">AIISI</orgName>
								<orgName type="institution" key="instit2">Khalifa University Abu Dhabi</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rino</forename><surname>Finazzo</surname></persName>
							<email>rino.finazzo@eng.it</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">AIISI</orgName>
								<orgName type="institution" key="instit2">Khalifa University Abu Dhabi</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Engineering Ingegneria Informatica S.p.A</orgName>
								<address>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Methodology for Cross-Platform, Event-Driven Big Data Analytics-as-a-Service</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Big Data Analytics</term>
					<term>Model-Driven Development</term>
					<term>Batch and Stream Processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The advent of Big Data has revolutionized the way in which data are collected, analyzed, and processed, becoming a pre-requisite for each enterprise that competes in the global market. In this respect, the commodization of Big Data analytics is an essential goal to be faced in the near future. Recently, some preliminary approaches have been presented mostly focusing on distributing Big Data platforms as a service, while less has been done on cross-platform Big Data analytics. In this paper, we propose a model-based methodology for Big Data Analytics-as-a-Service that extends existing techniques by supporting cross-communication between batch and stream processing, deployment on multiple platforms, and end-to-end verification against users' requirements.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The design, deployment, and management of Big Data analytics requires the integration of multiple competencies during a long-lasting and layered design process, with low visibility on the contributions of internal or intermediate steps. It needs to represent and manage the interconnections between multiple stages of the analytics process, ranging from requirement specifications to deployment configuration and online monitoring. For example, the quality of a Big Data computation largely depends on data preparation; the selected algorithm is conditional to the scales of measured variables; the adopted parallelization strategies must comply with Service Level Agreements (SLAs), budget availability, or the legal framework within which a project operates.</p><p>The work in <ref type="bibr" target="#b0">[1]</ref> first proposed a Model-based Big Data Analytics-as-a-Service (MBDAaaS) methodology, implementing a semi-automatic, model-based approach driving the setup and execution of Big Data computations. Three models control the interrelated design stages. A declarative model is used to specify the abstract goals of a computation. It supports the selection of the most appropriate set of services that can be composed in a platform-agnostic procedural model defining the flow of execution of the specific computation. The procedural model is then compiled into a deployment model consisting of executable code launched within a specific platform. The approach in <ref type="bibr" target="#b0">[1]</ref>, while increasing accountability, reproducibility, and verifiability of Big Data computations, suffers from some limitations that reduce its applicability in real scenarios: i) it considers batch computations only, ii) it does not support machine learning procedures that require to bisect the execution into training and test phases; iii) it deploys the Big Data computation on a single platform; iv) it validates the consistency of the declarative model, while leaving to the user the responsibility to guarantee procedural and deployment model correctness.</p><p>In this paper, we aim to fill in the above gaps by extending the formal definition of the three specification models in <ref type="bibr" target="#b0">[1]</ref> to provide a more generic MBDAaaS methodology. Our methodology supports the design of cross-platform, eventdriven Big Data computations, increasing inspection, transparency, and reusability of the computations. The contributions of this paper are manifold as discussed in the following.</p><p>? Event-driven architecture. Today, Big Data computations can be executed on multiple platforms only by writing ad hoc code. We then develop an event-driven approach where Big Data computations are executed on multiple platforms. Our methodology introduces service connectors to automatically support correct and consistent data flowing between batch and stream services, or components belonging to different platforms. ? Multiple platforms. Our methodology implements a smart compiler supporting the deployment of interconnected computations residing on different platforms. ? End-to-end verifiability. Our methodology provides an end-to-end procedure for checking the consistency of model specifications.</p><p>2019 IEEE International Conference on Big Data (Big Data)</p><p>978-1-7281-0858-2/19/$31.00 ?2019 IEEE</p><p>? Model reuse and refinement. Our methodology supports model reuse and refinement. Declarative, procedural, and deployment models can be stored in templates and used to replicate or extend existing computations. As demonstrated in our experimental evaluation, all these elements can significantly reduce the roll-out time for design and deployment of Big Data Analytics, an unavoidable prerequisite to their commoditization.</p><p>The remaining of this paper is organized as follows. After discussing our basic concepts (Section III), we present the steps driving users in defining technology-independent compositions (Section V) that address (Section VI) their requirements in declarative models (Section IV). Section V also introduces the connectors that bind services executing on cross-platform processes. Section VII presents an experimental evaluation of our approach in a real scenario focusing on the computational overhead introduced by our solution. Section II presents the related work and Section VIII gives our concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>The interest in Big Data Analytics-as-a-Service has grown with the increasing adoption of Big Data technologies <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. The underlying ambition is to streamline the usage of a very powerful computational model refrained by the high costs of design and enactment. A careful analysis on the key components required to deliver analytics workflows as-a-Service has been proposed in <ref type="bibr" target="#b4">[5]</ref>. It emerges that Big Data-as-a-Service implies the integration of different cloud platforms/infrastructures for data collection, storage, and processing. Starting from similar considerations, Zheng et al. <ref type="bibr" target="#b5">[6]</ref> proposed an architecture to consistently manage the above key components. Demirkan et al. <ref type="bibr" target="#b6">[7]</ref> proposed a conceptual framework for service-oriented decision support systems, proposing definitions for data-, information-, and analytics-as-services. The high complexity and side-costs of designing, developing, and deploying Big Data infrastructures suggest the adoption of model-driven approaches that foster modularity, reusability, and automation of design and implementation tasks <ref type="bibr" target="#b7">[8]</ref>. Existing solutions, such as the one in <ref type="bibr" target="#b0">[1]</ref>, specify procedural models as a composition of services where the users' knowledge and competences play a fundamental role in the definition of data flows between services. One limitation acknowledged by the authors is that models are translated into a single orchestration language. Dynamic orchestration of Big Data Service Networks is proposed in <ref type="bibr" target="#b8">[9]</ref>, but the focus is on designing a single dataas-service infrastructure.</p><p>Other studies presented a cost-benefit analysis of Big Data-as-a-Service. Big Data-as-a-Service can reduce the costs of software maintenance and execution, but at the same time the costs of data transfer and the safety of the stored data represent significant concerns to be balanced. Several research efforts have been devoted to the evaluation of the economic efficiency of cloud infrastructures <ref type="bibr" target="#b9">[10]</ref>, Big Data platforms <ref type="bibr" target="#b10">[11]</ref>, or to the estimation of the technical debt on cloud-based software engineering <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SERVICE-BASED DEVELOPMENT FOR BIG DATA ANALYTICS-AS-A-SERVICE</head><p>We present an overview of our methodology, the challenges introduced by stream analytics in MBDAaaS, and the reference scenario used for validating our approach. Model-based Big Data Analytics-as-a-Service (MBDAaaS) approach, introduced in <ref type="bibr" target="#b12">[13]</ref> decouples high-level specifications in the declarative model from low-level details of the Big Data architecture. It is triggered by the definition of the declarative model and is composed of additional steps as presented in Figure <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Model-driven Methodology</head><p>Figure <ref type="figure">1</ref> describes the three phases of our methodology, which embraces a model-driven approach to support the users during the specification and execution of Big Data computations. Rectangles represent the outputs of each phase, rounded rectangles the functionalities implemented in our methodology.</p><p>Abstract goals are collected in a declarative model, which drives all subsequent activities of the design process. A procedural model is then built by composing the services compatible with the declarative goals. The instantiation of the data flow over multiple platforms/services builds on connectors regulating the execution of workflows/services within heterogeneous platforms (Section V). The service composition is finally compiled in a Deployment Model that entails the computations to be executed on one or more target platforms.</p><p>More in detail, the services compatible with the Declarative Specifications are selected from a Service Catalog, based on annotations mapping these services to requirements included in the declarative model. Then, a Big Data customer defines a platform-independent composition, called procedural model, composing the different services of the big data campaign (Step Procedural Model Definition). Compositions are modeled using an OWL-S <ref type="bibr" target="#b13">[14]</ref> representation and saved in the Service Composition Repository. Furthermore, according to Deployment Configurations, a MBDAaaS compiler instantiates the procedural model in a platform-dependent workflow, called deployment model (Step MBDAaaS Compiler). The compiler is designed to be generic and adapt to the peculiarities of the target Big Data platform. Finally, the target platform executes the deployment model carrying out the designed analytics (Step Deployment Model Execution).</p><p>The organization of specifications at different abstraction layers (i.e., declarative, procedural, and deployment) actuates our methodology and permits to incrementally refine specifications themselves. The execution of verification procedures (i.e., consistency check and coverage) along different stages guides the users in generating consistent and effective specifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Challenges</head><p>Stream analytics requires continuous and sequential processing of data produced at high-speed <ref type="bibr" target="#b14">[15]</ref>. Formally, a data stream is an ordered pair (s, ?) where: i) s is a sequence of tuples and ii) ? is a sequence of positive real time-intervals. When integrating stIIIream analytics within a semi-automatic deployment model, different challenges emerge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data flow management [C1]. Stream analytics integrate tasks by specifying the data flow regulating their execution.</head><p>The sequence imposed on the execution is data-dependent and is effective only when data are produced according to the designed conditions. In other words, the functioning is not directly dependent on the order of execution, but it depends on events activating the matching between tasks. For example, a data flow</p><formula xml:id="formula_0">{T 1 ? G 1 , G 1 ? T 2 , G 1 ? T 3 }</formula><p>states that when the results produced by T 1 reach guard G 1 , tasks T 2 and T 3 can be triggered. A practical consequence is that the design of a data flow requires to identify the guards triggering a task and model conditionals paths using these guards. We addressed this challenge using the service connectors in Section V-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Orchestration modeling [C2].</head><p>Big Data computations can orchestrate stream and batch analytics to reach an objective. Orchestration modeling is a fundamental challenge, especially in MBDAaaS where different processes must be automatically orchestrated without human intervention. It requires the definition of connectors managing computations composed of different running processes. Connectors also manage data flowing between different services and analytics processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verification [C3]. Advanced information systems based on</head><p>Big Data platforms and cloud infrastructures cannot simply rely on design-time verification, because not all the interconnections between specifications can be known a priori. This brings to the adoption of a posteriori approaches, making use of the outputs produced by the system itself. When dealing with data streams, these outputs are continuously updated and continuous verification procedures must be then actuated <ref type="bibr" target="#b15">[16]</ref>. In a MBDAaaS methodology, the outputs generated by the systems are linked back to requirements or specifications, giving to the users i) full awareness about the achievements of their design and ii) the ability to reorganize the design itself. We then depart from a verification procedure defined as a mere derivation on a set of outputs, and propose a verification procedure as a derivation over system specifications, as discussed in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Reference Scenario</head><p>Our reference scenario is an infrastructure for pollution monitoring managed by Lombardia Informatica, an agency of Lombardy region in Italy. The infrastructure is composed of a network of sensors that continuously acquire pollution data. The collected dataset is open (https://www. dati.lombardia.it) and structured in different sources that represent: i) sensors, containing information on acquiring sensors such as ID, pollutant type, unit of measure; ii) data acquisition stations, managing a set of sensors and containing information on their position (e.g. longitude/latitude); iii) pollution values, containing the values acquired by sensors, the timestamp, and the validation status. Each value is validated by a human operator that manually labels it as normal or abnormal. We demonstrate our proposal by defining and deploying a Decision Support System (DSS) for pollution data labeling. The goal is to deploy, using our methodology, a Big Data computation that can predict the labels of the data acquired by the sensors in real time, and alert the operator when anomalous values are observed. The final aim is to support human operators in validating data, reducing the time needed to identify a problem/fault, which is currently in the order of months.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DECLARATIVE SPECIFICATION OF BIG DATA COMPUTATIONS</head><p>Our methodology builds on the definition of a declarative model D that specifies the requirements shaping the whole design process. Declarative specifications are computational independent as they describe what the system is expected to do, hiding the details of procedural or architectural design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition IV.1 (Declarative Model</head><formula xml:id="formula_1">D i ). A declarative model D i is a set {RS 1 ,. . .,RS n ),</formula><p>where each RS i collects the requirements of a specific portion of the computation. RS i is defined as a set of goals G=(I,O), with I an indicator representing a way of measuring or assessing the goal, and O an objective representing the target to be achieved to consider the goal fulfilled.</p><p>We note that, while Definition IV.1 is structurally equivalent to the one in <ref type="bibr" target="#b0">[1]</ref>, D i has been extended with multiple RS to accomplish complex computations that orchestrate different executing processes. Each RS i specifies requirements for a specific process that is then orchestrated in the Big Data computation. We also note that the vocabulary at the basis of declarative model specification has been extended to accomplish stream analytics and artificial [ . . . ] " tdm " : " h t t p : / / www. t o r e a d o r-p r o j e c t . eu /TDM/ " } , " @type " : " tdm : Area " , " tdm : l a b e l " : " D a t a A n a l y t i c s " , " tdm : i n c o r p o r a t e s " : [{ " @type " : " tdm : Goal " , " tdm : l a b e l " : " A n a l y t i c s Aim" , " tdm : i n c o r p o r a t e s " : [ { " @type " : " tdm : I n d i c a t o r " , " tdm : l a b e l " : " Task " , " tdm : i n c o r p o r a t e s " : [ { " @type " : " tdm : O b j e c t i v e " , " tdm : l a b e l " : " R e g r e s s i o n "} ]} , {" @type " : " tdm : I n d i c a t o r " , " tdm : l a b e l " : " L e a r n i n g S t e p " , " tdm : i n c o r p o r a t e s " : [ {" @type " : " tdm : O b j e c t i v e " , " tdm : l a b e l " : " P r e d i c t i o n " }] } , { " @type " : " tdm : I n d i c a t o r " , " tdm : l a b e l " : " L e a r n i n g Approach " , " tdm : i n c o r p o r a t e s " : [{ " @type " : " tdm : O b j e c t i v e " , " tdm : l a b e l " : " S u p e r v i s e d "} ] [ . . . ] intelligence on non-stationary environments, where an approach for updating the model is required. For instance, the vocabulary contains goals related to Micro Batch and Stream processing, as well as algorithms classified as one-pass or multi-pass. Declarative models are specified using a JSON-LD format, to guarantee common semantics, reasoning capabilities, and interoperability among the different steps of our methodology.  <ref type="figure" target="#fig_0">2</ref> presents an excerpt of the JSON-LD for RS 1 , where the learning approach is set to supervised, the learning step to training, and the analytics aim to regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example IV.1. Our reference scenario in Section III-C implements a computation that consists of two processes aimed to i) use the historical data of pollution sensors to train a mathematical model handling DSS and ii) implement real-time analytics that uses model predictions to label incoming data as correct</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SMART MODELING OF BIG DATA COMPUTATIONS</head><p>Our methodology addresses challenges C1 and C2 in Section III-B by defining i) a procedural model extended with connectors representing the service flow of a computation, ii) a deployment model representing an executable instance of the procedural model on the target platform(s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Procedural Language for Big Data Composition</head><p>Procedural models are technology-independent compositions of abstract services that verifiably support users' requirements in the declarative models. Abstract services contain the description of the parameters required to execute them and are annotated with a set of goals G in disjunctive normal form. Service annotations provide a mapping to declarative specifications allowing users to select those services that are consistent with their requirements. An abstract service is defined as follows.</p><p>Definition V.1 (Abstract service s i ). An abstract service s i ?SC is a triple ({i 1 ,. . .,i n },{o 1 ,. . .,o m },?), where {i 1 ,. . .,i n } is a set of input parameters for service execution, {o 1 ,. . .,o m } is a set of output parameters, and ? an annotation function. ?(s i ) annotates the service with a Boolean formula of goals G?RS in a disjunctive normal form. Each abstract service s i includes a reference to a WSDL or WADL file that specifies the execution path of the concrete service used at deployment time. It is stored in a service catalog SC, which can be linked to one or more platforms. A procedural model then formally and unambiguously describes how services in the catalog must be configured and composed to create the expected Big Data computation as defined below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition V.2 (Procedural Model M ). A procedural model</head><p>M is a direct acyclic bipartite graph G(V,U,E,?), where v i ?V is a service s?SC, u i ?U is an operator or a connector, (v i ,u j )?E ((u i ,v j )?E, resp.) is an edge that points to function call f i addressing the communication link between v i and u j (u i and v j , resp.), and ?:V?C is a labeling function that associates a set {c 1 ,. . .,c n }?C of constraints with each v i ?V.</p><p>We note that V and U are two disjoint sets of vertices. We also note that constraints C express low-level settings, which are applied to the parameters of the executed services. C is defined as a collection of constraints c i of the form op(attr,value), where op is an operator in {=, =,&lt;,&gt;,?,?,?, / ?}, attr is an attribute bound to an input parameter i of a service in M , and value is a value (or an array thereof) for the given attribute.</p><p>Example V.1. Figure <ref type="figure" target="#fig_1">3</ref> presents two procedural models <ref type="foot" target="#foot_0">1</ref>that comply with declarative model specifications RS 1 and   We note that predictive labeling in Figure <ref type="figure" target="#fig_1">3</ref>(b) is replicated for each sensor in the real implementation in Section VII. Also, for simplicity, connectors between sequential nodes have been omitted.</p><p>Our procedural model clarifies the compositional aspects that often remain internals and invisible when vendorspecific solutions are used. In case of orchestration, the communication link is mediated by an orchestrator that directly interconnects services deployed on a same platform. The link can specify different types of function calls activated during the execution process following operators sequence, alternative, or parallel. In case of choreography, the communication link directly interconnects services deployed on different Big Data platforms. Communications are mediated by a connector, whose role is fundamental to address requirements coming from the need of supporting batch and stream processing in a multi-platform, event-driven Big Data computation. The role of the connector is made clear in Example V.1, where the two procedural models must be connected to permit a prediction based on the model generated (and continuously updated) during the training step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Service Connectors</head><p>A connector is a computational node implementing the logic for addressing data transfer between services executing on different processes, possibly deployed on different plat-forms. It classifies services according to two distinct roles: Producer and Consumer. Each connector is described as an abstract service characterized by three I/O streams: source (standard inputsin), destination (standard outputsout), and exception (standard errorserr). Source and destination represent a producer and consumer, respectively, linked to the connector using a data synchronization protocol. They both provide information supporting data transfer, such as service configurations, input/output data, pre-conditions, and post-conditions. The connector is defined as a composition of 5 families of components as follows:</p><p>? Trigger (T). It triggers a specific composition. It can be of two types: batch and stream. For example, it specifies the amount of data requested for initiating a batch processing or simply start a stream processing upon the arrival of a new entry. ? Filter (F). It filters the input data set received through sin and passes it over towards sout. For example, specifies a time-based or a count-based filtering window, the columns to be kept for computation, the function (e.g., average, count, join) to be applied to data before executing analytics.</p><p>? Access Control (AC). It guarantees that access privileges to data and services are enforced during computation. For example, it specifies that specific data can be accessed by specific users/components, which connect from/are deployed in a specific country.</p><p>? Mapping (M). It maps data received by the producer through sin on the input of the consumers connected through sout. For example, it might undergo a 2-step process where producer outputs are first re-ordered and then mapped 1-on-1 on consumer inputs. ? Log (L). It logs all activities of the connector. For example, it monitors the status of each producer-consumer execution and communication.</p><p>? Error/Exception (Err). It collects the errors or the exceptions generated during execution.</p><p>The logic of the connector is transparent to the abstract description provided at the procedural layer. Each connector interconnects services by matching their pre-conditions and post-conditions and is formally defined as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition V.3 (Connector ?).</head><p>A connector ?(S in ,S out ,S err ) is a composite service modeled as a direct acyclic graph G ? (V,E) with a root S in ?V of the composition representing the producer, two final nodes S out , S err ?V of the composition representing the consumer and exception manager, respectively, a vertex v i ?V for each component of class trigger, filter, access control, mapping, or log, a set of operators v i ?V modeling alternative and parallel flows.</p><p>We note that there are no specific cardinality constraints on the links a connector may have with producers and Figure <ref type="figure" target="#fig_4">4</ref> shows the connector for MBDAaaS, which is executed when some inputs (e.g., configurations, data sets) are sent by the producer on S in . All activities are monitored and logged by the log component. Upon receiving the inputs, an access control evaluation is carried out, checking whether the Big Data process privileges are enough to access input data. The input data are then filtered. For example, input data can be aggregated, cleaned, anonymized, selected according to expectations of the service consumer. A trigger component is further executed preparing activities for batch or stream analysis. Finally, the input data and relevant configurations are mapped to the output data and published on stream S out . We note that, when failures in any of the above steps are observed, an error is raised on stream S err and the connector terminates. <ref type="figure" target="#fig_1">3</ref> representing two processes (training and prediction, resp.) of a single computation. A connector is deployed to connect the two models such that the inference model calculated in service Regression Model Generator in Figure <ref type="figure" target="#fig_1">3</ref>(a) is given as input to the corresponding service Predictive Labeling in Figure <ref type="figure" target="#fig_3">3(b)</ref>. In this example, the connector can be realized using components mapping and log.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example V.2. Let us consider the two procedural models in Figure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Deployment Process</head><p>The deployment process takes as input a procedural model G(V,U,E,?) and produces as output a deployment model G (V ,U ,E ) that is ready to be executed. The deployment model has the same structure of the procedural model and substitutes each abstract service s i in G with a real service instance s ? i the target platform(s). More in detail, the deployment process works as follows.</p><p>1) The procedural model is partitioned, according to the connectors, to identify sub-models G 1 ,. . .,G n whose services are executed on the same platform. 2) Each identified sub-model G i is either associated with workflow engine (e.g., Oozie <ref type="bibr" target="#b16">[17]</ref>, Azkaban <ref type="bibr" target="#b17">[18]</ref>) that orchestrates the services or a choreography environment (e.g., Spring Cloud Data Flow) over which the services communicate. 3) For each G i , a compiler loads the specific drivers of the workflow engine/choreography environment and produces the deployment sub-model G i . Corresponding connectors ? i are also instantiated in ? i to support flowing of data between different sub-models. 4) Finally, deployment model G ={G 1 ,. . .,G n } is executed according to the implemented execution flow and corresponding connectors. The result of the deployment model execution represents the outcome of our MBDAaaS methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. VERIFICATION PROCESS</head><p>Commoditization of Big Data analytics requires a proper approach to verify the consistency of MBDAaaS specifications throughout the whole execution process as follows.</p><p>Definition VI.1 (Verification procedure). Given two sets ? i and ? j of goals G retrieved from, possibly, different specifications (e.g., declarative model and service catalog), we denote as ? i , ? j ? ? V a verification procedure that returns three disjoint subsets of goals as follows:</p><p>? Matching specifications: the set ? mat ? ? V where ?G ? ? i , G ? ? j .</p><p>? Missing specifications: the set ? mis ? ? V where ?G ? ? i , G / ? ? j .</p><p>? Supplementary specifications: the set</p><formula xml:id="formula_2">? sup ? ? V where ?G ? ? j , G / ? ? i .</formula><p>The verification procedure is applied in three phases of our methodology in Figure <ref type="figure">1</ref> as follows.</p><p>Declarative phase. The verification procedure, as already presented in <ref type="bibr" target="#b0">[1]</ref>, first checks the validity of the declarative model specifications RS i against interference rules r (Consistency Check in Figure <ref type="figure">1</ref>). Given the set ? of goals G in D i , we calculate the Cartesian product ??? and apply our verification procedure to each pair (G i ,G j ). A declarative model is valid iff ? mat =? V according to the specified interference rules.</p><p>Procedural phase. The verification procedure then checks the validity of the procedural model M (Coverage in Figure <ref type="figure">1</ref>) in two steps as follows.</p><p>? A degree of inclusion v?? of two specifications evaluates whether the designed solution meets the requirements. For example, the degree of inclusion of a declarative model D into a service catalog SC can be defined as:</p><formula xml:id="formula_3">Inclusion (D, SC ) : v = |? mat | |? mat ? ? mis | .</formula><p>Similarly, a degree of inclusion can be computed to evaluate whether a procedural model M satisfies the requirements of a declarative model D. ? A degree of compatibility expresses whether a specification includes elements not foreseen in another. For example, it how many services s?M are mapped to goals G / ?D as:</p><formula xml:id="formula_4">Compatibility (D, M ) : v = |? mat | |? mat ? ? sup | .</formula><p>Deployment phase. The verification procedure finally checks the consistency of the deployment model (Platform Execution and Audit in Figure <ref type="figure">1</ref>). It is a post-execution auditing that monitors a Big Data computation and verifies its consistency with declarative requirements. We note that deployment model consistency is outside of the scope of this paper and we refer to the SLA-based solution in <ref type="bibr" target="#b0">[1]</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXPERIMENTAL EVALUATION</head><p>We experimentally evaluated the computational overhead of our methodology and assessed the additional management effort it requires.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Computational Overhead</head><p>We tested our methodology in the reference scenario in Section III-C using data acquired in 2017. We designed a computation based on predictive analytics where i) a training process generates predictive models, one for each sensor, according to historical data collected by sensors and ii) an inference process collects streams of real data from sensors and automatically labels them as normal or abnormal according to predictive models at step i). As already discussed in Example IV.1, we defined two procedural models, one for the training process (Figure <ref type="figure" target="#fig_3">3(a)</ref>) and one for the predictive process (Figure <ref type="figure" target="#fig_3">3(b)</ref>), based on the Gradient-Boosted Trees (GBTs) algorithm. The two models have been s p a r k-f i l t e r -s e n s o r s T e s t : f i l t e r --e x p r =" s e n s o r s D F # S e n s o r I d ===5958 " --i n p u t P a t h =" / u s e r / r o o t / s e n s o r s / j o i n e d . c s v " --o u t p u t P a t h =" / u s e r / r o o t / s e n s o r s t e s t . c s v " &amp;&amp; s p a r k-a s s e m b l e r T e s t : s p a r k-a s s e m b l e r --f e a t u r e s =" Data , Quote " --i n p u t P a t h =" / u s e r / r o o t / s e n s o r s t e s t . c s v " --o u t p u t P a t h =" / u s e r  later integrated using our connectors (Example V.2) and compiled in a deployment model executed in an Apache Big Data ecosystem. Figure <ref type="figure" target="#fig_5">5</ref> presents an excerpt of the script that drives the execution using the DSL language of Spring Cloud Data Flow.</p><p>In the experiments, we produced the predictive models of 4 different sensors located in different stations in Lombardy. Table <ref type="table">I</ref> describes the computational overhead introduced by our methodology in the deployment of the whole Big Data computation (global), and each single process (training and prediction). We considered the time needed to generate the procedural and the deployment models. In general, we observe that the computational overhead of our approach (8.3s) is negligible. In the same way, the time needed to deploy a connector between the two platforms is negligible, especially when the connector is a Kafka queue that permits to inject the model calculated in the training phase to the evaluation platform.</p><p>To evaluate the scalability of our approach, we also evaluated the computational overhead of our approach using synthetic procedural models automatically generated varying the number of nodes in 1, 2, 5, 10, 20, 25, and split operators in 1, 2, 4. Figure <ref type="figure" target="#fig_6">6</ref> shows that the time required to generate the procedural (Figure <ref type="figure" target="#fig_6">6(a)</ref>) and the deployment (Figure <ref type="figure" target="#fig_6">6(b)</ref>) models grows linearly with the number of elements in the composition and is not affected by the number of split operators. Still, the computational overhead is manageable reaching, in the worst case, about 1.38s for procedural model and 3.11s for deployment model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Management Effort</head><p>A major goal of our methodology is to reduce the effort needed to implement a computation, drastically decreasing the software development costs. We then provided a quantitative evaluation comparing the management effort required by our methodology against an estimation of the costs of developing a Big Data computation from scratch. We first measured the average management effort (in person months -PM) required by our reference scenario and other 4 pilots of similar complexity in different domains (i.e., security, energy, web advertisement, space). Here, the average time for creating the declarative model was equal to 0.77 PM, 1.06 PM for creating the procedural model. To estimate the software development cost, we used the intermediate Constructive Cost Model (COCOMO) methodology <ref type="bibr" target="#b18">[19]</ref>, which computes the cost as a function of the program size (Source Lines of Code -SLOC) and a set of "cost drivers" that include subjective assessment of the products, hardware, personnel, and project attributes. <ref type="foot" target="#foot_1">2</ref>  Finally, Table <ref type="table" target="#tab_4">III</ref> shows the accuracy of the labeling process. We note that, though accuracy maximization was not the primary goal of our MBDAaaS methodology and no optimization was done on the analytics, we achieved good labeling results (max mean error 14.1%). These results show the added value of our approach, which incidentally reduces roll-out time of analytics increasing their re-usability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSIONS</head><p>We presented a model-based methodology for Big Data Analytics-as-a-Service that extends existing solutions along three lines. First, our methodology supports the event-driven interconnection of stream and batch computations running on different platforms. The computations are implemented as composite services, where connectors automatically guarantee correct and consistent data flowing between them. Second, building on service connectors, our methodology implements smart compilers supporting the deployment of interconnected computations on multiple platforms. Finally, our methodology supports end-to-end verification of design specifications (from declarative to deployment models). This paper leaves space for future work: the use of a hierarchical catalogue of services, which integrates catalogues of different platforms; the definition of an approach that ranks suitable (according to users' requirements) procedural models identifying the optimal one; the implementation of an extended compiler that deploys the optimal computations on multiple platforms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. An excerpt of declarative model in Example IV.1 (training step)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Procedural models for training (a) and prediction (b).</figDesc><graphic url="image-2.png" coords="5,180.66,72.20,110.68,141.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>RS 2</head><label>2</label><figDesc>in Example IV.1. Figure 3(a) presents the procedural model of the training step (batch) of our reference scenario. It is composed of three phases: data acquisition from sensors using FTP (services FTP Stream *), a filtering state for training data preparation (service Clean *), and parallel computation of different regression models (services Regression Model Generator *).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 (</head><label>3</label><figDesc>b) presents the procedural model of the prediction step (stream). It is composed of three phases: data acquisition from a specific sensor (service Source Stream), data prediction and labeling (service Predictive Labeling), and data storage (service Store Results).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The scheme constructing a Connector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. An excerpt of the DSL output of the Execution Model compiler.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Compilation time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>or anomalous,respeectively. We then define a single declarative model consisting of two documents, each specifying the goals of one process. We note that, for simplicity, G=(I, O) is denoted as G.I.O in the examples. The first specification RS 1 (training) defines the following goals:</figDesc><table><row><cell cols="5">Data Preparation.Data Transformation.Filtering;</cell></row><row><cell cols="5">Data Analitycs.Learning Approach.Supervised;</cell></row><row><cell cols="4">Data Analitycs.Learning Step.Training;</cell><cell></cell></row><row><cell cols="4">Data Analitycs.Analytics Aim.Regression;</cell><cell></cell></row><row><cell cols="4">Data Processing.Analytics Goal.Batch.</cell><cell></cell></row><row><cell>The</cell><cell>second</cell><cell>specification</cell><cell>RS 2</cell><cell>(pre-</cell></row><row><cell>diction)</cell><cell>defines</cell><cell>the</cell><cell>following</cell><cell>goals:</cell></row><row><cell cols="5">Data Analitycs.Learning Approach.Supervised;</cell></row><row><cell cols="4">Data Analitycs.Learning Step.Prediction;</cell><cell></cell></row><row><cell cols="4">Data Analitycs.Analytics Aim.Regression;</cell><cell></cell></row><row><cell cols="5">Data Processing.Analytics Goal.Streaming. Figure</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Table II presents our results. The global management effort requested by our solution is 2.95 PM, while the average development cost calculated using COCOMO is 4.19 PM.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table II COMPARISON</head><label>II</label><figDesc>BETWEEN TIME MBDAAAS MANAGEMENT EFFORT AND SOFTWARE DEVELOPMENT COST ESTIMATED WITH COCOMO.</figDesc><table><row><cell></cell><cell></cell><cell>MBDAaaS</cell><cell></cell><cell cols="2">COCOMO</cell></row><row><cell>Project</cell><cell>Decl.</cell><cell>Proc.</cell><cell>Overhead</cell><cell>SLOC</cell><cell>Estimated</cell></row><row><cell>Phase</cell><cell>Model</cell><cell>Model</cell><cell>Costs</cell><cell></cell><cell>Duration</cell></row><row><cell>Training</cell><cell>0.75PM</cell><cell>1PM</cell><cell>4.9s</cell><cell>857</cell><cell>3.55P M</cell></row><row><cell>Prediction</cell><cell>0.5PM</cell><cell>0.7PM</cell><cell>3.4s</cell><cell>427</cell><cell>2.72P M</cell></row><row><cell>Global</cell><cell cols="2">2.95PM</cell><cell>8.3s</cell><cell>1284</cell><cell>4.19PM</cell></row><row><cell></cell><cell></cell><cell cols="2">Table III</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">RESULT</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Sensor Id</cell><cell>Type</cell><cell></cell><cell>Mean Error</cell><cell></cell></row><row><cell></cell><cell>134</cell><cell cols="2">Nitrogen dioxide</cell><cell>11.2%</cell><cell></cell></row><row><cell></cell><cell>101</cell><cell cols="2">Nitrogen oxides</cell><cell>13.1%</cell><cell></cell></row><row><cell></cell><cell>145</cell><cell cols="2">PM10 (SM2005)</cell><cell>12.3%</cell><cell></cell></row><row><cell></cell><cell>34</cell><cell cols="2">Sulfur Dioxide</cell><cell>14.1%</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The examples proposed in this section are provided using the Toreador Lab Project available at https://gitlab.ow2.org/toreador.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Our results have been calculated using the tool provided by NASA at https://strs.grc.nasa.gov/repository/forms/cocomo-calculation/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This project was partly supported by the program "piano sostegno alla ricerca 2018" funded by <rs type="funder">Universit? degli Studi di Milano</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Model-based big data analytics-as-a-service: Take big data to the next level</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ardagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bellandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bezzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ceravolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Damiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TSC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Big data computing and clouds: Trends and future directions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Assunc ??o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Calheiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Netto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on big data analytics: challenges, open research issues and tools</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Acharjya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Big data and cloud computing: A survey of the state-of-the-art and research challenges</title>
		<author>
			<persName><forename type="first">G</forename><surname>Skourletopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Mavromoustakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mastorakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Batalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dobre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Panagiotakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pallis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Mobile Cloud Computing and Big Data in the 5G Era</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Mavromoustakis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Mastorakis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Dobre</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="23" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Big data computing and clouds: Trends and future directions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Assuncao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Calheiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Netto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">80</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Service-generated big data and big data-as-a-service: An overview</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Big Data Congress</title>
		<meeting>of the IEEE Big Data Congress<address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06">2013. June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Leveraging the capabilities of service-oriented decision support systems: Putting analytics and big data in cloud</title>
		<author>
			<persName><forename type="first">H</forename><surname>Demirkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Delen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="412" to="421" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Big data analytics as-a-service: Issues and challenges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ardagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ceravolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Damiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of PSBD 2016</title>
		<meeting>of PSBD 2016<address><addrLine>Washington, VA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12">December 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Big data orchestration as a service network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="94" to="101" />
			<date type="published" when="2017-09">Sep. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cost-benefit analysis of cloud computing versus desktop grids</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><surname>Javadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Malecot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IPDPS</title>
		<meeting>of IPDPS<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-05">2009. May 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards the evaluation of a big data-as-a-service model: a decision theoretic approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Skourletopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Mavromoustakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chatzimisios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mastorakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Batalla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of INFOCOM WORKSHOPS 2016</title>
		<meeting>of INFOCOM WORKSHOPS 2016<address><addrLine>San CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-04">April 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hidden technical debt in machine learning systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Davydov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Crespo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dennison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS 2015</title>
		<meeting>of NIPS 2015<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12">December 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A model-driven methodology for big data analytics-as-a-service</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ardagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bellandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bezzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ceravolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Damiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of BigData Congress</title>
		<meeting>of BigData Congress<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06">2017. June 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bringing semantics to web services: The OWL-S approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paolucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcilraith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burnstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mc-Dermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sabou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Solanki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SWSWPC 2004</title>
		<meeting>of SWSWPC 2004<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07">July 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Data stream clustering: A survey</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Faria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>De Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM CSUR</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data stream verification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Algorithms</title>
		<editor>
			<persName><forename type="first">M.-Y</forename><surname>Kao</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Oozie: Towards a scalable workflow management system for hadoop</title>
		<author>
			<persName><forename type="first">M</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Battisha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdelnur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 1st ACM SIGMOD Workshop SWEET 2012</title>
		<meeting>of 1st ACM SIGMOD Workshop SWEET 2012<address><addrLine>Scottsdale, AR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The big data ecosystem at linkedin</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sumbaly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kreps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGMOD 2013</title>
		<meeting>of ACM SIGMOD 2013<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Software Cost Estimation with Cocomo II with Cdrom, 1st ed</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><surname>Reifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chulani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Madachy</surname></persName>
		</author>
		<author>
			<persName><surname>Steece</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Prentice Hall PTR</publisher>
			<pubPlace>Upper Saddle River, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
